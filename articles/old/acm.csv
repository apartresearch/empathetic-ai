"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"AANIM2W4","conferencePaper","2013","Jo, Doori; Han, Jooyun; Chung, Kyungmi; Lee, Sukhan","Empathy between human and robot?","Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction","978-1-4673-3055-8","","","","This paper aims at finding the answer to the essential question: Can people perceive a robot's presence as having a social existence? We attempt to apply a sociological and psychological approach to understand the influence of robot beings, by observing human emotion and perception changes while subjects watched a funny video clip in the presence of a robot or a human companion, each of which made their own typical laughing sounds. From this experiment, we found that the robot did not affect the human's positive emotions as much as a human companion did, but the robot did discourage negative emotions. However, the subjects were, in general, amused when they were watching the video with the robot. This amusement is similar to the contagious effect of sharing humor with another human being. Our findings suggest that the subjects accepted the robot's presence as a kind of existence empathically.","2013-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","151–152","","","","","","","HRI '13","","","","IEEE Press","Tokyo, Japan","","","","","","ACM Digital Library","","","","","","","social robot; empathy; robot companion; human robot interaction; emotional contagion; presence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XRS6IWUN","conferencePaper","2014","Tsuji, Yuichiro; Tsukamoto, Ami; Uchida, Takashi; Hattori, Yusuke; Nishida, Ryosuke; Fukada, Chie; Ozeki, Motoyuki; Omori, Takashi; Nagai, Takayuki; Oka, Natsuki","Experimental study of empathy and its behavioral indices in human-robot interaction","Proceedings of the second international conference on Human-agent interaction","978-1-4503-3035-0","","10.1145/2658861.2658933","https://doi.org/10.1145/2658861.2658933","Similar to relationships between humans, a person desiring to form a good relationship with a robot needs to be able to empathize with it. However, the specific kinds of human-robot interactions that would arouse and enhance empathy for the robot in the user's mind have not yet been clarified. In addition, the human behavioral traits that may be regarded as indices of empathy have not been investigated extensively. In an attempt to address these two issues, a preliminary experiment on empathy in human-robot interaction is conducted. The results suggest that the actions of naming or comforting a robot could contribute to enhancing its user's empathy and that eye fixation could be used as an index of empathy even when the use of a subjective index is inconclusive.","2014-10-29","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","245–248","","","","","","","HAI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; behavioral indices; visual fixation time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5X69E3Q","conferencePaper","2014","Mok, Brian K.; Yang, Stephen; Sirkin, David; Ju, Wendy","Empathy: interactions with emotive robotic drawers","Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction","978-1-4503-2658-2","","10.1145/2559636.2563720","https://doi.org/10.1145/2559636.2563720","The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.","2014-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","250–251","","","","","","Empathy","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","human robot interactions; interaction design; interactive furniture; video prototyping; wizard of oz experiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DGZDG4X","conferencePaper","2019","Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji","The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot","Proceedings of the 7th International Conference on Human-Agent Interaction","978-1-4503-6922-0","","10.1145/3349537.3351891","https://doi.org/10.1145/3349537.3351891","We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.","2019-09-25","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","51–58","","","","","","","HAI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; animism; robots' perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQQUXI92","conferencePaper","2013","Rosenthal-von der Pütten, Astrid Marieke; Schulte, Frank P.; Eimler, Sabrina C.; Hoffmann, Laura; Sobieraj, Sabrina; Maderwald, Stefan; Krämer, Nicole C.; Brand, Matthias","Neural correlates of empathy towards robots","Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction","978-1-4673-3055-8","","","","We conducted an fMRI study to investigate emotionality in human-robot interaction. Subjects (N=14) were presented videos showing a human, a robot and an unanimated object, being treated in either an affectionate or a violent way. Violent interaction towards both the robot and the human resulted in similar neural activation patterns in classic limbic structures indicating that both the robot and the human elicit similar emotional reactions. However, differences in neural activity suggest that participants show more negative empathetic concern for the human in a negative situation.","2013-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","215–216","","","","","","","HRI '13","","","","IEEE Press","Tokyo, Japan","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; experimental study; functional magnetic resonance imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJCE5FWN","conferencePaper","2010","Cramer, Henriette; Goddijn, Jorrit; Wielinga, Bob; Evers, Vanessa","Effects of (in)accurate empathy and situational valence on attitudes towards robots","Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction","978-1-4244-4893-7","","","","Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.","2010-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","141–142","","","","","","","HRI '10","","","","IEEE Press","Osaka, Japan","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; social robots; emotional valence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7R28TUC","conferencePaper","2014","Obaid, Mohammad; Kuchenbrandt, Dieta; Bartneck, Christoph","Empathy and yawn contagion: can we (humans) catch yawns from robots?","Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction","978-1-4503-2658-2","","10.1145/2559636.2563702","https://doi.org/10.1145/2559636.2563702","Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.","2014-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","260–261","","","","","","Empathy and yawn contagion","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; robot; humanoid; yawn","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZF8UQNN8","conferencePaper","2015","Zuckerman, Oren; Hoffman, Guy","Empathy Objects: Robotic Devices as Conversation Companions","Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction","978-1-4503-3305-4","","10.1145/2677199.2688805","https://doi.org/10.1145/2677199.2688805","We present the notion of Empathy Objects, ambient robotic devices accompanying human-human interaction. Empathy Objects respond to human behavior using physical gestures as nonverbal expressions of their ""emotional states"". The goal is to increase people's self-awareness to the emotional state of others, leading to behavior change. We demonstrate an Empathy Object prototype, Kip1, a conversation companion designed to promote non-aggressive conversation between people.","2015-01-15","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","593–598","","","","","","Empathy Objects","TEI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","social robots; tangible interfaces; ambient devices; behavior change; companion devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9FWTCUC","journalArticle","2019","Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana","Empathic Robot for Group Learning: A Field Study","ACM Transactions on Human-Robot Interaction","","","10.1145/3300188","https://doi.org/10.1145/3300188","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.","2019-03-06","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15 21:18:35","3:1–3:34","","1","8","","J. Hum.-Robot Interact.","Empathic Robot for Group Learning","","","","","","","","","","","","March 2019","","","","C:\Users\esben\Zotero\storage\8WK2EF8I\Alves-Oliveira et al. - 2019 - Empathic Robot for Group Learning A Field Study.pdf","","","education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SKDHD9CA","conferencePaper","2015","Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.","Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696471","https://doi.org/10.1145/2696454.2696471","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","125–132","","","","","","Poor Thing! Would You Feel Sorry for a Simulated Robot?","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; robot embodiment; simulated interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Q3XVL5X","conferencePaper","2016","Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid","Map Reading with an Empathic Robot Tutor","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.","2016-03-07","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","567","","","","","","","HRI '16","","","","IEEE Press","Christchurch, New Zealand","","","","","","ACM Digital Library","","","","","","","empathy; robot-child interaction; robotic tutor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSJQF22A","journalArticle","2017","Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke","Empathy in Virtual Agents and Robots: A Survey","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/2912150","https://doi.org/10.1145/2912150","This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.","2017-09-19","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15 21:18:40","11:1–11:40","","3","7","","ACM Trans. Interact. Intell. Syst.","Empathy in Virtual Agents and Robots","","","","","","","","","","","","October 2017","","","","","","","virtual agents; empathy; affective computing; human-computer interaction; human-robot interaction; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YREHDATV","conferencePaper","2019","Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie","Development of a Cloud-based Computational Framework for an Empathetic Robot","Proceedings of the 2019 11th International Conference on Computer and Automation Engineering","978-1-4503-6287-0","","10.1145/3313991.3314018","https://doi.org/10.1145/3313991.3314018","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.","2019-02-23","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","102–108","","","","","","","ICCAE 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","deep learning; robot; cloud control; emotion classification; intent perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY4IZRD9","conferencePaper","2015","Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana","The Empathic Robotic Tutor: Featuring the NAO Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702100","https://doi.org/10.1145/2701973.2702100","We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","285","","","","","","The Empathic Robotic Tutor","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","educational robotics; empathic robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMKPTC6Z","conferencePaper","2012","Leite, Iolanda; Castellano, Ginevra; Pereira, André; Martinho, Carlos; Paiva, Ana","Modelling empathic behaviour in a robotic game companion for children: an ethnographic study in real-world settings","Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction","978-1-4503-1063-5","","10.1145/2157689.2157811","https://doi.org/10.1145/2157689.2157811","The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with.","2012-03-05","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","367–374","","","","","","Modelling empathic behaviour in a robotic game companion for children","HRI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","children; empathy; social robots; affect recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KVYBEWRW","conferencePaper","2011","Leite, Iolanda","Using adaptive empathic responses to improve long-term interaction with social robots","Proceedings of the 19th international conference on User modeling, adaption, and personalization","978-3-642-22361-7","","","","The goal of this research is to investigate the effects of empathy and adaptive behaviour in long-term interaction between social robots and users. To address this issue, we propose an action selection mechanism that will allow a social robot to chose adaptive empathic responses, in the attempt to keep users engaged over several interactions.","2011-07-11","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","446–449","","","","","","","UMAP'11","","","","Springer-Verlag","Berlin, Heidelberg","","","","","","ACM Digital Library","","","","","","","empathy; social robots; adaptive feedback; affective user modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78NAU3Q4","conferencePaper","2015","Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Foster, Mary Ellen; Ribeiro, Tiago; Corrigan, Lee Joseph; Aylett, Ruth; Paiva, Ana; Papadopoulos, Fotios; Castellano, Ginevra","Empathic Robotic Tutors: Map Guide","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702693","https://doi.org/10.1145/2701973.2702693","In this demonstration we describe a scenario developed in the EMOTE project. The overall goal of the project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. We are aiming to develop an empathic robot tutor to teach map reading skills with this scenario on a touch-screen device.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","311","","","","","","Empathic Robotic Tutors","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FB4B3Q6X","conferencePaper","2015","De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe; Carofiglio, Valeria","Modeling and Simulating Empathic Behavior in Social Assistive Robots","Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter","978-1-4503-3684-0","","10.1145/2808435.2808445","https://doi.org/10.1145/2808435.2808445","Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living.","2015-09-28","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","110–117","","","","","","","CHItaly 2015","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Affective Computing; Social Assistive Robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHBHCPCS","conferencePaper","2014","Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth","Towards a serious game playing empathic robotic tutorial dialogue system","Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction","978-1-4503-2658-2","","10.1145/2559636.2563707","https://doi.org/10.1145/2559636.2563707","There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.","2014-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","180–181","","","","","","","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","serious games; dialogue management; empathic robotic tutor; tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSUY4Y68","journalArticle","2015","Leite, Iolanda","Long-term interactions with empathic social robots","AI Matters","","","10.1145/2735392.2735397","https://doi.org/10.1145/2735392.2735397","We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.","2015-03-10","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15 21:18:51","13–15","","3","1","","AI Matters","","","","","","","","","","","","","March 2015","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KC23H3EE","conferencePaper","2015","Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro","An Empathic Robotic Tutor in a Map Application","Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems","978-1-4503-3413-6","","","","In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.","2015-05-04","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1923–1924","","","","","","","AAMAS '15","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3BP727I","conferencePaper","2019","Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amélie; Lefort, Mathieu; Hassas, Salima","The RoPE scale: a measure of how empathic a robot is perceived","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.","2019-03-11","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","656–657","","","","","","The RoPE scale","HRI '19","","","","IEEE Press","Daegu, Republic of Korea","","","","","","ACM Digital Library","","","","","","","human-robot interaction; social robots; perceived empathy; psychometrics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KDAFW6FD","conferencePaper","2017","Hieida, Chie; Nagai, Takayuki","A Model of Emotion for Empathic Communication","Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4885-0","","10.1145/3029798.3038299","https://doi.org/10.1145/3029798.3038299","Most people believe that robots have no emotions, and nor do they need them. However, we strongly believe that having emotions is essential for robots to understand and sympathize with the feelings of people, thereby allowing them to be accepted into the human society. In this paper, we propose a model of emotion based on some neurological and psychological findings concerning empathic communication between humans and robots. Then, we examine a method for generating affect for given visual stimuli using a recurrent neural network as a first step.","2017-03-06","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","133–134","","","","","","","HRI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathic human-robot interaction; model of emotion; recurrent-attention model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EF3U5PU9","conferencePaper","2013","Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth","Towards empathic artificial tutors","Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction","978-1-4673-3055-8","","","","In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.","2013-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","113–114","","","","","","","HRI '13","","","","IEEE Press","Tokyo, Japan","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTWD89GB","bookSection","2020","Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri","Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419900","Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.","2020-11-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","262–266","","","","","","Playing with the Opposite of Uncanny","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotional intelligence; human-computer interaction; child-robot interaction; human-animal interaction; playful learning; robot toys; social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6WRPPFGX","conferencePaper","2016","Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne","I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor","Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems","978-1-4503-4239-1","","","","We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.","2016-05-09","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","931–939","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","empathy; human-agent interaction; human-robot interaction; memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4W8E3RGE","conferencePaper","2020","Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423864","https://doi.org/10.1145/3383652.3423864","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).","2020-10-20","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1–3","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; conversational agent; emotion detection; healthcare computing; pattern matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFD4D4HD","conferencePaper","2018","Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor","He who hesitates is lost (...in thoughts over a robot)","Proceedings of the Technology, Mind, and Society","978-1-4503-5420-2","","10.1145/3183654.3183703","https://doi.org/10.1145/3183654.3183703","In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.","2018-04-05","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1–6","","","","","","","TechMindSociety '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JCIVLLF","conferencePaper","2015","Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani Sherman, Tal","Design and Evaluation of a Peripheral Robotic Conversation Companion","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696495","https://doi.org/10.1145/2696454.2696495","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","3–10","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\MLNZIAL8\Hoffman et al. - 2015 - Design and Evaluation of a Peripheral Robotic Conv.pdf","","","empathy; human-robot interaction; design; behavior change; ambient kinetic tangibles; robotic companions; smartphone robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USK294DF","conferencePaper","2015","Franco, Gloria Adriana Mendoza","Evaluation of the emotional answer in HRI on a game situation","Proceedings of the Latin American Conference on Human Computer Interaction","978-1-4503-3960-5","","10.1145/2824893.2824897","https://doi.org/10.1145/2824893.2824897","This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.","2015-11-18","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1–7","","","","","","","CLIHC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; interaction design; HRI; Emocards; emotional evaluation; emotional reciprocity; lottery application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TFYW6FRB","conferencePaper","2010","Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Castellano, Ginevra; Martinho, Carlos; Prada, Rui; Paiva, Ana","Closing the loop: from affect recognition to empathic interaction","Proceedings of the 3rd international workshop on Affective interaction in natural environments","978-1-4503-0170-1","","10.1145/1877826.1877839","https://doi.org/10.1145/1877826.1877839","Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.","2010-10-29","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","43–48","","","","","","Closing the loop","AFFINE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; affect recognition; artificial companions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVTQ5GVJ","conferencePaper","2018","Björling, Elin A.; Rose, Emma; Ren, Rachel","Teen-Robot Interaction: A Pilot Study of Engagement with a Low-fidelity Prototype","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177068","https://doi.org/10.1145/3173386.3177068","Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies.","2018-03-01","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","69–70","","","","","","Teen-Robot Interaction","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\RPVKZPA8\Björling et al. - 2018 - Teen-Robot Interaction A Pilot Study of Engagemen.pdf","","","engagement; prototype; teen-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZH8PQFSM","conferencePaper","2018","Kang, Dahyun; Kim, SunKyoung; Kwak, Sonya S.","The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177023","https://doi.org/10.1145/3173386.3177023","We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand.","2018-03-01","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","143–144","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; functional intimacy; knowledgeableness; physical contact; safety; sociability; social distance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XN5SS8TT","conferencePaper","2012","Stienstra, Jelle; Marti, Patrizia","Squeeze me: gently please","Proceedings of the 7th Nordic Conference on Human-Computer Interaction: Making Sense Through Design","978-1-4503-1482-4","","10.1145/2399016.2399131","https://doi.org/10.1145/2399016.2399131","This paper presents the Squeeze Me, a research-through-design case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a double-layered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge.","2012-10-14","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","746–750","","","","","","Squeeze me","NordiCHI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; interaction design; continuous mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTP6JBLY","conferencePaper","2015","Jeong, Seongmi; Gu, Jihyang; Shin, Dong-Hee","I am Interested in What You are Saying: Role of Nonverbal Immediacy Cues in Listening","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702040","https://doi.org/10.1145/2701973.2702040","Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","129–130","","","","","","I am Interested in What You are Saying","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","hri; immediacy; nodding; nonverbal behavior; posture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALXJ9M2S","conferencePaper","2015","Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung","Design of Emotional Conversations with a Child for a Role Playing Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702009","https://doi.org/10.1145/2701973.2702009","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","73–74","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotional role playing robot; human intervention device; human-robot-interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUV5Y7SW","conferencePaper","2020","Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vázquez, Marynel","Prompting Prosocial Human Interventions in Response to Robot Mistreatment","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-6746-2","","10.1145/3319502.3374781","https://doi.org/10.1145/3319502.3374781","Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N=30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.","2020-03-09","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","211–220","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","human-robot interaction; prosocial behavior; robot abuse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ME7TVLW","conferencePaper","2014","Fraga, Luís; Coelho, António; Branco, Pedro","Meet the Frumbles: a post-digital toy orchestra","Proceedings of the 11th Conference on Advances in Computer Entertainment Technology","978-1-4503-2945-3","","10.1145/2663806.2663813","https://doi.org/10.1145/2663806.2663813","""Meet the Frumbles"" is a group of felt robotic characters that talk amongst themselves and interact with the audience. Empathy, cuteness and gags are explored as communicational facilitators and ludic interaction between a felt robot creature's orchestra and its human conductor. Creative coding using computer vision, electronic prototyping and physical actuators was used to implement the autonomous physical existence, sensing and behavior of creatures.","2014-11-11","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1–4","","","","","","Meet the Frumbles","ACE '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective computing; robotics; digital art; humor; post-digital; toys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PF7WCYFM","conferencePaper","2018","Lehmann, Hagen; Broz, Frank","Contagious Yawning in Human-Robot Interaction","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177063","https://doi.org/10.1145/3173386.3177063","This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data.","2018-03-01","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","173–174","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; behavior contagion; yawning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R7ZDSX5G","conferencePaper","2018","de Jesus Santos, Fabrícia; de Almeida, Antonio Lucas; Santos, Breno Santana; de Souza, Caio César Alves; Santos, Marcos Neto","Empathic Computer Science: A Systematic Mapping","Proceedings of the 17th Brazilian Symposium on Human Factors in Computing Systems","978-1-4503-6601-4","","10.1145/3274192.3274238","https://doi.org/10.1145/3274192.3274238","Described as the capability to understand the emotional state of an individual and often express a response that resonates with it, empathy is a crucial factor for social interactions. However, the ability to express empathy diminishes as people rely more and more on technological resources to interact. Due to fact of being an essential component to become a more effective social relationship between humans and computers, there are several approaches, techniques, methods or mechanisms to promote empathy in these interactions. This paper proposes to identify and systematize mechanisms used in Computer Science to promote empathy. Thus, it was carried out a systematic mapping on the main research databases of the area. We identified the main approaches used to promote empathy, such as Empathic Robotic Agent/Device and Empathic Virtual Agent, as well as the countries that hold the most research in this line, especially the United Kingdom, Japan and USA. In addition, it was found that this area of research is still not being explored in any significant way.","2018-10-22","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","1–5","","","","","","Empathic Computer Science","IHC 2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Empathy; Rapport; Computer Science; Secondary Study; Systematic Mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KT8P3LP","conferencePaper","2019","Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica","Good robot design or machiavellian? an in-the-wild robot leveraging minimal knowledge of passersby's culture","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019-03-11","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","382–391","","","","","","Good robot design or machiavellian?","HRI '19","","","","IEEE Press","Daegu, Republic of Korea","","","","","","ACM Digital Library","","","","","","","culture; social robots; in the wild; persuasive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZHVWYBB","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","The CoWriter Project: Teaching a Robot how to Write","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702091","https://doi.org/10.1145/2701973.2702091","This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","269","","","","","","The CoWriter Project","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\V6E57X8C\Hood et al. - 2015 - The CoWriter Project Teaching a Robot how to Writ.pdf","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PD2Z2KZM","conferencePaper","2020","Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon","Robots Teaching Recycling: Towards Improving Environmental Literacy of Children","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3379462","https://doi.org/10.1145/3371382.3379462","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.","2020-03-23","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","615–616","","","","","","Robots Teaching Recycling","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","educational robotics; children robot interaction; eco-literacy; environmental literacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q2DHD67","conferencePaper","2018","Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana","Group-based Emotions in Teams of Humans and Robots","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4953-6","","10.1145/3171221.3171252","https://doi.org/10.1145/3171221.3171252","Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.","2018-02-26","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","261–269","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotion; trust; group effects; identification; inter-group interactions; self-categorisation; human-robot teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJ5XJIZA","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696479","https://doi.org/10.1145/2696454.2696479","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015-03-02","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","83–90","","","","","","When Children Teach a Robot to Write","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\65JNBIHW\Hood et al. - 2015 - When Children Teach a Robot to Write An Autonomou.pdf","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EESENGZ","conferencePaper","2014","Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei","The fugitive: a robot in the wild","Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction","978-1-4503-2658-2","","10.1145/2559636.2559653","https://doi.org/10.1145/2559636.2559653","The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building. The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not. The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on. The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol. The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.","2014-03-03","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","111","","","","","","The fugitive","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","human-robot interaction; social robotics; robots in the wild","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VA9KUW7C","conferencePaper","2019","Vertesi, Janet","Seeing like a rover: team work and human-robot relations","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go --- in search and rescue operations, ocean voyages, or even into space --- they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019-03-11","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","152","","","","","","Seeing like a rover","HRI '19","","","","IEEE Press","Daegu, Republic of Korea","","","","","","ACM Digital Library","","","","","","","human-robot interaction; teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3I4JIGJK","conferencePaper","2010","Beck, Aryel; Hiolle, Antoine; Mazel, Alexandre; Cañamero, Lola","Interpretation of emotional body language displayed by robots","Proceedings of the 3rd international workshop on Affective interaction in natural environments","978-1-4503-0170-1","","10.1145/1877826.1877837","https://doi.org/10.1145/1877826.1877837","In order for robots to be socially accepted and generate empathy they must display emotions. For robots such as Nao, body language is the best medium available, as they do not have the ability to display facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should greatly improve its acceptance. This research investigates the creation of an ""Affect Space"" [1] for the generation of emotional body language that could be displayed by robots. An Affect Space is generated by ""blending"" (i.e. interpolating between) different emotional expressions to create new ones. An Affect Space for body language based on the Circumplex Model of emotions [2] has been created. The experiment reported in this paper investigated the perception of specific key poses from the Affect Space. The results suggest that this Affect Space for body expressions can be used to improve the expressiveness of humanoid robots. In addition, early results of a pilot study are described. It revealed that the context helps human subjects improve their recognition rate during a human-robot imitation game, and in turn this recognition leads to better outcome of the interactions.","2010-10-29","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","37–42","","","","","","","AFFINE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotional body language; human robot interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCIJ64R7","conferencePaper","2019","Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana","EmotoTent: Reducing School Violence through Embodied Empathy Games","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3326596","https://doi.org/10.1145/3311927.3326596","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.","2019-06-12","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15","755–760","","","","","","EmotoTent","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PG9DLAZL","journalArticle","2012","Beck, Aryel; Stevens, Brett; Bard, Kim A.; Cañamero, Lola","Emotional body language displayed by artificial agents","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/2133366.2133368","https://doi.org/10.1145/2133366.2133368","Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots.","2012-03-20","2021-02-15 21:19:32","2021-02-15 21:19:32","2021-02-15 21:19:32","2:1–2:29","","1","2","","ACM Trans. Interact. Intell. Syst.","","","","","","","","","","","","","March 2012","","","","C:\Users\esben\Zotero\storage\86VZVFZV\Beck et al. - 2012 - Emotional body language displayed by artificial ag.pdf","","","emotional body language; Human computer interactions; human robot interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B6UKMX4L","conferencePaper","2018","Tan, Xiang Zhi; Vázquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron","Inducing Bystander Interventions During Robot Abuse with Social Mechanisms","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4953-6","","10.1145/3171221.3171247","https://doi.org/10.1145/3171221.3171247","We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant»s performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.","2018-02-26","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","169–177","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\FBKMMCQB\Tan et al. - 2018 - Inducing Bystander Interventions During Robot Abus.pdf","","","robots; empathy; human-robot interaction; abuse; bullying; peer intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWEVNDJN","conferencePaper","2017","Thompson, Jeff","I touch you and you touch me","SIGGRAPH Asia 2017 Art Gallery","978-1-4503-5401-1","","10.1145/3143748.3143753","https://doi.org/10.1145/3143748.3143753","A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.","2017-11-27","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1","","","","","","","SA '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YQ7EMT4","conferencePaper","2016","Aylett, Ruth","Am I bovvered? Fifteen years of Empathic Agents","Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems","978-1-4503-4239-1","","","","In 2001, the EU-funded project VICTEC pioneered the concept of an Empathic Agent. This was reported at AAMAS in 2004 in a well-cited paper 'Caring for Agents and Agents that Care: Building Empathic Relations with Synthetic Agents' (Paiva, Dias, Sobral, Aylett, Sobreperez, Woods, Zoll, Hall). It advanced two goals for embodied empathic agents: characters that, by their actions and behaviours, are able to show empathy (or not) for other characters; and characters that, by their appearance, situation, and behaviour, are able to trigger empathic reactions in the user. In this talk we discuss how far Embodied Empathic Agents - whether graphical or robotic - are succeeding; what we can now do, and what open research questions remain. What are the key theoretical and technological advances already made and which are still needed? What applications are Empathic Agents `good' for, and how do we know they are? And how do they relate to the broader field of social agents?","2016-05-09","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","4","","","","","","Am I bovvered?","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5UJRNGXU","conferencePaper","2019","Aubergé, Véronique","The Socio-Affective Robot: Aimed to Understand Human Links?","Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop","978-1-4503-6913-8","","10.1145/3347320.3357687","https://doi.org/10.1145/3347320.3357687","Is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence, revealing some crucial aspects of social and cultural human processing? Among the smart objects, the social robot cannot be distinguished by precise and well defined technical or morphological cues. Even though no serious and discriminative attributes can be given by any science knowledge -- even the movement attribute, and the ""autonomous'' cognitive attribute are not clearly defined -- in order to understand how an object becomes, perceptively, a subject (social robot), it is a fact that the automatons and the talking artefacts are now named robot, which is particularly attractive for general public, for scientists and engineers. However, is it a socio-cultural desire or a technical need to add the augmentation of the social space to the ""augmented self'' (self body and self environment abilities)? In this talk we will explore some social space perturbations in ecological conditions, such as elderly people suffering from isolation and interacting with a robot that can emit solely non-verbal speech primitives. Long term interactions were collected and analysed using the concepts of the Dynamic Affective Network for Social Entities (D.A.N.S.E.) theory. We will try to show that non-verbal speech primitives, organised in the D.A.N.S.E.'s ""glue'' paradigm, permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance, but also to explore in particular an empathic dimension. Through a Living Lab method, evaluation of these hypotheses and building of an empathic socio-affective HRI were conducted together, within strong ethical constraints. In particular the development of frail robots for frail people will be proposed as possible ethical perspective.","2019-10-15","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1","","","","","","The Socio-Affective Robot","AVEC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","engagement; frail person; hri; living lab; social robot; socio-affective speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VX4TQXWM","conferencePaper","2016","Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra","How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.","2016-03-07","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","423–424","","","","","","","HRI '16","","","","IEEE Press","Christchurch, New Zealand","","","","","","ACM Digital Library","","","","","","","empathy; robotic tutors; child-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55ZWNUAG","conferencePaper","2015","Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia","Designing a socially assistive robot for pediatric care","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771923","https://doi.org/10.1145/2771839.2771923","We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.","2015-06-21","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","387–390","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGH4IF88","conferencePaper","2014","Ribeiro, Tiago; Pereira, André; Deshmukh, Amol; Aylett, Ruth; Paiva, Ana","I'm the mayor: a robot tutor in enercities-2","Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems","978-1-4503-2738-1","","","","We are addressing the problem of creating empathic robot tutors to support school students studying geography topics on a multi-touch table. A multi-role serious game Enercities-2 has been developed from an earlier single-user version in which a Mayor, Economist and Environmentalist have control over differing resources. The game explores the tension between individual and collaborative success. A robot tutor, embodied as a NAO Torso robot, can play any one of these roles. This interactive demo using a large tablet and the NAO will allow attendees to play with the robot, which currently tries to maximize the collaborative score.","2014-05-05","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1675–1676","","","","","","I'm the mayor","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","human-robot interaction; social robots; serious games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVKHPLBW","conferencePaper","2020","Kim, Jinwook; Baek, Kyungwon; Jang, Jinkyu","Petbe: Projecting a Real Being onto a Social Robot Using Contextual Data for a Pet Monitoring Method","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3378236","https://doi.org/10.1145/3371382.3378236","The demand for pet monitoring devices is growing due to the increasing number of one-person households raising pets. However, current monitoring methods using video camera entail various problems, which may lead to discontinued usage. To overcome this problem, we propose Petbe, a social robot that projects your own pet using a context-aware approach based on BLE beacons and Raspberry Pis. The corresponding smartphone application provides various robot status updates (robot head) and movements (robot body). With the development of Petbe, we conducted an exploratory study to verify the advancement of the above issues on monitoring user's own pets with the following factors: privacy concern, companionship, awareness, connectivity, and satisfaction. The outcomes indicate that Petbe helps to reduce privacy concerns and build companionship through empathetic interaction.","2020-03-23","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","290–292","","","","","","Petbe","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","social robot; context aware; pet monitoring; projection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFI93J8V","conferencePaper","2013","Plant, Nicola; Healey, Patrick G.T.","Surface tension","CHI '13 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-1952-2","","10.1145/2468356.2479589","https://doi.org/10.1145/2468356.2479589","The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?","2013-04-27","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","2979–2982","","","","","","","CHI EA '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; embodied cognition; gesture; nonverbal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88NLQ5DD","conferencePaper","2014","Aghel Manesh, Setareh; Beran, Tanya; Sharlin, Ehud; Greenberg, Saul","Medi, human robot interaction in pediatric health","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2579529","https://doi.org/10.1145/2559206.2579529","When children go through a medical procedure (e.g. a blood draw), they often experience increased levels of anxiety and stress. We believe that having an empathetic robot companion during the procedure can help children cope with pain and improve their overall experience. The robot makes use of a set of behaviors derived from pain management literature and modeled on human behaviors and cognitive behavioral therapy. In order to investigate the role of the robot as social companion, we are currently performing a Wizard of Oz study at a children's hospital. Our results are preliminary, but so far we have observed - as illustrated in the video - that the robot can improve the experience for children as long as they are not highly agitated.","2014-04-26","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","153–154","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","social robots; human robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LUUP24Q","conferencePaper","2019","Degraen, Donald; Kosmalla, Felix; Krüger, Antonio","Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3312833","https://doi.org/10.1145/3290607.3312833","Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.","2019-05-02","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1–6","","","","","","Overgrown","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","ambient notifications; empathic living media; focus group; ambient interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7I4CGC9S","bookSection","2020","Pollmann, Kathrin; Ziegler, Daniel","Personal quizmaster: a pattern approach to personalized interaction experiences with the MiRo robot","Proceedings of the Conference on Mensch und Computer","978-1-4503-7540-5","","","https://doi.org/10.1145/3404983.3410414","In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes.","2020-09-06","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","485–489","","","","","","Personal quizmaster","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","social robot; behavioral patterns; multimodal behavioral expressions; personalized human-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63MKJYFJ","conferencePaper","2019","Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher","Mutual reinforcement learning with robot trainers","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.","2019-03-11","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","572–573","","","","","","","HRI '19","","","","IEEE Press","Daegu, Republic of Korea","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5P4K95CC","conferencePaper","2016","Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia","Affect-Aware Student Models for Robot Tutors","Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems","978-1-4503-4239-1","","","","Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.","2016-05-09","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","864–872","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","affective computing; child-robot interaction; socially assistive robots; educational robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEHRQMHM","conferencePaper","2018","Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia","A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.","2018-07-09","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1658–1666","","","","","","A Social Robot System for Modeling Children's Word Pronunciation","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\H6EJJB5Z\Spaulding et al. - 2018 - A Social Robot System for Modeling Children's Word.pdf","","","social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPJA645A","conferencePaper","2020","Li, Yuanchao; Zhao, Tianyu; Shen, Xun","Attention-Based Multimodal Fusion for Estimating Human Emotion in Real-World HRI","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3378261","https://doi.org/10.1145/3371382.3378261","Toward empathetic and harmonious human-robot interaction (HRI), automatic estimation of human emotion has attracted increasing attention from multidisciplinary research fields. In this report, we propose an attention-based multimodal fusion approach that explores the space between traditional early and late fusion approaches, to deal with the problem of asynchronous multimodal inputs while considering their relatedness. The proposed approach enables the robot to align the human's visual and speech signals (more specifically, facial, acoustic, and lexical information) extracted by its cameras, microphones, and processing modules and is expected to achieve robust estimation performance in real-world HRI.","2020-03-23","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","340–342","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","attention mechanism; emotion estimation; human-robot interaction (hri); multimodal fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79SDNDSF","conferencePaper","2010","McDonnell, Rachel; Breidt, Martin","Face reality: investigating the Uncanny Valley for virtual faces","ACM SIGGRAPH ASIA 2010 Sketches","978-1-4503-0523-5","","10.1145/1899950.1899991","https://doi.org/10.1145/1899950.1899991","The Uncanny Valley (UV) has become a standard term for the theory that near-photorealistic virtual humans often appear unintentionally erie or creepy. This UV theory was first hypothesized by robotics professor Masahiro Mori in the 1970's [Mori 1970] but is still taken seriously today by movie and game developers as it can stop audiences feeling emotionally engaged in their stories or games. It has been speculated that this is due to audiences feeling a lack of empathy towards the characters. With the increase in popularity of interactive drama video games (such as L.A. Noire or Heavy Rain), delivering realistic conversing virtual characters has now become very important in the real-time domain. Video game rendering techniques have advanced to a very high quality; however, most games still use linear blend skinning due to the speed of computation. This causes a mismatch between the realism of the appearance and animation, which can result in an uncanny character. Many game developers opt for a stylised rendering (such as cel-shading) to avoid the uncanny effect [Thompson 2004]. In this preliminary work, we begin to study the complex interaction between rendering style and perceived trust, in order to provide guidelines for developers for creating plausible virtual characters.","2010-12-15","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1–2","","","","","","Face reality","SA '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L47W28NI","conferencePaper","2020","Troiano, Giovanni Maria; Wood, Matthew; Harteveld, Casper","""And This, Kids, Is How I Met Your Mother"": Consumerist, Mundane, and Uncanny Futures with Sex Robots","Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6708-0","","10.1145/3313831.3376598","https://doi.org/10.1145/3313831.3376598","Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM","2020-04-21","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1–17","","","","","","""And This, Kids, Is How I Met Your Mother""","CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","ethics; human-robot interaction; research fiction; sex robots; sexual HCI; speculative design; story completion method","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCZNNLQJ","conferencePaper","2015","Encinas, Enrique","Cyrafour: How Two Human Avatars Communicate With Each Other","Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-3146-3","","10.1145/2702613.2726962","https://doi.org/10.1145/2702613.2726962","Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.","2015-04-18","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","109–114","","","","","","Cyrafour","CHI EA '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MEFVKNRK","conferencePaper","2016","Shinohara, Yumiko; Kubo, Katsuhiro; Nozawa, Momoyo; Yoshizaki, Misa; Takahashi, Tomomi; Hayakawa, Hirofumi; Hirota, Atsushi; Nishizaki, Yukiko; Oka, Natsuki","The Optimum Rate of Mimicry in Human-Agent Interaction","Proceedings of the Fourth International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2980506","https://doi.org/10.1145/2974804.2980506","The importance of building rapport between a human and an agent is increasing with the burgeoning development of robot technology. Several recent studies have focused on the chameleon effect, using psychological concepts to investigate human-agent interaction. However, the validity of the chameleon effect in human-agent interaction is controversial. Few studies have explored the influence of individual cognitive ability and the rate of mimicry on the human-agent interaction. We explored the optimal rate of mimicry and the relationship between mimicry rate and individual empathic ability. We controlled the amount of agent mimicry and examined the effect on participants classified as high- and low-perspective takers. We found that, overall, participants preferred agents that mimicked their behavior 83% of the time. Moreover, high-, but not low-, perspective takers tended to be influenced by the mimicry rate.","2016-10-04","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","367–370","","","","","","","HAI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","human-agent interaction; perspective taking; mimicry; impression of robot; the chameleon effect","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKE7CXBZ","conferencePaper","2018","Hieida, Chie; Horii, Takato; Nagai, Takayuki","Decision-Making in Emotion Model","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177048","https://doi.org/10.1145/3173386.3177048","Having emotions is essential for robots to understand and sympathize with the feelings of people. In addition, it may allow the robots to be accepted into human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions based on various neurological and psychological findings that are related to empathic communication between humans and robots is proposed. Subsequently, a mechanism of decision-making that is based on affects using convolutional LSTM and deep Q-network is examined.","2018-03-01","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","127–128","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\UTR3MLNI\Hieida et al. - 2018 - Decision-Making in Emotion Model.pdf","","","decision-making; model of emotion; empathic hri","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3L7FR3BN","conferencePaper","2018","Spaulding, Samuel","Personalized Robot Tutors that Learn from Multimodal Data","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.","2018-07-09","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","1781–1783","","","","","","","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\2748W25F\Spaulding - 2018 - Personalized Robot Tutors that Learn from Multimod.pdf","","","human-robot interaction; social robotics; multimodal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HTWUJK4G","conferencePaper","2016","Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka","Sharing Emotion Described as Text on the Internet by Changing Self-physiological Perception","Proceedings of the Fourth International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2974825","https://doi.org/10.1145/2974804.2974825","Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.","2016-10-04","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","145–153","","","","","","","HAI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIJWLJTD","conferencePaper","2014","Iacono, Iolanda; Marti, Patrizia","Engaging older people with participatory design","Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational","978-1-4503-2542-4","","10.1145/2639189.2670180","https://doi.org/10.1145/2639189.2670180","We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.","2014-10-26","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","859–864","","","","","","","NordiCHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; participatory design; older people; gaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3A6EKVT","conferencePaper","2019","Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania","Ballbit Adventure: A Physical Game for a Collaborative Racing","Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts","978-1-4503-6871-1","","10.1145/3341215.3356982","https://doi.org/10.1145/3341215.3356982","Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.","2019-10-17","2021-02-15 21:20:47","2021-02-15 21:20:47","2021-02-15","97–103","","","","","","Ballbit Adventure","CHI PLAY '19 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TCKB9I5","conferencePaper","2015","Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana","The Empathic Robotic Tutor: Featuring the NAO Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702100","https://doi.org/10.1145/2701973.2702100","We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.","2015-03-02","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","285","","","","","","The Empathic Robotic Tutor","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","educational robotics; empathic robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYLA8JJ2","conferencePaper","2016","Liu, Xin; London, Kati","T.A.I: A Tangible AI Interface to Enhance Human-Artificial Intelligence (AI) Communication Beyond the Screen","Proceedings of the 2016 ACM Conference on Designing Interactive Systems","978-1-4503-4031-1","","10.1145/2901790.2901896","https://doi.org/10.1145/2901790.2901896","Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.","2016-06-04","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","281–285","","","","","","T.A.I","DIS '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective communication; shape-changing interface; social agent; tangible interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NXJC9PC","conferencePaper","2013","Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria","3D animated agent for tutoring based on WebGL","Proceedings of the 18th International Conference on 3D Web Technology","978-1-4503-2133-4","","10.1145/2466533.2466534","https://doi.org/10.1145/2466533.2466534","The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.","2013-06-20","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","129–134","","","","","","","Web3D '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","artificial intelligence; e-learning; virtual agents; Web3D technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FURDLKM6","conferencePaper","2019","Shvo, Maayan","Towards Empathetic Planning and Plan Recognition","Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","978-1-4503-6324-2","","10.1145/3306618.3314307","https://doi.org/10.1145/3306618.3314307","Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants.","2019-01-27","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","525–526","","","","","","","AIES '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","AI planning; plan recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZC7HT38","conferencePaper","2019","Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco","A Preliminary Work on Dog Emotion Recognition","IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume","978-1-4503-6988-6","","10.1145/3358695.3361750","https://doi.org/10.1145/3358695.3361750","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.","2019-10-14","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","91–96","","","","","","","WI '19 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDHCLWXP","conferencePaper","2019","Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana","EmotoTent: Reducing School Violence through Embodied Empathy Games","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3326596","https://doi.org/10.1145/3311927.3326596","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.","2019-06-12","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","755–760","","","","","","EmotoTent","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35PPCNN6","conferencePaper","2019","Aubergé, Véronique","The Socio-Affective Robot: Aimed to Understand Human Links?","Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop","978-1-4503-6913-8","","10.1145/3347320.3357687","https://doi.org/10.1145/3347320.3357687","Is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence, revealing some crucial aspects of social and cultural human processing? Among the smart objects, the social robot cannot be distinguished by precise and well defined technical or morphological cues. Even though no serious and discriminative attributes can be given by any science knowledge -- even the movement attribute, and the ""autonomous'' cognitive attribute are not clearly defined -- in order to understand how an object becomes, perceptively, a subject (social robot), it is a fact that the automatons and the talking artefacts are now named robot, which is particularly attractive for general public, for scientists and engineers. However, is it a socio-cultural desire or a technical need to add the augmentation of the social space to the ""augmented self'' (self body and self environment abilities)? In this talk we will explore some social space perturbations in ecological conditions, such as elderly people suffering from isolation and interacting with a robot that can emit solely non-verbal speech primitives. Long term interactions were collected and analysed using the concepts of the Dynamic Affective Network for Social Entities (D.A.N.S.E.) theory. We will try to show that non-verbal speech primitives, organised in the D.A.N.S.E.'s ""glue'' paradigm, permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance, but also to explore in particular an empathic dimension. Through a Living Lab method, evaluation of these hypotheses and building of an empathic socio-affective HRI were conducted together, within strong ethical constraints. In particular the development of frail robots for frail people will be proposed as possible ethical perspective.","2019-10-15","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1","","","","","","The Socio-Affective Robot","AVEC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","engagement; frail person; hri; living lab; social robot; socio-affective speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGRSSFNU","journalArticle","2020","McDonald, Nora; Pan, Shimei","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proceedings of the ACM on Human-Computer Interaction","","","10.1145/3415218","https://doi.org/10.1145/3415218","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.","2020-10-14","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15 21:25:13","147:1–147:19","","CSCW2","4","","Proc. ACM Hum.-Comput. Interact.","Intersectional AI","","","","","","","","","","","","October 2020","","","","","","","artificial intelligence; ethics; algorithm bias; education; intersectionality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4K2LKQ4","journalArticle","2016","Katsimerou, Christina; Albeda, Joris; Huldtgren, Alina; Heynderickx, Ingrid; Redi, Judith A.","Crowdsourcing Empathetic Intelligence: The Case of the Annotation of EMMA Database for Emotion and Mood Recognition","ACM Transactions on Intelligent Systems and Technology","","2157-6904","10.1145/2897369","https://doi.org/10.1145/2897369","Unobtrusive recognition of the user's mood is an essential capability for affect-adaptive systems. Mood is a subtle, long-term affective state, often misrecognized even by humans. The challenge to train a machine to recognize it from, for example, a video of the user, is significant, and already begins with the lack of ground truth for supervised learning. Existing affective databases consist mainly of short videos, annotated in terms of expressed emotions rather than mood. In very few cases, we encounter perceived mood annotations, of questionable reliability, however, due to the subjectivity of mood estimation and the small number of coders involved. In this work, we introduce a new database for mood recognition from video. Our database contains 180 long, acted videos, depicting typical daily scenarios, and subtle facial and bodily expressions. The videos cover three visual modalities (face, body, Kinect data), and are annotated in terms of emotions (via G-trace) and mood (via the Self-Assessment Manikin and the AffectButton). To annotate the database exhaustively, we exploit crowdsourcing to reach out to an extensive number of nonexpert coders. We validate the reliability of our crowdsourced annotations by (1) adopting a number of criteria to filter out unreliable coders, and (2) comparing the annotations of a subset of our videos with those collected in a controlled lab setting.","2016-05-02","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15 21:25:14","51:1–51:27","","4","7","","ACM Trans. Intell. Syst. Technol.","Crowdsourcing Empathetic Intelligence","","","","","","","","","","","","July 2016","","","","","","","emotion recognition; affective annotation; crowdsourcing; mood recognition; Multimodal database","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3WVULUQ","journalArticle","2017","Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke","Empathy in Virtual Agents and Robots: A Survey","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/2912150","https://doi.org/10.1145/2912150","This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.","2017-09-19","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15 21:25:15","11:1–11:40","","3","7","","ACM Trans. Interact. Intell. Syst.","Empathy in Virtual Agents and Robots","","","","","","","","","","","","October 2017","","","","","","","virtual agents; empathy; affective computing; human-computer interaction; human-robot interaction; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TI9V22TG","conferencePaper","2018","Dudzik, Bernd; Hung, Hayley; Neerincx, Mark; Broekens, Joost","Artificial Empathic Memory: Enabling Media Technologies to Better Understand Subjective User Experience","Proceedings of the 2018 Workshop on Understanding Subjective Attributes of Data, with the Focus on Evoked Emotions","978-1-4503-5978-8","","10.1145/3267799.3267801","https://doi.org/10.1145/3267799.3267801","An essential part of being an individual is our personal history, in particular our episodic memories. Episodic memories revolve around events that took place in a person's past and are typically defined by a time, place, emotional associations, and other contextual information. They form an important driver for our emotional and cognitive interpretation of what is currently happening. This includes interactions with media technologies. However, current approaches for personalizing interactions with these technologies are neither aware of what episodic memories are triggered in users, nor of their emotional interpretations of those memories. We argue that this is a serious limitation, because it prevents applications from correctly estimating users' experiences. In short, such technologies lack empathy. In this position paper, we argue that media technologies need an Artificial Empathic Memory (AEM) of their users to address this issue. We propose a psychologically inspired architecture, examine the challenges to be solved, and highlight how existing research can become a starting point for overcoming them.","2018-10-15","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–8","","","","","","Artificial Empathic Memory","EE-USAD'18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective computing; empathic technology; episodic memory; media-evoked emotions; personalization; user modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LXEN89GW","conferencePaper","2013","Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth","Towards empathic artificial tutors","Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction","978-1-4673-3055-8","","","","In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.","2013-03-03","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","113–114","","","","","","","HRI '13","","","","IEEE Press","Tokyo, Japan","","","","","","ACM Digital Library","","","","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC2UWZKT","conferencePaper","2010","Saunier, Julien; Jones, Hazael; Lourdeaux, Domitile","Empathy and Placebo for Autonomous Agents","Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 02","978-0-7695-4191-4","","10.1109/WI-IAT.2010.255","https://doi.org/10.1109/WI-IAT.2010.255","Computational modeling of emotion, physiology and personality is a major challenge in order to design believable virtual humans. These factors have an impact on both the individual behavior and the collective one. This requires to take into account the empathy phenomenon. Furthermore, in a crisis simulation context where the virtual humans can be contaminated by radiological or chemical substances, empathy may lead to placebo or nocebo effects. Stemming from works in the multi-agent systems (MAS) domain, we consider that a virtual human has two parts, its mind and its body. The agent is influenced by the mind, but controlled by the environment which manages the empathy and nocebo process. We describe these mechanisms and show the results of several experiments.","2010-08-31","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","277–282","","","","","","","WI-IAT '10","","","","IEEE Computer Society","USA","","","","","","ACM Digital Library","","","","","","","Personality; Emotions; Empathy; Multi-agent architecture; Placebo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XT6MUJQP","conferencePaper","2016","Oduola, Cassandra","Assessing Empathy through Mixed Reality","Companion Publication of the 21st International Conference on Intelligent User Interfaces","978-1-4503-4140-0","","10.1145/2876456.2876466","https://doi.org/10.1145/2876456.2876466","This research seeks to produce a new way of assessing empathy in individuals. The current widely used diagnostic tools are questionnaires. These questionnaires are easy to ""pass"" if the individual simply lies and chooses the answers that would be most beneficial to them. Furthermore, it is shown, assessing empathy is harder in a clinical setting because it is not the natural world, a person may purposely inhibit their behavior to seem more ""normal"". Finding methods that would assess affect while interacting with a computer could yield higher accuracy in diagnosis","2016-03-07","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","142–145","","","","","","","IUI '16 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective computing; virtual reality; mixed reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LYFHZM9H","conferencePaper","2018","Richards, Deborah; Bilgin, Ayse Aysin; Ranjbartabar, Hedieh","Users' perceptions of empathic dialogue cues: A data-driven approach to provide tailored empathy","Proceedings of the 18th International Conference on Intelligent Virtual Agents","978-1-4503-6013-5","","10.1145/3267851.3267857","https://doi.org/10.1145/3267851.3267857","Understanding how and in what circumstances users respond to different verbal expressions of empathy will be important for designing Intelligent Virtual Agents able to influence the emotions and intrinsic motivations of users. We report a study to teach healthy study habits and tips involving 239 undergraduate students, 161 of which interacted with a character designed to express empathy through dialogue. We elicited participants' personality and psychological state (depression, anxiety and stress levels) and attitudes to study. In this paper we present a detailed analysis of participants' responses to specific empathic dialogue snippets designed to include one or more empathic cues to determine whether they found it helpful, stupid or empathic. We provide an example of how we have used data mining on our dataset to suggest which cues are most appropriate to which user types to enhance user models and improve agent decision-making regarding the expression of empathy.","2018-11-05","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","35–42","","","","","","Users' perceptions of empathic dialogue cues","IVA '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","data mining; empathic dialog; Intelligent Virtual Agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8ASJEL5","conferencePaper","2013","Kim, Hyun-Jun; Choi, Young Sang","A Peak Detection Method for Understanding User States for Empathetic Intelligent Agents","Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 02","978-0-7695-5145-6","","10.1109/WI-IAT.2013.118","https://doi.org/10.1109/WI-IAT.2013.118","Recognition of facial expression is a useful and unobtrusive means for machines to understand users' internal states. However, most human facial expression is ambiguous or subtle to recognize resulting in poor accuracy. To overcome this limitation, we propose a peak detection method to select only meaningful images from image sequences which imply significant changes of facial expression by calculating differences between images. We believe this method will alleviate the accuracy degradation caused by different personal appearances and ambiguous facial expressions. When applied to commercial products, it can provides a suitable method for adaptation of the empathetic agent embedded in machines such as personal assistants on TV, smartphone and vehicles based on recognized facial expression of users. For experimental validation of the proposed method, we tested four different features for measuring image similarity with the extended Cohn-Kanade facial image dataset. As a result, we could get better recognition accuracy than the original image sequences. Moreover, we reduced the number of images that need to be recognized to 24.52% without degradation of accuracy.","2013-11-17","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","261–265","","","","","","","WI-IAT '13","","","","IEEE Computer Society","USA","","","","","","ACM Digital Library","","","","","","","Empathetic Agent; Facial Expression; Image Processing; Peak Detection; Temporal Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HT6ZJW86","conferencePaper","2019","Urakami, Jacqueline; Moore, Billie Akwa; Sutthithatip, Sujitra; Park, Sung","Users' Perception of Empathic Expressions by an Advanced Intelligent System","Proceedings of the 7th International Conference on Human-Agent Interaction","978-1-4503-6922-0","","10.1145/3349537.3351895","https://doi.org/10.1145/3349537.3351895","The goal of this study was to examine user\textquoteright s perception of expressions of empathy by an autonomous system. In a survey eight different components of empathy identified in literature studies and prior tests (Expressing own feelings, Expressing to know what the other feels, Helping, Showing interest, Taking the others perspective, Displaying regard, Situational understanding, and Agreement) were compared to neutral expressions. Differences in participants evaluations were found across the components of empathy as well as individual differences were revealed. Expressions of cognitive empathy (Showing interest, situational understanding) and expressions of empathy of assistance (helping) were perceived positively by participants. However, expressions of affective empathy (expressing own feelings, expressing to know what the other feels) received mainly negative ratings. Cluster analysis revealed individual differences especially for items relating to affective empathy. Whereas one group of participants identified in the cluster analysis rated expressions of affective empathy negatively, a second group of participants rated these expressions positively. Furthermore, large differences across participants also existed for taking the other's perspective, a component of cognitive empathy. Integrating expressions of empathy in human-machine interaction is a sensitive issue and designers must carefully choose what components of empathy are adequate depending on the situational circumstances and the targeted user group.","2019-09-25","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","11–18","","","","","","","HAI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; autonomous intelligent system; survey","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2ZY979B","conferencePaper","2014","Villarica, Ryan; Richards, Deborah","Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds","Proceedings of the 2014 Conference on Interactive Entertainment","978-1-4503-2790-9","","10.1145/2677758.2677761","https://doi.org/10.1145/2677758.2677761","Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.","2014-12-02","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–9","","","","","","","IE2014","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Empathic Agents; Omosa; Virtual Learning Environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M25V9VBT","conferencePaper","2010","Evers, Vanessa; Kröse, Ben","Toward an ambient empathic health companion for self care in the intelligent home","Proceedings of the 28th Annual European Conference on Cognitive Ergonomics","978-1-60558-946-6","","10.1145/1962300.1962387","https://doi.org/10.1145/1962300.1962387","Motivation--This paper describes our work in progress to develop a personal monitoring system that can monitor the physical and emotional condition of a patient by using contextual information from a sensor network, provide the patient with feedback concerning their health status and motivate the patient to adopt behavior with a positive health impact (such as exercising or taking medication at the right moment). Research approach -- We will extend the capabilities of an existing robotic health buddy with a (DBN based) sensor network. Then we will carry out a series of controlled, long-term field experiments where we identify and evaluate the effects of various agent social communicative behaviours on the user's adoption of health improving lifestyle patterns. Findings/Design -- The findings of the experiments will inform the final design of the health buddy and it's behaviours. We will also realise system adaptivity of the data processing and data fusion methods as well as the health buddy adaptivity to the user's emotional state. Research limitations/Implications -- The project will limit itself to monitoring and motivating people who suffer from cardiovascular chronic conditions and to the home environment. Originality/Value -- The research makes a contribution to the needs of health monitoring for a specific user group. The health buddy will use social behaviours to motivate users over a long-term time period. Take away message -- Home health monitoring and self care can be more enjoyable and easier through motivating smart health buddies.","2010-08-25","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","365–366","","","","","","","ECCE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective technology; embodied social agent; health buddy; sensor networks for health monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHYA7364","conferencePaper","2020","Yao, Heng; de Siqueira, Alexandre Gomes; Foster, Adriana; Galynker, Igor; Lok, Benjamin","Toward Automated Evaluation of Empathetic Responses in Virtual Human Interaction Systems for Mental Health Scenarios","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423916","https://doi.org/10.1145/3383652.3423916","This paper investigates the process of automating the evaluation of empathetic response levels in virtual human interaction systems implementing mental health scenarios. Two suicidal virtual patients were developed to collect clinician participants' empathetic responses. Before collecting clinicians' responses, we tested the virtual human interaction with healthcare trainees. Trainees' empathetic responses were evaluated by experts to use the ECCS scale based on the ECCS level (Empathetic Communication Coding System). We trained classifiers using trainees' empathetic responses with experts' coded empathy levels as the training dataset. Clinician participants' empathetic responses to virtual patients were evaluated by experts and the classifiers. The performance of the classifiers was evaluated using the experts' coded level of clinicians' empathetic responses as a test dataset. This work demonstrates the applicability of using virtual agents techniques to identify empathy levels of clinicians' responses automatically. This work shows the potential of using virtual human interaction to train clinicians' skills to show empathy. Corresponding feedback could be provided to clinicians based on the evaluation results. We hope this study motivates more research in using intelligent virtual agents in personal skills training in education.","2020-10-20","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–8","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","automated evaluation; empathetic response; suicidal virtual patient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WP9WJNWN","conferencePaper","2014","Billinghurst, Mark","Using augmented reality to create empathic experiences","Proceedings of the 19th international conference on Intelligent User Interfaces","978-1-4503-2184-6","","10.1145/2557500.2568057","https://doi.org/10.1145/2557500.2568057","Intelligent user interfaces have traditionally been used to create systems that respond intelligently to user input. However there is a recent trend towards Empathic Interfaces that are designed to go beyond understanding user input and to recognize emotional state and user feelings. In this presentation we explore how Augmented Reality (AR) can be used to convey that emotional state and so allow users to capture and share emotional experiences. In this way AR not only overlays virtual imagery on the real world, but also can create deeper understanding of user's experience at particular locations and points in time. The recent emergence of truly wearable systems, such as Google Glass, provide a platform for Empathic Communication using AR. Examples will be shown from research conducted at the HIT Lab NZ and other research organizations, and key areas for future research described.","2014-02-24","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","5–6","","","","","","","IUI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","augmented reality; collaboration; empathic computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3E2ZU7S","conferencePaper","2020","Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423864","https://doi.org/10.1145/3383652.3423864","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).","2020-10-20","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–3","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; conversational agent; emotion detection; healthcare computing; pattern matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSC43SS7","conferencePaper","2019","Tahara, Shunichi; Ikeda, Kazushi; Hoashi, Keiichiro","Empathic dialogue system based on emotions extracted from tweets","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3302281","https://doi.org/10.1145/3301275.3302281","Empathic conversations have increasingly been important for dialogue systems to improve the users' experience, and increase their engagement with the system, which is difficult for many existing monotonous systems. Existing empathic dialogue systems are designed for limited domain dialogues. They respond fixed phrases toward observed user emotions. In open domain conversations, however, generating empathic responses for a wide variety of topics is required. In this paper, we draw on psychological studies about empathy, and propose an empathic dialogue system in open domain conversations. The proposed system generates empathic utterances based on observed emotions in user utterances, thus is able to build empathy with users. Our experiments have proven that users were able to feel more empathy from the proposed system, especially when their emotions were explicitly expressed in their utterances.","2019-03-17","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","52–56","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; dialogue system; social networking service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6SL9SJT","conferencePaper","2020","Samrose, Samiha; Anbarasu, Kavya; Joshi, Ajjen; Mishra, Taniya","Mitigating Boredom Using An Empathetic Conversational Agent","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423905","https://doi.org/10.1145/3383652.3423905","In spite of their ubiquity, our interactions with contemporary conversational agents (CA), such as Alexa, are still transactional in nature and lack the expressiveness of human-human communication. Conversational agents equipped with the ability to detect and address users' emotional and cognitive states could make our interactions with them more human. In this work, we investigate whether an empathetic CA can help mitigate boredom. We design a protocol in order to first elicit boredom in users, and explore strategies that attempt to mitigate their boredom with the help of two conversational agents, an empathetic agent and a non-empathetic agent, administered in a Wizard-of-Oz setting. We quantify their efficacy by measuring the effects on user mood and task performance. Our user study with 34 participants shows that the empathetic CA outperforms the non-empathetic CA with respect to modulating users' mood and performance.","2020-10-20","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–8","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Conversational Agent; Empathetic Agent; Boredom Mitigation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQHZ6UFI","conferencePaper","2019","Dupuy, Lucile; De Sevin, Etienne; Ballot, Orlane; Cassoudesalle, Hélène; Dehail, Patrick; Aouizerate, Bruno; Cuny, Emmanuel; Micoulaud-Franchi, Jean-Arthur; Philip, Pierre","A Virtual Patient to Train Semiology Extraction and Empathic Communication Skills for Psychiatric Interview","Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents","978-1-4503-6672-4","","10.1145/3308532.3329429","https://doi.org/10.1145/3308532.3329429","Psychiatric diagnostic relies on physician's ability to create an empathic interaction with the patient (i.e., engage the patient in the conversation with empathic sentences, while keeping an emotional distance) in order to accurately extract semiology (i.e., clinical manifestations). Virtual patients (VPs) offer new ways to train these skills but need to be validated in terms of accuracy to measure the skills of interest, and be perceived positively by its users. We recruited 34 medicine students, who interacted with a VP suffering from depressive disorders. Results suggest good abilities for the students to use empathic sentences to communicate with the VP, but results varied regarding semiology extraction, students having a specialty in psychiatry performing better than their counterparts. Additionally, results suggest that students managed to keep an emotional distance during the interaction with the VP, but they let their emotions out when answering semiology questions. Positive feedbacks and limitations raised by students during debriefing interviews provide suggestions for improvements and ideas for future works.","2019-07-01","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","188–190","","","","","","","IVA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","user experience; emotion detection; empathic communication skills; medical training; psychiatric interview; semiology; virtual patient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMXEKEHG","conferencePaper","2019","Zhou, Michelle X.","Getting virtually personal: making responsible and empathetic ""her"" for everyone","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3308445","https://doi.org/10.1145/3301275.3308445","Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world. Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent. I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.","2019-03-17","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","i","","","","","","Getting virtually personal","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\I73SJB6H\Zhou - 2019 - Getting virtually personal making responsible and.pdf","","","computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38D2Y6XP","conferencePaper","2016","Feigenblat, Guy; Konopnicki, David; Shmueli-Scheuer, Michal; Herzig, Jonathan; Shkedi, Hen","I Understand Your Frustration","Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion","978-1-4503-3950-6","","10.1145/2818052.2874316","https://doi.org/10.1145/2818052.2874316","The use of emotional intelligence in a conversation has a significant positive effect on customer satisfaction and can help resolve difficult conflicts. Many enterprises use virtual agents that automatically interact with customers across a variety of interaction channels. However, these agents have no emotional intelligence and cannot express themselves in an empathic manner. This demo demonstrates the use of emotional intelligence in a technical conversation with a customer. The agent is augmented with emotion sensing capabilities, which allow him to detect expressed emotions, and reply in an appropriate manner by expressing empathy, for example.","2016-02-27","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","25–28","","","","","","","CSCW '16 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Emotions; Affective computing; Conversation; Dialog; Virtual agent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TYWMTNW","conferencePaper","2019","Davis, Claudia E.","Enhancing emotional intelligence in project management: strategies for better outcomes and community with limited financial overhead","ACM SIGGRAPH 2019 Talks","978-1-4503-6317-4","","10.1145/3306307.3328190","https://doi.org/10.1145/3306307.3328190","During the SIGGRAPH 2018 BOF ""Emphasizing Empathy in Pipeline Project Management,"" group consensus stated that highly effective project management can only be achieved when emphasis is placed on demonstrated empathy for any and all project contributors at the project management level and when challenges are framed as opportunities to enhance both the team and the project manager's own emotional intelligence. The reality faced in the industry, however, can present unique challenges, specifically relating to toxic cultural folkways, lack of leadership support, and lack of designated monetary resources. Based on subsequent discussions borne from the initial presentation with industry professionals and team leaders, it seems imperative to address not only the theories of Emotional Intelligence in greater depth, but also to acknowledge the potential obstacles in applying this basic theory in the real world. This talk aims to illuminate opportunities for individual production professionals to both challenge their own perceptions of the industry culture and make effective changes pertaining to their management and communication styles to affect positive change in their work environment, increase employee morale, and build community, barring financial allotment, to the overall benefit of their team members and their project health.","2019-07-28","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–2","","","","","","Enhancing emotional intelligence in project management","SIGGRAPH '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","advocacy; community building; development; emotional intelligence; empathy; pipeline; professional development; project management; work-life balance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CVY9DJX","bookSection","2020","Davis, Claudia E.","Making time for Emotional Intelligence in Production and Technology","ACM SIGGRAPH 2020 Talks","978-1-4503-7971-7","","","https://doi.org/10.1145/3388767.3407362","During the SIGGRAPH 2018 BOF ”Emphasizing Empathy in Pipeline Project Management,” group consensus stated that highly effective project management can only be achieved when emphasis is placed on demonstrated empathy for any and all project contributors at the project management level and when challenges are framed as opportunities to enhance both the team and the project manager’s own emotional intelligence. The reality faced in the industry, however, can present unique challenges, specifically relating to toxic cultural folkways, lack of leadership support, and lack of designated monetary resources. Based on subsequent discussions borne from the initial presentation with industry professionals and team leaders, it seems imperative to address not only the theories of Emotional Intelligence in greater depth, but also to acknowledge the potential obstacles in applying this basic theory in the real world specifically regarding the operational changes introduced to the working environment due to COVID-19 and current world events. A specific concern to address is that middle-tier management, for whom budget allocation is given and not guaranteed – want to improve their team environment, they are often not granted a financial allotment to do so most effectively for their specific teams. This talk aims to illuminate opportunities for individual production professionals to make effective changes pertaining to their management and communication styles to affect positive change in their work environment, increase employee morale, and build community, barring financial allotment, to the overall benefit of their team members and their project health.","2020-08-17","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–2","","","","","","","","10","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","advocacy; community building; development; emotional intelligence; empathy; pipeline; professional development; project management; work-life balance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6NJUNEV","conferencePaper","2020","Sankaran, Supraja; Zhang, Chao; Funk, Mathias; Aarts, Henk; Markopoulos, Panos","Do I have a say? Using conversational agents to re-imagine human-machine autonomy","Proceedings of the 2nd Conference on Conversational User Interfaces","978-1-4503-7544-3","","10.1145/3405755.3406135","https://doi.org/10.1145/3405755.3406135","With human-centered AI gaining traction, needs for algorithmic transparency, explainability, empathy and ethical considerations in artificial agents are forming core research issues. However, with intelligent agents getting increasingly independent and human-like, there is an increase in perceived threat to human autonomy. Will this perceived threat eventually become an actual threat where humans lose control over their own goals, decisions and actions? With this provocation paper, we want to urge researchers working on human-agent interactions and conversational agents (CAs) to explicitly consider the impact of intelligent agents on human autonomy. We present arguments and highlight the critical need to focus on human autonomy when interacting with CAs by presenting some core research considerations.","2020-07-22","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–3","","","","","","Do I have a say?","CUI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","conversational agents; human autonomy; human-agent interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KG77P9VK","conferencePaper","2019","Davis, Jr., Mark","How's your EQ? - Let's find out!","Proceedings of the 2019 ACM SIGUCCS Annual Conference","978-1-4503-5774-6","","10.1145/3347709.3347770","https://doi.org/10.1145/3347709.3347770","Do you understand the role your emotions play in how you see yourself and others? What role does Emotional Intelligence (EQ) play in successful leadership? How does EQ affect DEI (Diversity, Equity and Inclusion)? How much of an impact does emotional intelligence really have on your professional success and the relationships you build? The short answer: a lot! This interactive discussion will help us identify and assess our abilities in each of the EQ quadrants of self-awareness, self-regulation, empathy and social awareness. We will also discuss methods and strategies to help us embrace EQ at all levels and identify the influence it can have on creating a more Diverse, Equitable and Inclusive community.","2019-10-26","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","87–88","","","","","","How's your EQ?","SIGUCCS '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Empathy; Diversity Equity and inclusion; Emotional Intelligence; EQ Leadership; Self-Awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIGNTCMX","conferencePaper","2018","Hosseinpanah, Adineh; Krämer, Nicole C.; Straßmann, Carolin","Empathy for Everyone? The Effect of Age When Evaluating a Virtual Agent","Proceedings of the 6th International Conference on Human-Agent Interaction","978-1-4503-5953-5","","10.1145/3284432.3284442","https://doi.org/10.1145/3284432.3284442","The present study investigated the role of age in the perception of emotional nonverbal behaviors of a virtual assistant in a 2 (seniors vs young participants) x 2 (happy vs sad situations) x 4 (three emotional nonverbal behaviors related to each situation vs neutral behavior) mixed factorial design. In the study, a virtual agent acted as an assistant to review the imaginary monthly schedule of the participant. After uttering each schedule, the agent showed different emotional nonverbal behaviors to express empathy. The stimulus materials were presented to 60 participants (30 elderly people and 30 younger adults) in 25 videos. All participants had to rate the agent's friendliness, intelligence, empathy, trustworthiness, and helpfulness immediately after watching each video. The results indicated that in the presence of the emotional nonverbal behaviors the elderly rated the agent as more empathic and trustworthy compared to the younger adults. The data also revealed that there were differences with respect to rating specific emotional nonverbal behaviors as more empathic than others. Elderly people perceived Dropping the Arms plus Sad Face, Head down, Sad Face, Head Nod plus Smile, and Smile as more empathic, and the nonverbal behaviors perceived as most empathic for the younger adults were Dropping the Arms plus Sad Face, and Head down.","2018-12-04","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","184–190","","","","","","Empathy for Everyone?","HAI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; human-agent interaction; nonverbal-behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YX64TSYG","conferencePaper","2014","Gonzalez-Sanchez, Javier; Chavez-Echeagaray, Maria E.; Atkinson, Robert K.; Burleson, Winslow","Multimodal detection of affective states: a roadmap through diverse technologies","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2567820","https://doi.org/10.1145/2559206.2567820","One important way for systems to adapt to their individual users is related to their ability to show empathy. Being empathetic implies that the computer is able to recognize a user's affective states and understand the implication of those states. Detection of affective states is a step forward to provide machines with the necessary intelligence to appropriately interact with humans. This course provides a description and demonstration of tools and methodologies for automatically detecting affective states with a multimodal approach.","2014-04-26","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1023–1024","","","","","","Multimodal detection of affective states","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affect-driven adaptation; affective states; emotion recognition; multimodal; sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVHGIDH8","conferencePaper","2020","Spitale, Micol; Garzotto, Franca","Towards Empathic Conversational Interaction","Proceedings of the 2nd Conference on Conversational User Interfaces","978-1-4503-7544-3","","10.1145/3405755.3406146","https://doi.org/10.1145/3405755.3406146","In recent years, ""computational empathy"" has emerged as a new challenging research field. Computational empathy investigates how artificial agents can manifest empathic behaviours towards the user, and how they can elicit empathy during the human-agent interaction. Such ""empathic agents"" have the capacity to place themselves into the emotional position of a user (or another agent), and behave taking such emotional understanding into account. The paper explores a computational empathy approach in the context of conversational interaction, and presents an empathic conversational framework grounded on the empathy theory. The framework provides a conceptual tool for designing and evaluating empathic conversational agents. Overall, our research contributes to a deeper understanding of the role of empathy in conversational interaction.","2020-07-22","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–4","","","","","","","CUI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Empathy; Artificial Agents; Computational Empathy; Conversational Interaction; Framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZTDQ55F","conferencePaper","2018","Diallo, Saikou Y.; Lynch, Christopher J.; Rechowicz, Krzysztof J.; Zacharewicz, Gregory","How to create empathy and understanding: narrative analytics in agent-based modeling","Proceedings of the 2018 Winter Simulation Conference","","","","","In this paper we propose a different approach for interacting and analyzing agent-based models. The approach relies on creating empathy and understanding between physical agents in the physical world (people) and artificial agents in the simulated world (simulated agents). We propose a simulated empathy framework (SEF) in which artificial agents communicate directly with physical agents through verbal channels and social media. We argue that artificial agents should focus on the communication aspects between these two worlds, the ability to tell their story in a compelling way, and to read between the lines of physical agents speech. We present an implementation of the SEF and discuss challenges associated with implementing the framework in an artificial society.","2018-12-09","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1286–1297","","","","","","How to create empathy and understanding","WSC '18","","","","IEEE Press","Gothenburg, Sweden","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6DWJ7UCP","conferencePaper","2010","van den Broek, Egon L.; Nijholt, Anton; Westerink, Joyce H. D. M.","Unveiling affective signals","Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research","978-1-60558-926-8","","10.1145/1931344.1931350","https://doi.org/10.1145/1931344.1931350","The ability to process and, subsequently, understand affective signals is the core of emotional intelligence and empathy. However, more than a decade of research in affective computing has shown that it is hard to develop computational models of this process. We pose that the solution for this problem lays in a better understanding of how to process these affective signals. This article introduces a symposium that brought together various approaches towards unveiling affective signals. As such, it is envisioned to be a springboard for affective computing.","2010-08-24","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–4","","","","","","","MB '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotion; methods; affective computing; affect; pattern recognition; signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JAUXUDRW","conferencePaper","2020","Narayanan, Shrikanth Shri","Human-centered Multimodal Machine Intelligence","Proceedings of the 2020 International Conference on Multimodal Interaction","978-1-4503-7581-8","","10.1145/3382507.3417974","https://doi.org/10.1145/3382507.3417974","Multimodal machine intelligence offers enormous possibilities for helping understand the human condition and in creating technologies to support and enhance human experiences [1, 2]. What makes such approaches and systems exciting is the promise they hold for adaptation and personalization in the presence of the rich and vast inherent heterogeneity, variety and diversity within and across people. Multimodal engineering approaches can help analyze human trait (e.g., age), state (e.g., emotion), and behavior dynamics (e.g., interaction synchrony) objectively, and at scale. Machine intelligence could also help detect and analyze deviation in patterns from what is deemed typical. These techniques in turn can assist, facilitate or enhance decision making by humans, and by autonomous systems. Realizing such a promise requires addressing two major lines of, oft intertwined, challenges: creating inclusive technologies that work for everyone while enabling tools that can illuminate the source of variability or difference of interest. This talk will highlight some of these possibilities and opportunities through examples drawn from two specific domains. The first relates to advancing health informatics in behavioral and mental health [3, 4]. With over 10% of the world's population affected, and with clinical research and practice heavily dependent on (relatively scarce) human expertise in diagnosing, managing and treating the condition, engineering opportunities in offering access and tools to support care at scale are immense. For example, in determining whether a child is on the Autism spectrum, a clinician would engage and observe a child in a series of interactive activities, targeting relevant cognitive, communicative and socio- emotional aspects, and codify specific patterns of interest e.g., typicality of vocal intonation, facial expressions, joint attention behavior. Machine intelligence driven processing of speech, language, visual and physiological data, and combining them with other forms of clinical data, enable novel and objective ways of supporting and scaling up these diagnostics. Likewise, multimodal systems can automate the analysis of a psychotherapy session, including computing treatment quality-assurance measures e.g., rating a therapist's expressed empathy. These technology possibilities can go beyond the traditional realm of clinics, directly to patients in their natural settings. For example, remote multimodal sensing of biobehavioral cues can enable new ways for screening and tracking behaviors (e.g., stress in workplace) and progress to treatment (e.g., for depression), and offer just in time support. The second example is drawn from the world of media. Media are created by humans and for humans to tell stories. They cover an amazing range of domains'from the arts and entertainment to news, education and commerce and in staggering volume. Machine intelligence tools can help analyze media and measure their impact on individuals and society. This includes offering objective insights into diversity and inclusion in media representations through robustly characterizing media portrayals from an intersectional perspective along relevant dimensions of inclusion: gender, race, gender, age, ability and other attributes, and in creating tools to support change [5,6]. Again this underscores the twin technology requirements: to perform equally well in characterizing individuals regardless of the dimensions of the variability, and use those inclusive technologies to shine light on and create tools to support diversity and inclusion.","2020-10-21","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","4–5","","","","","","","ICMI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotion; behavior; computational psychology; diversity and inclusion; human signals; language; media intelligence; mental health; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49WYJII3","conferencePaper","2019","Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad","Multimodal Learning for Identifying Opportunities for Empathetic Responses","2019 International Conference on Multimodal Interaction","978-1-4503-6860-5","","10.1145/3340555.3353750","https://doi.org/10.1145/3340555.3353750","Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.","2019-10-14","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","95–104","","","","","","","ICMI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","machine learning; empathy; human behavior; multimodal sentiment; virtual human","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V56D27QB","conferencePaper","2020","Svanæs, Dag; Barkhuus, Louise","The Designer's Body as Resource in Design: Exploring Combinations of Point-of-view and Tense","Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6708-0","","10.1145/3313831.3376430","https://doi.org/10.1145/3313831.3376430","The design of wearable, tangible and embedded interactive products requires a focus on bodily/kinesthetic aspects of the user experience, that is, how the product ""feels"" in use. Although best practice in user-centered design (such as iterative design, prototyping, user testing) also applies for this new type of product, the designer's skill set needs to be supplemented with design methods and practices that utilize bodily intelligence and empathy with the user. We present a framework for categorizing such body-centered design practices based on two dimensions: point-of-view (1st, 2nd, 3rd person) and tense (past, present, future). Inspired by Merleau-Ponty's phenomenology of the body, Shusterman's work on somaesthetics, and Buber's theories on intersubjectivity, the framework provides a language for talking about different ways designers and co-designers can utilize their body as a design resource. The intention is not to be prescriptive on method, but to provide guidance during planning, execution and analysis.","2020-04-21","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–13","","","","","","The Designer's Body as Resource in Design","CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","body-centered design; design process; designer training; phenomenology; somaesthetics; user experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7R7NDIEJ","conferencePaper","2018","Fitzpatrick, Geraldine","Designing For Intelligence: Intelligence For Designing","Proceedings of the 4th International Conference on Human-Computer Interaction and User Experience in Indonesia, CHIuXiD '18","978-1-4503-6429-4","","10.1145/3205946.3205961","https://doi.org/10.1145/3205946.3205961","Intelligent technology is increasingly entangled in every aspect of our lives. As the designers/builders of these technologies, we wield considerable power, as is rightly being publicly scrutinized in recent debates around biased algorithms and (mis)use of social media data. Designing for intelligence is not just designing technology per se but designing ways of being human and negotiating complex choices. To do this well, engineering and design skills are not enough. We need better social, emotional, and existential intelligences to be critically reflective and empathic practitioners, able to negotiate contended values, engage with diverse user groups and stakeholders, and bring a values-based ethical lens to the choices we make.","2018-03-23","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","97–100","","","","","","Designing For Intelligence","CHIuXiD '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Existential intelligence; Social emotional intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXMU8Q3M","journalArticle","2018","Powell, Loreen; Hendon, Michalina","The need for an emotional intelligence for information technology course: framework for educators and academic institutions","Journal of Computing Sciences in Colleges","","1937-4771","","","Information Technology (IT) professionals are tasked with problem solving and educating the user on the solution at hand as well as assisting the organization with the correct use of technology to optimize business practices. The manner in which an IT professional communicates their knowledge and instructions for problem solving can be stifled through insufficient interpersonal skills. Currently, IT professionals use main sources of communication, such as email or a management system software tool, in which sufficient time can be taken to craft messages. However, when adequate time is not available to think about a response or read between the lines of a client's problem, the IT professional may find it challenging to communicate with empathy of the client's perspective, which can detract from the collaboration or problem-solving goal of the conversation. As such, organizations report that there is a vital need for IT students to understand and rely upon positive emotion intelligence (EI) to intergrade the interpersonal skills that allow the professional to be both a problem-solver and effective communicator. However, there is limited or nonexistent literature on the EI for IT courses, skills, and assessments. This research investigated current and past the employment needs by examining online IT job advertisements within the United States. Results revealed several key EI skills sought by IT employers. Based upon these results, a solid framework in support of an EI for IT course is offered. This research provides a solid framework for educators and higher education institutions to consider an emotional technology course within the IT curriculum.","2018-01-01","2021-02-15 21:25:58","2021-02-15 21:25:58","","72","","3","33","","J. Comput. Sci. Coll.","The need for an emotional intelligence for information technology course","","","","","","","","","","","","January 2018","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QDA3SZRS","journalArticle","2018","Cotler, Jami L.; Cusack, Matthew","Leveraging emotional intelligence (soft skills) to maximize career success for computer science students","Journal of Computing Sciences in Colleges","","1937-4771","","","With an industry focus on agile development practices, a premium has been put on communication and teamwork skills [21]. Software developers in the tech space will often need to interact with other developers, UX professionals, software testers, and perhaps even culturally diverse customers and clients. The capacity of professionals in this space need to meet customer expectations in a very competitive market centers around the ability of individuals to not only work collectively and as seamlessly as possible, but to also create synergies with a diverse group of professional colleagues. Individuals that have experience working in teams to accomplish goals tend to be more productive in meeting deliverables on agile software development projects [22]. Moreover, companies such as Google, Zappos, and Amazon, are using assessments of soft skills (or emotional intelligence) during the job search process to vet candidates [14]. Furthermore, Dr. Joseph Homan, former Chief Operating Officer at ZekiahTech in Maryland, tests for soft skills extensively when interviewing a new technical candidate and stated that he has noted that candidates with fewer soft skills are often perceived as having lower technical skills (personal communication, November 14, 2014). Another area where EI skills such as awareness of others and empathy is essential is in user experience. Being able to understand the user that technology is being designed for is vital to the ultimate success of the product. Based on these findings, a solid argument is made for the importance of teaching EI to Computer Science students at the undergraduate level.","2018-06-01","2021-02-15 21:25:58","2021-02-15 21:25:58","","148–153","","6","33","","J. Comput. Sci. Coll.","","","","","","","","","","","","","June 2018","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L97BL5EQ","conferencePaper","2010","Regazzoni, Carlo S.","Emphatic human interaction analysis for cognitive environments","Proceedings of the first ACM international workshop on Analysis and retrieval of tracked events and motion in imagery streams","978-1-4503-0163-3","","10.1145/1877868.1877870","https://doi.org/10.1145/1877868.1877870","Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment. Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available. Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation. Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world. Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it). Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.","2010-10-29","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","1–2","","","","","","","ARTEMIS '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","ambient intelligence; cognitive surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSWA8FQ9","conferencePaper","2010","Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Castellano, Ginevra; Martinho, Carlos; Prada, Rui; Paiva, Ana","Closing the loop: from affect recognition to empathic interaction","Proceedings of the 3rd international workshop on Affective interaction in natural environments","978-1-4503-0170-1","","10.1145/1877826.1877839","https://doi.org/10.1145/1877826.1877839","Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.","2010-10-29","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","43–48","","","","","","Closing the loop","AFFINE '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; affect recognition; artificial companions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IQPLR8J","journalArticle","2012","Dinakar, Karthik; Jones, Birago; Havasi, Catherine; Lieberman, Henry; Picard, Rosalind","Common Sense Reasoning for Detection, Prevention, and Mitigation of Cyberbullying","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/2362394.2362400","https://doi.org/10.1145/2362394.2362400","Cyberbullying (harassment on social networks) is widely recognized as a serious social problem, especially for adolescents. It is as much a threat to the viability of online social networks for youth today as spam once was to email in the early days of the Internet. Current work to tackle this problem has involved social and psychological studies on its prevalence as well as its negative effects on adolescents. While true solutions rest on teaching youth to have healthy personal relationships, few have considered innovative design of social network software as a tool for mitigating this problem. Mitigating cyberbullying involves two key components: robust techniques for effective detection and reflective user interfaces that encourage users to reflect upon their behavior and their choices. Spam filters have been successful by applying statistical approaches like Bayesian networks and hidden Markov models. They can, like Google’s GMail, aggregate human spam judgments because spam is sent nearly identically to many people. Bullying is more personalized, varied, and contextual. In this work, we present an approach for bullying detection based on state-of-the-art natural language processing and a common sense knowledge base, which permits recognition over a broad spectrum of topics in everyday life. We analyze a more narrow range of particular subject matter associated with bullying (e.g. appearance, intelligence, racial and ethnic slurs, social acceptance, and rejection), and construct BullySpace, a common sense knowledge base that encodes particular knowledge about bullying situations. We then perform joint reasoning with common sense knowledge about a wide range of everyday life topics. We analyze messages using our novel AnalogySpace common sense reasoning technique. We also take into account social network analysis and other factors. We evaluate the model on real-world instances that have been reported by users on Formspring, a social networking website that is popular with teenagers. On the intervention side, we explore a set of reflective user-interaction paradigms with the goal of promoting empathy among social network participants. We propose an “air traffic control”-like dashboard, which alerts moderators to large-scale outbreaks that appear to be escalating or spreading and helps them prioritize the current deluge of user complaints. For potential victims, we provide educational material that informs them about how to cope with the situation, and connects them with emotional support from others. A user evaluation shows that in-context, targeted, and dynamic help during cyberbullying situations fosters end-user reflection that promotes better coping strategies.","2012-09-01","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15 21:25:55","18:1–18:30","","3","2","","ACM Trans. Interact. Intell. Syst.","","","","","","","","","","","","","September 2012","","","","C:\Users\esben\Zotero\storage\X3V25YDG\Dinakar et al. - 2012 - Common Sense Reasoning for Detection, Prevention, .pdf","","","artificial intelligence; affective computing; Common sense reasoning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCAHZRLJ","journalArticle","2020","Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung","The Design and Implementation of XiaoIce, an Empathetic Social                     Chatbot","Computational Linguistics","","0891-2017","10.1162/coli_a_00368","https://doi.org/10.1162/coli_a_00368","This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.","2020-03-01","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15 21:25:56","53–93","","1","46","","Comput. Linguist.","","","","","","","","","","","","","March 2020","","","","C:\Users\esben\Zotero\storage\PFU6QFLG\Zhou et al. - 2020 - The Design and Implementation of XiaoIce, an Empat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HX9WSXE","conferencePaper","2014","Regenbrecht, H.; Müller, L.; Hoermann, S.; Langlotz, T.; Wagner, M.; Billinghurst, M.","Eye-to-eye contact for life-sized videoconferencing","Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: the Future of Design","978-1-4503-0653-9","","10.1145/2686612.2686632","https://doi.org/10.1145/2686612.2686632","Videoconferencing systems available for end users do not allow for eye-to-eye contact between participants. The different locations of video camera and video display make it impossible to directly look into each others eyes. This issue is known as the lack of mutual gaze. Combined with a lack of a life-sized video image of the communication partner videoconferencing becomes an artificial experience leading to decreased communication quality, empathy and trust. In this work, we present life-sized videoconferencing solution supporting mutual gaze and report on the experiences made with our system in empirical evaluations.","2014-12-02","2021-02-15 21:25:58","2021-02-15 21:25:58","2021-02-15","145–148","","","","","","","OzCHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","eye contact; mutual gaze; trust; videoconferencing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXZLQU8P","conferencePaper","2017","Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin","Beyond cute: exploring user types and design opportunities of virtual reality pet games","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3139132","https://doi.org/10.1145/3139131.3139132","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.","2017-11-08","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1–10","","","","","","Beyond cute","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\BRY6FR4G\Lin et al. - 2017 - Beyond cute exploring user types and design oppor.pdf","","","pet game; user types; virtual pet; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZL7ELKK","conferencePaper","2019","Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios","Smart, personalized and adaptive ICT solutions for active, healthy and productive ageing with enhanced workability","Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","978-1-4503-6232-0","","10.1145/3316782.3322767","https://doi.org/10.1145/3316782.3322767","Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""[email protected]"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.","2019-06-05","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","442–447","","","","","","","PETRA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\QEIESJJR\Giakoumis et al. - 2019 - Smart, personalized and adaptive ICT solutions for.pdf","","","age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQK2W4UG","journalArticle","2012","Beck, Aryel; Stevens, Brett; Bard, Kim A.; Cañamero, Lola","Emotional body language displayed by artificial agents","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/2133366.2133368","https://doi.org/10.1145/2133366.2133368","Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots.","2012-03-20","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15 21:26:21","2:1–2:29","","1","2","","ACM Trans. Interact. Intell. Syst.","","","","","","","","","","","","","March 2012","","","","C:\Users\esben\Zotero\storage\SL26BPL9\Beck et al. - 2012 - Emotional body language displayed by artificial ag.pdf","","","emotional body language; Human computer interactions; human robot interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BM6J97LK","bookSection","2020","Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph","Reputation Agent: Prompting Fair Reviews in Gig Markets","Proceedings of The Web Conference 2020","978-1-4503-7023-3","","","https://doi.org/10.1145/3366423.3380199","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.","2020-04-20","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1228–1240","","","","","","Reputation Agent","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVHJZR7V","conferencePaper","2016","Oertel, Catharine; Lopes, José; Yu, Yu; Mora, Kenneth A. Funes; Gustafson, Joakim; Black, Alan W.; Odobez, Jean-Marc","Towards building an attentive artificial listener: on the perception of attentiveness in audio-visual feedback tokens","Proceedings of the 18th ACM International Conference on Multimodal Interaction","978-1-4503-4556-9","","10.1145/2993148.2993188","https://doi.org/10.1145/2993148.2993188","Current dialogue systems typically lack a variation of audio-visual feedback tokens. Either they do not encompass feedback tokens at all, or only support a limited set of stereotypical functions. However, this does not mirror the subtleties of spontaneous conversations. If we want to be able to build an artificial listener, as a first step towards building an empathetic artificial agent, we also need to be able to synthesize more subtle audio-visual feedback tokens. In this study, we devised an array of monomodal and multimodal binary comparison perception tests and experiments to understand how different realisations of verbal and visual feedback tokens influence third-party perception of the degree of attentiveness. This allowed us to investigate i) which features (amplitude, frequency, duration...) of the visual feedback influences attentiveness perception; ii) whether visual or verbal backchannels are perceived to be more attentive iii) whether the fusion of unimodal tokens with low perceived attentiveness increases the degree of perceived attentiveness compared to unimodal tokens with high perceived attentiveness taken alone; iv) the automatic ranking of audio-visual feedback token in terms of conveyed degree of attentiveness.","2016-10-31","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","21–28","","","","","","Towards building an attentive artificial listener","ICMI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","backchannels; head nods; virtual agent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XT7Q3N5","conferencePaper","2016","O'Leary, Ciarán; Mtenzi, Fred; McAvinia, Claire","Towards Reusable Personas for Everyday Design","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2892411","https://doi.org/10.1145/2851581.2892411","Personas are artificial character based representations of user goals, attitudes, motivations and abilities which enable designers to focus their design efforts on key, targeted users. The success of personas in design is due to their capacity to enable designers to empathize with users and understand user goals. Persona development is rooted in the rigorous collection and analysis of data specifically related to the design project being undertaken. New design projects thus require the development of new personas. Since redevelopment is not always achievable attention has turned towards reuse of personas and the underlying data. This paper reports on ongoing research into the development of reusable personas for use by non-expert, everyday designers. Such designers are regularly faced with small scale but diverse design challenges for which they cannot carry out user research and modelling. They can, however, make use of general, reusable personas developed independently of their current design project.","2016-05-07","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","2915–2922","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","everyday design; personas; practices; reuse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EQ9IMUK","conferencePaper","2017","Valverde, Isabel; Cochrane, Todd","Senses Places: soma-tech mixed-reality participatory performance installation/environment","Proceedings of the 8th International Conference on Digital Arts","978-1-4503-5273-4","","10.1145/3106548.3106613","https://doi.org/10.1145/3106548.3106613","We present the latest developments of the art-tech research project Senses Places, a somatic-technological (soma-tech) mixed-reality participatory performance installation/environment, engaging expanded modes of embodied physical-virtual interaction. This ongoing somatic-technological dance/performance collaborative trans-disciplinary approach gathers artists and developer researchers, working remotely and physically in analogical-digital intermedia interfaces and their expanded experience design and choreography. The sensorial expansion and integration sought through human-computer interaction links participants, avatars, images and physical-virtual environments. They constitute different organic-artificial sensorial-expressive channels of visual, audio, tactile, and somatic/kinesthetic shared tuning/engagement/experience. At the core of this long-term intervention lies the common urging desire for more encompassing and empathic embodied interactivity among physical and remote subjects and places. With a cross-cultural somatic and dance practices, Senses Places critically experiments with different informational, communicational and biomedical technologies available, wishing to contribute to understand the world's and humans becoming through what we have been conceiving as posthuman corporealities [1] within a posthuman condition and emerging somatic epistemology [2].","2017-09-06","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","195–197","","","","","","Senses Places","ARTECH2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Dance-technology; Interaction design; Interactive art; Posthuman corporealities; Somatic epistemology; Somatics; Virtual and mixed-reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8N6SI9F","conferencePaper","2020","Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef","Facial expression based satisfaction index for empathic buildings","Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers","978-1-4503-8076-8","","10.1145/3410530.3414443","https://doi.org/10.1145/3410530.3414443","In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.","2020-09-10","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","704–707","","","","","","","UbiComp-ISWC '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","machine learning; empathic building; facial expressions; satisfaction index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSXEE8HF","conferencePaper","2017","Portela, Manuel; Granell-Canut, Carlos","A new friend in our smartphone? observing interactions with chatbots in the search of emotional engagement","Proceedings of the XVIII International Conference on Human Computer Interaction","978-1-4503-5229-1","","10.1145/3123818.3123826","https://doi.org/10.1145/3123818.3123826","We present the findings of a quantitative and qualitative empirical research to understand the possibilities of engagement and affection in the use of conversational agents (chatbots). Based on an experiment with 13 participants, we explored on one hand the correlation between the user expectation, user experience and intended use and, on the other, whether users feel keen and engaged in having a personal, empathic relation with an intelligent system like chatbots. We used psychological questionnaires to semi-structured interviews for disentangle the meaning of the interaction. In particular, the personal psychological background of participants was found critical while the experience itself allowed them to imagine new possible relations with chatbots. Our results show some insights on how people understand and empathize with future interactions with conversational agents and other non-visual interfaces.","2017-09-25","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1–7","","","","","","A new friend in our smartphone?","Interacci&#xf3;n '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","conversational agents; emotional engagement; empathic relations; mixed-method analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSKIQPDU","bookSection","2020","Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri","Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419900","Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.","2020-11-02","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","262–266","","","","","","Playing with the Opposite of Uncanny","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","emotional intelligence; human-computer interaction; child-robot interaction; human-animal interaction; playful learning; robot toys; social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUTKBH6E","conferencePaper","2014","Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid","Werewolves, cheats, and cultural sensitivity","Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems","978-1-4503-2738-1","","","","MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.","2014-05-05","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1085–1092","","","","","","","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","ACM Digital Library","","","","","","","empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRU458VQ","conferencePaper","2017","Cesar, Pablo","Sensing Engagement: Helping Performers to Evaluate their Impact","Proceedings of the 2017 ACM Workshop on Multimedia-based Educational and Knowledge Technologies for Personalized and Social Online Training","978-1-4503-5508-7","","10.1145/3132390.3132391","https://doi.org/10.1145/3132390.3132391","The keynote will provide an overview about different mechanisms to gather data by using wearable sensor technology for understanding the experience of people attending cultural events, public lectures, and courses. Through practical case studies in different areas of the creative industries and education, we will showcase our results and discuss about our failures. Based on realistic testing grounds, collaborating with several commercial and academic partners, we have deployed our technology and infrastructure in places such as the National Theatre of China in Shanghai. Our approach is to seamless connecting fashion and textiles with sensing technology, and with the environment. The final objective is to create intelligent and empathic systems that can react to the audience and their experience.","2017-10-27","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1","","","","","","Sensing Engagement","MultiEdTech '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\C7K7TEMJ\Cesar - 2017 - Sensing Engagement Helping Performers to Evaluate.pdf","","","education; sensors; cultural experiences; data visualization; gsr; physical installation; shared experiences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URZVMLEC","conferencePaper","2019","Torres, M. I.; Olaso, J. M.; Montenegro, C.; Santana, R.; Vázquez, A.; Justo, R.; Lozano, J. A.; Schlögl, S.; Chollet, G.; Dugan, N.; Irvine, M.; Glackin, N.; Pickard, C.; Esposito, A.; Cordasco, G.; Troncone, A.; Petrovska-Delacretaz, D.; Mtibaa, A.; Hmani, M. A.; Korsnes, M. S.; Martinussen, L. J.; Escalera, S.; Cantariño, C. Palmero; Deroo, O.; Gordeeva, O.; Tenorio-Laranga, J.; Gonzalez-Fraile, E.; Fernandez-Ruanova, B.; Gonzalez-Pinto, A.","The EMPATHIC project: mid-term achievements","Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","978-1-4503-6232-0","","10.1145/3316782.3322764","https://doi.org/10.1145/3316782.3322764","The goal of active aging is to promote changes in the elderly community so as to maintain an active, independent and socially-engaged lifestyle. Technological advancements currently provide the necessary tools to foster and monitor such processes. This paper reports on mid-term achievements of the European H2020 EMPATHIC project, which aims to research, innovate, explore and validate new interaction paradigms and platforms for future generations of personalized virtual coaches to assist the elderly and their carers to reach the active aging goal, in the vicinity of their home. The project focuses on evidence-based, user-validated research and integration of intelligent technology, and context sensing methods through automatic voice, eye and facial analysis, integrated with visual and spoken dialogue system capabilities. In this paper, we describe the current status of the system, with a special emphasis on its components and their integration, the creation of a Wizard of Oz platform, and findings gained from user interaction studies conducted throughout the first 18 months of the project.","2019-06-05","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","629–638","","","","","","The EMPATHIC project","PETRA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\EXE3JMDI\Torres et al. - 2019 - The EMPATHIC project mid-term achievements.pdf","","","assisted living; coaching; emotional artificial agents; spoken dialogue systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JDXJ36AF","conferencePaper","2017","Richards, Deborah","Intimately intelligent virtual agents: knowing the human beyond sensory input","Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents","978-1-4503-5558-2","","10.1145/3139491.3139505","https://doi.org/10.1145/3139491.3139505","Despite being in the era of Big Data, where our devices seem to anticipate and feed our every desire, intelligent virtual agents appear to lack intimate and important knowledge of their user. Current cognitive agent architectures usually include situation awareness that allows agents to sense their environment, including their human partner, and provide congruent empathic behaviours. Depending on the framework, agents may exhibit their own personality, culture, memories, goals and reasoning styles. However, tailored adaptive behaviours based on multi-dimensional and deep understanding of the human essential for enduring beneficial relationships in certain contexts are lacking. In this paper, examples are provided of what an agent may need to know about the human in the application domains of education, health and cybersecurity and the challenges around agent adaptation and acquisition of relevant data and knowledge.","2017-11-13","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","39–40","","","","","","Intimately intelligent virtual agents","ISIAA 2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Intelligent Virtual Agents; User Modelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5MN2YAM","conferencePaper","2016","Alyuz, Nese","Shaping the future of education with empathic companions","Proceedings of the 2nd workshop on Emotion Representations and Modelling for Companion Systems","978-1-4503-4558-3","","10.1145/3009960.3009964","https://doi.org/10.1145/3009960.3009964","With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.","2016-11-16","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","1–2","","","","","","","ERM4CT '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9SRHBKR","conferencePaper","2015","Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia","Designing a socially assistive robot for pediatric care","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771923","https://doi.org/10.1145/2771839.2771923","We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.","2015-06-21","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","387–390","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3ECBJKL","conferencePaper","2016","Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan","Semi-supervised model personalization for improved detection of learner's emotional engagement","Proceedings of the 18th ACM International Conference on Multimodal Interaction","978-1-4503-4556-9","","10.1145/2993148.2993166","https://doi.org/10.1145/2993148.2993166","Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.","2016-10-31","2021-02-15 21:26:45","2021-02-15 21:26:45","2021-02-15","100–107","","","","","","","ICMI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27MD3NZR","conferencePaper","2020","Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423864","https://doi.org/10.1145/3383652.3423864","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).","2020-10-20","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–3","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","empathy; conversational agent; emotion detection; healthcare computing; pattern matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3UG9BHN","journalArticle","2020","Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung","The Design and Implementation of XiaoIce, an Empathetic Social                     Chatbot","Computational Linguistics","","0891-2017","10.1162/coli_a_00368","https://doi.org/10.1162/coli_a_00368","This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.","2020-03-01","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15 21:29:04","53–93","","1","46","","Comput. Linguist.","","","","","","","","","","","","","March 2020","","","","C:\Users\esben\Zotero\storage\NJMQ7QM9\Zhou et al. - 2020 - The Design and Implementation of XiaoIce, an Empat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTF9C3L8","conferencePaper","2020","Harilal, Nidhin; Shah, Rushil; Sharma, Saumitra; Bhutani, Vedanta","CARO: An Empathetic Health Conversational Chatbot for People with Major Depression","Proceedings of the 7th ACM IKDD CoDS and 25th COMAD","978-1-4503-7738-6","","10.1145/3371158.3371220","https://doi.org/10.1145/3371158.3371220","There has been a rise in the number of patients suffering from major depression over the past decade. Most of the patients are reluctant and do not open up for councelling services. Conversational applications such as chatbots have been found efficient in overcoming alcohol addiction. Effective treatments can tackle depression, but only 10% of affected patients are able to avail such treatments mainly due to lack of resources and social stigma associated with mental disorders. We propose CARO, a chatbot app, which is capable of performing empathetic conversations and providing medical advice for people with major depression. CARO will be able to sense the conversational context, its intent and the associated emotions.","2020-01-05","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","349–350","","","","","","CARO","CoDS COMAD 2020","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Chatbot; Depression; Empathetic Response; Medical Advice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJWVSTXW","bookSection","2020","Chen, Zhifa; Lu, Yichen; Nieminen, Mika P.; Lucero, Andrés","Creating a Chatbot for and with Migrants: Chatbot Personality Drives Co-Design Activities","Proceedings of the 2020 ACM Designing Interactive Systems Conference","978-1-4503-6974-9","","","https://doi.org/10.1145/3357236.3395495","Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria.","2020-07-03","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","219–230","","","","","","Creating a Chatbot for and with Migrants","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\3TMXBM4P\Chen et al. - 2020 - Creating a Chatbot for and with Migrants Chatbot .pdf","","","chatbot; personality; avatar; co-design; conversation design; generative toolkit; migrants; probes; social integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHY832P2","conferencePaper","2020","Ravi, Akhilesh; Yadav, Amit Kumar Singh; Chauhan, Jainish; Dholakia, Jatin; Jain, Naman","SentEmoji: A Dataset to Generate Empathising Conversations","Proceedings of the 7th ACM IKDD CoDS and 25th COMAD","978-1-4503-7738-6","","10.1145/3371158.3371218","https://doi.org/10.1145/3371158.3371218","Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach.","2020-01-05","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","345–346","","","","","","SentEmoji","CoDS COMAD 2020","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NU77X2W5","conferencePaper","2019","Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid","BigBlueBot: teaching strategies for successful human-agent interactions","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3302290","https://doi.org/10.1145/3301275.3302290","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.","2019-03-17","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","448–459","","","","","","BigBlueBot","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","conversational agents; explainable AI; mechanical turk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YYAZ5RD","bookSection","2018","Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama","Touch Your Heart: A Tone-aware Chatbot for Customer Care on Social Media","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","","https://doi.org/10.1145/3173574.3173989","Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.","2018-04-21","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–12","","","","","","Touch Your Heart","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","social media; deep learning; chatbot; customer care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3CBCPGK","conferencePaper","2020","De Nieva, Johan Oswin; Joaquin, Jose Andres; Tan, Chaste Bernard; Marc Te, Ruzel Khyvin; Ong, Ethel","Investigating Students&#x2019; Use of a Mental Health Chatbot to Alleviate Academic Stress","6th International ACM In-Cooperation HCI and UX Conference","978-1-4503-8829-0","","10.1145/3431656.3431657","https://doi.org/10.1145/3431656.3431657","The amount of academic workload in schools can cause students to experience stress and become more susceptible to mental health problems. However, because of fear of societal stigma, students may find it more difficult to approach others about the stress they experience. A chatbot can provide an alternative avenue for students to freely share the stressful situations they are experiencing. In this study, we investigated the use of Woebot as a mechanism to help senior high school students alleviate stress from academic workload. 25 participants who engaged in daily conversations with Woebot for a two-week period rated the chatbot’s likeness to a human with a mean score of 5.56 out of 8, while its ability to understand the feelings of the participants and empathize with them had a mean score of 5.61. An analysis of the chat logs showed that the participants valued Woebot’s lessons and stories while they faced challenges in cases when the chatbot generated inappropriate responses. We discuss our findings and provide design suggestions that could make conversational agents like Woebot be more useful in helping the general student population cope with stress.","2020-10-21","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–10","","","","","","","CHIuXiD '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","Academic stress; Alleviating stress; Mental health chatbot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RQ2VA39T","conferencePaper","2020","Ahn, Yuna; Zhang, Yilin; Park, Yujin; Lee, Joonhwan","A Chatbot Solution to Chat App Problems: Envisioning a Chatbot Counseling System for Teenage Victims of Online Sexual Exploitation","Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6819-3","","10.1145/3334480.3383070","https://doi.org/10.1145/3334480.3383070","In recent years, online sexual exploitation targeting teenagers has been on the rise. Given teenagers' growing reluctance toward face-to-face communication, using a counseling chatbot could be a more effective way to provide teenage victims with necessary information and emotional support. There is a small number of counseling chatbots for victims of sexual crime, but none targeting teenagers specifically. This research suggests design guidelines for building a counseling chatbot for teenage victims of online sexual exploitation with a focus on establishing rapport by empathizing with their stories and providing them with the proper information. We conducted in-depth interviews with peer counselors at the Teenage Women's Human Rights Center, who have been consulting teenage victims in their age group using online messengers. The four key findings from our research suggested using open-ended questions, using teenager-friendly language, helping teenagers understand that they are victims and offering age-relevant information.","2020-04-25","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–7","","","","","","A Chatbot Solution to Chat App Problems","CHI EA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","rapport; counseling chatbot; online sexual exploitation; teenager","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZPXIYBT","conferencePaper","2020","Xiao, Ziang; Zhou, Michelle X.; Chen, Wenxi; Yang, Huahai; Chi, Changyan","If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills","Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6708-0","","10.1145/3313831.3376131","https://doi.org/10.1145/3313831.3376131","Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks.","2020-04-21","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–14","","","","","","If I Hear You Correctly","CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","C:\Users\esben\Zotero\storage\SQJIUGTJ\Xiao et al. - 2020 - If I Hear You Correctly Building and Evaluating I.pdf","","","deep learning; conversational agents; active listening; ai chatbot; chatbot platform; interview chatbot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VBCNWPE","conferencePaper","2019","Gu, Xiusen; Xu, Weiran; Zhang, Chao","Neural Emotional Response Generation via Adversarial Transfer Learning","Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence","978-1-4503-6128-6","","10.1145/3319921.3319933","https://doi.org/10.1145/3319921.3319933","Emotional response generation is a key step to build an empathetic chatbot. However, previous emotional chatting models mainly focus on single-turn conversation, and multi-turn context emotional response generation has not been explored. In this paper, we propose an adversarial transfer emotional chatting (ATEC) model for multi-turn conversation which is based on conditional variational autoencoders (CVAE). ATEC has two alternate training phases: supervised training and transfer training. In the supervised training stage, we train the CVAE model, a content discriminator and an emotional classifier based on ground truth corpus. And in the transfer training stage, we change the target emotion and use the content discriminator to force the model to transfer the multi-turn context information, while the emotional classifier regularizes the emotions expressed in the generated responses. Experiments show that the proposed approach achieves state of the art performance with diverse responses and accurate emotional expression.","2019-03-15","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","106–110","","","","","","","ICIAI 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","conditional variational autoencoders; emotion transfer; Emotional dialogue system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q66GR627","conferencePaper","2017","Portela, Manuel; Granell-Canut, Carlos","A new friend in our smartphone? observing interactions with chatbots in the search of emotional engagement","Proceedings of the XVIII International Conference on Human Computer Interaction","978-1-4503-5229-1","","10.1145/3123818.3123826","https://doi.org/10.1145/3123818.3123826","We present the findings of a quantitative and qualitative empirical research to understand the possibilities of engagement and affection in the use of conversational agents (chatbots). Based on an experiment with 13 participants, we explored on one hand the correlation between the user expectation, user experience and intended use and, on the other, whether users feel keen and engaged in having a personal, empathic relation with an intelligent system like chatbots. We used psychological questionnaires to semi-structured interviews for disentangle the meaning of the interaction. In particular, the personal psychological background of participants was found critical while the experience itself allowed them to imagine new possible relations with chatbots. Our results show some insights on how people understand and empathize with future interactions with conversational agents and other non-visual interfaces.","2017-09-25","2021-02-15 21:29:19","2021-02-15 21:29:19","2021-02-15","1–7","","","","","","A new friend in our smartphone?","Interacci&#xf3;n '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","","","","conversational agents; emotional engagement; empathic relations; mixed-method analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N9B6I9WU","conferencePaper","2017","Thompson, Jeff","I Touch You and You Touch Me","SIGGRAPH Asia 2017 Art Gallery","978-1-4503-5401-1","","10.1145/3143748.3143753","https://doi.org/10.1145/3143748.3143753","A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.","2017","2021-02-15 21:31:17","2021-02-15 21:31:17","","","","","","","","","SA '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bangkok, Thailand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLT3R663","conferencePaper","2010","Lee, Myunghee; Kim, Gerard J.","Empathetic Video Experience through Timely Multimodal Interaction","International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction","978-1-4503-0414-6","","10.1145/1891903.1891948","https://doi.org/10.1145/1891903.1891948","In this paper, we describe a video playing system, named ""Empatheater,"" that is controlled by multimodal interaction. As the video is played, the user must interact and emulate predefined video ""events"" through multimodal guidance and whole body interaction (e.g. following the main character's motion or gestures). Without the timely interaction, the video stops. The system shows guidance information as how to properly react and continue the video playing. The purpose of such a system is to provide indirect experience (of the given video content) by eliciting the user to mimic and empathize with the main character. The user is given the illusion (suspended disbelief) of playing an active role in the unraveling video content. We discuss various features of the newly proposed interactive medium. In addition, we report on the results of the pilot study that was carried out to evaluate its user experience compared to passive video viewing and keyboard based video control.","2010","2021-02-15 21:31:17","2021-02-15 21:31:17","","","","","","","","","ICMI-MLMI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Beijing, China","","","","empathy; user experience; interactive video; multimodality; user guidance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WY87E8Q","conferencePaper","2018","Roberts, Jasmine","Using Affective Computing for Proxemic Interactions in Mixed-Reality","Proceedings of the Symposium on Spatial User Interaction","978-1-4503-5708-1","","10.1145/3267782.3274692","https://doi.org/10.1145/3267782.3274692","Immersive technologies have been touted as empathetic mediums. This capability has yet to be fully explored through machine learning integration. Our demo seeks to explore proxemics in mixed-reality (MR) human-human interactions.The author developed a system, where spatial features can be manipulated in real time by identifying emotions corresponding to unique combinations of facial micro-expressions and tonal analysis. The Magic Leap One is used as the interactive interface, the first commercial spatial computing head mounted (virtual retinal) display (HUD).A novel spatial user interface visualization element is prototyped that leverages the affordances of mixed-reality by introducing both a spatial and affective component to interfaces.","2018","2021-02-15 21:31:17","2021-02-15 21:31:17","","176","","","","","","","SUI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Berlin, Germany","","","","affective computing; augmented reality; mixed reality; Proxemics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJT26LPR","conferencePaper","2020","Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef","Facial Expression Based Satisfaction Index for Empathic Buildings","Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers","978-1-4503-8076-8","","10.1145/3410530.3414443","https://doi.org/10.1145/3410530.3414443","In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.","2020","2021-02-15 21:31:17","2021-02-15 21:31:17","","704–707","","","","","","","UbiComp-ISWC '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Mexico","","","","machine learning; empathic building; facial expressions; satisfaction index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGRQZCE4","conferencePaper","2019","Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco","A Preliminary Work on Dog Emotion Recognition","IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume","978-1-4503-6988-6","","10.1145/3358695.3361750","https://doi.org/10.1145/3358695.3361750","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications.The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.","2019","2021-02-15 21:31:17","2021-02-15 21:31:17","","91–96","","","","","","","WI '19 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Thessaloniki, Greece","","","","Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MLLXAIVM","bookSection","2020","Chromik, Michael; Lachner, Florian; Butz, Andreas","ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research","Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society","978-1-4503-7579-5","","","https://doi.org/10.1145/3419249.3420163","Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML’s impact on current UXR activities and practitioners’ predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users’ emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research.","2020","2021-02-15 21:31:17","2021-02-15 21:31:17","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IV9NRRV6","conferencePaper","2019","Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie","Development of a Cloud-Based Computational Framework for an Empathetic Robot","Proceedings of the 2019 11th International Conference on Computer and Automation Engineering","978-1-4503-6287-0","","10.1145/3313991.3314018","https://doi.org/10.1145/3313991.3314018","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.","2019","2021-02-15 21:31:17","2021-02-15 21:31:17","","102–108","","","","","","","ICCAE 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Perth, WN, Australia","","","","deep learning; robot; cloud control; emotion classification; intent perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3CQIKGI6","bookSection","2020","Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph","Reputation Agent: Prompting Fair Reviews in Gig Markets","Proceedings of The Web Conference 2020","978-1-4503-7023-3","","","https://doi.org/10.1145/3366423.3380199","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.","2020","2021-02-15 21:31:17","2021-02-15 21:31:17","","1228–1240","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UL4ZGBCU","conferencePaper","2017","Frueh, Christian; Sud, Avneesh; Kwatra, Vivek","Headset Removal for Virtual and Mixed Reality","ACM SIGGRAPH 2017 Talks","978-1-4503-5008-2","","10.1145/3084363.3085083","https://doi.org/10.1145/3084363.3085083","Virtual Reality (VR) has advanced significantly in recent years and allows users to explore novel environments (both real and imaginary), play games, and engage with media in a way that is unprecedentedly immersive. However, compared to physical reality, sharing these experiences is difficult because the user's virtual environment is not easily observable from the outside and the user's face is partly occluded by the VR headset. Mixed Reality (MR) is a medium that alleviates some of this disconnect by sharing the virtual context of a VR user in a flat video format that can be consumed by an audience to get a feel for the user's experience.Even though MR allows audiences to connect actions of the VR user with their virtual environment, empathizing with them is difficult because their face is hidden by the headset. We present a solution to address this problem by virtually removing the headset and revealing the face underneath it using a combination of 3D vision, machine learning and graphics techniques. We have integrated our headset removal approach with Mixed Reality, and demonstrate results on several VR games and experiences.","2017","2021-02-15 21:31:17","2021-02-15 21:31:17","","","","","","","","","SIGGRAPH '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Los Angeles, California","","","","virtual reality; mixed reality; facial synthesis; headset removal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVD84XWI","conferencePaper","2015","Putnam, Cynthia; Dahman, Maria; Rose, Emma; Cheng, Jinghui; Bradford, Glenn","Teaching Accessibility, Learning Empathy","Proceedings of the 17th International ACM SIGACCESS Conference on Computers &amp; Accessibility","978-1-4503-3400-6","","10.1145/2700648.2811365","https://doi.org/10.1145/2700648.2811365","As information and communication technologies (ICTs) become more diffuse, the diversity of users that designers need to consider is growing; this includes people with disabilities and aging populations. As a result, computing education must provide students the means and inspiration to learn about inclusive design. This poster presents top-level findings from 18 interviews with professors from some of the top universities in the US. Our analysis yielded four categories of findings: (1) important student learning outcomes (the most common was for students to embrace diversity); (2) exercises and teaching materials (almost all focused on inclusion of people with disabilities in discovery and evaluation of ICTs); (3) frustrations and challenges (largely focused on how to engage students in accessibility topics); and (4) the importance of instructor initiative to include the topic of accessibility in their teaching. The unifying theme was the high importance of cultivating empathy with end users.","2015","2021-02-15 21:31:18","2021-02-15 21:31:18","","333–334","","","","","","","ASSETS '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","accessibility; pedagogy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGQ76ID7","conferencePaper","2020","Soleymani, Mohammad","Machine Understanding of Emotion and Sentiment","Companion Publication of the 2020 International Conference on Multimodal Interaction","978-1-4503-8002-7","","10.1145/3395035.3425321","https://doi.org/10.1145/3395035.3425321","Emotions are subjective experiences involving perceptual and con-textual factors [4]. There is no objective tool for precise measurement of emotions. However, we can anticipate an emotion's emergence through the knowledge of common responses to events in similar situations. We can also measure proxies of emotions by recognizing emotional expressions [3]. Studying emotional response to multimedia allows identifying expected emotions in users consuming the content. For example,abrupt loud voices are novel and unsettling which result in surprise and higher experience of arousal [2,6]. For a particular type of con-tent such as music, mid-level attributes such as rhythmic stability or melodiousness have strong association with expected emotions[1]. Given that such mid-level attributes are more related to the con-tent, their machine-perception is more straightforward. Moreover,their perception in combination with user models enables building person-specific emotion anticipation models.In addition to studying expected emotions, we can also observe users emotional reactions to understand emotion in multimedia.Typical methods of emotion recognition include recognizing emotions from facial or vocal expressions. Recognition of emotional expressions requires large amount of labeled data, expensive to produce. Hence, the most recent advances in machine-based emotion perception include methods that can leverage unlabeled data through self-supervised and semi-supervised learning [3, 5]. In this talk, I review the field and showcase methods for automatic modeling and recognition of emotions and sentiment indifferent contexts [3,8]. I show how we can identify underlying factors contributing to the construction of subjective experience of emotions [1,7]. Identification of these factors allows us to use them as mid-level attributes to build machine learning models for emotion and sentiment understanding. I also show how emotions and sentiment can be recognized from expressions with the goal of building empathetic autonomous agents [8].","2020","2021-02-15 21:31:18","2021-02-15 21:31:18","","206–207","","","","","","","ICMI '20 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Netherlands","","","","machine learning; emotion; affective computing; sentiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KP8DBCM","conferencePaper","2014","Slovák, Petr","Supporting Teaching and Learning of Situational Empathy by Technology","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2559957","https://doi.org/10.1145/2559206.2559957","Detecting and supporting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, most of this work is still based primarily on single persons' data, and there is little research on supporting complex interpersonal aspects such as empathy. To address this gap, the goal of my PhD work is to explore ways in which technology can facilitate learning and teaching of situational empathy, with particular focus on counselling students.","2014","2021-02-15 21:31:18","2021-02-15 21:31:18","","315–318","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","feedback; empathy; bio-sensors; mixed methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4YDHKCTA","conferencePaper","2017","Polignano, Marco; Basile, Pierpaolo; Rossiello, Gaetano; de Gemmis, Marco; Semeraro, Giovanni","Learning Inclination to Empathy from Social Media Footprints","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","978-1-4503-4635-1","","10.1145/3079628.3079639","https://doi.org/10.1145/3079628.3079639","In recent years we are witnessing a growing spread of social media footprints, as the consequence of the wide use of applications such as Facebook, Twitter or LinkedIn, which allow people to share content that might provide information about personal preferences and aptitudes. Among the traits that can be inferred, empathy is the ability to feel and share another person's emotions and we consider it as a relevant aspect for the profiling and recommendation tasks. We propose a method that predicts its level for the user by exploiting her social media data and using linear regression algorithms. The results show which are the most relevant correlations among the different groups of user's features and the empathy level predicted.","2017","2021-02-15 21:31:18","2021-02-15 21:31:18","","383–384","","","","","","","UMAP '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bratislava, Slovakia","","","","machine learning; empathy; social medium footprint","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMW857WB","conferencePaper","2019","Bevan, Chris; Green, David Philip; Farmer, Harry; Rose, Mandy; Cater, Kirsten; Stanton Fraser, Danaë; Brown, Helen","Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300736","https://doi.org/10.1145/3290605.3300736","Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","1–12","","","","","","","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","virtual reality; interaction; immersive media; nonfiction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDTBG6C2","book","2020","","HAI '20: Proceedings of the 8th International Conference on Human-Agent Interaction","","978-1-4503-8054-6","","","","It is our great pleasure to welcome you to the Eighth International Conference on Human-Agent Interaction HAI 2020 (Virtual Conference); hosted by the Western Sydney University (Australia) and supported by Chalmers University of Technology (Sweden).The conference is a venue with an interdisciplinary nature to discuss and disseminate state-ofthe- art research on topics related to human interactions with a range of agent systems, including physical robots and humanoids, virtual agents, socially interactive agents, and Artificially Intelligent (AI) agents. The topical areas of the conference include user studies, frameworks, simulations, technical developments and more within Human Agent and Robotic Interaction. The conference brings together a large variety of multidisciplinary research groups, companies, and researchers looking into the broader area of agents and robotics across Australia, Japan and the rest of the world.The theme for HAI 2020 is ""Artificial Intelligence + Experience Design."" The recent advent of AI has motivated researchers to focus on several algorithmic prospects in developing intelligent robotic agents and their interactions. Progressively, AI advances are leading to exciting outcomes in the HAI field and, at the same time, are opening up for a wide perspective on how to design intelligent robotic agents. For example, how to combine artificial intelligence and user experience design approaches in human-agent interaction. We are looking forward to sharing the latest research results of HAI that contribute a broad range of disciplines.Three keynote talks are featured. The first is titled ""We're in This Together: Social Robots in Group, Organizational, and Community Interactions"", by Associate Prof. Selma Šabanović, Indiana University Bloomington, USA. The second is titled ""What kind of human-centric robotics do we need? Investigations from human-robot interactions in socially assistive scenarios"", by Prof. Ginevra Castellano, Uppsala University, Sweden. The third is an industry talk titled ""The rapid rise in drone technology"", by Sebastian Robertson, CEO of BIRDI, Australia. Their keynote talks will provide cross-disciplinary examples of novel HAI research and applications that are highly inspiring for the HAI audience and research community.This year's submissions have come from more than 25 countries and cover leading-edge topics including human and machine learning, conversational agents, empathy and trust of social robots, social drones, social presence, robot applications, virtual agent applications and novel perspectives of HAI. With an acceptance rate of 38% (25 papers out of 65 submissions), the program committee has again set a high quality standard. In addition, 26 out of the 35 latebreaking poster papers submissions were accepted.","2020","2021-02-15 21:31:18","2021-02-15 21:31:18","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2HLAH5R","journalArticle","2019","Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana","Empathic Robot for Group Learning: A Field Study","J. Hum.-Robot Interact.","","","10.1145/3300188","https://doi.org/10.1145/3300188","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.","2019-03","2021-02-15 21:31:18","2021-02-15 21:31:18","","","","1","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WH3LS7JJ","conferencePaper","2017","De Lira, Carla","Improving the Learning Experiences of First-Year Computer Science Students with Empathetic IDEs","Proceedings of the 2017 ACM Conference on International Computing Education Research","978-1-4503-4968-0","","10.1145/3105726.3105742","https://doi.org/10.1145/3105726.3105742","Computer science has the highest dropout rate among undergraduate STEM degree programs. This is especially concerning, given that computer science-related jobs are projected to grow 12% in the next six years. One contributing factor is that media representations of computer science can lead underrepresented groups to perceive themselves as unfit for the discipline, and ultimately to drop out. To address this concern, I propose an empathetic IDE model that uses affective computing technologies to promote empathy among computer science students. A quasi-experimental research design will be used to evaluate the model's effectiveness in fostering a supportive community between instructors and students. By leveraging emotional learning process data as a form of constant feedback to both instructors and students, this research can gain new insights into how to improve learning environments for computer science students with or without affective computing technologies.","2017","2021-02-15 21:31:18","2021-02-15 21:31:18","","293–294","","","","","","","ICER '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tacoma, Washington, USA","","","","affective computing; computer science education; empathy in computer science; learning analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VESCDX8B","conferencePaper","2016","Bratitsis, Tharrenos","A Digital Storytelling Approach for Fostering Empathy Towards Autistic Children: Lessons Learned","Proceedings of the 7th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion","978-1-4503-4748-8","","10.1145/3019943.3019987","https://doi.org/10.1145/3019943.3019987","In this paper a case study in which interactive digital storytelling was exploited for fostering empathy towards children with Autism Spectrum Disorders (ASD) is presented. The research population consisted mainly by Kindergarten children. Based on the findings and the overall experience, even considering the design mistakes that occurred, this paper argues upon the deriving value of exploiting multimodal digital representations in the form of a story in order to cultivate empathy towards children with ASD and thus, facilitate social interaction and inclusion. This approach can be useful in mixed population classrooms, but in a wider educational context as well.","2016","2021-02-15 21:31:18","2021-02-15 21:31:18","","301–308","","","","","","","DSAI 2016","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vila Real, Portugal","","","","Empathy; ASD; Digital Storytelling; Inclusion; Kindergarten; Social Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NYAPZXTZ","conferencePaper","2019","Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad","Multimodal Learning for Identifying Opportunities for Empathetic Responses","2019 International Conference on Multimodal Interaction","978-1-4503-6860-5","","10.1145/3340555.3353750","https://doi.org/10.1145/3340555.3353750","Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","95–104","","","","","","","ICMI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Suzhou, China","","","","machine learning; empathy; human behavior; multimodal sentiment; virtual human","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C97P2NM2","conferencePaper","2014","Villarica, Ryan; Richards, Deborah","Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds","Proceedings of the 2014 Conference on Interactive Entertainment","978-1-4503-2790-9","","10.1145/2677758.2677761","https://doi.org/10.1145/2677758.2677761","Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.","2014","2021-02-15 21:31:18","2021-02-15 21:31:18","","1–9","","","","","","","IE2014","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Newcastle, NSW, Australia","","","","Empathic Agents; Omosa; Virtual Learning Environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7RIZDZZ2","conferencePaper","2018","Kroma, Assem; Lachman, Richard","Alzheimer's Eyes Challenge: The Gamification of Empathy Machines","Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts","978-1-4503-5968-9","","10.1145/3270316.3270320","https://doi.org/10.1145/3270316.3270320","Demographic projections of many western democracies show them to be aging nations. To keep thriving we must ensure that our citizens are aging in a healthy manner without isolation from society. Alzheimer's disease is one of the most misunderstood conditions of our aging population, and is a problematic condition for caregivers and family members to support. This project seeks to build a mixed reality environment that allows users to experience some of the symptoms of Alzheimer's in the form of serious games. By gamifying the notion of the somewhat controversial notion of the ""empathy machine"", the project makes a novel social impact on the general population.","2018","2021-02-15 21:31:18","2021-02-15 21:31:18","","329–336","","","","","","","CHI PLAY '18 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Melbourne, VIC, Australia","","","","virtual reality; augmented reality; mixed reality; serious games; gamification; alzheimer's disease; empathy machines; extended realities; meaningful play","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQ72S555","bookSection","2020","Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri","Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419900","Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.","2020","2021-02-15 21:31:18","2021-02-15 21:31:18","","262–266","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAINJ4EL","conferencePaper","2019","Urakami, Jacqueline; Moore, Billie Akwa; Sutthithatip, Sujitra; Park, Sung","Users' Perception of Empathic Expressions by an Advanced Intelligent System","Proceedings of the 7th International Conference on Human-Agent Interaction","978-1-4503-6922-0","","10.1145/3349537.3351895","https://doi.org/10.1145/3349537.3351895","The goal of this study was to examine usertextquoteright s perception of expressions of empathy by an autonomous system. In a survey eight different components of empathy identified in literature studies and prior tests (Expressing own feelings, Expressing to know what the other feels, Helping, Showing interest, Taking the others perspective, Displaying regard, Situational understanding, and Agreement) were compared to neutral expressions. Differences in participants evaluations were found across the components of empathy as well as individual differences were revealed. Expressions of cognitive empathy (Showing interest, situational understanding) and expressions of empathy of assistance (helping) were perceived positively by participants. However, expressions of affective empathy (expressing own feelings, expressing to know what the other feels) received mainly negative ratings. Cluster analysis revealed individual differences especially for items relating to affective empathy. Whereas one group of participants identified in the cluster analysis rated expressions of affective empathy negatively, a second group of participants rated these expressions positively. Furthermore, large differences across participants also existed for taking the other's perspective, a component of cognitive empathy. Integrating expressions of empathy in human-machine interaction is a sensitive issue and designers must carefully choose what components of empathy are adequate depending on the situational circumstances and the targeted user group.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","11–18","","","","","","","HAI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","empathy; autonomous intelligent system; survey","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UX4K5HK","conferencePaper","2019","Chen, Jize; Wang, Changhong","Reaching Cooperation Using Emerging Empathy and Counter-Empathy","Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-6309-9","","","","According to social neuropsychology, the cooperative behavior is largely influenced by empathy, which is deemed essential of emotional system and has wide impact on social interaction. In the work reported here, we believe that the emergence of empathy and counter-empathy is closely related to creatures' inertial impression on intragroup coexistence and competition. Based on this assumption, we establish a unified model of empathy and counter-empathy in light of Hebb's rule. We also present Adaptive Empathetic Learner (AEL), a training method for agents to enable affective utility evaluation and learning procedure in multi-agent system. In AEL, the empathy model is integrated into the adversarial bandit setting in order to achieve a high degree of versatility. Our algorithm is first verified in the survival game, which is designed to simulate the primitive hunting environment. In this game, empathy and cooperation emerge among agents with different power. In another test about Iterated Prisoners' Dilemma, cooperation was reached even between an AEL agent and a rational one. Moreover, when confronted with hostile, the AEL agent showed sufficient goodwill and vigilantly protected its safe payoffs. In the Ultimatum Game, it's worth mentioning that absolute fairness could be achieved on account of the self-adaptation of empathy and counter-empathy.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","746–753","","","","","","","AAMAS '19","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Montreal QC, Canada","","","","cooperation; adversarial bandit; empathy and counter-empathy; multi-agent system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WIRW8IWP","conferencePaper","2013","Buckingham Shum, Simon; de Laat, Maarten; De Liddo, Anna; Ferguson, Rebecca; Kirschner, Paul; Ravenscroft, Andrew; Sándor, Ágnes; Whitelock, Denise","DCLA13: 1<sup>st</sup> International Workshop on Discourse-Centric Learning Analytics","Proceedings of the Third International Conference on Learning Analytics and Knowledge","978-1-4503-1785-6","","10.1145/2460296.2460357","https://doi.org/10.1145/2460296.2460357","This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field.","2013","2021-02-15 21:31:18","2021-02-15 21:31:18","","282","","","","","","","LAK '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Leuven, Belgium","","","","dialogue; learning analytics; argumentation; deliberation; discourse; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FR4BXL8G","conferencePaper","2019","Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana","EmotoTent: Reducing School Violence through Embodied Empathy Games","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3326596","https://doi.org/10.1145/3311927.3326596","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","755–760","","","","","","","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWI6QL9M","conferencePaper","2019","Nakamura, Lisa","Virtual Reality and the Feeling of Virtue: Women of Color Narrators, Enforced Hospitality, and the Leveraging of Empathy","Proceedings of the 2019 on Designing Interactive Systems Conference","978-1-4503-5850-7","","10.1145/3322276.3325420","https://doi.org/10.1145/3322276.3325420","Many researchers and evangelists argue that V.R. is fundamentally more ""moving"" than other media because of users' visual immersion in navigable worlds and their empathic identification with another visual perspective. (see Rubin, Bailenson). This essay will analyze women of color's labor as virtual reality's documentary subjects whose digital presence and hospitality within war-torn, emiserated, and inhospitable scenes such as a Lebanese refugee camp, a favela, and a cucumber farm enables a fantasy of virtuous empathy on the part of the viewer. Virtual reality's painstakingly created virtuous identity as the ""empathy machine"" satisfies desires for prosocial feelings of compassion, empathy, and identification that replace encounters with politics, unwelcome bodies, and protest. Global South women of color, non-white refugee women, and trans women are all virtual objects of identification in virtual reality and video games, platforms that are inextricably connected yet carry very different moral and ethical connotations.","2019","2021-02-15 21:31:18","2021-02-15 21:31:18","","3","","","","","","","DIS '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, CA, USA","","","","empathy; virtual reality; hospitality; empathy machine; labor; women of color","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6WVS2PB","journalArticle","2016","McBride, Neil","The Ethics of Driverless Cars","SIGCAS Comput. Soc.","","0095-2737","10.1145/2874239.2874265","https://doi.org/10.1145/2874239.2874265","This paper critiques the idea of full autonomy, as illustrated by Oxford University's Robotcar. A fully autonomous driverless car relies on no external inputs, including GPS and solely learns from its environment using learning algorithms. These cars decide when they drive, learn from human drivers and bid for insurance in real time. Full autonomy is pitched as a good end in itself, fixing human inadequacies and creating safety and certainty by the elimination of human involvement. Using the ACTIVE ethics framework, an ethical response to the fully autonomous driverless cars is developed by addressing autonomy, community, transparency, identity, value and empathy. I suggest that the pursuit of full autonomy does not recognise the essential importance of interdependencies between humans and machines. The removal of human involvement should require the driverless car to be more connected with its environment, drawing all the information it can from infrastructure, internet and other road users. This requires a systemic view, which addresses systems and relationships, which recognises the place of driverless cars in a connected system, which is open to the study of complex relationships, both networked and hierarchical.","2016-01","2021-02-15 21:31:18","2021-02-15 21:31:18","","179–184","","3","45","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","ethics; driverless cars; full autonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJRYL9WU","journalArticle","2017","Otterbacher, Jahna; Ang, Chee Siang; Litvak, Marina; Atkins, David","Show Me You Care: Trait Empathy, Linguistic Style, and Mimicry on Facebook","ACM Trans. Internet Technol.","","1533-5399","10.1145/2996188","https://doi.org/10.1145/2996188","Linguistic mimicry, the adoption of another’s language patterns, is a subconscious behavior with pro-social benefits. However, some professions advocate its conscious use in empathic communication. This involves mutual mimicry; effective communicators mimic their interlocutors, who also mimic them back. Since mimicry has often been studied in face-to-face contexts, we ask whether individuals with empathic dispositions have unique communication styles and/or elicit mimicry in mediated communication on Facebook. Participants completed Davis’s Interpersonal Reactivity Index and provided access to Facebook activity. We confirm that dispositional empathy is correlated to the use of particular stylistic features. In addition, we identify four empathy profiles and find correlations to writing style. When a linguistic feature is used, this often “triggers” use by friends. However, the presence of particular features, rather than participant disposition, best predicts mimicry. This suggests that machine-human communications could be enhanced based on recently used features, without extensive user profiling.","2017-02","2021-02-15 21:31:19","2021-02-15 21:31:19","","","","1","17","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","social media; Affect; empathy; empathic response; interpersonal relations; linguistic alignment; linguistic mimicry; linguistic style","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRENGSE2","conferencePaper","2018","Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor","He Who Hesitates is Lost (...in Thoughts over a Robot)","Proceedings of the Technology, Mind, and Society","978-1-4503-5420-2","","10.1145/3183654.3183703","https://doi.org/10.1145/3183654.3183703","In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.","2018","2021-02-15 21:31:19","2021-02-15 21:31:19","","","","","","","","","TechMindSociety '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, DC, USA","","","","Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKUEZDYA","conferencePaper","2016","Sturdee, Miriam; Coulton, Paul; Lindley, Joseph G.; Stead, Mike; Ali, Haider; Hudson-Smith, Andy","Design Fiction: How to Build a Voight-Kampff Machine","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2892574","https://doi.org/10.1145/2851581.2892574","Tyrell: Is this to be an empathy test? Capillary dilation of the so-called blush response? Fluctuation of the pupil. Involuntary dilation of the iris... Deckard: We call it Voight-Kampff for short. Design fiction is a broad term that occupies a space within the wider miscellany of speculative design approaches and is appearing as a nascent method for HCI research. The factor that differentiates and distinguishes design fiction from other approaches is its novel use of world building and in this paper we consider whether there is value in creating fictional research worlds through which we might consider future interactions. As an example we build a world in which algorithms for detecting empathy will become a major compnent of future communications. We take inspiration from the sci-fi film Blade Runner in order to consider what a plausible world, in which it is useful to build a Voight-Kampff machine, might be like.","2016","2021-02-15 21:31:19","2021-02-15 21:31:19","","375–386","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","empathy; speculative design; blade runner; design fiction; research through design; Voight Kampff","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXMUJJPN","conferencePaper","2020","Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio","DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI","Proceedings of the International Conference on Advanced Visual Interfaces","978-1-4503-7535-1","","10.1145/3399715.3399820","https://doi.org/10.1145/3399715.3399820","Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.","2020","2021-02-15 21:31:19","2021-02-15 21:31:19","","","","","","","","","AVI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salerno, Italy","","","","Computer Vision; Deep Learning; User Emotions; User Experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6GWZDB4B","conferencePaper","2014","Watanabe, Yukako; Okada, Yoshiko; Osawa, Hirotaka; Sugaya, Midori","Digital Play Therapy for Children with Learning Disabilities","Proceedings of the Second International Conference on Human-Agent Interaction","978-1-4503-3035-0","","10.1145/2658861.2658918","https://doi.org/10.1145/2658861.2658918","Children who are suffering on learning and developmental disabilities require daily trainings for social skills. However, such daily training is not provided occasionally because it requires interactive helps from therapists. In this paper, we propose a digital dollhouse that enhanced traditional psychological play therapy with digital sensors and computer graphics. The digital dollhouse provides immersive space to children which grows children's communication skill through their imaging play. This device allows non-professional like parents to make play therapy. In this paper, we show details about prototype of digital dollhouse. We also categorize requirements for digital play therapy that are given by psychological viewpoints based on the prototype. Interdisciplinary design process collaborating with engineers and psychologists shows the possibility that digital dollhouse is enough to enhance empathy of children and such empathy will be enhanced by creating immersive characters.","2014","2021-02-15 21:31:19","2021-02-15 21:31:19","","185–188","","","","","","","HAI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tsukuba, Japan","","","","human-agent interaction; human robot interaction; augmented human; emotional labor; human interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUIM9W8U","conferencePaper","2019","Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid","BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3302290","https://doi.org/10.1145/3301275.3302290","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.","2019","2021-02-15 21:31:19","2021-02-15 21:31:19","","448–459","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina del Ray, California","","","","conversational agents; explainable AI; mechanical turk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L68MHZKG","conferencePaper","2020","El-Glaly, Yasmine; Shi, Weishi; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.","Presenting and Evaluating the Impact of Experiential Learning in Computing Accessibility Education","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training","978-1-4503-7124-7","","10.1145/3377814.3381710","https://doi.org/10.1145/3377814.3381710","Studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. Compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. To address these issues, we have created five Accessibility Learning Labs (ALL) using an experiential learning structure. The labs are designed to educate and create awareness of accessibility needs in computing. The labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. The labs are hosted on our servers and require only a browser to be utilized.To demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. Our findings include: (I) The demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (II) The labs are effective in informing students about foundational accessibility topics (III) Empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. Created labs and project materials are publicly available on the project website: http://all.rit.edu","2020","2021-02-15 21:31:19","2021-02-15 21:31:19","","49–60","","","","","","","ICSE-SEET '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, South Korea","","","","accessibility education; computing accessibility; computing education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFMJY97J","conferencePaper","2016","Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne","I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.","2016","2021-02-15 21:31:19","2021-02-15 21:31:19","","931–939","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","empathy; human-agent interaction; human-robot interaction; memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N34UW9K6","conferencePaper","2018","Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Klapwijk, Remke","Developing Children's Empathy in Co-Design Activities: A Pilot Case Study","Proceedings of the 17th ACM Conference on Interaction Design and Children","978-1-4503-5152-2","","10.1145/3202185.3210797","https://doi.org/10.1145/3202185.3210797","This paper explores how co-design activities in schools can contribute to developing children's empathy. A pilot case study is presented in which eight 10- to 12-year-old children participated. The design theme was outdoor education. After discussing the co-design procedure, preliminary results about three empathic techniques are discussed: (1) reflection on the role of empathy in design, (2) storytelling to introduce the design challenge, and (3) defining the needs and wishes of the story's protagonists. The lessons learned are taken into account in a comprehensive follow-up study.","2018","2021-02-15 21:31:19","2021-02-15 21:31:19","","669–674","","","","","","","IDC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","children; empathy; storytelling; co-design; 21st century skills; schools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XK2R28MY","conferencePaper","2013","Shanahan, Joseph; Marghitu, Daniela","Software Engineering Java Curriculum with Alice and Cloud Computing","Proceedings of Alice Symposium on Alice Symposium","978-1-4503-2250-8","","10.1145/2532333.2532337","https://doi.org/10.1145/2532333.2532337","Project Expression is a course designed to attract students into the field of computing. Participants are trained in Java programming and the art of multimedia production. By implementing a wide range of apps they learn cloud communication techniques in a software environment. The course focuses on a digital film project and participants are challenged with creating a movie that expresses an idea, opinion, or belief relative to society. The film project is a landscape for learning cloud-computer-programming and reaches across the computer spectrum with engaging activities that stimulate creative design. This study examines the curriculum's approach and measures its effectiveness to teach the cloud-computing mentality. It emphasizes the importance of empathy in a technology-based society. Furthermore, it investigates whether or not such a course is an effective method for attracting students into the field of computing.","2013","2021-02-15 21:31:19","2021-02-15 21:31:19","","","","","","","","","ALICE '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Durham, NC, USA","","","","3D animations; 3D Visualization; Computers and Empathy; K-12 Computer Science Curriculum; K12 Alice Curriculum; K12 Cloud Computing Curriculum; Movie-making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7ALHCDW","conferencePaper","2019","Muñoz, Diego; Ploderer, Bernd; Brereton, Margot","Position Exchange Workshops: A Method to Design for Each Other in Families","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300339","https://doi.org/10.1145/3290605.3300339","Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me &amp; You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships.","2019","2021-02-15 21:31:19","2021-02-15 21:31:19","","1–14","","","","","","","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","dialogicality; family relationships; parent-adult child relationship; position exchange; position exchange workshops; renegotiation of relationships","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFQHYN9B","conferencePaper","2017","Pantela, Nicoletta; Kyza, Eleni A.","The Investigation of Concept Mapping as a Scaffolding Tool in a Technologically-Mediated, Mobile Learning, Augmented Reality Environment","Proceedings of the 16th World Conference on Mobile and Contextual Learning","978-1-4503-5255-0","","10.1145/3136907.3136924","https://doi.org/10.1145/3136907.3136924","This study investigated concept maps as a form of support for primary school students' development of conceptual understanding, historical empathy, and for promoting collaborative learning. Students used the same historical learning augmented reality application on a mobile device, worked in pairs, and were divided in two conditions: the experimental group (n=12), supported by a tablet-based concept mapping tool, and the control group (n=11), who only used the learning application on the same mobile devices. The results showed that the experimental group students gained a deeper conceptual understanding after the visit, as evidenced by their concept maps and their discussions during their visit.","2017","2021-02-15 21:31:19","2021-02-15 21:31:19","","","","","","","","","mLearn 2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Larnaca, Cyprus","","","","informal learning; computer-supported collaborative learning; concept maps; Scaffolding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6ZA5TH5","conferencePaper","2012","Stienstra, Jelle; Marti, Patrizia","Squeeze Me: Gently Please","Proceedings of the 7th Nordic Conference on Human-Computer Interaction: Making Sense Through Design","978-1-4503-1482-4","","10.1145/2399016.2399131","https://doi.org/10.1145/2399016.2399131","This paper presents the Squeeze Me, a research-through-design case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a double-layered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge.","2012","2021-02-15 21:31:19","2021-02-15 21:31:19","","746–750","","","","","","","NordiCHI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Copenhagen, Denmark","","","","empathy; interaction design; continuous mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EEZVBMES","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: A Living Media Interface for Speech Intervention","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-2473-1","","10.1145/2556288.2557402","https://doi.org/10.1145/2556288.2557402","Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.","2014","2021-02-15 21:31:19","2021-02-15 21:31:19","","1817–1820","","","","","","","CHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","embedded computing; living media interfaces; speech intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E45AXW5J","conferencePaper","2020","de Oliveira, Lariza Laura","Mapping Empathy in the Computer Science Classroom","Proceedings of the 2020 ACM Conference on International Computing Education Research","978-1-4503-7092-9","","10.1145/3372782.3408109","https://doi.org/10.1145/3372782.3408109","Empathy is a humanistic skill, a capacity that allows us to perceive other people's emotions, putting ourselves under their perspective [1]. The study of empathy is highlighted as a tool to provide a better understanding of people's thoughts, feelings and how they affect behavior [2]. Being aware of that, a design company created the Empathy Map (EM), which is usually employed in the initial phase of the Design Thinking process to understand user's concerns, feelings and aspirations [3].Teaching practices known as student-centered, inherited from the constructivist school, are not new [4]. Several educators have applied these approaches inside the Computer Science (CS) classroom [5]. A key to success in CS education is the construction of the computational thinking [5]. Learning to program is not an easy task and the process is surrounded by several emotional reactions such as frustration, anxiety, happiness and others [6]. In this sense, EMs can be useful to capture student's feelings, guiding educators strategies during CS classes.Here, I describe the experience of using the EM inside the Computer Science classroom at the University Center Barão de Mauá. The process of building EMs involves the description of the persona, who, in this case, are the students of a given year in the CS course. In the center of EM, the picture of a student is drawn and the surrounding region is divided into 4 areas [3, 7]: 1) THINK and FEEL - What are the students thinking/feeling? 2) HEAR and SEE - What are the students hearing/seeing? 3) SAY and DO - What are the students saying/doing? 4) PAIN/CHALLENGES and GAINS - What are the challenges the students are facing? Is there anything painful to do? How do they measure success?The EM was performed in two different stages of the CS course: in the first and third years. The students were asked to build the EM, representing their feelings and aspirations about CS. The EM of the first year showed: 1) THINK and FEEL - ""thinking about the future"", ""feeling fear"", ""curiosity"", ""insecurity"", ""confusion"". 2) HEAR and SEE - "" hearing positive statements from family and friends"", ""seeing themselves in a trainee program"", ""working or doing a master's degree"", ""developing themselves"". They also reported to hear that CS is very difficult. 3) SAY and DO - They say learning is difficult, They do study and work; 4) PAIN/CHALLENGES - they report feeling insecure about finishing the course and find a position. The main challenge is to conciliate both working and studies. The students of the third year reported: 1) THINK and FEEL - ""thinking about the future"", ""feeling anxiety"", ""anger"", ""tiredness"", ""worry""; 2) HEAR and SEE - "" they hear that CS is a promising career"", ""see opportunities and/or lack of them"". They reported hear questions about what they will do in the future; 3) SAY and DO - ""procrastinating and working""; 4) PAIN/CHALLENGES - The pain reported refers to the anxiety of completing the course and the excessive procrastination. The main challenge reported was to set medium/short term goals as study to complete tasks in the CS course.As a conclusion, we highlight that the first year students were more motivated about their future, whereas the third year are tired and anxious about finishing the course. The EM construction was able to show student's feelings and pains about the course, allowing the educator to capture the student's perspectives. Based on that, it may be possible to conduct a more appropriate learning plan to manage how emotional aspects can influence the learning process. As a future work, EM will be used along with specific subjects in a qualitative study, considering subjects with highest failure rates in CS curriculum.","2020","2021-02-15 21:31:19","2021-02-15 21:31:19","","303","","","","","","","ICER '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, New Zealand","","","","computer science education; empathy map","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26CFIR4Z","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: A Living Media Interface for Learning Games","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2574772","https://doi.org/10.1145/2559206.2574772","Digital games can engage children in therapeutic and learning activities. Incorporating living media in these games can create feelings of empathy and caring in users and add more motivation and involvement to the gameplay. We present, Rafigh, a living media interface designed to motivate children to play learning games that involve repetitive and sometimes boring tasks. In the current implementation the interface is used for speech intervention games. During gameplay, children practice their speech and care for a living mushroom colony in the process. The mushroom's growth is used to communicate how much speech is used, as an indicator of degree of speech practice, during interaction.","2014","2021-02-15 21:31:20","2021-02-15 21:31:20","","407–410","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","embedded computing; living media interfaces; speech intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6GVD2LGP","conferencePaper","2019","Choi, Kyung Yun; Sumini, Valentina; Ishii, Hiroshi","ReSpire: Self-Awareness and Interpersonal Connectedness through Shape-Changing Fabric Display","Proceedings of the 2019 on Creativity and Cognition","978-1-4503-5917-7","","10.1145/3325480.3329176","https://doi.org/10.1145/3325480.3329176","reSpire lets people bring tangibility to their invisible physiological state through shape-changing fabric deformed by airflow. We explore a way to support mental wellness via improving a self-interaction and interpersonal connectedness. reSpire encourages not only people to focus on their connection to inner body but also to interact with others through playful tangible interactions in the same location and develop a empathy. We created a non-machine like interface responsive to users' respiration patterns and hand gestures using a fabric and its deformation by airflow control. We also introduce a computational model to simulate the deformation of fabric by the variance of airflow pres-sure and direction. Various interaction scenarios highlight its applications not only to health but also to interactive art installation.","2019","2021-02-15 21:31:20","2021-02-15 21:31:20","","449–454","","","","","","","C&amp;C '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, CA, USA","","","","mental health; self-awareness; tangible interaction; mindfulness; shape-changing display; synchronization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GD3IFDIW","conferencePaper","2020","Vennekens, Joost","Service-Learning for Web Technology: Observations from a Small Case Study","Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education","978-1-4503-6874-2","","10.1145/3341525.3387414","https://doi.org/10.1145/3341525.3387414","In the past academic year, we conducted an experiment at using service-learning in order to integrate learning of empathy and creativity into an undergraduate course on Web Technology. This was a small scale pilot project, conducted in collaboration with the service-learning team at our institute. In the project, students collaborated with WAI-NOT, a non-profit organization that develops an online platform for children with various kinds of (physical/mental) disabilities. The students developed new ""games"" for this platform, to teach the children basic computer skills (e.g., clicking, moving the mouse). Key in this project was the interaction between the students, the non-profit and the target audience. Due to the small size of the class, we did not conduct a quantitative evaluation of the project, but we do discuss the experiences and feedback from teachers, students and community.","2020","2021-02-15 21:31:20","2021-02-15 21:31:20","","328–334","","","","","","","ITiCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","computer science education; service-learning; experience report","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3EBKFZYC","conferencePaper","2019","Suzianti, Amalia; Atthousi, Hajid Naufal","Implementation of Design Thinking Approach In Designing Learning Support Tools In The Classroom For Hearing Impaired Person: Case Study: Elementary School Students in SLB-B Santi Rama","Proceedings of the 2019 5th International Conference on E-Business and Mobile Commerce","978-1-4503-7182-7","","10.1145/3332324.3332338","https://doi.org/10.1145/3332324.3332338","The absence of adequate accommodation for the hearing-impaired in the Education field is one of the problems in Indonesia nowadays. Teaching aids or learning support tools as accommodation can help the deaf to accelerate and improve the quality of their education. This research uses design thinking approach in designing the tool so that the result of the design is in accordance with the needs and desires of the users, which are deaf elementary students age 8-10. Started from the empathy phase until the define phase which obtained that the target users have a need and desire to learn the vocabulary with ease and fun then proceed with the ideation phase with stakeholders and prototyping to generate ideas and create the teaching aids in accordance with their needs and desires in the form of an arcade game with card of words and ended with the testing phase which shows that the tool is able to improve visual receptive language comprehension of 8.07% and visual expressive language of 77.74% in a fun way. This research has produced a teaching aids designed with design thinking approach which can improve the quality of their learning in school in accordance with the needs and desires of hearing-impaired elementary school students and has been validated by stakeholders.","2019","2021-02-15 21:31:20","2021-02-15 21:31:20","","75–80","","","","","","","ICEMC 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Taichung, Taiwan","","","","Design Thinking; Deaf Children; Hearing-impaired; Inclusive Design; Learning Support Tools; Persona","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPUQSR5D","conferencePaper","2020","Shi, Weishi; Khan, Saad; El-Glaly, Yasmine; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.","Experiential Learning in Computing Accessibility Education","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings","978-1-4503-7122-3","","10.1145/3377812.3390901","https://doi.org/10.1145/3377812.3390901","Many developers don't understand how to, or recognize the need to develop accessible software. To address this, we have created five educational Accessibility Learning Labs (ALL) using an experiential learning structure. Each of these labs addresses a foundational concept in computing accessibility and both inform participants about foundational concepts in creating accessible software while also demonstrating the necessity of creating accessible software. The hosted labs provide a complete educational experience, containing materials such as lecture slides, activities, and quizzes.We evaluated the labs in ten sections of a CS2 course at our university, with 276 students participating. Our primary findings include: I) The labs are an effective way to inform participants about foundational topics in creating accessible software II) The labs demonstrate the potential benefits of our proposed experiential learning format in motivating participants about the importance of creating accessible software III) The labs demonstrate that empathy material increases learning retention. Created labs and project materials are publicly available on the project website: http://all.rit.edu","2020","2021-02-15 21:31:20","2021-02-15 21:31:20","","250–251","","","","","","","ICSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, South Korea","","","","accessibility education; computing accessibility; computing education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UIMBXLV","conferencePaper","2014","Gonzalez-Sanchez, Javier; Chavez-Echeagaray, Maria E.; Atkinson, Robert K.; Burleson, Winslow","Multimodal Detection of Affective States: A Roadmap through Diverse Technologies","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2567820","https://doi.org/10.1145/2559206.2567820","One important way for systems to adapt to their individual users is related to their ability to show empathy. Being empathetic implies that the computer is able to recognize a user's affective states and understand the implication of those states. Detection of affective states is a step forward to provide machines with the necessary intelligence to appropriately interact with humans. This course provides a description and demonstration of tools and methodologies for automatically detecting affective states with a multimodal approach.","2014","2021-02-15 21:31:20","2021-02-15 21:31:20","","1023–1024","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","affect-driven adaptation; affective states; emotion recognition; multimodal; sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQ72YESD","bookSection","2020","Tiwari, Divyanshu","Fostering Collaboration and Empathy Through Games","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419929","Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.","2020","2021-02-15 21:31:20","2021-02-15 21:31:20","","91–93","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3RN8VP7","bookSection","2020","Tiwari, Divyanshu","Fostering Collaboration and Empathy Through Games","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419929","Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.","2020","2021-02-15 21:31:57","2021-02-15 21:31:57","","91–93","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLPP4KC7","conferencePaper","2018","Lyckvi, Sus; Torgersson, Olof","Privacy and Design Ethics vs Designing for Curiosity, Communication and Children: Lessons Learned","Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services","978-1-4503-5898-9","","10.1145/3229434.3229480","https://doi.org/10.1145/3229434.3229480","This paper describes the lessons learned when designing an empathy-oriented image-exchange app for fifth-grade pupils. The aim was to evoke curiosity and empathy towards someone living elsewhere or under different socio-economic circumstances. In addition, we strived to apply design ethics (e.g. protecting users from insults, humiliation, inappropriate content etc) and take users' privacy into account. By setting up these boundaries for this user group we found ourselves confronted with a set of conflicting design decisions which ultimately led to a lesser and different user experience than we had expected. Here, we discuss the interplay between our design decisions and the consequences thereof, and evaluate the mistakes we made. Moreover we discuss how to balance anonymity and curiosity, and comment on the benefits of making a pre-analysis of potential clashes related to intended UX and other core design decisions.","2018","2021-02-15 21:31:57","2021-02-15 21:31:57","","","","","","","","","MobileHCI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","ethics; communication; empathy; curiosity; design for children; image sharing; privacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHNZALJN","conferencePaper","2020","Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon","Robots Teaching Recycling: Towards Improving Environmental Literacy of Children","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3379462","https://doi.org/10.1145/3371382.3379462","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.","2020","2021-02-15 21:31:57","2021-02-15 21:31:57","","615–616","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cambridge, United Kingdom","","","","educational robotics; children robot interaction; eco-literacy; environmental literacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9UAVYKRQ","conferencePaper","2015","Lundgren, Sus; Torgersson, Olof; Björk, Staffan","Thrimage: An Empathy-Oriented Discussion Tool for Classroom Use","Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct","978-1-4503-3653-6","","10.1145/2786567.2792901","https://doi.org/10.1145/2786567.2792901","Thrimage is a class-application where pupils choose and rank images in relation to a given word or notion. In seeing who else chose similarly, as well as in a debriefing teacher-led discussion, pupils gain insight in others' way of thinking, and learn to argument for their own opinion but also to respect others, both of which supports the development of empathy and mutual understanding. The design is part of a long-running design exploration on designing of collaborative, co-located experiences using mobile devices, in combination with an educational need.","2015","2021-02-15 21:31:57","2021-02-15 21:31:57","","628–635","","","","","","","MobileHCI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Copenhagen, Denmark","","","","empathy; image sharing; Thrimage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DETM34WT","conferencePaper","2015","Ostrowski, S\lawomir; Rolczyński, Rafa\l; Pniewska, Joanna; Garnik, Igor","User-Friendly E-Learning Platform: A Case Study of a Design Thinking Approach Use","Proceedings of the Mulitimedia, Interaction, Design and Innnovation","978-1-4503-3601-7","","10.1145/2814464.2814483","https://doi.org/10.1145/2814464.2814483","E-learning systems are very popular means to support the teaching process today. These systems are mainly used by universities as well as by commercial training centres. We analysed several popular e-learning platforms used in Polish universities and find them very unfriendly for the users. For this reason, the authors began the work on the creation of a new system that would be not only useful, but also usable for students, teachers and system administrators. This paper presents a case study of e-learning platform design process. We applied Design Thinking (DT) approach which puts a strong emphasis on the participation of end-users throughout the design process. Such an approach makes final product more user-friendly and better suited to end-users needs. An interdisciplinary team of designers implemented the design process in five stages: Empathizing - a thorough analysis of the problem and its context; Defining - synthesis of information obtained in the previous step and identifying user needs and insights; Ideating - generating solutions; Prototyping and Testing solutions proposed in the Ideating phase. During the design process the team used many additional methods, such as Empathy map, Stakeholders map, Value preposition canvas, personas, brainstorming, Card sorting and many more. As the result of design process we obtain an interactive prototype of designed e-learning platform. The prototype was tested by end-users and the feedback from the testers was collected. It confirmed that the use of the DT approach in design process allows to better fit designed product to the users' needs. The next step will be the implementation of tested and approved solutions to the real system what is planned in the nearest future.","2015","2021-02-15 21:31:57","2021-02-15 21:31:57","","","","","","","","","MIDI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Warsaw, Poland","","","","e-learning; Design Thinking; design process management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2HCGJAZU","conferencePaper","2019","Berzowska, Joanna; Mommersteeg, Alex; Rosero Grueso, Laura Isabel; Ducray, Eric; Rabo, Michael Patrick; Moisan, Geneviève","Baby Tango: Electronic Textile Toys for Full-Body Interaction","Proceedings of the Thirteenth International Conference on Tangible, Embedded, and Embodied Interaction","978-1-4503-6196-5","","10.1145/3294109.3300973","https://doi.org/10.1145/3294109.3300973","We describe two prototypes from the Baby Tango project: electronic textile toys that enable soft, tangible, full-body interaction. It presents interaction techniques that bridge the physical, the digital, and the social, as well as a case study in constructing interactive composite textiles. Given that the softness of the toy is a central design constraint, most of the circuit, including the sensors, is embroidered directly on the surface of the artifact using technical threads (with varying electro-mechanical properties) and a digital embroidery/laying machine. This submission includes design and technical details, as well as initial interaction design scenarios. The next steps of this project will explore how these toys could support the development of empathy in toddlers through embodied play. Further work is needed in order to develop background research, collaborations with early childhood researchers, as well as empirical studies. Future work will include the development of these studies; iterating aspects of interaction and play through participatory design; and improving technical design to focus on reliability, robustness, and durability.","2019","2021-02-15 21:31:57","2021-02-15 21:31:57","","437–442","","","","","","","TEI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tempe, Arizona, USA","","","","tangible interaction; electronic textiles; embroidered sensors; empathy.; interactive toys; soft user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2TP4CQ6","conferencePaper","2019","Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Södergren, Antonia Clasina","Children's Assessment of Co-Design Skills: Creativity, Empathy and Collaboration","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3325334","https://doi.org/10.1145/3311927.3325334","This paper presents a co-design project in a school with 16 children ages 10 to 11 in which three learning goals were defined upfront: creativity, empathy, and collaboration. The first part of the paper demonstrates how these co-design skills were implemented through an iterative process of explanation, practice, reflection, and application. Based on the results of post-interviews and short questionnaires, the second part discusses children's assessments of these skills. Whereas children reported fluctuations in applying these skills, the findings show an overall positive trend towards the end of the project. In future work, these findings will be triangulated with observational data.","2019","2021-02-15 21:31:58","2021-02-15 21:31:58","","520–526","","","","","","","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","Empathy; Children; 21st Century Skills; Co-design; Collaboration; Creativity; Design-based Learning; Participatory Design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NDRSVU2","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696479","https://doi.org/10.1145/2696454.2696479","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015","2021-02-15 21:31:58","2021-02-15 21:31:58","","83–90","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXRBIX28","bookSection","2017","Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama","A New Chatbot for Customer Service on Social Media","Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems","978-1-4503-4655-9","","","https://doi.org/10.1145/3025453.3025496","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.","2017","2021-02-15 21:31:58","2021-02-15 21:31:58","","3506–3510","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UTTZQASC","conferencePaper","2017","Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin","Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3139132","https://doi.org/10.1145/3139131.3139132","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.","2017","2021-02-15 21:31:58","2021-02-15 21:31:58","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","pet game; user types; virtual pet; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RUF4ALKA","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","The CoWriter Project: Teaching a Robot How to Write","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702091","https://doi.org/10.1145/2701973.2702091","This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.","2015","2021-02-15 21:31:58","2021-02-15 21:31:58","","269","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9QPEJM3","conferencePaper","2020","Yu, Borou; Zhou, Tiange; Wang, Zeyu; Min, Jiajian","The World of Freedom","SIGGRAPH Asia 2020 Art Gallery","978-1-4503-8108-6","","10.1145/3414686.3427172","https://doi.org/10.1145/3414686.3427172","Indeed, people spend more time on deep thinking since 2020. The questions which ask mainly by the sociologists, now become the topics on the dining table. The debates on social and moral dilemmas are happening intensively 24 hours on the internet. We started to think more about who we are, where we are going, and how we will value the information we have received. Do we have freedom? Shall we believe absolute freedom? Sometimes people directly transform the idea of liberty into democracy. However, shall we also equal freedom to democracy? Since we are all inside this one pandemic bubble, after most people stay at home for a couple of months, we start emerging a global-size collective memory, which makes people more empathetically understand others' situations. Meanwhile, more and more people have to learn and take experience virtually. The attention of empathy and the new work-from-home mode evokes the initial idea of this virtual reality experience. We start to ask how people could learn and think more effectively in this brand new virtual age? Unity program makes this innovation possible. The innovative architecture modeling could permit a large group of people to experience personal space and sharing areas simultaneously. The sound design is specially designed for the various space sound and the audience's interactivities. We use this program to build up an immersive and empathetic space that embodies a hypothetical argument of a social dilemma into a virtual manifestation. People might be able to figure out the most meaningful answer by wearing the same shoes. The social distance could also be virtually controlled in this program by counting if the number of participates overload spaces.","2020","2021-02-15 21:31:58","2021-02-15 21:31:58","","","","","","","","","SA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Republic of Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MH868NN3","conferencePaper","2015","Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung","Design of Emotional Conversations with a Child for a Role Playing Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702009","https://doi.org/10.1145/2701973.2702009","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.","2015","2021-02-15 21:31:58","2021-02-15 21:31:58","","73–74","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","emotional role playing robot; human intervention device; human-robot-interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P9JPI7W","conferencePaper","2019","Kawano, Atsuko; Motoyama, Yuji; Aoyama, Mikio","A LX (Learner EXperience)-Based Evaluation Method of the Education and Training Programs for Professional Software Engineers","Proceedings of the 2019 7th International Conference on Information and Education Technology","978-1-4503-6639-7","","10.1145/3323771.3323789","https://doi.org/10.1145/3323771.3323789","We propose a new design methodology to maximize the training effect in a corporate education and training for professional software engineers. Conventionally, the education and training programs have been designed in a top-down manner based on the long-term strategy on the business and engineering resources development. However, to draw out the learners' high performance from the education and training programs, we need to have an empathy with the learners, and to analyze their expectations and emotions in order to motivate them. Therefore, this paper proposes the learner-centered design methodology of the corporate education and training programs inspired by the design thinking and lean start-up concepts. We define the learning processes in the education and training programs as LX (Learner eXperience), and propose LJM (Learning Journey Map) as the LX evaluation method as an extension of CJM (Customer Journey Map) in UX (User eXperience) design. The LJM enables to evaluate training effect and communicate with stakeholders in the training design expressing the LX quantitatively in a visual form. We applied the proposed design methodology to the education and training programs for professional software engineers in a company to evaluate LX and elicit learner requirements to the programs. We applied the proposed LJM to the education and training program of two levels of the whole program and its LUs (Learning Units), and identified problems in the LX. From the empirical study, we confirm the effectiveness of the proposed methodology.","2019","2021-02-15 21:31:58","2021-02-15 21:31:58","","151–159","","","","","","","ICIET 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aizu-Wakamatsu, Japan","","","","Design thinking; Corporate education and training program; Journey map; Lean start-up; LX (Learner eXperience); Professional software engineer; UX (User eXperience)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7QFS78U","conferencePaper","2016","Fan, Mingyue; Yu, Liyue; Bowler, Leanne","Feelbook: A Social Media App for Teens Designed to Foster Positive Online Behavior and Prevent Cyberbullying","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2892398","https://doi.org/10.1145/2851581.2892398","This project presents a prototype for a stand-alone social media application designed for teenage users in order to prevent and mitigate mean and cruel online behavior. The purpose of the app is to create a nurturing environment where teenagers use a variety of features designed to help raise self-awareness of their own online behavior, seek support when needed, and learn to control and, when possible, correct aggressive behavior. The prototype is framed by four design principles: design for reflection, design for empathy, design for empowerment, and design for the whole. We conclude by outlining the next steps in our project to develop an application that helps to improve the online experiences of young people. This work has implications for the CHI community because it applies software solutions to tackle a critical social problem that can affect the health and well being of young people.","2016","2021-02-15 21:31:58","2021-02-15 21:31:58","","1187–1192","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","social media; empathy; cyberbullying; reflection; social computing; teens; young adults","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IT7ZBLM","bookSection","2017","Schaper, Marie-Monique; Santos, Maria; Malinverni, Laura; Pares, Narcis","Towards the Design of a Virtual Heritage Experience Based on the World-as-Support Interaction Paradigm","Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4656-6","","","https://doi.org/10.1145/3027063.3053089","We present the initial design stage of a Virtual Heritage experience for a bomb shelter built during the Spanish Civil War, namely Refugi 307. The shelter currently belongs to the History Museum of Barcelona which provides guided tours through the cultural heritage site for schools and the general public. The aim of the study was to define the requirements for the design of a first prototype based on the World-as-Support interaction paradigm. We conducted an ethnographic study and Participatory Design workshop to analyze different aspects of the requirements and to include multiple needs and viewpoints of the involved stakeholders. Based on the outcomes, we outline the potential for activities to foster (1) contextual-awareness between the learning content and the cultural heritage site, (2) environment-awareness in relation to missing objects in the physical space and (3) social-awareness to embody feelings related to solidarity and empathy.","2017","2021-02-15 21:31:58","2021-02-15 21:31:58","","2034–2041","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FBLPKSQ","journalArticle","2018","Di Lascio, Elena; Gashi, Shkurta; Santini, Silvia","Unobtrusive Assessment of Students' Emotional Engagement during Lectures Using Electrodermal Activity Sensors","Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.","","","10.1145/3264913","https://doi.org/10.1145/3264913","Modern wearable devices enable the continuous and unobtrusive monitoring of human physiological parameters, including heart rate and electrodermal activity. Through the definition of adequate models these parameters allow to infer the wellbeing, empathy, or engagement of humans in different contexts. In this paper, we show that off-the-shelf wearable devices can be used to unobtrusively monitor the emotional engagement of students during lectures. We propose the use of several novel features to capture students' momentary engagement and use existing methods to characterize the general arousal of students and their physiological synchrony with the teacher. To evaluate our method we collect a data set that – after data cleaning – contains data from 24 students, 9 teachers, and 41 lectures. Our results show that non-engaged students can be identified with high reliability. Using a Support Vector Machine, for instance, we achieve a recall of 81% – which is a 25 percentage points improvement with respect to a Biased Random classifier. Overall, our findings may inform the design of systems that allow students to self-monitor their engagement and act upon the obtained feedback. Teachers could profit of information about non-engaged students too to perform self-reflection and to devise and evaluate methods to (re-)engage students.","2018-09","2021-02-15 21:31:58","2021-02-15 21:31:58","","","","3","2","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Engagement; Activity; Electrodermal; Students; Wearable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NAJBM6Y","journalArticle","2020","Lin, Xin Yao; Saksono, Herman; Stowell, Elizabeth; Lachman, Margie E.; Castaneda-Sceppa, Carmen; Parker, Andrea G.","Go&amp;Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3415222","https://doi.org/10.1145/3415222","Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&amp;Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&amp;Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&amp;Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.","2020-10","2021-02-15 21:31:58","2021-02-15 21:31:58","","","","CSCW2","4","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","caregiver; exergame; intervention; people with dementia; physical activity; social connectedness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WBWYH2L9","journalArticle","2020","Hwang, Amy S.; Jackson, Piper; Sixsmith, Andrew; Nygård, Louise; Astell, Arlene; Truong, Khai N.; Mihailidis, Alex","Exploring How Persons with Dementia and Care Partners Collaboratively Appropriate Information and Communication Technologies","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/3389377","https://doi.org/10.1145/3389377","Persons with dementia and their care partners have been found to adapt their own technological arrangements using commercially available information and communication technologies (ICTs). Yet, little is known about these processes of technology appropriation and how care practices are impacted. Adopting a relational perspective of care, we longitudinally examined how four family care networks appropriated a new commercial ICT service into their existing technological arrangements and care practices. Cross-case analysis interpreted collaborative appropriation to encompass two interrelated processes of creating and adapting technological practices and negotiating and augmenting care relationships. Four driving forces were also proposed: motivating meanings that actors ascribe to the technology and its use; the learnability of the technology and actors’ resourcefulness; the establishment of responsive and cooperative care practices; and the qualities of empathy and shared power in care relationships. The importance of technological literacy, learning, meaning-making, and the nature and quality of care relationships are discussed. Future work is urged to employ longitudinal and naturalistic approaches, and focus design efforts on promoting synergistic care relationships and care practices.","2020-11","2021-02-15 21:31:58","2021-02-15 21:31:58","","","","6","27","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","dementia; Alzheimer's disease; appropriation; care practices; care relationship; caregiving; case study; cognitive impairment; commercial product; family care; information and communication technologies; off-the-shelf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S5X89FXP","bookSection","2020","Qiu, Lisong; Shiu, Yingwai; Lin, Pingping; Song, Ruihua; Liu, Yue; Zhao, Dongyan; Yan, Rui","What If Bots Feel Moods?","Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-8016-4","","","https://doi.org/10.1145/3397271.3401108","For social bots, smooth emotional transitions are essential for delivering a genuine conversation experience to users. Yet, the task is challenging because emotion is too implicit and complicated to understand. Among previous studies in the domain of retrieval-based conversational model, they only consider the factors of semantic and functional dependencies of utterances. In this paper, to implement a more empathetic retrieval-based conversation system, we incorporate emotional factors into context-response matching from two aspects: 1) On top of semantic matching, we propose an emotion-aware transition network to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework; 2) We design several flexible controlling mechanisms to customize social bots in terms of emotion. Extensive experiments on two benchmark datasets indicate that the proposed model can effectively track the flow of emotions throughout a human-machine conversation and significantly improve response selection in dialogues over the state-of-the-art baselines. We also empirically validate the emotion-control effects of our proposed model on three different emotional aspects. Finally, we apply such functionalities to a real IoT application.","2020","2021-02-15 21:31:58","2021-02-15 21:31:58","","1161–1170","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDS4LM4S","bookSection","2020","van den Berg, Carolien; Verster, Belinda","Co-Creating Social, Digital Innovation to Recognise Agency in Communities: A Learning Intervention: Research in Progress","Conference of the South African Institute of Computer Scientists and Information Technologists 2020","978-1-4503-8847-4","","","https://doi.org/10.1145/3410886.3410912","This paper presents findings from a pilot project, of an ongoing Design-Based Research (DBR) initiative, where students in an Information Systems (IS) module proposed social, digital innovations for complex problems within marginalised communities in Cape Town, South Africa. The aim of the pilot project was to develop digital innovations that recognise agency in communities through lived experiences and local knowledge. An urban planning perspective was introduced to contextualise socio-environmental challenges to ground social innovations in reality and encourage a sustainable uptake of digital innovations by communities. The IS student projects emphasised empathy, storytelling and prototyping as part of a design thinking process which both incorporated and influenced the conceptual model presented in this paper. This conceptual model informed by four design principles of - relationality, reflexivity, responsiveness and recognition - is offered as an enrichment for a learning environment. It foregrounds the development of competencies for collaborative problem solving and ultimately transdisciplinary knowledge creation.","2020","2021-02-15 21:31:58","2021-02-15 21:31:58","","85–93","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HB4JJ3PR","conferencePaper","2017","Köppe, Christian; Nørgård, Rikke Toft; Pedersen, Alex Young","Towards a Pattern Language for Hybrid Education","Proceedings of the VikingPLoP 2017 Conference on Pattern Languages of Program","978-1-4503-6342-6","","10.1145/3158491.3158504","https://doi.org/10.1145/3158491.3158504","In this paper we offer an initial framework for a pattern language of hybrid education. With the term hybrid education, we imply the use of educational design patterns that actively strive to cut across, circumventing or upheave traditional dichotomies within education such as physical-digital, academic-nonacademic, online-offline, formal-informal, learning-teaching and individual-collective. In doing so, hybrid education invites uncertainty, open-endedness, risk-taking, experimentation, critical creativity, disruption, dialogue and democracy (back) into the heart of education. Accordingly we see, within hybrid education, the promise to push against and circumvent current trends of marketization, managerialism and standardization in higher education today. Here, a pattern language for hybrid education presents an alternative way of designing for future higher education in ways that are not focused on teaching to the test, playing it safe, rankings or gaming the system approaches. Rather, hybrid education focuses on open-endedness, risk-taking, relational entanglements, experimentation, exploration and empathy. In this way, designing for hybrid education is in this paper achieved, partly by taking a decidedly value-based and vision-driven approach to learning design patterns based on philosophy in higher education and critical pedagogy, partly by working together in hybrid ways and across disciplines and domains in order to open up both the field of teaching and learning in higher education as well as the field of learning design and design patterns. The result is the almost 80 design patterns for hybrid education. The paper presents the pattern categories for hybrid education, the different design patterns contained in these. Furthermore, the pattern mining ground and workshop process, the outcome of the value workshop and the vision workshop as well as three example scenarios is described in order to show both the underlying value and vision foundation for the pattern language as well as how it plays out in concrete scenarios.","2017","2021-02-15 21:31:59","2021-02-15 21:31:59","","","","","","","","","VikingPLoP '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Grube, Schleswig-Holstein, Germany","","","","education; educational patterns; hybrid pedagogy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJVED9WC","conferencePaper","2014","Potter, Leigh Ellen; Korte, Jessica; Nielsen, Sue","Design with the Deaf: Do Deaf Children Need Their Own Approach When Designing Technology?","Proceedings of the 2014 Conference on Interaction Design and Children","978-1-4503-2272-0","","10.1145/2593968.2610464","https://doi.org/10.1145/2593968.2610464","In this paper, we focus on the question of design of technology for Deaf children, and whether the needs of these children are different from their hearing counterparts in a technology design setting. We present findings from literature together with our own observations to determine if there are distinguishing characteristics for Deaf children that may influence design sessions with them. We found that Deaf children generally have reduced literacy and slower academic progress, reduced social and emotional development, reduced empathy and a level of nervousness in novel situations, delayed language development, and limited or delayed spoken language. We also found that Deaf children are active and innovative in approaching communication, have sensitive visual attention in their peripheral vision, enhanced attention to small visual changes, and a capacity for visual learning. Finally, cultural issues within the Deaf community mean that Deaf children should be free to interact on their own terms in a design situation. We suggest that these differences merit the development of a design approach specific to the needs of Deaf children.","2014","2021-02-15 21:31:59","2021-02-15 21:31:59","","249–252","","","","","","","IDC '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aarhus, Denmark","","","","prototyping; child computer interaction; deaf children","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNG7SDK3","conferencePaper","2020","Narayanan, Shrikanth Shri","Human-Centered Multimodal Machine Intelligence","Proceedings of the 2020 International Conference on Multimodal Interaction","978-1-4503-7581-8","","10.1145/3382507.3417974","https://doi.org/10.1145/3382507.3417974","Multimodal machine intelligence offers enormous possibilities for helping understand the human condition and in creating technologies to support and enhance human experiences [1, 2]. What makes such approaches and systems exciting is the promise they hold for adaptation and personalization in the presence of the rich and vast inherent heterogeneity, variety and diversity within and across people. Multimodal engineering approaches can help analyze human trait (e.g., age), state (e.g., emotion), and behavior dynamics (e.g., interaction synchrony) objectively, and at scale. Machine intelligence could also help detect and analyze deviation in patterns from what is deemed typical. These techniques in turn can assist, facilitate or enhance decision making by humans, and by autonomous systems. Realizing such a promise requires addressing two major lines of, oft intertwined, challenges: creating inclusive technologies that work for everyone while enabling tools that can illuminate the source of variability or difference of interest. This talk will highlight some of these possibilities and opportunities through examples drawn from two specific domains. The first relates to advancing health informatics in behavioral and mental health [3, 4]. With over 10% of the world's population affected, and with clinical research and practice heavily dependent on (relatively scarce) human expertise in diagnosing, managing and treating the condition, engineering opportunities in offering access and tools to support care at scale are immense. For example, in determining whether a child is on the Autism spectrum, a clinician would engage and observe a child in a series of interactive activities, targeting relevant cognitive, communicative and socio- emotional aspects, and codify specific patterns of interest e.g., typicality of vocal intonation, facial expressions, joint attention behavior. Machine intelligence driven processing of speech, language, visual and physiological data, and combining them with other forms of clinical data, enable novel and objective ways of supporting and scaling up these diagnostics. Likewise, multimodal systems can automate the analysis of a psychotherapy session, including computing treatment quality-assurance measures e.g., rating a therapist's expressed empathy. These technology possibilities can go beyond the traditional realm of clinics, directly to patients in their natural settings. For example, remote multimodal sensing of biobehavioral cues can enable new ways for screening and tracking behaviors (e.g., stress in workplace) and progress to treatment (e.g., for depression), and offer just in time support.The second example is drawn from the world of media. Media are created by humans and for humans to tell stories. They cover an amazing range of domains'from the arts and entertainment to news, education and commerce and in staggering volume. Machine intelligence tools can help analyze media and measure their impact on individuals and society. This includes offering objective insights into diversity and inclusion in media representations through robustly characterizing media portrayals from an intersectional perspective along relevant dimensions of inclusion: gender, race, gender, age, ability and other attributes, and in creating tools to support change [5,6]. Again this underscores the twin technology requirements: to perform equally well in characterizing individuals regardless of the dimensions of the variability, and use those inclusive technologies to shine light on and create tools to support diversity and inclusion.","2020","2021-02-15 21:31:59","2021-02-15 21:31:59","","4–5","","","","","","","ICMI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Netherlands","","","","emotion; behavior; computational psychology; diversity and inclusion; human signals; language; media intelligence; mental health; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLEDK7U3","conferencePaper","2019","Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica","Good Robot Design or Machiavellian? An in-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019","2021-02-15 21:31:59","2021-02-15 21:31:59","","382–391","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","culture; social robots; in the wild; persuasive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2GRM27H","conferencePaper","2015","Sobel, Kiley; O'Leary, Katie; Kientz, Julie A.","Maximizing Children's Opportunities with Inclusive Play: Considerations for Interactive Technology Design","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771844","https://doi.org/10.1145/2771839.2771844","Inclusive play, defined as play among children with and without disabilities, provides learning opportunities that challenge stereotypes, foster strong friendships, and help children develop empathy and other social and emotional skills. Designing technologies to support inclusive play are understudied in Human-Computer Interaction. We synthesized literature, conducted design ethnography in an inclusive classroom, and interviewed and surveyed parents and teachers to explore this problem. Our research contributes an empirical understanding of the current state of inclusive play and a characterization of the design space for interactive technologies that can support children and adults with inclusive play. We identify key facilitators of inclusive play: direct and embedded supports, transparency, adjustability, emphasis on children's interests and strengths, and current technology use. We also describe significant barriers to inclusive play: effort required to facilitate inclusive play, children's preferences, parental inexperience, and inappropriate technology. Through our discussion, we conclude that interactive technologies should be designed to harness the facilitators and help overcome the barriers in order to maximize children's opportunities with inclusive play.","2015","2021-02-15 21:31:59","2021-02-15 21:31:59","","39–48","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","children; human-centered design; assistive technology; inclusion; inclusive design; inclusive play; universal design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIJN5U68","conferencePaper","2013","Slegers, Karin; Wilkinson, Andrea; Hendriks, Niels","Active Collaboration in Healthcare Design: Participatory Design to Develop a Dementia Care App","CHI '13 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-1952-2","","10.1145/2468356.2468440","https://doi.org/10.1145/2468356.2468440","This paper describes a research project aimed at developing a mealtime data registration tool for people with dementia. As to actively involve all stakeholders in this healthcare design project and to generate empathy and involvement, methods from participatory design were used. For each of the three research phases (ethnography, ideation &amp; conceptualization and prototyping) we describe our approach towards stakeholder involvement and active collaboration. We discuss lessons learned in terms of good practices and the issues we struggle with.","2013","2021-02-15 21:31:59","2021-02-15 21:31:59","","475–480","","","","","","","CHI EA '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Paris, France","","","","dementia; participatory design; prototyping; healthcare","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9T4H9HCY","conferencePaper","2020","Olson, Danielle Marie; Harrell, D. Fox, Ph.D.","“I Don't See Color”: Characterizing Players’ Racial Attitudes and Experiences via an Anti-Bias Simulation Videogame","International Conference on the Foundations of Digital Games","978-1-4503-8807-8","","10.1145/3402942.3409783","https://doi.org/10.1145/3402942.3409783","Videogames and learning/training applications that address racial discrimination have risen in popularity recently, coinciding with the rapid development of the field of serious (or impact) games [1, 2]. While there has been much focus on understanding the efficacy of these systems as interventions to reduce racial bias, there has been less attention paid to how individuals’ prior physical-world racial attitudes influence their experiences of such games about racial issues. Toward addressing this gap, the study presented here examines the relationships between PreK-12 educators’ colorblind racial attitudes and their game experience and narrative interpretations in narrative videogame modeling racial and ethnic socialization called Passage Home. Passage Home embeds a novel computational model and simulation informed by the Racial Encounter Coping Appraisal and Socialization Theory (RECAST) [3] to simulate a discriminatory racial encounter in a classroom setting. The system serves as a tool for assessing players’ racial and ethnic socialization (RES) experiences to support interventions for learning about racial bias. This paper presents the results of a user study deploying Passage Home with PreK-12 educators. Analysis revealed that players’ colorblind racial attitudes and ethnic identity were related to their in-game racial appraisal and feelings of competence, negative affect, and empathy in the game. Given the prevalence of colorblind racial ideology across racial and ethnic groups in the United States [4, 5], we propose an initial typology of players’ colorblind racial attitudes emerging from this analysis to aid in the future development of serious game interventions addressing racial discrimination.","2020","2021-02-15 21:31:59","2021-02-15 21:31:59","","","","","","","","","FDG '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bugibba, Malta","","","","human-computer interaction; Avatars; serious games; social identity; reflection; educational game; game design; identity; impact games; interactive narrative; racial discrimination; serious play; transformative education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RUCF9G4","conferencePaper","2017","Vieira, Suanny; Santos, Alexandre; Costa, Rostand; Maritan, Tiago; Aschoff, Manuella; Veríssimo, Vinícius","A Study on the Use of Multiple Avatars in 3D Sign Language Dictionaries","Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web","978-1-4503-5096-9","","10.1145/3126858.3126865","https://doi.org/10.1145/3126858.3126865","Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors.","2017","2021-02-15 21:31:59","2021-02-15 21:31:59","","325–332","","","","","","","WebMedia '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gramado, RS, Brazil","","","","accessibility; avatar; machine translation; retargeting; sign language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAISANGT","conferencePaper","2019","Munteanu, Cosmin; Oviatt, Sharon","CHI 2019 Early Career Development Symposium","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3298999","https://doi.org/10.1145/3290607.3298999","The first few years after completing a PhD can be challenging to navigate. Job hunting, interviewing, navigating new contexts such as a junior academic position, applying for funding as a first time project investigator, learning to adapt to the culture of an industry-based workplace, supervising graduate students or full-time employees - these are just a few of the scenarios recent PhD graduates find themselves in. Within HCI, one may encounter more discipline-specific challenges, such as keeping up with the CHI publication cycles while taking on new administrative duties. The CHI community, however, strives to be collectively supportive and inclusive of researchers at all stages of their career - this is even more important as many of our design approaches are rooted in empathy for and empowerment of participants. By more actively supporting each other as researchers in our career paths, we can better grow as a community, and reflect it back into our collective body of practice. The Early Career Development Symposium has been proposed (and held yearly since 2016) to provide a more formal mentoring venue that reflects our aims as a community to more meaningfully support each other.","2019","2021-02-15 21:31:59","2021-02-15 21:31:59","","1–5","","","","","","","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","mentoring; early career; post phd","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZPXICI2","conferencePaper","2020","Groeneveld, Wouter; Jacobs, Hans; Vennekens, Joost; Aerts, Kris","Non-Cognitive Abilities of Exceptional Software Engineers: A Delphi Study","Proceedings of the 51st ACM Technical Symposium on Computer Science Education","978-1-4503-6793-6","","10.1145/3328778.3366811","https://doi.org/10.1145/3328778.3366811","Important building blocks of software engineering concepts are without a doubt technical. During the last decade, research and practical interest for non-technicalities has grown, revealing the building blocks to be various skills and abilities beside pure technical knowledge. Multiple attempts to categorise these blocks have been made, but so far little international studies have been performed that identify skills by asking experts from both the industrial and academic world: which abilities are needed for a developer to excel in the software engineering industry? To answer this question, we performed a Delphi study, inviting 36 experts from 11 different countries world-wide, affiliated with 21 internationally renowned institutions. This study presents the 55 identified and ranked skills as classified in four major areas: communicative skills (empathy, actively listening, etc.), collaborative skills (sharing responsibility, learning from each other, etc.), problem solving skills (verifying assumptions, solution-oriented thinking, etc.), and personal skills (curiosity, being open to ideas, etc.), of which a comparison has been made between opinions of technical experts, business experts, and academics. We hope this work inspires educators and practitioners to adjust their training programs, mitigating the gap between the industry and the academic world.","2020","2021-02-15 21:31:59","2021-02-15 21:31:59","","1096–1102","","","","","","","SIGCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, OR, USA","","","","delphi study; industry requirements; non-cognitive abilities; professional skills; software developer; software engineering edutation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Z7VQTLX","conferencePaper","2014","Matsuzawa, Tetsuro","Evolution of Human Mind and Culture Viewed from the Study of Chimpanzees","Proceedings of the 5th ACM International Conference on Collaboration across Boundaries: Culture, Distance &amp; Technology","978-1-4503-2557-8","","10.1145/2631488.2637432","https://doi.org/10.1145/2631488.2637432","I have studied chimpanzees both in the wild and in the laboratory. My talk illustrates the evolutionary origins of human mind and culture. The human mother–infant relationship is characterized by physical separation, and the stable supine posture of infants; enabling face-to-face communication via facial expressions, vocal exchange, and manual gestures, and also demonstration of object manipulation. I have used the novel ""participant observation"" method in the laboratory and through ""field experiments"" in their natural habitat. There are several critical differences between the two species: chimpanzees lack the social referencing ability observed in human children and chimpanzees seldom engage in active teaching. Moreover, although young chimpanzees showed unique working memory capacity, often superior to that of human adults, they are less able to learning symbols. In sum, mind and culture in humans is fundamentally influenced by the manner of raising young children; characterized by collaboration among multiple adults. This aspect of human rearing may be linked to the development of empathy, altruistic behavior, reciprocity, understanding others? minds, and so on. Taken together, my talk presents evolutionary and ontogenetic explanations for the uniquely human cognition and culture.","2014","2021-02-15 21:31:59","2021-02-15 21:31:59","","141","","","","","","","CABS '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","evolution; culture; chimpanzees and human comparison","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92SU6BNQ","conferencePaper","2018","McDonald, Heidi","IThirve Games Empathy Jam at DigiPen","Proceedings of the International Conference on Game Jams, Hackathons, and Game Creation Events","978-1-4503-6484-3","","10.1145/3196697.3196704","https://doi.org/10.1145/3196697.3196704","This Event Report concerns the Empathy Jam iThrive Games held in cooperation with DigiPen Institute of Technology in Seattle, WA, on September 15-17, 2017. iThrive Games is a nonprofit that exists to create meaningful opportunities for teens to enhance the knowledge, mindsets, and skills they need to thrive across development, to engage actively in their learning and in their community, and to be healthy. We embrace the positive potential of games, and find a strengths-based approach to be especially important to this work. Game Jams are an important way that iThrive can educate and perform developer outreach in accordance with our mission. We do game jams at universities and regional game festivals, with the goal of bringing together people to build games together using our science based, expert-developed design resources (available for free download at the iThrive Games website: www.ithrivegames.org) to help developers make games toward prosocial outcomes. Our jams not only demonstrate what kinds of games can result from these design concepts, but are also important events to foster ongoing collaboration and to facilitate mentoring relationships at multiple levels. These jams also allow us to test and refine our design resources with the help of the people they are intended for.","2018","2021-02-15 21:31:59","2021-02-15 21:31:59","","28–33","","","","","","","ICGJ 2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Francisco, CA, USA","","","","serious games; empathy games; games for teens; iThrive Games; jams for teens; kindness games; prosocial outcomes; social emotional learning; teen development; transformational frameworks; transformational games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQQK8XLV","journalArticle","2019","Not, Elena; Cavada, Dario; Maule, Stefano; Pisetti, Anna; Venturini, Adriano","Digital Augmentation of Historical Objects Through Tangible Interaction","J. Comput. Cult. Herit.","","1556-4673","10.1145/3297764","https://doi.org/10.1145/3297764","The technological advances brought about by the Internet of Things enable new opportunities for a more direct interaction among users, objects, and places. This is an extremely valuable innovation for the cultural heritage sector, as it allows a more transparent use of technology in the digital augmentation of museums and cultural heritage sites. The possibility to augment physical objects with sensors detecting when they are moved and manipulated enables scenarios where descriptive information about objects is presented to users at the very exact time they are looking at them, stimulating engagement. This article describes a collaborative research effort among cultural heritage professionals, human–computer interaction experts, and developers that was aimed at investigating the goals and constraints curators consider for a physical encounter between visitors and historic relics. In a case study, we co-designed an interactive plinth centred on tangible interaction and evaluated the impact on the user experience of combining digital information with a hands-on experience of relics of World War I. Our findings show that visitors value this type of tangible interaction with collection objects positively, as it allows the discovery of details and the learning of aspects that normally go unnoticed. The synergy between physical and digital aspects stimulates empathy with the original users of the object and fosters social interaction.","2019-06","2021-02-15 21:31:59","2021-02-15 21:31:59","","","","3","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","internet of things; Digitally augmented objects; museum experience; tangible and embodied interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4MZTRTA","bookSection","2020","Ranjbartabar, Hedieh; Richards, Deborah; Bilgin, Ayse Aysin; Kutay, Cat; Mascarenhas, Samuel","User-Models to Drive an Adaptive Virtual Advisor: Demonstration","Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-7518-4","","","","Agents that adapt to their user need to have knowledge of their user and expertise on how best to adapt to that type of user. In this paper we describe the addition of an agent's expertise and collection of machine-learnt user profiles to the proposed extended FAtiMA (Fearnot AffecTive Mind Architecture) cognitive agent architecture. A study to evaluate the extended architecture is presented which compares the benefit (i.e. reduced stress and increased rapport) of tailoring dialogue (i.e. empathic or neutral) to the specific user.","2020","2021-02-15 21:31:59","2021-02-15 21:31:59","","2117–2119","","","","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWYH7UM2","conferencePaper","2017","Chapman, Gail","Inspire, Innovate, Improve! What Does This Mean for CS for All?","Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education","978-1-4503-4698-6","","10.1145/3017680.3025047","https://doi.org/10.1145/3017680.3025047","In January 2016, President Obama unveiled the CS for All initiative. With all the attention and publicity surrounding CS for All and increased support from a variety of corners over the ensuing year, it is easy to become complacent and start believing that we have ""arrived"". During her 2016 SIGCSE keynote, Jan Cuny talked about catching the wave and using it to our advantage. This talk will focus on where we go from here. We caught the wave; now what do we do to ensure that we don't get swallowed by it? What lessons can be learned from an election that featured the likes of fake news, Wiki leaks, rogue email servers, runaway tweets and showed in stark relief the divides that exist in our country. Computer science represents one of those divides. Given this and the fact that addressing the educational inequities prevalent in computer science was front and center in the CS for All announcement, what better time is there to renew our commitment to broadening participation in computing? As educators we have a powerful opportunity and responsibility in the wake of the blowback from the election-to educate, to listen, to remind ourselves constantly that we live in a very diverse country. We have no shortage of innovation in computer science, but who are we inspiring, what impact are those innovations having, and what can we do to learn from the lessons of the past to improve CS education? And above all, how do we respond to the challenges before us with empathy for those who are impacted by the decisions we make?","2017","2021-02-15 21:31:59","2021-02-15 21:31:59","","1","","","","","","","SIGCSE '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9ZXU3U2","journalArticle","2013","Andre, Elisabeth","Exploiting Unconscious User Signals in Multimodal Human-Computer Interaction","ACM Trans. Multimedia Comput. Commun. Appl.","","1551-6857","10.1145/2502433","https://doi.org/10.1145/2502433","This article presents the idea of empathic stimulation that relies on the power and potential of unconsciously conveyed attentive and emotional information to facilitate human-machine interaction. Starting from a historical review of related work presented at past ACM Multimedia conferences, we discuss challenges that arise when exploiting unconscious human signals for empathic stimulation, such as the real-time analysis of psychological user states and the smooth adaptation of the human-machine interface based on this analysis. A classical application field that might benefit from the idea of unconscious human-computer interaction is the exploration of massive datasets.","2013-10","2021-02-15 21:32:00","2021-02-15 21:32:00","","","","1s","9","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","Emotion recognition; multimodal interfaces; social signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8MWVSUHK","conferencePaper","2019","Vertesi, Janet","Seeing like a Rover: Team Work and Human-Robot Relations","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go — in search and rescue operations, ocean voyages, or even into space — they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology.This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team.Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019","2021-02-15 21:32:00","2021-02-15 21:32:00","","152","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","human-robot interaction; teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LR8TMACP","conferencePaper","2013","Ramírez, Ricardo; Parthasarathy, Balaji; Gordon, Andrew","From Infomediaries to Infomediation at Public Access Venues: Lessons from a 3-Country Study","Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1","978-1-4503-1906-5","","10.1145/2516604.2516621","https://doi.org/10.1145/2516604.2516621","This study investigated the role of infomediaries to understand the process of infomediation in shaping outcomes for users at public access venues (PAVs) in Bangladesh, Chile and Lithuania. We examined the extent to which technical skills and empathy are relevant to and appreciated by different types of users, and whether differences in infomediaries are evident across different types of PAVs. We asked whether particular infomediary behaviours were associated with outcome differences as reported by PAV users. We learned that infomediaries provide the human face for the information age by taking on the functions of facilitation, coaching, referral and teaching, and by assuming the role of a trusted gatekeeper. The process of infomediation turned out to be of prominence, within which the infomediary is a key component. In the absence of infomediaries, those left behind (or excluded due to their age, socio-economic status, level of education/literacy, gender, disability or caste) will face additional, perhaps insurmountable, barriers.","2013","2021-02-15 21:32:00","2021-02-15 21:32:00","","124–132","","","","","","","ICTD '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cape Town, South Africa","","","","empathy; information and communication technologies; brokering; ICTD; infomediary; infomediation; public access","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AR7BEN8","conferencePaper","2020","Branco, Karina da S. C.; Oliveira, Rhenara A.; Silva, Francisco L. Q. da; de H. Rabelo, Jacilane; Marques, Anna B. S.","Does This Persona Represent Me? Investigating an Approach for Automatic Generation of Personas Based on Questionnaires and Clustering","Proceedings of the 19th Brazilian Symposium on Human Factors in Computing Systems","978-1-4503-8172-7","","10.1145/3424953.3426648","https://doi.org/10.1145/3424953.3426648","Personas are fictional representations of an end user based on data collected from a specific target audience. The creation of personas takes time, because part of the process is manual, which causes difficulties during the stages of data generation and analysis, if the data sample is large. The present work aims to investigate the results of the automatic generation of personas through a questionnaire and the Clustering method. Initially, a questionnaire was applied in order to outline the profile of students in the Computer Science and Software Engineering courses at the university Federal of Ceará. 130 responses were obtained from this applied questionnaire. The automatic generation of personas used the collected responses as a database, these data were applied to the Clustering method. From Clustering, using a specific tool for this purpose, it was possible to generate four personas automatically. In relation to the data generated from the personas, it was possible to identify some characteristics, such as: (a) course choice factor: the opportunity to work with new technologies, influence of family and friends and the possibility of living abroad; (b) factor of withdrawal from the course: lack of identification with the course, learning difficulties in the disciplines and finance; and, (c) area of interest: software engineering, human-computer interaction and computer graphics. A new questionnaire was applied in order to validate the personas generated in relation to credibility, empathy and similarity. Based on the results obtained, it was observed that two of the four personas generated achieved greater prominence in relation to the validation criteria, showing that the personas look like real people, students think like the personas and share similar interests.","2020","2021-02-15 21:32:00","2021-02-15 21:32:00","","","","","","","","","IHC '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Diamantina, Brazil","","","","personas; clustering; automatic generation of personas; personas validation; questionnaire","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKAFUXG6","conferencePaper","2014","Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth","Towards a Serious Game Playing Empathic Robotic Tutorial Dialogue System","Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2658-2","","10.1145/2559636.2563707","https://doi.org/10.1145/2559636.2563707","There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.","2014","2021-02-15 21:32:00","2021-02-15 21:32:00","","180–181","","","","","","","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bielefeld, Germany","","","","serious games; dialogue management; empathic robotic tutor; tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLWX2ZB5","conferencePaper","2010","Rivera, Fiona; Watten, Phil; Holroyd, Patrick; Beacher, Felix; Mania, Katerina; Critchley, Hugo","Real-Time Compositing Framework for Interactive Stereo FMRI Displays","ACM SIGGRAPH 2010 Posters","978-1-4503-0393-4","","10.1145/1836845.1836862","https://doi.org/10.1145/1836845.1836862","This research concentrates on providing high fidelity animation, only achievable with offline rendering solutions, for interactive fMRI-based experiments. Virtual characters are well established within the film, game and research worlds, yet much remains to be learned about which design, stylistic or behavioural factors combine to make a believable character. The definition of believability depends on context. When designing and implementing characters for entertainment, the concern is making believable characters that the audience will engage with. When using virtual characters in experiments, the aim is to create characters and synthetic spaces that people respond to in a similar manner to their real world counterparts. Research has shown that users show empathy for virtual characters. However, uncanny valley effects – ie dips in user impressions – can arise: behavioural fidelity expectations increase alongside increases in visual fidelity and vice versa. Often, characters used within virtual environments tend to be of fairly low fidelity due to technological constraints including rendering in real-time (Garau et al. 2003). This problem is addressed here by using non-linear playback and compositing of pre-rendered high fidelity sequences.","2010","2021-02-15 21:32:00","2021-02-15 21:32:00","","","","","","","","","SIGGRAPH '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Los Angeles, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTPBR4DN","conferencePaper","2019","Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios","Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability","Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","978-1-4503-6232-0","","10.1145/3316782.3322767","https://doi.org/10.1145/3316782.3322767","Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.","2019","2021-02-15 21:32:00","2021-02-15 21:32:00","","442–447","","","","","","","PETRA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rhodes, Greece","","","","age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJKU3A9E","conferencePaper","2020","Bastos, João Antonio D. M.; de Mello, Rafael Maiani; Garcia, Alessandro","Colloquy: A Method for Conversational API Design","Proceedings of the 34th Brazilian Symposium on Software Engineering","978-1-4503-8753-8","","10.1145/3422392.3422468","https://doi.org/10.1145/3422392.3422468","APIs (application programming interfaces) play a key role in software development. Virtually, all programmers are potential users of third-party APIs. From the perspective of the theory of Semiotic Engineering, we may characterize an API as an artifact mediating the communication between two types of developers: the API designers and its users. During the construction of an API, the designers should establish proper dialogues with the users. These dialogues will enable the conversation of these actors at the interaction time. In this way, we define a conversational API as an API capable of offering effective dialogues to its users. In this paper, we introduce Colloquy, a method for supporting the design of conversational APIs. Colloquy results from the lessons learnt during an action research conducted for redesigning a real and complex API. The set of Colloquy resources allow API designers to go beyond conventional concerns with usability. We also report in this paper a case study in which Colloquy was used for redesigning a refactoring API. The study findings indicate the method helped the designer creating empathy with the API users, as well as better reflecting and depicting the requirements and the conversations that the API should attend to the different user profiles.","2020","2021-02-15 21:32:00","2021-02-15 21:32:00","","514–519","","","","","","","SBES '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Natal, Brazil","","","","API Conversacional; Engenharia Semiótica; Método de Design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKBNUKME","conferencePaper","2018","Bosch, Esther; Oehl, Michael; Jeon, Myounghoon; Alvarez, Ignacio; Healey, Jennifer; Ju, Wendy; Jallais, Christophe","Emotional GaRage: A Workshop on In-Car Emotion Recognition and Regulation","Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-5947-4","","10.1145/3239092.3239098","https://doi.org/10.1145/3239092.3239098","In-car emotion detection and regulation have become an emerging and important branch of research within the automotive domain. Different emotional states can greatly influence human driving performance and user experience both in manual and automated driving conditions. The monitoring and regulation of relevant emotional states is therefore important to avoid critical driving scenarios with the human driver being in charge, and to ensure comfort and acceptance in autonomous driving. In this workshop we want to discuss the empathic user interface research to address challenges and opportunities and to reveal new research directions for future work. This workshop provides a forum for exchange and discussion on empathic user interfaces, including methods for emotion recognition and regulation, empathic automotive human-machine interaction design, user evaluation and measurements, and subsequent improvement of autonomous driving experience.","2018","2021-02-15 21:32:00","2021-02-15 21:32:00","","44–49","","","","","","","AutomotiveUI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, ON, Canada","","","","user acceptance; Driver state assessment; emotion recognition and regulation; empathic vehicles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2ZKL2B4","conferencePaper","2016","Chisik, Yoram; Mancini, Clara","Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans","Proceedings of the 14th Participatory Design Conference: Short Papers, Interactive Exhibitions, Workshops - Volume 2","978-1-4503-4136-3","","10.1145/2948076.2948093","https://doi.org/10.1145/2948076.2948093","Participatory Design strives to broaden the perspective of and increase empathy in design by giving specific and often under represented user groups, such as children or older people, a voice in the design process. The exact nature of the role played by such participants in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the participatory design community. The emerging field of Animal Computer Interaction, which seeks to empower animals through user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.","2016","2021-02-15 21:32:00","2021-02-15 21:32:00","","123–124","","","","","","","PDC '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aarhus, Denmark","","","","children; participatory design; ACI; animal computer interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSCCK2J5","conferencePaper","2014","Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei","The Fugitive: A Robot in the Wild","Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2658-2","","10.1145/2559636.2559653","https://doi.org/10.1145/2559636.2559653","The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building.The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not.The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on.The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol.The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.","2014","2021-02-15 21:32:00","2021-02-15 21:32:00","","111","","","","","","","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bielefeld, Germany","","","","human-robot interaction; social robotics; robots in the wild","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DCPACUQQ","bookSection","2017","Chisik, Yoram; Mancini, Clara","Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans","Proceedings of the 2017 Conference on Interaction Design and Children","978-1-4503-4921-5","","","https://doi.org/10.1145/3078072.3081311","Participatory Design with children strives to broaden the perspective of and increase empathy in design for the needs and desires of children by giving children a voice in the design process. The exact nature of the role played by children in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the IDC community. The emerging field of Animal Computer Interaction, which seeks to empower animals through the participatory design of user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.","2017","2021-02-15 21:32:00","2021-02-15 21:32:00","","753–756","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LANF7YV8","bookSection","2017","Cole, Amelia W.; Quesnel, Denise T.; Pekçetin, Serkan; Gromala, Diane; O'Brien, Heather; Antle, Alissa N.; Riecke, Bernhard E.","Integrating Affective Responses and Gamification into Early Reading Acquisition Software Applications","Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play","978-1-4503-5111-9","","","https://doi.org/10.1145/3130859.3131433","Sisu is a gamified learning application designed to assist school-aged children who are struggling to read. Sisu utilizes readily-available technology to promote learning at home, with unique elements tied to the learning experience: (1) a spelling game with (2) an empathic agent, and (3) a mini-game. The empathic agent utilizes a facial action coding system (FACS) to recognize core expressions of the child user and respond to the child's affect in-game. We anticipate that Sisu's accessible and affective nature will not only support children's emotional needs, but the addition of gamified elements will motivate them to practice reading and assist them in their learning objectives.","2017","2021-02-15 21:32:00","2021-02-15 21:32:00","","73–85","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYPYV5TS","conferencePaper","2018","Spaulding, Samuel","Personalized Robot Tutors That Learn from Multimodal Data","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.","2018","2021-02-15 21:32:00","2021-02-15 21:32:00","","1781–1783","","","","","","","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Stockholm, Sweden","","","","human-robot interaction; social robotics; multimodal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENQLCA5E","journalArticle","2020","McDonald, Nora; Pan, Shimei","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3415218","https://doi.org/10.1145/3415218","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.","2020-10","2021-02-15 21:33:24","2021-02-15 21:33:24","","","","CSCW2","4","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","artificial intelligence; ethics; algorithm bias; education; intersectionality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2K9T9V3Z","conferencePaper","2019","Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania","Ballbit Adventure: A Physical Game for a Collaborative Racing","Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts","978-1-4503-6871-1","","10.1145/3341215.3356982","https://doi.org/10.1145/3341215.3356982","Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.","2019","2021-02-15 21:33:24","2021-02-15 21:33:24","","97–103","","","","","","","CHI PLAY '19 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NB5BCB6K","conferencePaper","2013","Wagner, Johannes; Lingenfelser, Florian; André, Elisabeth; Mazzei, Daniele; Tognetti, Alessandro; Lanatà, Antonio; De Rossi, Danilo; Betella, Alberto; Zucca, Riccardo; Omedas, Pedro; Verschure, Paul F. M. J.","A Sensing Architecture for Empathetic Data Systems","Proceedings of the 4th Augmented Human International Conference","978-1-4503-1904-1","","10.1145/2459236.2459253","https://doi.org/10.1145/2459236.2459253","Today's increasingly large and complex databases require novel and machine aided ways of exploring data. To optimize the selection and presentation of data, we suggest an unconventional approach. Instead of exclusively relying on explicit user input to specify relevant information or to navigate through a data space, we exploit the power and potential of the users' unconscious processes in addition. To this end, the user is immersed in a mixed reality environment while his bodily reactions are captured using unobtrusive wearable devices. The users' reactions are analyzed in real-time and mapped onto higher-level psychological states, such as surprise or boredom, in order to trigger appropriate system responses that direct the users' attention to areas of potential interest in the visualizations. The realization of such a close experience-based human-machine loop raises a number of technical challenges, such as the real-time interpretation of psychological user states. The paper at hand describes a sensing architecture for empathetic data systems that has been developed as part of such a loop and how it tackles the diverse challenges.","2013","2021-02-15 21:33:24","2021-02-15 21:33:24","","96–99","","","","","","","AH '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stuttgart, Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JRJXDJX","conferencePaper","2016","Lim, Mei Yii; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Hall, Lynne","A Treasure Hunt With An Empathic Virtual Tutor: (Demonstration)","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","We present a demonstration of a Treasure Hunt Application with an Empathic Virtual Tutor. During the treasure hunt, this empathic agent adapts its interaction based on the affective state of the user to improve learning experience. We demonstrate the application domain; the technology used; and the app focusing on the empathic strategies applied.","2016","2021-02-15 21:33:24","2021-02-15 21:33:24","","1477–1478","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","human-agent interaction; valence; arousal; empathic agent; treasure hunt","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEWTXP46","journalArticle","2020","Cotler, Jami L.; Villa, Luis; Burshteyn, Dmitry; Bult, Zachary; Grant, Garrison; Tanski, Michael; Parente, Anthony","An Interdisciplinary Approach to Detecting Empathy through Emotional Analytics and Eye Tracking","J. Comput. Sci. Coll.","","1937-4771","","","The aim of this interdisciplinary study was to bring together different perspectives to discover if detecting empathetic emotional reactions is possible. This area of research has received recent attention from the computer science, human-computer interaction and psychological research communities. The research team consisted of three students; a computer science, sociology and marketing major. The team worked to understand the complexities of detecting emotions based on facial movement. The team collected time stamped facial emotional data from 210 participants as they watched a video clip from the popular movie depicting bullying behavior towards a disabled person. The results demonstrated significant before-and- after mean differences in emotions that are characterized as empathic towards the main character for the bullying events, which is a promising start to detecting empathic reactions. Each student brought a different perspective from their majors resulting in an educational experience that transcended learning about emotional analytics.","2020-04","2021-02-15 21:33:24","2021-02-15 21:33:24","","87–95","","8","35","","","","","","","","","","","","","","","","","Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P3SUXZG","conferencePaper","2016","Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan","Semi-Supervised Model Personalization for Improved Detection of Learner's Emotional Engagement","Proceedings of the 18th ACM International Conference on Multimodal Interaction","978-1-4503-4556-9","","10.1145/2993148.2993166","https://doi.org/10.1145/2993148.2993166","Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.","2016","2021-02-15 21:33:24","2021-02-15 21:33:24","","100–107","","","","","","","ICMI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QEIAI35R","conferencePaper","2015","Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana","The Empathic Robotic Tutor: Featuring the NAO Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702100","https://doi.org/10.1145/2701973.2702100","We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.","2015","2021-02-15 21:33:24","2021-02-15 21:33:24","","285","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","educational robotics; empathic robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TX7WJGS","conferencePaper","2019","Tchetgen, Pierre-Valery Njenji","DRUMBALL: Multimodal Meaning Production through Digital Drum Talk","Proceedings of the 2019 on Creativity and Cognition","978-1-4503-5917-7","","10.1145/3325480.3326544","https://doi.org/10.1145/3325480.3326544","In this demonstration, I present an interactive prototype of the Drumball system, an embodied learning environment that allows for drum patterns to be turned into and used as letters, words or phrases. The system acts as a transducer of rhythmic input into multimodal output, and was designed to investigate the affordances of this embodied learning approach on the early literacy skills acquisition of children. The project follows a design thinking process (empathize, define, ideate, prototype, test) to explore cultural systems as a grounding for learning technologies design. The session provides a space to think beyond the traditional keypad interface and its reliance on alphabetic input, to explore how the application of the talking drum cultural system in the domain of human-computer interaction can be used to transform children's early experiences with literacy. I will demonstrate creating sequences of letters and words using the system by playing drum tones of varying pitches (tone, slap and bass).","2019","2021-02-15 21:33:24","2021-02-15 21:33:24","","513–517","","","","","","","C&amp;C '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, CA, USA","","","","embodied learning; culturally-grounded pedagogies and technologies; drum language; haptic devices; interaction paradigm; literacy development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LLRH42Z","conferencePaper","2019","Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher","Mutual Reinforcement Learning with Robot Trainers","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.","2019","2021-02-15 21:33:24","2021-02-15 21:33:24","","572–573","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5ASQKE6","conferencePaper","2016","Alyuz, Nese","Shaping the Future of Education with Empathic Companions","Proceedings of the 2nd Workshop on Emotion Representations and Modelling for Companion Systems","978-1-4503-4558-3","","10.1145/3009960.3009964","https://doi.org/10.1145/3009960.3009964","With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.","2016","2021-02-15 21:33:24","2021-02-15 21:33:24","","","","","","","","","ERM4CT '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XPQY3WKM","conferencePaper","2010","Regazzoni, Carlo S.","Emphatic Human Interaction Analysis for Cognitive Environments","Proceedings of the First ACM International Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams","978-1-4503-0163-3","","10.1145/1877868.1877870","https://doi.org/10.1145/1877868.1877870","Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment.Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available.Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation.Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world.Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it).Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.","2010","2021-02-15 21:33:24","2021-02-15 21:33:24","","1–2","","","","","","","ARTEMIS '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Firenze, Italy","","","","ambient intelligence; cognitive surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S2N4L7P","conferencePaper","2019","Gu, Xiusen; Xu, Weiran; Li, Si","Towards Automated Emotional Conversation Generation with Implicit and Explicit Affective Strategy","Proceedings of the 2019 International Symposium on Signal Processing Systems","978-1-4503-6241-2","","10.1145/3364908.3365288","https://doi.org/10.1145/3364908.3365288","Building an empathic conversation machine in open-domain is a promising research topic in natural language processing. However, most current approaches rely on designated emotions to conduct generating responses and lack the ability to decide the appropriate emotion strategy. In this paper, we propose a dialogue model of jointly predicting and generating emotions called DRCVAE, which stands for Decoupled Representations of Conditional Variational Autoencoders.More specifically, the model separates the latent variable in conditional variational autoencoders (CVAE) into two parts: emotion and content. Then the latent emotional strategy (implicit) is further forced to predict the target emotion probability distribution (explicit). By using implicit and explicit emotional strategy, a newly designed paired decoder incorporates rich control information to decode the response. Experiment results demonstrate that DRCVAE provides an effective way to infer target emotions and generate high-quality responses simultaneously.","2019","2021-02-15 21:33:24","2021-02-15 21:33:24","","125–130","","","","","","","SSPS 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Beijing, China","","","","Emotional dialogue system; CVAE; decoupled representations; paired decoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5RRH8P2","conferencePaper","2011","Lee, Jung-Joo; Vaajakallio, Kirsikka; Mattelmäki, Tuuli","Tracing Situated Effects of Innovative Design Methods: Inexperienced Designers' Practices","Procedings of the Second Conference on Creativity and Innovation in Design","978-1-4503-0754-3","","10.1145/2079216.2079231","https://doi.org/10.1145/2079216.2079231","In recent years the design research community has been active in developing new methods for user involvement and collaboration in the design process. The new methods, often called innovative design methods, correspond more to designer's genuine ways of thinking and working than do traditional user-centered ones. The entire purpose of innovative method is to allow for designer's creativity in the design of method and reflective learning, instead of relying on predefined rules of method. For this reason, codification and scientific evaluation are often regarded very challenging, if meaningful at all. This leads us to raise a question; what could be relevant ways of framing and communicating innovative design methods to better capture their nature and value?As one attempt to explore this question, our study takes a close look at inexperienced designers' practices with innovative methods, such as probes or co-design workshops. We chose students as research subjects because their situated actions – and the challenges they face in understanding and applying these methods – reveal just kind of knowledge about the innovative methods that needs to be communicated. To do this, we analyzed students' learning diaries written during the design course. When the students reported uncertainties and disappointments due to 'ill-defined' nature of such methods, we were able to trace the reasons for disappointments. We also found that the innovative design methods in fact supported the students for empathic learning and design inspiration from the making process of the methods.","2011","2021-02-15 21:33:24","2021-02-15 21:33:24","","103–113","","","","","","","DESIRE '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Eindhoven, Netherlands","","","","empathic design; co-design; design education; innovative design methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INHM4BIB","conferencePaper","2013","Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria","3D Animated Agent for Tutoring Based on WebGL","Proceedings of the 18th International Conference on 3D Web Technology","978-1-4503-2133-4","","10.1145/2466533.2466534","https://doi.org/10.1145/2466533.2466534","The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.","2013","2021-02-15 21:33:24","2021-02-15 21:33:24","","129–134","","","","","","","Web3D '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Sebastian, Spain","","","","artificial intelligence; e-learning; virtual agents; Web3D technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIMUS7EW","conferencePaper","2017","Ranjbartabar, Hedieh; Richards, Deborah","Student Designed Virtual Teacher Feedback","Proceedings of the 9th International Conference on Computer and Automation Engineering","978-1-4503-4809-6","","10.1145/3057039.3057083","https://doi.org/10.1145/3057039.3057083","Interactive virtual learning environments (VLEs) have significant potential to influence students' learning achievements. Characters in these VLEs can act as a virtual peers and teachers by providing empathic responses tailored to the affective state of the students. Designing appropriate dialogues and feedback will be important in achieving the desired outcomes such as increased engagement, motivation and achievement. In this paper we report our findings from a study with 19 girls in Year 8 and 9 at high school using the Omosa VLE. The study investigated student responses to the initial dialogues we designed to elicit their emotional state and provide support. Analysis of responses and alternative dialogues offered by the students revealed that the feedback provided by our characters was mostly acceptable, but further improvements should be made to include elements such as self-disclosure and more helpful dialogue.","2017","2021-02-15 21:33:25","2021-02-15 21:33:25","","26–30","","","","","","","ICCAE '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, Australia","","","","Omosa; empathic virtual agent; Virtual learning environment; virtual world","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHP9296W","journalArticle","2020","Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung","The Design and Implementation of XiaoIce, an Empathetic Social Chatbot","Comput. Linguist.","","0891-2017","10.1162/coli_a_00368","https://doi.org/10.1162/coli_a_00368","This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.","2020-03","2021-02-15 21:33:25","2021-02-15 21:33:25","","53–93","","1","46","","","","","","","","","","","","","","","","","Place: Cambridge, MA, USA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6826YGWH","conferencePaper","2020","Latulipe, Celine; Provencal, Sarah; Frevert, Tonya","Challenging Social Exclusion in Computing via 'Theatre of the Oppressed' Pedagogy","Proceedings of the 51st ACM Technical Symposium on Computer Science Education","978-1-4503-6793-6","","10.1145/3328778.3367008","https://doi.org/10.1145/3328778.3367008","Micro-aggressions, hostile climates, and intersectional discrimination contribute to students feeling excluded from fully participating in Computer Science or other STEM programs. To address this exclusion, students need to empathize with each other, and for that we need them to be having frank, open conversations about difficult situations. This is hard to achieve, as people do not typically want to talk about difficult situations with strangers. Computer Science faculty may shy away from these difficult conversations, as they may feel they lack the expertise to address social issues effectively. To address this issue, we have been conducting 'Exclusion Response Workshops' based on the 'Theatre of the Oppressed' methodology of rehearsing social change. This involves students anonymously contributing scenarios of micro-aggressions they have experienced or witnessed and then roleplaying alternate outcomes. These workshops create an empathetic environment for frank and open discussion of difficult issues. We have been scaling this effort by conducting workshops with all freshmen and transfer students in our College of Computing and Informatics. In this SIGCSE workshop, attendees will participate in an Exclusion Response Workshop, then have an open discussion about the workshop experience, workshop logistics, and pros and cons of running this workshop as a mandatory class activity versus a voluntary activity. Participants will learn about the workshop structure, and the Theatre of the Oppressed methodology. This workshop is a taste of a 3-day, train-the-trainer workshop that we will be conducting at our institution in May 2020. Supported by NSF IUSE/RED Award #151960.","2020","2021-02-15 21:33:25","2021-02-15 21:33:25","","1395","","","","","","","SIGCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, OR, USA","","","","diversity; inclusion; participatory-theatre; theatre-of-the-oppressed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZFVN6KC","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: An Edible Living Media Installation","Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction","978-1-4503-2635-3","","10.1145/2540930.2555209","https://doi.org/10.1145/2540930.2555209","In the face of increasing urbanization and lack of contact with nature, it is important to design systems that facilitate a re-connection or at least dialogue around our interaction with living beings. Rafigh, an empathetic living media interface, is designed to motivate children and adults to care for a living mushroom colony by engaging in collaborative and learning activies.","2014","2021-02-15 21:33:25","2021-02-15 21:33:25","","345–346","","","","","","","TEI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Munich, Germany","","","","embedded computing; living media interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBVEMG8X","conferencePaper","2016","Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid","Map Reading with an Empathic Robot Tutor","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.","2016","2021-02-15 21:33:25","2021-02-15 21:33:25","","567","","","","","","","HRI '16","","","","IEEE Press","","","","","","","","","event-place: Christchurch, New Zealand","","","","empathy; robot-child interaction; robotic tutor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMBNDYP7","conferencePaper","2015","Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro","An Empathic Robotic Tutor in a Map Application","Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems","978-1-4503-3413-6","","","","In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.","2015","2021-02-15 21:33:25","2021-02-15 21:33:25","","1923–1924","","","","","","","AAMAS '15","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Istanbul, Turkey","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYQ3M8KW","conferencePaper","2012","Taylor, Jason","The Trade Aid Computer Kiosk: Inclusive and Human Centred Design Technology at the Point of Sale","Proceedings of the 13th International Conference of the NZ Chapter of the ACM's Special Interest Group on Human-Computer Interaction","978-1-4503-1474-9","","10.1145/2379256.2379275","https://doi.org/10.1145/2379256.2379275","We present a computer kiosk for learning in the retail space connecting producers and consumers through Fair Trade. The project has explored reactions to simple, inclusive technology focusing on the human narrative within not for profit trade and empathic human centered design toward all stakeholders.","2012","2021-02-15 21:33:25","2021-02-15 21:33:25","","91","","","","","","","CHINZ '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dunedin, New Zealand","","","","empathic design; computer kiosk; fair trade; human centred; rapid prototype; retail","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"59WVUKXJ","conferencePaper","2016","André, Elisabeth","Socially-Sensitive Interfaces: From Offline Studies to Interactive Experiences","Proceedings of the 21st International Conference on Intelligent User Interfaces","978-1-4503-4137-0","","10.1145/2856767.2856799","https://doi.org/10.1145/2856767.2856799","Recent years have initiated a paradigm shift from pure taskbased human-machine interfaces towards socially-sensitive interaction. In addition to what users explicitly say or gesture at, socially-sensitive interfaces are able to sense more subtle human cues, such as head postures and movements, to infer psychological user states, such as attention and affect, and also to enrich system responses with social signals. However, most approaches focus on offline analysis of previously recorded data limiting the investigation to prototypical behaviors in laboratory-like settings. In my presentation, I will focus on challenges that arise when integrating social signal processing techniques into interactive systems designed for real-world applications. From a technical perspective, this requires effective tools able to synchronize, process, and analyze relevant signals in online mode. From a user perspective, appropriate strategies need to be defined to respond to social signals at the right moment in time without disturbing the flow of interaction. I will discuss two interaction styles for socially-sensitive interfaces. In the area of information retrieval, the concept of empathic stimulation has been used to optimize the selection and presentation of data. The basic idea is to exploit sensory data on the users' emotional state to provide them with cues that inspire their curiosity during the data exploration task. In the domain of social coaching, the concept of social augmentation has been employed to give people ambient feedback on their behavior while being engaged in a social interaction. The presentation will be illustrated by examples from various national and international projects following these two interaction styles.","2016","2021-02-15 21:33:25","2021-02-15 21:33:25","","305","","","","","","","IUI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sonoma, California, USA","","","","affective computing; social signal processing; empathic stimulation; social augmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MV2HY4P6","journalArticle","2015","Leite, Iolanda","Long-Term Interactions with Empathic Social Robots","AI Matters","","","10.1145/2735392.2735397","https://doi.org/10.1145/2735392.2735397","We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.","2015-03","2021-02-15 21:33:25","2021-02-15 21:33:25","","13–15","","3","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6RKLMVX","conferencePaper","2014","Nazir, Asad; Aylett, Ruth S.; Lim, Mei Yii; Endrass, Birgit; Hall, Lynne; Ritter, Christopher","MIXER: Why the Difference?","Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-2738-1","","","","This interactive demo features MIXER, a Virtual Learning Environment (VLE) consisting of synthetic characters representing the various actors in a scenario group difference scenario. MIXER creates virtual dramas by using interactive narrative with those characters. The goal is to enable children to identify social rule differences, by interacting with one of the characters to which they become empathic. MIXER is evaluated in the UK and Germany with children aged 9 to 11 years. The video for the demo content can be found at: http://youtu.be/jKIndn5NPaQ","2014","2021-02-15 21:33:25","2021-02-15 21:33:25","","1687–1688","","","","","","","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Paris, France","","","","artificial intelligence; applications; virtual learning environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZYEBLMS","conferencePaper","2016","Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra","How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.","2016","2021-02-15 21:33:25","2021-02-15 21:33:25","","423–424","","","","","","","HRI '16","","","","IEEE Press","","","","","","","","","event-place: Christchurch, New Zealand","","","","empathy; robotic tutors; child-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFWTXSYE","conferencePaper","2019","Noortman, Renee; Schulte, Britta F.; Marshall, Paul; Bakker, Saskia; Cox, Anna L.","HawkEye - Deploying a Design Fiction Probe","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300652","https://doi.org/10.1145/3290605.3300652","This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.","2019","2021-02-15 21:33:25","2021-02-15 21:33:25","","1–14","","","","","","","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","design fiction; dementia care; future scenarios; informal caregiving; monitoring technologies; technology probes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4FVUYYG","conferencePaper","2020","Bourdin, Pierre; Calvet, Laura; Tesconi, Susanna; Arnedo-Moreno, Joan","Reflecting on Attitudes Towards Death Through the Use of Immersive Virtual Reality Commercial Video Games","Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality","978-1-4503-8850-4","","10.1145/3434780.3436559","https://doi.org/10.1145/3434780.3436559","Video games can be an invaluable learning tool beyond pure skill acquisition, such as teaching us how to empathize with others or even self-reflecting on basic existential concerns: isolation, freedom, meaninglessness or death. This is further emphasized with the use of immersive technologies and becomes especially relevant when the experience itself is very difficult to replicate, when not impossible, in the real world. On that regard, this paper analyzes the impact of virtual reality (VR) commercial video games on the existential concern of one's own death. Participants (N 30) played one of three games for 15 minutes and the aftermath was examined using questionnaires and the implicit relational assessment procedure (IRAP). Our results show that there is no difference in the game experience, despite the different gameplay. However, IRAP results seem to indicate that players of the action game have a different attitude towards death.","2020","2021-02-15 21:33:25","2021-02-15 21:33:25","","640–647","","","","","","","TEEM'20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salamanca, Spain","","","","Virtual reality; serious games; death-evaluation; death-identity; existential games; immersive player experiences; Implicit Relational Assessment Procedure; video games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXQBZFCP","bookSection","2018","Giglitto, Danilo; Lazem, Shaimaa; Preston, Anne","In the Eye of the Student: An Intangible Cultural Heritage Experience, with a Human-Computer Interaction Twist","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","","https://doi.org/10.1145/3173574.3173864","We critically engage with CHI communities emerging outside the global North (ArabHCI and AfriCHI) to explore how participation is configured and enacted within socio-cultural and political contexts fundamentally different from Western societies. We contribute to recent discussions about postcolonialism and decolonization of HCI by focusing on non-Western future technology designers. Our lens was a course designed to engage Egyptian students with a local yet culturally-distant community to design applications for documenting intangible heritage. Through an action research, the instructors reflect on selected students' activities. Despite deploying a flexible learning curriculum that encourages greater autonomy, the students perceived themselves with less agency than other institutional stakeholders involved in the project. Further, some of them struggled to empathize with the community as the impact of the cultural differences on configuring participation was profound. We discuss the implications of the findings on HCI education and in international cross-cultural design projects.","2018","2021-02-15 21:33:25","2021-02-15 21:33:25","","1–12","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EC6VCP4U","bookSection","2018","Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama","Touch Your Heart: A Tone-Aware Chatbot for Customer Care on Social Media","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","","https://doi.org/10.1145/3173574.3173989","Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.","2018","2021-02-15 21:33:25","2021-02-15 21:33:25","","1–12","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVZQ4UUY","conferencePaper","2020","Chapko, Dorota; Frumiento, Pino; Edwards, Nalini; Emeh, Lizzie; Kennedy, Donald; McNicholas, David; Overton, Michaela; Snead, Mark; Steward, Robyn; Sutton, Jenny M.; Jeffreys, Evie; Long, Catherine; Croll-Knight, Jess; Connors, Ben; Castell-Ward, Sam; Coke, David; McPeake, Bethany; Renel, William; McGinley, Chris; Remington, Anna; Whittuck, Dora; Kieffer, John; Ewans, Sarah; Williams, Mark; Grierson, Mick","""We Have Been Magnified for Years - Now You Are under the Microscope!"": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities","Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6708-0","","10.1145/3313831.3376278","https://doi.org/10.1145/3313831.3376278","Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.","2020","2021-02-15 21:33:25","2021-02-15 21:33:25","","1–17","","","","","","","CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Honolulu, HI, USA","","","","attitudes; design; disability; survey; participatory/inclusive research; video","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC5EI4AH","conferencePaper","2020","Carrasco, Romina; A. Baker, Felicity; A. Bukowska, Anna; N. Clark, Imogen; M. Flynn, Libby; McMahon, Kate; Odell-Miller, Helen; Stensaeth, Karette; Tamplin, Jeanette; Vieira Sousa, Tanara; Waycott, Jenny; Wosch, Thomas","Empowering Caregivers of People Living with Dementia to Use Music Therapeutically at Home: Design Opportunities","32nd Australian Conference on Human-Computer Interaction","978-1-4503-8975-4","","10.1145/3441000.3441082","https://doi.org/10.1145/3441000.3441082","Human-computer interaction researchers have explored how to design technologies to support people with dementia (PwD) and their caregivers, but limited attention has been given to how to facilitate music therapy in dementia care. The use of music to help manage the symptoms of dementia is often guided by a music therapist who adapts the intervention to respond to the changing needs of the person living with dementia. However, as the incidence of dementia increases worldwide, individualised therapy programs are less feasible, making it valuable to consider technology-based approaches. In this paper, we analyze data from case studies of home-based music therapy training interventions with two families. The findings show that embodied interactions supported the therapist in responding to the needs of the PwD and built an empathic environment that empowered the caregivers’ learning. We discuss opportunities and challenges for designing technologies that support family caregivers’ therapy-informed music use in dementia care.","2020","2021-02-15 21:33:26","2021-02-15 21:33:26","","198–209","","","","","","","OzCHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, NSW, Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35PCZLWM","conferencePaper","2014","Iacono, Iolanda; Marti, Patrizia","Engaging Older People with Participatory Design","Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational","978-1-4503-2542-4","","10.1145/2639189.2670180","https://doi.org/10.1145/2639189.2670180","We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.","2014","2021-02-15 21:33:26","2021-02-15 21:33:26","","859–864","","","","","","","NordiCHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Helsinki, Finland","","","","empathy; participatory design; older people; gaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMWC9PT6","conferencePaper","2012","Khaled, Rilla","Muse-Based Game Design","Proceedings of the Designing Interactive Systems Conference","978-1-4503-1210-3","","10.1145/2317956.2318065","https://doi.org/10.1145/2317956.2318065","Game design and user experience (UX) design both centre on the design of experiences. But whereas it is par for the course for end-user perspectives to be included during early design stages in UX, there is little methodological support or research into how to incorporate player perspectives into early stages of game design. In this paper, we introduce muse-based game design, an experimental empathic design approach foregrounding a dialogic artist – muse relationship between a game designer and player. Following a user research stage focused on learning about the player, the designer forms idiosyncratic design constraints inspired by and relating to the player, which are then used to inspire ideation. To understand the consequences, advantages, and disadvantages of this approach, we discuss findings from two years of application of this style of game design in a Master's-level class of game design students at the IT University of Copenhagen.","2012","2021-02-15 21:33:26","2021-02-15 21:33:26","","721–730","","","","","","","DIS '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Newcastle Upon Tyne, United Kingdom","","","","empathic design; game design; design processes; player-centred design; player-centric design; reflective design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AX32U7PG","conferencePaper","2019","W. Bennett, Gregory; Canner, Liz","Lost City of Mer","SIGGRAPH Asia 2019 XR","978-1-4503-6947-3","","10.1145/3355355.3361897","https://doi.org/10.1145/3355355.3361897","Lost City of Mer is a virtual reality (VR) game experience combined with a smartphone app that immerses players in a fantasy undersea civilization devastated by ecological disaster caused by global warning. The project aims to harness the immersive and empathetic potential of VR to address climate change and create a sense of urgency in the player with regard to their personal carbon footprint.Players are invited to help rebuild the lost world of Mer and its devastated ecosystem in VR by re-establishing its unique flora and fauna, and fighting ongoing dangers and threats, with the aim of bringing back to life its mysterious Mer-people inhabitants. Guided by a solitary seal spirit named Athina – the last of its kind in a dying ocean – players try to save the Mer population from extinction. They tend to secret gardens of coral threatened by pollution, create habitats for Mer-people, and explore the destroyed civilization, in the process learning how their real-world actions impact the world around them.The project was developed with the input of environmental scientists from Harvard University and Dartmouth College. The experience is based on real science, but told through fantasy, as it draws on the cross-cultural myth of the mermaid to appeal to people across the globe.","2019","2021-02-15 21:33:26","2021-02-15 21:33:26","","25–26","","","","","","","SA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Brisbane, QLD, Australia","","","","climate change; virtual reality; serious games; VR navigation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YK7BB9PX","conferencePaper","2013","Kim, Hyun-Jun; Choi, Young Sang","A Peak Detection Method for Understanding User States for Empathetic Intelligent Agents","Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 02","978-0-7695-5145-6","","10.1109/WI-IAT.2013.118","https://doi.org/10.1109/WI-IAT.2013.118","Recognition of facial expression is a useful and unobtrusive means for machines to understand users' internal states. However, most human facial expression is ambiguous or subtle to recognize resulting in poor accuracy. To overcome this limitation, we propose a peak detection method to select only meaningful images from image sequences which imply significant changes of facial expression by calculating differences between images. We believe this method will alleviate the accuracy degradation caused by different personal appearances and ambiguous facial expressions. When applied to commercial products, it can provides a suitable method for adaptation of the empathetic agent embedded in machines such as personal assistants on TV, smartphone and vehicles based on recognized facial expression of users. For experimental validation of the proposed method, we tested four different features for measuring image similarity with the extended Cohn-Kanade facial image dataset. As a result, we could get better recognition accuracy than the original image sequences. Moreover, we reduced the number of images that need to be recognized to 24.52% without degradation of accuracy.","2013","2021-02-15 21:33:26","2021-02-15 21:33:26","","261–265","","","","","","","WI-IAT '13","","","","IEEE Computer Society","USA","","","","","","","","","","","","Empathetic Agent; Facial Expression; Image Processing; Peak Detection; Temporal Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E94QU5H2","conferencePaper","2018","Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia","A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.","2018","2021-02-15 21:33:26","2021-02-15 21:33:26","","1658–1666","","","","","","","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Stockholm, Sweden","","","","social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPFMNUD6","conferencePaper","2018","Corral, Luis; Fronza, Ilenia","Design Thinking and Agile Practices for Software Engineering: An Opportunity for Innovation","Proceedings of the 19th Annual SIG Conference on Information Technology Education","978-1-4503-5954-2","","10.1145/3241815.3241864","https://doi.org/10.1145/3241815.3241864","Commonly, the instruction of Software Engineering implements processes that are inherent to the theory and practice of software development. Traditional and Agile methods lay the foundation for building ""functional software products"" that meet the requirements of a system of a larger scope. However, if we consider software as a product that frequently has the mission of satisfying the needs of human users, we can go beyond the typical ""analysis - design - implementation - testing"" process, to reinterpret it with the ""empathize - define - ideate - prototype - testing"" proposed by Design Thinking, a development methodology commonly used in creative and innovative professional settings. In this work, we study the use of Design Thinking as a methodological approach for the instruction of Software Engineering at undergraduate level, in courses that have the particular aim of creating innovative software products from scratch. We describe the similarities and differences between Design Thinking and Software Development Processes, taking as instance Agile Practices. We compare evidence on methods and deliverables produced by students in their learning path using Agile Practices and Design Thinking in two different educational environments. Finally, we discuss coincidences, weaknesses, and opportunities to keep investigating in this topic as a research subject, toward finding practices to promote in students both creativity and technical discipline to develop innovative software solutions","2018","2021-02-15 21:33:26","2021-02-15 21:33:26","","26–31","","","","","","","SIGITE '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Fort Lauderdale, Florida, USA","","","","education; creativity; agile; design thinking; software engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSXQTEJ5","conferencePaper","2019","Zhou, Michelle X.","Getting Virtually Personal: Making Responsible and Empathetic ""Her"" for Everyone","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3308445","https://doi.org/10.1145/3301275.3308445","Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world.Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent.I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.","2019","2021-02-15 21:33:26","2021-02-15 21:33:26","","i","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina del Ray, California","","","","computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AD7GUG88","book","2014","","IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces","","978-1-4503-2184-6","","","","It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.","2014","2021-02-15 21:33:26","2021-02-15 21:33:26","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZL23V7LB","book","2014","","IUI Companion '14: Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces","","978-1-4503-2729-9","","","","It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.","2014","2021-02-15 21:33:26","2021-02-15 21:33:26","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93TB99BB","conferencePaper","2016","Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Moncur, Wendy; McNaney, Roisin; Vines, John; Branham, Stacy","Ethical Encounters in Human-Computer Interaction","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2856498","https://doi.org/10.1145/2851581.2856498","In the HCI community, there is growing recognition that a reflective and empathetic approach is needed to conduct ethical research in sensitive settings with people who might be considered vulnerable or marginalized. At our CHI 2015 workshop on ethical encounters, researchers shared personal stories of the challenges and tensions they have faced when conducting HCI research in complex settings such as hospitals, with young mental health patients, in schools for children with disabilities, and with homeless people. These research contexts can present significant challenges for HCI researchers who would not typically receive the training that other professionals working in these environments would normally receive. From our discussions with attendees at the CHI 2015 workshop, we identified a number of ethical issues that researchers are grappling with. In this follow-up workshop we aim to build on the lessons learned and to generate pragmatic but sensitive solutions to manage complex ethical issues for HCI researchers working in challenging settings.","2016","2021-02-15 21:33:26","2021-02-15 21:33:26","","3387–3394","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","ethics; sensitive settings; vulnerable participants","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVYNGD5F","bookSection","2017","Van Mechelen, Maarten; Høiseth, Marikken; Baykal, Gökçe Elif; Van Doorn, Fenne; Vasalou, Asimina; Schut, Alice","Analyzing Children's Contributions and Experiences in Co-Design Activities: Synthesizing Productive Practices","Proceedings of the 2017 Conference on Interaction Design and Children","978-1-4503-4921-5","","","https://doi.org/10.1145/3078072.3081314","Today, it has been broadly acknowledged in the CCI community that children are not only active learners and users of technology, but can also actively participate in the design process. However, it remains challenging to analyze children's experiences and creative contributions resulting from co-design activities (e.g. stories, paper prototypes, enacted ideas). Broadly speaking, a distinction can be made between researchers looking for inspiration in the form of useful design ideas, and researchers that take a more interpretative stance by looking beyond the surface level of children's ideas to better understand and empathize with them. This knowledge about children is often used to more accurately define the problem space at the early stages of design. Both perspectives to co-design can be seen as the opposite ends of the same continuum, and many researchers combine aspects of both depending on where they are in the design process (e.g. defining the design problem, prototyping stage). This workshop will explore different ways to analyze children's (0 to 18 years) experiences and contributions in co-design activities, the perceived benefits and challenges of these approaches, and will serve as a venue for synthesizing productive practices that will move the CCI community forward.","2017","2021-02-15 21:33:26","2021-02-15 21:33:26","","769–772","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWRXC629","journalArticle","2014","Tracey, Ryan","The Agony or the Empathy? An Interview with Anne Bartlett-Bragg","ELearn","","","10.1145/2578511.2576869","https://doi.org/10.1145/2578511.2576869","Anne Bartlett-Bragg holds a unique space in eLearning as both a researcher and a practitioner. In this interview, Anne discusses the importance of immersion. By empathizing with the learner, one can truly design the best solution.","2014-02","2021-02-15 21:33:26","2021-02-15 21:33:26","","","","2","2014","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFC2DJVR","conferencePaper","2018","Itenge-Wheeler, Helvi; Winschiers-Theophilus, Heike; Soro, Alessandro; Brereton, Margot","Child Designers Creating Personas to Diversify Design Perspectives and Concepts for Their Own Technology Enhanced Library","Proceedings of the 17th ACM Conference on Interaction Design and Children","978-1-4503-5152-2","","10.1145/3202185.3202760","https://doi.org/10.1145/3202185.3202760","We report on a participatory design project that explored the use of child-created Personas to enable child designers to empathize with other children thereby contributing multiple divergent perspectives. The ongoing project aims to promote reading and creative writing skills among young children in Namibia. For decades libraries worldwide have been the key actors in fostering reading. Hence, in order to maintain their relevance, they are being re-conceptualized to cater for new needs and aspirations in the 21st century. In Namibia, dysfunctional public and school library services are lagging behind in this renovation effort, and are not contributing to the promotion of a reading culture. In an ongoing collaboration with a school in Windhoek, to design and implement an interactive tech library, 19 young learners engaged in weekly participatory design workshops to redesign their own school library. The children first created four distinct Personas for which they then modelled spaces and technologies. This paper reflects on the techniques used to enable children to become active design partners and to gain an understanding of designing for other children.","2018","2021-02-15 21:33:26","2021-02-15 21:33:26","","381–388","","","","","","","IDC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","children; design; participatory design; interactive tech library; Namibia; persona; reading experiences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGBJ8FFX","bookSection","2017","Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Branham, Stacy; Moncur, Wendy; McNaney, Roisin; Vines, John","Ethical Encounters in HCI: Implications for Research in Sensitive Settings","Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4656-6","","","https://doi.org/10.1145/3027063.3027089","This workshop builds on the success of prior workshops that brought together HCI researchers to share stories about ethical challenges faced when conducting research in sensitive settings. There is growing recognition that reflective and empathetic approaches are needed to conduct ethical research in settings involving people who might be considered vulnerable or marginalized. At our previous workshops, researchers discussed personal experiences and described the complex challenges they have faced in research as diverse as designing information systems for families of children in palliative care to analyzing social media posts about mental health. In this follow-up workshop we aim to extend opportunities for knowledge-sharing, build on the lessons learned, and generate a range of resources to help HCI researchers manage complex ethical issues when working in sensitive settings.","2017","2021-02-15 21:33:26","2021-02-15 21:33:26","","518–525","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R74UT9CI","conferencePaper","2015","Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia","Designing a Socially Assistive Robot for Pediatric Care","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771923","https://doi.org/10.1145/2771839.2771923","We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.","2015","2021-02-15 21:33:26","2021-02-15 21:33:26","","387–390","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFQ5FV3D","conferencePaper","2016","Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia","Affect-Aware Student Models for Robot Tutors","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration.In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models.These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.","2016","2021-02-15 21:33:27","2021-02-15 21:33:27","","864–872","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","affective computing; child-robot interaction; socially assistive robots; educational robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WW8G3BZS","conferencePaper","2010","Chen, Yu-Chung; Lee, Sangyoon; Hur, HyeJung; Leigh, Jason; Johnson, Andrew; Renambot, Luc","Case Study: Designing an Advanced Visualization System for Geological Core Drilling Expeditions","CHI '10 Extended Abstracts on Human Factors in Computing Systems","978-1-60558-930-5","","10.1145/1753846.1754206","https://doi.org/10.1145/1753846.1754206","We present the design and process of an interactive high-resolution visualization system for diverse and distributed real-world geological core drilling expeditions. The high domain knowledge barrier makes it difficult for a person who is outside this field to imagine the user experience, and the globally distributed core drilling community imposes more design constraints in space and time. In addition to activities proposed in prior literatures, we used the ""immersive empathic design"" approach of having a computer scientist trained as a junior core technician. Through in-situ observation and interview evaluations from on-going expeditions, we present the system and the lesson learned in the process. It makes the best use of precious co-located opportunities. It allows the developer to build up domain knowledge efficiently. It establishes a trust relationship between the developer and scientists. The system designed through this approach formed a sustainable foundation that was adapted in the following design iterations. This process allows the software developer to experience authentic user activities. The designed system is innovative and helps scientists solving real-world problems. This approach can be a useful example to HCI practitioners who work with potential users or communities that share similar properties.","2010","2021-02-15 21:33:27","2021-02-15 21:33:27","","4645–4660","","","","","","","CHI EA '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, Georgia, USA","","","","empathic design; visualization; hci","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHYV6K9N","conferencePaper","2014","Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid","Werewolves, Cheats, and Cultural Sensitivity","Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-2738-1","","","","MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.","2014","2021-02-15 21:33:27","2021-02-15 21:33:27","","1085–1092","","","","","","","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Paris, France","","","","empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSLE727F","conferencePaper","2013","Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth","Towards Empathic Artificial Tutors","Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction","978-1-4673-3055-8","","","","In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.","2013","2021-02-15 21:33:27","2021-02-15 21:33:27","","113–114","","","","","","","HRI '13","","","","IEEE Press","","","","","","","","","event-place: Tokyo, Japan","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKXXA6DI","conferencePaper","2020","Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio","DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI","Proceedings of the International Conference on Advanced Visual Interfaces","978-1-4503-7535-1","","10.1145/3399715.3399820","https://doi.org/10.1145/3399715.3399820","Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.","2020","2021-02-15 21:34:46","2021-02-15 21:34:46","","","","","","","","","AVI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salerno, Italy","","","","Computer Vision; Deep Learning; User Emotions; User Experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K5HDB4A","bookSection","2017","Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama","A New Chatbot for Customer Service on Social Media","Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems","978-1-4503-4655-9","","","https://doi.org/10.1145/3025453.3025496","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.","2017","2021-02-15 21:34:46","2021-02-15 21:34:46","","3506–3510","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZC7YBD3E","bookSection","2018","Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama","Touch Your Heart: A Tone-Aware Chatbot for Customer Care on Social Media","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","","https://doi.org/10.1145/3173574.3173989","Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.","2018","2021-02-15 21:34:46","2021-02-15 21:34:46","","1–12","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYLEZU3Q","bookSection","2020","Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph","Reputation Agent: Prompting Fair Reviews in Gig Markets","Proceedings of The Web Conference 2020","978-1-4503-7023-3","","","https://doi.org/10.1145/3366423.3380199","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.","2020","2021-02-15 21:34:46","2021-02-15 21:34:46","","1228–1240","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJEKT9CE","conferencePaper","2019","Zhou, Michelle X.","Getting Virtually Personal: Making Responsible and Empathetic ""Her"" for Everyone","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3308445","https://doi.org/10.1145/3301275.3308445","Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world.Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent.I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.","2019","2021-02-15 21:34:46","2021-02-15 21:34:46","","i","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina del Ray, California","","","","computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NSIHTE8","conferencePaper","2015","Putnam, Cynthia; Dahman, Maria; Rose, Emma; Cheng, Jinghui; Bradford, Glenn","Teaching Accessibility, Learning Empathy","Proceedings of the 17th International ACM SIGACCESS Conference on Computers &amp; Accessibility","978-1-4503-3400-6","","10.1145/2700648.2811365","https://doi.org/10.1145/2700648.2811365","As information and communication technologies (ICTs) become more diffuse, the diversity of users that designers need to consider is growing; this includes people with disabilities and aging populations. As a result, computing education must provide students the means and inspiration to learn about inclusive design. This poster presents top-level findings from 18 interviews with professors from some of the top universities in the US. Our analysis yielded four categories of findings: (1) important student learning outcomes (the most common was for students to embrace diversity); (2) exercises and teaching materials (almost all focused on inclusion of people with disabilities in discovery and evaluation of ICTs); (3) frustrations and challenges (largely focused on how to engage students in accessibility topics); and (4) the importance of instructor initiative to include the topic of accessibility in their teaching. The unifying theme was the high importance of cultivating empathy with end users.","2015","2021-02-15 21:34:47","2021-02-15 21:34:47","","333–334","","","","","","","ASSETS '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Lisbon, Portugal","","","","accessibility; pedagogy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPVGNEH2","conferencePaper","2014","Slovák, Petr","Supporting Teaching and Learning of Situational Empathy by Technology","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2559957","https://doi.org/10.1145/2559206.2559957","Detecting and supporting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, most of this work is still based primarily on single persons' data, and there is little research on supporting complex interpersonal aspects such as empathy. To address this gap, the goal of my PhD work is to explore ways in which technology can facilitate learning and teaching of situational empathy, with particular focus on counselling students.","2014","2021-02-15 21:34:47","2021-02-15 21:34:47","","315–318","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","feedback; empathy; bio-sensors; mixed methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HADPMHHX","conferencePaper","2017","Polignano, Marco; Basile, Pierpaolo; Rossiello, Gaetano; de Gemmis, Marco; Semeraro, Giovanni","Learning Inclination to Empathy from Social Media Footprints","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","978-1-4503-4635-1","","10.1145/3079628.3079639","https://doi.org/10.1145/3079628.3079639","In recent years we are witnessing a growing spread of social media footprints, as the consequence of the wide use of applications such as Facebook, Twitter or LinkedIn, which allow people to share content that might provide information about personal preferences and aptitudes. Among the traits that can be inferred, empathy is the ability to feel and share another person's emotions and we consider it as a relevant aspect for the profiling and recommendation tasks. We propose a method that predicts its level for the user by exploiting her social media data and using linear regression algorithms. The results show which are the most relevant correlations among the different groups of user's features and the empathy level predicted.","2017","2021-02-15 21:34:47","2021-02-15 21:34:47","","383–384","","","","","","","UMAP '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bratislava, Slovakia","","","","machine learning; empathy; social medium footprint","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S682VLKW","journalArticle","2019","Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana","Empathic Robot for Group Learning: A Field Study","J. Hum.-Robot Interact.","","","10.1145/3300188","https://doi.org/10.1145/3300188","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.","2019-03","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","1","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M368LV3J","conferencePaper","2019","Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad","Multimodal Learning for Identifying Opportunities for Empathetic Responses","2019 International Conference on Multimodal Interaction","978-1-4503-6860-5","","10.1145/3340555.3353750","https://doi.org/10.1145/3340555.3353750","Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.","2019","2021-02-15 21:34:47","2021-02-15 21:34:47","","95–104","","","","","","","ICMI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Suzhou, China","","","","machine learning; empathy; human behavior; multimodal sentiment; virtual human","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52QT45DQ","conferencePaper","2017","De Lira, Carla","Improving the Learning Experiences of First-Year Computer Science Students with Empathetic IDEs","Proceedings of the 2017 ACM Conference on International Computing Education Research","978-1-4503-4968-0","","10.1145/3105726.3105742","https://doi.org/10.1145/3105726.3105742","Computer science has the highest dropout rate among undergraduate STEM degree programs. This is especially concerning, given that computer science-related jobs are projected to grow 12% in the next six years. One contributing factor is that media representations of computer science can lead underrepresented groups to perceive themselves as unfit for the discipline, and ultimately to drop out. To address this concern, I propose an empathetic IDE model that uses affective computing technologies to promote empathy among computer science students. A quasi-experimental research design will be used to evaluate the model's effectiveness in fostering a supportive community between instructors and students. By leveraging emotional learning process data as a form of constant feedback to both instructors and students, this research can gain new insights into how to improve learning environments for computer science students with or without affective computing technologies.","2017","2021-02-15 21:34:47","2021-02-15 21:34:47","","293–294","","","","","","","ICER '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tacoma, Washington, USA","","","","affective computing; computer science education; empathy in computer science; learning analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IDAMGN22","conferencePaper","2016","Bratitsis, Tharrenos","A Digital Storytelling Approach for Fostering Empathy Towards Autistic Children: Lessons Learned","Proceedings of the 7th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion","978-1-4503-4748-8","","10.1145/3019943.3019987","https://doi.org/10.1145/3019943.3019987","In this paper a case study in which interactive digital storytelling was exploited for fostering empathy towards children with Autism Spectrum Disorders (ASD) is presented. The research population consisted mainly by Kindergarten children. Based on the findings and the overall experience, even considering the design mistakes that occurred, this paper argues upon the deriving value of exploiting multimodal digital representations in the form of a story in order to cultivate empathy towards children with ASD and thus, facilitate social interaction and inclusion. This approach can be useful in mixed population classrooms, but in a wider educational context as well.","2016","2021-02-15 21:34:47","2021-02-15 21:34:47","","301–308","","","","","","","DSAI 2016","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vila Real, Portugal","","","","Empathy; ASD; Digital Storytelling; Inclusion; Kindergarten; Social Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4VQ2Q34","conferencePaper","2014","Villarica, Ryan; Richards, Deborah","Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds","Proceedings of the 2014 Conference on Interactive Entertainment","978-1-4503-2790-9","","10.1145/2677758.2677761","https://doi.org/10.1145/2677758.2677761","Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.","2014","2021-02-15 21:34:47","2021-02-15 21:34:47","","1–9","","","","","","","IE2014","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Newcastle, NSW, Australia","","","","Empathic Agents; Omosa; Virtual Learning Environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CHIIKML","conferencePaper","2010","Lee, Myunghee; Kim, Gerard J.","Empathetic Video Experience through Timely Multimodal Interaction","International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction","978-1-4503-0414-6","","10.1145/1891903.1891948","https://doi.org/10.1145/1891903.1891948","In this paper, we describe a video playing system, named ""Empatheater,"" that is controlled by multimodal interaction. As the video is played, the user must interact and emulate predefined video ""events"" through multimodal guidance and whole body interaction (e.g. following the main character's motion or gestures). Without the timely interaction, the video stops. The system shows guidance information as how to properly react and continue the video playing. The purpose of such a system is to provide indirect experience (of the given video content) by eliciting the user to mimic and empathize with the main character. The user is given the illusion (suspended disbelief) of playing an active role in the unraveling video content. We discuss various features of the newly proposed interactive medium. In addition, we report on the results of the pilot study that was carried out to evaluate its user experience compared to passive video viewing and keyboard based video control.","2010","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","","","","","","ICMI-MLMI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Beijing, China","","","","empathy; user experience; interactive video; multimodality; user guidance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6JBDVST","bookSection","2020","Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri","Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419900","Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.","2020","2021-02-15 21:34:47","2021-02-15 21:34:47","","262–266","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5AHCI4R","conferencePaper","2020","Spitale, Micol; Garzotto, Franca","Towards Empathic Conversational Interaction","Proceedings of the 2nd Conference on Conversational User Interfaces","978-1-4503-7544-3","","10.1145/3405755.3406146","https://doi.org/10.1145/3405755.3406146","In recent years, ""computational empathy"" has emerged as a new challenging research field. Computational empathy investigates how artificial agents can manifest empathic behaviours towards the user, and how they can elicit empathy during the human-agent interaction. Such ""empathic agents"" have the capacity to place themselves into the emotional position of a user (or another agent), and behave taking such emotional understanding into account. The paper explores a computational empathy approach in the context of conversational interaction, and presents an empathic conversational framework grounded on the empathy theory. The framework provides a conceptual tool for designing and evaluating empathic conversational agents. Overall, our research contributes to a deeper understanding of the role of empathy in conversational interaction.","2020","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","","","","","","CUI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bilbao, Spain","","","","Empathy; Artificial Agents; Computational Empathy; Conversational Interaction; Framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IW9PVKNW","conferencePaper","2017","Pantela, Nicoletta; Kyza, Eleni A.","The Investigation of Concept Mapping as a Scaffolding Tool in a Technologically-Mediated, Mobile Learning, Augmented Reality Environment","Proceedings of the 16th World Conference on Mobile and Contextual Learning","978-1-4503-5255-0","","10.1145/3136907.3136924","https://doi.org/10.1145/3136907.3136924","This study investigated concept maps as a form of support for primary school students' development of conceptual understanding, historical empathy, and for promoting collaborative learning. Students used the same historical learning augmented reality application on a mobile device, worked in pairs, and were divided in two conditions: the experimental group (n=12), supported by a tablet-based concept mapping tool, and the control group (n=11), who only used the learning application on the same mobile devices. The results showed that the experimental group students gained a deeper conceptual understanding after the visit, as evidenced by their concept maps and their discussions during their visit.","2017","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","","","","","","mLearn 2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Larnaca, Cyprus","","","","informal learning; computer-supported collaborative learning; concept maps; Scaffolding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVQSVE6I","conferencePaper","2020","Yu, Borou; Zhou, Tiange; Wang, Zeyu; Min, Jiajian","The World of Freedom","SIGGRAPH Asia 2020 Art Gallery","978-1-4503-8108-6","","10.1145/3414686.3427172","https://doi.org/10.1145/3414686.3427172","Indeed, people spend more time on deep thinking since 2020. The questions which ask mainly by the sociologists, now become the topics on the dining table. The debates on social and moral dilemmas are happening intensively 24 hours on the internet. We started to think more about who we are, where we are going, and how we will value the information we have received. Do we have freedom? Shall we believe absolute freedom? Sometimes people directly transform the idea of liberty into democracy. However, shall we also equal freedom to democracy? Since we are all inside this one pandemic bubble, after most people stay at home for a couple of months, we start emerging a global-size collective memory, which makes people more empathetically understand others' situations. Meanwhile, more and more people have to learn and take experience virtually. The attention of empathy and the new work-from-home mode evokes the initial idea of this virtual reality experience. We start to ask how people could learn and think more effectively in this brand new virtual age? Unity program makes this innovation possible. The innovative architecture modeling could permit a large group of people to experience personal space and sharing areas simultaneously. The sound design is specially designed for the various space sound and the audience's interactivities. We use this program to build up an immersive and empathetic space that embodies a hypothetical argument of a social dilemma into a virtual manifestation. People might be able to figure out the most meaningful answer by wearing the same shoes. The social distance could also be virtually controlled in this program by counting if the number of participates overload spaces.","2020","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","","","","","","SA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Republic of Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPM6ZWUT","conferencePaper","2011","Adams, Anne; Coughlan, Tim; Lea, John; Rogers, Yvonne; Davies, Sarah; Collins, Trevor","Designing Interconnected Distributed Resources for Collaborative Inquiry Based Science Education","Proceedings of the 11th Annual International ACM/IEEE Joint Conference on Digital Libraries","978-1-4503-0744-4","","10.1145/1998076.1998152","https://doi.org/10.1145/1998076.1998152","This paper describes the design and evaluation of a distributed information resource system (IRS) shared between field and laboratory settings for higher education geology students. An investigation of geo-science scholarship and technical pilot studies highlighted the importance of situational specific and distributed information usage. To advance our understanding of novel resource approaches (i.e. from tabletops to tablets) and collaborative learning, two in-depth field trials evaluated 21 students' information journeys (i.e. initiating information needs, facilitating information and collaborative interpretation). Analysis identified how a designing for a varied device ecology supported information filtering and empathy between locations provoking deeper reflection and abstract understanding in the field, while live collaborative remote interaction provided an engaging yet distinct learning experience for those in the laboratory.","2011","2021-02-15 21:34:47","2021-02-15 21:34:47","","395–396","","","","","","","JCDL '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Ottawa, Ontario, Canada","","","","e-learning; design; collaborative information environment; mobile; tabletop","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6QENL6B","conferencePaper","2019","Chen, Jize; Wang, Changhong","Reaching Cooperation Using Emerging Empathy and Counter-Empathy","Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-6309-9","","","","According to social neuropsychology, the cooperative behavior is largely influenced by empathy, which is deemed essential of emotional system and has wide impact on social interaction. In the work reported here, we believe that the emergence of empathy and counter-empathy is closely related to creatures' inertial impression on intragroup coexistence and competition. Based on this assumption, we establish a unified model of empathy and counter-empathy in light of Hebb's rule. We also present Adaptive Empathetic Learner (AEL), a training method for agents to enable affective utility evaluation and learning procedure in multi-agent system. In AEL, the empathy model is integrated into the adversarial bandit setting in order to achieve a high degree of versatility. Our algorithm is first verified in the survival game, which is designed to simulate the primitive hunting environment. In this game, empathy and cooperation emerge among agents with different power. In another test about Iterated Prisoners' Dilemma, cooperation was reached even between an AEL agent and a rational one. Moreover, when confronted with hostile, the AEL agent showed sufficient goodwill and vigilantly protected its safe payoffs. In the Ultimatum Game, it's worth mentioning that absolute fairness could be achieved on account of the self-adaptation of empathy and counter-empathy.","2019","2021-02-15 21:34:47","2021-02-15 21:34:47","","746–753","","","","","","","AAMAS '19","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Montreal QC, Canada","","","","cooperation; adversarial bandit; empathy and counter-empathy; multi-agent system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSGN2K9I","conferencePaper","2013","Buckingham Shum, Simon; de Laat, Maarten; De Liddo, Anna; Ferguson, Rebecca; Kirschner, Paul; Ravenscroft, Andrew; Sándor, Ágnes; Whitelock, Denise","DCLA13: 1<sup>st</sup> International Workshop on Discourse-Centric Learning Analytics","Proceedings of the Third International Conference on Learning Analytics and Knowledge","978-1-4503-1785-6","","10.1145/2460296.2460357","https://doi.org/10.1145/2460296.2460357","This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field.","2013","2021-02-15 21:34:47","2021-02-15 21:34:47","","282","","","","","","","LAK '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Leuven, Belgium","","","","dialogue; learning analytics; argumentation; deliberation; discourse; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWAS7NI2","conferencePaper","2019","Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana","EmotoTent: Reducing School Violence through Embodied Empathy Games","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3326596","https://doi.org/10.1145/3311927.3326596","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.","2019","2021-02-15 21:34:47","2021-02-15 21:34:47","","755–760","","","","","","","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DH7Z8JS","conferencePaper","2016","Zhang, Emma Yann; Cheok, Adrian David; Nishiguchi, Shogo; Morisawa, Yukihiro","Kissenger: Development of a Remote Kissing Device for Affective Communication","Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology","978-1-4503-4773-0","","10.1145/3001773.3001831","https://doi.org/10.1145/3001773.3001831","As human communication is rapidly migrating from the physical world to the digital world, it is crucial to develop affective communication systems to enable the expression of intimacy, emotion and empathy over the Internet, as these are essential elements in forming social relationships. A multisensory, real-time kissing device, Kissenger, is developed to transmit multisensory kissing sensations remotely using mobile phones. The aim is to provide an intimate communication channel for families and friends to physically interact with each other remotely, in order to effectively convey deep emotions and intimacy through a multisensory internet communication experience.","2016","2021-02-15 21:34:47","2021-02-15 21:34:47","","","","","","","","","ACE '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Osaka, Japan","","","","affective communication; haptics; kiss transmission; multimodal communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45X22KPU","conferencePaper","2014","Vermeeren, Arnold P.O.S.; van Beusekom, Josje; Rozendaal, Marco C.; Giaccardi, Elisa","Design for Complex Persuasive Experiences: Helping Parents of Hospitalized Children Take Care of Themselves","Proceedings of the 2014 Conference on Designing Interactive Systems","978-1-4503-2902-6","","10.1145/2598510.2598548","https://doi.org/10.1145/2598510.2598548","In this paper we analyzed a case of designing for persuasive experiences. It concerns designing for the complex persuasive situation of helping parents of hospitalized children take better care of themselves. Our focus was on the experiences, on how these were designed to be persuasive, and on the design process needed to achieve that. We conclude that designing for complex persuasive experiences requires a design approach that allows for designers to gradually develop a rich understanding of the situation and develop empathy for the people they design for. We found that the persuasion should focus on a combination of starting a new practice, sustaining it, starting activities within the practice, and extending the duration of the activities. For such a complex persuasive situation a rich palette of experiences was needed. The design of those experiences was inspired by universal human needs and by gaining a deep and empathetic understanding of the situation.","2014","2021-02-15 21:34:47","2021-02-15 21:34:47","","335–344","","","","","","","DIS '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Vancouver, BC, Canada","","","","behavior change; design approach; experience design; persuasive experiences; persuasive technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYFT5TTP","conferencePaper","2019","Vertesi, Janet","Seeing like a Rover: Team Work and Human-Robot Relations","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go — in search and rescue operations, ocean voyages, or even into space — they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology.This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team.Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019","2021-02-15 21:34:48","2021-02-15 21:34:48","","152","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","human-robot interaction; teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZV9BNLEA","conferencePaper","2017","Thompson, Jeff","I Touch You and You Touch Me","SIGGRAPH Asia 2017 Art Gallery","978-1-4503-5401-1","","10.1145/3143748.3143753","https://doi.org/10.1145/3143748.3143753","A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.","2017","2021-02-15 21:34:48","2021-02-15 21:34:48","","","","","","","","","SA '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bangkok, Thailand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GN3G5D8H","conferencePaper","2014","Watanabe, Yukako; Okada, Yoshiko; Osawa, Hirotaka; Sugaya, Midori","Digital Play Therapy for Children with Learning Disabilities","Proceedings of the Second International Conference on Human-Agent Interaction","978-1-4503-3035-0","","10.1145/2658861.2658918","https://doi.org/10.1145/2658861.2658918","Children who are suffering on learning and developmental disabilities require daily trainings for social skills. However, such daily training is not provided occasionally because it requires interactive helps from therapists. In this paper, we propose a digital dollhouse that enhanced traditional psychological play therapy with digital sensors and computer graphics. The digital dollhouse provides immersive space to children which grows children's communication skill through their imaging play. This device allows non-professional like parents to make play therapy. In this paper, we show details about prototype of digital dollhouse. We also categorize requirements for digital play therapy that are given by psychological viewpoints based on the prototype. Interdisciplinary design process collaborating with engineers and psychologists shows the possibility that digital dollhouse is enough to enhance empathy of children and such empathy will be enhanced by creating immersive characters.","2014","2021-02-15 21:34:48","2021-02-15 21:34:48","","185–188","","","","","","","HAI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tsukuba, Japan","","","","human-agent interaction; human robot interaction; augmented human; emotional labor; human interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"689N7F5Q","conferencePaper","2019","Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid","BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3302290","https://doi.org/10.1145/3301275.3302290","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.","2019","2021-02-15 21:34:48","2021-02-15 21:34:48","","448–459","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina del Ray, California","","","","conversational agents; explainable AI; mechanical turk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y48LUS7T","conferencePaper","2020","El-Glaly, Yasmine; Shi, Weishi; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.","Presenting and Evaluating the Impact of Experiential Learning in Computing Accessibility Education","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training","978-1-4503-7124-7","","10.1145/3377814.3381710","https://doi.org/10.1145/3377814.3381710","Studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. Compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. To address these issues, we have created five Accessibility Learning Labs (ALL) using an experiential learning structure. The labs are designed to educate and create awareness of accessibility needs in computing. The labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. The labs are hosted on our servers and require only a browser to be utilized.To demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. Our findings include: (I) The demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (II) The labs are effective in informing students about foundational accessibility topics (III) Empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. Created labs and project materials are publicly available on the project website: http://all.rit.edu","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","49–60","","","","","","","ICSE-SEET '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, South Korea","","","","accessibility education; computing accessibility; computing education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38XZ5IMH","conferencePaper","2016","Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne","I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.","2016","2021-02-15 21:34:48","2021-02-15 21:34:48","","931–939","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","empathy; human-agent interaction; human-robot interaction; memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TS6L6YW2","conferencePaper","2020","Liu, Qinyuan","Let's Chat like This","SIGGRAPH Asia 2020 Art Gallery","978-1-4503-8108-6","","10.1145/3414686.3427118","https://doi.org/10.1145/3414686.3427118","""Let's Chat Like This"" is an interactive system that allows two people to observe each others' moods through interacting with a shared interactively generated image. The moving image changes according to the two people's facial expressions. Different from traditional ways of communication, ""Let's Chat Like This"" focuses more on the emotional aspect of communication. It shows a visualization of the complexity of human emotion and boosts people's emotional communication in a creative no-verbal way. When experiencing this work, people's emotions are bound together with the same moving image they see. The moving image changes depending on their moods. They will be aware of their current moods as well as the other's, the intimacy and empathy between them will be increased.This is not only a ""social distancing"" art installation that helps us connect emotionally during the COVID-19 pandemic, but also my hypothesis of what future emotional communication will be like. I hope this artwork can evoke deep thinking and maybe cheer people up in this challenging time.","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","","","","","","","","SA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Republic of Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZB3FZPM","conferencePaper","2018","Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Klapwijk, Remke","Developing Children's Empathy in Co-Design Activities: A Pilot Case Study","Proceedings of the 17th ACM Conference on Interaction Design and Children","978-1-4503-5152-2","","10.1145/3202185.3210797","https://doi.org/10.1145/3202185.3210797","This paper explores how co-design activities in schools can contribute to developing children's empathy. A pilot case study is presented in which eight 10- to 12-year-old children participated. The design theme was outdoor education. After discussing the co-design procedure, preliminary results about three empathic techniques are discussed: (1) reflection on the role of empathy in design, (2) storytelling to introduce the design challenge, and (3) defining the needs and wishes of the story's protagonists. The lessons learned are taken into account in a comprehensive follow-up study.","2018","2021-02-15 21:34:48","2021-02-15 21:34:48","","669–674","","","","","","","IDC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","children; empathy; storytelling; co-design; 21st century skills; schools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"296ZIL5L","conferencePaper","2013","Shanahan, Joseph; Marghitu, Daniela","Software Engineering Java Curriculum with Alice and Cloud Computing","Proceedings of Alice Symposium on Alice Symposium","978-1-4503-2250-8","","10.1145/2532333.2532337","https://doi.org/10.1145/2532333.2532337","Project Expression is a course designed to attract students into the field of computing. Participants are trained in Java programming and the art of multimedia production. By implementing a wide range of apps they learn cloud communication techniques in a software environment. The course focuses on a digital film project and participants are challenged with creating a movie that expresses an idea, opinion, or belief relative to society. The film project is a landscape for learning cloud-computer-programming and reaches across the computer spectrum with engaging activities that stimulate creative design. This study examines the curriculum's approach and measures its effectiveness to teach the cloud-computing mentality. It emphasizes the importance of empathy in a technology-based society. Furthermore, it investigates whether or not such a course is an effective method for attracting students into the field of computing.","2013","2021-02-15 21:34:48","2021-02-15 21:34:48","","","","","","","","","ALICE '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Durham, NC, USA","","","","3D animations; 3D Visualization; Computers and Empathy; K-12 Computer Science Curriculum; K12 Alice Curriculum; K12 Cloud Computing Curriculum; Movie-making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3ANZ9SI","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: A Living Media Interface for Speech Intervention","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-2473-1","","10.1145/2556288.2557402","https://doi.org/10.1145/2556288.2557402","Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.","2014","2021-02-15 21:34:48","2021-02-15 21:34:48","","1817–1820","","","","","","","CHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","embedded computing; living media interfaces; speech intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X67QZBM7","conferencePaper","2020","de Oliveira, Lariza Laura","Mapping Empathy in the Computer Science Classroom","Proceedings of the 2020 ACM Conference on International Computing Education Research","978-1-4503-7092-9","","10.1145/3372782.3408109","https://doi.org/10.1145/3372782.3408109","Empathy is a humanistic skill, a capacity that allows us to perceive other people's emotions, putting ourselves under their perspective [1]. The study of empathy is highlighted as a tool to provide a better understanding of people's thoughts, feelings and how they affect behavior [2]. Being aware of that, a design company created the Empathy Map (EM), which is usually employed in the initial phase of the Design Thinking process to understand user's concerns, feelings and aspirations [3].Teaching practices known as student-centered, inherited from the constructivist school, are not new [4]. Several educators have applied these approaches inside the Computer Science (CS) classroom [5]. A key to success in CS education is the construction of the computational thinking [5]. Learning to program is not an easy task and the process is surrounded by several emotional reactions such as frustration, anxiety, happiness and others [6]. In this sense, EMs can be useful to capture student's feelings, guiding educators strategies during CS classes.Here, I describe the experience of using the EM inside the Computer Science classroom at the University Center Barão de Mauá. The process of building EMs involves the description of the persona, who, in this case, are the students of a given year in the CS course. In the center of EM, the picture of a student is drawn and the surrounding region is divided into 4 areas [3, 7]: 1) THINK and FEEL - What are the students thinking/feeling? 2) HEAR and SEE - What are the students hearing/seeing? 3) SAY and DO - What are the students saying/doing? 4) PAIN/CHALLENGES and GAINS - What are the challenges the students are facing? Is there anything painful to do? How do they measure success?The EM was performed in two different stages of the CS course: in the first and third years. The students were asked to build the EM, representing their feelings and aspirations about CS. The EM of the first year showed: 1) THINK and FEEL - ""thinking about the future"", ""feeling fear"", ""curiosity"", ""insecurity"", ""confusion"". 2) HEAR and SEE - "" hearing positive statements from family and friends"", ""seeing themselves in a trainee program"", ""working or doing a master's degree"", ""developing themselves"". They also reported to hear that CS is very difficult. 3) SAY and DO - They say learning is difficult, They do study and work; 4) PAIN/CHALLENGES - they report feeling insecure about finishing the course and find a position. The main challenge is to conciliate both working and studies. The students of the third year reported: 1) THINK and FEEL - ""thinking about the future"", ""feeling anxiety"", ""anger"", ""tiredness"", ""worry""; 2) HEAR and SEE - "" they hear that CS is a promising career"", ""see opportunities and/or lack of them"". They reported hear questions about what they will do in the future; 3) SAY and DO - ""procrastinating and working""; 4) PAIN/CHALLENGES - The pain reported refers to the anxiety of completing the course and the excessive procrastination. The main challenge reported was to set medium/short term goals as study to complete tasks in the CS course.As a conclusion, we highlight that the first year students were more motivated about their future, whereas the third year are tired and anxious about finishing the course. The EM construction was able to show student's feelings and pains about the course, allowing the educator to capture the student's perspectives. Based on that, it may be possible to conduct a more appropriate learning plan to manage how emotional aspects can influence the learning process. As a future work, EM will be used along with specific subjects in a qualitative study, considering subjects with highest failure rates in CS curriculum.","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","303","","","","","","","ICER '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, New Zealand","","","","computer science education; empathy map","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Q73QDE3","conferencePaper","2019","Liu, Fannie","Expressive Biosignals: Authentic Social Cues for Social Connection","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3299081","https://doi.org/10.1145/3290607.3299081","My research introduces expressive biosignals as a novel social cue to improve interpersonal communication. Expressive biosignals are sensed physiological data revealed between people to provide a deeper understanding of each other's psychological states. My prior work has shown the potential for these cues to provide authentic and validating emotional expression, while fostering awareness and social connection between people. In my proposed research, I expand on this work by exploring how social responses to biosignals can benefit communication through empathy-building and social support. This work will scope the design space for expressive biosignals and inform future interventions for a variety of social contexts, including interpersonal relationships and mental health.","2019","2021-02-15 21:34:48","2021-02-15 21:34:48","","1–5","","","","","","","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","social cues; biosignals; interpersonal communication; physiological sensing; social connection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4ZVLSQU","journalArticle","2020","McDonald, Nora; Pan, Shimei","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3415218","https://doi.org/10.1145/3415218","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.","2020-10","2021-02-15 21:34:48","2021-02-15 21:34:48","","","","CSCW2","4","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","artificial intelligence; ethics; algorithm bias; education; intersectionality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TB6GNWYZ","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: A Living Media Interface for Learning Games","CHI '14 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-2474-8","","10.1145/2559206.2574772","https://doi.org/10.1145/2559206.2574772","Digital games can engage children in therapeutic and learning activities. Incorporating living media in these games can create feelings of empathy and caring in users and add more motivation and involvement to the gameplay. We present, Rafigh, a living media interface designed to motivate children to play learning games that involve repetitive and sometimes boring tasks. In the current implementation the interface is used for speech intervention games. During gameplay, children practice their speech and care for a living mushroom colony in the process. The mushroom's growth is used to communicate how much speech is used, as an indicator of degree of speech practice, during interaction.","2014","2021-02-15 21:34:48","2021-02-15 21:34:48","","407–410","","","","","","","CHI EA '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Toronto, Ontario, Canada","","","","embedded computing; living media interfaces; speech intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMZ4J7F5","conferencePaper","2012","Benkler, Yochai","The Penguin and the Leviathan: Towards Cooperative Human Systems Design","Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work","978-1-4503-1086-4","","10.1145/2145204.2145206","https://doi.org/10.1145/2145204.2145206","A decade ago, Wikipedia burst into a world not ready to comprehend it. Thousands of people cooperating effectively, without price signals to offer 'incentives' or managerial hierarchy to direct efforts, was an impossibility. And yet, it moves. And as it moved it combined with a deep shift across many disciplines, from biology and neuroscience to organizational sociology, experimental economics, and social psychology to paint a very different view of who we are as human beings. Slowly pushing back against decades of ever-refined analyses based on self-interested rationality, we begin to see that we are diverse beings; that a majority of us responds cooperatively to cooperative settings–we tend to treat well those who have treated us well, rather than take advantage of them; we tend to do what we think is right and fair, when it is clear in the setting what that is; we experience empathy, and it makes us more generous and trustworthy; we experience solidarity with others, and that makes us contributed more willingly to the group's goals. Moreover, explicit payments, the touchstone of mechanism design under universal self-interested rationality, turns out to have a much more complex relationship with motivation than simple addition. All this work in basic behavioral sciences combines with observations from organizational sociology, political science, and management studies combines with social software to provide an increasingly better articulated basis on which to develop a field of cooperative human systems design.","2012","2021-02-15 21:34:48","2021-02-15 21:34:48","","1–2","","","","","","","CSCW '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington, USA","","","","cooperative human systems design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F7X2N6UI","conferencePaper","2020","Vennekens, Joost","Service-Learning for Web Technology: Observations from a Small Case Study","Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education","978-1-4503-6874-2","","10.1145/3341525.3387414","https://doi.org/10.1145/3341525.3387414","In the past academic year, we conducted an experiment at using service-learning in order to integrate learning of empathy and creativity into an undergraduate course on Web Technology. This was a small scale pilot project, conducted in collaboration with the service-learning team at our institute. In the project, students collaborated with WAI-NOT, a non-profit organization that develops an online platform for children with various kinds of (physical/mental) disabilities. The students developed new ""games"" for this platform, to teach the children basic computer skills (e.g., clicking, moving the mouse). Key in this project was the interaction between the students, the non-profit and the target audience. Due to the small size of the class, we did not conduct a quantitative evaluation of the project, but we do discuss the experiences and feedback from teachers, students and community.","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","328–334","","","","","","","ITiCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","computer science education; service-learning; experience report","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JS6KKSH9","conferencePaper","2019","Suzianti, Amalia; Atthousi, Hajid Naufal","Implementation of Design Thinking Approach In Designing Learning Support Tools In The Classroom For Hearing Impaired Person: Case Study: Elementary School Students in SLB-B Santi Rama","Proceedings of the 2019 5th International Conference on E-Business and Mobile Commerce","978-1-4503-7182-7","","10.1145/3332324.3332338","https://doi.org/10.1145/3332324.3332338","The absence of adequate accommodation for the hearing-impaired in the Education field is one of the problems in Indonesia nowadays. Teaching aids or learning support tools as accommodation can help the deaf to accelerate and improve the quality of their education. This research uses design thinking approach in designing the tool so that the result of the design is in accordance with the needs and desires of the users, which are deaf elementary students age 8-10. Started from the empathy phase until the define phase which obtained that the target users have a need and desire to learn the vocabulary with ease and fun then proceed with the ideation phase with stakeholders and prototyping to generate ideas and create the teaching aids in accordance with their needs and desires in the form of an arcade game with card of words and ended with the testing phase which shows that the tool is able to improve visual receptive language comprehension of 8.07% and visual expressive language of 77.74% in a fun way. This research has produced a teaching aids designed with design thinking approach which can improve the quality of their learning in school in accordance with the needs and desires of hearing-impaired elementary school students and has been validated by stakeholders.","2019","2021-02-15 21:34:48","2021-02-15 21:34:48","","75–80","","","","","","","ICEMC 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Taichung, Taiwan","","","","Design Thinking; Deaf Children; Hearing-impaired; Inclusive Design; Learning Support Tools; Persona","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFRR6FNB","conferencePaper","2020","Shi, Weishi; Khan, Saad; El-Glaly, Yasmine; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.","Experiential Learning in Computing Accessibility Education","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings","978-1-4503-7122-3","","10.1145/3377812.3390901","https://doi.org/10.1145/3377812.3390901","Many developers don't understand how to, or recognize the need to develop accessible software. To address this, we have created five educational Accessibility Learning Labs (ALL) using an experiential learning structure. Each of these labs addresses a foundational concept in computing accessibility and both inform participants about foundational concepts in creating accessible software while also demonstrating the necessity of creating accessible software. The hosted labs provide a complete educational experience, containing materials such as lecture slides, activities, and quizzes.We evaluated the labs in ten sections of a CS2 course at our university, with 276 students participating. Our primary findings include: I) The labs are an effective way to inform participants about foundational topics in creating accessible software II) The labs demonstrate the potential benefits of our proposed experiential learning format in motivating participants about the importance of creating accessible software III) The labs demonstrate that empathy material increases learning retention. Created labs and project materials are publicly available on the project website: http://all.rit.edu","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","250–251","","","","","","","ICSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, South Korea","","","","accessibility education; computing accessibility; computing education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SALDPL5B","bookSection","2020","Tiwari, Divyanshu","Fostering Collaboration and Empathy Through Games","Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","","https://doi.org/10.1145/3383668.3419929","Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.","2020","2021-02-15 21:34:48","2021-02-15 21:34:48","","91–93","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMY3TEIV","conferencePaper","2018","Lyckvi, Sus; Torgersson, Olof","Privacy and Design Ethics vs Designing for Curiosity, Communication and Children: Lessons Learned","Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services","978-1-4503-5898-9","","10.1145/3229434.3229480","https://doi.org/10.1145/3229434.3229480","This paper describes the lessons learned when designing an empathy-oriented image-exchange app for fifth-grade pupils. The aim was to evoke curiosity and empathy towards someone living elsewhere or under different socio-economic circumstances. In addition, we strived to apply design ethics (e.g. protecting users from insults, humiliation, inappropriate content etc) and take users' privacy into account. By setting up these boundaries for this user group we found ourselves confronted with a set of conflicting design decisions which ultimately led to a lesser and different user experience than we had expected. Here, we discuss the interplay between our design decisions and the consequences thereof, and evaluate the mistakes we made. Moreover we discuss how to balance anonymity and curiosity, and comment on the benefits of making a pre-analysis of potential clashes related to intended UX and other core design decisions.","2018","2021-02-15 21:34:48","2021-02-15 21:34:48","","","","","","","","","MobileHCI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","ethics; communication; empathy; curiosity; design for children; image sharing; privacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9DUSU9YP","journalArticle","2016","McBride, Neil","The Ethics of Driverless Cars","SIGCAS Comput. Soc.","","0095-2737","10.1145/2874239.2874265","https://doi.org/10.1145/2874239.2874265","This paper critiques the idea of full autonomy, as illustrated by Oxford University's Robotcar. A fully autonomous driverless car relies on no external inputs, including GPS and solely learns from its environment using learning algorithms. These cars decide when they drive, learn from human drivers and bid for insurance in real time. Full autonomy is pitched as a good end in itself, fixing human inadequacies and creating safety and certainty by the elimination of human involvement. Using the ACTIVE ethics framework, an ethical response to the fully autonomous driverless cars is developed by addressing autonomy, community, transparency, identity, value and empathy. I suggest that the pursuit of full autonomy does not recognise the essential importance of interdependencies between humans and machines. The removal of human involvement should require the driverless car to be more connected with its environment, drawing all the information it can from infrastructure, internet and other road users. This requires a systemic view, which addresses systems and relationships, which recognises the place of driverless cars in a connected system, which is open to the study of complex relationships, both networked and hierarchical.","2016-01","2021-02-15 21:34:48","2021-02-15 21:34:48","","179–184","","3","45","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","ethics; driverless cars; full autonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8MIHI8I","conferencePaper","2019","Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco","A Preliminary Work on Dog Emotion Recognition","IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume","978-1-4503-6988-6","","10.1145/3358695.3361750","https://doi.org/10.1145/3358695.3361750","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications.The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.","2019","2021-02-15 21:34:49","2021-02-15 21:34:49","","91–96","","","","","","","WI '19 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Thessaloniki, Greece","","","","Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HJW356N","conferencePaper","2020","Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon","Robots Teaching Recycling: Towards Improving Environmental Literacy of Children","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3379462","https://doi.org/10.1145/3371382.3379462","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.","2020","2021-02-15 21:34:49","2021-02-15 21:34:49","","615–616","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cambridge, United Kingdom","","","","educational robotics; children robot interaction; eco-literacy; environmental literacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3HKLLJX","conferencePaper","2015","Lundgren, Sus; Torgersson, Olof; Björk, Staffan","Thrimage: An Empathy-Oriented Discussion Tool for Classroom Use","Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct","978-1-4503-3653-6","","10.1145/2786567.2792901","https://doi.org/10.1145/2786567.2792901","Thrimage is a class-application where pupils choose and rank images in relation to a given word or notion. In seeing who else chose similarly, as well as in a debriefing teacher-led discussion, pupils gain insight in others' way of thinking, and learn to argument for their own opinion but also to respect others, both of which supports the development of empathy and mutual understanding. The design is part of a long-running design exploration on designing of collaborative, co-located experiences using mobile devices, in combination with an educational need.","2015","2021-02-15 21:34:49","2021-02-15 21:34:49","","628–635","","","","","","","MobileHCI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Copenhagen, Denmark","","","","empathy; image sharing; Thrimage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YG9I8DJW","conferencePaper","2015","Ostrowski, S\lawomir; Rolczyński, Rafa\l; Pniewska, Joanna; Garnik, Igor","User-Friendly E-Learning Platform: A Case Study of a Design Thinking Approach Use","Proceedings of the Mulitimedia, Interaction, Design and Innnovation","978-1-4503-3601-7","","10.1145/2814464.2814483","https://doi.org/10.1145/2814464.2814483","E-learning systems are very popular means to support the teaching process today. These systems are mainly used by universities as well as by commercial training centres. We analysed several popular e-learning platforms used in Polish universities and find them very unfriendly for the users. For this reason, the authors began the work on the creation of a new system that would be not only useful, but also usable for students, teachers and system administrators. This paper presents a case study of e-learning platform design process. We applied Design Thinking (DT) approach which puts a strong emphasis on the participation of end-users throughout the design process. Such an approach makes final product more user-friendly and better suited to end-users needs. An interdisciplinary team of designers implemented the design process in five stages: Empathizing - a thorough analysis of the problem and its context; Defining - synthesis of information obtained in the previous step and identifying user needs and insights; Ideating - generating solutions; Prototyping and Testing solutions proposed in the Ideating phase. During the design process the team used many additional methods, such as Empathy map, Stakeholders map, Value preposition canvas, personas, brainstorming, Card sorting and many more. As the result of design process we obtain an interactive prototype of designed e-learning platform. The prototype was tested by end-users and the feedback from the testers was collected. It confirmed that the use of the DT approach in design process allows to better fit designed product to the users' needs. The next step will be the implementation of tested and approved solutions to the real system what is planned in the nearest future.","2015","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","","","","","","MIDI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Warsaw, Poland","","","","e-learning; Design Thinking; design process management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWIFUKA4","conferencePaper","2019","Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Södergren, Antonia Clasina","Children's Assessment of Co-Design Skills: Creativity, Empathy and Collaboration","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3325334","https://doi.org/10.1145/3311927.3325334","This paper presents a co-design project in a school with 16 children ages 10 to 11 in which three learning goals were defined upfront: creativity, empathy, and collaboration. The first part of the paper demonstrates how these co-design skills were implemented through an iterative process of explanation, practice, reflection, and application. Based on the results of post-interviews and short questionnaires, the second part discusses children's assessments of these skills. Whereas children reported fluctuations in applying these skills, the findings show an overall positive trend towards the end of the project. In future work, these findings will be triangulated with observational data.","2019","2021-02-15 21:34:49","2021-02-15 21:34:49","","520–526","","","","","","","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","Empathy; Children; 21st Century Skills; Co-design; Collaboration; Creativity; Design-based Learning; Participatory Design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSMPEFBN","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696479","https://doi.org/10.1145/2696454.2696479","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015","2021-02-15 21:34:49","2021-02-15 21:34:49","","83–90","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7R8TVJH","bookSection","2020","Chromik, Michael; Lachner, Florian; Butz, Andreas","ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research","Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society","978-1-4503-7579-5","","","https://doi.org/10.1145/3419249.3420163","Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML’s impact on current UXR activities and practitioners’ predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users’ emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research.","2020","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJU73DT3","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","The CoWriter Project: Teaching a Robot How to Write","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702091","https://doi.org/10.1145/2701973.2702091","This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.","2015","2021-02-15 21:34:49","2021-02-15 21:34:49","","269","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F9GKDGWZ","conferencePaper","2017","Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin","Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3139132","https://doi.org/10.1145/3139131.3139132","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.","2017","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","pet game; user types; virtual pet; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPKGJSC4","conferencePaper","2015","Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung","Design of Emotional Conversations with a Child for a Role Playing Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702009","https://doi.org/10.1145/2701973.2702009","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.","2015","2021-02-15 21:34:49","2021-02-15 21:34:49","","73–74","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","emotional role playing robot; human intervention device; human-robot-interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9F3UJ6HN","conferencePaper","2019","Kawano, Atsuko; Motoyama, Yuji; Aoyama, Mikio","A LX (Learner EXperience)-Based Evaluation Method of the Education and Training Programs for Professional Software Engineers","Proceedings of the 2019 7th International Conference on Information and Education Technology","978-1-4503-6639-7","","10.1145/3323771.3323789","https://doi.org/10.1145/3323771.3323789","We propose a new design methodology to maximize the training effect in a corporate education and training for professional software engineers. Conventionally, the education and training programs have been designed in a top-down manner based on the long-term strategy on the business and engineering resources development. However, to draw out the learners' high performance from the education and training programs, we need to have an empathy with the learners, and to analyze their expectations and emotions in order to motivate them. Therefore, this paper proposes the learner-centered design methodology of the corporate education and training programs inspired by the design thinking and lean start-up concepts. We define the learning processes in the education and training programs as LX (Learner eXperience), and propose LJM (Learning Journey Map) as the LX evaluation method as an extension of CJM (Customer Journey Map) in UX (User eXperience) design. The LJM enables to evaluate training effect and communicate with stakeholders in the training design expressing the LX quantitatively in a visual form. We applied the proposed design methodology to the education and training programs for professional software engineers in a company to evaluate LX and elicit learner requirements to the programs. We applied the proposed LJM to the education and training program of two levels of the whole program and its LUs (Learning Units), and identified problems in the LX. From the empirical study, we confirm the effectiveness of the proposed methodology.","2019","2021-02-15 21:34:49","2021-02-15 21:34:49","","151–159","","","","","","","ICIET 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aizu-Wakamatsu, Japan","","","","Design thinking; Corporate education and training program; Journey map; Lean start-up; LX (Learner eXperience); Professional software engineer; UX (User eXperience)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R8SS987J","conferencePaper","2016","Fan, Mingyue; Yu, Liyue; Bowler, Leanne","Feelbook: A Social Media App for Teens Designed to Foster Positive Online Behavior and Prevent Cyberbullying","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2892398","https://doi.org/10.1145/2851581.2892398","This project presents a prototype for a stand-alone social media application designed for teenage users in order to prevent and mitigate mean and cruel online behavior. The purpose of the app is to create a nurturing environment where teenagers use a variety of features designed to help raise self-awareness of their own online behavior, seek support when needed, and learn to control and, when possible, correct aggressive behavior. The prototype is framed by four design principles: design for reflection, design for empathy, design for empowerment, and design for the whole. We conclude by outlining the next steps in our project to develop an application that helps to improve the online experiences of young people. This work has implications for the CHI community because it applies software solutions to tackle a critical social problem that can affect the health and well being of young people.","2016","2021-02-15 21:34:49","2021-02-15 21:34:49","","1187–1192","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","social media; empathy; cyberbullying; reflection; social computing; teens; young adults","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9KXDAWP","bookSection","2017","Schaper, Marie-Monique; Santos, Maria; Malinverni, Laura; Pares, Narcis","Towards the Design of a Virtual Heritage Experience Based on the World-as-Support Interaction Paradigm","Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4656-6","","","https://doi.org/10.1145/3027063.3053089","We present the initial design stage of a Virtual Heritage experience for a bomb shelter built during the Spanish Civil War, namely Refugi 307. The shelter currently belongs to the History Museum of Barcelona which provides guided tours through the cultural heritage site for schools and the general public. The aim of the study was to define the requirements for the design of a first prototype based on the World-as-Support interaction paradigm. We conducted an ethnographic study and Participatory Design workshop to analyze different aspects of the requirements and to include multiple needs and viewpoints of the involved stakeholders. Based on the outcomes, we outline the potential for activities to foster (1) contextual-awareness between the learning content and the cultural heritage site, (2) environment-awareness in relation to missing objects in the physical space and (3) social-awareness to embody feelings related to solidarity and empathy.","2017","2021-02-15 21:34:49","2021-02-15 21:34:49","","2034–2041","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBY8S5UL","journalArticle","2020","Hwang, Amy S.; Jackson, Piper; Sixsmith, Andrew; Nygård, Louise; Astell, Arlene; Truong, Khai N.; Mihailidis, Alex","Exploring How Persons with Dementia and Care Partners Collaboratively Appropriate Information and Communication Technologies","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/3389377","https://doi.org/10.1145/3389377","Persons with dementia and their care partners have been found to adapt their own technological arrangements using commercially available information and communication technologies (ICTs). Yet, little is known about these processes of technology appropriation and how care practices are impacted. Adopting a relational perspective of care, we longitudinally examined how four family care networks appropriated a new commercial ICT service into their existing technological arrangements and care practices. Cross-case analysis interpreted collaborative appropriation to encompass two interrelated processes of creating and adapting technological practices and negotiating and augmenting care relationships. Four driving forces were also proposed: motivating meanings that actors ascribe to the technology and its use; the learnability of the technology and actors’ resourcefulness; the establishment of responsive and cooperative care practices; and the qualities of empathy and shared power in care relationships. The importance of technological literacy, learning, meaning-making, and the nature and quality of care relationships are discussed. Future work is urged to employ longitudinal and naturalistic approaches, and focus design efforts on promoting synergistic care relationships and care practices.","2020-11","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","6","27","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","dementia; Alzheimer's disease; appropriation; care practices; care relationship; caregiving; case study; cognitive impairment; commercial product; family care; information and communication technologies; off-the-shelf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBT6NB79","journalArticle","2020","Lin, Xin Yao; Saksono, Herman; Stowell, Elizabeth; Lachman, Margie E.; Castaneda-Sceppa, Carmen; Parker, Andrea G.","Go&amp;Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3415222","https://doi.org/10.1145/3415222","Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&amp;Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&amp;Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&amp;Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.","2020-10","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","CSCW2","4","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","caregiver; exergame; intervention; people with dementia; physical activity; social connectedness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K5H8BDF","bookSection","2020","van den Berg, Carolien; Verster, Belinda","Co-Creating Social, Digital Innovation to Recognise Agency in Communities: A Learning Intervention: Research in Progress","Conference of the South African Institute of Computer Scientists and Information Technologists 2020","978-1-4503-8847-4","","","https://doi.org/10.1145/3410886.3410912","This paper presents findings from a pilot project, of an ongoing Design-Based Research (DBR) initiative, where students in an Information Systems (IS) module proposed social, digital innovations for complex problems within marginalised communities in Cape Town, South Africa. The aim of the pilot project was to develop digital innovations that recognise agency in communities through lived experiences and local knowledge. An urban planning perspective was introduced to contextualise socio-environmental challenges to ground social innovations in reality and encourage a sustainable uptake of digital innovations by communities. The IS student projects emphasised empathy, storytelling and prototyping as part of a design thinking process which both incorporated and influenced the conceptual model presented in this paper. This conceptual model informed by four design principles of - relationality, reflexivity, responsiveness and recognition - is offered as an enrichment for a learning environment. It foregrounds the development of competencies for collaborative problem solving and ultimately transdisciplinary knowledge creation.","2020","2021-02-15 21:34:49","2021-02-15 21:34:49","","85–93","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ASGR7RR","conferencePaper","2017","Köppe, Christian; Nørgård, Rikke Toft; Pedersen, Alex Young","Towards a Pattern Language for Hybrid Education","Proceedings of the VikingPLoP 2017 Conference on Pattern Languages of Program","978-1-4503-6342-6","","10.1145/3158491.3158504","https://doi.org/10.1145/3158491.3158504","In this paper we offer an initial framework for a pattern language of hybrid education. With the term hybrid education, we imply the use of educational design patterns that actively strive to cut across, circumventing or upheave traditional dichotomies within education such as physical-digital, academic-nonacademic, online-offline, formal-informal, learning-teaching and individual-collective. In doing so, hybrid education invites uncertainty, open-endedness, risk-taking, experimentation, critical creativity, disruption, dialogue and democracy (back) into the heart of education. Accordingly we see, within hybrid education, the promise to push against and circumvent current trends of marketization, managerialism and standardization in higher education today. Here, a pattern language for hybrid education presents an alternative way of designing for future higher education in ways that are not focused on teaching to the test, playing it safe, rankings or gaming the system approaches. Rather, hybrid education focuses on open-endedness, risk-taking, relational entanglements, experimentation, exploration and empathy. In this way, designing for hybrid education is in this paper achieved, partly by taking a decidedly value-based and vision-driven approach to learning design patterns based on philosophy in higher education and critical pedagogy, partly by working together in hybrid ways and across disciplines and domains in order to open up both the field of teaching and learning in higher education as well as the field of learning design and design patterns. The result is the almost 80 design patterns for hybrid education. The paper presents the pattern categories for hybrid education, the different design patterns contained in these. Furthermore, the pattern mining ground and workshop process, the outcome of the value workshop and the vision workshop as well as three example scenarios is described in order to show both the underlying value and vision foundation for the pattern language as well as how it plays out in concrete scenarios.","2017","2021-02-15 21:34:49","2021-02-15 21:34:49","","","","","","","","","VikingPLoP '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Grube, Schleswig-Holstein, Germany","","","","education; educational patterns; hybrid pedagogy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULXGNCRI","conferencePaper","2014","Potter, Leigh Ellen; Korte, Jessica; Nielsen, Sue","Design with the Deaf: Do Deaf Children Need Their Own Approach When Designing Technology?","Proceedings of the 2014 Conference on Interaction Design and Children","978-1-4503-2272-0","","10.1145/2593968.2610464","https://doi.org/10.1145/2593968.2610464","In this paper, we focus on the question of design of technology for Deaf children, and whether the needs of these children are different from their hearing counterparts in a technology design setting. We present findings from literature together with our own observations to determine if there are distinguishing characteristics for Deaf children that may influence design sessions with them. We found that Deaf children generally have reduced literacy and slower academic progress, reduced social and emotional development, reduced empathy and a level of nervousness in novel situations, delayed language development, and limited or delayed spoken language. We also found that Deaf children are active and innovative in approaching communication, have sensitive visual attention in their peripheral vision, enhanced attention to small visual changes, and a capacity for visual learning. Finally, cultural issues within the Deaf community mean that Deaf children should be free to interact on their own terms in a design situation. We suggest that these differences merit the development of a design approach specific to the needs of Deaf children.","2014","2021-02-15 21:34:49","2021-02-15 21:34:49","","249–252","","","","","","","IDC '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aarhus, Denmark","","","","prototyping; child computer interaction; deaf children","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DD2GNFAW","conferencePaper","2013","Slegers, Karin; Wilkinson, Andrea; Hendriks, Niels","Active Collaboration in Healthcare Design: Participatory Design to Develop a Dementia Care App","CHI '13 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-1952-2","","10.1145/2468356.2468440","https://doi.org/10.1145/2468356.2468440","This paper describes a research project aimed at developing a mealtime data registration tool for people with dementia. As to actively involve all stakeholders in this healthcare design project and to generate empathy and involvement, methods from participatory design were used. For each of the three research phases (ethnography, ideation &amp; conceptualization and prototyping) we describe our approach towards stakeholder involvement and active collaboration. We discuss lessons learned in terms of good practices and the issues we struggle with.","2013","2021-02-15 21:34:49","2021-02-15 21:34:49","","475–480","","","","","","","CHI EA '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Paris, France","","","","dementia; participatory design; prototyping; healthcare","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZXVDZC6","conferencePaper","2019","Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica","Good Robot Design or Machiavellian? An in-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019","2021-02-15 21:34:50","2021-02-15 21:34:50","","382–391","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","culture; social robots; in the wild; persuasive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y843R339","conferencePaper","2019","Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie","Development of a Cloud-Based Computational Framework for an Empathetic Robot","Proceedings of the 2019 11th International Conference on Computer and Automation Engineering","978-1-4503-6287-0","","10.1145/3313991.3314018","https://doi.org/10.1145/3313991.3314018","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.","2019","2021-02-15 21:34:50","2021-02-15 21:34:50","","102–108","","","","","","","ICCAE 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Perth, WN, Australia","","","","deep learning; robot; cloud control; emotion classification; intent perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMSK565K","conferencePaper","2015","Sobel, Kiley; O'Leary, Katie; Kientz, Julie A.","Maximizing Children's Opportunities with Inclusive Play: Considerations for Interactive Technology Design","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771844","https://doi.org/10.1145/2771839.2771844","Inclusive play, defined as play among children with and without disabilities, provides learning opportunities that challenge stereotypes, foster strong friendships, and help children develop empathy and other social and emotional skills. Designing technologies to support inclusive play are understudied in Human-Computer Interaction. We synthesized literature, conducted design ethnography in an inclusive classroom, and interviewed and surveyed parents and teachers to explore this problem. Our research contributes an empirical understanding of the current state of inclusive play and a characterization of the design space for interactive technologies that can support children and adults with inclusive play. We identify key facilitators of inclusive play: direct and embedded supports, transparency, adjustability, emphasis on children's interests and strengths, and current technology use. We also describe significant barriers to inclusive play: effort required to facilitate inclusive play, children's preferences, parental inexperience, and inappropriate technology. Through our discussion, we conclude that interactive technologies should be designed to harness the facilitators and help overcome the barriers in order to maximize children's opportunities with inclusive play.","2015","2021-02-15 21:34:50","2021-02-15 21:34:50","","39–48","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","children; human-centered design; assistive technology; inclusion; inclusive design; inclusive play; universal design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKHYJZ4K","conferencePaper","2020","Olson, Danielle Marie; Harrell, D. Fox, Ph.D.","“I Don't See Color”: Characterizing Players’ Racial Attitudes and Experiences via an Anti-Bias Simulation Videogame","International Conference on the Foundations of Digital Games","978-1-4503-8807-8","","10.1145/3402942.3409783","https://doi.org/10.1145/3402942.3409783","Videogames and learning/training applications that address racial discrimination have risen in popularity recently, coinciding with the rapid development of the field of serious (or impact) games [1, 2]. While there has been much focus on understanding the efficacy of these systems as interventions to reduce racial bias, there has been less attention paid to how individuals’ prior physical-world racial attitudes influence their experiences of such games about racial issues. Toward addressing this gap, the study presented here examines the relationships between PreK-12 educators’ colorblind racial attitudes and their game experience and narrative interpretations in narrative videogame modeling racial and ethnic socialization called Passage Home. Passage Home embeds a novel computational model and simulation informed by the Racial Encounter Coping Appraisal and Socialization Theory (RECAST) [3] to simulate a discriminatory racial encounter in a classroom setting. The system serves as a tool for assessing players’ racial and ethnic socialization (RES) experiences to support interventions for learning about racial bias. This paper presents the results of a user study deploying Passage Home with PreK-12 educators. Analysis revealed that players’ colorblind racial attitudes and ethnic identity were related to their in-game racial appraisal and feelings of competence, negative affect, and empathy in the game. Given the prevalence of colorblind racial ideology across racial and ethnic groups in the United States [4, 5], we propose an initial typology of players’ colorblind racial attitudes emerging from this analysis to aid in the future development of serious game interventions addressing racial discrimination.","2020","2021-02-15 21:34:50","2021-02-15 21:34:50","","","","","","","","","FDG '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bugibba, Malta","","","","human-computer interaction; Avatars; serious games; social identity; reflection; educational game; game design; identity; impact games; interactive narrative; racial discrimination; serious play; transformative education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZWRS7AS","conferencePaper","2020","Groeneveld, Wouter; Jacobs, Hans; Vennekens, Joost; Aerts, Kris","Non-Cognitive Abilities of Exceptional Software Engineers: A Delphi Study","Proceedings of the 51st ACM Technical Symposium on Computer Science Education","978-1-4503-6793-6","","10.1145/3328778.3366811","https://doi.org/10.1145/3328778.3366811","Important building blocks of software engineering concepts are without a doubt technical. During the last decade, research and practical interest for non-technicalities has grown, revealing the building blocks to be various skills and abilities beside pure technical knowledge. Multiple attempts to categorise these blocks have been made, but so far little international studies have been performed that identify skills by asking experts from both the industrial and academic world: which abilities are needed for a developer to excel in the software engineering industry? To answer this question, we performed a Delphi study, inviting 36 experts from 11 different countries world-wide, affiliated with 21 internationally renowned institutions. This study presents the 55 identified and ranked skills as classified in four major areas: communicative skills (empathy, actively listening, etc.), collaborative skills (sharing responsibility, learning from each other, etc.), problem solving skills (verifying assumptions, solution-oriented thinking, etc.), and personal skills (curiosity, being open to ideas, etc.), of which a comparison has been made between opinions of technical experts, business experts, and academics. We hope this work inspires educators and practitioners to adjust their training programs, mitigating the gap between the industry and the academic world.","2020","2021-02-15 21:34:50","2021-02-15 21:34:50","","1096–1102","","","","","","","SIGCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, OR, USA","","","","delphi study; industry requirements; non-cognitive abilities; professional skills; software developer; software engineering edutation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VM2GUPI9","conferencePaper","2019","Munteanu, Cosmin; Oviatt, Sharon","CHI 2019 Early Career Development Symposium","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3298999","https://doi.org/10.1145/3290607.3298999","The first few years after completing a PhD can be challenging to navigate. Job hunting, interviewing, navigating new contexts such as a junior academic position, applying for funding as a first time project investigator, learning to adapt to the culture of an industry-based workplace, supervising graduate students or full-time employees - these are just a few of the scenarios recent PhD graduates find themselves in. Within HCI, one may encounter more discipline-specific challenges, such as keeping up with the CHI publication cycles while taking on new administrative duties. The CHI community, however, strives to be collectively supportive and inclusive of researchers at all stages of their career - this is even more important as many of our design approaches are rooted in empathy for and empowerment of participants. By more actively supporting each other as researchers in our career paths, we can better grow as a community, and reflect it back into our collective body of practice. The Early Career Development Symposium has been proposed (and held yearly since 2016) to provide a more formal mentoring venue that reflects our aims as a community to more meaningfully support each other.","2019","2021-02-15 21:34:50","2021-02-15 21:34:50","","1–5","","","","","","","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","mentoring; early career; post phd","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SXA3SM6W","conferencePaper","2014","Matsuzawa, Tetsuro","Evolution of Human Mind and Culture Viewed from the Study of Chimpanzees","Proceedings of the 5th ACM International Conference on Collaboration across Boundaries: Culture, Distance &amp; Technology","978-1-4503-2557-8","","10.1145/2631488.2637432","https://doi.org/10.1145/2631488.2637432","I have studied chimpanzees both in the wild and in the laboratory. My talk illustrates the evolutionary origins of human mind and culture. The human mother–infant relationship is characterized by physical separation, and the stable supine posture of infants; enabling face-to-face communication via facial expressions, vocal exchange, and manual gestures, and also demonstration of object manipulation. I have used the novel ""participant observation"" method in the laboratory and through ""field experiments"" in their natural habitat. There are several critical differences between the two species: chimpanzees lack the social referencing ability observed in human children and chimpanzees seldom engage in active teaching. Moreover, although young chimpanzees showed unique working memory capacity, often superior to that of human adults, they are less able to learning symbols. In sum, mind and culture in humans is fundamentally influenced by the manner of raising young children; characterized by collaboration among multiple adults. This aspect of human rearing may be linked to the development of empathy, altruistic behavior, reciprocity, understanding others? minds, and so on. Taken together, my talk presents evolutionary and ontogenetic explanations for the uniquely human cognition and culture.","2014","2021-02-15 21:34:50","2021-02-15 21:34:50","","141","","","","","","","CABS '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","evolution; culture; chimpanzees and human comparison","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAG3R7M3","conferencePaper","2018","McDonald, Heidi","IThirve Games Empathy Jam at DigiPen","Proceedings of the International Conference on Game Jams, Hackathons, and Game Creation Events","978-1-4503-6484-3","","10.1145/3196697.3196704","https://doi.org/10.1145/3196697.3196704","This Event Report concerns the Empathy Jam iThrive Games held in cooperation with DigiPen Institute of Technology in Seattle, WA, on September 15-17, 2017. iThrive Games is a nonprofit that exists to create meaningful opportunities for teens to enhance the knowledge, mindsets, and skills they need to thrive across development, to engage actively in their learning and in their community, and to be healthy. We embrace the positive potential of games, and find a strengths-based approach to be especially important to this work. Game Jams are an important way that iThrive can educate and perform developer outreach in accordance with our mission. We do game jams at universities and regional game festivals, with the goal of bringing together people to build games together using our science based, expert-developed design resources (available for free download at the iThrive Games website: www.ithrivegames.org) to help developers make games toward prosocial outcomes. Our jams not only demonstrate what kinds of games can result from these design concepts, but are also important events to foster ongoing collaboration and to facilitate mentoring relationships at multiple levels. These jams also allow us to test and refine our design resources with the help of the people they are intended for.","2018","2021-02-15 21:34:50","2021-02-15 21:34:50","","28–33","","","","","","","ICGJ 2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Francisco, CA, USA","","","","serious games; empathy games; games for teens; iThrive Games; jams for teens; kindness games; prosocial outcomes; social emotional learning; teen development; transformational frameworks; transformational games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F24SYU87","journalArticle","2019","Not, Elena; Cavada, Dario; Maule, Stefano; Pisetti, Anna; Venturini, Adriano","Digital Augmentation of Historical Objects Through Tangible Interaction","J. Comput. Cult. Herit.","","1556-4673","10.1145/3297764","https://doi.org/10.1145/3297764","The technological advances brought about by the Internet of Things enable new opportunities for a more direct interaction among users, objects, and places. This is an extremely valuable innovation for the cultural heritage sector, as it allows a more transparent use of technology in the digital augmentation of museums and cultural heritage sites. The possibility to augment physical objects with sensors detecting when they are moved and manipulated enables scenarios where descriptive information about objects is presented to users at the very exact time they are looking at them, stimulating engagement. This article describes a collaborative research effort among cultural heritage professionals, human–computer interaction experts, and developers that was aimed at investigating the goals and constraints curators consider for a physical encounter between visitors and historic relics. In a case study, we co-designed an interactive plinth centred on tangible interaction and evaluated the impact on the user experience of combining digital information with a hands-on experience of relics of World War I. Our findings show that visitors value this type of tangible interaction with collection objects positively, as it allows the discovery of details and the learning of aspects that normally go unnoticed. The synergy between physical and digital aspects stimulates empathy with the original users of the object and fosters social interaction.","2019-06","2021-02-15 21:34:50","2021-02-15 21:34:50","","","","3","12","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","internet of things; Digitally augmented objects; museum experience; tangible and embodied interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BJIB7QI2","conferencePaper","2017","Chapman, Gail","Inspire, Innovate, Improve! What Does This Mean for CS for All?","Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education","978-1-4503-4698-6","","10.1145/3017680.3025047","https://doi.org/10.1145/3017680.3025047","In January 2016, President Obama unveiled the CS for All initiative. With all the attention and publicity surrounding CS for All and increased support from a variety of corners over the ensuing year, it is easy to become complacent and start believing that we have ""arrived"". During her 2016 SIGCSE keynote, Jan Cuny talked about catching the wave and using it to our advantage. This talk will focus on where we go from here. We caught the wave; now what do we do to ensure that we don't get swallowed by it? What lessons can be learned from an election that featured the likes of fake news, Wiki leaks, rogue email servers, runaway tweets and showed in stark relief the divides that exist in our country. Computer science represents one of those divides. Given this and the fact that addressing the educational inequities prevalent in computer science was front and center in the CS for All announcement, what better time is there to renew our commitment to broadening participation in computing? As educators we have a powerful opportunity and responsibility in the wake of the blowback from the election-to educate, to listen, to remind ourselves constantly that we live in a very diverse country. We have no shortage of innovation in computer science, but who are we inspiring, what impact are those innovations having, and what can we do to learn from the lessons of the past to improve CS education? And above all, how do we respond to the challenges before us with empathy for those who are impacted by the decisions we make?","2017","2021-02-15 21:34:50","2021-02-15 21:34:50","","1","","","","","","","SIGCSE '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seattle, Washington, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUN9MTAL","conferencePaper","2018","Hieida, Chie; Horii, Takato; Nagai, Takayuki","Decision-Making in Emotion Model","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177048","https://doi.org/10.1145/3173386.3177048","Having emotions is essential for robots to understand and sympathize with the feelings of people. In addition, it may allow the robots to be accepted into human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions based on various neurological and psychological findings that are related to empathic communication between humans and robots is proposed. Subsequently, a mechanism of decision-making that is based on affects using convolutional LSTM and deep Q-network is examined.","2018","2021-02-15 21:34:50","2021-02-15 21:34:50","","127–128","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","decision-making; model of emotion; empathic hri","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"563DSPXU","conferencePaper","2013","Ramírez, Ricardo; Parthasarathy, Balaji; Gordon, Andrew","From Infomediaries to Infomediation at Public Access Venues: Lessons from a 3-Country Study","Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1","978-1-4503-1906-5","","10.1145/2516604.2516621","https://doi.org/10.1145/2516604.2516621","This study investigated the role of infomediaries to understand the process of infomediation in shaping outcomes for users at public access venues (PAVs) in Bangladesh, Chile and Lithuania. We examined the extent to which technical skills and empathy are relevant to and appreciated by different types of users, and whether differences in infomediaries are evident across different types of PAVs. We asked whether particular infomediary behaviours were associated with outcome differences as reported by PAV users. We learned that infomediaries provide the human face for the information age by taking on the functions of facilitation, coaching, referral and teaching, and by assuming the role of a trusted gatekeeper. The process of infomediation turned out to be of prominence, within which the infomediary is a key component. In the absence of infomediaries, those left behind (or excluded due to their age, socio-economic status, level of education/literacy, gender, disability or caste) will face additional, perhaps insurmountable, barriers.","2013","2021-02-15 21:34:50","2021-02-15 21:34:50","","124–132","","","","","","","ICTD '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cape Town, South Africa","","","","empathy; information and communication technologies; brokering; ICTD; infomediary; infomediation; public access","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSUZ6V88","conferencePaper","2020","Branco, Karina da S. C.; Oliveira, Rhenara A.; Silva, Francisco L. Q. da; de H. Rabelo, Jacilane; Marques, Anna B. S.","Does This Persona Represent Me? Investigating an Approach for Automatic Generation of Personas Based on Questionnaires and Clustering","Proceedings of the 19th Brazilian Symposium on Human Factors in Computing Systems","978-1-4503-8172-7","","10.1145/3424953.3426648","https://doi.org/10.1145/3424953.3426648","Personas are fictional representations of an end user based on data collected from a specific target audience. The creation of personas takes time, because part of the process is manual, which causes difficulties during the stages of data generation and analysis, if the data sample is large. The present work aims to investigate the results of the automatic generation of personas through a questionnaire and the Clustering method. Initially, a questionnaire was applied in order to outline the profile of students in the Computer Science and Software Engineering courses at the university Federal of Ceará. 130 responses were obtained from this applied questionnaire. The automatic generation of personas used the collected responses as a database, these data were applied to the Clustering method. From Clustering, using a specific tool for this purpose, it was possible to generate four personas automatically. In relation to the data generated from the personas, it was possible to identify some characteristics, such as: (a) course choice factor: the opportunity to work with new technologies, influence of family and friends and the possibility of living abroad; (b) factor of withdrawal from the course: lack of identification with the course, learning difficulties in the disciplines and finance; and, (c) area of interest: software engineering, human-computer interaction and computer graphics. A new questionnaire was applied in order to validate the personas generated in relation to credibility, empathy and similarity. Based on the results obtained, it was observed that two of the four personas generated achieved greater prominence in relation to the validation criteria, showing that the personas look like real people, students think like the personas and share similar interests.","2020","2021-02-15 21:34:50","2021-02-15 21:34:50","","","","","","","","","IHC '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Diamantina, Brazil","","","","personas; clustering; automatic generation of personas; personas validation; questionnaire","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUZKUKIJ","conferencePaper","2017","Richards, Deborah","Intimately Intelligent Virtual Agents: Knowing the Human beyond Sensory Input","Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents","978-1-4503-5558-2","","10.1145/3139491.3139505","https://doi.org/10.1145/3139491.3139505","Despite being in the era of Big Data, where our devices seem to anticipate and feed our every desire, intelligent virtual agents appear to lack intimate and important knowledge of their user. Current cognitive agent architectures usually include situation awareness that allows agents to sense their environment, including their human partner, and provide congruent empathic behaviours. Depending on the framework, agents may exhibit their own personality, culture, memories, goals and reasoning styles. However, tailored adaptive behaviours based on multi-dimensional and deep understanding of the human essential for enduring beneficial relationships in certain contexts are lacking. In this paper, examples are provided of what an agent may need to know about the human in the application domains of education, health and cybersecurity and the challenges around agent adaptation and acquisition of relevant data and knowledge.","2017","2021-02-15 21:34:50","2021-02-15 21:34:50","","39–40","","","","","","","ISIAA 2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, UK","","","","Intelligent Virtual Agents; User Modelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV9CNDM6","conferencePaper","2014","Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth","Towards a Serious Game Playing Empathic Robotic Tutorial Dialogue System","Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2658-2","","10.1145/2559636.2563707","https://doi.org/10.1145/2559636.2563707","There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.","2014","2021-02-15 21:34:50","2021-02-15 21:34:50","","180–181","","","","","","","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bielefeld, Germany","","","","serious games; dialogue management; empathic robotic tutor; tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTDRF4FQ","conferencePaper","2010","Rivera, Fiona; Watten, Phil; Holroyd, Patrick; Beacher, Felix; Mania, Katerina; Critchley, Hugo","Real-Time Compositing Framework for Interactive Stereo FMRI Displays","ACM SIGGRAPH 2010 Posters","978-1-4503-0393-4","","10.1145/1836845.1836862","https://doi.org/10.1145/1836845.1836862","This research concentrates on providing high fidelity animation, only achievable with offline rendering solutions, for interactive fMRI-based experiments. Virtual characters are well established within the film, game and research worlds, yet much remains to be learned about which design, stylistic or behavioural factors combine to make a believable character. The definition of believability depends on context. When designing and implementing characters for entertainment, the concern is making believable characters that the audience will engage with. When using virtual characters in experiments, the aim is to create characters and synthetic spaces that people respond to in a similar manner to their real world counterparts. Research has shown that users show empathy for virtual characters. However, uncanny valley effects – ie dips in user impressions – can arise: behavioural fidelity expectations increase alongside increases in visual fidelity and vice versa. Often, characters used within virtual environments tend to be of fairly low fidelity due to technological constraints including rendering in real-time (Garau et al. 2003). This problem is addressed here by using non-linear playback and compositing of pre-rendered high fidelity sequences.","2010","2021-02-15 21:34:50","2021-02-15 21:34:50","","","","","","","","","SIGGRAPH '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Los Angeles, California","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Y52A48Y","conferencePaper","2020","Bastos, João Antonio D. M.; de Mello, Rafael Maiani; Garcia, Alessandro","Colloquy: A Method for Conversational API Design","Proceedings of the 34th Brazilian Symposium on Software Engineering","978-1-4503-8753-8","","10.1145/3422392.3422468","https://doi.org/10.1145/3422392.3422468","APIs (application programming interfaces) play a key role in software development. Virtually, all programmers are potential users of third-party APIs. From the perspective of the theory of Semiotic Engineering, we may characterize an API as an artifact mediating the communication between two types of developers: the API designers and its users. During the construction of an API, the designers should establish proper dialogues with the users. These dialogues will enable the conversation of these actors at the interaction time. In this way, we define a conversational API as an API capable of offering effective dialogues to its users. In this paper, we introduce Colloquy, a method for supporting the design of conversational APIs. Colloquy results from the lessons learnt during an action research conducted for redesigning a real and complex API. The set of Colloquy resources allow API designers to go beyond conventional concerns with usability. We also report in this paper a case study in which Colloquy was used for redesigning a refactoring API. The study findings indicate the method helped the designer creating empathy with the API users, as well as better reflecting and depicting the requirements and the conversations that the API should attend to the different user profiles.","2020","2021-02-15 21:34:50","2021-02-15 21:34:50","","514–519","","","","","","","SBES '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Natal, Brazil","","","","API Conversacional; Engenharia Semiótica; Método de Design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NX5S99ZV","conferencePaper","2016","Chisik, Yoram; Mancini, Clara","Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans","Proceedings of the 14th Participatory Design Conference: Short Papers, Interactive Exhibitions, Workshops - Volume 2","978-1-4503-4136-3","","10.1145/2948076.2948093","https://doi.org/10.1145/2948076.2948093","Participatory Design strives to broaden the perspective of and increase empathy in design by giving specific and often under represented user groups, such as children or older people, a voice in the design process. The exact nature of the role played by such participants in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the participatory design community. The emerging field of Animal Computer Interaction, which seeks to empower animals through user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.","2016","2021-02-15 21:34:50","2021-02-15 21:34:50","","123–124","","","","","","","PDC '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aarhus, Denmark","","","","children; participatory design; ACI; animal computer interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMJ5BVVF","conferencePaper","2014","Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei","The Fugitive: A Robot in the Wild","Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2658-2","","10.1145/2559636.2559653","https://doi.org/10.1145/2559636.2559653","The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building.The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not.The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on.The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol.The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.","2014","2021-02-15 21:34:50","2021-02-15 21:34:50","","111","","","","","","","HRI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bielefeld, Germany","","","","human-robot interaction; social robotics; robots in the wild","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMIHMXLI","bookSection","2017","Cole, Amelia W.; Quesnel, Denise T.; Pekçetin, Serkan; Gromala, Diane; O'Brien, Heather; Antle, Alissa N.; Riecke, Bernhard E.","Integrating Affective Responses and Gamification into Early Reading Acquisition Software Applications","Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play","978-1-4503-5111-9","","","https://doi.org/10.1145/3130859.3131433","Sisu is a gamified learning application designed to assist school-aged children who are struggling to read. Sisu utilizes readily-available technology to promote learning at home, with unique elements tied to the learning experience: (1) a spelling game with (2) an empathic agent, and (3) a mini-game. The empathic agent utilizes a facial action coding system (FACS) to recognize core expressions of the child user and respond to the child's affect in-game. We anticipate that Sisu's accessible and affective nature will not only support children's emotional needs, but the addition of gamified elements will motivate them to practice reading and assist them in their learning objectives.","2017","2021-02-15 21:34:50","2021-02-15 21:34:50","","73–85","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQYZSGWB","bookSection","2017","Chisik, Yoram; Mancini, Clara","Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans","Proceedings of the 2017 Conference on Interaction Design and Children","978-1-4503-4921-5","","","https://doi.org/10.1145/3078072.3081311","Participatory Design with children strives to broaden the perspective of and increase empathy in design for the needs and desires of children by giving children a voice in the design process. The exact nature of the role played by children in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the IDC community. The emerging field of Animal Computer Interaction, which seeks to empower animals through the participatory design of user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.","2017","2021-02-15 21:34:50","2021-02-15 21:34:50","","753–756","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UY8CGHHZ","conferencePaper","2018","Spaulding, Samuel","Personalized Robot Tutors That Learn from Multimodal Data","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.","2018","2021-02-15 21:34:51","2021-02-15 21:34:51","","1781–1783","","","","","","","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Stockholm, Sweden","","","","human-robot interaction; social robotics; multimodal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EZ4JE7P","conferencePaper","2019","Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania","Ballbit Adventure: A Physical Game for a Collaborative Racing","Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts","978-1-4503-6871-1","","10.1145/3341215.3356982","https://doi.org/10.1145/3341215.3356982","Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.","2019","2021-02-15 21:34:51","2021-02-15 21:34:51","","97–103","","","","","","","CHI PLAY '19 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVVZ9JQU","book","2020","","HAI '20: Proceedings of the 8th International Conference on Human-Agent Interaction","","978-1-4503-8054-6","","","","It is our great pleasure to welcome you to the Eighth International Conference on Human-Agent Interaction HAI 2020 (Virtual Conference); hosted by the Western Sydney University (Australia) and supported by Chalmers University of Technology (Sweden).The conference is a venue with an interdisciplinary nature to discuss and disseminate state-ofthe- art research on topics related to human interactions with a range of agent systems, including physical robots and humanoids, virtual agents, socially interactive agents, and Artificially Intelligent (AI) agents. The topical areas of the conference include user studies, frameworks, simulations, technical developments and more within Human Agent and Robotic Interaction. The conference brings together a large variety of multidisciplinary research groups, companies, and researchers looking into the broader area of agents and robotics across Australia, Japan and the rest of the world.The theme for HAI 2020 is ""Artificial Intelligence + Experience Design."" The recent advent of AI has motivated researchers to focus on several algorithmic prospects in developing intelligent robotic agents and their interactions. Progressively, AI advances are leading to exciting outcomes in the HAI field and, at the same time, are opening up for a wide perspective on how to design intelligent robotic agents. For example, how to combine artificial intelligence and user experience design approaches in human-agent interaction. We are looking forward to sharing the latest research results of HAI that contribute a broad range of disciplines.Three keynote talks are featured. The first is titled ""We're in This Together: Social Robots in Group, Organizational, and Community Interactions"", by Associate Prof. Selma Šabanović, Indiana University Bloomington, USA. The second is titled ""What kind of human-centric robotics do we need? Investigations from human-robot interactions in socially assistive scenarios"", by Prof. Ginevra Castellano, Uppsala University, Sweden. The third is an industry talk titled ""The rapid rise in drone technology"", by Sebastian Robertson, CEO of BIRDI, Australia. Their keynote talks will provide cross-disciplinary examples of novel HAI research and applications that are highly inspiring for the HAI audience and research community.This year's submissions have come from more than 25 countries and cover leading-edge topics including human and machine learning, conversational agents, empathy and trust of social robots, social drones, social presence, robot applications, virtual agent applications and novel perspectives of HAI. With an acceptance rate of 38% (25 papers out of 65 submissions), the program committee has again set a high quality standard. In addition, 26 out of the 35 latebreaking poster papers submissions were accepted.","2020","2021-02-15 21:34:51","2021-02-15 21:34:51","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPF8JCEB","conferencePaper","2014","Billinghurst, Mark","Using Augmented Reality to Create Empathic Experiences","Proceedings of the 19th International Conference on Intelligent User Interfaces","978-1-4503-2184-6","","10.1145/2557500.2568057","https://doi.org/10.1145/2557500.2568057","Intelligent user interfaces have traditionally been used to create systems that respond intelligently to user input. However there is a recent trend towards Empathic Interfaces that are designed to go beyond understanding user input and to recognize emotional state and user feelings. In this presentation we explore how Augmented Reality (AR) can be used to convey that emotional state and so allow users to capture and share emotional experiences. In this way AR not only overlays virtual imagery on the real world, but also can create deeper understanding of user's experience at particular locations and points in time. The recent emergence of truly wearable systems, such as Google Glass, provide a platform for Empathic Communication using AR. Examples will be shown from research conducted at the HIT Lab NZ and other research organizations, and key areas for future research described.","2014","2021-02-15 21:34:51","2021-02-15 21:34:51","","5–6","","","","","","","IUI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Haifa, Israel","","","","augmented reality; collaboration; empathic computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PND2KN2D","conferencePaper","2016","Lim, Mei Yii; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Hall, Lynne","A Treasure Hunt With An Empathic Virtual Tutor: (Demonstration)","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","We present a demonstration of a Treasure Hunt Application with an Empathic Virtual Tutor. During the treasure hunt, this empathic agent adapts its interaction based on the affective state of the user to improve learning experience. We demonstrate the application domain; the technology used; and the app focusing on the empathic strategies applied.","2016","2021-02-15 21:34:51","2021-02-15 21:34:51","","1477–1478","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","human-agent interaction; valence; arousal; empathic agent; treasure hunt","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7IPRR6J","journalArticle","2020","Cotler, Jami L.; Villa, Luis; Burshteyn, Dmitry; Bult, Zachary; Grant, Garrison; Tanski, Michael; Parente, Anthony","An Interdisciplinary Approach to Detecting Empathy through Emotional Analytics and Eye Tracking","J. Comput. Sci. Coll.","","1937-4771","","","The aim of this interdisciplinary study was to bring together different perspectives to discover if detecting empathetic emotional reactions is possible. This area of research has received recent attention from the computer science, human-computer interaction and psychological research communities. The research team consisted of three students; a computer science, sociology and marketing major. The team worked to understand the complexities of detecting emotions based on facial movement. The team collected time stamped facial emotional data from 210 participants as they watched a video clip from the popular movie depicting bullying behavior towards a disabled person. The results demonstrated significant before-and- after mean differences in emotions that are characterized as empathic towards the main character for the bullying events, which is a promising start to detecting empathic reactions. Each student brought a different perspective from their majors resulting in an educational experience that transcended learning about emotional analytics.","2020-04","2021-02-15 21:34:51","2021-02-15 21:34:51","","87–95","","8","35","","","","","","","","","","","","","","","","","Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R78C9MHI","conferencePaper","2016","Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan","Semi-Supervised Model Personalization for Improved Detection of Learner's Emotional Engagement","Proceedings of the 18th ACM International Conference on Multimodal Interaction","978-1-4503-4556-9","","10.1145/2993148.2993166","https://doi.org/10.1145/2993148.2993166","Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.","2016","2021-02-15 21:34:51","2021-02-15 21:34:51","","100–107","","","","","","","ICMI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXU4ZPGP","conferencePaper","2015","Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana","The Empathic Robotic Tutor: Featuring the NAO Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702100","https://doi.org/10.1145/2701973.2702100","We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.","2015","2021-02-15 21:34:51","2021-02-15 21:34:51","","285","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","educational robotics; empathic robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"899G3SHM","conferencePaper","2019","Tchetgen, Pierre-Valery Njenji","DRUMBALL: Multimodal Meaning Production through Digital Drum Talk","Proceedings of the 2019 on Creativity and Cognition","978-1-4503-5917-7","","10.1145/3325480.3326544","https://doi.org/10.1145/3325480.3326544","In this demonstration, I present an interactive prototype of the Drumball system, an embodied learning environment that allows for drum patterns to be turned into and used as letters, words or phrases. The system acts as a transducer of rhythmic input into multimodal output, and was designed to investigate the affordances of this embodied learning approach on the early literacy skills acquisition of children. The project follows a design thinking process (empathize, define, ideate, prototype, test) to explore cultural systems as a grounding for learning technologies design. The session provides a space to think beyond the traditional keypad interface and its reliance on alphabetic input, to explore how the application of the talking drum cultural system in the domain of human-computer interaction can be used to transform children's early experiences with literacy. I will demonstrate creating sequences of letters and words using the system by playing drum tones of varying pitches (tone, slap and bass).","2019","2021-02-15 21:34:51","2021-02-15 21:34:51","","513–517","","","","","","","C&amp;C '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Diego, CA, USA","","","","embodied learning; culturally-grounded pedagogies and technologies; drum language; haptic devices; interaction paradigm; literacy development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RRGASSTP","conferencePaper","2020","Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef","Facial Expression Based Satisfaction Index for Empathic Buildings","Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers","978-1-4503-8076-8","","10.1145/3410530.3414443","https://doi.org/10.1145/3410530.3414443","In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.","2020","2021-02-15 21:34:51","2021-02-15 21:34:51","","704–707","","","","","","","UbiComp-ISWC '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Mexico","","","","machine learning; empathic building; facial expressions; satisfaction index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH84IDQX","conferencePaper","2016","Alyuz, Nese","Shaping the Future of Education with Empathic Companions","Proceedings of the 2nd Workshop on Emotion Representations and Modelling for Companion Systems","978-1-4503-4558-3","","10.1145/3009960.3009964","https://doi.org/10.1145/3009960.3009964","With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.","2016","2021-02-15 21:34:51","2021-02-15 21:34:51","","","","","","","","","ERM4CT '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tokyo, Japan","","","","machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LDX4MLE","conferencePaper","2019","Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher","Mutual Reinforcement Learning with Robot Trainers","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.","2019","2021-02-15 21:34:51","2021-02-15 21:34:51","","572–573","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IU5GTDXB","conferencePaper","2010","Regazzoni, Carlo S.","Emphatic Human Interaction Analysis for Cognitive Environments","Proceedings of the First ACM International Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams","978-1-4503-0163-3","","10.1145/1877868.1877870","https://doi.org/10.1145/1877868.1877870","Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment.Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available.Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation.Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world.Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it).Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.","2010","2021-02-15 21:34:51","2021-02-15 21:34:51","","1–2","","","","","","","ARTEMIS '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Firenze, Italy","","","","ambient intelligence; cognitive surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XCMGBNM","conferencePaper","2011","Lee, Jung-Joo; Vaajakallio, Kirsikka; Mattelmäki, Tuuli","Tracing Situated Effects of Innovative Design Methods: Inexperienced Designers' Practices","Procedings of the Second Conference on Creativity and Innovation in Design","978-1-4503-0754-3","","10.1145/2079216.2079231","https://doi.org/10.1145/2079216.2079231","In recent years the design research community has been active in developing new methods for user involvement and collaboration in the design process. The new methods, often called innovative design methods, correspond more to designer's genuine ways of thinking and working than do traditional user-centered ones. The entire purpose of innovative method is to allow for designer's creativity in the design of method and reflective learning, instead of relying on predefined rules of method. For this reason, codification and scientific evaluation are often regarded very challenging, if meaningful at all. This leads us to raise a question; what could be relevant ways of framing and communicating innovative design methods to better capture their nature and value?As one attempt to explore this question, our study takes a close look at inexperienced designers' practices with innovative methods, such as probes or co-design workshops. We chose students as research subjects because their situated actions – and the challenges they face in understanding and applying these methods – reveal just kind of knowledge about the innovative methods that needs to be communicated. To do this, we analyzed students' learning diaries written during the design course. When the students reported uncertainties and disappointments due to 'ill-defined' nature of such methods, we were able to trace the reasons for disappointments. We also found that the innovative design methods in fact supported the students for empathic learning and design inspiration from the making process of the methods.","2011","2021-02-15 21:34:51","2021-02-15 21:34:51","","103–113","","","","","","","DESIRE '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Eindhoven, Netherlands","","","","empathic design; co-design; design education; innovative design methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VVP6PUC","conferencePaper","2013","Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria","3D Animated Agent for Tutoring Based on WebGL","Proceedings of the 18th International Conference on 3D Web Technology","978-1-4503-2133-4","","10.1145/2466533.2466534","https://doi.org/10.1145/2466533.2466534","The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.","2013","2021-02-15 21:34:51","2021-02-15 21:34:51","","129–134","","","","","","","Web3D '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Sebastian, Spain","","","","artificial intelligence; e-learning; virtual agents; Web3D technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPWR87LU","conferencePaper","2017","Ranjbartabar, Hedieh; Richards, Deborah","Student Designed Virtual Teacher Feedback","Proceedings of the 9th International Conference on Computer and Automation Engineering","978-1-4503-4809-6","","10.1145/3057039.3057083","https://doi.org/10.1145/3057039.3057083","Interactive virtual learning environments (VLEs) have significant potential to influence students' learning achievements. Characters in these VLEs can act as a virtual peers and teachers by providing empathic responses tailored to the affective state of the students. Designing appropriate dialogues and feedback will be important in achieving the desired outcomes such as increased engagement, motivation and achievement. In this paper we report our findings from a study with 19 girls in Year 8 and 9 at high school using the Omosa VLE. The study investigated student responses to the initial dialogues we designed to elicit their emotional state and provide support. Analysis of responses and alternative dialogues offered by the students revealed that the feedback provided by our characters was mostly acceptable, but further improvements should be made to include elements such as self-disclosure and more helpful dialogue.","2017","2021-02-15 21:34:51","2021-02-15 21:34:51","","26–30","","","","","","","ICCAE '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, Australia","","","","Omosa; empathic virtual agent; Virtual learning environment; virtual world","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NJUF5TN","conferencePaper","2020","Latulipe, Celine; Provencal, Sarah; Frevert, Tonya","Challenging Social Exclusion in Computing via 'Theatre of the Oppressed' Pedagogy","Proceedings of the 51st ACM Technical Symposium on Computer Science Education","978-1-4503-6793-6","","10.1145/3328778.3367008","https://doi.org/10.1145/3328778.3367008","Micro-aggressions, hostile climates, and intersectional discrimination contribute to students feeling excluded from fully participating in Computer Science or other STEM programs. To address this exclusion, students need to empathize with each other, and for that we need them to be having frank, open conversations about difficult situations. This is hard to achieve, as people do not typically want to talk about difficult situations with strangers. Computer Science faculty may shy away from these difficult conversations, as they may feel they lack the expertise to address social issues effectively. To address this issue, we have been conducting 'Exclusion Response Workshops' based on the 'Theatre of the Oppressed' methodology of rehearsing social change. This involves students anonymously contributing scenarios of micro-aggressions they have experienced or witnessed and then roleplaying alternate outcomes. These workshops create an empathetic environment for frank and open discussion of difficult issues. We have been scaling this effort by conducting workshops with all freshmen and transfer students in our College of Computing and Informatics. In this SIGCSE workshop, attendees will participate in an Exclusion Response Workshop, then have an open discussion about the workshop experience, workshop logistics, and pros and cons of running this workshop as a mandatory class activity versus a voluntary activity. Participants will learn about the workshop structure, and the Theatre of the Oppressed methodology. This workshop is a taste of a 3-day, train-the-trainer workshop that we will be conducting at our institution in May 2020. Supported by NSF IUSE/RED Award #151960.","2020","2021-02-15 21:34:51","2021-02-15 21:34:51","","1395","","","","","","","SIGCSE '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, OR, USA","","","","diversity; inclusion; participatory-theatre; theatre-of-the-oppressed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITTJNNDL","conferencePaper","2014","Hamidi, Foad; Baljko, Melanie","Rafigh: An Edible Living Media Installation","Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction","978-1-4503-2635-3","","10.1145/2540930.2555209","https://doi.org/10.1145/2540930.2555209","In the face of increasing urbanization and lack of contact with nature, it is important to design systems that facilitate a re-connection or at least dialogue around our interaction with living beings. Rafigh, an empathetic living media interface, is designed to motivate children and adults to care for a living mushroom colony by engaging in collaborative and learning activies.","2014","2021-02-15 21:34:51","2021-02-15 21:34:51","","345–346","","","","","","","TEI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Munich, Germany","","","","embedded computing; living media interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBFC8RFC","conferencePaper","2016","Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid","Map Reading with an Empathic Robot Tutor","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.","2016","2021-02-15 21:34:51","2021-02-15 21:34:51","","567","","","","","","","HRI '16","","","","IEEE Press","","","","","","","","","event-place: Christchurch, New Zealand","","","","empathy; robot-child interaction; robotic tutor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57JQMV22","conferencePaper","2015","Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro","An Empathic Robotic Tutor in a Map Application","Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems","978-1-4503-3413-6","","","","In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.","2015","2021-02-15 21:34:51","2021-02-15 21:34:51","","1923–1924","","","","","","","AAMAS '15","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Istanbul, Turkey","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAREYWJ9","conferencePaper","2012","Taylor, Jason","The Trade Aid Computer Kiosk: Inclusive and Human Centred Design Technology at the Point of Sale","Proceedings of the 13th International Conference of the NZ Chapter of the ACM's Special Interest Group on Human-Computer Interaction","978-1-4503-1474-9","","10.1145/2379256.2379275","https://doi.org/10.1145/2379256.2379275","We present a computer kiosk for learning in the retail space connecting producers and consumers through Fair Trade. The project has explored reactions to simple, inclusive technology focusing on the human narrative within not for profit trade and empathic human centered design toward all stakeholders.","2012","2021-02-15 21:34:52","2021-02-15 21:34:52","","91","","","","","","","CHINZ '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Dunedin, New Zealand","","","","empathic design; computer kiosk; fair trade; human centred; rapid prototype; retail","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RQTP5Q42","journalArticle","2015","Leite, Iolanda","Long-Term Interactions with Empathic Social Robots","AI Matters","","","10.1145/2735392.2735397","https://doi.org/10.1145/2735392.2735397","We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.","2015-03","2021-02-15 21:34:52","2021-02-15 21:34:52","","13–15","","3","1","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2C4C2Y2Y","conferencePaper","2020","Soleymani, Mohammad","Machine Understanding of Emotion and Sentiment","Companion Publication of the 2020 International Conference on Multimodal Interaction","978-1-4503-8002-7","","10.1145/3395035.3425321","https://doi.org/10.1145/3395035.3425321","Emotions are subjective experiences involving perceptual and con-textual factors [4]. There is no objective tool for precise measurement of emotions. However, we can anticipate an emotion's emergence through the knowledge of common responses to events in similar situations. We can also measure proxies of emotions by recognizing emotional expressions [3]. Studying emotional response to multimedia allows identifying expected emotions in users consuming the content. For example,abrupt loud voices are novel and unsettling which result in surprise and higher experience of arousal [2,6]. For a particular type of con-tent such as music, mid-level attributes such as rhythmic stability or melodiousness have strong association with expected emotions[1]. Given that such mid-level attributes are more related to the con-tent, their machine-perception is more straightforward. Moreover,their perception in combination with user models enables building person-specific emotion anticipation models.In addition to studying expected emotions, we can also observe users emotional reactions to understand emotion in multimedia.Typical methods of emotion recognition include recognizing emotions from facial or vocal expressions. Recognition of emotional expressions requires large amount of labeled data, expensive to produce. Hence, the most recent advances in machine-based emotion perception include methods that can leverage unlabeled data through self-supervised and semi-supervised learning [3, 5]. In this talk, I review the field and showcase methods for automatic modeling and recognition of emotions and sentiment indifferent contexts [3,8]. I show how we can identify underlying factors contributing to the construction of subjective experience of emotions [1,7]. Identification of these factors allows us to use them as mid-level attributes to build machine learning models for emotion and sentiment understanding. I also show how emotions and sentiment can be recognized from expressions with the goal of building empathetic autonomous agents [8].","2020","2021-02-15 21:34:52","2021-02-15 21:34:52","","206–207","","","","","","","ICMI '20 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Netherlands","","","","machine learning; emotion; affective computing; sentiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XY8SSMIW","conferencePaper","2014","Nazir, Asad; Aylett, Ruth S.; Lim, Mei Yii; Endrass, Birgit; Hall, Lynne; Ritter, Christopher","MIXER: Why the Difference?","Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-2738-1","","","","This interactive demo features MIXER, a Virtual Learning Environment (VLE) consisting of synthetic characters representing the various actors in a scenario group difference scenario. MIXER creates virtual dramas by using interactive narrative with those characters. The goal is to enable children to identify social rule differences, by interacting with one of the characters to which they become empathic. MIXER is evaluated in the UK and Germany with children aged 9 to 11 years. The video for the demo content can be found at: http://youtu.be/jKIndn5NPaQ","2014","2021-02-15 21:34:52","2021-02-15 21:34:52","","1687–1688","","","","","","","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Paris, France","","","","artificial intelligence; applications; virtual learning environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHLVYCSD","conferencePaper","2016","Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra","How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","978-1-4673-8370-7","","","","We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.","2016","2021-02-15 21:34:52","2021-02-15 21:34:52","","423–424","","","","","","","HRI '16","","","","IEEE Press","","","","","","","","","event-place: Christchurch, New Zealand","","","","empathy; robotic tutors; child-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6699IAAP","conferencePaper","2018","Roberts, Jasmine","Using Affective Computing for Proxemic Interactions in Mixed-Reality","Proceedings of the Symposium on Spatial User Interaction","978-1-4503-5708-1","","10.1145/3267782.3274692","https://doi.org/10.1145/3267782.3274692","Immersive technologies have been touted as empathetic mediums. This capability has yet to be fully explored through machine learning integration. Our demo seeks to explore proxemics in mixed-reality (MR) human-human interactions.The author developed a system, where spatial features can be manipulated in real time by identifying emotions corresponding to unique combinations of facial micro-expressions and tonal analysis. The Magic Leap One is used as the interactive interface, the first commercial spatial computing head mounted (virtual retinal) display (HUD).A novel spatial user interface visualization element is prototyped that leverages the affordances of mixed-reality by introducing both a spatial and affective component to interfaces.","2018","2021-02-15 21:34:52","2021-02-15 21:34:52","","176","","","","","","","SUI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Berlin, Germany","","","","affective computing; augmented reality; mixed reality; Proxemics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZJM9Y88","conferencePaper","2019","Noortman, Renee; Schulte, Britta F.; Marshall, Paul; Bakker, Saskia; Cox, Anna L.","HawkEye - Deploying a Design Fiction Probe","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300652","https://doi.org/10.1145/3290605.3300652","This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.","2019","2021-02-15 21:34:52","2021-02-15 21:34:52","","1–14","","","","","","","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","design fiction; dementia care; future scenarios; informal caregiving; monitoring technologies; technology probes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AR5SNDRX","conferencePaper","2020","Bourdin, Pierre; Calvet, Laura; Tesconi, Susanna; Arnedo-Moreno, Joan","Reflecting on Attitudes Towards Death Through the Use of Immersive Virtual Reality Commercial Video Games","Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality","978-1-4503-8850-4","","10.1145/3434780.3436559","https://doi.org/10.1145/3434780.3436559","Video games can be an invaluable learning tool beyond pure skill acquisition, such as teaching us how to empathize with others or even self-reflecting on basic existential concerns: isolation, freedom, meaninglessness or death. This is further emphasized with the use of immersive technologies and becomes especially relevant when the experience itself is very difficult to replicate, when not impossible, in the real world. On that regard, this paper analyzes the impact of virtual reality (VR) commercial video games on the existential concern of one's own death. Participants (N 30) played one of three games for 15 minutes and the aftermath was examined using questionnaires and the implicit relational assessment procedure (IRAP). Our results show that there is no difference in the game experience, despite the different gameplay. However, IRAP results seem to indicate that players of the action game have a different attitude towards death.","2020","2021-02-15 21:34:52","2021-02-15 21:34:52","","640–647","","","","","","","TEEM'20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Salamanca, Spain","","","","Virtual reality; serious games; death-evaluation; death-identity; existential games; immersive player experiences; Implicit Relational Assessment Procedure; video games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8SMN2NFR","bookSection","2018","Giglitto, Danilo; Lazem, Shaimaa; Preston, Anne","In the Eye of the Student: An Intangible Cultural Heritage Experience, with a Human-Computer Interaction Twist","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","","https://doi.org/10.1145/3173574.3173864","We critically engage with CHI communities emerging outside the global North (ArabHCI and AfriCHI) to explore how participation is configured and enacted within socio-cultural and political contexts fundamentally different from Western societies. We contribute to recent discussions about postcolonialism and decolonization of HCI by focusing on non-Western future technology designers. Our lens was a course designed to engage Egyptian students with a local yet culturally-distant community to design applications for documenting intangible heritage. Through an action research, the instructors reflect on selected students' activities. Despite deploying a flexible learning curriculum that encourages greater autonomy, the students perceived themselves with less agency than other institutional stakeholders involved in the project. Further, some of them struggled to empathize with the community as the impact of the cultural differences on configuring participation was profound. We discuss the implications of the findings on HCI education and in international cross-cultural design projects.","2018","2021-02-15 21:34:52","2021-02-15 21:34:52","","1–12","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U8CSL74E","bookSection","2020","Qiu, Lisong; Shiu, Yingwai; Lin, Pingping; Song, Ruihua; Liu, Yue; Zhao, Dongyan; Yan, Rui","What If Bots Feel Moods?","Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","978-1-4503-8016-4","","","https://doi.org/10.1145/3397271.3401108","For social bots, smooth emotional transitions are essential for delivering a genuine conversation experience to users. Yet, the task is challenging because emotion is too implicit and complicated to understand. Among previous studies in the domain of retrieval-based conversational model, they only consider the factors of semantic and functional dependencies of utterances. In this paper, to implement a more empathetic retrieval-based conversation system, we incorporate emotional factors into context-response matching from two aspects: 1) On top of semantic matching, we propose an emotion-aware transition network to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework; 2) We design several flexible controlling mechanisms to customize social bots in terms of emotion. Extensive experiments on two benchmark datasets indicate that the proposed model can effectively track the flow of emotions throughout a human-machine conversation and significantly improve response selection in dialogues over the state-of-the-art baselines. We also empirically validate the emotion-control effects of our proposed model on three different emotional aspects. Finally, we apply such functionalities to a real IoT application.","2020","2021-02-15 21:34:52","2021-02-15 21:34:52","","1161–1170","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7WEGCQNR","conferencePaper","2020","Chapko, Dorota; Frumiento, Pino; Edwards, Nalini; Emeh, Lizzie; Kennedy, Donald; McNicholas, David; Overton, Michaela; Snead, Mark; Steward, Robyn; Sutton, Jenny M.; Jeffreys, Evie; Long, Catherine; Croll-Knight, Jess; Connors, Ben; Castell-Ward, Sam; Coke, David; McPeake, Bethany; Renel, William; McGinley, Chris; Remington, Anna; Whittuck, Dora; Kieffer, John; Ewans, Sarah; Williams, Mark; Grierson, Mick","""We Have Been Magnified for Years - Now You Are under the Microscope!"": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities","Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","978-1-4503-6708-0","","10.1145/3313831.3376278","https://doi.org/10.1145/3313831.3376278","Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.","2020","2021-02-15 21:34:52","2021-02-15 21:34:52","","1–17","","","","","","","CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Honolulu, HI, USA","","","","attitudes; design; disability; survey; participatory/inclusive research; video","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7KP5ECK","conferencePaper","2020","Carrasco, Romina; A. Baker, Felicity; A. Bukowska, Anna; N. Clark, Imogen; M. Flynn, Libby; McMahon, Kate; Odell-Miller, Helen; Stensaeth, Karette; Tamplin, Jeanette; Vieira Sousa, Tanara; Waycott, Jenny; Wosch, Thomas","Empowering Caregivers of People Living with Dementia to Use Music Therapeutically at Home: Design Opportunities","32nd Australian Conference on Human-Computer Interaction","978-1-4503-8975-4","","10.1145/3441000.3441082","https://doi.org/10.1145/3441000.3441082","Human-computer interaction researchers have explored how to design technologies to support people with dementia (PwD) and their caregivers, but limited attention has been given to how to facilitate music therapy in dementia care. The use of music to help manage the symptoms of dementia is often guided by a music therapist who adapts the intervention to respond to the changing needs of the person living with dementia. However, as the incidence of dementia increases worldwide, individualised therapy programs are less feasible, making it valuable to consider technology-based approaches. In this paper, we analyze data from case studies of home-based music therapy training interventions with two families. The findings show that embodied interactions supported the therapist in responding to the needs of the PwD and built an empathic environment that empowered the caregivers’ learning. We discuss opportunities and challenges for designing technologies that support family caregivers’ therapy-informed music use in dementia care.","2020","2021-02-15 21:34:52","2021-02-15 21:34:52","","198–209","","","","","","","OzCHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Sydney, NSW, Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BNFP56I","conferencePaper","2012","Khaled, Rilla","Muse-Based Game Design","Proceedings of the Designing Interactive Systems Conference","978-1-4503-1210-3","","10.1145/2317956.2318065","https://doi.org/10.1145/2317956.2318065","Game design and user experience (UX) design both centre on the design of experiences. But whereas it is par for the course for end-user perspectives to be included during early design stages in UX, there is little methodological support or research into how to incorporate player perspectives into early stages of game design. In this paper, we introduce muse-based game design, an experimental empathic design approach foregrounding a dialogic artist – muse relationship between a game designer and player. Following a user research stage focused on learning about the player, the designer forms idiosyncratic design constraints inspired by and relating to the player, which are then used to inspire ideation. To understand the consequences, advantages, and disadvantages of this approach, we discuss findings from two years of application of this style of game design in a Master's-level class of game design students at the IT University of Copenhagen.","2012","2021-02-15 21:34:52","2021-02-15 21:34:52","","721–730","","","","","","","DIS '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Newcastle Upon Tyne, United Kingdom","","","","empathic design; game design; design processes; player-centred design; player-centric design; reflective design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WH7556LY","conferencePaper","2014","Iacono, Iolanda; Marti, Patrizia","Engaging Older People with Participatory Design","Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational","978-1-4503-2542-4","","10.1145/2639189.2670180","https://doi.org/10.1145/2639189.2670180","We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.","2014","2021-02-15 21:34:52","2021-02-15 21:34:52","","859–864","","","","","","","NordiCHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Helsinki, Finland","","","","empathy; participatory design; older people; gaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JW5AKTN","conferencePaper","2019","W. Bennett, Gregory; Canner, Liz","Lost City of Mer","SIGGRAPH Asia 2019 XR","978-1-4503-6947-3","","10.1145/3355355.3361897","https://doi.org/10.1145/3355355.3361897","Lost City of Mer is a virtual reality (VR) game experience combined with a smartphone app that immerses players in a fantasy undersea civilization devastated by ecological disaster caused by global warning. The project aims to harness the immersive and empathetic potential of VR to address climate change and create a sense of urgency in the player with regard to their personal carbon footprint.Players are invited to help rebuild the lost world of Mer and its devastated ecosystem in VR by re-establishing its unique flora and fauna, and fighting ongoing dangers and threats, with the aim of bringing back to life its mysterious Mer-people inhabitants. Guided by a solitary seal spirit named Athina – the last of its kind in a dying ocean – players try to save the Mer population from extinction. They tend to secret gardens of coral threatened by pollution, create habitats for Mer-people, and explore the destroyed civilization, in the process learning how their real-world actions impact the world around them.The project was developed with the input of environmental scientists from Harvard University and Dartmouth College. The experience is based on real science, but told through fantasy, as it draws on the cross-cultural myth of the mermaid to appeal to people across the globe.","2019","2021-02-15 21:34:52","2021-02-15 21:34:52","","25–26","","","","","","","SA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Brisbane, QLD, Australia","","","","climate change; virtual reality; serious games; VR navigation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9U8HYFLE","conferencePaper","2018","Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia","A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","","","","","Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.","2018","2021-02-15 21:34:52","2021-02-15 21:34:52","","1658–1666","","","","","","","AAMAS '18","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Stockholm, Sweden","","","","social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8YW9QFF","conferencePaper","2017","Frueh, Christian; Sud, Avneesh; Kwatra, Vivek","Headset Removal for Virtual and Mixed Reality","ACM SIGGRAPH 2017 Talks","978-1-4503-5008-2","","10.1145/3084363.3085083","https://doi.org/10.1145/3084363.3085083","Virtual Reality (VR) has advanced significantly in recent years and allows users to explore novel environments (both real and imaginary), play games, and engage with media in a way that is unprecedentedly immersive. However, compared to physical reality, sharing these experiences is difficult because the user's virtual environment is not easily observable from the outside and the user's face is partly occluded by the VR headset. Mixed Reality (MR) is a medium that alleviates some of this disconnect by sharing the virtual context of a VR user in a flat video format that can be consumed by an audience to get a feel for the user's experience.Even though MR allows audiences to connect actions of the VR user with their virtual environment, empathizing with them is difficult because their face is hidden by the headset. We present a solution to address this problem by virtually removing the headset and revealing the face underneath it using a combination of 3D vision, machine learning and graphics techniques. We have integrated our headset removal approach with Mixed Reality, and demonstrate results on several VR games and experiences.","2017","2021-02-15 21:34:52","2021-02-15 21:34:52","","","","","","","","","SIGGRAPH '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Los Angeles, California","","","","virtual reality; mixed reality; facial synthesis; headset removal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HK3HTASI","conferencePaper","2018","Corral, Luis; Fronza, Ilenia","Design Thinking and Agile Practices for Software Engineering: An Opportunity for Innovation","Proceedings of the 19th Annual SIG Conference on Information Technology Education","978-1-4503-5954-2","","10.1145/3241815.3241864","https://doi.org/10.1145/3241815.3241864","Commonly, the instruction of Software Engineering implements processes that are inherent to the theory and practice of software development. Traditional and Agile methods lay the foundation for building ""functional software products"" that meet the requirements of a system of a larger scope. However, if we consider software as a product that frequently has the mission of satisfying the needs of human users, we can go beyond the typical ""analysis - design - implementation - testing"" process, to reinterpret it with the ""empathize - define - ideate - prototype - testing"" proposed by Design Thinking, a development methodology commonly used in creative and innovative professional settings. In this work, we study the use of Design Thinking as a methodological approach for the instruction of Software Engineering at undergraduate level, in courses that have the particular aim of creating innovative software products from scratch. We describe the similarities and differences between Design Thinking and Software Development Processes, taking as instance Agile Practices. We compare evidence on methods and deliverables produced by students in their learning path using Agile Practices and Design Thinking in two different educational environments. Finally, we discuss coincidences, weaknesses, and opportunities to keep investigating in this topic as a research subject, toward finding practices to promote in students both creativity and technical discipline to develop innovative software solutions","2018","2021-02-15 21:34:52","2021-02-15 21:34:52","","26–31","","","","","","","SIGITE '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Fort Lauderdale, Florida, USA","","","","education; creativity; agile; design thinking; software engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGYYMFI6","conferencePaper","2019","Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios","Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability","Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","978-1-4503-6232-0","","10.1145/3316782.3322767","https://doi.org/10.1145/3316782.3322767","Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.","2019","2021-02-15 21:34:52","2021-02-15 21:34:52","","442–447","","","","","","","PETRA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rhodes, Greece","","","","age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3LZXM2G","book","2014","","IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces","","978-1-4503-2184-6","","","","It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.","2014","2021-02-15 21:34:52","2021-02-15 21:34:52","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4U8UTHWD","book","2014","","IUI Companion '14: Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces","","978-1-4503-2729-9","","","","It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.","2014","2021-02-15 21:34:52","2021-02-15 21:34:52","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PDWWFJUV","conferencePaper","2016","Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Moncur, Wendy; McNaney, Roisin; Vines, John; Branham, Stacy","Ethical Encounters in Human-Computer Interaction","Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4082-3","","10.1145/2851581.2856498","https://doi.org/10.1145/2851581.2856498","In the HCI community, there is growing recognition that a reflective and empathetic approach is needed to conduct ethical research in sensitive settings with people who might be considered vulnerable or marginalized. At our CHI 2015 workshop on ethical encounters, researchers shared personal stories of the challenges and tensions they have faced when conducting HCI research in complex settings such as hospitals, with young mental health patients, in schools for children with disabilities, and with homeless people. These research contexts can present significant challenges for HCI researchers who would not typically receive the training that other professionals working in these environments would normally receive. From our discussions with attendees at the CHI 2015 workshop, we identified a number of ethical issues that researchers are grappling with. In this follow-up workshop we aim to build on the lessons learned and to generate pragmatic but sensitive solutions to manage complex ethical issues for HCI researchers working in challenging settings.","2016","2021-02-15 21:34:52","2021-02-15 21:34:52","","3387–3394","","","","","","","CHI EA '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Jose, California, USA","","","","ethics; sensitive settings; vulnerable participants","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3QBK3GV","bookSection","2017","Van Mechelen, Maarten; Høiseth, Marikken; Baykal, Gökçe Elif; Van Doorn, Fenne; Vasalou, Asimina; Schut, Alice","Analyzing Children's Contributions and Experiences in Co-Design Activities: Synthesizing Productive Practices","Proceedings of the 2017 Conference on Interaction Design and Children","978-1-4503-4921-5","","","https://doi.org/10.1145/3078072.3081314","Today, it has been broadly acknowledged in the CCI community that children are not only active learners and users of technology, but can also actively participate in the design process. However, it remains challenging to analyze children's experiences and creative contributions resulting from co-design activities (e.g. stories, paper prototypes, enacted ideas). Broadly speaking, a distinction can be made between researchers looking for inspiration in the form of useful design ideas, and researchers that take a more interpretative stance by looking beyond the surface level of children's ideas to better understand and empathize with them. This knowledge about children is often used to more accurately define the problem space at the early stages of design. Both perspectives to co-design can be seen as the opposite ends of the same continuum, and many researchers combine aspects of both depending on where they are in the design process (e.g. defining the design problem, prototyping stage). This workshop will explore different ways to analyze children's (0 to 18 years) experiences and contributions in co-design activities, the perceived benefits and challenges of these approaches, and will serve as a venue for synthesizing productive practices that will move the CCI community forward.","2017","2021-02-15 21:34:53","2021-02-15 21:34:53","","769–772","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCWWIFQI","journalArticle","2014","Tracey, Ryan","The Agony or the Empathy? An Interview with Anne Bartlett-Bragg","ELearn","","","10.1145/2578511.2576869","https://doi.org/10.1145/2578511.2576869","Anne Bartlett-Bragg holds a unique space in eLearning as both a researcher and a practitioner. In this interview, Anne discusses the importance of immersion. By empathizing with the learner, one can truly design the best solution.","2014-02","2021-02-15 21:34:53","2021-02-15 21:34:53","","","","2","2014","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XS77SBCG","bookSection","2020","Ranjbartabar, Hedieh; Richards, Deborah; Bilgin, Ayse Aysin; Kutay, Cat; Mascarenhas, Samuel","User-Models to Drive an Adaptive Virtual Advisor: Demonstration","Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems","978-1-4503-7518-4","","","","Agents that adapt to their user need to have knowledge of their user and expertise on how best to adapt to that type of user. In this paper we describe the addition of an agent's expertise and collection of machine-learnt user profiles to the proposed extended FAtiMA (Fearnot AffecTive Mind Architecture) cognitive agent architecture. A study to evaluate the extended architecture is presented which compares the benefit (i.e. reduced stress and increased rapport) of tailoring dialogue (i.e. empathic or neutral) to the specific user.","2020","2021-02-15 21:34:53","2021-02-15 21:34:53","","2117–2119","","","","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQKP7XPV","conferencePaper","2018","Itenge-Wheeler, Helvi; Winschiers-Theophilus, Heike; Soro, Alessandro; Brereton, Margot","Child Designers Creating Personas to Diversify Design Perspectives and Concepts for Their Own Technology Enhanced Library","Proceedings of the 17th ACM Conference on Interaction Design and Children","978-1-4503-5152-2","","10.1145/3202185.3202760","https://doi.org/10.1145/3202185.3202760","We report on a participatory design project that explored the use of child-created Personas to enable child designers to empathize with other children thereby contributing multiple divergent perspectives. The ongoing project aims to promote reading and creative writing skills among young children in Namibia. For decades libraries worldwide have been the key actors in fostering reading. Hence, in order to maintain their relevance, they are being re-conceptualized to cater for new needs and aspirations in the 21st century. In Namibia, dysfunctional public and school library services are lagging behind in this renovation effort, and are not contributing to the promotion of a reading culture. In an ongoing collaboration with a school in Windhoek, to design and implement an interactive tech library, 19 young learners engaged in weekly participatory design workshops to redesign their own school library. The children first created four distinct Personas for which they then modelled spaces and technologies. This paper reflects on the techniques used to enable children to become active design partners and to gain an understanding of designing for other children.","2018","2021-02-15 21:34:53","2021-02-15 21:34:53","","381–388","","","","","","","IDC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Trondheim, Norway","","","","children; design; participatory design; interactive tech library; Namibia; persona; reading experiences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZTNHDTH","bookSection","2017","Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Branham, Stacy; Moncur, Wendy; McNaney, Roisin; Vines, John","Ethical Encounters in HCI: Implications for Research in Sensitive Settings","Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-4656-6","","","https://doi.org/10.1145/3027063.3027089","This workshop builds on the success of prior workshops that brought together HCI researchers to share stories about ethical challenges faced when conducting research in sensitive settings. There is growing recognition that reflective and empathetic approaches are needed to conduct ethical research in settings involving people who might be considered vulnerable or marginalized. At our previous workshops, researchers discussed personal experiences and described the complex challenges they have faced in research as diverse as designing information systems for families of children in palliative care to analyzing social media posts about mental health. In this follow-up workshop we aim to extend opportunities for knowledge-sharing, build on the lessons learned, and generate a range of resources to help HCI researchers manage complex ethical issues when working in sensitive settings.","2017","2021-02-15 21:34:53","2021-02-15 21:34:53","","518–525","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTBHRCVN","conferencePaper","2015","Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia","Designing a Socially Assistive Robot for Pediatric Care","Proceedings of the 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771923","https://doi.org/10.1145/2771839.2771923","We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.","2015","2021-02-15 21:34:53","2021-02-15 21:34:53","","387–390","","","","","","","IDC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boston, Massachusetts","","","","child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86DCU99N","conferencePaper","2014","Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid","Werewolves, Cheats, and Cultural Sensitivity","Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems","978-1-4503-2738-1","","","","MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.","2014","2021-02-15 21:34:53","2021-02-15 21:34:53","","1085–1092","","","","","","","AAMAS '14","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Paris, France","","","","empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RP2Y9HQ","conferencePaper","2013","Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth","Towards Empathic Artificial Tutors","Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction","978-1-4673-3055-8","","","","In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.","2013","2021-02-15 21:34:53","2021-02-15 21:34:53","","113–114","","","","","","","HRI '13","","","","IEEE Press","","","","","","","","","event-place: Tokyo, Japan","","","","empathy; human-robot interaction; robotic tutors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XVIX84U","conferencePaper","2016","Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia","Affect-Aware Student Models for Robot Tutors","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration.In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models.These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.","2016","2021-02-15 21:34:53","2021-02-15 21:34:53","","864–872","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","affective computing; child-robot interaction; socially assistive robots; educational robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPTAVIA8","conferencePaper","2010","Chen, Yu-Chung; Lee, Sangyoon; Hur, HyeJung; Leigh, Jason; Johnson, Andrew; Renambot, Luc","Case Study: Designing an Advanced Visualization System for Geological Core Drilling Expeditions","CHI '10 Extended Abstracts on Human Factors in Computing Systems","978-1-60558-930-5","","10.1145/1753846.1754206","https://doi.org/10.1145/1753846.1754206","We present the design and process of an interactive high-resolution visualization system for diverse and distributed real-world geological core drilling expeditions. The high domain knowledge barrier makes it difficult for a person who is outside this field to imagine the user experience, and the globally distributed core drilling community imposes more design constraints in space and time. In addition to activities proposed in prior literatures, we used the ""immersive empathic design"" approach of having a computer scientist trained as a junior core technician. Through in-situ observation and interview evaluations from on-going expeditions, we present the system and the lesson learned in the process. It makes the best use of precious co-located opportunities. It allows the developer to build up domain knowledge efficiently. It establishes a trust relationship between the developer and scientists. The system designed through this approach formed a sustainable foundation that was adapted in the following design iterations. This process allows the software developer to experience authentic user activities. The designed system is innovative and helps scientists solving real-world problems. This approach can be a useful example to HCI practitioners who work with potential users or communities that share similar properties.","2010","2021-02-15 21:34:53","2021-02-15 21:34:53","","4645–4660","","","","","","","CHI EA '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Atlanta, Georgia, USA","","","","empathic design; visualization; hci","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUEXYV2P","conferencePaper","2019","Roth, Daniel; Bloch, Carola; Schmitt, Josephine; Frischlich, Lena; Latoschik, Marc Erich; Bente, Gary","Perceived Authenticity, Empathy, and Pro-Social Intentions Evoked through Avatar-Mediated Self-Disclosures","Proceedings of Mensch Und Computer 2019","978-1-4503-7198-8","","10.1145/3340764.3340797","https://doi.org/10.1145/3340764.3340797","Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one's avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support.","2019","2021-02-15 21:35:37","2021-02-15 21:35:37","","21–30","","","","","","","MuC'19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hamburg, Germany","","","","Empathy; Avatars; Social Perception; Virtual Characters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AY746YDJ","conferencePaper","2017","Murphy, Dooley","Building a Hybrid Virtual Agent for Testing User Empathy and Arousal in Response to Avatar (Micro-)Expressions","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3141217","https://doi.org/10.1145/3139131.3141217","This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR.","2017","2021-02-15 21:35:37","2021-02-15 21:35:37","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","virtual reality; social presence; avatar capture; social plausibility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NT3G869D","conferencePaper","2016","Ishii, Yutaka; Watanabe, Tomio; Sejima, Yoshihiro","Development of an Embodied Avatar System Using Avatar-Shadow's Color Expressions with an Interaction-Activated Communication Model","Proceedings of the Fourth International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2980487","https://doi.org/10.1145/2974804.2980487","In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color.","2016","2021-02-15 21:35:37","2021-02-15 21:35:37","","337–340","","","","","","","HAI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Biopolis, Singapore","","","","avatar-mediated communication; embodied interaction; avatar's shadow; color expression.; virtual face-to-face communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKXALRVS","conferencePaper","2010","Van Looy, Jan; Courtois, Cédric; De Vocht, Melanie","Player Identification in Online Games: Validation of a Scale for Measuring Identification in MMORPGs","Proceedings of the 3rd International Conference on Fun and Games","978-1-60558-907-7","","10.1145/1823818.1823832","https://doi.org/10.1145/1823818.1823832","In this paper, we present a Player Identification (PI) scale for measuring identification in MMORPGs. Three main dimensions were derived from the literature (1) Avatar (character) Identification, (2) Group (guild) Identification and (3) Game (community) Identification whereby Avatar Identification is a second-order factor consisting of (1a) Perceived Similarity, (1b) Wishful Identification and (1c) Embodied Presence. Based on the results of a cross-sectional survey of 544 World of Warcraft players the measurement instrument's proposed factorial structure was confirmed. Subsequently, the constructs were successfully tested both for convergent and discriminant validity. Finally, evidence for nomological validity was gathered by testing ten theoretically rooted hypotheses regarding the effects of Player Identification. The results showed that Avatar Identification positively predicts Empathy, Proteus effect and the motivations role-play, customization and escapism. Group Identification predicts socializing and relationship, and Game Identification predicts advancement, mechanics and escapism.","2010","2021-02-15 21:35:37","2021-02-15 21:35:37","","126–134","","","","","","","Fun and Games '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Leuven, Belgium","","","","identification; avatar; MMORPG; World of Warcraft; measurement scale","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N84LURWE","conferencePaper","2017","Vieira, Suanny; Santos, Alexandre; Costa, Rostand; Maritan, Tiago; Aschoff, Manuella; Veríssimo, Vinícius","A Study on the Use of Multiple Avatars in 3D Sign Language Dictionaries","Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web","978-1-4503-5096-9","","10.1145/3126858.3126865","https://doi.org/10.1145/3126858.3126865","Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors.","2017","2021-02-15 21:35:37","2021-02-15 21:35:37","","325–332","","","","","","","WebMedia '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gramado, RS, Brazil","","","","accessibility; avatar; machine translation; retargeting; sign language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZL8ZQZD","conferencePaper","2011","Cheong, Wei Lun; Jung, Younbo; Theng, Yin-Leng","Avatar: A Virtual Face for the Elderly","Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry","978-1-4503-1060-4","","10.1145/2087756.2087850","https://doi.org/10.1145/2087756.2087850","Studies in the field of human-computer interaction have demonstrated a significant impact of avatars and virtual environments on users' interaction experiences and behaviors. However, most of these studies are focused on the young users. With an aging population and more virtual environments built for the elderly, it is important to investigate the types of avatars elderly users prefer and hence provide them with a richer interaction experience through the use of avatars as virtual representations of themselves. In our exploratory study, 24 seniors aged 55 years and above evaluated 20 custom-created avatars. Results showed that the elderly participants were unable to identify with the avatars. However, the results showed a strong trust towards child avatars and an attraction towards animal and object avatars, which indicates a different form of identification or empathy. The paper concludes with discussion of avatar design for the elderly users.","2011","2021-02-15 21:35:37","2021-02-15 21:35:37","","491–498","","","","","","","VRCAI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hong Kong, China","","","","avatars; elderly","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIC6T3I3","conferencePaper","2017","Tong, Xin; Ulas, Servet; Jin, Weina; Gromala, Diane; Shaw, Chris","The Design and Evaluation of a Body-Sensing Video Game to Foster Empathy towards Chronic Pain Patients","Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare","978-1-4503-6363-1","","10.1145/3154862.3154869","https://doi.org/10.1145/3154862.3154869","Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations.","2017","2021-02-15 21:35:37","2021-02-15 21:35:37","","244–250","","","","","","","PervasiveHealth '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","empathy; serious games; body-sensing games; chronic pain; embodied simulation; gaming for a purpose","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLMYBW2V","conferencePaper","2015","Andersen, Josephine Soegaard; Schoenau-Fog, Henrik","Using Role-Taking and Behavioral Mimicking in Games to Increase Awareness on the Bystander Effect","Proceedings of the 19th International Academic Mindtrek Conference","978-1-4503-3948-3","","10.1145/2818187.2818290","https://doi.org/10.1145/2818187.2818290","This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.","2015","2021-02-15 21:35:37","2021-02-15 21:35:37","","69–72","","","","","","","AcademicMindTrek '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tampere, Finland","","","","behavioral mimicking; bystander effect; mimetic activity; proteus effect; role playing; role-taking; serious game; simulations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPWE3GD5","conferencePaper","2019","Degraen, Donald; Kosmalla, Felix; Krüger, Antonio","Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3312833","https://doi.org/10.1145/3290607.3312833","Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.","2019","2021-02-15 21:35:37","2021-02-15 21:35:37","","1–6","","","","","","","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","ambient notifications; empathic living media; focus group; ambient interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZU7TZZ27","conferencePaper","2015","Encinas, Enrique","Cyrafour: How Two Human Avatars Communicate With Each Other","Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems","978-1-4503-3146-3","","10.1145/2702613.2726962","https://doi.org/10.1145/2702613.2726962","Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.","2015","2021-02-15 21:35:37","2021-02-15 21:35:37","","109–114","","","","","","","CHI EA '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Seoul, Republic of Korea","","","","embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRC9FWGY","conferencePaper","2017","Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin","Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3139132","https://doi.org/10.1145/3139131.3139132","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.","2017","2021-02-15 21:35:37","2021-02-15 21:35:37","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","pet game; user types; virtual pet; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K88BLLSK","conferencePaper","2013","Plant, Nicola; Healey, Patrick G.T.","Surface Tension","CHI '13 Extended Abstracts on Human Factors in Computing Systems","978-1-4503-1952-2","","10.1145/2468356.2479589","https://doi.org/10.1145/2468356.2479589","The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?","2013","2021-02-15 21:35:37","2021-02-15 21:35:37","","2979–2982","","","","","","","CHI EA '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Paris, France","","","","empathy; embodied cognition; gesture; nonverbal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6F9NWBT6","conferencePaper","2014","Gasselseder, Hans-Peter","Dynamic Music and Immersion in the Action-Adventure an Empirical Investigation","Proceedings of the 9th Audio Mostly: A Conference on Interaction With Sound","978-1-4503-3032-9","","10.1145/2636879.2636908","https://doi.org/10.1145/2636879.2636908","Aiming to immerse players into a new realm of drama experience, a growing number of video games utilize interactive, 'dynamic' music that reacts adaptively to game events. Though little is known about the involved perceptual processes, the design rationale of enhanced immersive experiences is taken over by public discussion including scientific accounts, despite lacking empirical validation. The present paper intends to fill this gap by hypothesizing facilitatory effects of dynamic music on attention allocation in the matching of expected and incoming expressive characteristics of concurrent stimuli. Moreover, personality constructs are investigated in mediating the decoding and sensing of experiences linked to immersion, presence, and emotion. The experiment explored experiential states of immersion, emotional valence/arousal as well as trait music empathizing and emotional involvement in the context of dynamic and non-dynamic music. 60 subjects answered self-report questionnaires each time after playing a 3rd-person action-adventure in one of three conditions accounting for (1) dynamic music, (2) non-dynamic music/low arousal potential and (3) non-dynamic music/high arousal potential, in this way aiming to manipulate structural-temporal alignment, emotional arousal and resulting congruency of nondiegetic music. Shedding light on the implications of music dramaturgy within a semantic ecology, different layers of mind sets between the player, avatar, and game environment are assumed to moderate a continuous regulatory modulation of emotional response achieved by context effects of dynamic music.","2014","2021-02-15 21:35:38","2021-02-15 21:35:38","","","","","","","","","AM '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Aalborg, Denmark","","","","emotion; presence; immersion; dynamic music; games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECF5R9TU","conferencePaper","2019","Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios","Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability","Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","978-1-4503-6232-0","","10.1145/3316782.3322767","https://doi.org/10.1145/3316782.3322767","Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.","2019","2021-02-15 21:35:38","2021-02-15 21:35:38","","442–447","","","","","","","PETRA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Rhodes, Greece","","","","age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R9AUWELX","conferencePaper","2015","Encinas, Enrique; Mitchell, Robb","Cyrafour: An Experiential Activity Facilitating Empathic Distant Communication among Copresent Individuals","Proceedings of the 6th Augmented Human International Conference","978-1-4503-3349-8","","10.1145/2735711.2735815","https://doi.org/10.1145/2735711.2735815","Distant communication relies mostly on a non-embodied representation of participants (e.g. textual in chats, photographic in videoconference, auditory in telephony, etc) that lessens the sensory richness of conversational interactions. Cyrafour is a novel activity that explores the implications of using human avatars (cyranoids) for empathic interpersonal remote communication. An unscripted conversation between two individuals (the sources) is transmitted through radio waves and reproduced by two copresent subjects (the cyranoids) following certain conversational guidelines. In particular, the Sources were invited to discuss about a topic, play a conversation game and comment on an opinionated video. All Cyrafour sessions were video-taped and participants interviewed afterwards in order to support analysis and discussion. Cyrafour could be considered as a playful embodied identity game in which cyranoids are simultaneously together in and aside from a conversation generated elsewhere. This puzzling circumstance seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised.","2015","2021-02-15 21:35:38","2021-02-15 21:35:38","","165–166","","","","","","","AH '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","embodied cognition; serious games; copresence; cyranoids; human avatars; telepresence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MR225G7U","conferencePaper","2019","Zelenskaya, Maria; Harvey, Louise","Virtual Avatars as a Tool for Audience Engagement","The 17th International Conference on Virtual-Reality Continuum and Its Applications in Industry","978-1-4503-7002-8","","10.1145/3359997.3365717","https://doi.org/10.1145/3359997.3365717","Modern motion capture tools can be used to animate sophisticated digital characters in real time. Through these virtual avatars human performers can communicate with live audience, creating a promising new area of application for public engagement. This study describes a social experiment where a real-time multimedia setup was used to facilitate an interaction between a digital character and visitors at a public venue. The technical implementation featured some innovative elements, such as using iPhone TrueDepth Camera as part of the performance capture pipeline. The study examined public reactions during the experiment in order to explore the empathic potential of virtual avatars and assess their ability to engage live audience.","2019","2021-02-15 21:35:38","2021-02-15 21:35:38","","","","","","","","","VRCAI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Brisbane, QLD, Australia","","","","audience engagement; Real-time motion capture; virtual avatar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZTLTK4H","conferencePaper","2016","Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka","Sharing Emotion Described as Text on the Internet by Changing Self-Physiological Perception","Proceedings of the Fourth International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2974825","https://doi.org/10.1145/2974804.2974825","Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.","2016","2021-02-15 21:35:38","2021-02-15 21:35:38","","145–153","","","","","","","HAI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Biopolis, Singapore","","","","emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJVWHGZG","conferencePaper","2017","Valverde, Isabel; Cochrane, Todd","Senses Places: Soma-Tech Mixed-Reality Participatory Performance Installation/Environment","Proceedings of the 8th International Conference on Digital Arts","978-1-4503-5273-4","","10.1145/3106548.3106613","https://doi.org/10.1145/3106548.3106613","We present the latest developments of the art-tech research project Senses Places, a somatic-technological (soma-tech) mixed-reality participatory performance installation/environment, engaging expanded modes of embodied physical-virtual interaction. This ongoing somatic-technological dance/performance collaborative trans-disciplinary approach gathers artists and developer researchers, working remotely and physically in analogical-digital intermedia interfaces and their expanded experience design and choreography. The sensorial expansion and integration sought through human-computer interaction links participants, avatars, images and physical-virtual environments. They constitute different organic-artificial sensorial-expressive channels of visual, audio, tactile, and somatic/kinesthetic shared tuning/engagement/experience. At the core of this long-term intervention lies the common urging desire for more encompassing and empathic embodied interactivity among physical and remote subjects and places. With a cross-cultural somatic and dance practices, Senses Places critically experiments with different informational, communicational and biomedical technologies available, wishing to contribute to understand the world's and humans becoming through what we have been conceiving as posthuman corporealities [1] within a posthuman condition and emerging somatic epistemology [2].","2017","2021-02-15 21:35:38","2021-02-15 21:35:38","","195–197","","","","","","","ARTECH2017","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Macau, China","","","","Dance-technology; Interaction design; Interactive art; Posthuman corporealities; Somatic epistemology; Somatics; Virtual and mixed-reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KS4TE2MZ","conferencePaper","2013","Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria","3D Animated Agent for Tutoring Based on WebGL","Proceedings of the 18th International Conference on 3D Web Technology","978-1-4503-2133-4","","10.1145/2466533.2466534","https://doi.org/10.1145/2466533.2466534","The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.","2013","2021-02-15 21:35:38","2021-02-15 21:35:38","","129–134","","","","","","","Web3D '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: San Sebastian, Spain","","","","artificial intelligence; e-learning; virtual agents; Web3D technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TSJD4SI","conferencePaper","2016","Kim, Jungwoo; Kim, Hyesook; Choi, Jaeboong","Development of Smart Product, DUET Using SQFD and Storytelling","Proceedings of HCI Korea","978-89-6848-791-0","","10.17210/hcik.2016.01.298","https://doi.org/10.17210/hcik.2016.01.298","This paper presents a smart product design process for a wearable device to provide empathy and fun to users. As the first step, keywords were extracted using open-coding methods from text WebData of online sites for wearable devices, Smardi, Sblog, and Wsite. The Smart Quality Function Deployment (SQFD) was then applied to prioritize the keywords and corresponding user requirements. The key user requirements such as 'separable band from core module' and 'function for media control' were then materialized into a wearable band, DUET, using rapid prototyping, and refined through three stages of user evaluation. DUET connectable to iOS and Android smartphones was introduced by a storytelling transmedia videoclip by experts with a theme of empathy and fun. It was also advertised on a cloud funding site, Indiegogo, and through a PPL in S entertainment program, and received positive responses. Further detailed analysis of user responses was performed for 72 days through the operation of facebook-DUET site and for 10 days through Google keyword marketing which derived various levels of user activities.","2016","2021-02-15 21:36:05","2021-02-15 21:36:05","","298–306","","","","","","","HCIK '16","","","","Hanbit Media, Inc.","Seoul, KOR","","","","","","","","event-place: Jeongseon, Republic of Korea","","","","RP; SQFD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KD9RUDW8","conferencePaper","2018","Brueckner, Sophia","Empathy Amulet: A Wearable to Connect with Strangers","Proceedings of the 2018 ACM International Symposium on Wearable Computers","978-1-4503-5967-2","","10.1145/3267242.3267301","https://doi.org/10.1145/3267242.3267301","The Empathy Amulet is a wearable interpretation of Philip K. Dick's empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both haptically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today's world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson's theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4].","2018","2021-02-15 21:36:05","2021-02-15 21:36:05","","248–253","","","","","","","ISWC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","embodied cognition; haptic I/O; internet of things; prototyping; wearable electronics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
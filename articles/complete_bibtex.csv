Key;Item Type;Publication Year;Author;Title;Publication Title;ISBN;ISSN;DOI;Url;Abstract Note;Date;Date Added;Date Modified;Access Date;Pages;Num Pages;Issue;Volume;Number Of Volumes;Journal Abbreviation;Short Title;Series;Series Number;Series Text;Series Title;Publisher;Place;Language;Rights;Type;Archive;Archive Location;Library Catalog;Call Number;Extra;Notes;File Attachments;Link Attachments;Manual Tags;Automatic Tags;Editor;Series Editor;Translator;Contributor;Attorney Agent;Book Author;Cast Member;Commenter;Composer;Cosponsor;Counsel;Interviewer;Producer;Recipient;Reviewed Author;Scriptwriter;Words By;Guest;Number;Edition;Running Time;Scale;Medium;Artwork Size;Filing Date;Application Number;Assignee;Issuing Authority;Country;Meeting Name;Conference Name;Court;References;Reporter;Legal Status;Priority Numbers;Programming Language;Version;System;Code;Code Number;Section;Session;Committee;History;Legislative Body
3RR4P2S4;journalArticle;2021;"Cuzzocrea, Alfredo; Pilato, Giovanni";A composite framework for supporting user emotion detection based on intelligent taxonomy handling;LOGIC JOURNAL OF THE IGPL;NA;1367-0751;10.1093/jigpal/jzaa047;NA;One of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her. The first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper. The system can analyze the Twitter ID of the new acquaintance, trying to detect the IAB (Interactive Advertising Bureau) Tier 1 categories that possibly can let arise in him/her a joyful feeling. Furthermore, it can retrieve news about that category and report them to the user, hopefully increasing his/her curiosity towards the system, improving the naturalness of the interaction. Moreover, the system is capable of querying Wikipedia in order to clarify any doubts that may arise in the user. A sample of a possible interaction is reported at the end of the paper.;2021-04;2021-05-19T13:29:52Z;2021-05-19T13:29:52Z;NA;207-219;13;2;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article;NA;NA;NA;NA;"human-robot interaction; affective AI; Taxonomies";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
62YLIVK7;journalArticle;2021;"Pozharliev, Rumen; De Angelis, Matteo; Rossi, Dario; Romani, Simona; Verbeke, Willem; Cherubino, Patrizia";Attachment styles moderate customer responses to frontline service robots: Evidence from affective, attitudinal, and behavioral measures;PSYCHOLOGY & MARKETING;NA;0742-6046;10.1002/mar.21475;NA;Despite the growing application of interactive technologies like service robots in customer service, there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees. Moreover, it is unclear whether all customers respond to the interaction with frontline service robots in the same way. Our research looks at how individual differences in social behaviors, specifically in customers' attachment styles, influence three types of customer responses: affective responses (experienced pleasantness), attitudinal responses (perceived empathy, satisfaction), and behavioral responses (word-of-mouth). Three experimental studies reveal that customers with low (vs. high) scores on anxious attachment style (AAS) measures respond more negatively to frontline service robot (compared to a frontline human agent). We investigate alternative explanations for these findings, such as robots' level of anthropomorphism and we show that human-likeness features such as voice type and level of human-like physical appearance, cannot explain our findings. Our results indicate that for low-AAS customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots, leading to possible implications on customer segmentation, targeting, and marketing communication.;2021-05;2021-05-19T13:29:53Z;2021-05-19T13:29:53Z;NA;881-895;15;5;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"empathy; service robots; anthropomorphism; attachment styles; social response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
NYC4J548;journalArticle;2021;"Riddoch, Katie A.; Cross, Emily S.";“Hit the Robot on the Head With This Mallet” - Making a Case for Including More Open Questions in HRI Research;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2021.603510;NA;Researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents, as opposed to objects. One such approach involves asking participants to inflict `harm' on a robot. Researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying, and propose that relatively long periods of hesitation might reflect empathy for the robot, and perhaps even attribution of human-like qualities, such as agency and sentience. In a recent experiment, we adapted the so-called `hesitance to hit' paradigm, in which participants were instructed to hit a humanoid robot on the head with a mallet. After standing up to do so (signaling intent to hit the robot), participants were stopped, and then took part in a semi-structured interview to probe their thoughts and feelings during the period of hesitation. Thematic analysis of the responses indicate that hesitation not only reflects perceived socialness, but also other factors including (but not limited to) concerns about cost, mallet disbelief, processing of the task instruction, and the influence of authority. The open-ended, free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism, perceived power imbalances, and feelings of connection toward the robot. In addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots, we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics.;2021-02-25;2021-05-19T13:29:53Z;2021-05-19T13:29:53Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; social robotics; qualitative research; human- robot interaction; prosocial behaviour; social perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SCEACN3G;journalArticle;2021;"Babel, Franziska; Kraus, Johannes M.; Baumann, Martin";Development and Testing of Psychological Conflict Resolution Strategies for Assertive Robots to Resolve Human-Robot Goal Conflict;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.591448;NA;"As service robots become increasingly autonomous and follow their own task-related goals, human-robot conflicts seem inevitable, especially in shared spaces. Goal conflicts can arise from simple trajectory planning to complex task prioritization. For successful human-robot goal-conflict resolution, humans and robots need to negotiate their goals and priorities. For this, the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user. In this paper, conflict resolution strategies for service robots (public cleaning robot, home assistant robot) are developed by transferring psychological concepts (e.g., negotiation, cooperation) to HRI. Altogether, fifteen strategies were grouped by the expected affective outcome (positive, neutral, negative). In two online experiments, the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts (public: n(1) = 61; private: n(2) = 93). To obtain a comparative value, the strategies were also applied by a human. As additional outcomes trust, fear, arousal, and valence, as well as perceived politeness of the agent were assessed. The positive/neutral strategies were found to be more acceptable and effective than negative strategies. Some negative strategies (i.e., threat, command) even led to reactance and fear. Some strategies were only positively evaluated and effective for certain agents (human or robot) or only acceptable in one of the two application contexts (i.e., approach, empathy). Influences on strategy acceptance and compliance in the public context could be found: acceptance was predicted by politeness and trust. Compliance was predicted by interpersonal power. Taken together, psychological conflict resolution strategies can be applied in HRI to enhance robot task effectiveness. If applied robot-specifically and context-sensitively they are accepted by the user. The contribution of this paper is twofold: conflict resolution strategies based on Human Factors and Social Psychology are introduced and empirically evaluated in two online studies for two application contexts. Influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed.";2021-01-26;2021-05-19T13:29:54Z;2021-05-19T13:29:54Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"trust; persuasive robots; acceptance; HRI strategies; robot assertiveness; user compliance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
XJNCCCZQ;journalArticle;2021;"Chang, Wenwen; Wang, Hong; Yan, Guanghui; Lu, Zhiguo; Liu, Chong; Hua, Chengcheng";EEG based functional connectivity analysis of human pain empathy towards humans and robots;NEUROPSYCHOLOGIA;NA;0028-3932;10.1016/j.neuropsychologia.2020.107695;NA;Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots.;2021-01-22;2021-05-19T13:29:54Z;2021-05-19T13:29:54Z;NA;NA;NA;NA;151;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"EEG; Functional connectivity; Empathy; Human-robot interaction; Empathy index; Mutual information";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
9SWDV3ZD;journalArticle;NA;"Ho, Jeffrey C. F.; Ng, Ryan";Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion;BEHAVIOUR & INFORMATION TECHNOLOGY;NA;0144-929X;10.1080/0144929X.2020.1864018;NA;This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters - NPCs in a prosocial VR game - influences players' in-game empathy towards NPCs and game immersion. Participants first experienced either a robot's perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants' game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players' weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed.;NA;2021-05-19T13:29:56Z;2021-05-19T13:29:56Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article; Early Access";NA;NA;NA;NA;"empathy; virtual reality; digital games; Perspective taking; prosocial games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LDQ5LCHS;journalArticle;2020;"Ionta, Silvio; Costantini, Marcello; Ferretti, Antonio; Galati, Gaspare; Romani, Gian Luca; Aglioti, Salvatore M.";Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain;CORTEX;NA;0010-9452;10.1016/j.cortex.2020.09.028;NA;Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by lowand high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively. (C) 2020 The Author(s). Published by Elsevier Ltd.;2020-12;2021-05-19T13:29:56Z;2021-05-19T13:29:56Z;NA;295-308;14;NA;133;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE Publisher: ELSEVIER MASSON, CORP OFF Type: Article;NA;NA;NA;NA;"fMRI; Empathy; Pain; Affective; Sensorimotor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
URG73Y5L;journalArticle;2020;"Konijn, Elly A.; Hoorn, Johan F.";Differential Facial Articulacy in Robots and Humans Elicit Different Levels of Responsiveness, Empathy, and Projected Feelings;ROBOTICS;NA;NA;10.3390/robotics9040092;NA;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot's face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot's face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) x 2 (treatment: affectionate vs. maltreated). Participants (N = 265; M-age = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of `because I feel, I believe it's real,' despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of `it is just a robot' fades into the background and appears not relevant anymore.";2020-12;2021-05-19T13:29:57Z;2021-05-19T13:29:57Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; social robots; facial expression; experiment; human-robot communication; user response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VM3URQDR;journalArticle;2020;"Bagheri, Elahe; Esteban, Pablo G.; Cao, Hoang-Long; De Beir, Albert; Lefeber, Dirk; Vanderborght, Bram";An Autonomous Cognitive Empathy Model Responsive to Users' Facial Emotion Expressions;ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS;NA;2160-6455;10.1145/3341198;NA;Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.;2020-11;2021-05-19T13:29:58Z;2021-05-19T13:29:58Z;NA;NA;NA;3, SI;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"Empathy; social robots; human robot interaction; adaptive interaction; facial emotion detection; non-verbal behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
97Z9FJDE;journalArticle;2020;"Giannopulu, Irini; Etournaud, Aude; Terada, Kazunori; Velonaki, Mari; Watanabe, Tomio";Ordered interpersonal synchronisation in ASD children via robots;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-020-74438-6;NA;Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020-10-15;2021-05-19T13:29:59Z;2021-05-19T13:29:59Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY Publisher: NATURE RESEARCH Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
29DPG2CR;journalArticle;NA;"Bagheri, Elahe; Roesler, Oliver; Cao, Hoang-Long; Vanderborght, Bram";A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00683-4;NA;Robots that express human's social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better.;NA;2021-05-19T13:30:00Z;2021-05-19T13:30:00Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Personality; Reinforcement learning; Empathy; Human-robot interaction; Social robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
QMPZ8IGA;journalArticle;2021;"Kuester, Dennis; Swiderska, Aleksandra";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;INTERNATIONAL JOURNAL OF PSYCHOLOGY;NA;0020-7594;10.1002/ijop.12715;NA;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.;2021-06;2021-05-19T13:30:00Z;2021-05-19T13:30:00Z;NA;454-465;12;3;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND Publisher: JOHN WILEY & SONS LTD Type: Article;NA;NA;NA;NA;"Robots; Benevolent intentions; Dehumanisation; Mind perception; Moral typecasting theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
C4NJ4JAH;journalArticle;NA;"James, Jesin; Balamurali, B. T.; Watson, Catherine I.; MacDonald, Bruce";Empathetic Speech Synthesis and Testing for Healthcare Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00691-4;NA;One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot's voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people's acceptance of social robots.;NA;2021-05-19T13:30:01Z;2021-05-19T13:30:01Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Social robots; Artificial empathy; Emotional speech synthesis; Healthcare; Prosody modelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
KMDAUZEC;journalArticle;2020;"Casas-Bocanegra, Diego; Gomez-Vargas, Daniel; Pinto-Bernal, Maria J.; Maldonado, Juan; Munera, Marcela; Villa-Moreno, Adriana; Stoelen, Martin F.; Belpaeme, Tony; Cifuentes, Carlos A.";An Open-Source Social Robot Based on Compliant Soft Robotics for Therapy with Children with ASD;ACTUATORS;NA;NA;10.3390/act9030091;NA;Therapy with robotic tools is a promising way to help improve verbal and nonverbal communication in children. The robotic tools are able to increase aspects such as eye contact and the ability to follow instructions and to empathize with others. This work presents the design methodology, development, and experimental validation of a novel social robot based on CompliAnt SofT Robotics called the CASTOR robot, which intends to be used as an open-source platform for the long-term therapy of children with autism spectrum disorder (CwASD). CASTOR integrates the concepts of soft actuators and compliant mechanisms to create a replicable robotic platform aimed at real therapy scenarios involving physical interaction between the children and the robot. The validation shows promising results in terms of robustness and the safety of the user and robot. Likewise, mechanical tests assess the robot's response to blocking conditions for two critical modules (i.e., neck and arm) in interaction scenarios. Future works should focus on the validation of the robot's effectiveness in the therapy of CwASD.;2020-09;2021-05-19T13:30:01Z;2021-05-19T13:30:01Z;NA;NA;NA;3;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"robot design; autism therapy; autism spectrum disorder; compliant mechanisms; physical interaction; series elastic actuators; social assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CDILTHJ9;journalArticle;2020;"Sumitani, Mizuho; Osumi, Michihiro; Abe, Hiroaki; Azuma, Kenji; Tsuchida, Rikuhei; Sumitani, Masahiko";A Robot Has a Mind of Its Own Because We Intuitively Share It;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app10186531;NA;People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we `share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent).;2020-09;2021-05-19T13:30:02Z;2021-05-19T13:30:02Z;NA;NA;NA;18;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"pain; empathy; affective mind; facial expression; robot (virtual agent)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
84YRC76D;journalArticle;2020;"Pepito, Joseph Andrew; Ito, Hirokazu; Betriana, Feni; Tanioka, Tetsuya; Locsin, Rozzano C.";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations;NURSING PHILOSOPHY;NA;1466-7681;10.1111/nup.12318;NA;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.";2020-10;2021-05-19T13:30:02Z;2021-05-19T13:30:02Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; affective developmental robotics; artificial empathy; humanoid nurse robots; intelligent humanoid robots; nursing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
US8G9LRZ;journalArticle;2020;"Stokes, Felicia; Palmer, Amitabha";Artificial Intelligence and Robotics in Nursing: Ethics of Caring as a Guide to Dividing Tasks Between AI and Humans;NURSING PHILOSOPHY;NA;1466-7681;10.1111/nup.12306;NA;Nurses have traditionally been regarded as clinicians that deliver compassionate, safe, and empathetic health care (Nurses again outpace other professions for honesty & ethics, 2018). Caring is a fundamental characteristic, expectation, and moral obligation of the nursing and caregiving professions (Nursing: Scope and standards of practice, American Nurses Association, Silver Spring, MD, 2015). Along with caring, nurses are expected to undertake ever-expanding duties and complex tasks. In part because of the growing physical, intellectual and emotional demandingness, of nursing as well as technological advances, artificial intelligence (AI) and AI care robots are rapidly changing the healthcare landscape. As technology becomes more advanced, efficient, and economical, opportunities and pressure to introduce AI into nursing care will only increase. In the first part of the article, we review recent and existing applications of AI in nursing and speculate on future use. Second, situate our project within the recent literature on the ethics of nursing and AI. Third, we explore three dominant theories of caring and the two paradigmatic expressions of caring (touch and presence) and conclude that AI-at least for the foreseeable future-is incapable of caring in the sense central to nursing and caregiving ethics. We conclude that for AI to be implemented ethically, it cannot transgress the core values of nursing, usurp aspects of caring that can only meaningfully be carried out by human beings, and it must support, open, or improve opportunities for nurses to provide the uniquely human aspects of care.;2020-10;2021-05-19T13:30:03Z;2021-05-19T13:30:03Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; ethics; nursing; robotics; ethics of caring";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZLLD8J62;journalArticle;2020;"Rossi, Silvia; Conti, Daniela; Garramone, Federica; Santangelo, Gabriella; Staffa, Mariacarla; Varrasi, Simone; Di Nuovo, Alessandro";The Role of Personality Factors and Empathy in the Acceptance and Performance of a Social Robot for Psychometric Evaluations;ROBOTICS;NA;NA;10.3390/robotics9020039;NA;Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the “openness to experience”, on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests.;2020-06;2021-05-19T13:30:04Z;2021-05-19T13:30:04Z;NA;NA;NA;2;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; human friendly cognitive robotics; personality factors; psychometric evaluation; social assistive robots; technology acceptance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
S99XEAV3;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots;TOURISM MANAGEMENT;NA;0261-5177;10.1016/j.tourman.2019.104042;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-05-19T13:30:04Z;2021-05-19T13:30:04Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CD4R6IUH;journalArticle;2020;"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung";The Design and Implementation of XiaoIce, an Empathetic Social Chatbot;COMPUTATIONAL LINGUISTICS;NA;0891-2017;10.1162/coli_a_00368;NA;This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human-machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.;2020-03;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;53-93;41;1;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA Publisher: MIT PRESS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZT2NC7TU;journalArticle;2020;McBride, Neil;Robot Enhanced Therapy for Autistic Children: An Ethical Analysis;IEEE TECHNOLOGY AND SOCIETY MAGAZINE;NA;0278-0097;10.1109/MTS.2020.2967493;NA;The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in IEEE Technology and Society Magazine, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions.;2020-03;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;51-60;10;1;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Medical treatment; Ethics; Robot sensing systems; Autism; Pediatrics; Social implications of technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
GWM22WQW;journalArticle;2020;"Bjorling, Elin A.; Thomas, Kyle; Rose, Emma J.; Cakmak, Maya";Exploring Teens as Robot Operators, Users and Witnesses in the Wild;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.00005;NA;As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.;2020-02-21;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; social robots; mental health; adolescence; human-centered design; participatory; Wizard of Oz";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LWWYWHSC;journalArticle;2020;"Anders, Silke; Beck, Christian; Domin, Martin; Lotze, Martin";Empathic responses to unknown others are modulated by shared behavioural traits;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-020-57711-6;NA;How empathically people respond to a stranger's pain or pleasure does not only depend on the situational context, individual traits and intentions, but also on interindividual factors. Here we ask whether empathic responses towards unknown others are modulated by behavioural similarity as a potential marker of genetic relatedness. Participants watched two supposed human players who were modelled as having a strong (player LP) or weak (player NLP) tendency to lead in social situations executing penalty shots in a virtual reality robot soccer game. As predicted, empathic response were modulated by shared behavioural traits: participants whose tendency to lead was more similar to player LP's tendency to lead experienced more reward, and showed stronger neural activity in reward-related brain regions, when they saw player LP score a goal, and participants whose tendency to lead was more similar to player NLP's tendency to lead showed stronger empathic responses when they saw player NLP score a goal. These findings highlight the potentially evolutionary grounded role of phenotypic similarity for neural processes underlying human social perception.;2020-02-06;2021-05-19T13:30:08Z;2021-05-19T13:30:08Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
DZAXM7UT;conferencePaper;2020;"Rossi, Silvia; Dell'Aquila, Elena; Russo, Davide; Maggi, Gianpaolo";Increasing Engagement with Chameleon Robots in Bartending Services;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;As the field of service robotics has been rapidly growing, it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way. This is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users' experience. In this paper, we address the question of whether a specific behavioral style of a barman-robot, acted through para-verbal and non-verbal behaviors, can affect users' engagement and the creation of positive emotions. To that end, we endowed a barman-robot taking drink orders from human customers, with an empathic behavioral style. This aims at triggering to alignment process by mimicking the conversation partner's behavior. This behavioral style is compared to an entertaining style, aiming at creating a positive relationship with the users, and a neutral style for control. Results suggest that when participants experienced more positive emotions, the robot was perceived as safer, so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement. Indeed, when the empathic robot modulates its behavior according to the user's one, this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in public-service contexts.;2020;2021-05-19T13:30:12Z;2021-05-19T13:30:12Z;NA;464-469;6;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
G8AYUJ4K;conferencePaper;2020;"Mitsuno, Seiya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.;2020;2021-05-19T13:30:12Z;2021-05-19T13:30:12Z;NA;653-658;6;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
JYDVDUAF;conferencePaper;2020;"Perusquia-Hernandez, Monica; Balda, Marisabel Cuberos; Jauregui, David Antonio Gomez; Paez-Granados, Diego; Dollack, Felix; Salazar, Jose Victorio";Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self-tracking results might cause the opposite effect. Subtle self-tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.;2020;2021-05-19T13:30:13Z;2021-05-19T13:30:13Z;NA;1328-1333;6;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;"embodiment; empathy and intersubjectivity; haptic feedback; human-machine interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
DGKJPQ4Z;conferencePaper;2020;"Garcia Corretjer, Marialejandra; Ros, Raquel; Martin, Fernando; Miralles, David";The Maze of Realizing Empathy with Social Robots;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.;2020;2021-05-19T13:30:14Z;2021-05-19T13:30:14Z;NA;1334-1339;6;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
BQF6P7UL;conferencePaper;2020;"Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vazquez, Marynel";Prompting Prosocial Human Interventions in Response to Robot Mistreatment;PROCEEDINGS OF THE 2020 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI `20);978-1-4503-6746-2;NA;10.1145/3319502.3374781;NA;Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.;2020;2021-05-19T13:30:15Z;2021-05-19T13:30:15Z;NA;211-220;10;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; SIGAI; IEEE Robot & Automat Soc; ACM Digital Lib; FN Robot; ARM; Cambridge Consultants; Furhat Robot; Halodi; Toyota Res Inst; Cambridge Univ Press; EXG Wear; Frontiers Robot & AI; Honda Res Inst; IDLab; MDPI Robot; MIT Press Europe; Promobot; Semio ISSN: 2167-2121 Type: Proceedings Paper";<p>ACM/IEEE International Conference on Human-Robot Interaction (HRI), Cambridge, ENGLAND, MAR 23-26, 2020</p>;NA;NA;NA;"Human-robot interaction; prosocial behavior; robot abuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
FYHNFM95;conferencePaper;2020;"Sani-Bozkurt, Sunagul; Bozkus-Genc, Gulden";NEW TREND ON ASD: CAN SOCIAL ROBOT BE A USEFUL TOOL IN JOINT ATTENTION FOR ASD?;14TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT CONFERENCE (INTED2020);978-84-09-17939-8;NA;NA;NA;Children with Autism Spectrum Disorder (ASD) suffer from a characteristic impairment in the ability to interpret social cues and often fail to use social gaze in empathetic and joint-attention tasks. The behavior of tracking an adult's eye movements, which appears in typically developing children in about 6th month, is considered as the beginning point of the ability to respond to joint attention. Studies show that children with ASD exhibit less joint attention skill and they fail in looking at the direction others are looking at and pointing at and in following the direction others are looking at, pointing at when they are compared to typically developing children and other children with developmental retardation. It is reported in some studies that the behaviors of responding to others' joint attention and initiation to joint attention are taught separately, and in other studies, both joint attention abilities are taught together. Nowadays, robot applications have appeared as a new approach in ASD implementations as a result of technological and scientific developments. Various social robots have been produced with an aim to increase the motivation of those with ASD by decreasing the stress level in complicated situations in the social setting and by enabling them to learn in simpler, predictable, and controlled settings. Besides, recently, social robots have increasingly been used in teaching joint attention abilities. In this study, it was aimed to give information about joint attention and types of robots, explain the characteristics of social robots, and put forward the current trends related to social robots by examining the studies conducted on the use of social robots for teaching joint attention abilities to children with ASD. Social robots could be a promising method for ASD treatment. There are remarkably different results regarding the robot applications in teaching the joint attention abilities to children with ASD. Therefore, it is not definitively known to which extent robot therapy contributes to the student's joint attention improvement. While efficiency research is frequently conducted in the studies in which robots have been used for teaching joint attention abilities to children with ASD, although rarely, comparative studies have also been conducted in recent years. Positive results are mentioned in this efficiency research, whereas there are also controversial results. In comparative studies, it is noteworthy that the human being and robot applications were compared in only one study. As a result, robots are thought to provide a significant support for the development of joint attention interactions such as attracting the attention of children, helping them participate in activities, building a bond for social interaction, motivating them, providing natural stimuli and bringing about different emotional expressions although there are different results about robot applications in the development of the joint attention abilities of children with ASD. In the related literature, it is also suggested to work with larger and different sample groups in order to generalize the existing study results since it is observed that the dimension of generalization is not addressed. Further studies in which robots play an active role compared to therapists can be carried out.;2020;2021-05-19T13:30:16Z;2021-05-19T13:30:16Z;NA;2090-2097;8;NA;NA;NA;NA;NA;INTED Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1079 Type: Proceedings Paper;<p>14th International Technology, Education and Development Conference (INTED), Valencia, SPAIN, MAR 02-04, 2020</p>;NA;NA;NA;"robots; social robot; joint attention; Autism spectrum disorder";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
2TZC78CD;journalArticle;2020;"Rafique, Memoona; Hassan, Muhammad Awais; Jaleel, Abdul; Khalid, Hina; Bano, Gulshan";A Computation Model for Learning Programming and Emotional Intelligence;IEEE ACCESS;NA;2169-3536;10.1109/ACCESS.2020.3015533;NA;Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.;2020;2021-05-19T13:30:16Z;2021-05-19T13:30:16Z;NA;149616-149629;14;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Computational modeling; Education; Robots; Emotional intelligence; basic programming; Programming profession; robots based learning; screen-free interface; Sequential analysis; Tools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
66CX8XIS;journalArticle;2019;"Carlson, Zachary; Lemmon, Louise; Higgins, MacCallister; Frank, David; Shahrezaie, Roya Salek; Feil-Seifer, David";Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-019-00599-8;NA;"Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable.";2019-12;2021-05-19T13:30:19Z;2021-05-19T13:30:19Z;NA;727-739;13;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Perception; Human-robot interaction; Human-robot cooperation; Mistreatment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
K9QCI43Y;journalArticle;2019;"Johanson, Deborah L.; Ahn, Ho Seok; MacDonald, Bruce A.; Ahn, Byeong Kyu; Lim, JongYoon; Hwang, Euijun; Sutherland, Craig J.; Broadbent, Elizabeth";The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction: Randomized Controlled Trial;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/13667;NA;Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings.;2019-10-04;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"engagement; social interaction; robotics; health care robotics; social intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
F74D6R55;journalArticle;2019;"Tatsukawa, Kyohei; Takahashi, Hideyuki; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Android Pretending to Have Similar Traits of Imagination as Humans Evokes Stronger Perceived Capacity to Feel;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2019.00088;NA;"The perception of robots as mindful enriches how humans relate to them. Given that congruence in perceived representations of the world enable humans to experience commonality in mental states (a shared reality), we propose that congruence between humans, and robots will encourage humans to attribute humanlike mental capacities to robots. To investigate this, we assessed the mental perceptions of a robot in a visual imagination task using Gray et al. mind perception scale, which evaluates experience (capacity to feel), and agency (capacity to plan and do). For each ambiguous picture in the designed task, humans, and a robot imagined an animal. The task was performed under six conditions (2 x 3: Lead/Follow for Low/Medium/High). In the Lead condition, the robot records its perceived animal first; in the Follow condition, the robot records after the human participant. The experiment had three different degrees of congruence: Low (0%), Medium (60%), and High (100%). The results showed that perceived experiences were higher in the Lead condition, suggesting that the robot is perceived to be empathetic. It is probable that the Follow condition was perceived as mimicry rather than shared reality. Therefore, the order of response may have played an important role in commonality in mental states. No differences were observed in the perceived agency across all conditions. These results suggest that the order of response affects how humans perceive the minds of robots. Additionally, we assessed a post-task questionnaire to evaluate the interpersonal closeness that the humans felt toward the android. The main effect was observed in the degrees of congruence. This result is in line with those of previous studies that report relationships across sharing of similarities and friendliness.";2019-09-18;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"mind perception; robot; interpersonal closeness; shared reality; visual imagination";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VU4ADQQD;journalArticle;2019;"Nishio, Toshiaki; Yoshikawa, Yuichiro; Ogawa, Kohei; Ishiguro, Hiroshi";Development of an Effective Information Media Using Two Android Robots;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app9173442;NA;Conversational robots have been used to convey information to people in the real world. Android robots, which have a human-like appearance, are expected to be able to convey not only objective information but also subjective information, such as a robot's feelings. Meanwhile, as an approach to realize attractive conversation, multi-party conversation by multiple robots was the focus of this study. By collaborating among several robots, the robots provide information while maintaining the naturalness of conversation. However, the effectiveness of interaction with people has not been surveyed using this method. In this paper, to develop more efficient media to convey information, we propose a scenario-based, semi-passive conversation system using two androids. To verify its effectiveness, we conducted a subjective experiment comparing it to a system that does not include any interaction with people, and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids. The experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids.;2019-09-01;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;17;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"human robot interaction; android robot; multiple conversation robots; passive social conversation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
4GFTW38Q;journalArticle;2019;"Tsiourti, Christiana; Weiss, Astrid; Wac, Katarzyna; Vincze, Markus";Multimodal Integration of Emotional Signals from Voice, Body, and Context: Effects of (In)Congruence on Emotion Recognition and Attitudes Towards Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-019-00524-z;NA;Humanoid social robots have an increasingly prominent place in today's world. Their acceptance in social and emotional human-robot interaction (HRI) scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users. In this article, we incorporate recent findings from psychology, neuroscience, human-computer interaction, and HRI, to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots, with a particular emphasis on the effects of incongruence. In a social HRI laboratory experiment, we investigated contextual incongruence (i.e., the conflict situation where a robot's reaction is incongrous with the socio-emotional context of the interaction) and cross-modal incongruence (i.e., the conflict situation where an observer receives incongruous emotional information across the auditory (vocal prosody) and visual (whole-body expressions) modalities). Results showed that both contextual incongruence and cross-modal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot. This, in turn, gives the impression that the robot is unintelligent or unable to express “empathic” behaviour and leads to profoundly harmful effects on likability and believability. Our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way. We offer recommendations regarding design choices and discuss future research areas in the direction of multimodal HRI.;2019-08;2021-05-19T13:30:21Z;2021-05-19T13:30:21Z;NA;555-573;19;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Robot emotions; Body language; Believability; Multi-modal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
HFHGYGD7;journalArticle;2019;"Gong, Chao; Lin, Fuhong; Zhou, Xianwei; Lu, Xing";Amygdala-Inspired Affective Computing: to Realize Personalized Intracranial Emotions with Accurately Observed External Emotions;CHINA COMMUNICATIONS;NA;1673-5447;NA;NA;Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected.;2019-08;2021-05-19T13:30:22Z;2021-05-19T13:30:22Z;NA;115-129;15;8;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article;NA;NA;NA;NA;"emotion recognition; affective computing; external emotions; intracranial emotions; personalized machines";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZKT6LFHT;journalArticle;2019;"Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farne, A.; Dominey, P. F.; Pavani, F.";Embodiment into a robot increases its acceptability;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-019-46528-7;NA;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects' head movements. As a result, participants saw themselves as a robot. When participant' and robot's head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots' humanoid's appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019-07-12;2021-05-19T13:30:22Z;2021-05-19T13:30:22Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
THM8SBPE;journalArticle;2019;"Pham, Hai Van; Asadi, Farzin; Abut, Nurettin; Kandilli, Ismet";Hybrid Spiral STC-Hedge Algebras Model in Knowledge Reasonings for Robot Coverage Path Planning and Its Applications;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app9091909;NA;Robotics is a highly developed field in industry, and there is a large research effort in terms of humanoid robotics, including the development of multi-functional empathetic robots as human companions. An important function of a robot is to find an optimal coverage path planning, with obstacle avoidance in dynamic environments for cleaning and monitoring robotics. This paper proposes a novel approach to enable robotic path planning. The proposed approach combines robot reasoning with knowledge reasoning techniques, hedge algebra, and the Spiral Spanning Tree Coverage (STC) algorithm, for a cleaning and monitoring robot with optimal decisions. This approach is used to apply knowledge inference and hedge algebra with the Spiral STC algorithm to enable autonomous robot control in the optimal coverage path planning, with minimum obstacle avoidance. The results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot. Experimental results are compared with current methods under the same conditions. The proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates. Experiments are done with real robots for cleaning in dynamic environments.;2019-05-01;2021-05-19T13:30:25Z;2021-05-19T13:30:25Z;NA;NA;NA;9;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"hedge algebra; robot coverage path planning; robot knowledge reasonings; simulation of a robot; spiral spanning tree coverage";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
MNSWJU25;journalArticle;2019;"Cross, Emily S.; Riddoch, Katie A.; Pratts, Jaydan; Titone, Simon; Chaudhury, Bishakha; Hortensius, Ruud";A neurocognitive investigation of the impact of socializing with a robot on empathy for pain;PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES;NA;0962-8436;10.1098/rstb.2018.0034;NA;To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue `From social brains to social robots: applying neurocognitive insights to human-robot interaction'.;2019-04-29;2021-05-19T13:30:25Z;2021-05-19T13:30:25Z;NA;NA;NA;1771;374;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND Publisher: ROYAL SOC Type: Article;NA;NA;NA;NA;"fMRI; social cognition; empathy; human-robot interaction; social robotics; experience-dependent plasticity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
FY7J55HR;journalArticle;2019;"Haynes, Alice; Simons, Melanie F.; Helps, Tim; Nakamura, Yuichi; Rossiter, Jonathan";A Wearable Skin-Stretching Tactile Interface for Human-Robot and Human-Human Communication;IEEE ROBOTICS AND AUTOMATION LETTERS;NA;2377-3766;10.1109/LRA.2019.2896933;NA;Currently, the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user. While this can be very effective, vibration as a physical stimulation is limited in modality and is uncommon in the natural world. In many cases, for human-robot and human-human interaction, a more natural, affective tactile interaction is needed to provide comfortable and varied stimuli. In this letter, we present the super-cutaneous wearable electrical empathic stimulator (SCWEES), a tactile device that gently stretches and squeezes the surface of the skin. Our hypothesis is that this device can create a pleasant, unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts. We describe the design of the SCWEES, a lightweight 3D-printed semi-flexible structure that attaches to the skin at two points and actuates via two shape-memory alloy coil actuators. We evaluate the SCWEES through a range of human interaction experiments: stimulation strength and pleasantness, contraction and extension, and the conveyance of non-disruptive notifications. Quantitative and qualitative results show that the SCWEES generates a pleasant sensation, can convey useful information in human-machine interactions, and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task.;2019-04;2021-05-19T13:30:26Z;2021-05-19T13:30:26Z;NA;1641-1646;6;2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"affective tactile stimulation; haptics and haptic interfaces; social human-robot interaction; soft robot applications; Wearable robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Q9G6VRUI;journalArticle;2019;"Alves-Oliveira, Patricia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION;NA;NA;10.1145/3300188;NA;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03;2021-05-19T13:30:26Z;2021-05-19T13:30:26Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
NSEBSJ26;conferencePaper;2019;"Qureshi, Shahnawaz; Hagelback, Johan; Iqbal, Syed Muhammad Zeeshan; Javaid, Hamad; Lindley, Craig A.";Evaluation of Classifiers for Emotion Detection While Performing Physical and Visual Tasks: Tower of Hanoi and IAPS;IN℡LIGENT SYSTEMS AND APPLICATIONS, VOL 1;978-3-030-01054-6 978-3-030-01053-9;NA;10.1007/978-3-030-01054-6_25;NA;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT.;2019;2021-05-19T13:30:27Z;2021-05-19T13:30:27Z;NA;347-363;17;NA;868;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>Intelligent Systems Conference (IntelliSys), London, ENGLAND, SEP 06-07, 2018</p>;NA;NA;NA;"Electroencephalography (EEG); Artificial Neural Networks (ANN); Bayesian Network (BNT); Cognitive psychology; Human Computer Interaction (HCI); K-Nearest Neighbor (KNN); Regression Tree (RT); Support Vector Machine (SVM); Tower of Hanoi (ToH)";Arai, K and Kapoor, S and Bhatia, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5TFI9Z5Y;conferencePaper;2019;"Esfandbod, Alireza; Rokhi, Zeynab; Taheri, Alireza; Alemi, Minoo; Meghdari, Ali";Human-Robot Interaction based on Facial Expression Imitation;2019 7TH INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM 2019);978-1-72816-604-9;NA;NA;NA;Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database, which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants' viewpoints on the imitation capability of the robot of 4.1 out of 5.;2019;2021-05-19T13:30:27Z;2021-05-19T13:30:27Z;NA;69-73;5;NA;NA;NA;NA;NA;RSI International Conference on Robotics and Mechatronics ICRoM;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Iran ISSN: 2377-679X Type: Proceedings Paper";<p>7th International Conference on Robotics and Mechatronics (ICRoM), Sharif Univ Technol, Tehran, IRAN, NOV 20-21, 2019</p>;NA;NA;NA;"Human Robot Interaction; Social Robots; Facial Expression Recognition; Convolutional Neural Network; Imitation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
732L9J28;conferencePaper;2019;"Bechade, Lucile; Dubuisson-Duplessis, Guillaume; Pittaro, Gabrielle; Garcia, Melanie; Devillers, Laurence";Towards Metrics of Evaluation of Pepper Robot as a Social Companion for the Elderly;ADVANCED SOCIAL INTERACTION WITH AGENTS;978-3-319-92108-2 978-3-319-92107-5;NA;10.1007/978-3-319-92108-2_11;NA;For the design of socially acceptable robots, field studies in Human-Robot Interaction are necessary. Constructing dialogue benchmarks can have a meaning only if researchers take into account the evaluation of robot, human, and their interaction. This paper describes a study aiming at finding an objective evaluation procedure of the dialogue with a social robot. The goal is to build an empathic robot (JOKER project) and it focuses on elderly people, the end-users expected by ROMEO2 project. The authors carried out three experimental sessions. The first time, the robot was NAO, and it was with a Wizard of Oz (emotions were entered manually by experimenters as inputs to the program). The other times, the robot was Pepper, and it was totally autonomous (automatic detection of emotions and decision according to). Each interaction involved various scenarios dealing with emotion recognition, humor, negotiation and cultural quiz. The paper details the system functioning, the scenarios and the evaluation of the experiments.;2019;2021-05-19T13:30:29Z;2021-05-19T13:30:29Z;NA;89-101;13;NA;510;NA;NA;NA;Lecture Notes in Electrical Engineering;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1876-1100 Type: Proceedings Paper;<p>8th International Workshop on Spoken Dialogue Systems (IWSDS), Farmington, PA, JUN 06-09, 2017</p>;NA;NA;NA;"Human-Robot Interaction; Evaluation; Data collection; Metrics; Elderly end-users";Eskenazi, M and Devillers, L and Mariani, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
BIJL9QCM;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019);978-1-4503-6690-8;NA;10.1145/3311927.3326596;NA;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (Al), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic Al agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019;2021-05-19T13:30:29Z;2021-05-19T13:30:29Z;NA;755-760;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Boise State Univ; Stem Act Ctr; St Lukes; Osmo; Langan Barber Fdn; Discovery Ctr Idaho; StemFinity; NSF; Boise Type: Proceedings Paper";<p>18th Annual ACM Interaction Design and Children (IDC), Boise, ID, JUN 12-15, 2019</p>;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
KMGRY635;conferencePaper;2019;"Sripian, Peeraya; Kurono, Yuya; Yoshida, Reiji; Sugaya, Midori";Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals;2019 28TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72812-622-7;NA;NA;NA;Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.;2019;2021-05-19T13:30:31Z;2021-05-19T13:30:31Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 1944-9445 Type: Proceedings Paper;<p>28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), New Delhi, INDIA, OCT 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
R7BIDUWZ;conferencePaper;2019;"Barbieri, Francesco; Guizzo, Eric; Lucchesi, Federico; Maffei, Giovanni; del Prado Martin, Fermin Moscoso; Weyde, Tillman";Towards a Multimodal Time-Based Empathy Prediction System;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community(1);2019;2021-05-19T13:30:34Z;2021-05-19T13:30:34Z;NA;716-720;5;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YD94XTA9;conferencePaper;2019;"Mallol-Ragolta, Adria; Schmitt, Maximilian; Baird, Alice; Cummins, Nicholas; Schuller, Bjoern";Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual ( OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient ( CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.;2019;2021-05-19T13:30:35Z;2021-05-19T13:30:35Z;NA;721-725;5;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
WJKWQ3AA;conferencePaper;2019;"Peterson, Jordan; Cohen, Chase; Harrison, Paige; Novak, Jonathan; Tossell, Chad; Phillips, Elizabeth";Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming;2019 SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS);978-1-72810-998-5;NA;NA;NA;The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.;2019;2021-05-19T13:30:36Z;2021-05-19T13:30:36Z;NA;170-175;6;NA;NA;NA;NA;NA;IEEE Systems and Information Engineering Design Symposium;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2639-7439 Type: Proceedings Paper;<p>Systems and Information Engineering Design Symposium (SIEDS), Univ Virginia, Charlottesville, VA, APR 26, 2019</p>;NA;NA;NA;"Human-robot interaction; Human-machine teaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
G5KVAUD3;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019);978-1-4503-6287-0;NA;10.1145/3313991.3314018;NA;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-05-19T13:30:38Z;2021-05-19T13:30:38Z;NA;102-108;7;NA;NA;NA;NA;NA;International Conference on Computer and Automation Engineering;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2154-4352 Type: Proceedings Paper;<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
NXKR7845;journalArticle;2019;"Sejima, Yoshihiro; Egawa, Shoichi; Sato, Yoichiro; Watanabe, Tomio";A pupil response system using hemispherical displays for enhancing affective conveyance;JOURNAL OF ADVANCED MECHANICAL DESIGN SYSTEMS AND MANUFACTURING;NA;1881-3054;10.1299/jamdsm.2019jamdsm0032;NA;In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker's affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot's eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance.;2019;2021-05-19T13:30:40Z;2021-05-19T13:30:40Z;NA;NA;NA;2;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: SHINANOMACHI-RENGAKAN BLDG., SHINANOMACHI 35, SHINJUKU-KU, TOKYO, 160-0016, JAPAN Publisher: JAPAN SOC MECHANICAL ENGINEERS Type: Article;NA;NA;NA;NA;"Empathy; Human interface; Human-robot interaction design; Kansei and affective engineering; Media representation; Pupil response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
GI7VYRXG;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodriguez, Veronica";Good Robot Design or Machiavellian? An in-the-wild robot leveraging minimal knowledge of passersby's culture;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people ( changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019;2021-05-19T13:30:42Z;2021-05-19T13:30:42Z;NA;382-391;10;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5DZHGQ9C;conferencePaper;2019;"Jarvela, Simo; Salminen, Mikko; Ruonala, Antti; Timonen, Janne; Mannermaa, Kristiina; Ravaja, Niklas; Jacucci, Giulio";DYNECOM: Augmenting Empathy in VR with Dyadic Synchrony Neurofeedback;PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES;978-0-9981331-2-6;NA;NA;NA;In a novel experimental setting, we augmented a variation of traditional compassion meditation with our custom built VR environment for multiple concurrent users. The system incorporates respiration and brainwave based biofeedback that enables responsiveness to the shared physiological states of the users. The presence of another user's avatar in the shared virtual space supported low level social interactions and provided active targets for evoked compassion. We enhanced interoception and the deep empathetic processes involved in compassion meditation with real time visualizations of breathing rates and the level of approach motivation assessed from EEG frontal asymmetry, and the dyadic synchrony of those signals between the two users. We found how the different biofeedback types increased both the amount of physiological synchrony between the users and their self-reported empathy, illustrating how dyadic synchrony biofeedback can expand the possibilities of biofeedback in affective computing and VR solutions for health and wellness.;2019;2021-05-19T13:30:45Z;2021-05-19T13:30:45Z;NA;4212-4220;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;HICSS;Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>;NA;NA;NA;NA;Bui, TX;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Z7XQI2UC;conferencePaper;2019;"Homburg, Nadine; Merkle, Moritz";A Cross-Country Comparison of Attitudes toward Humanoid Robots in Germany, the US, and India;PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES;978-0-9981331-2-6;NA;NA;NA;So far, researchers know very little about what people actually expect from humanoid robots during a human-robot interaction. Therefore, this study surveyed 610 non-experts from Germany (133), the US (174), and India (303) and asked them to rate the following attributes regarding humanoid robots: empathy, expertise, reliability, and trust. This paper develops hypotheses, connecting robot attributes to the four cultural dimensions suggested by Hofstede individualism, masculinity versus femininity, power distance, and uncertainty avoidance. The results show, that India rates all the attributes the highest, and that Germany and the US rate all aspects rather similarly with the largest difference regarding reliability.;2019;2021-05-19T13:30:46Z;2021-05-19T13:30:46Z;NA;4773-4782;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;HICSS;Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>;NA;NA;NA;NA;Bui, TX;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SETK48M2;journalArticle;2018;"Swiderska, Aleksandra; Kuester, Dennis";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;PERCEPTION;NA;0301-0066;10.1177/0301006618809919;NA;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.;2018-12;2021-05-19T13:30:47Z;2021-05-19T13:30:47Z;NA;1139-1152;14;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"pain; robots; empathy; mind perception; anthropomorphism; harm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TYI7IRQG;journalArticle;2018;"Giannopulu, Irini; Terada, Kazunori; Watanabe, Tomio";Emotional Empathy as a Mechanism of Synchronisation in Child-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2018.01852;NA;Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation.;2018-10-16;2021-05-19T13:30:48Z;2021-05-19T13:30:48Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"child; emotional empathy; heart rate; interactor robot; synchronisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5KQ3DUK9;journalArticle;2018;"Yalcin, Ozge Nilay; DiPaola, Steve";A computational model of empathy for interactive agents;BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES;NA;2212-683X;10.1016/j.bica.2018.07.010;NA;Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018-10;2021-05-19T13:30:48Z;2021-05-19T13:30:48Z;NA;20-25;6;NA;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Conversational agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YAER6HZX;journalArticle;2018;"Ghosh, Dipanjan; Olewnik, Andrew; Lewis, Kemper";Application of autoencoders in cyber-empathic design;DESIGN SCIENCE;NA;2053-4701;10.1017/dsj.2018.11;NA;A critical task in product design is mapping information from the consumer space to the design space. This process is largely dependent on the designer to identify and relate psychological and consumer level factors to engineered product attributes. In this way, current methodologies lack provision to test a designer's cognitive reasoning and may introduce bias through the mapping process. Prior work on Cyber-Empathic Design (CED) supports this mapping by relating user-product interaction data from embedded sensors to psychological constructs. To understand consumer perceptions, a network of psychological constructs is developed using Structural Equation Modeling for parameter estimation and hypothesis testing, making the framework falsifiable in nature. The focus of this technical brief is toward automating CED through unsupervised deep learning to extract features from raw data. Additionally, Partial Least Square Structural Equation Modeling is used with extracted sensor features as inputs. To demonstrate the effectiveness of the approach a case study involving sensor-integrated shoes compares three models - a survey-only model (no sensor data), the existing CED approach with manually extracted sensor features, and the proposed deep learning based CED approach. The deep learning based approach results in improved model fit.;2018-07-30;2021-05-19T13:30:50Z;2021-05-19T13:30:50Z;NA;NA;NA;NA;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA Publisher: CAMBRIDGE UNIV PRESS Type: Article;NA;NA;NA;NA;"machine learning; sensors; empathic design; product design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TAQNSX56;journalArticle;2018;"Martens, Amanda L.; Grover, Cathy A.; Saucier, Donald A.; Morrison, Breanna A.";An examination of gender differences versus similarities in a virtual world;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2018.03.012;NA;"We derived competing hypotheses from the gender similarities perspective versus the gender differences perspective to examine participants' behavior in an online virtual world in which we manipulated participants' gender. To manipulate participants' gender in the virtual environment, we randomly assigned them to one of three avatars (female, male, or robot). Using a screen recording device, we measured the percentage of time participants spent interacting with empathizing (e.g., options for shopping, telephone) and systemizing (e.g., weapons, options for building) objects in a virtual reality house that we constructed to reflect evidence put forth by the differences perspective. Because we derived competing hypotheses we expected to find support for either the similarities perspective or the differences perspective; however, our results suggested support for both. Consistent with the differences perspective hypotheses, participants paid attention to objects in the environment that were consistent with the social representation of their own gender. However, our results were consistent with the similarities perspective hypotheses, such that the avatars' gender also played a role in the percentage of time participants spent interacting with empathizing and systemizing objects. Therefore, we conclude that observable differences between men and women are the consequence of both biological and social forces, and research should focus on the interaction between the two as etiologies and explanations for sex and gender differences and similarities. (C) 2018 Elsevier Ltd. All rights reserved.";2018-07;2021-05-19T13:30:51Z;2021-05-19T13:30:51Z;NA;404-409;6;NA;84;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Virtual reality; Gender differences; Gender similarities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LLJWU6DU;journalArticle;2018;"Costa, Sandra; Brunete, Alberto; Bae, Byung-Chull; Mavridis, Nikolaos";Emotional Storytelling Using Virtual and Robotic Agents;INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS;NA;0219-8436;10.1142/S0219843618500068;NA;In order to create effective storytelling agents three fundamental questions must be answered: first, is a physically embodied agent preferable to a virtual agent or a voice-only narration? Second, does a human voice have an advantage over a synthesised voice? Third, how should the emotional trajectory of the different characters in a story be related to a storyteller's facial expressions during storytelling time, and how does this correlate with the apparent emotions on the faces of the listeners? The results of two specially designed studies indicate that the physically embodied robot produces more attention to the listener as compared to a virtual embodiment, that a human voice is preferable over the current state of the art of text-to-speech, and that there is a complex yet interesting relation between the emotion lines of the story, the facial expressions of the narrating agent, and the emotions of the listener, and that the empathising of the listener is evident through its facial expressions. This work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximise their effectiveness.;2018-06;2021-05-19T13:30:52Z;2021-05-19T13:30:52Z;NA;NA;NA;3;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type: Article;NA;NA;NA;NA;"facial expression analysis; non-verbal communication; Storytelling; emotional affective response; eye blink analysis; posture analysis; robot and virtual agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
STDTV8ND;journalArticle;2018;"da Silva, Joana Galvao Gomes; Kavanagh, David J.; Belpaeme, Tony; Taylor, Lloyd; Beeson, Konna; Andrade, Jackie";Experiences of a Motivational Interview Delivered by a Robot: Qualitative Study;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/jmir.7737;NA;Background: Motivational interviewing is an effective intervention for supporting behavior change but traditionally depends on face-to-face dialogue with a human counselor. This study addressed a key challenge for the goal of developing social robotic motivational interviewers: creating an interview protocol, within the constraints of current artificial intelligence, which participants will find engaging and helpful. Objective: The aim of this study was to explore participants' qualitative experiences of a motivational interview delivered by a social robot, including their evaluation of usability of the robot during the interaction and its impact on their motivation. Methods: NAO robots are humanoid, child-sized social robots. We programmed a NAO robot with Choregraphe software to deliver a scripted motivational interview focused on increasing physical activity. The interview was designed to be comprehensible even without an empathetic response from the robot. Robot breathing and face-tracking functions were used to give an impression of attentiveness. A total of 20 participants took part in the robot-delivered motivational interview and evaluated it after 1 week by responding to a series of written open-ended questions. Each participant was left alone to speak aloud with the robot, advancing through a series of questions by tapping the robot's head sensor. Evaluations were content-analyzed utilizing Boyatzis' steps: (1) sampling and design, (2) developing themes and codes, and (3) validating and applying the codes. Results: Themes focused on interaction with the robot, motivation, change in physical activity, and overall evaluation of the intervention. Participants found the instructions clear and the navigation easy to use. Most enjoyed the interaction but also found it was restricted by the lack of individualized response from the robot. Many positively appraised the nonjudgmental aspect of the interview and how it gave space to articulate their motivation for change. Some participants felt that the intervention increased their physical activity levels. Conclusions: Social robots can achieve a fundamental objective of motivational interviewing, encouraging participants to articulate their goals and dilemmas aloud. Because they are perceived as nonjudgmental, robots may have advantages over more humanoid avatars for delivering virtual support for behavioral change.;2018-05;2021-05-19T13:30:53Z;2021-05-19T13:30:53Z;NA;NA;NA;5;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"qualitative research; robotics; motivational interviewing; motivation; counseling; computer-assisted therapy; exercise; person-centered therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6N6RRVGR;journalArticle;2018;"Lazzeri, Nicole; Mazzei, Daniele; Cominelli, Lorenzo; Cisternino, Antonio; De Rossi, Danilo Emilio";Designing the Mind of a Social Robot;APPLIED SCIENCES-BASEL;NA;2076-3417;10.3390/app8020302;NA;Humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with human-inspired capabilities and traits. In the last few decades, this has become a reality with enormous advances in hardware performance, computer graphics, robotics technology, and artificial intelligence. New interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social, empathetic and affective capabilities. This paper presents the design, implementation, and test of a human-inspired cognitive architecture for social robots. State-of-the-art design approaches and methods are thoroughly analyzed and discussed, cases where the developed system has been successfully used are reported. The tests demonstrated the system's ability to endow a social humanoid robot with human social behaviors and with in-silico robotic emotions.;2018-02;2021-05-19T13:30:55Z;2021-05-19T13:30:55Z;NA;NA;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"social cognition; social robot; cognitive architecture; humanoid; human-inspired robot; robot mind";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
XTBIYGDM;conferencePaper;2018;"Kuehnlenz, Barbara; Busse, Fabian; Foertsch, Pascal; Wolf, Maximilian; Kuehnlenz, Kolja";Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.;2018;2021-05-19T13:30:56Z;2021-05-19T13:30:56Z;NA;275-281;7;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
87NM3XKJ;conferencePaper;2018;"James, Jesin; Watson, Catherine Inez; MacDonald, Bruce";Artificial Empathy in Social Robots: An analysis of Emotions in Speech;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.;2018;2021-05-19T13:30:57Z;2021-05-19T13:30:57Z;NA;632-637;6;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
7AKIUZGJ;conferencePaper;2018;"Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H.";Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.;2018;2021-05-19T13:30:58Z;2021-05-19T13:30:58Z;NA;783-789;7;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
KLHQ5SFV;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor";He who hesitates is lost (...in thoughts over a robot);PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18);978-1-4503-5420-2;NA;10.1145/3183654.3183703;NA;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.;2018;2021-05-19T13:30:58Z;2021-05-19T13:30:58Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Amer Psychol Assoc Type: Proceedings Paper;<p>Technology, Mind, and Society Conference (TechMindSociety), Washington, DC, APR 05-07, 2018</p>;NA;NA;NA;"Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
XPTHFDNH;conferencePaper;2018;"Tan, Xiang Zhi; Vazquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron";Inducing Bystander Interventions During Robot Abuse with Social Mechanisms;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171247;NA;We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant's performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.;2018;2021-05-19T13:31:02Z;2021-05-19T13:31:02Z;NA;169-177;9;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"robots; empathy; Human-robot interaction; abuse; bullying; peer intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ITV5YQLP;conferencePaper;2018;"Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana";Group-based Emotions in Teams of Humans and Robots;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171252;NA;Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.;2018;2021-05-19T13:31:03Z;2021-05-19T13:31:03Z;NA;261-269;9;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"emotion; trust; group effects; Human-robot teamwork; identification; inter-group interactions; self-categorisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YRVIY56X;conferencePaper;2018;"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea";Counseling Robot Implementation and Evaluation;2018 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC);978-1-5386-6650-0;NA;10.1109/SMC.2018.00297;NA;A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called “unazuki” in Japanese, a kind of nodding to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared according several subjective feelings by the evaluation subjects.;2018;2021-05-19T13:31:04Z;2021-05-19T13:31:04Z;NA;1716-1722;7;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Sci Council Japan ISSN: 1062-922X Type: Proceedings Paper";"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE Syst Man &amp; Cybernet Soc, Miyazaki, JAPAN, OCT 07-10, 2018</p>";NA;NA;NA;"Robot; Counseling; Dialog Promotion; Nodding; unazuki";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5ETBULZB;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Tossell, Chad";Band of Brothers and Bolts: Caring About Your Robot Teammate;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.;2018;2021-05-19T13:31:05Z;2021-05-19T13:31:05Z;NA;1853-1858;6;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TBPV8EEU;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.;2018;2021-05-19T13:31:05Z;2021-05-19T13:31:05Z;NA;2008-2013;6;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
V8G24QHE;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression;2018 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS (UR);978-1-5386-6334-9;NA;NA;NA;Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.;2018;2021-05-19T13:31:13Z;2021-05-19T13:31:13Z;NA;377-382;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>15th International Conference on Ubiquitous Robots (UR), Honolulu, HI, JUN 26-30, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZJGUULA6;conferencePaper;2018;"Kohori, Tomoko; Hirayama, Shiho; Hara, Takenori; Muramatsu, Michiko; Naganuma, Hiroyuki; Yamano, Masayuki; Ichikawa, Kazuko; Matsumoto, Hiroko; Uchiyama, Hiroko";Development and Evaluation of an Interactive Therapy Robot;ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY, ACE 2017;978-3-319-76270-8 978-3-319-76269-2;NA;10.1007/978-3-319-76270-8_6;NA;Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes.;2018;2021-05-19T13:31:17Z;2021-05-19T13:31:17Z;NA;66-83;18;NA;10714;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Multimodal Technologies & Interact Journal ISSN: 0302-9743 Type: Proceedings Paper;<p>14th International Conference on Advances in Computer Entertainment Technology (ACE), London, ENGLAND, DEC 14-16, 2017</p>;NA;NA;NA;"Healing elements Therapeutic robots designed to communicate with humans; Therapeutic effect";Cheok, AD and Inami, M and Romao, T;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
JLWCRTQG;journalArticle;2018;"Barakova, E. I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.";Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot;CONNECTION SCIENCE;NA;0954-0091;10.1080/09540091.2017.1350938;NA;In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game - the game with the robot was seen as more challenging and the robot - as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world.;2018;2021-05-19T13:31:19Z;2021-05-19T13:31:19Z;NA;81-98;18;1, SI;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"combining social and game strategy; Economic game strategies for robots; engagement robot/computer; long-term relations with robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
52IU7ENA;conferencePaper;2018;"Churamani, Nikhil; Banos, Pablo; Strahl, Erik; Wermter, Stefan";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6014-6;NA;NA;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018;2021-05-19T13:31:20Z;2021-05-19T13:31:20Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2161-4393 Type: Proceedings Paper;<p>International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, BRAZIL, JUL 08-13, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
BXXQ2R7B;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-05-19T13:31:21Z;2021-05-19T13:31:21Z;NA;173-193;21;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LJFIZGR3;conferencePaper;2018;"Macianskiene, Nemira; Bijeikiene, Vilma";APPLICATION OF FORMATIVE ASSESSMENT FOR THE ENHANCED FOREIGN LANGUAGE LEARNING;EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-02709-5;NA;NA;NA;"Education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking, problem-solving, global empathy, tolerance, intercultural awareness as well as team-work and collaboration. Formative assessment (FA) has emerged to be one of the efficient tools in the development of the above-mentioned competences and thus a topical issue in today's education. A number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills, student responsibility, active self-regulated learning, viewing learning as a goal rather than an outcome (Anderson, M., 2016; Brookhart, 2009; Chappuis, J., 2016; Fisher & Frey, 2014; [13]). The present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education. It aims at investigating how the application of formative assessment assists in fostering deep learning, student-centered approach, collaborative and tension free environment, active learning in small groups, enhanced dynamic exchange of feedback between teachers and students as well as self-assessment and peer-assessment both in traditional classroom as well as in virtual learning environment. It also explores the impact of formative assessment upon student lifelong learning skill development. Methodologically, the study is based on an opinion survey, reflection and class observation performed with 181 university students and 21 language teachers. The study has revealed that formative assessment adds significant value to the learning and teaching of languages. It settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality, cooperative learning, connection-building among all members of the learning and teaching process including students and teachers. It has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further in-depth research.";2018;2021-05-19T13:31:22Z;2021-05-19T13:31:22Z;NA;10084-10091;8;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>;NA;NA;NA;"foreign language learning and teaching; Formative assessment; student-centered approach; tertiary education";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VFLS6D9H;conferencePaper;2018;"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama";Touch Your Heart: A Tone-aware Chatbot for Customer Care on Social Media;PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018);978-1-4503-5620-6;NA;10.1145/3173574.3173989;NA;Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone -aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.;2018;2021-05-19T13:31:23Z;2021-05-19T13:31:23Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>CHI Conference on Human Factors in Computing Systems (CHI), Montreal, CANADA, APR 21-26, 2018</p>;NA;NA;NA;"Chatbot; Deep Learning; Social Media; Customer Care";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
KYUUCPFM;journalArticle;2018;"Vallverdu, Jordi; Nishida, Toyoaki; Ohmoto, Yoshisama; Moran, Stuart; Lazare, Sarah";Fake Empathy and Human-Robot Interaction (HRI): A Preliminary Study;INTERNATIONAL JOURNAL OF TECHNOLOGY AND HUMAN INTERACTION;NA;1548-3908;10.4018/IJTHI.2018010103;NA;Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call `fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different `humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi-angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment.;2018-03;2021-05-19T13:31:23Z;2021-05-19T13:31:23Z;NA;44-59;16;1;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type: Article;NA;NA;NA;NA;"Emotions; Empathy; Robots; Human-Robot Interaction; Fake; HRI; WOZ";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LCQIVA68;journalArticle;2017;"Chikaraishi, Takenobu; Yoshikawa, Yuichiro; Ogawa, Kohei; Hirata, Oriza; Ishiguro, Hiroshi";Creation and Staging of Android Theatre “Sayonara” towards Developing Highly Human-Like Robots;FUTURE INTERNET;NA;1999-5903;10.3390/fi9040075;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017-12;2021-05-19T13:31:24Z;2021-05-19T13:31:24Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI AG Type: Article;NA;NA;NA;NA;"social robots; android theatre; contemporary colloquial theatre theory; robot theatre";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
MAM7KB5E;journalArticle;2017;"Borenstein, Jason; Arkin, Ronald C.";Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior;AI & SOCIETY;NA;0951-5666;10.1007/s00146-016-0684-1;NA;"An under-examined aspect of human-robot interaction that warrants further exploration is whether robots should be permitted to influence a user's behavior for that person's own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user's behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user's empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be.";2017-11;2021-05-19T13:31:24Z;2021-05-19T13:31:24Z;NA;499-507;9;4;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Charity; Companion robots; Design ethics; Nudges; Robot ethics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
X6ELKEYM;journalArticle;2017;"Wiese, Eva; Metta, Giorgio; Wykowska, Agnieszka";Robots As Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.01663;NA;Robots are increasingly envisaged as our future cohabitants. However, while considerable progress has been made in recent years in terms of their technological realization, the ability of robots to interact with humans in an intuitive and social way is still quite limited. An important challenge for social robotics is to determine how to design robots that can perceive the user's needs, feelings, and intentions, and adapt to users over a broad range of cognitive abilities. It is conceivable that if robots were able to adequately demonstrate these skills, humans would eventually accept them as social companions. We argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motion/eye-tracking, electroencephalography, or functional near-infrared spectroscopy embedded in interactive human-robot paradigms. This approach requires understanding how humans interact with each other, how they perform tasks together and how they develop feelings of social connection over time, and using these insights to formulate design principles that make social robots attuned to the workings of the human brain. In this review, we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in social-cognitive processing. We first review literature related to social-cognitive processes and mechanisms involved in human-human interactions, and highlight the importance of perceiving others as intentional agents to activate these social brain areas. We then discuss how attribution of intentionality can positively affect human-robot interaction by (a) fostering feelings of social connection, empathy and prosociality, and by (b) enhancing performance on joint human-robot tasks. Lastly, we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous, and discuss challenges associated with designing social robots that are inspired by neuroscientific principles.;2017-10-04;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Review;NA;NA;NA;NA;"social neuroscience; human-robot interaction; social robotics; mind perception; attribution of intentionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
E23N7EYG;journalArticle;2017;"Liu, Xin; Xie, Lun; Wang, Zhiliang";Empathizing with Emotional Robot Based on Cognition Reappraisal;CHINA COMMUNICATIONS;NA;1673-5447;NA;NA;This paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive person's expressions. It integrates a guiding cognitive reappraisal strategy into the HMM (Hidden Markov Model) emotional interactive model for empathizing between robot and person. The emotion is considered as a source in the 3D space (Arousal, Valence, and Stance). State transition and emotion intensity can be quantitatively analyzed in the continuous space. This cognition-emotion interactive model have been verified by the expression and behavior robot. Empathizing is the main distinguishing feature of our work, and it is realized by the emotional regulation which operated in a continuous 3D emotional space enabling a wide range of intermediate emotions. The experiment results provide evidence with acceptability, accuracy, richness, fluency, interestingness, friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the human-robot interaction (HRI).;2017-09;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;100-113;14;9;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article;NA;NA;NA;NA;"human-robot interaction; emotional robot; active field emotion space; emotional regulation; guiding cognitive reappraisal";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
WJWXG4MW;journalArticle;2017;"Abubshait, Abdulaziz; Wiese, Eva";You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.01393;NA;Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed.;2017-08-23;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"intentionality; social cognition; human-robot interaction; social robotics; mind perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
4ZEIILSG;journalArticle;2017;"Rouaix, Natacha; Retru-Chavastel, Laure; Rigaud, Anne-Sophie; Monnet, Clotilde; Lenoir, Hermine; Pino, Maribel";Affective and Engagement Issues in the Conception and Assessment of a Robot-Assisted Psychomotor Therapy for Persons with Dementia;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.00950;NA;"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a “control software” for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient-therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction.";2017-06-30;2021-05-19T13:31:26Z;2021-05-19T13:31:26Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"engagement; social robots; control software; dementia; geriatrics; psychomotor therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6R7K2F3R;journalArticle;2017;"Slomian, Justine; Emonts, Patrick; Vigneron, Lara; Acconcia, Alessandro; Reginster, Jean-Yves; Oumourgh, Mina; Bruyere, Olivier";Meeting the Needs of Mothers During the Postpartum Period: Using Co-Creation Workshops to Find Technological Solutions;JMIR RESEARCH PROTOCOLS;NA;1929-0748;10.2196/resprot.6831;NA;Background: The postnatal period is associated with many new needs for mothers. Objective: The aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth. Methods: Two co-creation workshops were undertaken with parents and professionals. The aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth. The aim of the second workshop was to create solutions in response to the criteria selected during the first workshop. Results: Parents and health professionals want solutions that include empathy (ie, to help fight against the feelings of abnormality and loneliness), that help mothers in daily life, that are personalized and adapted to different situations, that are educational, and that assures some continuity in their contact with health professionals. In practice, we found that parents and professionals think the solution should be accessible to everyone and available at all times. To address these criteria, technology experts proposed different solutions, such as a forum dedicated to the postpartum period that is supervised by professionals, a centralized website, a system of videoconferencing, an online exchange group, a “gift voucher” system, a virtual reality app, or a companion robot. Conclusions: The human component seems to be very important during the postnatal period. Nevertheless, technology could be a great ally in helping mothers during the postpartum period. Technology can help reliably inform parents and may also give them the right tools to find supportive people. However, these technologies should be tested in clinical trials.;2017-05;2021-05-19T13:31:26Z;2021-05-19T13:31:26Z;NA;NA;NA;5;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"co-creating workshop; co-creation; mothers' needs; postpartum needs; technological solutions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
JZ9LYPQR;journalArticle;2017;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe";Simulating empathic behavior in a social assistive robot;MULTIMEDIA TOOLS AND APPLICATIONS;NA;1380-7501;10.1007/s11042-016-3797-0;NA;When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user's affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot's affective state and, consequently, the most appropriate empathic behavior. The robot's empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.;2017-02;2021-05-19T13:31:27Z;2021-05-19T13:31:27Z;NA;5073-5094;22;4;76;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Social assistive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
8387VVLJ;conferencePaper;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17);978-1-4503-4655-9;NA;10.1145/3025453.3025496;NA;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-05-19T13:31:28Z;2021-05-19T13:31:28Z;NA;3506-3510;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>ACM SIGCHI Conference on Human Factors in Computing Systems (CHI), Denver, CO, MAY 06-11, 2017</p>;NA;NA;NA;"social media; deep learning; Chatbot; customer service";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZB69PL3Q;conferencePaper;2017;"Anshar, Muh; Williams, Mary-Anne";Evolving Artificial Pain from Fault Detection through Pattern Data Analysis;2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR);978-1-5386-2035-9;NA;NA;NA;Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.;2017;2021-05-19T13:31:30Z;2021-05-19T13:31:30Z;NA;694-699;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Inst Elect & Elect Engineers; Inst Elect & Elect Engineers Robot & Automat Soc; Harbin Inst Technol; Beijing Inst Technol; Univ Nevada; Univ Electro Commun Tokyo; Chinese Univ Hong Kong; Chinese Acad Sci Type: Proceedings Paper";<p>IEEE International Conference on Real-time Computing and Robotics (RCAR), Okinawa, JAPAN, JUL 14-18, 2017</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
NKSK8KC5;conferencePaper;2017;"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile";Stacked Deep Convolutional Auto-Encoders for Emotion Recognition from Facial Expressions;2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6182-2;NA;NA;NA;Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system.;2017;2021-05-19T13:31:32Z;2021-05-19T13:31:32Z;NA;1586-1593;8;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Neurol Network Soc; IEEE Computat Intelligence Soc; Intel; BMI; Budapest Semester Cognit Sci ISSN: 2161-4393 Type: Proceedings Paper";<p>International Joint Conference on Neural Networks (IJCNN), Anchorage, AK, MAY 14-19, 2017</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZX5F45B5;journalArticle;2017;"Woo, Jinseok; Botzheim, Janos; Kubota, Naoyuki";EMOTIONAL EMPATHY MODEL FOR ROBOT PARTNERS USING RECURRENT SPIKING NEURAL NETWORK MODEL WITH HEBBIAN-LMS LEARNING;MALAYSIAN JOURNAL OF COMPUTER SCIENCE;NA;0127-9084;NA;NA;This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply “Hebbian-LMS” learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner “iPhonoid-C”. Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.;2017;2021-05-19T13:31:32Z;2021-05-19T13:31:32Z;NA;258-285;28;4;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA Publisher: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH Type: Article;NA;NA;NA;NA;"Conversation System; Emotional Empathy Model; Hebbian-LMS Learning; Recurrent Spiking Neural Network; Robot Partner";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
8DFICJ9C;conferencePaper;2017;Pareto, Lena;Robot as Tutee;ROBOTICS IN EDUCATION: RESEARCH AND PRACTICES FOR ROBOTICS IN STEM EDUCATION;978-3-319-42975-5 978-3-319-42974-8;NA;10.1007/978-3-319-42975-5_24;NA;"This paper explores the possible advantages of substituting teachable agents in a learning environment, with a humanoid robot as the non-human tutee. Teachable agents are used as an extension to educational games in order to leverage engagement, reflection and learning. The learning environment is engaging and shown to be effective for learning and promote self-efficacy in experimental studies in authentic classroom settings. Features beneficial for learning which are further enhanced by a robot compared to an agent are identified. These include embodiment of the robot; a social, empathic behaviour, better conversational abilities which together provide a better role model of an ideal learner for the student to identify with.";2017;2021-05-19T13:31:34Z;2021-05-19T13:31:34Z;NA;271-277;7;NA;457;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>7th International Conference on Robotics in Education (RiE), Vienna, AUSTRIA, APR 14-15, 2016</p>;NA;NA;NA;"Robotics; Tutoring; Robot tutee; Role-model learner; Teachable agent";Merdan, M and Lepuschitz, W and Koppensteiner, G and Balogh, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
75L8CF64;conferencePaper;2017;"Fan, Lisa; Scheutz, Matthias; Lohani, Monika; Mccoy, Marissa; Stokes, Charlene";Do We Need Emotionally Intelligent Artificial Agents? First Results of Human Perceptions of Emotional Intelligence in Humans Compared to Robots;IN℡LIGENT VIRTUAL AGENTS, IVA 2017;978-3-319-67401-8 978-3-319-67400-1;NA;10.1007/978-3-319-67401-8_15;NA;Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent's emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them.;2017;2021-05-19T13:31:37Z;2021-05-19T13:31:37Z;NA;129-141;13;NA;10498;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: KTH Royal Inst Technol ISSN: 0302-9743 Type: Proceedings Paper;"<p>17th International Conference on Intelligent Virtual Agents (IVA), Swedish Natl Museum Sci &amp; Technol, Stockholm, SWEDEN, AUG 27-30, 2017</p>";NA;NA;NA;"emotional intelligence; Human-robot interaction; empathetic robot";Beskow, J and Peters, C and Castellano, G and OSullivan, C and Leite, I and Kopp, S;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
E9AA9F36;conferencePaper;2017;"Bin Siddique, Farhad; Kampman, Onno; Yang, Yang; Dey, Anik; Fung, Pascale";Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent;PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS;978-1-945626-71-5;NA;10.18653/v1/P17-4021;NA;Virtual agents need to adapt their personality to the user in order to become more empathetic. To this end, we developed Zara the Supergirl, an interactive empathetic agent, using a modular approach. In this paper, we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks. From raw audio, an average F-score of 69.6 was obtained from real-time personality assessment using a Convolutional Neural Network (CNN) model. From text, we improved personality recognition results with a CNN model on top of pre-trained word embeddings and obtained an average F-score of 71.0. Results from our Human-Agent Interaction study confirmed our assumption that people have different agent personality preferences. We use insights from this study to adapt our agent to user personality.;2017;2021-05-19T13:31:38Z;2021-05-19T13:31:38Z;NA;121-126;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTATIONAL LINGUISTICS-ACL;209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Alibaba Grp; Amazon; Apple; Baidu; Bloomberg; Facebook; Google; Samsung; Tencent; eBay; Elsevier; IBM Res; KPMG; Maluuba; Microsoft; Naver Line; NEC; Recruit Inst Technol; SAP; Adobe; Bosch; CVTE; Duolingo; Huawei; Nuance; Oracle; Sogou; Grammarly; Toutiao; Yandex Type: Proceedings Paper";<p>55th Annual Meeting of the Association-for-Computational-Linguistics (ACL), Vancouver, CANADA, JUL 30-AUG 04, 2017</p>;NA;NA;NA;NA;Bansal, M and Ji, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
PAFNX8SK;journalArticle;2016;"Mazzei, Daniele; De Maria, Carmelo; Vozzi, Giovanni";Touch sensor for social robots and interactive objects affective interaction;SENSORS AND ACTUATORS A-PHYSICAL;NA;0924-4247;10.1016/j.sna.2016.10.006;NA;The recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human robot affective interaction. Most of these sensors, implemented as matrix of pressure sensors, are rigid, cannot be fabricated in complex shapes, cannot be subjected to large deformations, and usually allow to capture only the contact event, without any information about the interaction context. This paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns. The sensor is made of alternate layers of sensitive and insulating silicone: the soft nature of the sensor makes it adaptable to complex and deformable bodies. The main features from electrical signals are extracted with the principal component analysis, and a self-organising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture. The results open to interesting applications, which span from toy manufacturing, to human-robot interaction, and even to sport and biomedical equipment and applications. (C) 2016 Elsevier B.V. All rights reserved.;2016-11-01;2021-05-19T13:31:40Z;2021-05-19T13:31:40Z;NA;92-99;8;NA;251;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 564, 1001 LAUSANNE, SWITZERLAND Publisher: ELSEVIER SCIENCE SA Type: Article;NA;NA;NA;NA;"Affective robotics; Flexible silicone sensor; Tactile interaction; Touch sensor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
G2CYVWUK;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Masato, Koike";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES;NA;2212-683X;10.1016/j.bica.2016.09.004;NA;"Companion or `pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like `emotion' and based on emotional intelligence (El) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. (C) 2016 Elsevier B.V. All rights reserved.";2016-10;2021-05-19T13:31:40Z;2021-05-19T13:31:40Z;NA;51-67;17;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Behavior; Human-robot interaction; Emotional intelligence; Companion robot; Consciousness based architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Y2K9XBWS;journalArticle;2016;"Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge";Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns;IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE IN℡LIGENCE;NA;0162-8828;10.1109/TPAMI.2015.2496209;NA;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading). The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.;2016-08;2021-05-19T13:31:42Z;2021-05-19T13:31:42Z;NA;1679-1691;13;8, SI;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA Publisher: IEEE COMPUTER SOC Type: Article;NA;NA;NA;NA;"Bayesian approach; frequency domain; human movement analysis; social role; Social signal processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UM9PVKJ8;conferencePaper;2016;"Gibson, James; Can, Dogan; Xiao, Bo; Imel, Zac E.; Atkins, David C.; Georgiou, Panayiotis; Narayanan, Shrikanth";A Deep Learning Approach to Modeling Empathy in Addiction Counseling;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;10.21437/Interspeech.2016-554;NA;Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics.;2016;2021-05-19T13:31:44Z;2021-05-19T13:31:44Z;NA;1447-1451;5;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"behavioral signal processing; motivational interviews; recurrent neural networks; word embedding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
R266D7YW;conferencePaper;2016;"Egawa, Shoichi; Sejima, Yoshihiro; Sato, Yoichiro; Watanabe, Tomio";A Laughing-driven Pupil Response System for Inducing Empathy;2016 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII);978-1-5090-3329-4;NA;NA;NA;Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.;2016;2021-05-19T13:31:45Z;2021-05-19T13:31:45Z;NA;520-525;6;NA;NA;NA;NA;NA;IEEE/SICE International Symposium on System Integration;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; SICE; SICE Syst Integrat Div; IEEE Robot & Automat Soc; IEEE ind Elect Soc; Hokkaido Univ, Grad Sch Informat Sci & Technol ISSN: 2474-2317 Type: Proceedings Paper";<p>IEEE/SICE International Symposium on System Integration (SII), Sapporo, JAPAN, DEC 13-15, 2016</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
EMJS4LPV;conferencePaper;2016;"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile";Emotion Recognition Using Facial Expression Images for a Robotic Companion;ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2016;978-3-319-44188-7 978-3-319-44187-0;NA;10.1007/978-3-319-44188-7_6;NA;Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5%. These experiments serve as benchmark for our current research project in the area of social robotics.;2016;2021-05-19T13:31:47Z;2021-05-19T13:31:47Z;NA;79-93;15;NA;629;NA;NA;NA;Communications in Computer and Information Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1865-0929 Type: Proceedings Paper;<p>17th International Conference on Engineering Applications of Neural Networks (EANN), Robert Gordon Univ, Aberdeen, SCOTLAND, SEP 02-05, 2016</p>;NA;NA;NA;"Neural networks; Social robots; Emotion recognition; Gabor filter; Image classification; Support Vector Machine";Jayne, C and Iliadis, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
AUDACTUN;conferencePaper;2016;"Johnson, Esperanza; Lopez de la Franca, Carlos Gutierrez; Hervas, Ramon; Mondejar, Tania; Bravo, Jose";Analyzing Human-Avatar Interaction with Neurotypical and not Neurotypical Users;UBIQUITOUS COMPUTING AND AMBIENT IN℡LIGENCE, UCAMI 2016, PT I;978-3-319-48746-5 978-3-319-48745-8;NA;10.1007/978-3-319-48746-5_54;NA;Assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues. In this case, we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of Social Communications Disorders (SCD). The designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions, with those emotions changing according to the interactions that the user chooses to perform on the avatar. We have used Blender for the design of the emotions, which are happiness, sadness, surprise, fear and anger, plus a neutral emotion, while Unity was used to dictate the behavior of the avatar when the interactions were performed, which could be positive (caress), negative (poke) or neutral (wait). The avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users, as well as the difference between neurotypical and non-neurotypical users in terms of emotion recognition and chosen interactions. A ground truth has been established in terms of prototypic empathic interactions by the users.;2016;2021-05-19T13:31:47Z;2021-05-19T13:31:47Z;NA;525-536;12;NA;10069;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Las Palmas Gran Canaria; MAmI Res Grp ISSN: 0302-9743 Type: Proceedings Paper";<p>10th International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI), San Bartolome de Tirajana, SPAIN, NOV 29-DEC 02, 2016</p>;NA;NA;NA;"Empathy; Affective computing; Affective avatar; Cognitive disabilities; Human-avatar interaction; Social communication disorder";Garcia, CR and CaballeroGil, P and Burmester, M and QuesadaArencibia, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
89993U4Z;conferencePaper;2016;"Sin, Yap Miao Robin; Liang, Qiao; Tani, Koyu; Ogawa, Ken-ichiro; Miyake, Yoshihiro";Evaluation of a Head Motion Synchronization System in the Communicative Process Between Human and Robot;2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE);978-4-907764-50-0;NA;NA;NA;An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.;2016;2021-05-19T13:31:48Z;2021-05-19T13:31:48Z;NA;1514-1519;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE), Tsukuba, JAPAN, SEP 20-23, 2016</p>;NA;NA;NA;"human-robot interaction; Head motion synchronization; mutual entrainment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CBRCN438;conferencePaper;2016;"Li, Chaochao; Jia, Qingxuan; Feng, Yongli";Human-Robot Interactoin Design for Robot-Assisted Intervention for Children with Autism Based on E-S Theory;2016 8TH INTERNATIONAL CONFERENCE ON IN℡LIGENT HUMAN-MACHINE SYSTEMS AND CYBERNETICS (IHMSC), VOL. 2;978-1-5090-0768-4;NA;10.1109/IHMSC.2016.103;NA;The paper presents a novel human-robot interaction (HRI) framework to assist intervention for children with autism, based on Empathizing-Systemizing (E-S) theory. E-S theory explains the social difficulties in autism as the result of deficits or delays in empathizing, while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing. In this paper, the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robot-assisted intervention, which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism. The design of HRI scenarios and tasks based on E-S theory makes the robot-assisted intervention more effective and efficient.;2016;2021-05-19T13:31:49Z;2021-05-19T13:31:49Z;NA;320-324;5;NA;NA;NA;NA;NA;International Conference on Intelligent Human-Machine Systems and Cybernetics;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; Univ Bristol; Japan Adv Inst Sci & Technol; Beihang Univ ISSN: 2157-8982 Type: Proceedings Paper";<p>8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), Zhejiang Univ, Hangzhou, PEOPLES R CHINA, SEP 11-12, 2016</p>;NA;NA;NA;"social robot; autism therapy; Human Robot Interaction (HRI); Empathizing-Systemizing (E-S) theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
BHM2MTQK;conferencePaper;2016;"Ranieri, Caetano M.; Romero, Roseli A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016;978-1-5090-3656-1;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016;2021-05-19T13:31:49Z;2021-05-19T13:31:49Z;NA;31-36;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Brazilian Comp Soc; Centro Estudos Sistemas Avancados Recife; Centro Informatica UFPE; ROBOLIURE; VIRTUS IMPAVIDA; Inst Inovacao; Robolivre; CAPES; Inst SENAI Inovacao; Conselho Nacl Desenvolvimento Cientifico Tecnologico; Fundacao Amparo Ciencia Tecnologia Estado Pernambuco; IEEE Robot & Automat Soc Chapter Brazil; IEEE Latin Amer Robot Council Type: Proceedings Paper";<p>13th Latin American Robotics Symposium / 4th Brazilian Robotics Symposium (LARS/SBR), Recife, BRAZIL, OCT 08-12, 2016</p>;NA;NA;NA;NA;Cavalcante, SV and Tonidandel, F;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
L5YPJQYX;conferencePaper;2016;"Fosch-Villaronga, Eduard; Barco, Alex; Ozcan, Beste; Shukla, Jainendra";An Interdisciplinary Approach to Improving Cognitive Human-Robot Interaction - A Novel Emotion-Based Model;WHAT SOCIAL ROBOTS CAN AND SHOULD DO;978-1-61499-708-5 978-1-61499-707-8;NA;10.3233/978-1-61499-708-5-195;NA;"Socially Assistive Robotics (SAR) aims to provide robot-assisted therapy, for physical as well as cognitive rehabilitation. The paper analyzes two distinct use cases of cognitive rehabilitation therapies, one among involving children with Traumatic Brain Injury (TBI); and another one; second among involving individuals with Intellectual Disability (ID), and raises concerns regarding emotional adaptation, personalization, design, and ELS issues of human-robot interaction in such cases. The paper's aim is to provide some guidance on how social robots should be designed in order to accommodate emotions in HRI as well as to respect the rights of the persons with disabilities. We argue that it is critically important to address the concerns highlighted in order to empower robots with empathetic behavior and to deliver effective cognitive rehabilitation therapies.";2016;2021-05-19T13:31:50Z;2021-05-19T13:31:50Z;NA;195-205;11;NA;290;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Aarhus Univ, Sch Culture & Soc, Res Unit Robophilosophy; Res Network Transdisciplinary Studies Social Robot; Danish Res Council Humanities ISSN: 0922-6389 Type: Proceedings Paper";<p>Conference on Robot Philosophy / TRANSOR Conference on What Social Robots Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016</p>;NA;NA;NA;"emotions; social robots; ELS aspects; human-robot interaction (HRI); social robot design";Seibt, J and Norskov, M and Andersen, SS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Q8HZ8X6P;conferencePaper;2016;"Bechade, Lucile; Duplessis, Guillaume Dubuisson; Devillers, Laurence";Empirical Study of Humor Support in Social Human-Robot Interaction;DISTRIBUTED, AMBIENT AND PERVASIVE INTERACTIONS, (DAPI 2016);978-3-319-39862-4 978-3-319-39861-7;NA;10.1007/978-3-319-39862-4_28;NA;As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event's context.;2016;2021-05-19T13:31:53Z;2021-05-19T13:31:53Z;NA;305-316;12;NA;9749;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>4th International Conference on Distributed, Ambient and Pervasive Interactions (DAPI) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;NA;Streitz, N and Markopoulos, P;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UII28LK6;conferencePaper;2016;"Biswas, Mriganka; Murray, John";The Effects of Cognitive Biases in Long-Term Human-Robot Interactions: Case Studies Using Three Cognitive Biases on MARC the Humanoid Robot;SOCIAL ROBOTICS, (ICSR 2016);978-3-319-47437-3 978-3-319-47436-6;NA;10.1007/978-3-319-47437-3_15;NA;The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant's names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours.;2016;2021-05-19T13:31:53Z;2021-05-19T13:31:53Z;NA;148-158;11;NA;9979;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper";<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>;NA;NA;NA;"Human-robot interaction; Cognitive bias in robot; Human-robot long-term interactions; Imperfect robot";Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
57ZQF6HC;conferencePaper;2016;"Ojha, Suman; Williams, Mary-Anne";Ethically-Guided Emotional Responses for Social Robots: Should I Be Angry?;SOCIAL ROBOTICS, (ICSR 2016);978-3-319-47437-3 978-3-319-47436-6;NA;10.1007/978-3-319-47437-3_23;NA;Emotions play a critical role in human-robot interaction. Human-robot interaction in social contexts will be more effective if robots can understand human emotions and express (display) emotions accordingly as a means to communicate their own internal state. In this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement. There have been recent advances in developing emotion for robots. However, despite the extensive research on robot emotion, it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation. A key question is - to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity? Realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people, we present a novel Ethical Emotion Generation System (EEGS) for the expression of the most acceptable emotions in social robots.;2016;2021-05-19T13:31:54Z;2021-05-19T13:31:54Z;NA;233-242;10;NA;9979;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper";<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>;NA;NA;NA;"Social robots; Appraisal theory; Ethical emotion; Appraisal compensation; EEGS";Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
XPC9DEAH;conferencePaper;2016;"Giambattista, Angela; Teixeira, Luis; Ayanoglu, Hande; Saraiva, Magda; Duarte, Emilia";Expression of Emotions by a Service Robot: A Pilot Study;DESIGN, USER EXPERIENCE, AND USABILITY: TECHNOLOGICAL CONTEXTS, PT III;978-3-319-40406-6 978-3-319-40405-9;NA;10.1007/978-3-319-40406-6_31;NA;A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot's facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children.;2016;2021-05-19T13:31:55Z;2021-05-19T13:31:55Z;NA;328-336;9;NA;9748;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>5th International Conference on Design, User Experience, and Usability (DUXU) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;"Service robot; Human robot interaction; Healthcare; Emotional design; User experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CB5P8G8Q;conferencePaper;2016;"Sorbello, Rosario; Chella, Antonio; Giardina, Marcello; Nishio, Shuichi; Ishiguro, Hiroshi";An Architecture for Telenoid Robot as Empathic Conversational Android Companion for Elderly People;IN℡LIGENT AUTONOMOUS SYSTEMS 13;978-3-319-08338-4 978-3-319-08337-7;NA;10.1007/978-3-319-08338-4_68;NA;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic human-android interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user.;2016;2021-05-19T13:31:56Z;2021-05-19T13:31:56Z;NA;939-953;15;NA;302;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Univ Padova ISSN: 2194-5357 Type: Proceedings Paper;<p>13th International Conference on Intelligent Autonomous Systems (IAS), Centro Congressi Padova, Padova, ITALY, JUL 15-18, 2014</p>;NA;NA;NA;"Humanoid robot; Humanoid robot interaction; Life support empathic robot; Telenoid";Menegatti, E and Michael, N and Berns, K and Yamaguchi, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
49YLLKTT;conferencePaper;2016;"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia";Affect-Aware Student Models for Robot Tutors;AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS;978-1-4503-4239-1;NA;NA;NA;Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.;2016;2021-05-19T13:32:01Z;2021-05-19T13:32:01Z;NA;864-872;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Fdn Autonomous Agents & Multiagent Syst; Natl Sci Fdn; Artificial Intelligence Journal; Springer; Unicen; Sumitomo Elect; Living Analyt Res Ctr; Panasonic R & D Ctr Singapore; Assoc Comp Machinery Special Interest Grp Artificial Intelligence; Assoc Comp Machinery Type: Proceedings Paper";<p>15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Singapore, SINGAPORE, MAY 09-10, 2016</p>;NA;NA;NA;"affective computing; child-robot interaction; socially assistive robots; educational robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YHZG6FR2;conferencePaper;2016;"Cominelli, Lorenzo; Mazzei, Daniele; Carbonaro, Nicola; Garofalo, Roberto; Zaraki, Abolfazl; Tognetti, Alessandro; De Rossi, Danilo";A Preliminary Framework for a Social Robot “Sixth Sense”;BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2016;978-3-319-42417-0 978-3-319-42416-3;NA;10.1007/978-3-319-42417-0_6;NA;Building a social robot that is able to interact naturally with people is a challenging task that becomes even more ambitious if the robots' interlocutors are children involved in crowded scenarios like a classroom or a museum. In such scenarios, the main concern is enabling the robot to track the subjects' social and affective state modulating its behaviour on the basis of the engagement and the emotional state of its interlocutors. To reach this goal, the robot needs to gather visual and auditory data, but also to acquire physiological signals, which are fundamental for understating the interlocutors' psycho-physiological state. Following this purpose, several Human-Robot Interaction (HRI) frameworks have been proposed in the last years, although most of them have been based on the use of wearable sensors. However, wearable equipments are not the best technology for acquisition in crowded multi-party environments for obvious reasons (e.g., all the subjects should be prepared before the experiment by wearing the acquisition devices). Furthermore, wearable sensors, also if designed to be minimally intrusive, add an extra factor to the HRI scenarios, introducing a bias in the measurements due to psychological stress. In order to overcome this limitations, in this work, we present an unobtrusive method to acquire both visual and physiological signals from multiple subjects involved in HRI. The system is able to integrate acquired data and associate them with unique subjects' IDs. The implemented system has been tested with the FACE humanoid in order to assess integrated devices and algorithms technical features. Preliminary tests demonstrated that the developed system can be used for extending the FACE perception capabilities giving it a sort of sixth sense that will improve the robot empathic and behavioural capabilities.;2016;2021-05-19T13:32:02Z;2021-05-19T13:32:02Z;NA;58-70;13;NA;9793;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Future Emerging Technologies, European Unions Framework 7 Program; Heriot Watt Univ ISSN: 0302-9743 Type: Proceedings Paper";<p>5th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Edinburgh, SCOTLAND, JUL 19-22, 2016</p>;NA;NA;NA;"Affective computing; Human-Robot Interaction; Social robotics; Behaviour monitoring; Synthetic tutor";Lepora, NF and Mura, A and Mangan, M and Verschure, PFMJ and Desmulliez, M and Prescott, TJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
T7WVJQZ3;journalArticle;2015;"Suzuki, Yutaka; Galli, Lisa; Ikeda, Ayaka; Itakura, Shoji; Kitazaki, Michiteru";Measuring empathy for human and robot hand pain using electroencephalography;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/srep15924;NA;This study provides the first physiological evidence of humans' ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.;2015-11-03;2021-05-19T13:32:04Z;2021-05-19T13:32:04Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SIIXSLNX;journalArticle;2015;"Han, Jeonghye; Jo, Miheon; Hyun, Eunja; So, Hyo-jeong";Examining young children's perception toward augmented reality-infused dramatic play;ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT;NA;1042-1629;10.1007/s11423-015-9374-9;NA;Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children's satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children's perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5-6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children's perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed.;2015-06;2021-05-19T13:32:05Z;2021-05-19T13:32:05Z;NA;455-474;20;3;63;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Augmented reality; Dramatic play; Educational robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
3A6EMT4M;journalArticle;2015;"de Borst, Aline W.; de Gelder, Beatrice";Is it the real deal? Perception of virtual characters versus humans: an affective cognitive neuroscience perspective;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2015.00576;NA;Recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film, avatars, or androids. These stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control. While avatars and androids are well suited to study human cognition, they should not be equated to human stimuli. For example, the uncanny valley hypothesis theorizes that artificial agents with high human-likeness may evoke feelings of eeriness in the human observer. Here we review if, when, and how the perception of human-like avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies. First, we discuss how the appearance of virtual characters affects perception. When stimuli are morphed across categories from non-human to human, the most ambiguous stimuli, rather than the most human-like stimuli, show prolonged classification times and increased eeriness. Human-like to human stimuli show a positive linear relationship with familiarity. Secondly, we show that expressions of emotions in human-like avatars can be perceived similarly to human emotions, with corresponding behavioral, physiological and neuronal activations, with exception of physical dissimilarities. Subsequently, we consider if and when one perceives differences in action representation by artificial agents versus humans. Motor resonance and predictive coding models may account for empirical findings, such as an interference effect on action for observed human-like, natural moving characters. However, the expansion of these models to explain more complex behavior, such as empathy, still needs to be investigated in more detail. Finally, we broaden our outlook to social interaction, where virtual reality stimuli can be utilized to imitate complex social situations.;2015-05-12;2021-05-19T13:32:06Z;2021-05-19T13:32:06Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Review;NA;NA;NA;NA;"fMRI; virtual reality; social interaction; uncanny valley; action perception; emotion perception; naturalistic stimuli; virtual characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SY9974KU;journalArticle;2015;"Mirnig, Nicole; Strasser, Ewald; Weiss, Astrid; Kuehnlenz, Barbara; Wollherr, Dirk; Tscheligi, Manfred";Can You Read My Face? A Methodological Variation for Assessing Facial Expressions of Robotic Heads;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0261-z;NA;Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants' dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach.;2015-02;2021-05-19T13:32:08Z;2021-05-19T13:32:08Z;NA;63-76;14;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Facial expressions; Robot emotions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VJYRYEWZ;journalArticle;2015;"Tisseron, Serge; Tordo, Frederic; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0268-5;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015-02;2021-05-19T13:32:09Z;2021-05-19T13:32:09Z;NA;97-102;6;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Psychology; Human-robot interaction; Auto-empathy; Direct empathy; Empathy with robots; Intersubjective empathy; Reciprocal empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UTAMVD4W;journalArticle;2015;"Lim, Angelica; Okuno, Hiroshi G.";A Recipe for Empathy Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0262-y;NA;Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (”flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence.;2015-02;2021-05-19T13:32:10Z;2021-05-19T13:32:10Z;NA;35-49;15;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Developmental robotics; Emotional contagion based on SIRE model; MEI robot; Robot empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6TR84DP7;conferencePaper;2015;"Chumkamon, Sakmongkon; Masato, Koike; Hayashi, Eiji";Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot;2015 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2015): BIG DATA ANALYTICS FOR HUMAN-CENTRIC SYSTEMS;978-1-4799-8696-5;NA;10.1109/SMC.2015.45;NA;This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).;2015;2021-05-19T13:32:12Z;2021-05-19T13:32:12Z;NA;185-190;6;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE COMPUTER SOC;10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; IEEE Syst Man & Cybernet Soc; Hong Kong Polytechn Univ; K C Wong Fdn ISSN: 1062-922X Type: Proceedings Paper";<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), City Univ Hong Kong, Hong Kong, PEOPLES R CHINA, OCT 09-12, 2015</p>;NA;NA;NA;"CBA; Facial Expression Recognition; Human-Robot Interactio; Social Robot; component";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
HFHU22DB;conferencePaper;2015;"Vircikova, Maria; Magyar, Gergely; Sincak, Peter";The Affective Loop: A Tool for Autonomous and Adaptive Emotional Human-Robot Interaction;ROBOT IN℡LIGENCE TECHNOLOGY ANDAPPLICATIONS 3;978-3-319-16841-8 978-3-319-16840-1;NA;10.1007/978-3-319-16841-8_23;NA;The paper presents an affective model for social robotics, where the robot is capable of behavior adaptation, in accordance with the needs and preferences of a particular user. The proposed approach differs from other studies in human-robot interaction as these usually have been using the `Wizard of Oz' technique, where a person remotely operates a robot. On the other side, simulated robots are not able of personalized behaviors and behave according to the preprogrammed set of rules. We provide a tool to personalize affective artificial behaviors in cooperative human-robot scenarios, where human emotion recognition, appropriate robotic behavior selection and expression of robotic emotions play a key role. The preliminary experiments show that the personalized affective robotic behavior can achieve better results in a scenario in which a robot motivates children in learning. We believe that human-robot interfaces which mimic how humans interact with one another in an empathic way could ultimately lead to robots being accepted in the wider domain.;2015;2021-05-19T13:32:12Z;2021-05-19T13:32:12Z;NA;247-254;8;NA;345;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>3rd International Conference on Robot Intelligence Technology and Applications, Beijing, PEOPLES R CHINA, NOV 06-08, 2014</p>;NA;NA;NA;"Social Robots; Affective Robotics; Personalization; Social Human-Robot Interaction; Subjective Computing";Kim, JH and Yang, W and Jo, J and Sincak, P and Myung, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SQY3D5XK;conferencePaper;2015;"Rasool, Zeeshan; Masuyama, Naoki; Islam, Md. Nazrul; Loo, Chu Kiong";Empathic Interaction using the Computational Emotion Model;2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL IN℡LIGENCE (IEEE SSCI);978-1-4799-7560-0;NA;10.1109/SSCI.2015.26;NA;"This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model; whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.";2015;2021-05-19T13:32:13Z;2021-05-19T13:32:13Z;NA;109-116;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computational Intelligence Soc; IEEE BigData Type: Proceedings Paper";<p>IEEE Symposium Series Computational Intelligence, Cape Town, SOUTH AFRICA, DEC 07-10, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CJ88GZ8Z;conferencePaper;2015;"Marti, Patrizia; Iacono, Iolanda";Social and empathic behaviours: novel interfaces and interaction modalities;2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-4673-6704-2;NA;NA;NA;This paper describes the results of a research conducted in the European project Accompany, whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home. The project developed a system consisting of a robotic companion, Care-O-bot, as part of a smart environment. An intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot. The paper is articulated in two parts. The first part illustrates the theory that inspired the development of a context-aware Graphical User Interface (GUI) used to interact with the robot. The GUI integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges. The second part focuses on the user evaluation, and reports the outcomes from three different tests. The results of the first two tests show a positive acceptance of the GUI by the older people. The final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot.;2015;2021-05-19T13:32:14Z;2021-05-19T13:32:14Z;NA;217-222;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper";<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Y86HVEAP;conferencePaper;2015;"Darling, Kate; Nandy, Palash; Breazeal, Cynthia";Empathic concern and the effect of stories in human-robot interaction;2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-4673-6704-2;NA;NA;NA;People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.;2015;2021-05-19T13:32:15Z;2021-05-19T13:32:15Z;NA;770-775;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper";<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
8KLULTCA;conferencePaper;2015;"Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani-Sherman, Tal";Design and Evaluation of a Peripheral Robotic Conversation Companion;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696495;NA;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.;2015;2021-05-19T13:32:18Z;2021-05-19T13:32:18Z;NA;3-10;8;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"Empathy; Human-robot interaction; Ambient kinetic tangibles; Behavior change; Design; Robotic companions; Smartphone robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6V2GZMJ6;conferencePaper;2015;"Hood, Deanna; Lemaignan, Severin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696479;NA;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced bene fits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015;2021-05-19T13:32:19Z;2021-05-19T13:32:19Z;NA;83-90;8;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
7MHVEEY2;conferencePaper;2015;"Alves-Oliveira, Patricia; Ribeiro, Tiago; Petisca, Sofia; di Tullio, Eugenio; Melo, Francisco S.; Paiva, Ana";An Empathic Robotic Tutor for School Classrooms: Considering Expectation and Satisfaction of Children as End-Users;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_3;NA;Before interacting with a futuristic technology such as a robot, there is a lot of space for the creation of a whole set of expectations towards that interaction. Once that interaction happens, users can be left with a hand full of satisfaction, dissatisfaction, or even a mix of both. To study the possible role of experience as a mediator between expectation and satisfaction, we developed a scale for HRI that measures expectations and satisfaction of the users. Afterwards, we conducted a study with end-users interacting with a social robot. The robot is being developed to be an empathic robotic tutor to be used in real schools, with input from primary end-users (children). Children's expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed. The results can be fed back to the system developers on how well it is being designed for such a target population, and what factors regarding their expectation and satisfaction have shifted after the experience of interaction. By delivering on the children's expectations, we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational environment.;2015;2021-05-19T13:32:20Z;2021-05-19T13:32:20Z;NA;21-30;10;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;"Human-Robot Interaction; Expectation; Satisfaction; Robotic tutor; User-centered design";Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CXHJV6YN;conferencePaper;2015;"Fuente, Luis A.; Ierardi, Hannah; Pilling, Michael; Crook, Nigel T.";Influence of Upper Body Pose Mirroring in Human-Robot Interaction;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_22;NA;This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people's perception of their conversation with it. A set of twelve questions about the participants' university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots.;2015;2021-05-19T13:32:21Z;2021-05-19T13:32:21Z;NA;214-223;10;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;"Empathy; Anthropomorphism; Body-pose mirroring; Rapport";Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YKFRAJ9A;conferencePaper;2015;"Pettinati, Michael J.; Arkin, Ronald C.";Towards a Robot Computational Model to Preserve Dignity in Stigmatizing Patient-Caregiver Relationships;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_53;NA;Parkinson's disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patient-caregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity.;2015;2021-05-19T13:32:24Z;2021-05-19T13:32:24Z;NA;532-542;11;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;NA;Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
2TMLMG5P;conferencePaper;2015;"Gil, Pablo; Rossi, Claudio; Coral, William";Biophilic Evolutionary Buildings that Restore the Experience of Animality in the City;BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2015;978-3-319-22979-9 978-3-319-22978-2;NA;10.1007/978-3-319-22979-9_47;NA;In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible - or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa, cade that learns optimal configurations according to the perception of aggressiveness and calmness.;2015;2021-05-19T13:32:25Z;2021-05-19T13:32:25Z;NA;465-472;8;NA;9222;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Univ Sheffield; Univ Pompeu Fabra Barcelona; Inst Catalana Recerca Estudis Avancats ISSN: 0302-9743 Type: Proceedings Paper";<p>4th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Barcelona, SPAIN, JUL 28-31, 2015</p>;NA;NA;NA;"Biomimicry; Biophilia; Evolutionary robotics; Intelligent buildings; Wellbeing; Embodied evolution";Wilson, SP and Verschure, PFMJ and Mura, A and Prescott, TJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
9BHCNVES;journalArticle;2015;"Lazzeri, Nicole; Mazzei, Daniele; Greco, Alberto; Rotesi, Annalisa; Lanata, Antonio; De Rossi, Danilo Emilio";Can a humanoid face be expressive? A psychophysiological investigation;FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY;NA;2296-4185;10.3389/fbioe.2015.00064;NA;Non-verbal signals expressed through body language play a crucial role in multi-modal human communication during social relations. Indeed, in all cultures, facial expressions are the most universal and direct signs to express innate emotional cues. A human face conveys important information in social interactions and helps us to better understand our social partners and establish empathic links. Latest researches show that humanoid and social robots are becoming increasingly similar to humans, both esthetically and expressively. However, their visual expressiveness is a crucial issue that must be improved to make these robots more realistic and intuitively perceivable by humans as not different from them. This study concerns the capability of a humanoid robot to exhibit emotions through facial expressions. More specifically, emotional signs performed by a humanoid robot have been compared with corresponding human facial expressions in terms of recognition rate and response time. The set of stimuli included standardized human expressions taken from an Ekman-based database and the same facial expressions performed by the robot. Furthermore, participants' psychophysiological responses have been explored to investigate whether there could be differences induced by interpreting robot or human emotional stimuli. Preliminary results show a trend to better recognize expressions performed by the robot than 2D photos or 3D models. Moreover, no significant differences in the subjects' psychophysiological state have been found during the discrimination of facial expressions performed by the robot in comparison with the same task performed with 2D photos and 3D models.;2015;2021-05-19T13:32:28Z;2021-05-19T13:32:28Z;NA;NA;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"affective computing; social robots; facial expressions; humanoid robot; emotion perception; expression recognition; psychophysiological signals";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
FVWMZN9I;conferencePaper;2015;"Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.";Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696471;NA;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.";2015;2021-05-19T13:32:28Z;2021-05-19T13:32:28Z;NA;125-132;8;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"empathy; Human-robot interaction; robot embodiment; simulated interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
366NWT4A;journalArticle;2018;Heyes, Cecilia;empathy is not in our genes;Neuroscience & Biobehavioral Reviews;NA;0149-7634;https://doi.org/10.1016/j.neubiorev.2018.11.001;https://www.sciencedirect.com/science/article/pii/S0149763418308194;in academic and public life empathy is seen as a fundamental force of morality – a psychological phenomenon, rooted in biology, with profound effects in law, policy, and international relations. but the roots of empathy are not as firm as we like to think. the matching mechanism that distinguishes empathy from compassion, envy, schadenfreude, and sadism is a product of learning. here i present a dual system model that distinguishes empathy1, an automatic process that catches the feelings of others, from empathy2, controlled processes that interpret those feelings. research with animals, infants, adults and robots suggests that the mechanism of empathy1, emotional contagion, is constructed in the course of development through social interaction. learned matching implies that empathy is both agile and fragile. it can be enhanced and redirected by novel experience, and broken by social change.;2018;2021-05-19T13:19:57Z;2021-05-19T13:19:57Z;NA;499-507;9;NA;95;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Affective empathy; Mirror neurons; Emotional contagion; Affect mirroring; Associative learning; Empathic understanding; Learned Matching; Self-stimulation; Synchronous emotion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ILKWRYCM;journalArticle;2015;"Balint, Tibor S.; Hall, Ashley";humanly space objects—perception and connection with the observer;Acta Astronautica;NA;0094-5765;https://doi.org/10.1016/j.actaastro.2015.01.010;https://www.sciencedirect.com/science/article/pii/S0094576515000144;expanding humanity into space is an inevitable step in our quest to explore our world. yet space exploration is costly, and the awaiting environment challenges us with extreme cold, heat, vacuum and radiation, unlike anything encountered on earth. thus, the few pioneers who experience it needed to be well protected throughout their spaceflight. the resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life. such connections may occur via sensory inputs, namely vision, touch, sound, smell, and taste. this then follows the process of sensing, interpreting, and recognizing familiar patterns, or learning from new experiences. the desire to connect could even transfer to observed objects, if their movements and characteristics trigger the appropriate desires from the observer. when ordered in a familiar way, for example visual stimuli from lights and movements of an object, it may create a perceived real bond with an observer, and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable. these behavior patterns can be designed into an object and performed autonomously in front of an observer, in our case an astronaut. the experience may introduce multiple responses, including communication, connection, empathy, order, and disorder. while emotions are clearly evoked in the observer and may seem one sided, in effect the object itself provides a decoupled bond, connectivity and communication between the observer and the artist-designer of the object. in this paper we will discuss examples from the field of arts and other domains, including robotics, where human perception through object interaction was explored, and investigate the starting point for new innovative design concepts and future prototype designs, that extend these experiences beyond the boundaries of earth, while taking advantage of remoteness and the zero gravity environment. through a form of emotional connection and design, these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a co-located observer in spaceflight. we conclude that beyond providing creative expressions for humanly contacts, these experiences may also provide further insights into human perception in spaceflight, and could be tested on the international space station, and serve as a stepping-stone towards use on long-duration spaceflight to mars.;2015;2021-05-19T13:19:58Z;2021-05-19T13:19:58Z;NA;129-144;16;NA;110;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Dynamics and Control of Space Systems</p>;NA;NA;"Perception; Cognition; Affordances; Design; Art; Cybernetics; Tacit-knowledge";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LGYTD4GC;conferencePaper;2020;"Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio";DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI;Proceedings of the International Conference on Advanced Visual Interfaces;978-1-4503-7535-1;NA;10.1145/3399715.3399820;https://doi.org/10.1145/3399715.3399820;Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.;2020;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;NA;NA;NA;NA;NA;NA;NA;AVI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salerno, Italy;NA;NA;NA;"Computer Vision; Deep Learning; User Emotions; User Experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
CNJGJPUS;conferencePaper;2019;"Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji";The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot;Proceedings of the 7th International Conference on Human-Agent Interaction;978-1-4503-6922-0;NA;10.1145/3349537.3351891;https://doi.org/10.1145/3349537.3351891;We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.;2019;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;51–58;8;NA;NA;NA;NA;NA;HAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Kyoto, Japan;NA;NA;NA;"empathy; human-robot interaction; animism; robots' perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6JC7UN9R;conferencePaper;2015;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe; Carofiglio, Valeria";Modeling and Simulating Empathic Behavior in Social Assistive Robots;Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter;978-1-4503-3684-0;NA;10.1145/2808435.2808445;https://doi.org/10.1145/2808435.2808445;Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living.;2015;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;110–117;8;NA;NA;NA;NA;NA;CHItaly 2015;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Rome, Italy;NA;NA;NA;"Affective Computing; Social Assistive Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TMB9JQ9T;conferencePaper;2020;"Patro, Jasabanta; Rathore, Pushpendra Singh";A Sociolinguistic Route to the Characterization and Detection of the Credibility of Events on Twitter;Proceedings of the 31st ACM Conference on Hypertext and Social Media;978-1-4503-7098-1;NA;10.1145/3372923.3404795;https://doi.org/10.1145/3372923.3404795;Although Twitter constitutes as one of the primary sources of real-time news with users acting as the sensors updating the content from all across the globe, yet the spread of rumours via Twitter is becoming an increasingly alarming issue and is known to have caused significant damage already. We propose a credibility analysis approach based on the linguistic structure of the tweets. We not only characterize the Twitter events but also predict their perceived credibility of them by a novel deep learning architecture. We use the huge CREDBANK data to conduct our experiments. Some of our exciting findings are that standard LIWC categories like 'negate', 'discrep', 'cogmech', 'swear' and the Empath categories like 'hate', 'poor', 'government', 'worship' and 'swearing-terms' correlate negatively with the credibility of events. While some of our results resonate with the earlier literature others represent novel insights of the fake and legitimate twitter events. Using the above observations and the current deep learning architecture we predict the credibility of an event (a four-class classification problem in our case) with an accuracy of 0.54 that improves the best-known state-of-the-art (current accuracy 0.43) by 26%. A fascinating observation is that even by looking at the first few tweets of an event, it is possible to make the prediction almost as accurate as in the case where the entire volume of tweets is observed.;2020;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;241–250;10;NA;NA;NA;NA;NA;HT '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, USA;NA;NA;NA;"credibility detection; event credibility; sociolinguistic approach";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
FVLZ42QE;journalArticle;2020;"McDonald, Nora; Pan, Shimei";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415218;https://doi.org/10.1145/3415218;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.;2020-10;2021-05-19T12:52:11Z;2021-05-19T12:52:11Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"artificial intelligence; ethics; algorithm bias; education; intersectionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
MQTYRXW6;conferencePaper;2015;Encinas, Enrique;Cyrafour: How Two Human Avatars Communicate With Each Other;Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-3146-3;NA;10.1145/2702613.2726962;https://doi.org/10.1145/2702613.2726962;Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.;2015;2021-05-19T12:52:11Z;2021-05-19T12:52:11Z;NA;109–114;6;NA;NA;NA;NA;NA;CHI EA '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, Republic of Korea;NA;NA;NA;"embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
AKSF7SZ8;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016;2021-05-19T12:52:55Z;2021-05-19T12:52:55Z;NA;931–939;9;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"empathy; human-agent interaction; human-robot interaction; memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
PQI958GE;conferencePaper;2016;"Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka";Sharing Emotion Described as Text on the Internet by Changing Self-Physiological Perception;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2974825;https://doi.org/10.1145/2974804.2974825;"Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.";2016;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;145–153;9;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Biopolis, Singapore;NA;NA;NA;"emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5MAHCZAT;conferencePaper;2021;"Urakami, Jacqueline; Sutthithatip, Sujitra";Building a Collaborative Relationship between Human and Robot through Verbal and Non-Verbal Interaction;Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-8290-8;NA;10.1145/3434074.3447171;https://doi.org/10.1145/3434074.3447171;Interpersonal communication and relationship building promote successful collaborations. This study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partner.Participants interacted with two robots that differed in their nonverbal and verbal expressiveness. The interactive robot actively engaged the participant in a conversation before, during and after a collaborative task whereas the non-interactive robot remained passive. The robots' nonverbal and verbal interactions increased participants' perception of the robot as a social actor and strengthened bonding and relationship building between human and robot. The results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact, the robot is attributed a certain personality, and the robot is perceived as being alive.Our study could not show that an interactive robot receives more help by the collaboration partner. Future research should investigate additional factors that facilitate helpful behavior among humans, such as similarity, attributional judgement and empathy.;2021;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;257–261;5;NA;NA;NA;NA;NA;HRI '21 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boulder, CO, USA;NA;NA;NA;"social presence; helping; human robot collaboration; relationship building";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UNJC4X4P;conferencePaper;2015;Franco, Gloria Adriana Mendoza;Evaluation of the Emotional Answer in HRI on a Game Situation;Proceedings of the Latin American Conference on Human Computer Interaction;978-1-4503-3960-5;NA;10.1145/2824893.2824897;https://doi.org/10.1145/2824893.2824897;This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.;2015;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;NA;NA;NA;NA;NA;NA;NA;CLIHC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Córdoba, Argentina;NA;NA;NA;"empathy; interaction design; HRI; Emocards; emotional evaluation; emotional reciprocity; lottery application";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UFDLZAS9;conferencePaper;2020;"Pollmann, Kathrin; Ziegler, Daniel";Personal Quizmaster: A Pattern Approach to Personalized Interaction Experiences with the MiRo Robot;Proceedings of the Conference on Mensch Und Computer;978-1-4503-7540-5;NA;10.1145/3404983.3410414;https://doi.org/10.1145/3404983.3410414;In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes.;2020;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;485–489;5;NA;NA;NA;NA;NA;MuC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Magdeburg, Germany;NA;NA;NA;"social robot; behavioral patterns; multimodal behavioral expressions; personalized human-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
JPKDHXJZ;conferencePaper;2021;"Chirapornchai, Chatchai; Bremner, Paul; Daly, Joseph E.";Helper's High with a Robot Pet;Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-8290-8;NA;10.1145/3434074.3447165;https://doi.org/10.1145/3434074.3447165;Helper's high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement. This study investigates if a robot pet can, like a real pet, induce helpers high in people interacting with it. A Vector robot was programmed to express the need for daily exercise and attention, and participants were instructed how to help the robot meet those needs. Our within subjects design had two conditions: with and without emotional behaviour modifiers to the robot's behaviour. Our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants, which would create a stronger helper's high effect than purely functional need expression behaviours. We present a long-term (4 day) remote study design that not only facilitates the kind of interactions needed for helper's high, but abides by government guidelines on Covid-19 safety (under which a laboratory study is not possible). Preliminary results suggest that Vector was able to improve the mood of some participants, and mood changes tend to be greater when Vector expressed behaviours with emotional components. Our post-study interview data suggests that individual differences in living environment and mood impacting external factors, affected Vector's efficacy in mood influencing.;2021;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;229–233;5;NA;NA;NA;NA;NA;HRI '21 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boulder, CO, USA;NA;NA;NA;"empathy; helper's high; mood improvement; robot pet; vector";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
BFCKYF8N;conferencePaper;2018;"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia";A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.;2018;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;1658–1666;9;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
C5Y6JTSN;conferencePaper;2021;"Herdel, Viviane; Kuzminykh, Anastasia; Hildebrandt, Andrea; Cauchard, Jessica R.";Drone in Love: Emotional Perception of Facial Expressions on Flying Robots;Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;978-1-4503-8096-6;NA;10.1145/3411764.3445495;https://doi.org/10.1145/3411764.3445495;Drones are rapidly populating human spaces, yet little is known about how these flying robots are perceived and understood by humans. Recent works suggested that their acceptance is predicated upon their sociability. This paper explores the use of facial expressions to represent emotions on social drones. We leveraged design practices from ground robotics and created a set of rendered robotic faces that convey basic emotions. We evaluated individuals’ response to these emotional facial expressions on drones in two empirical studies (N = 98, N = 98). Our results demonstrate that individuals accurately recognize five drone emotional expressions, as well as make sense of intensities within emotion categories. We describe how participants were emotionally affected by the drone, showed empathy towards it, and created narratives to interpret its emotions. As a consequence, we formulate design recommendations for social drones and discuss methodological insights on the use of static versus dynamic stimuli in affective robotics studies.;2021;2021-05-19T12:53:15Z;2021-05-19T12:53:15Z;NA;NA;NA;NA;NA;NA;NA;NA;CHI '21;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Yokohama, Japan;NA;NA;NA;"Affective Computing; Emotion Recognition; Anthropomorphism; Robot; Facial Expressions; Human-Drone Interaction; UAV.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
YIIBZ78F;conferencePaper;2019;"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania";Ballbit Adventure: A Physical Game for a Collaborative Racing;Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-6871-1;NA;10.1145/3341215.3356982;https://doi.org/10.1145/3341215.3356982;Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.;2019;2021-05-19T12:53:16Z;2021-05-19T12:53:16Z;NA;97–103;7;NA;NA;NA;NA;NA;CHI PLAY '19 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UBPMUAWD;conferencePaper;2018;"Febtriko, Anip; Rahayuningsih, Tri; Septiani, Dinda; Trisnawati, Liza; Arisandi, Diki; Sukri";Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;10.1109/ICAITI.2018.8686759;NA;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.;2018-09;2021-05-19T12:41:47Z;2021-05-19T12:41:47Z;NA;208-212;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Mobile Robot; Android; Asperger syndrome; Rank Wilcoxon";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6WZJZHQM;conferencePaper;2019;"Chai, Yibo; Wu, Fengyang; Sun, Rui; Zhang, Zhongliang; Bao, Jie; Ma, Runxin; Peng, Qizhou; Wu, Danqin; Wan, Yexing; Li, Keyu";Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;NA;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.;2019-12;2021-05-19T12:41:48Z;2021-05-19T12:41:48Z;NA;1564-1571;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Big Data; social media; deep learning; Cloud computing; Distributed processing; Electromagnetic interference; Erbium; mental illness; Social computing; online empathy.; social network";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
4D8L7N55;conferencePaper;2019;"Lopez-Martinez, Daniel; El-Haouij, Neska; Picard, Rosalind";Detection of Real-World Driving-Induced Affective State Using Physiological Signals and Multi-View Multi-Task Machine Learning;2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW);NA;NA;10.1109/ACIIW.2019.8925190;NA;Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance.;2019-09;2021-05-19T12:41:49Z;2021-05-19T12:41:49Z;NA;356-361;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Stress; Machine learning; Feature extraction; Heart rate; Physiology; Affective State; Databases; Multi-task Multi-view Machine Learning; Physiological data; Real-world driving; Vehicles";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
3G25GYJA;journalArticle;2021;"Cominelli L; Feri F; Garofalo R; Giannetti C; Meléndez-Jiménez MA; Greco A; Nardelli M; Scilingo EP; Kirchkamp O";Promises and trust in human-robot interaction.;Scientific reports;NA;NA;NA;NA;Understanding human trust in machine partners has become imperative due to the widespread use of intelligent machines in a variety of applications and contexts. The aim of this paper is to investigate whether human-beings trust a social robot-i.e. a human-like robot that embodies emotional states, empathy, and non-verbal communication-differently than other types of agents. To do so, we adapt the well-known economic trust-game proposed by Charness and Dufwenberg (2006) to assess whether receiving a promise from a robot increases human-trust in it. We find that receiving a promise from the robot increases the trust of the human in it, but only for individuals who perceive the robot very similar to a human-being. Importantly, we observe a similar pattern in choices when we replace the humanoid counterpart with a real human but not when it is replaced by a computer-box. Additionally, we investigate participants' psychophysiological reaction in terms of cardiovascular and electrodermal activity. Our results highlight an increased psychophysiological arousal when the game is played with the social robot compared to the computer-box. Taken all together, these results strongly support the development of technologies enhancing the humanity of robots.;2021;2021-06-05T11:16:49Z;2021-06-05T11:16:49Z;NA;NA;NA;1;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 9025257044;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VG6JXBH7;journalArticle;2020;"Sakurai, Eriko; Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea; Frati, Fulvio";Embodiment matters: toward culture-specific robotized counselling;J Reliable Intell Environ Journal of Reliable Intelligent Environments;NA;2199-4668;NA;NA;Abstract: In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures.;2020;2021-06-05T11:21:26Z;2021-06-05T11:21:26Z;NA;129-139;11;3;6;NA;NA;Embodiment matters;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8644462671;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
ZYFH2W49;journalArticle;2015;NA;Towards the synthetic self: making othersperceive me as an other;Paladyn: Journal of Behavioral Robotics;NA;2081-4836;NA;NA;Future applications of robotic technologies willinvolve interactions with non-expert humans as machineswill assume the role of companions, teachers or healthcareassistants. In all those tasks social behavior is a key abilitythat needs to be systematically investigated and modelledat the lowest level, as even a minor inconsistency of therobot’s behavior can greatly affect the way humans willperceive it and react to it. Here we propose an integratedarchitecture for generating a socially competent robot.Wevalidate our architecture using a humanoid robot, demonstratingthat gaze, eye contact and utilitarian emotionsplay an essential role in the psychological validity or socialsalience of Human-Robot Interaction (HRI). We showthat this social salience affects both the empathic bondingbetween the human and a humanoid robot and, to acertain extent, the attribution of a Theory of Mind (ToM).More specifically, we investigate whether these social cuesaffect other utilitarian aspects of the interaction such asknowledge transfer within a teaching context.;2015;2021-06-05T11:27:37Z;2021-06-05T11:27:37Z;NA;NA;NA;NA;6;NA;NA;Towards the synthetic self;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181678012;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
9NEMTAEA;journalArticle;2021;NA;Vocal Synchrony of Robots Boosts Positive Affective Empathy;Applied Sciences;NA;2076-3417;NA;NA;Robots that can talk with humans play increasingly important roles in society. However, current conversation robots remain unskilled at eliciting empathic feelings in humans. To address this problem, we used a robot that speaks in a voice synchronized with human vocal prosody. We conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization. We assessed seven subjective responses related to affective empathy (e.g., emotional connection) and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level. The subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the de-synchronizing condition. The physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization. These findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses.;2021;2021-06-05T11:32:03Z;2021-06-05T11:32:03Z;NA;NA;NA;2502;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8974746860;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
HPV4W3WS;journalArticle;2019;NA;Affective Embodied Agents and Their Effect on Decision Making;Proceedings;NA;2504-3900;NA;NA;Embodied agents, such as avatars and social robots, are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor. This influences how users perceive these technologies and how they interact with them. We report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being. Twenty-one individuals were asked to play the ultimatum game, playing the role of a responder against another person, a computer, an avatar and a robot for a total of 32 games (8 per condition). We hypothesize that affective expressions by avatars and robots influence the emotional state of the users, leading them to irrational behavior by rejecting unfair proposals. We monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder. Our results show that most fair offers were accepted while most unfair offers were rejected. However, participants rejected more very unfair offers made by people and computers than by the avatars or robots.;2019;2021-06-05T11:34:10Z;2021-06-05T11:34:10Z;NA;NA;NA;1;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8464672719;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
HWDTYRT7;journalArticle;2017;"Richard Stillman II; Richard Stillman II";Public professionalism in an era of radical transformations: its meaning, challenges, and training;Revista de Administração Pública;NA;0034-7612;NA;NA;"ArticlePublic professionalism in an era of radical transformations: its meaning, challenges, and trainingProfesionalismo público en una era de transformaciones radicales: su significado, desafíos y entrenamientoRichard Stillman II1  2  1University of Colorado / EUA2Public Administration Review/ EUAPublic professionalism lives within a schizophrenic world today. On one hand more people aspire to be professionals than ever before. As the late Everett Hughes, perhaps the most eminent scholar of this topic, once wrote, “professions are more numerous than ever before. Professional people are a larger portion of the labor force. The professional attitude or mood is likewise more widespread; professional status more sought after.” Everywhere in advanced and developing nations public professionals and professionalism are triumphant in contributing to the GDP growth to shaping and implementing most if not all areas of public policy. In 2017 27% of the full-time American Federal Workforce are classed as professionals, 37% as administrators, and 27% as technical personnel such as 5,521 economists, 35,529 nurses, 20,115 electronics engineers, 17,118 attorneys, and 242 museum curators. Thus over a one-third of federal employees are classed as “professional-technical (a figure which would be much higher if contract employees were included). So widespread is professionalization that long ago, Frederick Mosher termed government as “the professional state”; or Don Price referred to it as “the scientific estate” or Zbigniew Brzezinski called it “the technocratic society”. Whatever it is labelled, public professionals unquestionably make modern government tick and contemporary society run. Yet, in 2017 western nations are reeling from widespread, determined populist revolts against unelected officials. Voter cries against public professionals and their pervasive influence over shaping public policy are loud and frequent. The Brexit vote last year in England sought independence from those unseen, unelected EU officials in Brussels. Donald Trump’s presidential inauguration this year can be attributed significantly to the fact he was “an outsider” who had never been an elected politician, nor even served in any public position, even the military (the first such president ever in U.S. History). His campaign targets were established institutions such as Nato, the Paris Climate Accords, Affordable Health Care, the CIA, and more recently the FBI Director. France, Italy, the Netherlands, and others have witnessed the rise and power of similar populist leaders with wide-ranging agendas to cut government and/or radically reform it. In short, recently the electorate everywhere seem to want to “apply a stick to the backsides” and “bloody the noses” of experts! Ideally rid the world of them!This lecture will attempt to address the challenges of professionals who work in this Janus-Faced, contradictory world that both enthusiastically embraces and forcefully rejects them by examining first, what is public professionalism today? How do we define the term nowadays? What are its major foundational values?Second, what are the key political-sociological-economic trends influencing the activities and shaping actions of public professionals? Their sources and impacts? And how are these forces reshaping the work professionals perform as well as those foundational values that served in the past to create and sustain public professionalism?Finally, given these new realities of radical transformations confronting public professionals world-wide in the second decade of the 21st century, how best can teachers educate those aiming for careers as public professionals as well as advance the skills and expertise of “old hands” who are already in the public service? How can “it” be best taught, given the immense challenges governments everywhere confront?Before going further, it is important to spell out the premises behind my lecture. They are six-fold, relatively clear-cut, and simple:Government decisions and official behavior immensely impact every nation and the world as a whole by influencing society’s development, its economic prosperity, and legitimacy of democracy;The great bulk of public sector decisions, indeed THE key decisions, are determined by public professionals who are largely unelected and tenured;The quality and kinds of decisions and actions these public professionals make depend upon their skills, orientation, outlooks, and values;These professional qualities depend heavily upon their backgrounds, training, education, career development, as well as their current involvement in whatever professional associations or groups they belong;Government is composed of many professions-physicians, lawyers, engineers, etc.-and so it never can hope to become just one professional body, but rather public sector professionalization realistically involves advancing the degree of their individual influence on decision-making as well as inculcating professional values throughout many groups working in the public sector; andThe activities and challenges facing public professionals as well as the advancement of professionalism within each nation are not identical but share many of the same attributes world-wide today.Since “public professional” and “public professionalism” are frequently referred to, it is first essential to define what we are talking about here. These terms are slippery, even ambiguous and open to many interpretations and ways of thinking. Oxford English Dictionary, for example, tells us its earliest meaning derived from “professing” or someone who “professes” to know more about a subject and is better qualified to do a job as a result. “The occupation which one professes to be skilled in and to follow […] A vocation in which professional knowledge of some branch of learning is used in its application to the affairs of others, and in the practice of the art based upon it.” Originally the term “professional” was confined to the traditional callings of divinity, law, medicine, and the military. Today it applies to a far wider, more pervasive, and ever growing groups-some employed exclusively by government such as foreign service officers, city managers, police, military, and urban planners and others employed across the public, nonprofit, and private sectors who enormously influence public sector choices such as lawyers, engineers, scientists, physicians, and economists. And this does not even begin to encompass the newly emerging professions such as cyber-security and emergency disaster personnel or other many specializations and sub-specializations. Given the ever-growing numbers of specialized occupations, can these recent job categories be labelled as professionals? It is not easy to tell nor offer up clear-cut definitions. While there is no commonly agreed up meaning today of public professionals and/or professionalization of the public service, Frederick Mosher’s definition is useful, both precise and flexible enough to fit common-day understanding:[…] a more or less specialized and purposeful field of human activity which require some specialized education or training (though it may be acquired on the job), which offers a career of life work, and enjoys a relatively high status. It normally aspires to social, not selfish, purpose. Usually, but not always, it requires a degree or certification, and credential of some kind. Often its members join in a professional organization, local, state, or national, which enunciates standards and ethics of professional performance sometimes with the powers of enforcement.Note the three value components of Mosher’s definition that serve as the foundational norms of public professionals past and present: applied expertise, corporate identity, and ethical responsibility.First, and above all, public professionalism is based upon expertise. Knowledge, theoretically based but pragmatically applied to shaping directly or indirectly human affairs, serve as origins and ongoing rationale of every professional’s existence. The modern military profession grew out the creation of the formation of the nation-state in the 15th and 16th centuries that demanded trained expertise in what Harold Lasswell once characterized as “the management of violence”. The American City Manager Profession was a mundane result of what to do about potholes in city streets thanks to the newly invented automobile at the dawn of the 20th century. Staunton, Virginia hired the first city manager in 1909, Charles Ashburner, a trained civil engineer, to deal with that pothole problem. Similarly, contemporary responses to specific empirical necessities of coping with cloud computing, applying new crime-fighting CSI techniques, dealing with a sudden outbreak of a heretofore unknown medical disease, or combating the threats of Isis are likewise the cause of the origins and growth of new professions. An urbanized, industrialized, globalized, and information-driven world spawns professionalization at a rapid rate, far more rapid than ever before. Not too long ago, someone went to “an ear, nose, and throat doctor” to treat ailments related to those body parts, but nowadays a myriad of specialists subdivide work in that single area with strange unpronounceable titles such as otolaryngologists, pulmonologists, gastroenterologists, allergists, and much more. Specialization is driven by speedier accumulation of scientific knowledge that requires a subdivision of labor but it also stems from self-interest, i.e. specialized expertise is generally considered higher status and receives higher pay. But whatever the cause of narrowing specialization, according to a recent empirical study by Lotte Anderson and Lene Peterson, professionalism is negatively correlated with compassion, defined as being emotionally (empathically) based motivation to do good for others by improving public service delivery. Rather professional norms of applied expertise are the determining factor for effective service delivery performance to clients rather than the application of more humanly compassion or user friendly approaches. In short, the degree of specialized applied and theoretical knowledge and the firmness and consistence of its application remain the cornerstone of “best practices” of professionals everywhere.Second, a corporate identity forges development and expansion of professions. It also gives structure and purpose to their existence, sets boundaries for the scope and substance of any professional activity, and establishes lines of who belongs inside its ranks and who does not. It further defines and creates “professional elites” who govern and control internal “hidden hierarchies”, in the words of Corinne Gibbs. State Bar Associations or Medical Societies for traditional fields like Law and Medicine or the International City/County Managers’ Association and Society of Civil Engineers for newer careers in local public management and civil engineers provide such corporate structures in America and define the best educational practices, entrance routes, credentialing requirements, continuing training options, codes of conduct, and methods of enforcement. They serve as advocates for a profession by advancing its cause through publicity campaigns with many varieties of internet, lobbying, and hard-copy literature and disseminate knowledge through regular meetings and serious journal publications. As a recent study by Mirko Noordegraaf underscores, professionalism is developed and nurtured via “connectedness” which is advanced in three ways: between professional actions and practices, between segments and groups, and between workplaces and other spaces. Above all, professionals resist political intrusion into their work. Ironically professionals of all stripes often express hostility to anything smacking of “the political” although public professionals by definition work for government and must be ultimately responsive to elected officials. Likewise, they are keen to maintain their independence from other professional groups. Fierce rivalries inside government are frequent between neighboring professions like the repeated conflicts among army, navy, air force personnel. Often invisible to the public and little studied by scholars, these professional associations and their elites exert powerful influences over shaping modern-day professional identities and the public actions they take.Finally, ethical responsibility undergirds as every profession’s ultimate raison d’etre. Professions are rooted in moral purposes of serving others beyond selfish interests. Such moral aims are more often than not codified in written statements, explicit codes of conduct, frequently combined with enforceable mechanisms to ensure their compliance. These may be framed in ancient Hippocratic Oath of Doctors to do no harm or more recent public professional codes of ethics of the Government Finance Officers Association or the American Society for Public Administration that spell out complicated professional, moral, legal standards of conduct for association members. Though realistically the transmission of ethical norms throughout professional ranks is not a product of written documents or codes of ethics but through informal communications of what is acceptable behavior or not. Especially the role models of elites serve to set standards for “best practices”, norms of good behavior, essential training, “ideal career tracks”, and what defines success or not within the field. Conferences, in-house journals, informal discussions inculcate ethical values informally throughout the membership. As James Svara wrote recently, the essence of the articulated ethical values for public professions should stress serving “the public with respect, concern, courtesy, and responsiveness, recognizing that service to the public is beyond service to oneself.” Effective enforcement prods strong, ongoing reminders that violations have significant career consequences-both in the short term and long run. The challenges of ensuring effective ethical enforcement within every profession remain some of the most difficult, complex, and enduring issues they confront.So how are the socio-economic-political trends of today reshaping these professional foundational values for tomorrow? What are the challenges professions face world-wide in recent years? Are the core values upon which public professions were created and grew being strengthen? Or, in decline? My thesis: the traditional three values-applied expertise, corporate identity, and ethical responsibility-upon which public professionals originated and are sustained nowadays are being transformed profoundly across the planet by a series of influential, even contradictory forces. Here are several that appear prominently world-wide, serving shape and reshape the framing values of public professionalism:Populist Revolt vs. the Necessity for Expertise in the Public Sector: As was indicated at the beginning of this lecture, western democracies in recent years experienced strong reactions to unelected officials of all stripes and elected many committed to cutting or eliminating such individuals, but at the same time the demand for more government services remains unabated. How to reconcile these opposites which simultaneously reject and sustain effective government as well as the core values of neutral, objective expertise at the heart of public professionalism?Social Media vs. Sustained Expertise: In 2007 Apple launched it iPhone; late 2006 Facebook opened its doors; Google came out with the Android operating system in 2007; Amazon introduced Kindle in 2007; and Airbnb started in 2007. Thanks to social media the last decade witnessed a fundamental reshaping of individual behavior, work, commerce, finance, education, government, the economy, and yes, public professionalism. Social media asks everyone to be immediately involved, offering immediate answers to complex issues, plus making rapidly shifting demands on public officials. Yes, social media is more democratic because it allows everyone to be involved almost instantaneously, but simultaneously social media fosters “presentism” that drives out long-term thought and action. So how can public professionals who value-indeed require--long term, neutral, applied, objective expertise for problem solving cope with social media? How can they nurture applied expertise that involves thoughtful reflection and careful decision-making among those “who know best”? Given the massive data available-more information than accumulated by humans up to 2003-what is the right sort of data to identify, collect, and utilize vs. ignore and disregard? How do we know the real impact of social media on public professionals?The Pseudo-Event vs. the Real Event: Many years ago Daniel Boorstin referred to a media created event that was unreal or fake as “a pseudo-event”. The rise of social media has accelerated what now is called “fake news”. Often pseudo-events create reality that happens and has serious consequences, such as suicides, staged riots, or shootings. Yet, professionalism rests upon honest information, verifiable facts, as well as objective analysis. Sorting out truth from fiction has always been challenging for public professionals, but the expansion of social media during the last decade only exacerbates an already devilish dilemma. How can professionals discern fact from fiction today and respond appropriately in an increasingly social media saturated world?The Drive to Specialize vs. Integrated Professional Policy-Making: As was emphasized before, the drive to specialize and sub-specialize and so on is apparent within the professional ranks as new issues and new information demand new varieties of expertise. The result is what some term, “stovepipes” throughout government or little clusters of experts who talk to themselves rather than those outside their specialization, beyond their immediate agency, or wider general public. Hence, the right hand often is unaware of what the left hand is doing. Competition among professional groups such as within the defense department-army, air force, navy-further inhibits collaboration. Yet, effective public policy making requires integration across many professional fields to succeed. No professional group can go it alone in any policy-making arena. Thus the dilemma: how to foster integration and collaboration across increasingly narrow specialized and competitive professional ranks?Proliferation of Temporary Contractors vs. In-House Professionals: The recent devastating leaks in American Intelligence have all been the result of temporary contract employees such as Edward Snowden. Increased use of contractors is often justified politically for keeping costs down and cutting government employees. That is good political rhetoric, but there is little evidence to support such rationales. Instead, in the words of Hugh Heclo, we have become a “government of strangers”. As a result, there is potential for a serious erosion of a professional corporate identity due to the lack of commonly shared professional norms plus effective ethical enforcement mechanisms. Hence, the key question: how can professionalization of government as a whole advance when it is seriously challenged from within due to the rise of temporary contract workers (which in national security and law enforcement cases can jeopardize human life as well)?Global Interconnectedness vs. Local Accountability: As mentioned before, professional groups are rooted in state and community level associations such as the State Bar Association or State Medical Societies for entrance exams, credentialing, ethics enforcement, and much more. Yet, increasingly professional work spans the global or at least are interconnected beyond the borders of any single nation. Again, problem-solving demands wider international cooperation and collaboration to succeed in almost every field today from environmental protection to military intervention. Hence, how to insure that public professionals, educated and credentialed within a local jurisdiction, are prepared to see “the big picture” and work effectively with colleagues across national boundaries?Increased Ethical Responsibilities vs. Limited Ethical Training: Not very long ago, it was assumed if you studied public administration, you WERE ETHICAL! Hence, MPA programs until recently were largely devoted to training students in the “bread and butter” topics of training for the 3Es-economy, efficiency, effectiveness-via classes in organization and management, budgeting and finance, human resources management, etc. Few teachers paid much attention to ethics and the subject was largely absent from public administration curricula. While more is being done in classrooms to incorporate ethical training as well as establishing codes of conduct that are enforced by professional associations, the rapid escalation of ethical responsibilities and demands upon public officials continues to grow at a staggering rate. From first-line employee to top department head in government, ethical dilemmas are profound and pervasive. So the central, if not THE CENTRAL CHALLENGE, confronting the field today is: how to develop ethical awareness among professionals in order to make and to apply ethically sound choices for resolving problems they confront?Specialist vs. Generalist Public Service Education: Universities remain conveyor belts for advancing expertise, credentialing, and educating public professionals. Until relatively recently it was easy to name the top public administration schools, the top scholars in the field, an agreed upon means of academic preparation, and recognize a common curriculum for training throughout the field. A generalist orientation largely prepared students for a variety of public sector careers. While today university training beyond the BS or BA degree is generally accepted as the appropriate route to professional careers in government, the choice of schools, curricula, and specializations are staggering in the USA. Generalist degrees have largely declined or disappeared in favor of highly narrow subject matter such as defense policy making, emergency management training, law enforcement administration, budgeting and financial management, or human resources management. Once many of these were designated as sub-fields of a generalist MPA degree but now are offered as stand-alone graduate degrees. But does specialized training adequately prepare students for government work that requires understanding “the big picture”, how to integrate the parts, and then make them operate altogether as a “whole ball of wax”? At what point does increasing professional specialization become counterproductive to achieving “the public interest”?A Clear Dichotomy vs. An Integrated Political/Professional Team: Since the rise of democracy with elected officials and growth of bureaucracies with appointed public professions, the dilemma has always been how to “mesh” the two distinctively different realms of the political and administrative into an effective collaborative team to serve the public interest, especially since both have profoundly different incentive structures, agendas, outlooks, and purposes. The issue is as old as public administration itself; indeed, it was a major concern of Woodrow Wilson’s first essay written in America on the subject, The study of administration (1887), i.e. how to ensure responsible government in light of the creation of a new civil service system? How to make certain professionals are accountable to the public? The topic remains front and center to the public sector world-wide today, namely how can elected officials hold appointed public professionals accountable while at the same time how can professionals offer the best neutral, objective, independent advice and service to elected representatives? Everywhere in the world nowadays this issue of “marrying” political and professional is not only challenging but decides ultimately the fate of many, if not all, key public policy debates.Certainly other current world-wide trends impacting public professionalism could be added to this list, such as citizen participation, union representation in government, and career mobility. But I tried to emphasize those most recent, most critical, and with the greatest potential global impacts on the public sector. Granted, many of my examples and citations were drawn from the USA. So my perspectives and this discussion may well be somewhat limited, parochial, and even biased. I certainly know little about Brazilian public administration and the specific challenges your public service confronts, but I suspect many of the trends outlined above are effecting your nation and its public sector in equally profound, pervasive, and often unknown ways. Especially for those seminal public profession values of applied expertise, corporate identity, and ethical responsibility, my hunch is that individually and collectively these aforementioned forces serve to fragment, diffuse, even negate many aspects of foundational professional values in Brazil as well as everywhere abroad. Thus my central argument for advancing public service education is aimed to revitalize, reinvigorate, and rejuvenate those core values that created and developed public professionalism as we now know it and are under attack in many quarters. Why? Again, as emphasized in the stated premises to this lecture, government decisions and official behavior have immense impact on any nation and the world-social, political, economic-hence, it is the education of public professionals that is critical to shaping public choices and actions. Effective government and a just modern society cannot work without a professionalized public service. If Carl Friedrich once wrote that “bureaucracy is the core of modern government”, certainly “public professionals” are the core of that core.So what are the best routes for advancing public professionalism in the second decade of the 21st century and beyond? Again, I must claim ignorance about Brazil’s public service and its particular contemporary challenges. Though permit me to discuss general educational strategies in light of the nine forgoing global trends and speculate about routes that can significantly serve to strengthen and advance those three foundational professional values. Here I will sum up this talk--not by outlining specific remedies or educational programs and curricula, not arguing for part-time vs. full time alternatives, not in-house vs. university training, not online vs. in classroom face-to-face teaching-but rather by speculating on general educational strategies aimed at broadly strengthening the three seminal foundational values of public professionalism.First, by fostering greater constitutional understanding: Here I am not suggesting more legal training in the specifics of constitutional law. Rather I refer to the broader Aristotelian sense of comprehending the basic purposes, meaning, and influence on public professionals of framing legal documents for every nation. In the case of the United States Constitution, such instruction would not ask students to learn the specifics of the 6 thousand word framing document but rather to comprehend its intellectual origins in the late 18th century and why that era and the men involved fashioned a very unique founding arrangement; its central aims as embodied in its preamble that lay out possibilities, limits, and roles of today’s public sector; its general structure that shapes the current actions and constraints on modern American Government; as well as its 27 amendments since 1789 and evolving interpretations over time that influence public sector activities today. By linking greater constitutional understanding to contemporary public professional education can rejuvenate and invigorate basic ethical values that undergird all professional decision-making activities.Second, by encouraging deeper appreciation of professional history and the lives of professional leaders: Professionals live within a stream of history that runs deep and wide and decisively influences their modern corporate identities of who they are, what they do, and how they operate in the modern-day world. History can tremendously enrich professional careers, inspire their work, by knowledge of their past development, key founders, their accomplishments and, yes, failures. It can broaden their way of thinking about problems; offer examples of not just how-to-do-something, but how-to-do-it-well; what works best or not; as well as approaches and strategies that succeed-or fail. Such education would include reading about the lives of the great professional leaders: why they entered the field, how they learned their professional skills, what they learned about, experienced in their apprenticeships that fostered their career development, how they rose to prominence within the professional ranks, what inspired their deep commitment to this line of work, role models that aided their advancement, and decisions they made that made them historically famous-or infamous as professional leaders. Much of professional education requires hard work and sheer perspiration. History and biography offers invaluable inspiration for those who aspire to top leadership ranks as well as those “old hands” already in charge.Third, by grasping lessons of administrative cases: The world of government does not present its practitioners with simple questions or neat solutions. Especially as they move up in every organizational hierarchy, administrative issues become more and more complex. Professionals in government do not wake up in the morning and say, “Today I will deal with a budget issue”; “tomorrow I will address policy of such and such an area” and “the next day hiring a new employee will be my agenda”. Nothing is so neat and tidy in government. Rather, everything is usually interconnected, events come upon desks unpredictably, and choices are more often than not neither right nor wrong, but mixed with a lot grey uncertainty, without full information, and considerable questions as to the results and outcomes to be achieved. Here is where administrative cases are a necessary pedagogical tool. Unlike medical school or law school cases with often clear-cut right and wrong answers, the best administrative cases are open to many interpretations and force students to see the ambiguity and complexity of so much of what real-life government decision-making is all about. The best administrative cases encourage students to appreciate and navigate such cloudy operational environments as well as learn how successful policy-making and implementation of policy involves working across agency, departmental, and unit lines, using multiple administrative skills of budgeting and finance, human resources, planning, and so on in order to achieve results. In short, cases focusing upon gaining collaborative management skills, seeing “the big picture” beyond the limited intellectual horizons of most professional training, are vital for advancing professionalization in all parts of modern government.Finally, by studying the future: The old adage that we should study the future because that is where we spend the rest of our lives is certainly true or contains an important truth for those who work in the public sector. For better or worse-or better AND worse-virtually all government activities involve shaping the future. It may concern big choices of peace or war, or simply entail plugging numbers into a line-item budget or hiring a new employee. Such big choices or mundane tasks in the public service help to decide what tomorrow will become. The destinies of societies everywhere are the hands of public professionals who are employed throughout government, deciding on the social challenges we face, what they are, and how to confront them by making choices big and small. Though few would debate the value of knowing about the future, the question is how? Or, how to educate professionals in futuristic learning? Certainly the rise of “big data” and its world-wide immense influence on business and government planning and decision-making is apparent and fact of modern life. Thus learning to gather, comprehend, and analyze large data, separating the essential from non-essential, fact from fiction, unlocking the relevant information related to the questions at hand in order to glean future trends is invaluable for predicting the future. But other less grand routes to glimpsing the future can be found by learning how to conduct focus groups, sample expert opinion, or gather reference material from a wide variety of document sources. While certainly no one-best-way exists to properly examine where we are headed tomorrow, the most striking aspect of professional education to date is how little involves thinking about the future. Part of the problem is the popular association of futuristic studies with tea-leaf reading and casting horoscopes, activities not enthusiastically embraced by university academics-so far. But there are numerous more reputable technological-scientific methods worth at least somehow, someway incorporating into our professional training programs which include: trend extrapolation, genius forecasting, Delphic exercises, simulation, scenario building, cross-impact matrix development and much more that can help us predict and plan for tomorrow. Perhaps we cannot see the future with precision or a degree of accuracy we wish, but some guidance is better than nothing to point the way forward in order assist professionals to plan better today. Simply because we do not know how to educate for “it” or so far there is no agreed upon proper training methodology are no excuses for not trying-given that the stakes are so high for professionals working in government, indeed more generally for society’s prosperity and survival.Received: June 21, 2017; Accepted: October 26, 2017Richard Stillman II - Professor of Public Administration at University of Colorado / EUA and Former Editor-in-chief at Public Administration Review / EUA. E-mail: Richard.Stillman@ucdenver.edu. This is an open-access article distributed under the terms of the Creative Commons Attribution License";2017;2021-06-05T11:35:50Z;2021-06-05T11:35:50Z;NA;917-926;10;6;51;NA;NA;Public professionalism in an era of radical transformations;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8522323859;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TSCR3ZQP;journalArticle;2021;Balle, S.N.;Empathic responses and moral status for social robots: an argument in favor of robot patienthood based on K. E. Løgstrup;AI and Society;NA;09515666;10.1007/s00146-021-01211-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104950822&doi=10.1007%2fs00146-021-01211-2&partnerID=40&md5=3787db2c2f40a90ea3212ba2a25225a5;"Empirical research on human–robot interaction (HRI) has demonstrated how humans tend to react to social robots with empathic responses and moral behavior. How should we ethically evaluate such responses to robots? Are people wrong to treat non-sentient artefacts as moral patients since this rests on anthropomorphism and ‘over-identification’ (Bryson and Kime, Proc Twenty-Second Int Jt Conf Artif Intell Barc Catalonia Spain 16–22:1641–1646, 2011)—or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood, such that social robots become our ‘Others’ (Gunkel, Robot rights, MIT Press, London, 2018; Coeckelbergh, Kairos J Philos Sci 20:141–158, 2018)?. In this research paper, I weave extant HRI studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots, on which the ethical evaluation of moral behavior toward them is dependent. Patienthood for robots has standardly been thought to obtain on some intrinsic ground, such as being sentient, conscious, or having interest. But since these attempts neglect moral experience and are curbed by epistemic difficulties, I take inspiration from Coeckelbergh and Gunkel’s ‘relational approach’ to explore an alternative way of accounting for robot patienthood based on extrinsic premises. Based on the ethics of Danish theologian K. E. Løgstrup (1905–1981) I argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjects—even if they emerge from social interaction afforded by robots we have anthropomorphized. I ultimately develop an argument in defense of treating robots as moral patients. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.";2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media Deutschland GmbH;<p>cited By 0</p>;NA;NA;"Social robots; Philosophical aspects; Robot interactions; Social interactions; Human subjects; Catalonia; Empirical research; Research papers";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
63PFUFUA;journalArticle;2021;Pashevich, E.;Can communication with social robots influence how children develop empathy? Best-evidence synthesis;AI and Society;NA;09515666;10.1007/s00146-021-01214-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105417711&doi=10.1007%2fs00146-021-01214-z&partnerID=40&md5=3450c898fc3bbd8515987bb1735a8566;Social robots are gradually entering children’s lives in a period when children learn about social relationships and exercise prosocial behaviors with parents, peers, and teachers. Designed for long-term emotional engagement and to take the roles of friends, teachers, and babysitters, such robots have the potential to influence how children develop empathy. This article presents a review of the literature (2010–2020) in the fields of human–robot interaction (HRI), psychology, neuropsychology, and roboethics, discussing the potential impact of communication with social robots on children’s social and emotional development. The critical analysis of evidence behind these discussions shows that, although robots theoretically have high chances of influencing the development of empathy in children, depending on their design, intensity, and context of use, there is no certainty about the kind of effect they might have. Most of the analyzed studies, which showed the ability of robots to improve empathy levels in children, were not longitudinal, while the studies observing and arguing for the negative effect of robots on children’s empathy were either purely theoretical or dependent on the specific design of the robot and the situation. Therefore, there is a need for studies investigating the effects on children’s social and emotional development of long-term regular and consistent communication with robots of various designs and in different situations. © 2021, The Author(s).;2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media Deutschland GmbH;<p>cited By 0</p>;NA;NA;"Social robots; Machine design; Robot interactions; Social relationships; Economic and social effects; CAN communications; Context of use; Critical analysis; Emotional engagements; Neuropsychology; Potential impacts";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
8H37WPQZ;journalArticle;2021;"Vargas Martin, M.; Pérez Valle, E.; Horsburgh, S.";Artificial Empathy for Clinical Companion Robots with Privacy-By-Design;Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST;NA;18678211;10.1007/978-3-030-70569-5_23;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104418757&doi=10.1007%2f978-3-030-70569-5_23&partnerID=40&md5=d3890f65cafff1ceba3086b0fd4212bf;We present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families. Our approach removes the need for Cloud-based automatic speech recognition systems to address healthcare privacy expectations. Furthermore, we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation. Our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.;2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;351-361;11;NA;362 LNICST;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030705688 Publisher: Springer Science and Business Media Deutschland GmbH;"<p>cited By 0; Conference of 9th EAI International Conference on Wireless Mobile Communication and Healthcare, MobiHealth 2020 ; Conference Date: 19 November 2020 Through 19 November 2020; Conference Code:255799</p>";NA;NA;"Mental health; Health care; Companion robot; Speech recognition; Human robot interaction; Humanoid robot; Machine design; Robot interactions; Anthropomorphic robots; Facial Expressions; Privacy by design; Automatic speech recognition system; Cloud-based; Mobile telecommunication systems";NA;Ye J., Yordanova K., O'Grady M.J., Civitarese G.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
SRBA6GP4;conferencePaper;2021;"Zafar, Z.; Ashok, A.; Berns, K.";Personality traits assessment using p.A.D. Emotional space in human-robot interaction;VISIGRAPP 2021 - Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications;978-989-758-488-6;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974518&partnerID=40&md5=579d9d515e2e418c556711a934135b57;"Cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings. Humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish human-human interaction. Similarly, assessment of human personality is highly critical in realizing natural and intelligent human-robot interaction. Numerous personality traits assessment systems have been reported in the literature; however, most of them target the big five personality traits. From only visual information, this work proposes to use pleasure, arousal, and dominance emotional space for the assessment of personality traits based on the work of Mehrabian. To validate the system, three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot. Experimental results show that the system can assess human personality traits with 84% accuracy in real-time and, hence, it can adapt its behavior according to the perceived personality of the interaction partner. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.";2021;2021-05-19T13:26:07Z;2021-05-19T13:26:07Z;NA;111-118;8;NA;2;NA;NA;NA;NA;NA;NA;NA;SciTePress;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2021 ; Conference Date: 8 February 2021 Through 10 February 2021; Conference Code:167535</p>";NA;NA;"Computer vision; Social robots; Social robotics; Humanoid robot; Personality traits; Man machine systems; Anthropomorphic robots; Assessment system; Computer graphics; Human being; Human-human interactions; Real time; Visual information";NA;Paljic A., Bouatouch K., Peck T., Braz J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
R6B668TQ;journalArticle;2021;"Erel, H.; Trayman, D.; Levy, C.; Manor, A.; Mikulincer, M.; Zuckerman, O.";Enhancing Emotional Support: The Effect of a Robotic Object on Human–Human Support Quality;International Journal of Social Robotics;NA;18754791;10.1007/s12369-021-00779-5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105378198&doi=10.1007%2fs12369-021-00779-5&partnerID=40&md5=31fccb98f281cb4956d06a3377775de0;Emotional support in the context of psychological caregiving is an important aspect of human–human interaction that can significantly increase well-being. In this study, we tested if non-verbal gestures of a non-humanoid robot can increase emotional support in a human–human interaction. Sixty-four participants were invited in pairs to take turns in disclosing a personal problem and responding in a supportive manner. In the experimental condition, the robotic object performed emphatic gestures, modeled according to the behavior of a trained therapist. In the baseline condition, the robotic object performed up-and-down gestures, without directing attention towards the participants. Findings show that the robot’s empathy-related gestures significantly improved the emotional support quality provided by one participant to another, as indicated by both subjective and objective measures. The non-humanoid robot was perceived as peripheral to the natural human–human interaction and influenced participants’ behavior without interfering. We conclude that non-humanoid gestures of a robotic object can enhance the quality of emotional support in intimate human–human interaction. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.;2021;2021-05-19T13:26:07Z;2021-05-19T13:26:07Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media B.V.;<p>cited By 0</p>;NA;NA;"Robotics; Social robots; Humanoid robot; Agricultural robots; Anthropomorphic robots; Human interactions; Base-line conditions; Emotional supports; Experimental conditions; Human support; Subjective and objective measures; Well being";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Z4EBSUD4;journalArticle;2020;Wales, J.J.;Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots;Frontiers in Artificial Intelligence and Applications;NA;09226389;10.3233/FAIA200906;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65;According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.;2020;2021-05-19T13:26:08Z;2021-05-19T13:26:08Z;NA;114-124;11;NA;335;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9781643681542 Publisher: IOS Press BV;"<p>cited By 0; Conference of 4th Conference on Robophilosophy 2020: Culturally Sustainable Social Robotics ; Conference Date: 18 August 2020 Through 21 August 2020; Conference Code:165874</p>";NA;NA;"Robotics; Social robots; Philosophical aspects; Training data; Augustine; Bodily movement; Consumer products; Educational robots; Instrumentalization; Personal robot; Users' satisfactions";NA;Norskov M., Quick O.S., Seibt J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
WWZZQQSJ;journalArticle;2020;"Xiao, G.; Tu, G.; Zheng, L.; Zhou, T.; Li, X.; Ahmed, S.H.; Jiang, D.";Multi-modality Sentiment Analysis in Social Internet of Things based on Hierarchical Attentions and CSATTCN with MBM Network;IEEE Internet of Things Journal;NA;23274662;10.1109/JIOT.2020.3015381;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099552559&doi=10.1109%2fJIOT.2020.3015381&partnerID=40&md5=00cb27c2be4c5b7cab3cc2add96681ec;Multi-modality sentiment analysis in the social internet of things is a developing field, which is basic to empathetic mechanisms, affective computing, and artificial intelligence. Current works in this domain do not explicitly consider the influence of contextual information fusion based on correlation coefficient and memory network with branch structure for sentiment analysis. Unlike present works, this paper presents a Hierarchical Self-attention Fusion (H-SATF) model for capturing contextual information better among utterances, a Contextual Self-attention Temporal Convolutional Network (CSAT-TCN) for the sentiment recognition in social internet of things, and a Multi Branches Memory (MBM) network that stores self-speaker and inter-speaker sentimental states into global memories. For the MOSI datasets, the hybrid H-SATF-CSAT-TCN-MBM model outperforms the state-of-art networks and shows 0.31 9.93% improvement. IEEE;2020;2021-05-19T13:26:16Z;2021-05-19T13:26:16Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Institute of Electrical and Electronics Engineers Inc.;<p>cited By 5</p>;NA;NA;"Sentiment analysis; Affective Computing; Internet of things; Convolutional neural networks; Correlation coefficient; ART networks; Arts computing; Branch structure; Contextual information; Convolutional networks; Memory network; Multi modality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
NK9PK8ZM;journalArticle;2020;"Hickton, L.; Lewis, M.; Cañamero, L.";Expression of Grounded Affect: How Much Emotion Can Arousal Convey?;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-63486-5_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231;In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:17Z;2021-05-19T13:26:17Z;NA;234-248;15;NA;12228 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030634858 Publisher: Springer Science and Business Media Deutschland GmbH;"<p>cited By 0; Conference of 21th Annual Conference on Towards Autonomous Robotics, TAROS 20120 ; Conference Date: 16 September 2020 Through 16 September 2020; Conference Code:252749</p>";NA;NA;"Robotics; Social robots; Humanoid robot; Anthropomorphic robots; Affective state; Control robots; Exploratory studies; Hexapod robots; Simple modeling";NA;Mohammad A., Russo M., Dong X.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Q28YISCM;journalArticle;2020;"Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.";Emotion Synchronization Method for Robot Facial Expression;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-49062-1_44;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20;Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:17Z;2021-05-19T13:26:17Z;NA;644-653;10;NA;12182 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030490614 Publisher: Springer;"<p>cited By 0; Conference of Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242229</p>";NA;NA;"Robots; Synchronization; Communication robot; Emotion estimation; Facial Expressions; Human computer interaction; Human robots; Biological signals; Human emotion; Subjective impressions; Synchronization method";NA;M, Kurosu;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
N7E9HMBI;journalArticle;2020;"Sejima, Y.; Sato, Y.; Watanabe, T.";Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-030-20441-9_11;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b;Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;95-102;8;NA;952;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030204402 Publisher: Springer Verlag;"<p>cited By 0; Conference of AHFE International Conference on Affective and Pleasurable Design, 2019 ; Conference Date: 24 July 2019 Through 28 July 2019; Conference Code:226989</p>";NA;NA;"Empathy; Human robot interaction; Pupil response; Man machine systems; Non-verbal communications; Body contacts; Emotional expressions; Face to face; Measurement device; Pet Robots";NA;S, Fukuda;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
Z2PWQV5Y;conferencePaper;2020;"Firdaus, M.; Ekbal, A.; Bhattacharyya, P.";Incorporating politeness across languages in customer care responses: Towards building a multi-lingual empathetic dialogue agent;LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings;979-10-95546-34-4;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096584871&partnerID=40&md5=7e8e8d8f2bef5ac7638ad3b967c8b7f7;Customer satisfaction is an essential aspect of customer care systems. It is imperative for such systems to be polite while handling the customer requests or demands. In this paper, we present a large multi-lingual conversational dataset for English and Hindi. We choose data from Twitter having both generic and courteous responses between customer care agents and aggrieved users. We also propose strong baselines that can induce courteous behaviour in generic customer care response in a multi-lingual scenario. We build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agent's responses. Our system is competent in generating responses in different languages (here, English and Hindi) depending on the customer's preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention. Experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system. Qualitative and quantitative analysis show that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction. © European Language Resources Association (ELRA), licensed under CC-BY-NC;2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;4172-4182;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;European Language Resources Association (ELRA);NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>";NA;NA;"Deep learning; Linguistics; Customer satisfaction; Sales; Customer care; Customer care systems; Information shared; Large dataset; Learning frameworks; Qualitative and quantitative analysis";NA;Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
E6WFDILN;journalArticle;2020;"Chung, S.-E.; Ryoo, H.-Y.";Gesture design attribute and level value of social robot: A user experience based study;Journal of System and Management Sciences;NA;18166075;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3;"This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.";2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;108-121;14;2;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Success Culture Press;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
66NMRVTN;journalArticle;2019;"Sena, J.R.; Cabatuan, M.";Deep learning-based facial expression recognition and analysis for filipino gamers;International Journal of Recent Technology and Engineering;NA;22773878;10.35940/ijrte.B1027.078219;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286;This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.;2019;2021-05-19T13:26:22Z;2021-05-19T13:26:22Z;NA;1822-1827;6;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Blue Eyes Intelligence Engineering and Sciences Publication;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
2IG7HJYR;journalArticle;2019;"Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.";Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects;Lecture Notes in Electrical Engineering;NA;18761100;10.1007/978-3-030-04672-9_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f;The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:25Z;2021-05-19T13:26:25Z;NA;101-113;13;NA;540;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030046712 Publisher: Springer Verlag;"<p>cited By 0; Conference of 8th Italian Forum on Ambient Assisted Living, ForitAAL 2017 ; Conference Date: 12 June 2017 Through 15 June 2017; Conference Code:223489</p>";NA;NA;"Robotics; Animals; Empathy; Robots; Social robotics; Human-object continuum; Living-nonliving continuum; Social distance; Assisted living";NA;Casiddu N., Monteriu A., Porfirione C., Cavallo F.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
5T8D4UEI;journalArticle;2019;"Parviainen, J.; van Aerschot, L.; Särkikoski, T.; Pekkarinen, S.; Melkas, H.; Hennala, L.";Motions with emotions? A phenomenological approach to understanding the simulated aliveness of a robot body;Techne: Research in Philosophy and Technology;NA;10918264;10.5840/techne20191126106;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081323649&doi=10.5840%2ftechne20191126106&partnerID=40&md5=378eb5e3022a3bfccf7c5f223679272b;This article examines how the interactive capabilities of companion robots, particularly their materiality and animate movements, appeal to human users and generate an image of aliveness. Building on Husserl's phenomenological notion of a 'double body' and theories of emotions as affective responses, we develop a new understanding of the robots' simulated aliveness. Analyzing empirical findings of a field study on the use of the robot Zora in care homes for older people, we suggest that the aliveness of companion robots is the result of a combination of four aspects: 1) material ingredients, 2) morphology, 3) animate movements guided by software programs and human operators as in Wizard of Oz-settings and 4) anthropomorphising narratives created by their users to support the robot's performance. We suggest that narratives on affective states, such as, sleepiness or becoming frightened attached to the robot trigger users' empathic feelings, caring and tenderness toward the robot. © 2019 Philosophy Documentation Center. All rights reserved.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;318-341;24;3;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Philosophy Documentation Center;<p>cited By 10</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
G2XV38T9;journalArticle;2019;"Zhang, Y.; Qi, S.";User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-22335-9_24;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825;With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;350-366;17;NA;11588 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030223342 Publisher: Springer Verlag;"<p>cited By 2; Conference of 6th International Conference on HCI in Business, Government, and Organizations, HCIBGO 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228649</p>";NA;NA;"Robotics; Surveys; Decision making; Robots; User experience; Hospitality; Service quality management; Human computer interaction; User interfaces; Consumer behavior; Decision making process; Hotels; Quality of service; Quantitative research; Regression analysis; Research objectives; Service expectations; User classification; Wages";NA;Nah F.F.-H., Siau K.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
6VLJCLM4;conferencePaper;2019;"Arriaga, O.; Valdenegro-Toro, M.; Plöger, P.G.";Real-time convolutional neural networks for emotion and gender classification;ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning;978-2-87587-065-0;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2;Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;221-226;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;ESANN (i6doc.com);NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 6; Conference of 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2019 ; Conference Date: 24 April 2019 Through 26 April 2019; Conference Code:149793</p>";NA;NA;"Neural networks; Machine learning; Convolutional neural network; Convolution; Real time; Computation time; Facial feature; Gender classification; Gender recognition; Open source license; Open systems; Real time evaluation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
X9SLPHH8;journalArticle;2019;"Matsuyama, Y.; Asahi, Y.";High Sensitivity Layer Feature Analysis in Food Market;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-22649-7_19;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335;It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:27Z;2021-05-19T13:26:27Z;NA;232-243;12;NA;11570 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030226480 Publisher: Springer Verlag;"<p>cited By 1; Conference of Thematic Area on Human Interface and the Management of Information, HIMI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228569</p>";NA;NA;"Deep learning; Intelligent systems; Testing; Decision tree analysis; Innovation theory; Test marketing; Human computer interaction; Commerce; Conducting tests; Decision theory; Decision trees; Feature analysis; Generalized models; High sensitivity; Image analysis; Market researches; Sales; Text processing";NA;Yamamoto S., Mori H.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
IQN3B54D;conferencePaper;2019;"Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.";Digital empathy secures Frankenstein’s monster;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210;People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.;2019;2021-05-19T13:26:27Z;2021-05-19T13:26:27Z;NA;335-349;15;NA;2348;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 4; Conference of 5th Collaborative European Research Conference, CERC 2019 ; Conference Date: 29 March 2019 Through 30 March 2019; Conference Code:147497</p>";NA;NA;"Speech recognition; Diagnosis; Computation theory; Computer games; Computational model; Image recognition; Asian games; Expert systems; General practitioners; Large datasets; Medical imaging; Robotic surgery; Surgery; Surgical operation";NA;Walsh P., Low R., Burkhardt D., Bleimann U., Regier S., Stengel I., Humm B.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
3NJTM4KV;conferencePaper;2018;"Hieida, C.; Horii, T.; Nagai, T.";Emotion Differentiation based on Decision-Making in Emotion Model;RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication;978-1-5386-7980-7;NA;10.1109/ROMAN.2018.8525579;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058082859&doi=10.1109%2fROMAN.2018.8525579&partnerID=40&md5=a8b97edffc128454fce9f7f211968e30;Having emotions is essential for robots in order for them to understand and sympathize with people's feelings. In addition, it may allow robots to be accepted in human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions is proposed based on various neurological and psychological findings related to empathic communication between humans and robots. Subsequently, a decision-making mechanism based on affects using convolutional long short-term memory and deep deterministic policy gradient is examined. We set a 'facial expression' task simulating mother-child interactions and verified emotion differentiation during the task. © 2018 IEEE.;2018;2021-05-19T13:26:28Z;2021-05-19T13:26:28Z;NA;659-665;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 1; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>";NA;NA;"Decision making; Robots; Human society; Facial Expressions; Behavioral research; Emotion modeling; Decision-making mechanisms; Policy gradient";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
IVJTPPUI;journalArticle;2018;"Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.";Approaches for generating empathy: A systematic mapping;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-319-54978-1_89;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f;Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.;2018;2021-05-19T13:26:31Z;2021-05-19T13:26:31Z;NA;715-722;8;NA;558;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319549774 Publisher: Springer Verlag;"<p>cited By 5; Conference of 14th International Conference on Information Technology - New Generations, ITNG 2017 ; Conference Date: 10 April 2017 Through 12 April 2017; Conference Code:195369</p>";NA;NA;"Robotics; Virtual reality; Empathy; Human robot interaction; Customer satisfaction; Rapport; Secondary study; Teaching; Human computer interaction; Social interactions; Mapping; Computer games; Computer supported cooperative work; Computer aided instruction; Collaborative learning environment; Collaborative systems; Customer relationships; Public relations; Systematic mapping studies";NA;S, Latifi;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
UGMA3339;journalArticle;2018;"Kwon, O.; Kim, J.; Jin, Y.; Lee, N.";Impact of human-robot interaction on user satisfaction with humanoid-based healthcare;International Journal of Engineering and Technology(UAE);NA;2227524X;10.14419/ijet.v7i2.12.11038;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911;Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.;2018;2021-05-19T13:26:32Z;2021-05-19T13:26:32Z;NA;68-75;8;2;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Science Publishing Corporation Inc;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VI8PE6FJ;journalArticle;2018;"Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.";Smiles of children with ASD may facilitate helping behaviors to the robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-05204-1_6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5;Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.;2018;2021-05-19T13:26:32Z;2021-05-19T13:26:32Z;NA;55-64;10;NA;11357 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030052034 Publisher: Springer Verlag;"<p>cited By 0; Conference of 10th International Conference on Social Robotics, ICSR 2018 ; Conference Date: 28 November 2018 Through 30 November 2018; Conference Code:221569</p>";NA;NA;"Robotics; Robots; Helping behavior; Smile; Diseases; Autism spectrum disorders; Children with autisms; Positive correlations; Social communications";NA;Broadbent E., Wagner A.R., Ge S.S., Salichs M.A., Castro-Gonzalez A., He H., Cabibihan J.-J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
VCGBWBXG;journalArticle;2017;Chan, Z.C.Y.;Poetry writing and artistic ability in problem-based learning;International Journal on Disability and Human Development;NA;21911231;10.1515/ijdhd-2016-0003;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb;Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;37-44;8;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Walter de Gruyter GmbH;<p>cited By 2</p>;NA;NA;"writing; empathy; nursing; teaching; literature; creativity; human; clinical article; content analysis; follow up; Hong Kong; interview; long term memory; narrative; problem based learning; professional knowledge; stress management";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
GPRSZF8H;conferencePaper;2017;"Lewandowska-Tomaszczyk, B.; Wilson, P.A.";Compassion, empathy and sympathy expression features in affective robotics;7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings;978-1-5090-2645-6;NA;10.1109/CogInfoCom.2016.7804526;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2;"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.";2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;65-70;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 10; Conference of 7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 ; Conference Date: 16 October 2016 Through 18 October 2016; Conference Code:125734</p>";NA;NA;"Robotics; emotions; empathy; expressiveness; action tendencies; British English; compassion; empatia; GRID; responsiveness; sympathy; sympatia; valence; Corpus linguistics; False negatives; False positive; Polishing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
TD7PTSNQ;journalArticle;2017;"Chumkamon, S.; Hayashi, E.";Consciousnes-based emotion and behavior of pet robot with brain-inspired method;Information (Japan);NA;13434500;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1;A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;615-629;15;1;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: International Information Institute Ltd.;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
V72RVEC5;conferencePaper;2017;Silvey, P.E.;Leveling up: Strategies to achieve integrated cognitive architectures;AAAI Fall Symposium - Technical Report;978-1-57735-794-0;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044476959&partnerID=40&md5=09dc018b9aa3ed3c09f13c6428cf44b4;Human-level cognition (most uniquely characterized by our abilities to use language) should be seen as a superset of functional and behavioral capabilities shared by lower life-forms including animals and insects, and this perspective ought to principally guide our strategies for developing integrated cognitive architectures. Just as the study of biological model organisms has led to tremendous advances in our scientific knowledge of genetics and cellular function, the study of embodied cognition in simple agent-environment simulations can yield similar advances in Cognitive Science, Artificial Intelligence, and Robotics. By working first on the foundations of intelligent interaction with one's environment, and by focusing on core functions such as predictive and inductive learning, probabilistic goal-directed behavior compilation, and empathetic reasoning, we can better establish the grounding that the physical symbol system hypothesis assumes (Newell and Simon 1976), yet often without explicit demonstration of a mechanism to derive symbolic relations and semantics from raw sensory data. Logic and language are seen to emerge from our willingness to make discrete simplifying assumptions in a continuous and probabilistic world of experience, and developing a Standard Model of the Mind can help build much-needed bridges between historically nonaligned research communities. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;460-465;6;NA;FS-17-01 - FS-17-05;NA;NA;NA;NA;NA;NA;NA;AI Access Foundation;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 2017 AAAI Fall Symposium ; Conference Date: 9 November 2017 Through 11 November 2017; Conference Code:134706</p>";NA;NA;"Semantics; Artificial intelligence; Human robot interaction; Cognitive architectures; Intelligent robots; Cognitive systems; Research communities; Bioinformatics; Biological modeling; Environment simulation; Intelligent interactions; Military applications; Probabilistic goals; Public risks; Scientific knowledge; Simplifying assumptions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
U6FFXJCS;journalArticle;2017;"Cho, H.-K.; Oh, J.; Lee, K.";A study on the potential roles of a robot peer in socio-emotional development of children;International Journal of Computational Vision and Robotics;NA;17529131;10.1504/IJCVR.2017.083447;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b;This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;335-343;9;3;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Inderscience Publishers;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
3VEZNKK2;journalArticle;2017;"Smith, S.J.; Stone, B.T.; Ranatunga, T.; Nel, K.; Ramsoy, T.Z.; Berka, C.";Neurophysiological indices of human social interactions between humans and robots;Communications in Computer and Information Science;NA;18650929;10.1007/978-3-319-58750-9_36;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025174844&doi=10.1007%2f978-3-319-58750-9_36&partnerID=40&md5=a79ac8fdcd00acc223e0c6708767cf68;"Technology continues to advance at exponential rates and we are exposed to a multitude of electronic interfaces in almost every aspect of our lives. In order to achieve seamless integration of both, human and technology, we must examine the objective and subjective responses to such interactions. The goal of this study was to examine neurophysiological responses to movement, communication, and usability with a robot assistant, in comparison to human assistant, in a real-world setting. OSHbot (robot assistants designed by Fellow Robots) were utilized as mobile store clerks to identify and locate merchandise in order to assist customers in finding items within a hardware store. By acquiring neurophysiological measures (electroencephalogram; EEG and electrocardiogram; ECG) of human perception and interaction with robots, we found evidence of Mirror Neuron System (MNS) elicitation and motor imagery processing, which is consistent with other studies examining human-robot interactions. Multiple analyses were conducted to assess differences between human-human interaction and human-robot interaction. Several EEG metrics were identified that were distinguishable based on interaction type; among these was the change observed across the Mu bandwidth (8–13 Hz). The variance in this EEG correlate has been related to empathetic state change. In order to explore differences in the interactions related to gender and age additional analyses were conducted to compare the effects of human-human interaction versus human-robot interaction with data stratified by gender and age. This analysis yielded significant differences across these categories between human-human interaction and human-robot interaction within EEG metrics. These preliminary data show promise for future research in the field of human-robot relations in contributing to the design and implementation of machines that not only deliver basic services but also create a social connection with humans. © Springer International Publishing AG 2017.";2017;2021-05-19T13:26:37Z;2021-05-19T13:26:37Z;NA;251-262;12;NA;713;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319587493 Publisher: Springer Verlag;"<p>cited By 1; Conference of 19th International Conference on Human-Computer Interaction, HCI International 2017 ; Conference Date: 9 July 2017 Through 14 July 2017; Conference Code:194249</p>";NA;NA;"Neurophysiology; Electroencephalography; Robots; Human robot interaction; Eye-tracking; Man machine systems; Machine design; Human-human interactions; Human computer interaction; Social interactions; Social sciences; Human social interactions; Electrocardiography; Design and implementations; Bandwidth; Electronic interface; Neurophysiological measures; Seamless integration";NA;C, Stephanidis;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
FYPEQ7KH;conferencePaper;2017;"De Carolis, B.; Ferilli, S.; Palestra, G.; Redavid, D.";Emotion-recognition from speech-based interaction in AAL environment;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016315295&partnerID=40&md5=48d39fe986e3c8fb67cf9285e325457c;In Ambient Assisted Living environments assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. To this aim social assistive robots are being employed as a mediator interface and, in order to achieve a relation with the user, they should be endowed with the capability of recognizing the user affective state. Since a natural way to interact with a robot is speech, spoken user's input can be used to give to the robot the capability of recognizing the emotions and attitude of the user, thus providing more detail information about the user state. This paper focuses on this topic and proposes an approach based on the dimensional model of emotions in which the valence and arousal of user's spoken input are recognized. The experimental analysis shows the performance in terms of accuracy of the proposed approach on an Italian dataset. In order to show its application in the context of Ambient Assisted Living, an example is provided. © 2017, CEUR-WS. All rights reserved.;2017;2021-05-19T13:26:37Z;2021-05-19T13:26:37Z;NA;92-104;13;NA;1803;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 1; Conference of 2nd Italian Workshop on Artificial Intelligence for Ambient Assisted Living, AI*AAL.it 2016 ; Conference Date: 28 November 2016; Conference Code:126783</p>";NA;NA;"Artificial intelligence; Robots; Speech recognition; Ambient assisted living; Affective state; Assistive robots; Deep neural networks; Assisted living; ITS applications; Ambient intelligence; Task-oriented; Emotion recognition from speech; Interface states; Dimensional model; Experimental analysis";NA;Bandini S., Cortellessa G., Palumbo F.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
T72TY9EG;journalArticle;2016;"Bennett, P.; Moore, M.; Wenham, J.";The PAUL Suit©: An experience of ageing;Clinical Teacher;NA;17434971;10.1111/tct.12410;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962516324&doi=10.1111%2ftct.12410&partnerID=40&md5=b1c6d99b190d125ab4dbf1d3806b09d5;Background: An ageing population worldwide makes it increasingly important that health students understand issues that elderly people face and can provide empathic care to them. Context: This teaching department in an isolated rural setting developed an interprofessional learning session to assist health students to understand issues of functional loss and social isolation that can affect elderly people. Innovation: The Premature Ageing Unisex Leisure (PAUL) Suit© was developed as part of a 1-day learning session for undergraduate health students - including students of medicine, nursing and allied health - attending clinical placement in far-west New South Wales. The suit was developed locally and can be adjusted to simulate a wide range of functional losses in the wearer. Students undertake a range of daily tasks in the community while wearing the suit in the company of a student 'carer'. Over the past 4 years, approximately 140 students have participated in the simulation. Post-simulation evaluations report that students gain a greater understanding of some functional issues associated with ageing, and of the social isolation that can be associated with these. The experiential nature of the activity leads to some powerful insights. This activity is an innovative, experiential tool to deepen students understanding of issues related to ageing Implications: This activity is an innovative, experiential tool to deepen students understanding of issues relating to ageing. The interprofessional nature of the activity is an important factor in the success of the day, and produces a wide range of shared insights. The activity also enhances the partnerships between the university, the health service and the local community. Our experience supports the value of simulation in providing a deep learning opportunity in the area of ageing and disability. © 2016 John Wiley & Sons Ltd.;2016;2021-05-19T13:26:39Z;2021-05-19T13:26:39Z;NA;107-111;5;2;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Blackwell Publishing Ltd;<p>cited By 8</p>;NA;NA;"Humans; learning; Learning; education; psychology; Aging; human; health care personnel; Health Personnel; aging; Interprofessional Relations; Mobility Limitation; New South Wales; program evaluation; Program Evaluation; public relations; walking difficulty";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
8CLPN3UV;journalArticle;2016;"Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.";Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy;Paladyn;NA;20814836;10.1515/pjbr-2016-0005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88;An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.;2016;2021-05-19T13:26:39Z;2021-05-19T13:26:39Z;NA;55-66;12;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: De Gruyter Open Ltd;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
XAEAITMC;conferencePaper;2016;"Ferreira, M.I.A.; Sequeira, J.S.";Designing a robotic interface for children: The MOnarCH robot example;Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016;978-981-314-912-0;NA;10.1142/9789813149137_0076;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999663794&doi=10.1142%2f9789813149137_0076&partnerID=40&md5=7de84e5ccd68ae2c76e5f3801431a3f9;The development of an empathic link between oneself and the Other is a fundamental part of interpersonal relationships determining the establishment of effective social and affective links that are the grounding basis of successful communication and cooperation on which the cohesion of human societies depend and on which harmonious global personal development also stands. The design of efficient robotic interfaces for interaction with people, namely with children, depends on the development of expressive elements to be present in the appearance of robots and in the way they address and interact with people, i.e. on the definition of a set of socially behaviours identified as communication enhancers. The present paper reflects how the previous assumptions have determined the process that led to the construction of the MOnarCH robots and some of its design options. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.;2016;2021-05-19T13:26:41Z;2021-05-19T13:26:41Z;NA;652-659;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;World Scientific Publishing Co. Pte Ltd;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 1; Conference of 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016 ; Conference Date: 12 September 2016 Through 14 September 2016; Conference Code:185329</p>";NA;NA;"Robotics; Communication; Mobile robots; Social robotics; Machine design; Human society; Economic and social effects; Interpersonal relationship; Children/robot interaction; Designing for interaction; Expressiveness; Personal development; Robotic interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
F6TNAXP8;journalArticle;2016;"Shukla, J.; Barreda-Ángeles, M.; Oliver, J.; Puig, D.";MuDERI: Multimodal database for emotion recognition among intellectually disabled individuals;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-319-47437-3_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992523179&doi=10.1007%2f978-3-319-47437-3_26&partnerID=40&md5=5ecb6239283b3977469c0dc20359fa09;Social robots with empathic interaction is a crucial requirement towards deliverance of an effective cognitive stimulation among individuals with Intellectual Disability (ID) and has been challenged by absence of any particular database. Project REHABIBOTICS presents a first ever multimodal database of individuals with ID, recorded in a nearly real world settings for analysis of human affective states. MuDERI is an annotated multimodal database of audiovisual recordings, RGB-D videos and physiological signals of 12 participants in actual settings, which were recorded as participants were elicited using personalized real world objects and/or activities. The database is publicly available. © Springer International Publishing AG 2016.;2016;2021-05-19T13:26:41Z;2021-05-19T13:26:41Z;NA;264-273;10;NA;9979 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319474366 Publisher: Springer Verlag;"<p>cited By 4; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>";NA;NA;"Robotics; Emotion recognition; Multimodal database; Assistive robotics; Intellectual disability; Database systems; Physiological signals; Robot-assisted therapies; Cognitive stimulations; Disabled individuals; Rating";NA;Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
W9PXXX4R;conferencePaper;2015;"Mazzei, D.; Zaraki, A.; Lazzeri, N.; De Rossi, D.";Recognition and expression of emotions by a symbiotic android head;IEEE-RAS International Conference on Humanoid Robots;978-1-4799-7174-9;NA;10.1109/HUMANOIDS.2014.7041349;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945179051&doi=10.1109%2fHUMANOIDS.2014.7041349&partnerID=40&md5=f47b54fd692ed1f07a9bef8e2a4b0f1c;The creation of social empathie communication channels between social robots and humans has started to become reality. Nowadays, the development of empathie and affective agents is giving to scientists another way to explore the social dimension of human beings. In this work, we introduce the FACE humanoid project that aims at creating a social and emotional android. FACE is an android head with an articulated neck mounted on a passive body. In order to enable FACE to perceive and express emotions, two dedicated engines have been developed. A sensory apparatus able to perceive the 'social world', and a facial expressions generation engine that allows the robot to express its synthetic emotions. The system has been also integrated with an attention-based gaze generation component that allows the robot to autonomously follow a conversation between its partners. The developed framework has been implemented and tested in several standard human-robot interaction settings. Results demonstrated the promising social capabilities of the robot to perceive and convey emotions to humans through the generation of emotional perceivable facial expressions and socially aligned behaviour. © 2014 IEEE.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;134-139;6;NA;2015-February;NA;NA;NA;NA;NA;NA;NA;IEEE Computer Society;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 21640572;"<p>cited By 3; Conference of 2014 14th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2014 ; Conference Date: 18 November 2014 Through 20 November 2014; Conference Code:112990</p>";NA;NA;"Social robots; Human robot interaction; Anthropomorphic robots; Human being; Facial Expressions; Behavioral research; Express emotions; Engines; Social dimensions; Synthetic emotions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
S6N2JSV6;conferencePaper;2015;"De Carolis, B.; Ferilli, S.; Palestra, G.; Carofiglio, V.";Towards an empathic social robot for ambient assisted living;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928737527&partnerID=40&md5=b573ae7afac79bef8ae0c8f77bd8451d;In the context of Ambient Assisted Living, assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. This can be achieved, for instance, using a social assistive robot as interface towards the environment services. In the context of the NICA (Natural Interaction with a Caring Agent) project we developed the behavioral architecture of a social robot able to assist the user in the interaction with a smart home environment. In this paper we describe how this robot has been endowed with the capability of recognizing the user affective state from the combination of facial expressions and spoken utterances and to reason on in order to simulate an empathic behavior.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;19-34;16;NA;1351;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 8; Conference of 2nd International Workshop on Emotion and Sentiment in Social and Expressive Media, ESSEM 2015 ; Conference Date: 5 May 2015; Conference Code:112014</p>";NA;NA;"Robots; Social robots; Autonomous agents; Intelligent buildings; Ambient assisted living; Affective state; Facial Expressions; Assistive robots; Multi agent systems; Automation; Natural interactions; Task-oriented; As interfaces";NA;Cambria E., Patti V., Rosso P., Bosco C., Damiano R.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
34JPKPGJ;journalArticle;2015;"Vallverdú, J.; Casacuberta, D.";Ethical and technical aspects of emotions to create empathy in medical machines;Intelligent Systems, Control and Automation: Science and Engineering;NA;22138986;10.1007/978-3-319-08108-3_20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e;This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;341-362;22;NA;74;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Kluwer Academic Publishers;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
A89B4BEA;journalArticle;2015;"Virčíkova, M.; Sinčák, P.";Teach your robot how you want it to express emotions: On the personalized affective human-humanoid interaction;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-319-10783-7_9;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032118207&doi=10.1007%2f978-3-319-10783-7_9&partnerID=40&md5=22af8b608d901d438a4c1910a06c47ef;We believe that in order for robots to interact naturally with humans, they should be able to express affective behavior. This paper deals with the development of an affective model for social robotics in which the resulting robotic expressions adapt according to the human subjective preferences. We have developed a method which can be used by non-technical individuals to design the affective models of humanoid robots. Our vision of the future research is that the proposed personalization will be treated, from user’s perspective, as an empathic response of the machine. We see the major contribution of this unique approach especially in long-term human-robot relationships and it could ultimately lead to robots being accepted in a wider domain. © Springer International Publishing Switzerland 2015.;2015;2021-05-19T13:26:44Z;2021-05-19T13:26:44Z;NA;81-92;12;NA;316;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Verlag;<p>cited By 0</p>;NA;NA;"Robotics; Computer vision; Robots; Human robot interaction; Social robotics; Humanoid robot; Machine design; Anthropomorphic robots; Humanoid interaction; Human robots; Economic and social effects; Affective behaviors; Personalizations; Express emotions; Affective model";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA
LYXK3QA8;conferencePaper;2015;"Pieroni, M.; Rizzello, L.; Rosini, N.; Fantoni, G.; De Rossi, D.; Mazzei, D.";Affective Internet of Things: Mimicking human-like personality in designing smart-objects;IEEE World Forum on Internet of Things, WF-IoT 2015 - Proceedings;978-1-5090-0365-5;NA;10.1109/WF-IoT.2015.7389088;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964556250&doi=10.1109%2fWF-IoT.2015.7389088&partnerID=40&md5=8a13b6d0e0a3f31879eb1dbd9bcdce78;The paper wants to introduce the concept of Affective Internet of Things (AIoT) where smart objects are empowered with affective capability in terms of abstraction of their emotional state. Moreover each smart object can be associated with a specific 'personality'. This approach, already used in the field of social robotics, mainly exploits robots' appearance (i.e. anthropomorphism or zoomorphism). The research aims at extending such a paradigm to everyday-life objects in order to 'warm-up' the empathic connections that humans generally establish with 'cold' gadgets and devices. A new framework for the Affective IoT has been developed: EMPATI (EMPATI Mimics Personalities on Affective Things on Internet). It provides models and functions to simulate different personality for affective objects living in both virtual and real world. Finally, a set of experiments has been conceived to assess the key aspects of the framework in terms of capability to simulate emotional responses depending on the object interaction with the environment and the affective stimuli. © 2015 IEEE.;2015;2021-05-19T13:26:45Z;2021-05-19T13:26:45Z;NA;400-405;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 6; Conference of 2nd IEEE World Forum on Internet of Things, WF-IoT 2015 ; Conference Date: 14 December 2015 Through 16 December 2015; Conference Code:119271</p>";NA;NA;"Robotics; Internet; Social robotics; Emotional state; Emotional response; Human computer interaction; Human like; Internet of things; Real-world; affective object; Object interactions; Smart objects";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA

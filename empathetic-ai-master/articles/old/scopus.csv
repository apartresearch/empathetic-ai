"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"ZXV4N2ZU","journalArticle","2021","Irfan, F.","Artificial intelligence: Help or hindrance for family physicians?","Pakistan Journal of Medical Sciences","","","10.12669/pjms.37.1.3351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096989073&doi=10.12669%2fpjms.37.1.3351&partnerID=40&md5=c41326d8fd2999819e37ec0e1a8eb331","The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician’s new assistant; AI-physician combinations can act like models of ‘peaceful co-existence’. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician’s diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients’ frustration. © 2021, Professional Medical Publications. All rights reserved.","2021","2021-02-15 22:33:58","2021-02-15 22:33:58","","1-4","","1","37","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RVTE2H9","journalArticle","2021","Bilewicz, M.; Tempska, P.; Leliwa, G.; Dowgiałło, M.; Tańska, M.; Urbaniak, R.; Wroczyński, M.","Artificial intelligence against hate: Intervention reducing verbal aggression in the social network environment","Aggressive Behavior","","","10.1002/ab.21948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100209523&doi=10.1002%2fab.21948&partnerID=40&md5=9c486d6fb70ead5dab93d1c932aada1c","This article presents a quasi-experimental intervention study designed to reduce the level of verbal aggression on a social networking service (Reddit). The interventions were based on three psychological mechanisms: induction of a descriptive norm, induction of a prescriptive norm, and empathy induction. Each intervention was generated using a communicating bot. Participants exposed to these interventions were compared with a control group that received no intervention. The bot-generated normative communications (both the ones priming descriptive and the ones priming prescriptive norms), as well as the empathizing intervention, reduced the proportion of verbal aggression posted by Reddit accounts. All three interventions proved effective in reducing verbal violence when compared with the control condition. © 2021 Wiley Periodicals LLC","2021","2021-02-15 22:33:58","2021-02-15 22:33:58","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DW4KCRX","journalArticle","2021","Hashiguchi, T.; Yamamoto, T.; Fujita, S.; Ohshima, H.","Searching for distress of similar situation from CQA content","Transactions of the Japanese Society for Artificial Intelligence","","","10.1527/tjsai.36-1_WI2-B","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099157569&doi=10.1527%2ftjsai.36-1_WI2-B&partnerID=40&md5=c5003c12ca7efda18147f000346742c2","In this study, we tackle the problem of retrieving questions from a corpus archived in a Community Question Answering service that a consultant having distress can feel empathy with them. We hypothesize that the consultant feels empathy with the questions having a similar situation with that of the consultant’s distress, and propose a method of retrieving similar sentences focusing on the situation of the distress. Specifically, we propose two approaches to fine-tuning the pre-trained BERT model so that the learned model better captures the similarity of the situation between distress. One tries to extract only the words representing the situation of the distress, the other tries to predict whether the two sentences show the same situation. The data for training the models are gathered by the crowdsourcing task where the workers are asked to gather the sentences whose situation is similar to the given sentence and to annotate the words in the sentences that represent the situation. The data is then used to fine-tune the BERT model. The effectiveness of the proposed methods is evaluated with the baselines such as TF-IDF, Okapi BM25, and the pre-trained BERT. The results of the experiment with 20 queries showed that one of our methods achieved the highest nDCG@5 while we could not observe any significant differences among the methods. © 2021, Japanese Society for Artificial Intelligence. All rights reserved.","2021","2021-02-15 22:33:58","2021-02-15 22:33:58","","WI2-B_1-WI2-B_13","","1","36","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KY6AV5D","journalArticle","2020","Schmetkamp, S.","Understanding A.I. — Can and Should we Empathize with Robots?","Review of Philosophy and Psychology","","","10.1007/s13164-020-00473-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083955575&doi=10.1007%2fs13164-020-00473-x&partnerID=40&md5=8c5a1a9139fa546337a1ecdeea7e1f49","Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding. © 2020, Springer Nature B.V.","2020","2021-02-15 22:33:58","2021-02-15 22:33:58","","881-897","","4","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VS6NZGTH","journalArticle","2020","Liao, J.; Hansen, P.; Chai, C.","A framework of artificial intelligence augmented design support","Human-Computer Interaction","","","10.1080/07370024.2020.1733576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084312865&doi=10.1080%2f07370024.2020.1733576&partnerID=40&md5=098f22d0398c863d6ad804592ff100f6","Recent advances in Artificial Intelligence raise interest in its participation in design activity, which is commonly considered to be complex and human-dominated. In this work, we aim to examine AI roles in early design stages. The human ideation components and design tools related to AI are discussed in a framework of AI-augmented design support. The framework develops a hierarchy of design cognition (basis), approaches and principles. The cognitive models are constructed in an empirical study of 30 designers (26 for analysis, 4 for pilot study) by concurrent Think-Aloud protocol and behavior analysis. The process of producing new design ideas is explained by a transparent analysis of designers’ language and behaviors. Three strategies to organize cognitive activities in design ideation are summarized: develop structured consideration, relate to a scenario, and stick-to designing. These strategies suggest AI could act as (1) representation creation, (2) empathy trigger and (3) engagement, in principles of “knowledge-driven” and “decompose-and-integrate”. The design support with AI provides new perspectives on computer-based design tools that limit to well-defined design variables. The framework is built on a generic notion of design activity and “mimic” human design rationales, expected to benefit research of domain-independent computational design supports and cognitive supports. © 2020 Taylor & Francis Group, LLC.","2020","2021-02-15 22:33:58","2021-02-15 22:33:58","","511-544","","5-6","35","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A87JHFBH","journalArticle","2020","Baki Kocaballi, A.; Ijaz, K.; Laranjo, L.; Quiroz, J.C.; Rezazadegan, D.; Tong, H.L.; Willcock, S.; Berkovsky, S.; Coiera, E.","Envisioning an artificial intelligence documentation assistant for future primary care consultations: A co-design study with general practitioners","Journal of the American Medical Informatics Association","","","10.1093/jamia/ocaa131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096355732&doi=10.1093%2fjamia%2focaa131&partnerID=40&md5=8bfdd5fbd3064e7bb5b25a8cc185ccb9","Objective: The study sought to understand the potential roles of a future artificial intelligence (AI) documentation assistant in primary care consultations and to identify implications for doctors, patients, healthcare system, and technology design from the perspective of general practitioners. Materials and Methods: Co-design workshops with general practitioners were conducted. The workshops focused on (1) understanding the current consultation context and identifying existing problems, (2) ideating future solutions to these problems, and (3) discussing future roles for AI in primary care. The workshop activities included affinity diagramming, brainwriting, and video prototyping methods. The workshops were audio-recorded and transcribed verbatim. Inductive thematic analysis of the transcripts of conversations was performed. Results: Two researchers facilitated 3 co-design workshops with 16 general practitioners. Three main themes emerged: professional autonomy, human-AI collaboration, and new models of care. Major implications identified within these themes included (1) concerns with medico-legal aspects arising from constant recording and accessibility of full consultation records, (2) future consultations taking place out of the exam rooms in a distributed system involving empowered patients, (3) human conversation and empathy remaining the core tasks of doctors in any future AI-enabled consultations, and (4) questioning the current focus of AI initiatives on improved efficiency as opposed to patient care. Conclusions: AI documentation assistants will likely to be integral to the future primary care consultations. However, these technologies will still need to be supervised by a human until strong evidence for reliable autonomous performance is available. Therefore, different human-AI collaboration models will need to be designed and evaluated to ensure patient safety, quality of care, doctor safety, and doctor autonomy. © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.","2020","2021-02-15 22:33:58","2021-02-15 22:33:58","","1695-1704","","11","27","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5M8AN3LD","journalArticle","2020","McDonald, N.; Pan, S.","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proceedings of the ACM on Human-Computer Interaction","","","10.1145/3415218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094204706&doi=10.1145%2f3415218&partnerID=40&md5=e91f074cfe55852594702ade8fcff795","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course. © 2020 ACM.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","CSCW2","4","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBWE5JR2","conferencePaper","2020","Wang, Z.","Future challenges in the next generation of voice user interface","Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020","","","10.1109/CDS49703.2020.00045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098868220&doi=10.1109%2fCDS49703.2020.00045&partnerID=40&md5=5242ff50af9fa8ad1855ea7df90463e7","With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI. © 2020 IEEE","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","191-193","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QEAC3WRM","journalArticle","2020","Kerasidou, A.","Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare [L'intelligence artificielle et le besoin constant d’empathie, de compassion et de confiance dans le secteur de la santé] [La inteligencia artificial y la continua necesidad de empatía, compasión y confianza en la atención sanitaria]","Bulletin of the World Health Organization","","","10.2471/BLT.19.237198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083246717&doi=10.2471%2fBLT.19.237198&partnerID=40&md5=cb5246773745079c64d8a27e85022353","Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote. © 2020, World Health Organization. All rights reserved.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","245-250","","4","98","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJINAGBK","conferencePaper","2020","Dixit, R.; Chinnam, R.B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","IEEE Aerospace Conference Proceedings","","","10.1109/AERO47225.2020.9172612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092594173&doi=10.1109%2fAERO47225.2020.9172612&partnerID=40&md5=0e5e0dbad1bd51bfa0c0a6e225195406","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once 'trained,' can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to 'techies' from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further. © 2020 IEEE.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KV34A3NB","journalArticle","2020","Kim, H.C.; Cha, M.C.; Ji, Y.G.","The effect of empathy on human-agent interaction","ICIC Express Letters, Part B: Applications","","","10.24507/icicelb.11.06.551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085004414&doi=10.24507%2ficicelb.11.06.551&partnerID=40&md5=2a2ed44f0075def60a3d405839efaab1","Technology development and information communication have led to an in-crease of human-agent communication and provided an opportunity to overcome the ex-isting limitation human-human communication. Psychological counseling studies suggest conventional face-to-face counseling method can replace the role of a counselor by ap-plying agent technology. The present study has been established to identify the effects of empathy in human-agent interaction. In order to do so, we designed and conducted a pilot study of a prototype of counseling conversation based on psychological counseling theory. We have found that empathic agents resulted in lower score on counselor’s as-sessment and lower level of empathy perceived by the subjects. The simple empathy used in this study may have given the participants a sense of imitating a clumsy human be-ing and have caused a higher level of displeasure and discomfort compared to the agents without empathy response. This study is meaningful in that it provides basic data for developing and improving an artificial intelligence-based psychological counseling system by designing artificial intelligence counseling agents and varying levels of empathy. © ICIC International 2020.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","551-557","","6","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YU4SKFN","journalArticle","2020","Erden, Y.J.; Hummerstone, H.; Rainey, S.","Automating autism assessment: What AI can bring to the diagnostic process","Journal of Evaluation in Clinical Practice","","","10.1111/jep.13527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097612678&doi=10.1111%2fjep.13527&partnerID=40&md5=e4fff3517d81410cf748b34bfdb6bf25","This paper examines the use of artificial intelligence (AI) for the diagnosis of autism spectrum disorder (ASD, hereafter autism). In so doing we examine some problems in existing diagnostic processes and criteria, including issues of bias and interpretation, and on concepts like the ‘double empathy problem’. We then consider how novel applications of AI might contribute to these contexts. We're focussed specifically on adult diagnostic procedures as childhood diagnosis is already well covered in the literature. © 2020 The Authors. Journal of Evaluation in Clinical Practice published by John Wiley & Sons Ltd.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REX3BB4I","journalArticle","2020","Ostherr, K.","Artificial Intelligence and Medical Humanities","Journal of Medical Humanities","","","10.1007/s10912-020-09636-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088927968&doi=10.1007%2fs10912-020-09636-4&partnerID=40&md5=53ea81de6d941d02b11180d7678fa092","The use of artificial intelligence in healthcare has led to debates about the role of human clinicians in the increasingly technological contexts of medicine. Some researchers have argued that AI will augment the capacities of physicians and increase their availability to provide empathy and other uniquely human forms of care to their patients. The human vulnerabilities experienced in the healthcare context raise the stakes of new technologies such as AI, and the human dimensions of AI in healthcare have particular significance for research in the humanities. This article explains four key areas of concern relating to AI and the role that medical/health humanities research can play in addressing them: definition and regulation of “medical” versus “health” data and apps; social determinants of health; narrative medicine; and technological mediation of care. Issues include data privacy and trust, flawed datasets and algorithmic bias, racial discrimination, and the rhetoric of humanism and disability. Through a discussion of potential humanities contributions to these emerging intersections with AI, this article will suggest future scholarly directions for the field. © 2020, The Author(s).","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BINWUHBM","journalArticle","2020","Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.","Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey","Digital Health","","","10.1177/2055207620968355","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094669527&doi=10.1177%2f2055207620968355&partnerID=40&md5=5e2909e410f68527e010deb3b1f9b7b3","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues. © The Author(s) 2020.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","6","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ZBRW28B","conferencePaper","2020","Nobles, A.L.; Leas, E.C.; Dredze, M.; Ayers, J.W.","Examining peer-to-peer and patient-provider interactions on a social media community facilitating ask the doctor services","Proceedings of the 14th International AAAI Conference on Web and Social Media, ICWSM 2020","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099601301&partnerID=40&md5=6cd8f112b367c90578389a21573a3e13","Ask the Doctor (AtD) services provide patients the opportunity to seek medical advice using online platforms. While these services represent a new mode of healthcare delivery, study of these online health communities and how they are used is limited. In particular, it is unknown if these platforms replicate existing barriers and biases in traditional healthcare delivery across demographic groups. We present an analysis of AskDocs, a subreddit that functions as a public AtD platform on social media. We examine the demographics of users, the health topics discussed, if biases present in offline healthcare settings exist on this platform, and how empathy is expressed in interactions between users and physicians. Our findings suggest a number of implications to enhance and support peer-to-peer and patient-provider interactions on online platforms. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","464-475","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGDYPP4J","conferencePaper","2020","Baggio, B.","AI and education reborn","ICSIT 2020 - 11th International Conference on Society and Information Technologies, Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085913813&partnerID=40&md5=c04d7d1a2cb21e5464fb3932a7117e19","AI (Artificial Intelligence) will have enormous impacts on education, learning and talent development in K-12, higher Education and workplace learning. AIEd has barely scratched the surface. It will redefine the role of the teacher and support creative and human acts that provide ingenuity and empathy in support of learning. The gold is in the data. As AI interprets data, examines the role of the teacher or expert, supports classroom evolution and provides one on one tutoring, AIEd will be inextricably linked to the future of AI. AI comes with opportunities and many challenges. The adoption rate of new AI technologies seems to be on a path unprecedented in history. AI will need to provide insight in to learning and measure innate characteristics like curiosity and creativity. New pedagogies, research into existing learning sciences and learning contexts are needed. © 2020 by the International Institute of Informatics and Systemics. All rights reserved.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","34-39","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4N8I938","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective intelligence: When, where and why","Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering","","","10.1109/Confluence47617.2020.9058000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083999561&doi=10.1109%2fConfluence47617.2020.9058000&partnerID=40&md5=dc43e7ffcf6adf8f724ffaf9d79a8e30","The term 'Collective' is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief. © 2020 IEEE.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","805-810","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXVJ77TF","journalArticle","2020","Chiang, A.-H.; Trimi, S.","Impacts of service robots on service quality","Service Business","","","10.1007/s11628-020-00423-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089085301&doi=10.1007%2fs11628-020-00423-8&partnerID=40&md5=845fde74db3c352ab9c164b287bcc23f","With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZJSLLXTJ","journalArticle","2020","Davis, A.E.","The future of law firms (and lawyers) in the age of artificial intelligence [O Futuro dos escritorios de advocacia (e dos advogados) na era da inteligencia artificial]","Revista Direito GV","","","10.1590/2317-6172201945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090527121&doi=10.1590%2f2317-6172201945&partnerID=40&md5=fc37caa4e681a8f07c4ae6a46375adb7","This article explores the future for lawyers and law firms in the light of the changes that Artificial Intelligence (""AI"") is already bringing to the universe of legal services. Part I briefly describes some of the ways AI is already in use in ordinary life-from facial recognition, through medical diagnosis to translation services. Part II describes how AI is transforming what it means to provide legal services in six primary areas: Litigation review; expertise automation; legal research; contract analytics; contract and litigation document generation; and predictive analytics. Part III explores who are the providers of these AI driven legal services-often non-lawyer legal service providers-and how these providers are replacing at least some of what clients have traditionally sought from lawyers. Part III also discusses the implications of all these changes both for the future role of lawyers individually, and in particular what services will clients still need lawyers to perform: Judgment, empathy, creativity and adaptability. In turn, this Part examines what will these changes mean for the size, shape, composition and economic model of law firms, as well as the implications of these changes for legal education and lawyer training. Part IV identifies the principal legal, ethical, regulatory and risk management issues raised by the use of AI in the provision of legal services. Finally, in Part V the article considers who will be the likely providers of AI based services other than law firms: Legal publishers, major accounting firms and venture capital funded businesses. © 2020 Fundacao Getulio Vargas, Escola de Direito de Sao Paulo. All rights reserved.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","1DUMMT","","1","16","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXKMY2Y5","journalArticle","2020","Johnson, J.","Delegating strategic decision-making to machines: Dr. Strangelove Redux?","Journal of Strategic Studies","","","10.1080/01402390.2020.1759038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084253030&doi=10.1080%2f01402390.2020.1759038&partnerID=40&md5=6b22890c802c9b5864b40f003515f307","Will the use of artificial intelligence (AI) in strategic decision-making be stabilizing or destabilizing? What are the risks and trade-offs of pre-delegating military force (or automating escalation) to machines? How might non-nuclear state and non-state actors leverage AI to put pressure on nuclear states? This article analyzes the impact of strategic stability of the use of AI in the strategic decision-making process, in particular, the risks and trade-offs of pre-delegating military force (or automating escalation) to machines. It argues that AI-enabled decision support tools, by substituting the role of human critical thinking, empathy, creativity, and intuition in the strategic decision-making process, will be fundamentally destabilizing if defense planners come to view AI’s ‘support’ function as a panacea for the cognitive fallibilities and human analysis and decision-making. The article also considers the nefarious use of AI-enhanced fake news, deepfakes, bots, and other forms of social media by non-state actors and state proxy actors, which might cause states to exaggerate a threat from ambiguous or manipulated information, increasing instability. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J5K2PRFU","journalArticle","2020","Lima Dantas, D.; Filgueiras, L.V.L.; Brandão, A.A.F.; Machado Domingues, M.C.; Ferreira, M.R.","Detecting IoT Applications Opportunities and Requirements Elicitation: A Design Thinking Based Approach","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-50344-4_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740148&doi=10.1007%2f978-3-030-50344-4_7&partnerID=40&md5=82f5cd968cdecbc941b929dd7ba6216c","IoT development is complex. To reduce this complexity, IoT platforms provide a set of resources and functionalities to enable application development and support its execution. In this work, we present a human-centered approach for requirements elicitation and mapping them to application resources in IoT platforms, using empathy, definition and ideation methods. A previous study by the authors has identified 11 categories of resources provided by 47 IoT platforms to developers in their application layers. From this set, 6 categories were selected for this work: schedulers and triggers, message and notification triggers, big data and analytics, artificial intelligence and machine learning, dashboards, and services. We invited 18 members of 8 projects for a workshop and divided them in 4 teams, according their project areas, which are: Industry 4.0 (6 participants), Environmental Disasters (4 participants), Environmental Management (3 participants) and Pollution (5 participants). We divided the workshop in 3 phases: warm-up, with user journey mapping, requirements identification using “how might we” questions as a trigger and requirements clustering the questions by the 6 selected categories of resources or an extra category named “others” for those which could not be related to any previous category. Our contribution for the IoT application development is an approach for turning easier requirements elicitation using DT techniques, covering the stages of empathise, definition and ideation, with well-available materials and considering the resources present at application layer of IoT platforms. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:33:59","2021-02-15 22:33:59","","85-100","","","12203 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8HJJHMU","journalArticle","2019","Lee, Y.; Ha, M.; Kwon, S.; Shim, Y.; Kim, J.","Egoistic and altruistic motivation: How to induce users’ willingness to help for imperfect AI","Computers in Human Behavior","","","10.1016/j.chb.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069643866&doi=10.1016%2fj.chb.2019.06.009&partnerID=40&md5=28cafea9d01522cf0bc054743c000c61","Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI. © 2019","2019","2021-02-15 22:33:59","2021-02-15 22:33:59","","180-196","","","101","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH8ZSMQ7","conferencePaper","2019","Chiu, K.C.","Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation","IEEE International Conference on Industrial Engineering and Engineering Management","","","10.1109/IEEM44572.2019.8978876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079589864&doi=10.1109%2fIEEM44572.2019.8978876&partnerID=40&md5=9e2b70a2e94f2f185efda9854aa1323f","This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence. © 2019 IEEE.","2019","2021-02-15 22:33:59","2021-02-15 22:33:59","","1516-1520","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FD3V8R64","conferencePaper","2019","Franzoni, V.; Milani, A.; Biondi, G.; Micheli, F.","A preliminary work on dog emotion recognition","Proceedings - 2019 IEEE/WIC/ACM International Conference on Web Intelligence Workshops, WI 2019 Companion","","","10.1145/3358695.3361750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074373338&doi=10.1145%2f3358695.3361750&partnerID=40&md5=28643a3c506d284761d30c4e16a889af","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence. © 2019 Copyright held by the owner/author(s).","2019","2021-02-15 22:33:59","2021-02-15 22:33:59","","91-96","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BS8HS2CZ","journalArticle","2019","Bristol, R.C.","An Essay on Narrative, Reality, and Imagination","Psychoanalytic Inquiry","","","10.1080/07351690.2019.1659025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074169447&doi=10.1080%2f07351690.2019.1659025&partnerID=40&md5=e63ea1dc96732323847d76ffb96ead71","Narrative is a verbal account, a story of related events which can be factual, fictional or both. Life experience and imagination are as essential to narrative as narrative is to mankind. The phylogenic perspective of literature suggests an inborn capacity for empathy, intelligence and inventiveness, whereas the ontological example is variable. Western knowledge, politics and ethics have evolved from their narrative of Greek myth, epic and drama, the few medieval writers, singularly by the Elizabethan theater, importantly the Arthurian legend and romance stories, English and Russian novels, and uniquely the American short story. This heritage progressively demarcated such life themes as the hero, maiden and adversary; love, hate and indifference; loyalty, deception and betrayal; desire, achievement and loss. These characterizations of self and other remain relevant to the contemporary novel, cinema/TV, and theater, as well as the news, commentary, and real life. Conversely, postmodern assumptions challenge that individual subjectivity determines what is real, valid or authentic, consequently the relativism of traditional, institutional and historical precedents of the truth. Further, the computer, gaming, smart device, and artificial intelligence have changed the content and function of customary narrative. Nonetheless, narrative — real and imagined, ancient and new — retains the meaning of a story about connected events which variously transcends the boundaries of difference. ©, Copyright © Melvin Bornstein, Joseph Lichtenberg, Donald Silver.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","476-484","","7","39","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WL23FZWH","journalArticle","2019","Powell, J.","Trust me, i'm a chatbot: How artificial intelligence in health care fails the turing test","Journal of Medical Internet Research","","","10.2196/16222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074230200&doi=10.2196%2f16222&partnerID=40&md5=f07051700ad8b816ddd71e05e867d094","Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. © 2019 John Powell.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WE7NX3IC","journalArticle","2019","Gong, C.; Lin, F.; Zhou, X.; Lu, X.","Amygdala-inspired affective computing: To realize personalized intracranial emotions with accurately observed external emotions","China Communications","","","10.23919/JCC.2019.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072068065&doi=10.23919%2fJCC.2019.08.011&partnerID=40&md5=3572d915fbee1668aed2dea06ab6916b","Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected. © 2013 China Institute of Communications.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","115-129","","8","16","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RB6G29YR","journalArticle","2019","Brocker, L.; Fazilleau, C.; Naudin, D.","Artificial intelligence in medicine: benefits and limits [L'intelligence artificielle en médecine: intérêts et limites]","Oxymag","","","10.1016/j.oxy.2019.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074056912&doi=10.1016%2fj.oxy.2019.06.003&partnerID=40&md5=57183ca6f74749e13959cc6e9b952387","Artificial intelligence (AI) has been developed in the field of healthcare in order to help professionals improve their efficiency, their productivity and their consistency in the quality of care provided to patients. The use of artificial intelligence in fields such as imaging or medicines management has proved to be effective. There is no doubt that it exceeds the analysis capability of humans. Nevertheless, in many other fields, AI cannot equal human intelligence as the latter's complexity cannot be copied. The brain's ability to adapt, consciousness and subjectivity as well as qualities essential for decision-making such as empathy still remain unique to humans. © 2019 Elsevier Masson SAS L’intelligence artificielle a été développée dans le domaine de la santé afin d’aider les professionnels à améliorer leur efficacité, leur productivité et leur constance dans la qualité des soins apportés aux patients Ses applications dans des domaines tels que l’imagerie ou la gestion des médicaments ont montré son efficacité Sans nul doute, l’intelligence artificielle dépasse la capacité d’analyse humaine Dans bien d’autres domaines, elle ne peut pourtant égaler l’intelligence humaine dont la complexité ne peut être copiée La capacité du cerveau à s’adapter, à laquelle s’ajoutent la conscience et la subjectivité, ainsi que les qualités essentielles à la prise de décision comme l’empathie, restent encore le propre de l’homme. © 2019 Elsevier Masson SAS","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","8-13","","167","32","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X85UMYPW","conferencePaper","2019","Antle, A.N.; Sadka, O.; Radu, I.; Gong, B.; Cheung, V.; Baishya, U.","Emototent: Reducing school violence through embodied empathy games","Proceedings of the 18th ACM International Conference on Interaction Design and Children, IDC 2019","","","10.1145/3311927.3326596","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068777726&doi=10.1145%2f3311927.3326596&partnerID=40&md5=97a693937d75a70c18a1fc709fe74d36","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being. © 2019 Association for Computing Machinery.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","755-760","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9HQSWJM","journalArticle","2019","Hueso, L.C.","Ethics in design for the development of an artificial intelligence, trustworthy robotics and big data and their utility for the law [Ética en el diseño para el desarrollo de una inteligencia artificial, robótica y big data confiables y su utilidad desde el derecho]","Revista Catalana de Dret Public","","","10.2436/rcdp.i58.2019.3303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602971&doi=10.2436%2frcdp.i58.2019.3303&partnerID=40&md5=863eada5a2fd83cae50e563f874c41e9","The study deals with the ethics of artificial intelligence (AI). Firstly, we explain the proclamation of the ethics and its necessity in the different international reference documents, although the analysis is focused on the actions carried out in the European Union. It is precisely in the EU where there is a special commitment to developing an ethics for a trustworthy AI in design and made in Europe, to position itself in front of United States and especially China, two countries that don’t pay much attention to the issue. Firstly, we describe the content of ethics of AI and its essential principles from the point of view of the dignity and rights; second, we describe the main five principles contained in the international declarations. Third, we include other basic principles which arise from the demands of empathy with humans. From a somewhat sceptical perspective, we argue the potential utilities of ethics of AI for the law: it is considered to be an especially preventive instrument and that an ethical governance of AI can be developed, following the examples of policies and frameworks on public ethics and institutional integrity. The phases to be followed are described in this regard. We explain in detail the opportunity and the basic content of codes of conduct and committees and other control systems. Finally, we make an appeal for the design of algorithms that serve as guardians of regulatory compliance and the ethics of AI. © 2019, Public Administration School of Catalonia. All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","29-48","","58","2019","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GLS97G4J","journalArticle","2019","Clavelle, J.T.; Sweeney, C.D.; Swartwout, E.; Lefton, C.; Guney, S.","Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition","Journal of Nursing Administration","","","10.1097/NNA.0000000000000757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931093&doi=10.1097%2fNNA.0000000000000757&partnerID=40&md5=c67866ef50603649810f548af2d47672","Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented. © Wolters Kluwer Health, Inc. All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","303-309","","6","49","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMINYE3Y","journalArticle","2019","Sanal, M.G.; Paul, K.; Kumar, S.; Ganguly, N.K.","Artificial intelligence and deep learning: The future of medicine and medical practice","Journal of Association of Physicians of India","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067569100&partnerID=40&md5=cc6799f54fa56c639d845a3e9b5806d1","Artificial Intelligence (AI) and access to “Big Data” together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (“wiki”) with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition. © 2019, Journal of Association of Physicians of India. All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","71-73","","May","67","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFHSAZL4","journalArticle","2019","Arnar, D.O.","Digital cardiology, artificial intelligence and the value of empathy","Laeknabladid","","","10.17992/lbl.2019.04.223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064007194&doi=10.17992%2flbl.2019.04.223&partnerID=40&md5=f8dffc44ae531b62aa2fa71d2f556f75","","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","159","","4","105","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HD3NRUL7","journalArticle","2019","Blease, C.; Kaptchuk, T.J.; Bernstein, M.H.; Mandl, K.D.; Halamka, J.D.; Desroches, C.M.","Artificial intelligence and the future of primary care: exploratory qualitative study of UK general practitioners' views","Journal of Medical Internet Research","","","10.2196/12802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063303215&doi=10.2196%2f12802&partnerID=40&md5=41136ee763c24454922fbdbed2e48d68","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPS') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPS' opinions about the likelihood of future technology to fully replace GPS in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPS also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPS believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPS considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPS' views. © 2019 Journal of Medical Internet Research. All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","","","3","21","","","","","","","","","","","","","","","","","","<p>cited By 15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IM4NTZK6","journalArticle","2019","Wartman, S.A.; Combs, C.D.","Reimagining medical education in the age of AI","AMA Journal of Ethics","","","10.1001/amajethics.2019.146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061990597&doi=10.1001%2famajethics.2019.146&partnerID=40&md5=eb1325df514ae1ebc5c6e2532c89d224","Available medical knowledge exceeds the organizing capacity of the human mind, yet medical education remains based on information acquisition and application. Complicating this information overload crisis among learners is the fact that physicians' skill sets now must include collaborating with and managing artificial intelligence (AI) applications that aggregate big data, generate diagnostic and treatment recommendations, and assign confidence ratings to those recommendations. Thus, an overhaul of medical school curricula is due and should focus on knowledge management (rather than information acquisition), effective use of AI, improved communication, and empathy cultivation. ©2019 American Medical Association.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","146-152","","2","21","","","","","","","","","","","","","","","","","","<p>cited By 21</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVJDY829","conferencePaper","2019","Das, A.K.; Ashrafi, A.; Ahmmad, M.","Joint cognition of both human and machine for predicting criminal punishment in judicial system","2019 IEEE 4th International Conference on Computer and Communication Systems, ICCCS 2019","","","10.1109/CCOMS.2019.8821655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071115729&doi=10.1109%2fCCOMS.2019.8821655&partnerID=40&md5=c2141b9cb6d314f80753bcccba34ada4","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can’t only perform faster but also predict better than human. But a human has some qualities which can never be gained by a Machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to ‘Women and Children Repression Prevention Act, 2000’. We apply several Machine learning algorithms to make a Machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide Machine for judging a delinquent. © 2019 IEEE.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","36-40","","","","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPTHVNYX","conferencePaper","2019","Shvo, M.","Towards empathetic planning and plan recognition","AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","","","10.1145/3306618.3314307","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070635759&doi=10.1145%2f3306618.3314307&partnerID=40&md5=69bd49013c7283146e3d8efb1d0c94a9","Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants. © 2019 Copyright held by the owner/author(s).","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","525-526","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBI5F9NV","journalArticle","2019","Varlamov, O.O.; Chuvikov, D.A.; Adamova, L.E.; Petrov, M.A.; Zabolotskaya, I.K.; Zhilina, T.N.","Logical, philosophical and ethical aspects of AI in medicine","International Journal of Machine Learning and Computing","","","10.18178/ijmlc.2019.9.6.885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077569724&doi=10.18178%2fijmlc.2019.9.6.885&partnerID=40&md5=b1dc5825375f976debfee3cffa094d4c","The logical type of Artificial Intelligence is presented in the article. MIVAR (Multidimensional Informational Variable Adaptive Reality) technology is based on the gnoseological triplet concept ""Thing - Property - Relationship."" The unlimited number of MIVAR units fill the MIVAR space that makes it communicatory, discrete, and scalable. MIVAR information processing allows creating complicated algorithms for medicine. We have chosen the clinical model of pain in the heart for preparation ontology for doctors. Knowledge expert model MIVAR WiMi ""Chest Pain"" is shown. The logical Artificial Intelligence (expert model) can help doctors fast, precisely and in the best way in the decision-making process. Except medical ontology Artificial Intelligence must have an empathic, emotional experience, without that medical care cannot be imagined. MIVAR technology is the closest to human thinking among other Artificial Intelligence technologies; it differs from the Artificial network of Mirror neurons, related to emotional perception, but MIVAR space with rules and constraints can imitate emotions and empathy. © 2019 International Association of Computer Science and Information Technology.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","868-873","","6","9","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMZHKZ72","journalArticle","2019","Solé, J.P.","Artificial intelligence, administrative law and mankind reservation: algorithms and due technological process [Inteligencia artificial, derecho administrativo y reserva de humanidad: algoritmos y procedimiento administrativo debido tecnológico]","Revista General de Derecho Administrativo","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068589087&partnerID=40&md5=e4350872b2bcf9ffdc0e541e5080fcba","After analyzing the situation in Spain, it suggests some regulatory improvements in accordance to international ideas and regulations. The study recommends a reservation for human intervention in the case of discretionary powers due to the need of human empathy for their proper exercise. It includes some measures against opacity of algorithms to guarantee the right to good administration and specially its expressions as a right to understand public decisions. © 2019 Revista General de Derecho Administrativo. All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","","","50","2019","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LZ5ZRWW","conferencePaper","2019","Takano, M.; Tsunoda, T.","Self-disclosure of bullying experiences and social support in avatar communication: Analysis of verbal and nonverbal communications","Proceedings of the 13th International Conference on Web and Social Media, ICWSM 2019","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070376669&partnerID=40&md5=c4980b3e2f1fec8b0a980aab67deb0fa","Avatar communication through the Internet has great potential to be an appropriate environment for self-disclosure and social support. Anonymity and ease of access drive self-disclosure of even the most serious problems. Rich nonverbal communication, co-presence, and real-time interaction increase emotional closeness. However, there has not been much research with regard to examining social support in avatar communication. In this paper, we aim to facilitate self-disclosure and social support for bullied people through avatar communication. For this purpose, we analyzed verbal and nonverbal communication about bullying experiences through an avatar communication service. We demonstrate that people who emotionally disclosed their bullying experiences received better social support. In addition, people who provided social support used emotional expressions to convey emotional empathy. These were observed in conversations with a few acquaintances in closed spaces. Our findings reveal areas where we can improve upon the design of avatar communication spaces for effective social support. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","473-481","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHI9ZAIM","journalArticle","2019","Bhalla, N.","The 3S process: A framework for teaching AI strategy in business education","Technology Innovation Management Review","","","10.22215/timreview/1290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082424709&doi=10.22215%2ftimreview%2f1290&partnerID=40&md5=71f1e049ab206f1122d9f31a5dba4ee8","A gap has emerged in teaching artificial intelligence (AI) in business education, where a style of curriculum based on strategy is missing. This article presents a new framework, the 3S Process, as a method for teaching leaders how to strategically adopt AI within their organizations. At a high-level, the 3S Process consists of three stages (Story, Strategy, and Solution), which are described in detail in the article. Stage 1: Story in the process is inspired by the Harvard Case Method to provide context for a problem. Stage 2: Strategy uses Design Thinking to produce candidate solutions. The substage of Empathy in Design Thinking plays a crucial role to reduce bias in designing AI. Virtualization technology is a tool for students to experience hands-on learning in prototype development. Stage 3: Solution is where students advocate for their conceptual AI solution in the context of the case study. AI is a type of complex system; therefore, students should consider feedback loops and the potential for unintended biases to enter a deployed solution. The presentation of the 3S Process in this article is conceptual. Further empirical studies, including evaluations of the 3S Process in classroom settings, will be considered in the future. © 2019 Carleton University. All Rights Reserved.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","36-42","","12","9","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HY49NUYS","journalArticle","2019","Franzoni, V.; Milani, A.","Emotion Recognition for Self-aid in Addiction Treatment, Psychotherapy, and Nonviolent Communication","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-24296-1_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069166203&doi=10.1007%2f978-3-030-24296-1_32&partnerID=40&md5=9fd3cca43de6e1c5747776bab3c03cf0","This position paper aims to highlight possible future directions of applications for Affective Computing (AC) and Emotion Recognition (ER) for self-aid applications, as they emerge from the experience of the ACER-EMORE Workshops Series. ER in Artificial Intelligence offers a growing number of problem-solving multidisciplinary opportunities. Most current AC and ER applications are focused on a somewhat controversial enterprise-centered approach, i.e., recognizing user emotions to enable a third-party to achieve its own goals, in areas such as e-commerce, cybersecurity, behavior profiling, user experience. In this work we propose to explore a human-centered research direction, aiming at using AC/ER to enhance user consciousness of emotional states, ultimately supporting the development of self-aid applications. The use of facial ER and text ER to help forms of assistive technologies in the fields of Psychotherapy and Communication is an example of such a human-centered approach. A general framework for ER in Self-aid is depicted, and some relevant application domains are suggested and discussed: dependencies treatment (DT) (e.g., workaholism, sexaholism); non-violent communication (NVC) for people in leading roles using e-mail or chat communication; empathy learning for parents and teachers in the circle-of-security (COS) caring environment. Far from being complete and comprehensive, the purpose of this work is to trigger discussions and ideas for feasible studies and applications of ER in self-aid, which we hope to see published in the future editions of our workshops, believing that it may be one of the drops needed in the ocean of a better world. © 2019, Springer Nature Switzerland AG.","2019","2021-02-15 22:34:00","2021-02-15 22:34:00","","391-404","","","11620 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DS75ZP5V","journalArticle","2019","Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.","A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study","Journal of Medical Internet Research","","","10.2196/14658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2","Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.","2019","2021-02-15 22:34:01","2021-02-15 22:34:01","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"368532YI","journalArticle","2018","Weber, A.S.","Emerging medical ethical issues in healthcare and medical robotics","International Journal of Mechanical Engineering and Robotics Research","","","10.18178/ijmerr.7.6.604-607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056576175&doi=10.18178%2fijmerr.7.6.604-607&partnerID=40&md5=497839d4cdb779d178e34f97ca54283a","Due to the increasing sophistication and complexity of autonomous machines, Artificial Intelligence, Computerized Decision Support Systems (CDSS), natural language question-answering robots, and social / emotive medical robots, new medical ethics conundrums are arising. Unresolved questions revolve around autonomy, responsibility, empathy, trust, moral agency and the social and economic impacts of medical robots. © 2018 Int. J. Mech. Eng. Rob. Res.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","604-607","","6","7","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSMDWS93","journalArticle","2018","Inkster, B.; Sarda, S.; Subramanian, V.","An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study","JMIR mHealth and uHealth","","","10.2196/12106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f","Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","","","11","6","","","","","","","","","","","","","","","","","","<p>cited By 58</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4X7J8ZW","journalArticle","2018","Yalcin, O.N.; Dipaola, S.","A computational model of empathy for interactive agents","Biologically Inspired Cognitive Architectures","","","10.1016/j.bica.2018.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050357957&doi=10.1016%2fj.bica.2018.07.010&partnerID=40&md5=6cb0808ca3ac7e67ad477c8fee67392d","Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents. © 2018 Elsevier B.V. All rights reserved.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","20-25","","","26","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHZS93I8","journalArticle","2018","Johnston, S.C.","Anticipating and Training the Physician of the Future: The Importance of Caring in an Age of Artificial Intelligence","Academic medicine : journal of the Association of American Medical Colleges","","","10.1097/ACM.0000000000002175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050403831&doi=10.1097%2fACM.0000000000002175&partnerID=40&md5=ba7c843dd7d3e8f51b8914002c463db1","Artificial intelligence and other forms of information technology are only just beginning to change the practice of medicine. The pace of change is expected to accelerate as tools improve and as demands for analyzing a rapidly growing body of knowledge and array of data increase. The medical students of today will practice in a world where information technology is sophisticated and omnipresent. In this world, the tasks of memorization and analysis will be less important to them as practicing physicians. On the other hand, the nonanalytical, humanistic aspects of medicine-most importantly, the art of caring-will remain a critical function of the physician, and facility with improving systems of care will be required. Communication, empathy, shared decision making, leadership, team building, and creativity are all skills that will continue to gain importance for physicians. These skills should be further prioritized in medical school curricula to produce an even more effective physician for the future.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","1105-1106","","8","93","","","","","","","","","","","","","","","","","","<p>cited By 18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXBXX8PN","conferencePaper","2018","Y Restrepo, E.G.; Boticario, J.G.","Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future","2017 International Conference on Engineering, Technology and Innovation: Engineering, Technology and Innovation Management Beyond 2020: New Challenges, New Approaches, ICE/ITMC 2017 - Proceedings","","","10.1109/ICE.2017.8280067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047627034&doi=10.1109%2fICE.2017.8280067&partnerID=40&md5=dcfa25236d464d9783d4a9c0c7675df2","This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society. © 2017 IEEE.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","1552-1558","","","2018-January","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F7HFMQPT","conferencePaper","2018","Kouzov, O.","Art, social and culture education supported by artificial intelligence tools","Digital Presentation and Preservation of Cultural and Scientific Heritage","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063348999&partnerID=40&md5=4ee842958b24c16cf7fad0f082796b2c","The use of tools, based on AI, will become a regular practice in education due to the dynamic social development. The role of the artificial intelligence in social sciences, arts and culture is key to the achievement of emotional empathy of people in view of the future symbiosis of man and machine. © 2018 Digital Presentation and Preservation of Cultural and Scientific Heritage.All Rights Reserved.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","111-119","","","8","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I62ICQN8","journalArticle","2018","Kolonin, A.","Resource-constrained social evidence based cognitive model for empathy-driven artificial intelligence","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-97676-1_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051425417&doi=10.1007%2f978-3-319-97676-1_10&partnerID=40&md5=10c85a843431a41274b2e5042aaa682a","Working model of social aspects of human and non-human intelligence is required for social embodiment of artificial general intelligence systems to explain, predict and manage behavioral patterns in multi-agent communities. For this purpose, we propose implementation of resource-constrained social evidence based model and discuss possible implications of its application. © 2018, Springer Nature Switzerland AG.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","100-108","","","10999 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W78X3X2D","journalArticle","2018","Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.","Approaches for generating empathy: A systematic mapping","Advances in Intelligent Systems and Computing","","","10.1007/978-3-319-54978-1_89","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f","Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","715-722","","","558","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X94CZTTJ","conferencePaper","2018","Jaidka, K.; Guntuku, S.C.; Ungar, L.H.","Facebook versus twitter: Cross-platform differences in self-disclosure and trait prediction","12th International AAAI Conference on Web and Social Media, ICWSM 2018","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050628739&partnerID=40&md5=056ed358ec0669149b0e51c0ffbec73d","This study compares self-disclosure on Facebook and Twitter through the lens of demographic and psychological traits. Predictive evaluation reveals that language models trained on Facebook posts are more accurate at predicting age, gender, stress, and empathy than those trained on Twitter posts. Qualitative analyses of the underlying linguistic and demographic differences reveal that users are significantly more likely to disclose information about their family, personal concerns, and emotions and provide a more 'honest' self-representation on Facebook. On the other hand, the same users significantly preferred to disclose their needs, drives, and ambitions on Twitter. The higher predictive performance of Facebook is also partly due to the greater volume of language on Facebook than Twitter - Facebook and Twitter are equally good at predicting user traits when the same-sized language samples are used to train language models. We explore the implications of these differences in cross-platform user trait prediction. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","141-150","","","","","","","","","","","","","","","","","","","","","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4C5FKSCZ","journalArticle","2018","Tory Toole, J.; Kurian, P.; Craddock, T.J.A.","Coherent energy transfer and the potential implications for consciousness","Journal of Cognitive Science","","","10.17791/jcs.2018.19.2.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050143668&doi=10.17791%2fjcs.2018.19.2.115&partnerID=40&md5=ceeeecd1e033f898418e72908f6fc7cc","The argument that biological systems are too ""warm and wet"" to support quantum effects is becoming increasingly antiquated as research in the field of quantum biology progresses. In fact, not only is it becoming apparent that quantum processes may regularly take place in biological systems, but these processes may underlie the mechanisms of consciousness and propel our models of conceptualizing the human brain into the next era of scientific understanding. The phenomena of consciousness have allured scientists and philosophers for thousands of years, while a precise technical understanding has remained elusive. If possible, developing this understanding will likely be one of humanity's greatest achievements. Knowing the fundamental processes that create conscious experience has far-reaching implications, from the potential birth of true artificial intelligence to a better understanding of mental health disorder etiologies and treatments. One major challenge in the mental health professions, and, ultimately, in empathy of any kind, is being able to see from and appreciate another person's unique, subjective experience. Discoveries in the field of consciousness could help bridge this gap. © 2018 Institute for Cognitive Science, Seoul National University.","2018","2021-02-15 22:34:01","2021-02-15 22:34:01","","115-124","","2","19","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BS7FKYM","journalArticle","2017","Moritz, J.","Augmented humanity","Technoetic Arts","","","10.1386/tear.15.3.341_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042419209&doi=10.1386%2ftear.15.3.341_1&partnerID=40&md5=6a9d2d151fb5d856a706e0b47ec99161","Augmented Reality (AR) is commonly defined as a digital layer of information viewed on top of the physical world through a smartphone, tablet or eyewear. Increasingly, this understanding of AR is shifting to a dynamic framework of 'smart things', including wearable technology, sensors and artificial intelligence (AI), with the ability to intercede in key moments and to deliver contextual and meaningful experiences. The things that come into context are the logical next steps in an evolutionary development towards computers that are better able to show empathy in relation to people: even more human-oriented, anticipative and ubiquitous. Thus, this outsourcing of meaning to empathic technologies points to one of the fundamental questions concerning the relation of human and technology - the nature of the trust that users place in technology. © 2017 Intellect Ltd.","2017","2021-02-15 22:34:01","2021-02-15 22:34:01","","341-352","","3","15","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TDEPVMTR","conferencePaper","2017","Abdul-Mageed, M.; Buffone, A.; Peng, H.; Giorgi, S.; Eichstaedt, J.; Ungar, L.","Recognizing pathogenic empathy in social media","Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453209&partnerID=40&md5=7649bbca2c296ce3a22690e6454b92c3","Empathy is an integral part of human social life, as people care about and for others who experience adversity. However, a specific ""pathogenic"" form of empathy, marked by automatic contagion of negative emotions, can lead to stress and burnout. This is particularly detrimental for individuals in caregiving professions who experience empathic states more frequently, because it can result in illness and high costs for health systems. Automatically recognizing pathogenic empathy from text is potentially valuable to identify at-risk individuals and monitor burnout risk in caregiving populations. We build a model to predict this type of empathy from social media language on a data set we collected of users' Facebook posts and their answers to a new questionnaire measuring empathy. We obtain promising results in identifying individuals' empathetic states from their social media (Pearson r = 0.252, p < 0.003). © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2017","2021-02-15 22:34:01","2021-02-15 22:34:01","","448-451","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPZWESIA","journalArticle","2017","Boella, L.","How to do the best without emotions?","Notizie di Politeia","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031102019&partnerID=40&md5=02472ddee9b8e3ba675d6a7b498143df","From the richness of Harris' consideration of the main aspects of the contemporary debate - the nature of good, the question of the ""human"", post-human and of non-human animals, of freedom as being master of our lives, of Artificial Intelligence - I draw out the building block of the morality as ""trying to be good"". To be a good person implies insight, sympathy, empathy, understanding and knowledge to build clear ideas of what might conduce to the good.","2017","2021-02-15 22:34:01","2021-02-15 22:34:01","","184-186","","127","33","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZMUPFAB","conferencePaper","2016","Liu, X.; London, K.","T.A.I: A tangible AI interface to enhance human-artificial intelligence (AI) communication beyond the screen","DIS 2016 - Proceedings of the 2016 ACM Conference on Designing Interactive Systems: Fuse","","","10.1145/2901790.2901896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978646804&doi=10.1145%2f2901790.2901896&partnerID=40&md5=0872ed99d2fa2b941be3307017eb6085","Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","281-285","","","","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2UVRBUV","conferencePaper","2016","Headleand, C.J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L.A.","Does the Perceived Identity of Non-player Characters Change How We Interact with Them?","Proceedings - 2015 International Conference on Cyberworlds, CW 2015","","","10.1109/CW.2015.35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964255469&doi=10.1109%2fCW.2015.35&partnerID=40&md5=0e24ff4477d953ab395db33157d255bf","Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it. © 2015 IEEE.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","145-152","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4YQY6NYT","conferencePaper","2016","Kido, T.; Swan, M.","Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51","Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","362-368","","","SS-16-01 - 07","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWE9PAAU","journalArticle","2016","Mototake, Y.-I.; Fukuda, H.; Ueda, K.","Creating an in-group relation between humans and agents","Transactions of the Japanese Society for Artificial Intelligence","","","10.1527/tjsai.AI30-J","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994593462&doi=10.1527%2ftjsai.AI30-J&partnerID=40&md5=e45a827b07fe39236bdc7097263cb4cc","The purpose answer the question whether an artificial agent can build or not an in-group relation with a human. To answer this, we created a three-way discussion setting between a participant and two artificial agents: One agent took the same opinion as a participant while the other did the opposite. This resulted in a feeling of group identity between the participant and the first agent, i.e. the same side. This feeling of group identity was shown to be detected using error-related negativity (ERN), a component of an event-related potential that accompanies errors in speeded performance. We found that amplitude of ERN was bigger for the same side agent’s failure than for the other side’s. We also found ERN difference correlated to an empathy ability detected by a questionnaire. From these results, we can say that a person can form an in-group relation between an artificial agent, which can be detected by ERN. © 2016, Japanese Society for Artificial Intelligence. All rights reserved.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","","","6","31","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I4P8FQRC","journalArticle","2016","Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.","Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents","Transactions of the Japanese Society for Artificial Intelligence","","","10.1527/tjsai.C-G31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a","There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","","","4","31","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7IQBZ76","conferencePaper","2016","Lok, B.","Training with virtual operating room teammates to influence team behaviors","Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016","","","10.1109/CTS.2016.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016990802&doi=10.1109%2fCTS.2016.115&partnerID=40&md5=43b8f2a891be99dc9798e92fe575cfde","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care? In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room. We will examine the latest research into simulating healthcare teams with mixed reality humans. Mixed reality humans are virtual humans that can share the same physical space as the user. These virtual humans combine interactive graphics, natural language processing, artificial intelligence, human-computer interaction, and data mining to create in situ learning experiences. In these learning experiences, critical care personnel can work to improve teamwork with life-sized interactive virtual team-mates [1]. These learning experiences can also help implement best-practices to address address difficult teamwork concepts such as authority gradients, conflict negotiation, empathy and critical thinking [2][3]. Our research team (Samsun Lampotang, Anesthesia Department, University of Florida, Adam Wendling, Anesthesia Department, University of Florida, and Casey White, College of Medicine, University of Virginia) has developed VR hardware and software platforms to create compelling experiences for users to work on teams with mixed reality humans (MRHs). MRHs are virtual humans that can inhabit the user's physical space [4]. The MRH virtual team members can respond to the user's speech and actions and respond with natural speech and gestures. The virtual team members cannot physically interact with the environment. However, they can present realistic personalities and role-play the roles of operating room teammates, such as surgeons, anesthesiologists, nurses, and surgical technicians. The virtual team members combine the benefits of dynamic visuals of virtual humans with the physicality of mannequins (Figure 1). (Figure Presented) The virtual teammates are composed of comprise a minitower desktop for computation, networking, and rendering, a 40′ TV for display, and a Microsoft Kinect® (version 2) for tracking. All of these components are mounted onto a TV stand. Additionally, a Sennheiser DW-Pro 1 wireless headset is used for speech capture. ANDI's torso, arms, and head are rendered using a virtual human model from Autodesk's Character Generator. The virtual teammate's legs were physical and were composed of shoes and pants filled with stuffing. The physical props were used to integrate the virtual teammate into the user's space. A series of studies evaluated the social presence impact of ANDI design decisions and the current system configuration was shown to provide a virtual teammate with which participants reported a high sense of presence [5]. The virtual teammates' audio responses are pre-recorded by voice talent, and gestures are generated using motion capture and professionally key-framed animations. The virtual teammates can gaze at whoever is speaking, and intermittently glance at the other team members. They also blink and mimic idle motions when not speaking. We will examine results from studies evaluating the perception of virtual teammates, lessons learned in integrating such systems into hospital training, and areas for future research. © 2016 IEEE.","2016","2021-02-15 22:34:01","2021-02-15 22:34:01","","615-616","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SM73UZ9B","journalArticle","2015","Vallverdú, J.; Casacuberta, D.","Ethical and technical aspects of emotions to create empathy in medical machines","Intelligent Systems, Control and Automation: Science and Engineering","","","10.1007/978-3-319-08108-3_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e","This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:34:02","2021-02-15 22:34:02","","341-362","","","74","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLIHZWYJ","journalArticle","2015","Ceschi, A.; Scalco, A.; Dickert, S.; Sartori, R.","Compassion and prosocial behavior. Is it possible to simulate them virtually?","Advances in Intelligent Systems and Computing","","","10.1007/978-3-319-19629-9_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946410442&doi=10.1007%2f978-3-319-19629-9_23&partnerID=40&md5=1d820a863bf587f7f0f85fe86d00561e","In the field of artificial intelligence, a question dealing with computer and cognitive science is arising and becoming more and more crucial: Can we design agents so sophisticated that they are capable of mimicking emotional behaviors in general as well as specific emotions like compassion or empathy? Despite the production of different computational models, their integration with cognitive and psychological theories remains a central problem. Reasons are both methodological and theoretical. Primarily, it is difficult to quantify the impact of such factors as individual differences, inclinations and personality traits. In addition, Agent-Based Models (ABMs) often use linear dynamics, even in describing emotions, without considering the basis of psychophysics. Bearing in mind this and focusing on compassion as a particular emotion, the paper aims to present a “Decalogue” for those interested in designing agents capable of mimicking human emotional behaviors. In the paper, compassion will be translated as prosocial behavior. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:34:02","2021-02-15 22:34:02","","207-214","","","372","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EIQDB4F","journalArticle","2015","Gil, P.; Rossi, C.; Coral, W.","Biophilic evolutionary buildings that restore the experience of animality in the city","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-22979-9_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947104679&doi=10.1007%2f978-3-319-22979-9_47&partnerID=40&md5=906ff7465fc2103a0556f85aed9a7a97","In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible –or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa¸cade that learns optimal configurations according to the perception of aggressiveness and calmness. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:34:02","2021-02-15 22:34:02","","465-472","","","9222","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E86CUKZ2","conferencePaper","2014","Tasse, D.; Hong, J.","Finding a city's activity bubbles in geotagged social media","AAAI Workshop - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974839179&partnerID=40&md5=3e5a9de773f53deb957cb6edd66ebbb1","Bill Bishop popularized the idea that we all live in a self-curated world of bubbles in his book, ""The Big Sort"" (Bishop 2009). People often spend most of their time in completely different places from their neighbors, and this fragmentation of society leads to reduced empathy, policy quarrels, and even violence. People may not even be aware that they are segregating themselves so dramatically. Fortunately, thanks to the abundance of available geotagged social media data, we can easily and cheaply detect these social bubbles and give people a greater insight into their activity patterns. Understanding how we spend our time can be the first step in changing from isolated citizens into a connected community. © Copyright 2014. Association for the Advancement of Artificial Intelligence (www.aaai.org).All rights reserved.","2014","2021-02-15 22:34:02","2021-02-15 22:34:02","","33-34","","","WS-14-20","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVAY9BYE","conferencePaper","2014","Rzepka, R.; Araki, K.","Experience of crowds as a guarantee for safe artificial self","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904869125&partnerID=40&md5=8fd797ff6e2f229cb3b785a938a3df20","In this paper we introduce an approach for achieving a self that is able to simulate average ethical intuitions by retrieving knowledge about human behavior from the Internet resources. We show how applying text mining techniques could be useful for virtual and physical agents which base their knowledge on natural language. We discuss the importance of empathy and pros and cons of crowd experience based algorithm, then we introduce our thoughts on possibility of manufacturing agents for particular purposes as behavior analyzers or moral advisors which could refer to millions of different experiences had by people in various cultures. We think such systems could lead to selves that are capable to non-biased decisions morally superior to these of average human. Copyright © 2014, Association for the Advancement of Artificial Intelligence. All rights reserved.","2014","2021-02-15 22:34:02","2021-02-15 22:34:02","","40-44","","","SS-14-03","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVMX9VX3","conferencePaper","2014","Majot, A.M.; Yampolskiy, R.V.","AI safety engineering through introduction of self-reference into felicific calculus via artificial pain and pleasure","2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, ETHICS 2014","","","10.1109/ETHICS.2014.6893398","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929249460&doi=10.1109%2fETHICS.2014.6893398&partnerID=40&md5=394f38624e7a494b0cae76589c4ef386","In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of ""moral mathematics"" felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed. © 2014 IEEE.","2014","2021-02-15 22:34:02","2021-02-15 22:34:02","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5THALCUF","conferencePaper","2013","Kido, T.; Swan, M.","Exploring the mind with the aid of personal genome - Citizen science genetics to promote positive weil-being","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883338761&partnerID=40&md5=faa8ca187f27af10799d276c75cfc596","Understanding the human mind and increasing individual happiness are important goals in Artificial Intelligence (AI) and well-being science. The recent revolution in portable self-tracking devices in the data-driven wellness movement and participatory-driven wellness communities, such as the Quantified Self community, provides us with new opportunities to collect psychological or physiological data for understanding the human mind. While new technologies make it possible to track our daily behavior and various biological signals such as physiological or genetic data more easily, one of the important remaining challenges is to discover our own truly meaningful personal values. Citizen science, scientific research by crowdsourcing or human-based computation, is a new and challenging framework that promotes interdisciplinary research in the fields of computer science, life/brain science, and social psychological/ behavioral science, which may introduce new paradigms to the AI community. We have been working on citizen science projects related to the area of personal genomics and have developed a personal genomics information environment named MyFinder. The developed platform supports the search for our inherited talents and maximizes our potential for a meaningful life. In particular, we are interested in the human mind and the personal genome. In this paper, we introduce our MyFinder Project and present the results of a recent study on ""social intelligence genomics and empathy building"", and discuss issues involved in exploring our mind within the context of personal genomics. Copyright © 2013 Association for the Advancement of Artificial Intelligence.","2013","2021-02-15 22:34:02","2021-02-15 22:34:02","","12-17","","","SS-13-03","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J5QDAA6E","journalArticle","2013","Kile, F.","Artificial intelligence and society: A furtive transformation","AI and Society","","","10.1007/s00146-012-0396-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873145024&doi=10.1007%2fs00146-012-0396-0&partnerID=40&md5=4ad4d8b9e4c078e460a94d6e29ca7896","During the 1950s, there was a burst of enthusiasm about whether artificial intelligence might surpass human intelligence. Since then, technology has changed society so dramatically that the focus of study has shifted toward society's ability to adapt to technological change. Technology and rapid communications weaken the capacity of society to integrate into the broader social structure those people who have had little or no access to education. (Most of the recent use of communications by the excluded has been disruptive, not integrative.) Interweaving of socioeconomic activity and large-scale systems had a dehumanizing effect on people excluded from social participation by these trends. Jobs vanish at an accelerating rate. Marketing creates demand for goods which stress the global environment, even while the global environment no longer yields readily accessible resources. Mining and petroleum firms push into ever more challenging environments (e. g., deep mines and seabed mining) to meet resource demands. These activities are expensive, and resource prices rise rapidly, further excluding groups that cannot pay for these resources. The impact of large-scale systems on society leads to mass idleness, with the accompanying threat of violent reaction as unemployed masses seek to blame both people in power as well as the broader social structure for their plight. Perhaps, the impact of large-scale systems on society has already eroded essential qualities of humanness. Humans, when they feel ""socially useless,"" are dehumanized. (At the same time, machines (at any scale) seem incapable of emotion or empathy.) Has the cost of technological progress been too high to pay? These issues are addressed in this paper. © 2012 Springer-Verlag London Limited.","2013","2021-02-15 22:34:02","2021-02-15 22:34:02","","107-115","","1","28","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUAZ8M3T","journalArticle","2012","Coronato, A.; De Pietro, G.","Detection of motion disorders of patients with autism spectrum disorders","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-35395-6_56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870956015&doi=10.1007%2f978-3-642-35395-6_56&partnerID=40&md5=81b35f0220892de5cae29a9e80af4fe3","The autistic spectrum disorders (ASD) are behaviorally-defined developmental disorders of the immature brain which affect three domains of behavior: sociability and empathy; communication, language and imagination; and mental flexibility and range of interests. Main symptoms include motion disorders and stereotyped behaviors. This paper presents an approach based on Artificial Intelligence techniques and Ambient Intelligence technologies for the detection of stereotyped motion disorders of patients with ASD. Specifically, monitoring is realized by means of tri-axis accelerometers applied to the patient's wrists. Signals obtained by accelerometers are pre-processed to obtain features that, in turn, are passed to classifiers that classifies the current observation in order to detect stereotyped motions. Results are under validation at the Department of Child Psychiatry at Children's Hospital Santobono-Pausilipon in Naples. © 2012 Springer-Verlag.","2012","2021-02-15 22:34:02","2021-02-15 22:34:02","","415-422","","","7657 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A783KSMV","conferencePaper","2012","Kanai, R.","Brain structure and individual differences in social behaviors","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865016334&partnerID=40&md5=afa9d1ce5a52c454a1d658998348810f","Brain structure exhibits systematic relationships with a variety of an individual's cognitive abilities and such relationships can be captured by voxel-based morphometry (VBM) that computes regional gray matter volume based on anatomical MRIs. This method has been successfully used to reveal brain regions that are associated with individual differences in a broad range of contexts such as perceptual performance, attention control, face recognition, introspection and personality traits (Kanai & Rees 2011). Here, we show that such relationships with brain structure extend to complex social behaviors by presenting our recent VBM studies that examined the relationships between brain structure and diverse aspects of socio-cognitive behavioral traits. Specifically, we identified brain regions in which individual differences in gray matter volumes were associated with political orientation, moral sentiment, empathy and loneliness. These findings suggest that information derived from standard MRI scans could be used to extract information about an individual's real-world and online social behavior. Unlike conventional functional neuroimaging research, our structural neuroimaging approach does not require a virtual environment that emulates social interactions and thus can directly link brain structure to real-world human behavior. As such, our approach based on individual differences in brain structure and behavior provides an important anchor point that integrates genetic and environmental factors determining diversity of human cognition and behavior. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.","2012","2021-02-15 22:34:02","2021-02-15 22:34:02","","24-25","","","SS-12-05","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EV2CVZFC","conferencePaper","2011","Green, N.L.; Stadler, B.; Kimbrough, J.","Adding affective argumentation to the GenIE assistant","AAAI Workshop - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054905660&partnerID=40&md5=54c17dc65a39c8f3a755c41b930970c8","This paper presents preliminary results of an empirical study to investigate effects of adding affective argumentation to the GenIE Assistant, an implemented proof-of-concept computational model of normative biomedical argument generation. The Assistant has been implemented in the domain of genetic counseling, a domain where human writers are advised to show empathy in addition to presenting clinical arguments for the diagnosis and source of a patient's condition. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.","2011","2021-02-15 22:34:02","2021-02-15 22:34:02","","16-19","","","WS-11-10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRDZA8B5","conferencePaper","2010","Duhaut, D.","A way to put empathy in a Robot","Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866108268&partnerID=40&md5=b7aefa120587dbd4e227a2ab51730e20","A report on the experiments carried out with our robot in the Emotirob project is given in this paper, in which we show how we build emotion and personality in the robot. With children, the results of interaction with the robot are quite satisfactory in a short-term experiment. However, it was noted that during long-term interaction between the children and the robot, the relationship changes as a kind of lassitude sets up. Thus, the question addressed here is, how can we make a robot acceptable for long-term interaction? We propose to explain why empathy is a part of the solution and what the key points are for artificial intelligence to solve this new problem.","2010","2021-02-15 22:34:02","2021-02-15 22:34:02","","549-554","","","2","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S2XEK9TK","journalArticle","2021","Chang, W.; Wang, H.; Yan, G.; Lu, Z.; Liu, C.; Hua, C.","EEG based functional connectivity analysis of human pain empathy towards humans and robots","Neuropsychologia","","","10.1016/j.neuropsychologia.2020.107695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097757961&doi=10.1016%2fj.neuropsychologia.2020.107695&partnerID=40&md5=95c990a62e5739f884d45547193f3cab","Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots. © 2020 Elsevier Ltd","2021","2021-02-15 22:35:16","2021-02-15 22:35:16","","","","","151","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2MGPPE5","journalArticle","2020","Wales, J.J.","Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots","Frontiers in Artificial Intelligence and Applications","","","10.3233/FAIA200906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65","According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.","2020","2021-02-15 22:35:16","2021-02-15 22:35:16","","114-124","","","335","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4T36ILIF","journalArticle","2020","Malinowska, J.K.","The Growing Need for Reliable Conceptual Analysis in HRI Studies: The Example of the Term 'Empathy'","Frontiers in Artificial Intelligence and Applications","","","10.3233/FAIA200904","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098855262&doi=10.3233%2fFAIA200904&partnerID=40&md5=212a39f56d6ab3af3994b8e30aee16c6","Due to its interdisciplinary nature, the field of HRI uses many concepts typical of the social sciences and humanities, in addition to terms that are usually associated with technology. In this paper, I analyse the problems that arise when we use the term âempathy' to describe and explain the interaction between robots and humans. I argue that this not only raises questions about the possibility of applying this term in situations in which only one of the participants of the interaction is a traditionally understood social subject but also requires answers to questions about such problematic concepts as values and culture. © 2020 The authors and IOS Press. All rights reserved.","2020","2021-02-15 22:35:16","2021-02-15 22:35:16","","96-104","","","335","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2DHJR4U","journalArticle","2020","Schmetkamp, S.","Understanding A.I. — Can and Should we Empathize with Robots?","Review of Philosophy and Psychology","","","10.1007/s13164-020-00473-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083955575&doi=10.1007%2fs13164-020-00473-x&partnerID=40&md5=8c5a1a9139fa546337a1ecdeea7e1f49","Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding. © 2020, Springer Nature B.V.","2020","2021-02-15 22:35:16","2021-02-15 22:35:16","","881-897","","4","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICK3UPDK","journalArticle","2020","Konijn, E.A.; Hoorn, J.F.","Differential facial articulacy in robots and humans elicit different levels of responsiveness, empathy, and projected feelings","Robotics","","","10.3390/robotics9040092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096119375&doi=10.3390%2frobotics9040092&partnerID=40&md5=16358e35deb385522e159e206aa5199e","Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot’s face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot’s face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) × 2 (treatment: affectionate vs. maltreated). Participants (N = 265; Mage = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of ‘because I feel, I believe it’s real,’ despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of ‘it is just a robot’ fades into the background and appears not relevant anymore. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-02-15 22:35:16","2021-02-15 22:35:16","","1-17","","4","9","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INAJJCKA","journalArticle","2020","Giannopulu, I.; Etournaud, A.; Terada, K.; Velonaki, M.; Watanabe, T.","Ordered interpersonal synchronisation in ASD children via robots","Scientific Reports","","","10.1038/s41598-020-74438-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092659030&doi=10.1038%2fs41598-020-74438-6&partnerID=40&md5=ba25cca4d93dfcc0d9b69aa2ee0148d5","Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping. © 2020, The Author(s).","2020","2021-02-15 22:35:16","2021-02-15 22:35:16","","","","1","10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAPE98PC","journalArticle","2020","Gramantieri, R.","Alexithymic personality in Philip K. Dick’s Do androids dream of electric sheep?","Neohelicon","","","10.1007/s11059-020-00544-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745112&doi=10.1007%2fs11059-020-00544-z&partnerID=40&md5=d7ae68506033a119722c578a57aa02bd","The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients’ comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novel Do androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commenting Do androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick. © 2020, Akadémiai Kiadó, Budapest, Hungary.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","673-683","","2","47","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHEYS5UH","journalArticle","2020","Bagheri, E.; Esteban, P.G.; Cao, H.-L.; Beir, A.D.; Lefeber, D.; Vanderborght, B.","An autonomous cognitive empathy model responsive to users' facial emotion expressions","ACM Transactions on Interactive Intelligent Systems","","","10.1145/3341198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097225306&doi=10.1145%2f3341198&partnerID=40&md5=6b3056773f580546273a9ec06bea4681","Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot. © 2020 ACM.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","3","10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYR4P2X5","conferencePaper","2020","Daher, K.; Casas, J.; Khaled, O.A.; Mugellini, E.","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020","","","10.1145/3383652.3423864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096965302&doi=10.1145%2f3383652.3423864&partnerID=40&md5=fe8b298b7d7e4ba7330d713c3261bfca","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12). © 2020 Owner/Author.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JGPCMWQ","conferencePaper","2020","Sonmez, E.B.; Kose, H.; Barkana, D.E.","Towards a New Computational Affective System for Personal Assistive Robots","2020 28th Signal Processing and Communications Applications Conference, SIU 2020 - Proceedings","","","10.1109/SIU49456.2020.9302238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100292356&doi=10.1109%2fSIU49456.2020.9302238&partnerID=40&md5=1c6d4cdda7d6442c842e9caac9ed4e0b","The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively. © 2020 IEEE.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LQ2P4BM","journalArticle","2020","Pepito, J.A.; Ito, H.; Betriana, F.; Tanioka, T.; Locsin, R.C.","Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations","Nursing Philosophy","","","10.1111/nup.12318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088269058&doi=10.1111%2fnup.12318&partnerID=40&md5=9764df20ca03d74991df8a514f7e7133","Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology. © 2020 John Wiley & Sons Ltd","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","4","21","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L344UH4D","conferencePaper","2020","Desolda, G.; Deufemia, V.; Gena, C.; Matera, M.; Paternò, F.; Treccani, B.","EMPATHY: Empowering People in Dealing with Internet of Things Ecosystems (Workshop)","ACM International Conference Proceeding Series","","","10.1145/3399715.3400870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093077722&doi=10.1145%2f3399715.3400870&partnerID=40&md5=355e1750764d9f345807dfcd6785474d","The Internet of Things is a pervasive technology widely adopted in several contexts ranging from smart homes to automotive cars. In this context, the End User Development is gaining momentum: different solutions support non-technical users to define the smart objects behavior to better satisfy their needs. This workshop aimed to stimulates participants in providing discussions in line with the workshop themes and goals, for example, user mental models, acceptance of EUD solutions, the role of AI in EUD tools, humanoid robots were discussed. © 2020 Owner/Author.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ2KQM77","journalArticle","2020","Sakurai, E.; Kurashige, K.; Tsuruta, S.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.; Frati, F.","Embodiment matters: toward culture-specific robotized counselling","Journal of Reliable Intelligent Environments","","","10.1007/s40860-020-00109-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087487620&doi=10.1007%2fs40860-020-00109-y&partnerID=40&md5=bbf9e8b747887c35e9498c0749840555","In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","129-139","","3","6","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N77XTZ4V","journalArticle","2020","Ivkov, M.; Blešić, I.; Dudić, B.; Bartáková, G.P.; Dudić, Z.","Are future professionals willing to implement service robots? Attitudes of hospitality and tourism students towards service robotization","Electronics (Switzerland)","","","10.3390/electronics9091442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093903132&doi=10.3390%2felectronics9091442&partnerID=40&md5=0042f4d6afbcca5932415c05a7c3f97f","This paper aims to examine attitudes of hospitality and tourism students, as future professionals, towards willingness to implement service robots. The study proposes a new theoretical conceptual model that includes new constructs and items, differentiating it from the others. The model was formed based on the extensive literature review and the interview with an eight-member focus group (hotel managers and academic researchers). Data collection was performed in two stages, pilot research based on 82 respondents and the main study, with the final number of respondents being 236. The initial results of the exploratory factor analysis were further tested using the confirmatory factor analysis. After the exclusion of several items due to low factor loadings and in order to improve model validity, analyses further suggested a nine-dimensional solution with 45 items. The study findings reveal a positive relationship between seven constructs and students’ willingness to implement service robots, with the expected business outcome being the most influencing one. On the other hand, positive relation was not found for empathy and social influence constructs. Theoretical contributions and practical implications are discussed in the paper. In conclusion, study limitations and future research suggestions are provided. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","1-16","","9","9","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GW2ZG3PP","conferencePaper","2020","Corretjer, M.G.; Ros, R.; Martin, F.; Miralles, D.","The Maze of Realizing Empathy with Social Robots","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","","","10.1109/RO-MAN47096.2020.9223466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095760531&doi=10.1109%2fRO-MAN47096.2020.9223466&partnerID=40&md5=0898316eb3582aa6430fa85f72edb83b","Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy. © 2020 IEEE.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","1334-1339","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LLGVU3Z","conferencePaper","2020","Ye, S.; Feigh, K.; Howard, A.","Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","","","10.1109/RO-MAN47096.2020.9223437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095735091&doi=10.1109%2fRO-MAN47096.2020.9223437&partnerID=40&md5=74bfb142371d9fab0e75afbaa05d3b0c","Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device. © 2020 IEEE.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","1186-1189","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ES5KW2P","conferencePaper","2020","Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.","Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","","","10.1109/RO-MAN47096.2020.9223442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095730396&doi=10.1109%2fRO-MAN47096.2020.9223442&partnerID=40&md5=ac2ec563cda67bf4704bb20f32ef0b07","In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction. © 2020 IEEE.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","653-658","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GR2AQ9XW","conferencePaper","2020","Perusquia-Hemandez, M.; Balda, M.C.; Gomez Jauregui, D.A.; Paez-Granados, D.; Dollack, F.; Salazar, J.V.","Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","","","10.1109/RO-MAN47096.2020.9223598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095745482&doi=10.1109%2fRO-MAN47096.2020.9223598&partnerID=40&md5=f2b4aa17536e3404041a17e644e85abf","Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization. © 2020 IEEE.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","1328-1333","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RCTSADAA","journalArticle","2020","de Kervenoael, R.; Hasan, R.; Schwob, A.; Goh, E.","Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots","Tourism Management","","","10.1016/j.tourman.2019.104042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075628508&doi=10.1016%2fj.tourman.2019.104042&partnerID=40&md5=f56ef158af2d44659553121590311519","Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies. © 2019 Elsevier Ltd","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","","78","","","","","","","","","","","","","","","","","","<p>cited By 18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72X8ATSE","journalArticle","2020","Rossi, S.; Conti, D.; Garramone, F.; Santangelo, G.; Staffa, M.; Varrasi, S.; Di Nuovo, A.","The role of personality factors and empathy in the acceptance and performance of a social robot for psychometric evaluations","Robotics","","","10.3390/ROBOTICS9020039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086668483&doi=10.3390%2fROBOTICS9020039&partnerID=40&md5=c2ec5388361d460022f6c3d10f29ebcb","Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the ""openness to experience"", on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests. © 2020 by the authors.","2020","2021-02-15 22:35:17","2021-02-15 22:35:17","","","","2","9","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55PK4C7S","conferencePaper","2020","Arnett, M.; Luo, Z.; Paladugula, P.K.; Cardenas, I.S.; Kim, J.-H.","Robots teaching recycling: Towards improving environmental literacy of children","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3371382.3379462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083168399&doi=10.1145%2f3371382.3379462&partnerID=40&md5=f2c5deecfbb5b7dbc8343530bb6d2c03","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle. © 2020 ACM.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","615-616","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTXRNVQS","conferencePaper","2020","Bhardwaj, P.; Joseph, C.V.; Shah, A.; Yadava, S.K.","Juno: An interactive storytelling robot for early constructive childhood intervention","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3371382.3379458","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083253085&doi=10.1145%2f3371382.3379458&partnerID=40&md5=a7d0171aec43f7ddceb928a2de07709c","Early life adversity is a major risk factor for the development of psychological and behavioral problems in adult life. Traumatic experiences in childhood are linked to higher rates of depression, anxiety disorders and a range of mental health issues.[4] Additionally, stories form the basis of understanding in children and help develop empathy and cultivate imaginative and divergent thinking in them. In this paper, we expound on the idea of leveraging the potential of storytelling through an interactive toy i.e. transitional object as a means of intentful intervention to help children understand and cope better with stressors in developmental ages. © 2020 ACM.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","617-618","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MME7VL5C","conferencePaper","2020","Connolly, J.; Mocz, V.; Salomons, N.; Valdez, J.; Tsoi, N.; Scassellati, B.; Vazquez, M.","Prompting prosocial human interventions in response to robot mistreatment","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3319502.3374781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082005598&doi=10.1145%2f3319502.3374781&partnerID=40&md5=5ca37572e421853f75ed741b638c5e9a","Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 betweensubjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI. © 2020 Association for Computing Machinery.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","211-220","","","","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4E9Q4MQ","journalArticle","2020","McBride, N.","Robot Enhanced Therapy for Autistic Children: An Ethical Analysis","IEEE Technology and Society Magazine","","","10.1109/MTS.2020.2967493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082031020&doi=10.1109%2fMTS.2020.2967493&partnerID=40&md5=7ee555189c1a7a2bf1f6ae1bc24dce07","The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in <italic>IEEE Technology and Society Magazine</italic>, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions. © 1982-2012 IEEE.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","51-60","","1","39","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLDCYDG7","journalArticle","2020","Björling, E.A.; Thomas, K.; Rose, E.J.; Cakmak, M.","Exploring Teens as Robot Operators, Users and Witnesses in the Wild","Frontiers in Robotics and AI","","","10.3389/frobt.2020.00005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081700133&doi=10.3389%2ffrobt.2020.00005&partnerID=40&md5=b3727eb4331051d6aa27b67a53ab255c","As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot. © Copyright © 2020 Björling, Thomas, Rose and Cakmak.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","","","","7","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6MB2U92P","journalArticle","2020","Bagheri, E.; Roesler, O.; Cao, H.-L.; Vanderborght, B.","A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots","International Journal of Social Robotics","","","10.1007/s12369-020-00683-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091144365&doi=10.1007%2fs12369-020-00683-4&partnerID=40&md5=f3b6bad671fdea58d1e7adfee9eb2754","Robots that express human’s social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better. © 2020, Springer Nature B.V.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YU9LKP23","journalArticle","2020","James, J.; Balamurali, B.T.; Watson, C.I.; MacDonald, B.","Empathetic Speech Synthesis and Testing for Healthcare Robots","International Journal of Social Robotics","","","10.1007/s12369-020-00691-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090755646&doi=10.1007%2fs12369-020-00691-4&partnerID=40&md5=e6d2fbb614c296ba7d803a31715e7357","One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot’s voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people’s acceptance of social robots. © 2020, Springer Nature B.V.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXM72SSP","journalArticle","2020","Trost, M.J.; Chrysilla, G.; Gold, J.I.; Matarić, M.","Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children","Pain Research and Management","","","10.1155/2020/7935215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083881603&doi=10.1155%2f2020%2f7935215&partnerID=40&md5=ea3dec2f225f6047f5a5282c0de25503","Objectives. Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods. We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot's empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with NCT02840942. Results. Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions. Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management. © 2020 Margaret J Trost et al.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","","","","2020","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTYJ3QW7","journalArticle","2020","Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.","Emotion Synchronization Method for Robot Facial Expression","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-49062-1_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20","Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","644-653","","","12182 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVFS7HWS","journalArticle","2020","Ho, J.C.F.; Ng, R.","Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion","Behaviour and Information Technology","","","10.1080/0144929X.2020.1864018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098553464&doi=10.1080%2f0144929X.2020.1864018&partnerID=40&md5=78bc6d559d259fece1c757b340b9b1ba","This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters–NPCs in a prosocial VR game–influences players’ in-game empathy towards NPCs and game immersion. Participants first experienced either a robot’s perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants’ game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players’ weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DB8D4YGF","conferencePaper","2020","Buono, P.; Castellano, G.; Decarolis, B.; MacChiarulo, N.","Social assistive robots in elderly care: Exploring the role of empathy","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094831887&partnerID=40&md5=9c71a17ac85c7fe16e8b3521eec02d0e","The COVID-19 emergency has shown that elderly people living in Assisted Living Houses (ALHs) have been highly exposed to the virus. Besides health problems, during the social distancing restrictions, the elderly were also strongly affected by loneliness due to a lack of contact with their loved ones. Innovative solutions for ALH based on Social Assistive Robotics can reduce the risk of infection and, at the same time, improve the quality of life of elderly people. In this work, after a brief overview on the Pepper4Elderly project, we focus on the role of empathy and affective behaviors in human-robot interaction when the robot is used as a caring agent to assist and entertain the elderly guests of ALHs. © 2020 CEUR-WS. All rights reserved.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","12-19","","","2702","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGA5ZMFC","conferencePaper","2020","Ito, K.; Murata, M.; Ohno, T.; Matsubara, S.","Relation between degree of empathy for narrative speech and type of responsive utterance in attentive listening","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512903&partnerID=40&md5=1ff80d168c8d91743e767819a0d7b887","Nowadays, spoken dialogue agents such as communication robots and smart speakers listen to narratives of humans. In order for such an agent to be recognized as a listener of narratives and convey the attitude of attentive listening, it is necessary to generate responsive utterances. Moreover, responsive utterances can express empathy to narratives and showing an appropriate degree of empathy to narratives is significant for enhancing speaker's motivation. The degree of empathy shown by responsive utterances is thought to depend on their type. However, the relation between responsive utterances and degrees of the empathy has not been explored yet. This paper describes the classification of responsive utterances based on the degree of empathy in order to explain that relation. In this research, responsive utterances are classified into five levels based on the effect of utterances and literature on attentive listening. Quantitative evaluations using 37,995 responsive utterances showed the appropriateness of the proposed classification. © European Language Resources Association (ELRA), licensed under CC-BY-NC","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","696-701","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5PHU38FM","journalArticle","2020","Perugia, G.; Paetzel, M.; Castellano, G.","On the Role of Personality and Empathy in Human-Human, Human-Agent, and Human-Robot Mimicry","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-62056-1_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097197855&doi=10.1007%2f978-3-030-62056-1_11&partnerID=40&md5=95f5dab4e658c63f6012ff6fc072f43a","Facial mimicry is crucial in social interactions as it communicates the intent to bond with another person. While human-human mimicry has been extensively studied, human-agent and human-robot mimicry have been addressed only recently, and the individual characteristics that affect them are still unknown. This paper explores whether the humanlikeness and embodiment of an agent affect human facial mimicry and which personality and empathy traits are related to facial mimicry of human and artificial agents. We exposed 46 participants to the six basic emotions displayed by a video-recorded human and three artificial agents (a physical robot, a video-recorded robot, and a virtual agent) differing in humanlikeness (humanlike, characterlike, and a morph between the two). We asked participants to recognize the facial expressions performed by each agent and measured their facial mimicry using automatic detection of facial action unit activation. Results showed that mimicry was affected by the agents’ embodiment, but not by their humanlikeness, and that it correlated both with individual traits denoting sociability and sympathy and with traits advantageous for emotion recognition. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","120-131","","","12483 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R64E9VLC","journalArticle","2020","Sejima, Y.; Sato, Y.; Watanabe, T.","Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact","Advances in Intelligent Systems and Computing","","","10.1007/978-3-030-20441-9_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b","Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:18","2021-02-15 22:35:18","","95-102","","","952","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q93WGLHK","journalArticle","2020","Hickton, L.; Lewis, M.; Cañamero, L.","Expression of Grounded Affect: How Much Emotion Can Arousal Convey?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-63486-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231","In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","234-248","","","12228 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XSFLKF5","journalArticle","2020","Chiang, A.-H.; Trimi, S.","Impacts of service robots on service quality","Service Business","","","10.1007/s11628-020-00423-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089085301&doi=10.1007%2fs11628-020-00423-8&partnerID=40&md5=845fde74db3c352ab9c164b287bcc23f","With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7T52K2WI","journalArticle","2020","Johanson, D.L.; Ahn, H.S.; Broadbent, E.","Improving Interactions with Healthcare Robots: A Review of Communication Behaviours in Social and Healthcare Contexts","International Journal of Social Robotics","","","10.1007/s12369-020-00719-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095992051&doi=10.1007%2fs12369-020-00719-9&partnerID=40&md5=f3f195ead2052764e3a972a247dbf24f","A growing shortfall exists between the number of older individuals who require healthcare support and the number of qualified healthcare professionals who can provide this. Robots offer the potential to provide healthcare support to patients both at home and in healthcare settings. However, in order for robots to be successfully implemented in these environments, they need to behave in ways that are appropriate and acceptable to human users. One way to identify appropriate social behaviours for healthcare robots is to model their behaviour on interactions between healthcare professionals and patients. This literature review aimed to inform healthcare robotics research by highlighting communication behaviours that are important within the context of healthcare. The review focussed on relevant research in human clinical interactions, followed by a review of similar factors in social robotics research. Three databases were searched for terms relating to healthcare professional communication behaviours associated with patient outcomes. The results identified key communication behaviours that can convey clinical empathy, including humour, self-disclosure, facial expressions, eye gaze, body posture, and gestures. A further search was conducted to identify research examining these key behaviours within the context of social and healthcare robotics. Research into these factors in human–robot interaction in healthcare is limited to date, and this review provides a useful guide for future research. © 2020, Springer Nature B.V.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2IDNUPI","journalArticle","2020","Chung, S.-E.; Ryoo, H.-Y.","Gesture design attribute and level value of social robot: A user experience based study","Journal of System and Management Sciences","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3","This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","108-121","","2","10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVYJ2WPT","journalArticle","2020","Küster, D.; Swiderska, A.","Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes","International Journal of Psychology","","","10.1002/ijop.12715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090926311&doi=10.1002%2fijop.12715&partnerID=40&md5=93cd342d1b06662a239ccc999e6dde9d","According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation. © 2020 The Authors. International Journal of Psychology published by John Wiley & Sons Ltd on behalf of International Union of Psychological Science.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JA9ZZ6WG","journalArticle","2020","Balistreri, M.; Casile, F.","Care Robots: From Tools of Care to Training Opportunities. Moral Considerations","Advances in Intelligent Systems and Computing","","","10.1007/978-3-030-23884-1_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068643881&doi=10.1007%2f978-3-030-23884-1_3&partnerID=40&md5=ddeacd68dcfb7fbd19f08f5b10213563","New technology should not perceived as a threat: on the contrary, it is a resource. It is our job to use it in the most appropriate way. Moreover, new technology can make a significant contribution to nurse training: for example, immersion into virtual reality with a visor and a simple application does not only allow one to experience fantastic adventures, but also to enjoy a relationship with the patient through simulation. Also, virtual reality can promote patient/teacher interaction: both, for example, can be projected or immersed in virtual reality, or the teacher can project his ‘virtual’ image into a real scenario. However, robots too could contribute to training nursing staff: health operator training courses today widely use dummies which are appropriately planned for standing training. They are increasingly true-to-life, favouring empathy with the clinical situation simulated each time and allowing the student to exercise not only technical abilities, but also critical thinking, the ability to work in a team and communication skills. We shall examine some moral questions linked to the increasingly frequent use of human-faceted robots to train nursing staff. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","18-25","","","1008","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JATUII48","journalArticle","2020","Andreotta, A.J.","The hard problem of AI rights","AI and Society","","","10.1007/s00146-020-00997-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085877284&doi=10.1007%2fs00146-020-00997-x&partnerID=40&md5=bd9018524171b9ac98aa2157ae1ac084","In the past few years, the subject of AI rights—the thesis that AIs, robots, and other artefacts (hereafter, simply ‘AIs’) ought to be included in the sphere of moral concern—has started to receive serious attention from scholars. In this paper, I argue that the AI rights research program is beset by an epistemic problem that threatens to impede its progress—namely, a lack of a solution to the ‘Hard Problem’ of consciousness: the problem of explaining why certain brain states give rise to experience. To motivate this claim, I consider three ways in which to ground AI rights—namely: superintelligence, empathy, and a capacity for consciousness. I argue that appeals to superintelligence and empathy are problematic, and that consciousness should be our central focus, as in the case of animal rights. However, I also argue that AI rights is disanalogous from animal rights in an important respect: animal rights can proceed without a solution to the ‘Hard Problem’ of consciousness. Not so with AI rights, I argue. There we cannot make the same kinds of assumptions that we do about animal consciousness, since we still do not understand why brain states give rise to conscious mental states in humans. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EERPITEC","journalArticle","2020","Bergen, J.P.","Love(rs) in the making: Moral subjectivity in the face of sexbots","Paladyn","","","10.1515/pjbr-2020-0016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088011901&doi=10.1515%2fpjbr-2020-0016&partnerID=40&md5=a1955bd5c3aa900399f2f1c1ffd6180d","This article offers a novel reading of the criticisms of sex robots put forward by the Campaign Against Sex Robots (CASR). Focusing on the implication of a loss of empathy, it structures CASR's worries as an argument from moral degradation centered around the potential effects on sexbot users' sexual and moral subjectivity. This argument is subsequently explored through the combined lenses of postphenomenology and the ethical phenomenology of Emmanuel Levinas. In so doing, it describes the type of human-technology relations that sexbots invite, identifying alterity as a central feature. It also highlights how alterity, responsibility, and subjectivity are intimately connected. However, that connection is distinctly different in sexual circumstances, making current versions of Levinasian roboethics largely inapplicable for the ethics of sexbots. To overcome this, the article delves into Levinas' phenomenology of Eros and identifies voluptuousness as a type of enjoyment of the Other that is different from the enjoyment invited by current sexbots and is compatible with responsibility. Based on this, the article provides examples of how this phenomenology of Eros can inspire the design of future sexbots in ways that alleviate some of CASR's concerns. © 2020 Jan Peter Bergen, published by De Gruyter 2020.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","284-300","","1","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5A5H4IXW","journalArticle","2020","Karpov, V.E.","Can a robot be a moral agent?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-59535-7_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092173472&doi=10.1007%2f978-3-030-59535-7_5&partnerID=40&md5=d8316768b923311d1b05807222c77b02","Issues of the ethically aligned design of intelligent/autonomous systems have now moved into the fields of normative and technical regulation. If a system must make ethically determined decisions, then it must be recognized as a moral agent. This paper provides a list of the properties of a moral agent and shows not only that an artificial agent can have such properties, but also that they are technically determined as manifestations of adaptive mechanisms. In particular, it is shown that mechanisms such as the presence of the “I” component in the sign-oriented picture of the agent’s world, the presence of an emotional-needs architecture, and the mechanism for comparing the observed conspecific with the “I” make it possible to realize the phenomena of social learning and a property such as empathy. © Springer Nature Switzerland AG 2020.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","61-70","","","12412 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLQLAX8I","journalArticle","2020","Rafique, M.; Hassan, M.A.; Jaleel, A.; Khalid, H.; Bano, G.","A Computation Model for Learning Programming and Emotional Intelligence","IEEE Access","","","10.1109/ACCESS.2020.3015533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091848953&doi=10.1109%2fACCESS.2020.3015533&partnerID=40&md5=184fadf767e187ea5ac11feef75422fd","Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface. © 2013 IEEE.","2020","2021-02-15 22:35:19","2021-02-15 22:35:19","","149616-149629","","","8","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZ4FPF5F","journalArticle","2019","Carlson, Z.; Lemmon, L.; Higgins, M.C.; Frank, D.; Salek Shahrezaie, R.; Feil-Seifer, D.","Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers","International Journal of Social Robotics","","","10.1007/s12369-019-00599-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074582945&doi=10.1007%2fs12369-019-00599-8&partnerID=40&md5=cda66cf87d85769abf9cea41a774b3cf","Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable. © 2019, The Author(s).","2019","2021-02-15 22:35:19","2021-02-15 22:35:19","","727-739","","5","11","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDDKQ8W7","journalArticle","2019","Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farnè, A.; Dominey, P.F.; Pavani, F.","Embodiment into a robot increases its acceptability","Scientific Reports","","","10.1038/s41598-019-46528-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069005120&doi=10.1038%2fs41598-019-46528-7&partnerID=40&md5=c7b84e03aa3b4bd20eb345fc595e7e4e","Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects’ head movements. As a result, participants saw themselves as a robot. When participant’ and robot’s head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots’ humanoid’s appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable. © 2019, The Author(s).","2019","2021-02-15 22:35:19","2021-02-15 22:35:19","","","","1","9","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YI9T738F","conferencePaper","2019","Esfandbod, A.; Rokhi, Z.; Taheri, A.; Alemi, M.; Meghdari, A.","Human-Robot Interaction based on Facial Expression Imitation","ICRoM 2019 - 7th International Conference on Robotics and Mechatronics","","","10.1109/ICRoM48714.2019.9071837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084358069&doi=10.1109%2fICRoM48714.2019.9071837&partnerID=40&md5=ae795b1eb257f51d3eebb251402352f6","Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database., which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants, viewpoints on the imitation capability of the robot of 4.1 out of 5. © 2019 IEEE.","2019","2021-02-15 22:35:19","2021-02-15 22:35:19","","69-73","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6UJ6DSB","conferencePaper","2019","Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019","","","10.1109/RITAPP.2019.8932852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","160-163","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTK53AIG","conferencePaper","2019","Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.","Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals","2019 28th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2019","","","10.1109/RO-MAN46459.2019.8956353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078837141&doi=10.1109%2fRO-MAN46459.2019.8956353&partnerID=40&md5=7d59754dade81e0ffa2bdbd5efe9a98a","Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDCLWG9X","journalArticle","2019","Johanson, D.L.; Ahn, H.S.; MacDonald, B.A.; Ahn, B.K.; Lim, J.; Hwang, E.; Sutherland, C.J.; Broadbent, E.","The effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction: Randomized controlled trial","Journal of Medical Internet Research","","","10.2196/13667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072908937&doi=10.2196%2f13667&partnerID=40&md5=244df67bd1698544f060020541459c91","Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings. © Deborah L Johanson, Ho Seok Ahn, Bruce A MacDonald, Byeong Kyu Ahn, JongYoon Lim, Euijun Hwang, Craig J Sutherland, Elizabeth Broadbent.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNG734GQ","conferencePaper","2019","Okanda, M.; Taniguchi, K.; Itakura, S.","The role of animism tendencies and empathy in adult evaluations of robot","HAI 2019 - Proceedings of the 7th International Conference on Human-Agent Interaction","","","10.1145/3349537.3351891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077124144&doi=10.1145%2f3349537.3351891&partnerID=40&md5=e9499c2611c38d3507959f62e604ef78","We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness. © 2019 ACM.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","51-58","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJEG36BW","journalArticle","2019","Rincon, J.A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.","A new emotional robot assistant that facilitates human interaction and persuasion","Knowledge and Information Systems","","","10.1007/s10115-018-1231-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049128718&doi=10.1007%2fs10115-018-1231-9&partnerID=40&md5=5c66a64dc9959c1533168f3b8df3e72e","The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare center in the northern area of Portugal. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","363-383","","1","60","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWH3JPP2","conferencePaper","2019","Costantini, S.; De Gasperis, G.; Migliarini, P.","Multi-agent system engineering for emphatic human-robot interaction","Proceedings - IEEE 2nd International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2019","","","10.1109/AIKE.2019.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071453043&doi=10.1109%2fAIKE.2019.00015&partnerID=40&md5=3f40048836bffb6e0cc5a9b52df01a87","Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","36-42","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSV5CART","conferencePaper","2019","Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.","Performance analysis of unimodal and multimodal models in valence-based empathy recognition","Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019","","","10.1109/FG.2019.8756517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070455625&doi=10.1109%2fFG.2019.8756517&partnerID=40&md5=cf50721db883d29dc85761df97f9ee76","The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, humanrobot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWKTAUA8","journalArticle","2019","Cross, E.S.; Riddoch, K.A.; Pratts, J.; Titone, S.; Chaudhury, B.; Hortensius, R.","A neurocognitive investigation of the impact of socializing with a robot on empathy for pain","Philosophical Transactions of the Royal Society B: Biological Sciences","","","10.1098/rstb.2018.0034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062693788&doi=10.1098%2frstb.2018.0034&partnerID=40&md5=2571e9a19730d18d3a12e4bda31d9487","To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'. © 2019 The Author(s) Published by the Royal Society. All rights reserved.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","1771","374","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KRKNFPU","conferencePaper","2019","Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.","Ideal warrior and robot relations: Stress and empathy's role in human-robot teaming","2019 Systems and Information Engineering Design Symposium, SIEDS 2019","","","10.1109/SIEDS.2019.8735613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068571842&doi=10.1109%2fSIEDS.2019.8735613&partnerID=40&md5=ccc21f2fe0c8fc29e283088fe64aa7f2","The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IZN6GK9","conferencePaper","2019","Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.","The RoPE Scale: A Measure of How Empathic a Robot is Perceived","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1109/HRI.2019.8673082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063988065&doi=10.1109%2fHRI.2019.8673082&partnerID=40&md5=bb92abeea2fde8a7291997b624203491","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","656-657","","","2019-March","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6I7YLZCR","conferencePaper","2019","Sanoubari, E.; Seo, S.H.; Garcha, D.; Young, J.E.; Loureiro-Rodriguez, V.","Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1109/HRI.2019.8673326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064013532&doi=10.1109%2fHRI.2019.8673326&partnerID=40&md5=790f12ed481e2a7fd36f88f62a4c702b","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable? © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","382-391","","","2019-March","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MMGXANE8","conferencePaper","2019","Vertesi, J.","Seeing Like a Rover: Team Work and Human-Robot Relations","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1109/HRI.2019.8673224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064000114&doi=10.1109%2fHRI.2019.8673224&partnerID=40&md5=8408e02463168815ec87397c3fa3c02f","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' 'eyes' on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life. © 2019 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","152","","","2019-March","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ARPBDNT","journalArticle","2019","Alves-Oliveira, P.; Sequeira, P.; Melo, F.S.; Castellano, G.; Paiva, A.","Empathic Robot for Group Learning: A Field Study","ACM Transactions on Human-Robot Interaction","","","10.1145/3300188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068536369&doi=10.1145%2f3300188&partnerID=40&md5=38936e838e88debca3eecfa94296497b","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning. © 2019 ACM.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","","","1","8","","","","","","","","","","","","","","","","","","<p>cited By 18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR2EXC58","conferencePaper","2019","Salaken, S.M.; Nahavandi, S.; McGinn, C.; Hossny, M.; Kelly, K.; Abobakr, A.; Nahavandi, D.; Iskander, J.","Development of a cloud-based computational framework for an empathetic robot","ACM International Conference Proceeding Series","","","10.1145/3313991.3314018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064612068&doi=10.1145%2f3313991.3314018&partnerID=40&md5=63ff43c5b27f0b4f09c443d56e71a480","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator’s voice is presented. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","102-108","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7V7B5C2","conferencePaper","2019","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.","Counseling Robot Implementation and Evaluation","Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018","","","10.1109/SMC.2018.00297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062214049&doi=10.1109%2fSMC.2018.00297&partnerID=40&md5=430fc180d5787ab662d9003595001288","A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called 'unazuki' in Japanese, a kind of nodding to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared. © 2018 IEEE.","2019","2021-02-15 22:35:20","2021-02-15 22:35:20","","1716-1722","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNFZV2MC","journalArticle","2019","Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.","Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects","Lecture Notes in Electrical Engineering","","","10.1007/978-3-030-04672-9_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f","The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","101-113","","","540","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RWVNNDS4","conferencePaper","2019","Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.","Digital empathy secures Frankenstein’s monster","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210","People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","335-349","","","2348","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJ6B2BSV","journalArticle","2019","Vanman, E.J.; Kappas, A.","“Danger, Will Robinson!” The challenges of social robots for intergroup relations","Social and Personality Psychology Compass","","","10.1111/spc3.12489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070056360&doi=10.1111%2fspc3.12489&partnerID=40&md5=df6ade6d0336dd74942733c534399eb2","Society's increasing reliance on robots in everyday life provides exciting opportunities for social psychologists to work with engineers in the nascent field of social robotics. In contrast to industrial robots that, for example, may be used on an assembly line, social robots are designed specifically to interact with humans and/or other robots. People tend to perceive social robots as autonomous and capable of having a mind. As such, they are also more likely to be subject to social categorization by humans. As social robots become more human like, people may also feel greater empathy for them and treat robots more like (human) ingroup members. On the other hand, as they become more human like, robots also challenge our human distinctiveness, threaten our identity, and elicit suspicion about their ability to deceive us with their human-like qualities. We review relevant research to explore this apparent paradox, particularly from an intergroup relations perspective. We discuss these findings and propose three research questions that we believe social psychologists are ideally suited to address. © 2019 John Wiley & Sons Ltd","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","","","8","13","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PDXJJSNK","journalArticle","2019","Omokawa, R.; Kobayashi, M.; Matsuura, S.","Expressing the Personality of a Humanoid Robot as a Talking Partner in an Elementary School Classroom","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-23560-4_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069875511&doi=10.1007%2f978-3-030-23560-4_36&partnerID=40&md5=6fcb8f37cfa76597c0643f0aa6619d9d","A humanoid robot NAO was introduced as a talking partner of teaching AI and robot to the elementary school students to stimulate empathy for the intelligent machines. Two dialog types were defined. First, the query type dialog was defined as a robot’s answer to human questioning. Second, the phatic type dialogs were defined to express the personality of the robot. While the former type dialog is initiated by formulated questioning, the latter type response can even be induced by misrecognition of human speech. Applying this simple method, the same unit sessions for each of the three classrooms on AI and robot were conducted. During the sessions, students’ burst of laughter was induced at 83% of the phatic type dialog, and the laughing response was found at 44% of the query type dialogs. By this representation, it became easier for the students to empathize with the robot. After this session, a questionnaire survey on the preference of robot pet, on what the students wanted to talk with the robot that dreams at night, and on their view of life if AI robots replaced human workers was conducted. The results suggested that the students got to imagine a virtual subjectivity of the intelligent machines and considered a better life for the human with them. © 2019, Springer Nature Switzerland AG.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","494-506","","","11572 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGQ6BJEA","conferencePaper","2019","Gemeinboeck, P.; Saunders, R.","Exploring social co-presence through movement in human-robot encounters","2019 AISB Convention","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075273167&partnerID=40&md5=25ec4efb84ecdc0459bba9ce60def3df","This paper explores the social capacity of robots as an emergent phenomenon of the exchange between humans and robots, rather than an intrinsic property of robots as is often assumed in social robotics research. Using our Performative Body Mapping (PBM) approach, we have developed a robotic object for studying how social meaning is enacted when movement qualities meet kinesthetic empathy. In this paper we introduce PBM and how it harnesses performers' kinesthetic imagination and movement expertise for designing the movement potential and movement qualities of abstract, non-humanlike robots. We then present our recent study of how the social presence of our robotic object-in-motion emerges in an encounter, involving experts from performance and design. Preliminary results of this study show that our robotic object can successfully convey movement qualities and their intended expressions as embodied by a dancer as part of the PBM process. Finally, we discuss how our observations can shift our focus from attributing qualities to the object to an emergence of qualities, propelled by the encounter. We believe our study provides a glimpse into the dynamic enactment of agency and how it requires both sides to 'give' for the robotic object's characteristics and the participants' experience to evolve. © 2019 AISB Convention.All right reserved.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","31-37","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPS4J34L","journalArticle","2019","Zhang, Y.; Qi, S.","User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-22335-9_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825","With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","350-366","","","11588 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFLH4K8Q","conferencePaper","2019","Arriaga, O.; Valdenegro-Toro, M.; Plöger, P.G.","Real-time convolutional neural networks for emotion and gender classification","ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2","Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.","2019","2021-02-15 22:35:21","2021-02-15 22:35:21","","221-226","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWLQGLGP","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.","Band of Brothers and Bolts: Caring about Your Robot Teammate","IEEE International Conference on Intelligent Robots and Systems","","","10.1109/IROS.2018.8594324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062974656&doi=10.1109%2fIROS.2018.8594324&partnerID=40&md5=3d70c11d1788c11aba3e15e67bb7dd7b","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected. © 2018 IEEE.","2018","2021-02-15 22:35:21","2021-02-15 22:35:21","","1853-1858","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RG5R55P","conferencePaper","2018","Viet Tuyen, N.T.; Jeong, S.; Chong, N.Y.","Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","IEEE International Conference on Intelligent Robots and Systems","","","10.1109/IROS.2018.8593974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062987621&doi=10.1109%2fIROS.2018.8593974&partnerID=40&md5=755c3fc2f1c863f79b55e63646138d4d","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator. © 2018 IEEE.","2018","2021-02-15 22:35:21","2021-02-15 22:35:21","","2008-2013","","","","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W27CVGTJ","journalArticle","2018","Obaid, M.; Aylett, R.; Barendregt, W.; Basedow, C.; Corrigan, L.J.; Hall, L.; Jones, A.; Kappas, A.; Küster, D.; Paiva, A.; Papadopoulos, F.; Serholt, S.; Castellano, G.","Endowing a robotic tutor with empathic qualities: Design and pilot evaluation","International Journal of Humanoid Robotics","","","10.1142/S0219843618500251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058160758&doi=10.1142%2fS0219843618500251&partnerID=40&md5=60f7dbb32b8b7344ac5c0d8be964a7cb","As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions. © 2018 World Scientific Publishing Company.","2018","2021-02-15 22:35:21","2021-02-15 22:35:21","","","","6","15","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84PRAKQ9","journalArticle","2018","Swiderska, A.; Küster, D.","Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots","Perception","","","10.1177/0301006618809919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058656094&doi=10.1177%2f0301006618809919&partnerID=40&md5=2d29a1feddf28df7efb1c2f080d656ba","Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain. © The Author(s) 2018.","2018","2021-02-15 22:35:21","2021-02-15 22:35:21","","1139-1152","","12","47","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8C7I9DY","conferencePaper","2018","James, J.; Watson, C.I.; MacDonald, B.","Artificial Empathy in Social Robots: An analysis of Emotions in Speech","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","","","10.1109/ROMAN.2018.8525652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055010165&doi=10.1109%2fROMAN.2018.8525652&partnerID=40&md5=dc6f59a151e5db0e00c350424b2adb5f","Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","632-637","","","","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2F274BF5","conferencePaper","2018","Mollahosseini, A.; Abdollahi, H.; Mahoor, M.H.","Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","","","10.1109/ROMAN.2018.8525777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058084838&doi=10.1109%2fROMAN.2018.8525777&partnerID=40&md5=0bd7cd6c5c720a217ec19787cc5218c6","Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","783-789","","","","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTCWCQVC","conferencePaper","2018","Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.","Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","","","10.1109/ROMAN.2018.8525515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058099794&doi=10.1109%2fROMAN.2018.8525515&partnerID=40&md5=64fa73971c77b5ebeb7809d94607f32a","Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","275-281","","","","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RI2VN2HN","journalArticle","2018","Weber, A.S.","Emerging medical ethical issues in healthcare and medical robotics","International Journal of Mechanical Engineering and Robotics Research","","","10.18178/ijmerr.7.6.604-607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056576175&doi=10.18178%2fijmerr.7.6.604-607&partnerID=40&md5=497839d4cdb779d178e34f97ca54283a","Due to the increasing sophistication and complexity of autonomous machines, Artificial Intelligence, Computerized Decision Support Systems (CDSS), natural language question-answering robots, and social / emotive medical robots, new medical ethics conundrums are arising. Unresolved questions revolve around autonomy, responsibility, empathy, trust, moral agency and the social and economic impacts of medical robots. © 2018 Int. J. Mech. Eng. Rob. Res.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","604-607","","6","7","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSWK2JR8","journalArticle","2018","Giannopulu, I.; Terada, K.; Watanabe, T.","Emotional empathy as a mechanism of synchronisation in child-robot interaction","Frontiers in Psychology","","","10.3389/fpsyg.2018.01852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055052507&doi=10.3389%2ffpsyg.2018.01852&partnerID=40&md5=4e3455fc4099810d57dbf0e2e66d93bf","Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation. © 2018 Giannopulu, Terada and Watanabe.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","","","OCT","9","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8WYB9H3H","conferencePaper","2018","Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.","Learning Empathy-Driven Emotion Expressions using Affective Modulations","Proceedings of the International Joint Conference on Neural Networks","","","10.1109/IJCNN.2018.8489158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056556433&doi=10.1109%2fIJCNN.2018.8489158&partnerID=40&md5=14dfc5df0848f6da4a7837cf8b02c2d7","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","","","","2018-July","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AH3U5ZY","conferencePaper","2018","Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.","Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression","2018 15th International Conference on Ubiquitous Robots, UR 2018","","","10.1109/URAI.2018.8441767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053513255&doi=10.1109%2fURAI.2018.8441767&partnerID=40&md5=0e071356103385e8abbf327f361ed75a","Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","377-382","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"246RWPT2","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness of Android-Based Mobile Robots for Children Asperger Syndrome","Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care","","","10.1109/ICAITI.2018.8686759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753069&doi=10.1109%2fICAITI.2018.8686759&partnerID=40&md5=af11f585df846db5c051b6434459ed42","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","208-212","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILP9U7DB","conferencePaper","2018","Iranzo, R.M.G.; Padilla-Zea, N.; Paderewski-Rodriguez, P.; Gonzalez-Gonzalez, C.S.","Empathy and virtual agents for learning applications in symbiotic systems","IEEE Global Engineering Education Conference, EDUCON","","","10.1109/EDUCON.2018.8363298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048111659&doi=10.1109%2fEDUCON.2018.8363298&partnerID=40&md5=62f6bfb9db56637dd5db81cf57ef1d67","Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges. © 2018 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","694-697","","","2018-April","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBMTEII5","conferencePaper","2018","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Design of counseling robot for production by 3D printer","Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017","","","10.1109/SITIS.2017.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048855912&doi=10.1109%2fSITIS.2017.20&partnerID=40&md5=56c2a96a7c71f8e67c1dd1dcc7fee57d","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called 'unazuki' in Japanese, a kind of 'nodding' to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a 'unazuki' or 'dialog promotion nodding' robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such 'unazuki', the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling. © 2017 IEEE.","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","56-62","","","2018-January","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q33Q3PIS","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Dey, A.; Tossell, C.; Finomore, V.","He who hesitates is lost (..in thoughts over a robot)","ACM International Conference Proceeding Series","","","10.1145/3183654.3183703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048734329&doi=10.1145%2f3183654.3183703&partnerID=40&md5=b3763171447b67063b193bdef1ec99ee","In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams. © 2018 Copyright held by the owner/author(s).","2018","2021-02-15 22:35:22","2021-02-15 22:35:22","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIVTSY6P","conferencePaper","2018","Anshar, M.; Williams, M.-A.","Evolving artificial pain from fault detection through pattern data analysis","2017 IEEE International Conference on Real-Time Computing and Robotics, RCAR 2017","","","10.1109/RCAR.2017.8311945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050694528&doi=10.1109%2fRCAR.2017.8311945&partnerID=40&md5=e13b223e149d6fdfdfed4b5bf7088696","Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment. © 2017 IEEE.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","694-699","","","2017-July","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTXN9QDS","conferencePaper","2018","Lehmann, H.; Broz, F.","Contagious Yawning in Human-Robot Interaction","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3173386.3177063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045279372&doi=10.1145%2f3173386.3177063&partnerID=40&md5=c34b27a9315cc4b991b432223e771e6a","This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data. © 2018 Authors.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","173-174","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJSGPNBG","conferencePaper","2018","Björling, E.A.; Rose, E.; Ren, R.","Teen-Robot Interaction: A Pilot Study of Engagement with a Low-fidelity Prototype","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3173386.3177068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045253387&doi=10.1145%2f3173386.3177068&partnerID=40&md5=7e37fee6758bc871489fac3d9259145c","Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies. © 2018 Authors.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","69-70","","","","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TVZ4EFL","conferencePaper","2018","Kang, D.; Kim, S.; Kwak, S.S.","The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3173386.3177023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045233579&doi=10.1145%2f3173386.3177023&partnerID=40&md5=ccd02586641d7f3d562f91a4cbdde86f","We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand. © 2018 Authors.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","143-144","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DWUK4I7A","conferencePaper","2018","Correia, F.; Mascarenhas, S.; Prada, R.; Melo, F.S.; Paiva, A.","Group-based Emotions in Teams of Humans and Robots","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/3171221.3171252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045153556&doi=10.1145%2f3171221.3171252&partnerID=40&md5=545acc745afe80d9bf6537715a5b6bbf","Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions. © 2018 ACM.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","261-269","","","","","","","","","","","","","","","","","","","","","<p>cited By 19</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84YQT7P4","journalArticle","2018","Barakova, E.I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.","Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot","Connection Science","","","10.1080/09540091.2017.1350938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034210275&doi=10.1080%2f09540091.2017.1350938&partnerID=40&md5=abe1cbc4737c660b91d193a7ede94cf5","In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game–the game with the robot was seen as more challenging and the robot–as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","81-98","","1","30","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S9DVZEW","journalArticle","2018","Vallverdú, J.; Nishida, T.; Ohmoto, Y.; Moran, S.; Lázare, S.","Fake empathy and human- robot interaction (HRI): A preliminary study","International Journal of Technology and Human Interaction","","","10.4018/IJTHI.2018010103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033380873&doi=10.4018%2fIJTHI.2018010103&partnerID=40&md5=e8c1b39365a7dd4fb4e56730f51ebee7","Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call 'fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different 'humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi- angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment. © Copyright 2018, IGI Global.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","44-59","","1","14","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69QJFWR2","journalArticle","2018","Anshar, M.; Williams, M.-A.","Evolving robot empathy towards humans with motor disabilities through artificial pain generation","AIMS Neuroscience","","","10.3934/NEUROSCIENCE.2018.1.56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046542640&doi=10.3934%2fNEUROSCIENCE.2018.1.56&partnerID=40&md5=94774a1cfd673260d0b54325f0e577c0","In contact assistive robots, a prolonged physical engagement between robots and humans with motor disabilities due to shoulder injuries, for instance, may at times lead humans to experience pain. In this situation, robots will require sophisticated capabilities, such as the ability to recognize human pain in advance and generate counter-responses as follow up emphatic action. Hence, it is important for robots to acquire an appropriate pain concept that allows them to develop these capabilities. This paper conceptualizes empathy generation through the realization of synthetic pain classes integrated into a robot's self-awareness framework, and the implementation of fault detection on the robot body serves as a primary source of pain activation. Projection of human shoulder motion into the robot arm motion acts as a fusion process, which is used as a medium to gather information for analyses then to generate corresponding synthetic pain and emphatic responses. An experiment is designed to mirror a human peer's shoulder motion into an observer robot. The results demonstrate that the fusion takes place accurately whenever unified internal states are achieved, allowing accurate classification of synthetic pain categories and generation of empathy responses in a timely fashion. Future works will consider a pain activation mechanism development. © 2018 the Author(s).","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","56-73","","1","5","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XV2NDTWM","conferencePaper","2018","Rincon, J.A.; Martin, A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.","EmIR: An emotional intelligent robot assistant","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052709722&partnerID=40&md5=ce9bc64a438e015843ae7c9faca4c4c1","The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare centre in the northern area of Portugal. © 2018 CEUR-WS. All rights reserved.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","","","","2166","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KUJ3FR4C","journalArticle","2018","Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.","Smiles of children with ASD may facilitate helping behaviors to the robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-05204-1_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5","Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","55-64","","","11357 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVNIE98V","journalArticle","2018","Kwon, O.; Kim, J.; Jin, Y.; Lee, N.","Impact of human-robot interaction on user satisfaction with humanoid-based healthcare","International Journal of Engineering and Technology(UAE)","","","10.14419/ijet.v7i2.12.11038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911","Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","68-75","","2","7","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN2HCVLY","journalArticle","2018","Kohori, T.; Hirayama, S.; Hara, T.; Muramatsu, M.; Naganuma, H.; Yamano, M.; Ichikawa, K.; Matsumoto, H.; Uchiyama, H.","Development and evaluation of an interactive therapy robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-76270-8_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043505794&doi=10.1007%2f978-3-319-76270-8_6&partnerID=40&md5=9a33e24baf10f8235290981d937942ce","Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","66-83","","","10714 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TM4CKA7V","conferencePaper","2018","Asada, M.","Artificial pain: Empathy, morality, and ethics as a developmental process of consciousness","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059816137&partnerID=40&md5=0c3d169632da3fae45d6ce00852c1fc0","In this article, I propose a working hypothesis that the nervous system of pain sensation is a key component to shape robots' (artificial systems') conscious minds through the developmental process of empathy, morality, and ethics based on the MNS that promotes the emergence of concept of self (and others). First, the limitation of the current progress of AI focusing on deep learning is pointed out from a viewpoint of the emergence of consciousness. Next, the outline of ideological back-ground on issues of mind in a broad sense is shown. Then, cognitive developmental robotics (CDR) is introduced with two important concepts; physical embodiment and social interaction both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, an issue how robots (artificial systems) could be moral and legal agents is shown. © 2018 for the individual papers by the papers' authors. All rights reserved.","2018","2021-02-15 22:35:23","2021-02-15 22:35:23","","","","","2287","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7I94VC4X","journalArticle","2018","Sancar, A.E.; Battini Sönmez, E.","A model for an emotional respondent robot","Advances in Intelligent Systems and Computing","","","10.1007/978-3-319-67934-1_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030167102&doi=10.1007%2f978-3-319-67934-1_37&partnerID=40&md5=fa973e11e625a3847ce9b2b2e7082ffc","The aim of this study is to design an emotional regulation model based on facial expressions. It is argued that emotions serve a critical function in intelligent behavior and some researchers posed the questions of whether a robot could be intelligent without emotions. As a result, emotion recognition and adequate reaction are essential requirements for enhancing the quality of human robot interaction. This study proposes a computational model of emotion capable of clustering the perceived facial expression, and using cognitive reappraisal to switch its internal state so as to give a human-like reaction over the time. That is, the agent learns the person’s facial expression by using Self Organizing Map, and gives it a meaning by mapping the perceived expression into its internal state diagram. As a result, the presented model implements empathy with the aim to enhance human-robot communication. © Springer International Publishing AG 2018.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","406-416","","","678","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CA9FLLSM","journalArticle","2018","Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.","Towards empathetic human-robot interactions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-75487-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25","Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","173-193","","","9624 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNMN2NNA","journalArticle","2018","Qureshi, S.; Hagelbäck, J.; Iqbal, S.M.Z.; Javaid, H.; Lindley, C.A.","Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS","Advances in Intelligent Systems and Computing","","","10.1007/978-3-030-01054-6_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206","With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","347-363","","","868","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9NH6WWN","journalArticle","2018","Chen, A.C.-Y.; Lin, Y.-C.","Warm Robot Classroom_Using Wearable Technology as a Gateway to Culturally Responsive Teaching","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-91152-6_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050464253&doi=10.1007%2f978-3-319-91152-6_19&partnerID=40&md5=1c19f03d879291cd2cc0f914750ebf1e","[Warm Robot classroom] is related to answer the question of introduce computational thinking teaching aids and course design by studies robots and wearables with social humanity. The discussion is about how to cultivate students with the rational technology thinking and humanity empathy? The research method includes design and research on cultural response teaching curriculum with the composition of product designers and electronic engineers, planning of teaching contents, and solicitation of teaching and learning of cultural responses from more than five kinds of different cultural backgrounds through the a one semester course. Develop the performances from different cultural groups through 3D printing, laser cutting and digital embroidery creations and assess the applicability of course design. This course was held with 64 participants (9 different countries, 5 backgrounds). We describe our experience in designing and organizing a wearable course. We will show that (1) Three interactive modules of difficult levels of soft wearable prototypes. (2) The culturally responsive curriculum. (3) The learning outcome of the teaching implementations with interactive toolkits from the final performance. The result shows that curriculum with different background works together can built students from either side to response to each other. © 2018, Springer International Publishing AG, part of Springer Nature.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","239-253","","","10925 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SR5G2GX","journalArticle","2018","Korać, S.T.","Depersonalisation of killing: Towards a 21st century use of force “beyond good and evil?” [Depersonalizacija ubijanja ka upotrebi sile u 21. Veku „s onu stranu dobra i zla?“]","Filozofija i Drustvo","","","10.2298/FID1801049K","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059193212&doi=10.2298%2fFID1801049K&partnerID=40&md5=87fab0df617879e99bff27aab7f6a083","The article analyses how robotisation as the latest advance in military technology can depersonalise the methods of killing in the 21st century by turning enemy soldiers and civilians into mere objects devoid of moral value. The departing assumption is that robotisation of warfare transforms military operations into automated industrial processes with the aim of removing empathy as a redundant ‘cost’. The development of autonomous weapons systems raises a number of sharp ethical controversies related to the projected moral insensitivity of robots regarding the treatment of enemies and civilian population. The futurist vision of war as a foreign policy instrument entirely ‘purified’ of the risk of morally wrong actions is in opposition with the negative effects of the use of drones. The author concludes that the use of lethal robots in combat would eventually remove enemy soldiers and civilians from the realm of ethical reasoning and deprive them of human dignity. Decision to kill in military operations ought to be based on human conscience as the only proper framework of making decisions by reasoning whether an action is right or wrong. © 2018, University of Belgrade - Institute for Philosophy and Social Theory. All rights reserved.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","49-64","","1","29","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89BFKERS","journalArticle","2018","Baylor, A.L.","Three research directions for affective learning technologies","Proceedings of International Conference of the Learning Sciences, ICLS","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852093&partnerID=40&md5=f752722081155797b31c18bfb8421fc9","Looking to the future of advanced learning technology research, understanding, supporting and explicitly designing for the role of affect is of great importance. I highlight three emerging areas of research with current research exemplars. First, simulating affect is necessary to enhance human-like relationships with technology; for example, with artificially intelligent virtual agents, or teachable robots as learning companions. Second, sensing and responding to learner affect in immersive learning experiences as well as learning at scale is rapidly evolving; for example, through affective intelligent tutoring systems, or dashboards driven by multimodal analytics. Third, designing technology-based learning experiences that promote, elicit and support affective outcomes requires theory building within the learning sciences; for example, to realize outcomes such as empathy or curiosity and formulate linkages to learning. Finally, I suggest how research in these areas of affective technology afford new opportunities to prepare learners for future learning and work environments. © ISLS.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","1843-1846","","2018-June","3","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQZ3L3SE","conferencePaper","2018","Vallejo-Jiménez, M.M.; Martínez-Puerta, J.J.; Agudelo, S.B.; Salgado, N.D.","SENA Tecnoacademia Risaralda and Caldas as a collaborative learning scenario in robotics","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062656500&partnerID=40&md5=dffca2434457967c2b9144db0e10a2d5","The Research, Technological Development and Innovation System of SENA (SENNOVA) of Colombia, has the purpose of strengthening the standards of quality and relevance, through programs and projects as Tecnoacademias, defined as a STEM learning scenario, equipped with emerging technologies to develop innovation-oriented skills, through project training, to students of basic and secondary education, in courses such as Mathematics, Physics, Chemistry, Biology, applied sciences such as Robotics, Nanotechnology, Biotechnology and Virtual Technologies. This work presents some of the activities carried out by the apprentices through the Educational Robotics in Tecnoacademia Risaralda and Tecnoacademia Caldas sites, based on Industrial and Mechatronic Design methodologies, using LEGO MINDSTORM EV3 kits and Design Thinking for educators and LEGO, successfully applied in the EducarChile program. It is based on three fundamental pillars, which are empathy, collaboration and experimentation, which are presented in the five (5) phases of the methodology. It should be noted that the tools of innovation and prototyping per se, do not serve much if the team that executes them is not immersed in a culture of tolerance, teamwork, leadership and if there is no feedback and if the capacities are not taken into account and strengths of the work team. All this was achieved through different prototypes of robots of light and robust type originated in a PON scenario (problem, opportunity, needs). © 2018 CEUR-WS. All rights reserved.","2018","2021-02-15 22:35:24","2021-02-15 22:35:24","","","","","2312","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVQSLUAJ","conferencePaper","2017","Burns, H.D.; Lesseig, K.","Empathy in middle school engineering design process","Proceedings - Frontiers in Education Conference, FIE","","","10.1109/FIE.2017.8190669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043250525&doi=10.1109%2fFIE.2017.8190669&partnerID=40&md5=2de94d98be1bbb33936099368e3ff4f4","This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word ""empathy"" is not used, these problems are defined from an empathetic perspective as ""situations people want to change"" of ""social and global significance."" However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design. © 2017 IEEE.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","1-4","","","2017-October","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YQLGH7LN","conferencePaper","2017","Kurashige, K.; Sakurai, E.; Knauf, R.; Tsuruta, S.; Sakurai, Y.; Damiani, E.","Context respectful counseling agent integrated with robot nodding for dialog promotion","2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017","","","10.1109/SMC.2017.8122833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044231442&doi=10.1109%2fSMC.2017.8122833&partnerID=40&md5=9b50118f2dd3ce8a24156a3edb15f411","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling. © 2017 IEEE.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","1540-1545","","","2017-January","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZPFKTCQ","journalArticle","2017","Borenstein, J.; Arkin, R.C.","Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior","AI and Society","","","10.1007/s00146-016-0684-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000443585&doi=10.1007%2fs00146-016-0684-1&partnerID=40&md5=aeb23d28928c11d0e8a8c5616b33c63b","An under-examined aspect of human–robot interaction that warrants further exploration is whether robots should be permitted to influence a user’s behavior for that person’s own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user’s behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user’s empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be. © 2016, Springer-Verlag London.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","499-507","","4","32","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQC8JFKH","journalArticle","2017","Chikaraishi, T.; Yoshikawa, Y.; Ogawa, K.; Hirata, O.; Ishiguro, H.","Creation and staging of android theatre ""Sayonara"" towards developing highly human-like robots","Future Internet","","","10.3390/fi9040075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040790411&doi=10.3390%2ffi9040075&partnerID=40&md5=7741ec53279dea95f8e1cde8863ea639","Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world. © 2016 by the authors.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","","","4","9","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4B52VS5","journalArticle","2017","Paiva, A.; Leite, I.; Boukricha, H.; Wachsmuth, I.","Empathy in virtual agents and robots: A survey","ACM Transactions on Interactive Intelligent Systems","","","10.1145/2912150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030721207&doi=10.1145%2f2912150&partnerID=40&md5=0ee6b019cd9a77afad3da844eab99772","This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user's or another agent's emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent's situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future. Copyright is held by the owner/author(s).","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","","","3","7","","","","","","","","","","","","","","","","","","<p>cited By 43</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45SJLQPX","journalArticle","2017","Abubshait, A.; Wiese, E.","You look human, but act like a machine: Agent appearance and behavior modulate different aspects of human-robot interaction","Frontiers in Psychology","","","10.3389/fpsyg.2017.01393","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028087757&doi=10.3389%2ffpsyg.2017.01393&partnerID=40&md5=7c76b89b0bf2a723ace310a3123236ab","Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed. © 2017 Abubshait and Wiese.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","","","AUG","8","","","","","","","","","","","","","","","","","","<p>cited By 31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DA3ZHCTE","conferencePaper","2017","Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.","Learning human behavior for emotional body expression in socially assistive robotics","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2017","","","10.1109/URAI.2017.7992882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034217006&doi=10.1109%2fURAI.2017.7992882&partnerID=40&md5=9ad61da9fc07256c0888f6888db1c4a2","Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots. © 2017 IEEE.","2017","2021-02-15 22:35:24","2021-02-15 22:35:24","","45-50","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJ8KNHCS","journalArticle","2017","Rouaix, N.; Retru-Chavastel, L.; Rigaud, A.-S.; Monnet, C.; Lenoir, H.; Pino, M.","Affective and engagement issues in the conception and assessment of a robot-assisted psychomotor therapy for persons with dementia","Frontiers in Psychology","","","10.3389/fpsyg.2017.00950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021340604&doi=10.3389%2ffpsyg.2017.00950&partnerID=40&md5=76571d1aa765fd440c392484c9fc5bae","The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a ""control software"" for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient- therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction. © 2017 Rouaix, Retru-Chavastel, Rigaud, Monnet, Lenoir and Pino.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","","","JUN","8","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z79LTRD2","conferencePaper","2017","Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.","A laughing-driven pupil response system for inducing empathy","SII 2016 - 2016 IEEE/SICE International Symposium on System Integration","","","10.1109/SII.2016.7844051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015395679&doi=10.1109%2fSII.2016.7844051&partnerID=40&md5=79e71dbc5d0d655d939d8f50b2639752","Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy. © 2016 IEEE.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","520-525","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G46Y8JWD","journalArticle","2017","De Carolis, B.; Ferilli, S.; Palestra, G.","Simulating empathic behavior in a social assistive robot","Multimedia Tools and Applications","","","10.1007/s11042-016-3797-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988691125&doi=10.1007%2fs11042-016-3797-0&partnerID=40&md5=3d3264938f9865faf7b3dd27a9d15393","When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user’s affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot’s affective state and, consequently, the most appropriate empathic behavior. The robot’s empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot. © 2016, Springer Science+Business Media New York.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","5073-5094","","4","76","","","","","","","","","","","","","","","","","","<p>cited By 15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24E8HTWC","conferencePaper","2017","Lewandowska-Tomaszczyk, B.; Wilson, P.A.","Compassion, empathy and sympathy expression features in affective robotics","7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings","","","10.1109/CogInfoCom.2016.7804526","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2","The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","65-70","","","","","","","","","","","","","","","","","","","","","<p>cited By 10</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5T72L6S","journalArticle","2017","Woo, J.; Botzheim, J.; Kubota, N.","Emotional empathy model for robot partners using recurrent spiking neural network model with Hebbian-LMS learning","Malaysian Journal of Computer Science","","","10.22452/mjcs.vol30no4.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036526555&doi=10.22452%2fmjcs.vol30no4.1&partnerID=40&md5=7bf71955acddbdefa5deeff07d6d74dc","This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply ""Hebbian-LMS"" learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner ""iPhonoid-C"". Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","258-285","","4","30","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZVT72Y7","journalArticle","2017","Chumkamon, S.; Hayashi, E.","Consciousnes-based emotion and behavior of pet robot with brain-inspired method","Information (Japan)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1","A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","615-629","","1","20","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYVJP9HQ","journalArticle","2017","Cho, H.-K.; Oh, J.; Lee, K.","A study on the potential roles of a robot peer in socio-emotional development of children","International Journal of Computational Vision and Robotics","","","10.1504/IJCVR.2017.083447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b","This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","335-343","","3","7","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MF9GB4SQ","journalArticle","2017","Fan, L.; Scheutz, M.; Lohani, M.; McCoy, M.; Stokes, C.","Do we need emotionally intelligent artificial agents? First results of human perceptions of emotional intelligence in humans compared to robots","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-67401-8_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029009078&doi=10.1007%2f978-3-319-67401-8_15&partnerID=40&md5=40847ef441d91c4b0c0d33b427b6059c","Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent’s emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them. © Springer International Publishing AG 2017.","2017","2021-02-15 22:35:25","2021-02-15 22:35:25","","129-141","","","10498 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JMB4TW75","conferencePaper","2016","Ranieri, C.M.; Romero, R.A.F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","Proceedings - 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016","","","10.1109/LARS-SBR.2016.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010416838&doi=10.1109%2fLARS-SBR.2016.13&partnerID=40&md5=48a1a71aed354854f322eb1a82dcc7eb","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness. © 2016 IEEE.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","31-36","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGN4QZDJ","conferencePaper","2016","Sin, Y.M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.-I.; Miyake, Y.","Evaluation of a head motion synchronization system in the communicative process between human and robot","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan, SICE 2016","","","10.1109/SICE.2016.7749252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263059&doi=10.1109%2fSICE.2016.7749252&partnerID=40&md5=ee5466b2a448823dac918c1ff6b6ac0e","An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation. © 2016 The Society of Instrument and Control Engineers - SICE.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","1514-1519","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7K4265H","journalArticle","2016","Chumkamon, S.; Hayashi, E.; Koike, M.","Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot","Biologically Inspired Cognitive Architectures","","","10.1016/j.bica.2016.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992027508&doi=10.1016%2fj.bica.2016.09.004&partnerID=40&md5=648a687454e6dd807ff6eafa3fbbcddd","Companion or 'pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross-communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like 'emotion' and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. © 2016 Elsevier B.V. All rights reserved.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","51-67","","","18","","","","","","","","","","","","","","","","","","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVE6UZPM","journalArticle","2016","Roudposhti, K.K.; Nunes, U.; Dias, J.","Probabilistic social behavior analysis by exploring body motion-based patterns","IEEE Transactions on Pattern Analysis and Machine Intelligence","","","10.1109/TPAMI.2015.2496209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978763318&doi=10.1109%2fTPAMI.2015.2496209&partnerID=40&md5=db01d33fa9bc27fd5f8ab2a7bcd42047","Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction. © 1979-2012 IEEE.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","1679-1691","","8","38","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RM66TMES","conferencePaper","2016","Chumkamon, S.; Masato, K.; Hayashi, E.","Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot","Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015","","","10.1109/SMC.2015.45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964478149&doi=10.1109%2fSMC.2015.45&partnerID=40&md5=9f91bfb404d3b6db6083d78cea8a6634","This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA). © 2015 IEEE.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","185-190","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SI2CKDXA","conferencePaper","2016","Coeckelbergh, M.","Moving machines: Robots, empathy, and the performance of suffering","AISB Annual Convention 2016, AISB 2016","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041917924&partnerID=40&md5=4dcb71c2728f658225bedc448591eef2","","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXP9KLH5","journalArticle","2016","Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.","Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy","Paladyn","","","10.1515/pjbr-2016-0005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88","An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.","2016","2021-02-15 22:35:25","2021-02-15 22:35:25","","55-66","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR9LZTM9","journalArticle","2016","Giambattista, A.; Teixeira, L.; Ayanoğlu, H.; Saraiva, M.; Duarte, E.","Expression of emotions by a service robot: A pilot study","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-40406-6_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977557359&doi=10.1007%2f978-3-319-40406-6_31&partnerID=40&md5=4e3540b931b764e55a11e0446d99c472","A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot’s facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children. © Springer International Publishing Switzerland 2016.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","328-336","","","9748","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIXRVSK9","journalArticle","2016","Musiall, M.","Magical thinking and empathy towards robots","Frontiers in Artificial Intelligence and Applications","","","10.3233/978-1-61499-708-5-347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992603376&doi=10.3233%2f978-1-61499-708-5-347&partnerID=40&md5=d0fd98141be39c30e95ee0a8507671b6","This paper aims to understand why human beings develop empathetic attitudes towards robots. Whilst much research studies this issue from the perspective of the natural sciences, by referring to biological features of the human brain, it is also possible to investigate it from the perspective of the humanities by referring to humans' cultural features. After establishing animation as a necessary condition of empathy towards robots, the presentation delivers a hypothesis that magical thinking - typical for children, members of ""primitive"" societies and individuals with mental disorders - is involved in the empathetic relations with robots. Furthermore, arguments to defend and clarify this hypothesis are presented. © 2016 The authors and IOS Press. All rights reserved.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","347-356","","","290","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXMP89GH","journalArticle","2016","Sorbello, R.; Chella, A.; Giardina, M.; Nishio, S.; Ishiguro, H.","An architecture for Telenoid robot as empathic conversational android companion for elderly people","Advances in Intelligent Systems and Computing","","","10.1007/978-3-319-08338-4_68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974382&doi=10.1007%2f978-3-319-08338-4_68&partnerID=40&md5=284d20453f0caff779f01dbae2648464","In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user. © Springer International Publishing Switzerland 2016.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","939-953","","","302","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CSCB3M8","journalArticle","2016","Bechade, L.; Duplessis, G.D.; Devillers, L.","Empirical study of humor support in social human-robot interaction","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-39862-4_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978870310&doi=10.1007%2f978-3-319-39862-4_28&partnerID=40&md5=1ef7ba186fefcb5c0b2d3249f892d26b","As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event’s context. © Springer International Publishing Switzerland 2016.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","305-316","","","9749","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C43TSVNB","journalArticle","2016","Biswas, M.; Murray, J.","The effects of cognitive biases in long-term human-robot interactions: Case studies using three cognitive biases on MARC the humanoid robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-47437-3_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992530101&doi=10.1007%2f978-3-319-47437-3_15&partnerID=40&md5=04c0c77ee6491b684750e79ae72cd6c4","The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant’s names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours. © Springer International Publishing AG 2016.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","148-158","","","9979 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CA5S3ZYB","conferencePaper","2016","Fung, P.; Dey, A.; Siddique, F.B.; Lin, R.; Yang, Y.; Yan, W.; Yin, R.C.H.","Zara: An empathetic interactive virtual agent","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994232510&partnerID=40&md5=2f53e4c08a96e5fc3df960ad4e028852","Zara, or 'Zara the Supergirl', is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented humanrobot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015. Copyright © 2016 ISCA.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","1176-1177","","","08-12-September-2016","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XHBMV458","journalArticle","2016","Sejima, Y.; Egawa, S.; Sato, Y.; Watanabe, T.","A pupil response system using hemispherical displays for enhancing affective conveyance","Journal of Advanced Mechanical Design, Systems and Manufacturing","","","10.1299/JAMDSM.2019JAMDSM0032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078309015&doi=10.1299%2fJAMDSM.2019JAMDSM0032&partnerID=40&md5=29a5562526052c2c6b4b3c50b9ee2dfb","In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker’s affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot’s eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance. © 2019 The Japan Society of Mechanical Engineers.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","","","4","10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N54MSGWS","conferencePaper","2016","Fung, P.; Dey, A.; Bin Siddique, F.; Lin, R.; Yang, Y.; Bertero, D.; Yan, W.; Yin, R.C.H.; Wu, C.-S.","Zara: A virtual interactive dialogue system incorporating emotion, sentiment and personality recognition","COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048777533&partnerID=40&md5=fbcd4dcbaee2c6a3edb8e95be195275d","Zara, or 'Zara the Supergirl' is a virtual robot, that can exhibit empathy while interacting with an user, with the aid of its built in facial and emotion recognition, sentiment analysis, and speech module. At the end of the 5-10 minute conversation, Zara can give a personality analysis of the user based on all the user utterances. We have also implemented a real-time emotion recognition, using a CNN model that detects emotion from raw audio without feature extraction, and have achieved an average of 65.7% accuracy on six different emotion classes, which is an impressive 4.5% improvement from the conventional feature based SVM classification. Also, we have described a CNN based sentiment analysis module trained using out-of-domain data, that recognizes sentiment from the speech recognition transcript, which has a 74.8 F-measure when tested on human-machine dialogues. © COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","278-281","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZJ6TAYM","journalArticle","2016","Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.","Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents","Transactions of the Japanese Society for Artificial Intelligence","","","10.1527/tjsai.C-G31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a","There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.","2016","2021-02-15 22:35:26","2021-02-15 22:35:26","","","","4","31","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LR4896U","conferencePaper","2015","Darling, K.; Nandy, P.; Breazeal, C.","Empathic concern and the effect of stories in human-robot interaction","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2015.7333675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954066644&doi=10.1109%2fROMAN.2015.7333675&partnerID=40&md5=cdb1729f65a77b7680f2decb250845e0","People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses. © 2015 IEEE.","2015","2021-02-15 22:35:26","2021-02-15 22:35:26","","770-775","","","2015-November","","","","","","","","","","","","","","","","","","<p>cited By 35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S2REIJ6R","conferencePaper","2015","Franco, G.A.M.","Evaluation of the emotional answer in HRI on a game situation","Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015","","","10.1145/2824893.2824897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979647991&doi=10.1145%2f2824893.2824897&partnerID=40&md5=3c3eddadd8b9eb02473ab17a28a8c9ab","This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.","2015","2021-02-15 22:35:26","2021-02-15 22:35:26","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNKZ4WQB","journalArticle","2015","Suzuki, Y.; Galli, L.; Ikeda, A.; Itakura, S.; Kitazaki, M.","Measuring empathy for human and robot hand pain using electroencephalography","Scientific Reports","","","10.1038/srep15924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946601210&doi=10.1038%2fsrep15924&partnerID=40&md5=7480591126ea8768b8ce1b5b5879fca1","This study provides the first physiological evidence of humans € ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.","2015","2021-02-15 22:35:26","2021-02-15 22:35:26","","","","","5","","","","","","","","","","","","","","","","","","<p>cited By 53</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4PQR5JX","journalArticle","2015","Han, J.; Jo, M.; Hyun, E.; So, H.-J.","Examining young children’s perception toward augmented reality-infused dramatic play","Educational Technology Research and Development","","","10.1007/s11423-015-9374-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939948308&doi=10.1007%2fs11423-015-9374-9&partnerID=40&md5=8ca770924db1fe1a9950b09569d11ad1","Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children’s satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children’s perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5–6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children’s perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed. © 2015, Association for Educational Communications and Technology.","2015","2021-02-15 22:35:26","2021-02-15 22:35:26","","455-474","","3","63","","","","","","","","","","","","","","","","","","<p>cited By 47</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVXYXU54","conferencePaper","2015","Ji, S.H.; You, S.J.; Cho, H.-K.","Design of Emotional Conversations with a Child for a Role Playing Robot","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2701973.2702009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969278892&doi=10.1145%2f2701973.2702009&partnerID=40&md5=22de8e058c04462574e4504c77cf3ddd","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot. © 2015 Authors.","2015","2021-02-15 22:35:26","2021-02-15 22:35:26","","73-74","","","02-05-March-2015","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCWK6X7V","conferencePaper","2015","Jeong, S.; Gu, J.; Shin, D.-H.","I am Interested in What You are Saying: Role of Nonverbal Immediacy Cues in Listening","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2701973.2702040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969131750&doi=10.1145%2f2701973.2702040&partnerID=40&md5=430338bf874134357991c30484c63e40","Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot. © 2015 Authors.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","129-130","","","02-05-March-2015","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVGHPNHK","journalArticle","2015","Tisseron, S.; Tordo, F.; Baddoura, R.","Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items","International Journal of Social Robotics","","","10.1007/s12369-014-0268-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924301513&doi=10.1007%2fs12369-014-0268-5&partnerID=40&md5=ae9ddda552ec58f57dc89db088c53239","The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","97-102","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KD8HQZ4B","journalArticle","2015","Lim, A.; Okuno, H.G.","A Recipe for Empathy: Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese","International Journal of Social Robotics","","","10.1007/s12369-014-0262-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924287073&doi=10.1007%2fs12369-014-0262-y&partnerID=40&md5=0b55eb0be5c80bdacedbf176adf6fbd4","Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (“flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","35-49","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHTJWXST","journalArticle","2015","Asada, M.","Towards Artificial Empathy: How Can Artificial Empathy Follow the Developmental Pathway of Natural Empathy?","International Journal of Social Robotics","","","10.1007/s12369-014-0253-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924289838&doi=10.1007%2fs12369-014-0253-z&partnerID=40&md5=c0449e6915eb39b5a3612055fec7f938","The design of artificial empathy is one of the most essential issues in social robotics. This is because empathic interactions with ordinary people are needed to introduce robots into our society. Several attempts have been made for specific situations. However, such attempts have provided several limitations; thus, diminishing authenticity. The present article proposes “affective developmental robotics (hereafter, ADR),” which provides more authentic artificial empathy based on the concept of cognitive developmental robotics (hereafter, CDR). First, the evolution and development of empathy as revealed in neuroscience and biobehavioral studies are reviewed, moving from emotional contagion to envy and schadenfreude. These terms are then reconsidered from the ADR/CDR viewpoint, particularly along the developmental trajectory of self-other cognition. Next, a conceptual model of artificial empathy is proposed based on an ADR/CDR viewpoint and discussed with respect to several existing studies. Finally, a general discussion and proposals for addressing future issues are given. © 2014, The Author(s).","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","19-33","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ATP9MI44","journalArticle","2015","Damiano, L.; Dumouchel, P.; Lehmann, H.","Towards Human–Robot Affective Co-evolution Overcoming Oppositions in Constructing Emotions and Empathy","International Journal of Social Robotics","","","10.1007/s12369-014-0258-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924341694&doi=10.1007%2fs12369-014-0258-7&partnerID=40&md5=80851efee3b5a5866fe3182d7ca5c9b2","This article deals with contemporary research aimed at building emotional and empathic robots, and gives an overview of the field focusing on its main characteristics and ongoing transformations. It interprets the latter as precursors to a paradigmatic transition that could significantly change our social ecologies. This shift consists in abandoning the classical view of emotions as essentially individual states, and developing a relational view of emotions, which, as we argue, can create genuinely new emotional and empathic processes—dynamics of “human–robot” affective coordination supporting the development of mixed (human–robot) ecologies. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","7-18","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 19</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HCLCWW4","journalArticle","2015","Mirnig, N.; Strasser, E.; Weiss, A.; Kühnlenz, B.; Wollherr, D.; Tscheligi, M.","Can You Read My Face?: A Methodological Variation for Assessing Facial Expressions of Robotic Heads","International Journal of Social Robotics","","","10.1007/s12369-014-0261-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924308183&doi=10.1007%2fs12369-014-0261-z&partnerID=40&md5=c7634d4e7d25e2feda063822ac3b47b8","Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants’ dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","63-76","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSB4S63F","journalArticle","2015","Airenti, G.","The Cognitive Bases of Anthropomorphism: From Relatedness to Empathy","International Journal of Social Robotics","","","10.1007/s12369-014-0263-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924336727&doi=10.1007%2fs12369-014-0263-x&partnerID=40&md5=7771b24f56c2451979b51997da835912","Humans may react very differently with respect to mechanical devices, including robots. They can interact with them with delight or retreat in aversion or fear. According to the famous model of the uncanny valley these opposite reactions depend on the degree of familiarity that different artifacts engender in humans. The aim of my work is trying to find out the cognitive bases of familiarity, analyzing the origin of anthropomorphic projection, namely human disposition to attribute anthropomorphic features - like intentions or feelings—to artifacts. I shall discuss two concepts: relatedness and empathy, and argue that relatedness is the precondition for empathy. The fact that it is possible to attribute anthropomorphic features virtually to any object shows that resemblance is not the point. Anthropomorphism is a kind of relation that humans establish with an artifact, and in order to comprehend this phenomenon we have to focus on the relational aspect. I shall argue that what we call anthropomorphism is an extension to nonhumans of forms of interactions typical of human communication, i.e. the attribution to an artifact of the position of interlocutor in a possible dialogue. It can be shown that attributing to an artifact the position of interlocutor in a dialogue implies dealing with it as if it were endowed of the features characterizing human mind, i.e. mental states and emotions. © 2015, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","117-127","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 21</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SI38TS4V","conferencePaper","2015","Seo, S.H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J.E.","Poor Thing! Would You Feel Sorry for a Simulated Robot?: A comparison of empathy toward a physical and a simulated robot","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2696454.2696471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943526431&doi=10.1145%2f2696454.2696471&partnerID=40&md5=5ac18b53dc70b062ef9d8f67cfea37d1","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. © 2015 ACM.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","125-132","","","2015-March","","","","","","","","","","","","","","","","","","<p>cited By 49</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6A36RKRE","conferencePaper","2015","Yoshida, N.; Nakataniy, Y.; Yonezawa, T.","Breathing expression for intimate communication corresponding to the physical distance and contact between human and robot","EAI International Conference on Bio-inspired Information and Communications Technologies (BICT)","","","10.4108/eai.3-12-2015.2262419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052166553&doi=10.4108%2feai.3-12-2015.2262419&partnerID=40&md5=9713dbd5e5ed533a7a82dfbe30666dfd","In this paper, we propose living-being-like breathing expressions concurrent with both aspiration and utterances using a stuffed-Toy robot in order to enable intimate interactions. The focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two. From the factor analysis of the impression for the word ıntimacy"" and the distance between the robot and the participants, it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility. © 2016 ICST.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JLFKUUAU","journalArticle","2015","Fuente, L.A.; Ierardi, H.; Pilling, M.; Crook, N.T.","Influence of upper body pose mirroring in human-robot interaction","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-25554-5_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983598081&doi=10.1007%2f978-3-319-25554-5_22&partnerID=40&md5=3f7276e6bca1a0a0ba38bb00b597daee","This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people’s perception of their conversation with it. A set of twelve questions about the participants’ university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","214-223","","","9388 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9MRHLSG","journalArticle","2015","Garza, A.A.; Lemus Zuñiga, L.G.; del Rosario Baltazar, M.; Marquez, B.Y.; Ramírez, C.L.; Romero, K.","Intelligent social agent for the development of social relations based on primary emotions","Smart Innovation, Systems and Technologies","","","10.1007/978-3-319-19728-9_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947904053&doi=10.1007%2f978-3-319-19728-9_28&partnerID=40&md5=e146418f66b057d4a871dfc2954a655e","This article shows the experimentation with emotions in a scenario with a specific task, where the main goal is to see the behavior of emotions to the task given to them that based on the level of empathy that exists between these emotions, all this work is done within a Social Multi-Agent System, in which it is intended that two or more robots can present a profile of personality and emotion for the search of empathy between them to make a team. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","337-344","","","38","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZJQ3GD6","journalArticle","2015","Ahn, T.-B.; Kang, E.-S.","Evaluation study of a human-sized bipedal humanoid robot through a public demonstration in a science museum","Journal of Institute of Control, Robotics and Systems","","","10.5302/J.ICROS.2015.15.0109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941275810&doi=10.5302%2fJ.ICROS.2015.15.0109&partnerID=40&md5=4fa5bf50debed289c455d163e9699f20","Although human-sized bipedal humanoid robots have been developed as the ideal form of human-friendly robots, studies of humanoid robots from the user perspective and of actual interaction between humanoid robots and the public in daily environments are few. This paper presents a long-term public demonstration that encouraged interaction between a humanoid robot and unspecified individuals. We have collected a significant amount of subjective evaluation data from the public by performing a storytelling demonstration that enhanced people's empathy towards the robot. The evaluation model consists of the robot's human friendliness, which involves its impression on humans, interaction with humans, and imitation of human motions and the robot's human appearance which involves gender, age, height, and body type. This study shows that there is no significant difference in human-friendliness between gender groups (male and female), while there is a significant difference between age groups (children and adults). In human appearance, it appears that there is no significant difference between either gender groups or age groups, except for the case of the robot's height. © ICROS 2015.","2015","2021-02-15 22:35:27","2021-02-15 22:35:27","","849-857","","9","21","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"25XBINKU","conferencePaper","2015","Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani Sherman, T.","Design and Evaluation of a Peripheral Robotic Conversation Companion","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2696454.2696495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943575630&doi=10.1145%2f2696454.2696495&partnerID=40&md5=25d296afd2bb48f4924a435a5cdb57c8","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy. © 2015 ACM.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","3-10","","","2015-March","","","","","","","","","","","","","","","","","","<p>cited By 54</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SF4WMDK","conferencePaper","2015","Koltick, N.","Autonomous botanist: The poetic potentials of a new robotic species","ACADIA 2015 - Computational Ecologies: Design in the Anthropocene: Proceedings of the 35th Annual Conference of the Association for Computer Aided Design in Architecture","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051989770&partnerID=40&md5=d2e2f91d070c255ab324f046a72147b0","This project begins by asking questions about ethics and empathy towards robots, and contemplates the future of their behavior in ways not informed by pragmatics or economy. What if a robot had a hobby? How do robots make aesthetic decisions? What is a robot’s point of view? It seeks to shift perception of robotic agency and allow the audience to embody the robotic gardeners’ vision, behavior and influence its aesthetics. By amplifying perceptual differences between humans and robots and we allow for both tangible and virtual embodiment experiences from multiple scales and perspectives. This compelling design speculation seeks to deploy a variety of interactive computational techniques, exploring novel forms and behaviors in order to engage deeper philosophical issues surrounding aesthetics, non-human agencies, and the role of the synthetic in the future. © 2015 ACADIA. All rights reserved.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","","","","2015-October","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHWTXWR4","journalArticle","2015","Vallverdú, J.; Casacuberta, D.","Ethical and technical aspects of emotions to create empathy in medical machines","Intelligent Systems, Control and Automation: Science and Engineering","","","10.1007/978-3-319-08108-3_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e","This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","341-362","","","74","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WD3C6KVD","conferencePaper","2015","Hood, D.; Lemaignan, S.; Dillenbourg, P.","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2696454.2696479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943550932&doi=10.1145%2f2696454.2696479&partnerID=40&md5=c5d573890e88b608b9382205e80c22f5","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education. © 2015 ACM.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","83-90","","","2015-March","","","","","","","","","","","","","","","","","","<p>cited By 78</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F77AVV8P","journalArticle","2015","Pettinati, M.J.; Arkin, R.C.","Towards a robot computational model to preserve dignity in stigmatizing patient-caregiver relationships","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-25554-5_53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983551906&doi=10.1007%2f978-3-319-25554-5_53&partnerID=40&md5=101e69f850eee5fb87938dd20f24c8b8","Parkinson’s disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patientcaregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","532-542","","","9388 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8IHQXUZ","conferencePaper","2015","Rasool, Z.; Masuyama, N.; Islam, M.N.; Loo, C.K.","Empathic interaction using the computational emotion model","Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015","","","10.1109/SSCI.2015.26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964955492&doi=10.1109%2fSSCI.2015.26&partnerID=40&md5=a46376a05176a93e601b99827119b808","This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-Arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors. © 2015 IEEE.","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","109-116","","","","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHJNFCIH","journalArticle","2015","Nijholt, A.","Designing Humor for Playable Cities","Procedia Manufacturing","","","10.1016/j.promfg.2015.07.358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009957570&doi=10.1016%2fj.promfg.2015.07.358&partnerID=40&md5=f471888187c5afeb3635554f745fa9c3","Smartness, made possible by intelligent sensors and actuators, is invading our home, office and public environments. This smartness monitors, anticipates and supports our activities, increasing efficiency of our activities. Smartness is usually associated with efficiency, but it also allows environments, virtual humans and social robots to display emotions, empathy and provide environments to introduce and support humorous events. We review examples of playful and humorous street furniture in ‘playable’ cities and projects that allow residents and visitors to interact with objects and environments in playful and humorous ways. We add observations on humor theory, in particular observations that deal with physical, visual and multimodal humor. Our emphasis is on introducing incongruities and on exploring different forms of incongruities in order to introduce humorous situations. Inventories of incongruities are explored. These inventories have been obtained from observing humor in everyday situations, in comedies, in movies, and in TV commercials. Shortcomings of these inventories from the point of view of multimodal and interaction humor are discussed and some preliminary views on additional approaches are provided. © 2015 The Authors","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","2175-2182","","","3","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XF9FGGCH","journalArticle","2015","Santos-Lang, C.C.","Moral ecology approaches to machine ethics","Intelligent Systems, Control and Automation: Science and Engineering","","","10.1007/978-3-319-08108-3_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921383640&doi=10.1007%2f978-3-319-08108-3_8&partnerID=40&md5=a85fa6ea1a4880edfbb476c3505fd3d9","Wallach and Allen’s seminal book, Moral Machines: Teaching Robots Right from Wrong, categorized theories of machine ethics by the types of algorithms each employs (e.g., top-down vs. bottom-up), ultimately concluding that a hybrid approach would be necessary. Humans are hybrids individually: our brains are wired to adapt our evaluative approach to our circumstances. For example, stressors can inhibit the action of oxytocin in the brain, thus forcing a nurse who usually acts from subjective empathy to defer to objective rules instead. In contrast, ecosystem approaches to ethics promote hybridization across, rather than within, individuals; the nurse being empowered to specialize in personalized care because other workers specialize in standardization, and profitability. Various philosophers have argued, or laid the framework to argue, that such specialization can be advantageous to teams and societies. Rather than mass-produce identical machines to emulate the best individual human, perhaps we should build diverse teams of machines to emulate the best human teams. © Springer International Publishing Switzerland 2015","2015","2021-02-15 22:35:28","2021-02-15 22:35:28","","111-127","","","74","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKMS65VK","conferencePaper","2014","Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.","People help robots who help others, not robots who help themselves","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2014.6926262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937552129&doi=10.1109%2fROMAN.2014.6926262&partnerID=40&md5=752f0cf2f56d804937ab84c1ea24d172","Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot. © 2014 IEEE.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","255-260","","","2014-October","","","","","","","","","","","","","","","","","Issue: October","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PF7SC8E4","conferencePaper","2014","Sejima, Y.; Watanabe, T.; Jindai, M.","Development of an interaction-activated communication model based on a heat conduction equation in voice communication","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2014.6926356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937538530&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=91ef1fc789e5cfd5dd2329481e79a23e","In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication. © 2014 IEEE.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","832-837","","","2014-October","","","","","","","","","","","","","","","","","Issue: October","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G3TYP25J","journalArticle","2014","Hofree, G.; Ruvolo, P.; Bartlett, M.S.; Winkielman, P.","Bridging the mechanical and the human mind: Spontaneous mimicry of a physically present android","PLoS ONE","","","10.1371/journal.pone.0099934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904490592&doi=10.1371%2fjournal.pone.0099934&partnerID=40&md5=160e9e9b43fd8eecd3d04c3cb2e090d0","The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users. © 2014 Hofree et al.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","","","7","9","","","","","","","","","","","","","","","","","","<p>cited By 25</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDDRERIE","journalArticle","2014","Rosenthal-Von Der Pütten, A.M.; Schulte, F.P.; Eimler, S.C.; Sobieraj, S.; Hoffmann, L.; Maderwald, S.; Brand, M.; Krämer, N.C.","Investigations on empathy towards humans and robots using fMRI","Computers in Human Behavior","","","10.1016/j.chb.2014.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893955979&doi=10.1016%2fj.chb.2014.01.004&partnerID=40&md5=28e6e8e0f0617f9322528b0c8ae2a8b6","Although robots are starting to enter into our professional and private lives, little is known about the emotional effects they elicit. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots, we conducted a study that provides further insights into the question of whether humans show emotional reactions towards a robot and whether these reactions differ from those towards a human. To explore emotionality in human-robot interaction we conducted an fMRI study (n = 14). Participants were presented videos showing a human, a robot and an inanimate object, being treated in either an affectionate or in a violent way. Self-reported emotional states and functional imaging data revealed that participants indeed reacted emotionally when seeing the affectionate and violent videos. While no different neural activation patterns emerged for the affectionate interaction towards both, the robot and the human, we found differences in neural activity when comparing only the videos showing abusive behavior indicating that participants experience more emotional distress and show negative empathetic concern for the human in the abuse condition. This was supported by similar findings with regard to participant's self-reported emotional states. © 2014 Elsevier Ltd. All rights reserved.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","201-212","","","33","","","","","","","","","","","","","","","","","","<p>cited By 58</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KLHWQGF","journalArticle","2014","Boucenna, S.; Gaussier, P.; Hafemeister, L.","Development of first social referencing skills: Emotional interaction as a way to regulate robot behavior","IEEE Transactions on Autonomous Mental Development","","","10.1109/TAMD.2013.2284065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897900303&doi=10.1109%2fTAMD.2013.2284065&partnerID=40&md5=be7811d799d82165d41f45eb2bf0ebe1","In this paper, we study how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensory-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some 'empathy' or at least 'resonate' with the robot head (low level emotional resonance). Hence, we advocate the idea that social referencing can be bootstrapped from a simple sensory-motor system not dedicated to social interactions. © 2014 IEEE.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","42-55","","1","6","","","","","","","","","","","","","","","","","","<p>cited By 16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KKKYDFEP","conferencePaper","2014","Chumkamon, S.; Hayashi, E.","ConBe robot: The development of self-perception and expression in face-to-face interaction","2014 Joint 7th International Conference on Soft Computing and Intelligent Systems, SCIS 2014 and 15th International Symposium on Advanced Intelligent Systems, ISIS 2014","","","10.1109/SCIS-ISIS.2014.7044703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946531137&doi=10.1109%2fSCIS-ISIS.2014.7044703&partnerID=40&md5=51b3b861908f3facf3b820b97d69b54f","In social robot development of interaction system robot, it is necessary to develop the fundamental function such as the robot perception. Due to the robot should correctly interpret a behavior or mental expression of the human. If the robot has a good emotional insight of the human, it is the advantage for the robot perception. In this paper, we implement the significant technique that take an advantage to the robot such as the human detection, face detection and recognition. Basically, these techniques could further enable the robot capability of intelligent empathy from the expression of human. We intensively study the vision method for facial expression recognition (FER) to understanding the human emotion and interacting by the robot expression in particular case. The robot interaction is based on the interested person that the robot can recognize with their emotional expression. We also experiment the system in term of face-to-face between robot and user with demonstrate using the head robot along with the result, such as the performance of the perception and the behavior expression of the robot. © 2014 IEEE.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","769-775","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VH9Q6SP","conferencePaper","2014","Tsuji, Y.; Tsukamoto, A.; Uchida, T.; Hattori, Y.; Nishida, R.; Fukada, C.; Ozeki, M.; Omori, T.; Nagai, T.; Oka, N.","Experimental study of empathy and its behavioral indices in Human-Robot interaction","HAI 2014 - Proceedings of the 2nd International Conference on Human-Agent Interaction","","","10.1145/2658861.2658933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914703944&doi=10.1145%2f2658861.2658933&partnerID=40&md5=16221be63a9e817ee01369d52d6d7c36","Similar to relationships between humans, a person desiring to form a good relationship with a robot needs to be able to empathize with it. However, the specific kinds of human-robot interactions that would arouse and enhance empathy for the robot in the user's mind have not yet been clarified. In addition, the human behavioral traits that may be regarded as indices of empathy have not been investigated extensively. In an attempt to address these two issues, a preliminary experiment on empathy in human-robot interaction is conducted. The results suggest that the actions of naming or comforting a robot could contribute to enhancing its user's empathy and that eye fixation could be used as an index of empathy even when the use of a subjective index is inconclusive.","2014","2021-02-15 22:35:28","2021-02-15 22:35:28","","245-248","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q9VC3VK","journalArticle","2014","Yamazaki, R.","Conditions of empathy in human-robot interaction","Frontiers in Artificial Intelligence and Applications","","","10.3233/978-1-61499-480-0-179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922515215&doi=10.3233%2f978-1-61499-480-0-179&partnerID=40&md5=d468a5cfbde95954321cabda5ce7ab22","The purpose of this paper is to consider the sociality of social robots with the focus on the notion of empathy. Social robots are designed to exploit various biological mechanisms that trigger anthropomorphizing reactions in humans and systems that seem capable of experiencing or feeling are being constructed. A question is whether empathic reactions by humans are justifiable from a conceptual and ethical point of view. I will mainly address the conceptual strand of this question and investigate whether empathy with robots is appropriate or misapplied relative to our current concept of empathy. © 2014 The authors and IOS Press. All rights reserved.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","179-186","","","273","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"279PGW4T","conferencePaper","2014","Obaid, M.; Kuchenbrandt, D.; Bartneck, C.","Empathy and yawn contagion: Can we (Humans) catch yawns from robots?","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2559636.2563702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896926638&doi=10.1145%2f2559636.2563702&partnerID=40&md5=43372d1b56dc6c0a1c12425952a546cc","Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","260-261","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGSQHUF2","conferencePaper","2014","Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.","People help robots who help others, not robots who help themselves","IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions","","","10.1109/ROMAN.2014.6926262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937566083&doi=10.1109%2fROMAN.2014.6926262&partnerID=40&md5=9fe071102df11945351c6d32dccf993a","Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot. © 2014 IEEE.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","255-260","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTNQ8HHX","journalArticle","2014","Redstone, J.","Making sense of empathy with social robots","Frontiers in Artificial Intelligence and Applications","","","10.3233/978-1-61499-480-0-171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922487652&doi=10.3233%2f978-1-61499-480-0-171&partnerID=40&md5=3b8962d6d462d30230135087952c79a4","Social robots exploit human-like behaviors so that people might form emotional bonds with them. Ostensibly, such bonding is an empathic response on the part of the person toward the robot. However, as philosopher Catrin Misselhorn points out, it's conceptually problematic to say that people empathize with robots, for the social robots of the present arguably don't possess human-like emotions. To address this concern, Misselhorn proposes that empathy with robots is possible owing to a sort of interplay between perception and imagination that she calls 'imaginative perception.' In this paper, I shall make a preliminary sketch of a conceptual framework that, I argue, serves as a clearer, more conceptually straight-forward alternative to imaginative perception. On this framework, empathy with social robots is the result of a kind of perceptual illusion, rather than the result of the imaginative perception of emotion. © 2014 The authors and IOS Press. All rights reserved.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","171-177","","","273","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3BHWD9P","conferencePaper","2014","Baumgaertner, B.; Weiss, A.","Do emotions matter in the ethics of human-robot interaction? - Artificial empathy and companion robots","AISB 2014 - 50th Annual Convention of the AISB","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907404285&partnerID=40&md5=601ad60390ef3f89eeeb3e60d5ef1d62","In this position statement we shall argue that emotions are not directly relevant in the ethics of human-robot interaction, particularly in the context of robot care-givers and human care-receivers. Our argument is based on (1) current theories of emotion and (2) empirical findings on organizational emotion research in health care.We use a thought experiment to guide the reader through aspects of emotional empathy that support our conclusion. Our general argument is that what matters to care behavior is just the relevant behavior, not the source that drives the behavior. Our reflection will show that emotional deception may not directly impact the care-receiver (as often assumed in HRI) but more relevantly other care personnel.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZ34PVBB","conferencePaper","2014","Mok, B.; Yang, S.; Sirkin, D.; Ju, W.","Empathy: Interactions with emotive robotic drawers","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2559636.2563720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896930170&doi=10.1145%2f2559636.2563720&partnerID=40&md5=4c2bc80edba4918c82e8ba556bcdf4ca","The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - Angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","250-251","","","","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSMJR8MG","journalArticle","2014","Gou, M.S.; Vouloutsi, V.; Grechuta, K.; Lallée, S.; Verschure, P.F.M.J.","Empathy in humanoid robots","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-09435-9_50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905240698&doi=10.1007%2f978-3-319-09435-9_50&partnerID=40&md5=feaef6aa957d395fb24bd3ed5dd63cdd","Humanoid robots should be able to interact with humans in a familiar way since they are going to play a significant role in the future. Thus, it is necessary that Human-Robot Interaction (HRI) is designed in such a way that allows humans to communicate with robots effortlessly and naturally. Emotions play an important role in this interaction since humans feel more predisposed to interact with robots if they are able to create an affective bond with them. In this study, we want to know whether humans are able to empathize with a humanoid robot. Therefore, in the present research, we are going to recreate a Milgram experiment in which we expect participants to empathize with the robot while playing a matching game. Like in Milgram's experiment, they will have to give fake electrical shocks to the robot thinking that they are punishing it. In that way, an empathic state, which we expect to see in our results, may be induced. © 2014 Springer International Publishing.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","423-426","","","8608 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFEEPK6I","conferencePaper","2014","Fraga, L.; Coelho, A.; Branco, P.","Meet the frumbles-A post-digital toy orchestra","ACM International Conference Proceeding Series","","","10.1145/2663806.2663813","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938392555&doi=10.1145%2f2663806.2663813&partnerID=40&md5=76c17d07ebb1f60cbdedc94bbd5183c6","""Meet the Frumbles"" is a group of felt robotic characters that talk amongst themselves and interact with the audience. Empathy, cuteness and gags are explored as communicational facilitators and ludic interaction between a felt robot creature's orchestra and its human conductor. Creative coding using computer vision, electronic prototyping and physical actuators was used to implement the autonomous physical existence, sensing and behavior of creatures. Copyright © 2014 ACM.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","","","","2014-November","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2QEKFASJ","conferencePaper","2014","Sejima, Y.; Watanabe, T.; Jindai, M.","Development of an interaction-Activated communication model based on a heat conduction equation in voice communication","IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions","","","10.1109/ROMAN.2014.6926356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937573084&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=22e427095e4bdb9f1b57facf7adeb784","In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-Activated communication model based on the heat conduction equation in heat-Transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-Activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-Activated communication. © 2014 IEEE.","2014","2021-02-15 22:35:29","2021-02-15 22:35:29","","832-837","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAXSL2Y9","conferencePaper","2013","Kwak, S.S.; Kim, Y.; Kim, E.; Shin, C.; Cho, K.","What makes people empathize with an emotional robot?: The impact of agency and physical embodiment on human empathy for a robot","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2013.6628441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889583757&doi=10.1109%2fROMAN.2013.6628441&partnerID=40&md5=10cee47cd33839f55e4ca124f8091bd9","As empathy is important for the emotional interaction between a human and a robot, the design factors which induce human empathy toward robots need to be explored. Human empathy toward a robot can be affected by the presence of a robot. Thus, we focused on the levels of agency and the physical embodiment of a robot, which are influential factors pertaining to social presence, by executing two experiments. In the first experiment, in a 2 (levels of agency: mediated vs. simulated) between-participants experiment, participants interacted with either a mediated robot which delivers the emotional state of a remote user or a simulated robot which expresses its own emotion. Participants empathized more with the mediated robot than with the simulated robot, demonstrating that the proper form of an emotional robot is as a mediator during emotional interaction between people. In the second study, in a 2 (physical embodiment: physically embodied vs. physically disembodied) between-participants experiment design, participants interacted with either a physically embodied robot or a physically disembodied robot. The results showed that participants empathized more with a physically embodied robot than with a physically disembodied robot, indicating the impact of physical embodiment on human empathy. Implications for the design of human-robot interactions are discussed. © 2013 IEEE.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","180-185","","","","","","","","","","","","","","","","","","","","","<p>cited By 49</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPPSIY9B","conferencePaper","2013","Marti, P.; Iacono, I.; Tittarelli, M.; Stienstra, J.","Shaping empathy through perspective taking","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2013.6628403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889605391&doi=10.1109%2fROMAN.2013.6628403&partnerID=40&md5=c90b77dbc8dda0f686c942f72e051ecd","This paper describes an explorative study to evaluate a dynamic expressive mask associated to a remote robot-view used to control an assistive robot. The mask is generated by a graphical-user-interface platform displayed on a tablet used to control the robot in a smart home environment. The hypothesis of the study is that when robot's behaviour conforms to human social expectations, interactions are more likely to be found enjoyable and meaningful by people. Furthermore the expressivity of the mask is expected to result in empathic interactions with the robot and therefore to sustain rich and meaningful social exchanges. In this study we compared four scenarios of interaction between a robot and a person at home. The scenarios depicted scenes where the robot was asked to execute tasks. Each scenario was showed in two versions: with a static robot-view and with a dynamic, expressive robot-view. The results of a questionnaire administered to 60 persons showed a preference of people to interact with the dynamic expressive mask. Expressivity was a means to stimulate empathic concern and to facilitate perspective taking during the execution of the scenarios. © 2013 IEEE.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","751-756","","","","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIL9C6DU","journalArticle","2013","Haffey, A.; Press, C.; O'Connell, G.; Chakrabarti, B.","Autistic traits modulate mimicry of social but not nonsocial rewards","Autism Research","","","10.1002/aur.1323","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890791615&doi=10.1002%2faur.1323&partnerID=40&md5=92c1fa7dd324146ab56c658894e4a084","Autism Spectrum Conditions (ASC) are associated with diminished responsiveness to social stimuli, and especially to social rewards such as smiles. Atypical responsiveness to social rewards, which reinforce socially appropriate behavior in children, can potentially lead to a cascade of deficits in social behavior. Individuals with ASC often show diminished spontaneous mimicry of social stimuli in a natural setting. In the general population, mimicry is modulated both by the reward value and the sociality of the stimulus (i.e., whether the stimulus is perceived to belong to a conspecific or an inanimate object). Since empathy and autistic traits are distributed continuously in the general population, this study aimed to test if and how these traits modulated automatic mimicry of rewarded social and nonsocial stimuli. High and low rewards were associated with human and robot hands using a conditioned learning paradigm. Thirty-six participants from the general population then completed a mimicry task involving performing a prespecified hand movement which was either compatible or incompatible with a hand movement presented to the participant. High autistic traits (measured using the Autism Spectrum Quotient, AQ) predicted lesser mimicry of high-reward than low-reward conditioned human hands, whereas trait empathy showed an opposite pattern of correlations. No such relations were observed for high-reward vs. low-reward conditioned robot hands. These results demonstrate how autistic traits and empathy modulate the effects of reward on mimicry of social compared to nonsocial stimuli. This evidence suggests a potential role for the reward system in underlying the atypical social behavior in individuals with ASC, who constitute the extreme end of the spectrum of autistic traits. © 2013 International Society for Autism Research, Wiley Periodicals, Inc.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","614-620","","6","6","","","","","","","","","","","","","","","","","","<p>cited By 14</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAGXIXSX","journalArticle","2013","Kühnlenz, B.; Sosnowski, S.; Buß, M.; Wollherr, D.; Kühnlenz, K.; Buss, M.","Increasing Helpfulness towards a Robot by Emotional Adaption to the User","International Journal of Social Robotics","","","10.1007/s12369-013-0182-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886781468&doi=10.1007%2fs12369-013-0182-2&partnerID=40&md5=3841f37f6837c58790a3c7feae6fd93f","This article describes an emotional adaption approach to proactively trigger increased helpfulness towards a robot in task-related human-robot interaction (HRI). Based on social-psychological predictions of human behavior, the approach aims at inducing empathy, paired with a feeling of similarity in human users towards the robot. This is achieved by two differently expressed emotional control variables: by an explicit statement of similarity before task-related interaction, and implicitly expressed by adapting the emotional state of the robot to the mood of the human user, such that the current values of the human mood in the dimensions of pleasure, arousal, and dominance (PAD) are matched. The thereby shifted emotional state of the robot serves as a basis for the generation of task-driven emotional facial- and verbal expressions, employed to induce and sustain high empathy towards the robot throughout the interaction. The approach is evaluated in a user study utilizing an expressive robot head. The effectiveness of the approach is confirmed by significant experimental results. An analysis of the individual components of the approach reveals significant effects of explicit emotional adaption on helpfulness, as well as on the HRI-key concepts anthropomorphism and animacy. © 2013 Springer Science+Business Media Dordrecht.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","457-476","","4","5","","","","","","","","","","","","","","","","","","<p>cited By 30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFQGRHHT","journalArticle","2013","Moussa, M.B.; Magnenat-Thalmann, N.","Toward socially responsible agents: Integrating attachment and learning in emotional decision-making","Computer Animation and Virtual Worlds","","","10.1002/cav.1515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877874878&doi=10.1002%2fcav.1515&partnerID=40&md5=42d30568a9bb3aebd86ac51a9fa1491f","Our goal is to create socially responsible agents, either robots or virtual humans. In this paper, we present an integration of emotions, attachment, and learning in emotional decision-making to achieve this goal. Based on emerging psychological theories, we aim at building human-like emotional decision-making, where emotions play a central role in selecting the next action to be performed by the agent. Here, we present our own approach for emotion appraisal where we use emotional attachment as an important impulse for determining the intensities of emotions. Emotions in their turn are used to calculate the emotional attachment toward the users and for learning to predict future consequences. We report on the results of a simulation evaluation where we assess the influence of emotions, attachment, and learning on decision-making. It is our strong belief that by giving an agent the ability to have emotions and to feel empathy and emotional attachment toward others, we will ultimately give this agent the ability to learn and improve its social behavior skills through interactions with the users and through user feedback. Copyright © 2013 John Wiley & Sons, Ltd.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","327-334","","3-4","24","","","","","","","","","","","","","","","","","","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBFKB67S","conferencePaper","2013","Plant, N.; Healey, P.G.T.","Surface Tension","Conference on Human Factors in Computing Systems - Proceedings","","","10.1145/2468356.2479589","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040727714&doi=10.1145%2f2468356.2479589&partnerID=40&md5=9a87b07b1b9698f79ac1c66418476b1c","The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?.","2013","2021-02-15 22:35:29","2021-02-15 22:35:29","","2979-2982","","","2013-April","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKT23DV2","conferencePaper","2013","Rosenthal-Von Der Pütten, A.M.; Schulte, F.P.; Eimler, S.C.; Hoffmann, L.; Sobieraj, S.; Maderwald, S.; Krämer, N.C.; Brand, M.","Neural correlates of empathy towards robots","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1109/HRI.2013.6483578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875695930&doi=10.1109%2fHRI.2013.6483578&partnerID=40&md5=b280b07156fa005c0d3d86ebe820c650","We conducted an fMRI study to investigate emotionality in human-robot interaction. Subjects (N=14) were presented videos showing a human, a robot and an unanimated object, being treated in either an affectionate or a violent way. Violent interaction towards both the robot and the human resulted in similar neural activation patterns in classic limbic structures indicating that both the robot and the human elicit similar emotional reactions. However, differences in neural activity suggest that participants show more negative empathetic concern for the human in a negative situation. © 2013 IEEE.","2013","2021-02-15 22:35:30","2021-02-15 22:35:30","","215-216","","","","","","","","","","","","","","","","","","","","","<p>cited By 21</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DNC57VY","conferencePaper","2013","Jo, D.; Han, J.; Chung, K.; Lee, S.","Empathy between human and robot?","ACM/IEEE International Conference on Human-Robot Interaction","","","10.1109/HRI.2013.6483546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875753667&doi=10.1109%2fHRI.2013.6483546&partnerID=40&md5=95cc534f086bc47fdb87cdc2edab4133","This paper aims at finding the answer to the essential question: Can people perceive a robot's presence as having a social existence? We attempt to apply a sociological and psychological approach to understand the influence of robot beings, by observing human emotion and perception changes while subjects watched a funny video clip in the presence of a robot or a human companion, each of which made their own typical laughing sounds. From this experiment, we found that the robot did not affect the human's positive emotions as much as a human companion did, but the robot did discourage negative emotions. However, the subjects were, in general, amused when they were watching the video with the robot. This amusement is similar to the contagious effect of sharing humor with another human being. Our findings suggest that the subjects accepted the robot's presence as a kind of existence empathically. © 2013 IEEE.","2013","2021-02-15 22:35:30","2021-02-15 22:35:30","","151-152","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPK69ADW","journalArticle","2013","Niculescu, A.; van Dijk, B.; Nijholt, A.; Li, H.; See, S.L.","Making Social Robots More Attractive: The Effects of Voice Pitch, Humor and Empathy","International Journal of Social Robotics","","","10.1007/s12369-012-0171-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876427330&doi=10.1007%2fs12369-012-0171-x&partnerID=40&md5=e5170bc6f627cbe2b4e6b47229b7ac0e","In this paper we explore how simple auditory/verbal features of the spoken language, such as voice characteristics (pitch) and language cues (empathy/humor expression) influence the quality of interaction with a social robot receptionist. For our experiment two robot characters were created: Olivia, the more extrovert, exuberant, and humorous robot with a higher voice pitch and Cynthia, the more introvert, calmer and more serious robot with a lower voice pitch. Our results showed that the voice pitch seemed to have a strong influence on the way users rated the overall interaction quality, as well as the robot's appeal and overall enjoyment. Further, the humor appeared to improve the users' perception of task enjoyment, robot personality and speaking style while the empathy showed effects on the way users evaluated the robot's receptive behavior and the interaction ease. With our study, we would like to stress in particular the importance of voice pitch in human robot interaction and to encourage further research on this topic. © 2012 Springer Science+Business Media Dordrecht.","2013","2021-02-15 22:35:30","2021-02-15 22:35:30","","171-191","","2","5","","","","","","","","","","","","","","","","","","<p>cited By 82</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXWIZIRY","journalArticle","2013","Leite, I.; Pereira, A.; Mascarenhas, S.; Martinho, C.; Prada, R.; Paiva, A.","The influence of empathy in human-robot relations","International Journal of Human Computer Studies","","","10.1016/j.ijhcs.2012.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870847748&doi=10.1016%2fj.ijhcs.2012.09.005&partnerID=40&md5=24b444eb789fafcc1eccc1fe602b1bec","The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human-robot interaction. © 2012 Elsevier Ltd. All rights reserved.","2013","2021-02-15 22:35:30","2021-02-15 22:35:30","","250-260","","3","71","","","","","","","","","","","","","","","","","","<p>cited By 91</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7GNT6M2","journalArticle","2013","Urgen, B.A.; Plank, M.; Ishiguro, H.; Poizner, H.; Saygin, A.P.","EEG theta and Mu oscillations during perception of human and robot actions","Frontiers in Neurorobotics","","","10.3389/fnbot.2013.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899682291&doi=10.3389%2ffnbot.2013.00019&partnerID=40&md5=b4aae2154c5beca9ef9fffd9bde2d77a","The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin.","2013","2021-02-15 22:35:30","2021-02-15 22:35:30","","","","NOV","7","","","","","","","","","","","","","","","","","","<p>cited By 34</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9N64EVDF","conferencePaper","2012","Stienstra, J.; Marti, P.","Squeeze me: Gently please","NordiCHI 2012: Making Sense Through Design - Proceedings of the 7th Nordic Conference on Human-Computer Interaction","","","10.1145/2399016.2399131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871548513&doi=10.1145%2f2399016.2399131&partnerID=40&md5=7ea7f0a39509c35dee111044bead8f9d","This paper presents the Squeeze Me, a research-throughdesign case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a doublelayered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge. Copyright © 2012 ACM.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","746-750","","","","","","","","","","","","","","","","","","","","","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMM8BFKJ","conferencePaper","2012","Wallach, W.; Allen, C.","Hard problems: Framing the Chinese room in which a robot takes a moral turing test","AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893196594&partnerID=40&md5=984e7b89899e5cf0d4d527848dc72d3b","Research on approaches for implementing moral decision-making capabilities within AI systems is contributing to a more comprehensive understanding of moral acumen. In addition to being able to reason, consciousness and understanding, a theory of mind, social skills, cooperating with other agents, the ability to solve frame problems, being embodied, empathy, and feeling pleasure and pain may be required for agents to successfully select morally acceptable courses of action within certain domains. The multifaceted nature of moral intelligence complicates both the task of designing artificial moral agents (AMAs) and the challenge of evaluating whether an artificial agent can make safe, legal, and appropriate decisions. Confronted with a somewhat comparable difficulty in determining whether a machine can think, Alan Turing [1] proposed his now famous imitation game. Fifty years later, Colin Allen, Gary Varner, and Jason Zinser [2] suggested a variant of the test: a moral Turing test (MTT). Within some limited domains, reason alone is sufficient for making moral judgments, and moral intelligence may be tested by using the traditional conversational method of posing a question and comparing the AI system's response to that of a human. However, evaluating an artificial agent's ability to accommodate a variety of moral considerations, including some that are difficult to quantify or describe, will necessitate testing it in complex situations. Consider the ability of an artificial agent to deduce the beliefs, desires, and intentions of other agents so that it might work cooperatively with them on a shared task, to distinguish a combatant from a non-combatant during guerrilla warfare, to discern that it is in a morally significant situation, or to discriminate which of many concurrent challenges it should respond to first. These tasks are not easy for humans, and yet we bring resources to bear in tackling such challenges that will be hard to reproduce artificially. Evaluating whether AI systems can manage such tasks sufficiently will either require special variants of the MTT, or they reveal the inadequacy of a MTT for evaluating the moral intelligence of artificial systems.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWJUGWJT","journalArticle","2012","Damiano, L.; Dumouchel, P.; Lehmann, H.","Should empathic social robots have interiority?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-34103-8_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868703579&doi=10.1007%2f978-3-642-34103-8_27&partnerID=40&md5=273e4818c6cd8d4ff043f7c125f0658c","In this article we discuss whether robots need ""interiority"" in order to competently participate in emotional and empathic dynamics with human partners. We draw on original research on emotions, mind, neurophysiological mechanisms of social interaction and HRI to contest the common sense thesis according to which robots without ""interiority"" can only simulate emotions and empathy, to the extent that the affective (emotional and empathic) relationships between them and humans would not be authentic. The main thesis of our article is that empathic social robots do not need ""interiority"", but the ability of dynamical coordination with their social partners and the surrounding environment(s), since this ability (and not ""interiority"") is at the basis of human cognitive and affective (emotional and empathic) activity. © 2012 Springer-Verlag.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","268-277","","","7621 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBUMQVMH","journalArticle","2012","Lim, A.; Okuno, H.G.","Using speech data to recognize emotion in human gait","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-34014-7_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867628984&doi=10.1007%2f978-3-642-34014-7_5&partnerID=40&md5=7ab30baab585123d34f2f79cae6da69f","Robots that can recognize emotions can improve humans' mental health by providing empathy and social communication. Emotion recognition by robots is challenging because unlike in human-computer environments, facial information is not always available. Instead, our method proposes using speech and gait analysis to recognize human emotion. Previous research suggests that the dynamics of emotional human speech also underlie emotional gait (walking). We investigate the possibility of combining these two modalities via perceptually common parameters: Speed, Intensity, irRegularity, and Extent (SIRE). We map low-level features to this 4D cross-modal emotion space and train a Gaussian Mixture Model using independent samples from both voice and gait. Our results show that a single, modality-mixed trained model can perform emotion recognition for both modalities. Most interestingly, recognition of emotion in gait using a model trained uniquely on speech data gives comparable results to a model trained on gait data alone, providing evidence for a common underlying model for emotion across modalities. © 2012 Springer-Verlag.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","52-64","","","7559 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EL76M4M","conferencePaper","2012","Gonsior, B.; Buß, M.; Sosnowski, S.; Wollherr, D.; Kuhnlenz, K.; Buss, M.","Towards transferability of theories on prosocial behavior from Social Psychology to HRI","Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO","","","10.1109/ARSO.2012.6213407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863676143&doi=10.1109%2fARSO.2012.6213407&partnerID=40&md5=e83b24886eae05fe86baff1e203e9ffd","This paper describes the transfer of theories on prosocial behavior from Social Psychology to human-robot interaction (HRI) in terms of helpfulness shown by humans towards a robot. Theoretical foundations are given, and relevant influence factors for prosocial behavior are defined. The paper provides an overview on how these factors can be transferred to HRI and are implemented in two experimental settings. In a first experiment, situational empathy towards a robot is increased. In a second experiment, similarity is induced by means of emotional adaption to the mood of the user. Results show that helpfulness towards a robot can be increased by this approach, thus, re-evaluating the transferability of theories from Social Psychology to HRI. © 2012 IEEE.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","101-103","","","","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ4Z3MQD","journalArticle","2012","Mori, M.; MacDorman, K.F.; Kageki, N.","The uncanny valley","IEEE Robotics and Automation Magazine","","","10.1109/MRA.2012.2192811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862286533&doi=10.1109%2fMRA.2012.2192811&partnerID=40&md5=8a553f5c078346018240a4c24a66346e","Recently, the concept of the uncanny valley has rapidly attracted interest in robotics and other scientific circles as well as in popular culture. According to Masahiro Mori, a robotics professor at the Tokyo Institute of Technology, who first researched on this subject, a person's response to a humanlike robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance. This descent into eeriness is known as the uncanny valley. As healthy persons, we are represented at the second peak (moving). Then when we die, we are unable to move; the body goes cold, and the face becomes pale. Therefore, our death can be regarded as a movement from the second peak (moving) to the bottom of the uncanny valley (still). Researchers should begin to build an accurate map of the uncanny valley so that through robotics research they can begin to understand what makes them human.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","98-100","","2","19","","","","","","","","","","","","","","","","","","<p>cited By 776</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W5C5JS63","journalArticle","2012","Glaskin, K.","Empathy and the robot: A neuroanthropological analysis","Annals of Anthropological Practice","","","10.1111/j.2153-9588.2012.01093.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866548084&doi=10.1111%2fj.2153-9588.2012.01093.x&partnerID=40&md5=59405e41826fbe02a20a7f7938bacf29","Roboticists developing socially interactive robots seek to design them in such a way that humans will readily anthropomorphize them. For this anthropomorphizing to occur, robots need to display emotion-like responses to elicit empathy from the person, so as to enable social interaction. This article focuses on roboticists' efforts to create emotion-like responses in humanoid robots. In particular, I investigate the extent to which the cultural dimensions of emotion and empathy are factored into these endeavors. Recent research suggests that mirror neurons or other brain structures may have a role to play in empathy and imitation. Notwithstanding this, the effect of sociocultural experience in shaping appropriate empathic responses and expectations is also crucial. More broadly, this article highlights how we are literally anthropomorphizing technology, even as the complexity of technology and the role it plays in our lives grows. Both the actual design process and the understanding of how technology shapes our daily lives are core applied dimensions of this work, from carrying out the research to capturing the critical implications of these technological innovations. © 2012 by the American Anthropological Association.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","68-87","","1","36","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ASZI9PM6","conferencePaper","2012","Leite, I.; Castellano, G.; Pereira, A.; Martinho, C.; Paiva, A.","Modelling empathic behaviour in a robotic game companion for children: An ethnographic study in real-world settings","HRI'12 - Proceedings of the 7th Annual ACM/IEEE International Conference on Human-Robot Interaction","","","10.1145/2157689.2157811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859967043&doi=10.1145%2f2157689.2157811&partnerID=40&md5=b23b27299cb277eaa16dabb494d6a6df","The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with. © 2012 ACM.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","367-374","","","","","","","","","","","","","","","","","","","","","<p>cited By 62</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FEMLUSHV","journalArticle","2012","Leite, I.; Pereira, A.; Castellano, G.; Mascarenhas, S.; Martinho, C.; Paiva, A.","Modelling empathy in social robotic companions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-28509-7_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857580365&doi=10.1007%2f978-3-642-28509-7_14&partnerID=40&md5=b66eeaac8dbba75981f970bfbce5eb6b","Empathy can be broadly defined as the ability to understand and respond appropriately to the affective states of others. In this paper, we present a scenario where a social robot acts as a chess companion for children, and describe our current efforts towards endowing such robot with empathic capabilities. A multimodal framework for modeling some of the user's affective states that combines visual and task-related features is presented. Using this model of the user, we personalise the learning environment by adapting the robot's empathic responses to the particular preferences of the child who is interacting with the robot. We also describe a preliminary study conducted in this scenario. © 2012 Springer-Verlag.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","135-147","","","7138 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 40</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQN8Y2B4","journalArticle","2012","Beck, A.; Stevens, B.; Bard, K.A.; Cañamero, L.","Emotional body language displayed by artificial agents","ACM Transactions on Interactive Intelligent Systems","","","10.1145/2133366.2133368","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983513884&doi=10.1145%2f2133366.2133368&partnerID=40&md5=81b4e97a2648aa1e21e58e61ae07a3ee","Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots. © 2012 ACM.","2012","2021-02-15 22:35:30","2021-02-15 22:35:30","","","","1","2","","","","","","","","","","","","","","","","","","<p>cited By 43</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QN6B9WU5","conferencePaper","2011","Mazzei, D.; Lazzeri, N.; Billeci, L.; Igliozzi, R.; Mancini, A.; Ahluwalia, A.; Muratori, F.; De Rossi, D.","Development and evaluation of a social robot platform for therapy in autism","Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS","","","10.1109/IEMBS.2011.6091119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863580441&doi=10.1109%2fIEMBS.2011.6091119&partnerID=40&md5=ef2cf1468c54887befa6d75b94330654","People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred affective state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training. © 2011 IEEE.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","4515-4518","","","","","","","","","","","","","","","","","","","","","<p>cited By 28</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTZULK5M","journalArticle","2011","Pereira, A.; Leite, I.; Mascarenhas, S.; Martinho, C.; Paiva, A.","Using empathy to improve human-robot relationships","Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","","","10.1007/978-3-642-19385-9_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885883906&doi=10.1007%2f978-3-642-19385-9_17&partnerID=40&md5=9619e98158ace82186d35585fcfef530","For robots to become our personal companions in the future, they need to know how to socially interact with us. One defining characteristic of human social behaviour is empathy. In this paper, we present a robot that acts as a social companion expressing different kinds of empathic behaviours through its facial expressions and utterances. The robot comments the moves of two subjects playing a chess game against each other, being empathic to one of them and neutral towards the other. The results of a pilot study suggest that users to whom the robot was empathic perceived the robot more as a friend. © ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering 2011.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","130-138","","","59 LNICST","","","","","","","","","","","","","","","","","","<p>cited By 30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBRE45I3","journalArticle","2011","Syrdal, D.S.; Nomura, T.; Hirai, H.; Dautenhahn, K.","Examining the Frankenstein Syndrome: An open-ended cross-cultural survey","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-25504-5_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155166431&doi=10.1007%2f978-3-642-25504-5_13&partnerID=40&md5=eed0d3a7848398bcdea4116602779f7f","This paper reports findings from an open-ended survey on attitudes towards humanoid robots collected from samples in the United Kingdom and Japan. 335 participants were asked how they felt about humanoid robots becoming widespread in society and what tasks they wanted humanoid robots to perform. While the UK sample was overall less negative towards humanoid robots than their Japanese counterparts, the UK sample did not want robots to perform tasks that required capabilities deemed as human qualities, such as empathy, caring, or independent decision making. © 2011 Springer-Verlag.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","125-134","","","7072 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VY7XT443","journalArticle","2011","Bickmore, T.; Pfeifer, L.; Schulman, D.","Relational agents improve engagement and learning in science museum visitors","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-23974-8_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053188794&doi=10.1007%2f978-3-642-23974-8_7&partnerID=40&md5=a953ddc287a525d045d246ae2d972cfe","A virtual museum guide agent that uses human relationship-building behaviors to engage museum visitors is described. The agent, named ""Tinker"", appears in the form of a human-sized anthropomorphic robot, and uses nonverbal conversational behavior, empathy, social dialogue, reciprocal self-disclosure and other relational behavior to establish social bonds with users. Tinker can describe exhibits in the museum, give directions, and discuss technical aspects of her own implementation. Results from an experiment involving 1,607 visitors indicate that the use of relational behavior leads to significantly greater engagement by museum visitors, measured by session length, number of sessions, and self-reported attitude, as well as learning gains, as measured by a knowledge test, compared to the same agent that did not use relational behavior. Implications for museum exhibits and intelligent tutoring systems are discussed. © 2011 Springer-Verlag.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","55-67","","","6895 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 39</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYZ4LGR9","conferencePaper","2011","Gonsior, B.; Sosnowski, S.; Mayer, C.; Blume, J.; Radig, B.; Wollherr, D.; Kuhnlenz, K.","Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2011.6005294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053019859&doi=10.1109%2fROMAN.2011.6005294&partnerID=40&md5=5d5d3a8ce9853510d7f865baff145c8d","In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application ""Akinator"" serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode. © 2011 IEEE.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","350-356","","","","","","","","","","","","","","","","","","","","","<p>cited By 46</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2SATBG27","journalArticle","2011","Mushiaki, S.","Chapitre 5. Neuroscience and nanotechnologies in Japan ? Beyond the hope and hype of converging technologies","Journal International de Bioethique","","","10.3917/jib.221.0089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155163375&doi=10.3917%2fjib.221.0089&partnerID=40&md5=c140a86972e32e4a780e7683f64c662f","Nanotechnologies are often said to be «converging» with other technologies like biotechnology, information technology, and cognitive science. And so-called «NBIC convergence» is thought to enable «enhancement» of human performance. First, I classify various kinds of enhancement. Second, I focus on the «cybernetic enhancement,» to which nanotechnologies are supposed to contribute, and analyze the connection and integration of humans with machines, which could lead to the cyborgization of human beings. Third, I examine the portrayal of robot/cyborg technology in Japanese popular media, point out the tendency to empathy or ensoulment concerning robots/cyborgs, and raise the question of «ethical issues of ethical enhancement.» Fourth, I compare nanotechnologies with neurotechnology and criticize the hype of «converging technologies.» Copyright 2011 ESKA. All rights reserved.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","89-97","","1-2","22","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MDHTW9G","journalArticle","2011","Leite, I.","Using adaptive empathic responses to improve long-term interaction with social robots","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-22362-4_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960289713&doi=10.1007%2f978-3-642-22362-4_48&partnerID=40&md5=334d2ce9b0459548ad46fa184320ec4d","The goal of this research is to investigate the effects of empathy and adaptive behaviour in long-term interaction between social robots and users. To address this issue, we propose an action selection mechanism that will allow a social robot to chose adaptive empathic responses, in the attempt to keep users engaged over several interactions. © 2011 Springer-Verlag.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","446-449","","","6787 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXW35QMY","journalArticle","2011","Angulo, C.; Comas, J.; Pardo, D.","Aibo JukeBox - A robot dance interactive experience","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-21498-1_76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957949420&doi=10.1007%2f978-3-642-21498-1_76&partnerID=40&md5=b0253c42d996edbaa78a9649c1237e40","This paper presents a human-robot interaction system based on the Aibo platform. This robot is both, complex and empathetic enough to generate a high level of interest from the user. The complete system is an interactive JukeBox intending to generate affective participation, i.e., empathy, from the user towards the robot and its behavior. This application is based on a robotic dance control system that generates movements adequate to the music rhythm using a stochastic controller. The user can interact with the system selecting or providing the songs to be danced by the robot. The application has been successfully presented in different non-scientific scenarios. © 2011 Springer-Verlag.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","605-612","","PART 2","6692 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQ3AX72C","journalArticle","2011","Mushiaki, S.","Neuroscience and nanotechnologies in Japan–beyond the hope and hype of converging technologies.","Journal international de bioéthique = International journal of bioethics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053313070&partnerID=40&md5=27a265c06fdb7cfa3778a5d44ec1c569","Nanotechnologies are often said to be ""converging"" with other technologies like biotechnology, information technology, and cognitive science. And so-called ""NBIC convergence"" is thought to enable ""enhancement"" of human performance. First, I classify various kinds of enhancement. Second, I focus on the ""cybernetic enhancement,"" to which nanotechnologies are supposed to contribute, and analyze the connection and integration of humans with machines, which could lead to the cyborgization of human beings. Third, I examine the portrayal of robot/cyborg technology in Japanese popular media, point out the tendency to empathy or ensoulment concerning robots/cyborgs, and raise the question of ""ethical issues of ethical enhancement."" Fourth, I compare nanotechnologies with neurotechnology and criticize the hype of ""converging technologies.""","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","91-97, 210-211","","1","22","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRWHV53U","conferencePaper","2011","Trappl, R.; Krajewski, M.; Ruttkay, Z.; Widrich, V.","Robots as companions: What can we learn from servants and companions in literature, theater, and film?","Procedia Computer Science","","","10.1016/j.procs.2011.12.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856455778&doi=10.1016%2fj.procs.2011.12.029&partnerID=40&md5=f06303ccb8971eb8c816f56957a1e181","Many researchers are working on developing robots into adequate partners, be it at the working place, be it at home or in leisure activities, or enabling elder persons to lead a self-determined, independent life. While quite some progress has been made in e.g. speech or emotion understanding, processing and expressing, the relations between humans and robots are usually only short-term. In order to build long-term, i.e. social relations, qualities like empathy, trust building, dependability, non-patronizing, and others will be required. But these are just terms and as such no adequate starting points to ""program"" these capacities even more how to avoid the problems and pitfalls in interactions between humans and robots. However, a rich source for doing this is available, unused until now for this purpose: artistic productions, namely literature, theater plays, not to forget operas, and films with their multitude of examples. Poets, writers, dramatists, screen-writers, etc. have studied for centuries the facets of interactions between persons, their dynamics, and the related snags. And since we wish for human-robot relations as master-servant relations - the human obviously being the master - the study of these relations will be prominent. A procedure is proposed, with four consecutive steps, namely Selection, Analysis, Categorization, and Integration. Only if we succeed in developing robots which are seen as servants we will be successful in supporting and helping humans through robots. © Selection and peer-review under responsibility of FET11 conference organizers and published by Elsevier B.V.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","96-98","","","7","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMDCP8DV","journalArticle","2011","Yamashiro, T.; Kawada, K.; Nagamatsu, M.; Yamamoto, T.","A practice of 'monozukuri' education featuring ""rescue robots production"" in an elementary school","Nihon Kikai Gakkai Ronbunshu, C Hen/Transactions of the Japan Society of Mechanical Engineers, Part C","","","10.1299/kikaic.77.1465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863072864&doi=10.1299%2fkikaic.77.1465&partnerID=40&md5=5e1a1697bcc104010d94c4107288ae1a","The problem of avoidance of science and technology learning is one of the big issues for education in Japan. Part of the problem might arise from the lack of experiences of so-called ""monozukuri"" or engineering design activities at elementary school levels. Hands on class room activities for elementary schools are developed including the followings. 1)Visual contents including robots in the real world, earthquake disasters, and robots engaging in rescue missions, 2)Using the same kind of body frame of the vehicle robot, four different types of prototype cars are prepared, which enable pupils to find the difference of the effect of gear-ratio, 3)Small cardboard parts called ""parts card"" for each component of the robot which enables pupils to develop their design by manipulating and placing the card to the body frame, 4)Mechanical models varying from simple to complex, multi-link structures. The results of the pre-post questionnaire shows that over 70% of pupils have positive feelings to ""monozukuri"" and shows 10% increase. The parts card facilitates design resulting that almost all design requires only minor modification. The image map method is used, the numbers of the concepts are increased by four points and its quality is improved. One of the objectives of this project is to enhance empathy; the ability to relate well to others. We examined the designs of pupils and found that a variety of equipments are added for disaster victims. © 2011 The Japan Society of Mechanical Engineers.","2011","2021-02-15 22:35:31","2021-02-15 22:35:31","","1465-1476","","776","77","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRKFDJM5","conferencePaper","2010","Beck, A.; Hiolle, A.; Mazel, A.; Cañamero, L.","Interpretation of emotional body language displayed by robots","AFFINE'10 - Proceedings of the 3rd ACM Workshop on Affective Interaction in Natural Environments, Co-located with ACM Multimedia 2010","","","10.1145/1877826.1877837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650424811&doi=10.1145%2f1877826.1877837&partnerID=40&md5=f082bcdd148bb341f0169829a4168370","In order for robots to be socially accepted and generate empathy they must display emotions. For robots such as Nao, body language is the best medium available, as they do not have the ability to display facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should greatly improve its acceptance. This research investigates the creation of an ""Affect Space"" [1] for the generation of emotional body language that could be displayed by robots. An Affect Space is generated by ""blending"" (i.e. interpolating between) different emotional expressions to create new ones. An Affect Space for body language based on the Circumplex Model of emotions [2] has been created. The experiment reported in this paper investigated the perception of specific key poses from the Affect Space. The results suggest that this Affect Space for body expressions can be used to improve the expressiveness of humanoid robots. In addition, early results of a pilot study are described. It revealed that the context helps human subjects improve their recognition rate during a human-robot imitation game, and in turn this recognition leads to better outcome of the interactions.","2010","2021-02-15 22:35:31","2021-02-15 22:35:31","","37-42","","","","","","","","","","","","","","","","","","","","","<p>cited By 39</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2LLLMB92","conferencePaper","2010","Leite, I.; Pereira, A.; Mascarenhas, S.; Castellano, G.; Martinho, C.; Prada, R.; Paiva, A.","Closing the loop: From affect recognition to empathic interaction","AFFINE'10 - Proceedings of the 3rd ACM Workshop on Affective Interaction in Natural Environments, Co-located with ACM Multimedia 2010","","","10.1145/1877826.1877839","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650479851&doi=10.1145%2f1877826.1877839&partnerID=40&md5=457610fa47de048d31f4c8807bf630dc","Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.","2010","2021-02-15 22:35:31","2021-02-15 22:35:31","","43-47","","","","","","","","","","","","","","","","","","","","","<p>cited By 15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYPGL2J6","journalArticle","2010","Evers, V.; Winterboer, A.; Pavlin, G.; Groen, F.","The evaluation of empathy, autonomy and touch to inform the design of an environmental monitoring robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-17248-9_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649920020&doi=10.1007%2f978-3-642-17248-9_30&partnerID=40&md5=3c87a3b5f3154ef0d5bcffd732bbf9b4","This paper reports the application of results from human- social agent interaction experiments to inform the design of a social robot to monitor levels of pollutive gasses in the air. Next to licensed environmental agents and immobile chemical sensors, mobile technologies such as robotic agents are needed to collect complaints and smell descriptions from humans in urban industrial areas. These robots will interact with members of the public and ensure responsiveness and accuracy of responses. For robots to be accepted as representative environmental monitoring agents and for people to comply to robot instructions in the case of a calamity, social skills will be important. In this paper we will describe the intelligent environment the environmental robot is part of and discuss preliminary work on the effects of robot empathic and touch behaviors on human responses to robots. These and future findings will inform the design of social monitoring robot behaviors in public settings. © 2010 Springer-Verlag.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","285-294","","","6414 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"97YZGDED","conferencePaper","2010","Mayer, C.; Sosnowski, S.; Kühnlenz, K.; Radig, B.","Towards robotic facial mimicry: System development and evaluation","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649811811&doi=10.1109%2fROMAN.2010.5598629&partnerID=40&md5=be1e023f6c26e8fefbef602794622f7f","We introduce a facial mimicry system, which combines facial expression analysis and synthesis on a robot, utilizing the facial action coding system. The activation of action units on a user's face is automatically extracted from a video stream and mapped to the robot, thus mirroring the facial expression. As a novel approach, a user study quantifies the congruence of the initial human facial expression with the robotic facial expression. The evaluation shows that the robotic facial expression is perceived to be close to the human facial expression, from which it is derived. This is a fundamental aspect for a mimicry system, providing a basis for future research on empathy and emotional closed loop control. © 2010 IEEE.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","198-203","","","","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZS45DS8","conferencePaper","2010","Beck, A.; Cañamero, L.; Bard, K.A.","Towards an Affect Space for robots to display emotional body language","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649809554&doi=10.1109%2fROMAN.2010.5598649&partnerID=40&md5=155a713176f4ea9f15710c1cb7a8bf7a","In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex. © 2010 IEEE.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","464-469","","","","","","","","","","","","","","","","","","","","","<p>cited By 70</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VXTEJFS","conferencePaper","2010","Mazzei, D.; Billeci, L.; Armato, A.; Lazzeri, N.; Cisternino, A.; Pioggia, G.; Igliozzi, R.; Muratori, F.; Ahluwalia, A.; De Rossi, D.","The FACE of autism","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649834348&doi=10.1109%2fROMAN.2010.5598683&partnerID=40&md5=a240f42caa411330d0809d58579705bd","People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented. © 2010 IEEE.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","791-796","","","","","","","","","","","","","","","","","","","","","<p>cited By 38</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKMWQ6RA","journalArticle","2010","Coeckelbergh, M.","Artificial companions: Empathy and vulnerability mirroring in human-robot relations","Studies in Ethics, Law, and Technology","","","10.2202/1941-6008.1126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951518701&doi=10.2202%2f1941-6008.1126&partnerID=40&md5=291aad81c3578195777069239c232628","Under what conditions can robots become companions and what are the ethical issues that might arise in human-robot companionship relations? I argue that the possibility and future of robots as companions depends (among other things) on the robot's capacity to be a recipient of human empathy, and that one necessary condition for this to happen is that the robot mirrors human vulnerabilities. For the purpose of these arguments, I make a distinction between empathy-as-cognition and empathy-as-feeling, connecting the latter to the moral sentiment tradition and its concept of ""fellow feeling."" Furthermore, I sympathise with the intuition that vulnerability mirroring raises the ethical issue of deception. However, given the importance of appearance in social relations, problems with the concept of deception, and contemporary technologies that question the artificial-natural distinction, we cannot easily justify the underlying assumptions of the deception objection. If we want to hold on to them, we need convincing answers to these problems. © 2011 Berkeley Electronic Press. All rights reserved.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","","","3","4","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77SHG4UF","conferencePaper","2010","Duhaut, D.","A way to put empathy in a Robot","Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866108268&partnerID=40&md5=b7aefa120587dbd4e227a2ab51730e20","A report on the experiments carried out with our robot in the Emotirob project is given in this paper, in which we show how we build emotion and personality in the robot. With children, the results of interaction with the robot are quite satisfactory in a short-term experiment. However, it was noted that during long-term interaction between the children and the robot, the relationship changes as a kind of lassitude sets up. Thus, the question addressed here is, how can we make a robot acceptable for long-term interaction? We propose to explain why empathy is a part of the solution and what the key points are for artificial intelligence to solve this new problem.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","549-554","","","2","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIAVPMT4","journalArticle","2010","Boucenna, S.; Gaussier, P.; Hafemeister, L.; Bard, K.","Autonomous development of social referencing skills","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-15193-4_59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249265355&doi=10.1007%2f978-3-642-15193-4_59&partnerID=40&md5=14ed2d292c580e3cbfc3fb0f93322108","In this work, we are interested in understanding how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensori-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some ""empathy"" or at least ""resonate"" with the robot head (low level emotional resonance). Hence we advocate the idea that social referencing can be bootstrapped from a simple sensori-motor system not dedicated to social interactions. © 2010 Springer-Verlag.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","628-638","","","6226 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5J6RVNT6","journalArticle","2010","Leite, I.; Mascarenhas, S.; Pereira, A.; Martinho, C.; Prada, R.; Paiva, A.","""Why can't we be friends?"" an empathic game companion for long-term interaction","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-642-15892-6_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049379436&doi=10.1007%2f978-3-642-15892-6_32&partnerID=40&md5=e59385a36b95870356be6a9e75a4c25c","The ability of artificial companions (virtual agents or robots) to establish meaningful relationships with users is still limited. In humans, a key aspect of such ability is empathy, often seen as the basis of social cooperation and pro-social behaviour. In this paper, we present a study where a social robot with empathic capabilities interacts with two users playing a chess game against each other. During the game, the agent behaves in an empathic manner towards one of the players and in a neutral way towards the other. In an experiment conducted with 40 participants, results showed that users to whom the robot was empathic provided higher ratings in terms of companionship. © 2010 Springer-Verlag Berlin Heidelberg.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","315-321","","","6356 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJTWNMIB","conferencePaper","2010","Cramer, H.; Goddijn, J.; Wielinga, B.; Evers, V.","Effects of (in)accurate empathy and situational valence on attitudes towards robots","5th ACM/IEEE International Conference on Human-Robot Interaction, HRI 2010","","","10.1145/1734454.1734513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951614868&doi=10.1145%2f1734454.1734513&partnerID=40&md5=9f89fcdee313e99eb0b65f9b667e75a2","Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive. © 2010 IEEE.","2010","2021-02-15 22:35:32","2021-02-15 22:35:32","","141-142","","","","","","","","","","","","","","","","","","","","","<p>cited By 48</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q44YH8TT","journalArticle","2021","Croes, E.A.J.; Antheunis, M.L.","Can we be friends with Mitsuku? A longitudinal study on the process of relationship formation between humans and a social chatbot","Journal of Social and Personal Relationships","","","10.1177/0265407520959463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091422686&doi=10.1177%2f0265407520959463&partnerID=40&md5=7a1fafb08fcca7eb9c8e2df2e58c3779","This explorative study investigated (a) whether social attraction, self-disclosure, interaction quality, intimacy, empathy and communicative competence play a role in getting-acquainted interactions between humans and a chatbot, and (b) whether humans can build a relationship with a chatbot. Although human-machine communication research suggests that humans can develop feelings for computers, this does not automatically imply that humans experience feelings of friendship with a chatbot. In this longitudinal study, 118 participants had seven interactions with chatbot Mitsuku over a 3-week period. After each interaction participants filled out a questionnaire. The results showed that the social processes decreased after each interaction and feelings of friendship were low. In line with the ABCDE model of relationship development, the social processes that aid relationship continuation decrease, leading to deterioration of the relationship. Furthermore, a novelty effect was at play after the first interaction, after which the chatbot became predictable and the interactions less enjoyable. © The Author(s) 2020.","2021","2021-02-15 22:35:55","2021-02-15 22:35:55","","279-300","","1","38","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H86ZEXL9","conferencePaper","2020","Daher, K.; Casas, J.; Khaled, O.A.; Mugellini, E.","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020","","","10.1145/3383652.3423864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096965302&doi=10.1145%2f3383652.3423864&partnerID=40&md5=fe8b298b7d7e4ba7330d713c3261bfca","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12). © 2020 Owner/Author.","2020","2021-02-15 22:35:56","2021-02-15 22:35:56","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GNLDX3C2","conferencePaper","2020","Chen, Z.; Lu, Y.; Nieminen, M.P.; Lucero, A.","Creating a chatbot for and with migrants: Chatbot personality drives co-design activities","DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference","","","10.1145/3357236.3395495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090504800&doi=10.1145%2f3357236.3395495&partnerID=40&md5=f1462d9b4b9746c6d634685538c4ee2d","Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria. © 2020 Owner/Author.","2020","2021-02-15 22:35:56","2021-02-15 22:35:56","","219-230","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJ3HPI3T","conferencePaper","2020","Ravi, A.; Yadav, A.K.S.; Chauhan, J.; Dholakia, J.; Jain, N.","Sentemoji: A dataset to generate empathising conversations","ACM International Conference Proceeding Series","","","10.1145/3371158.3371218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078411780&doi=10.1145%2f3371158.3371218&partnerID=40&md5=0bc1621a71993b93cf7db57a229cc50e","Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach. © 2020 Association for Computing Machinery.","2020","2021-02-15 22:35:56","2021-02-15 22:35:56","","345-346","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUDGUTPA","journalArticle","2020","El Kamali, M.; Angelini, L.; Caon, M.; Lalanne, D.; Abou Khaled, O.; Mugellini, E.","An embodied and ubiquitous e-coach for accompanying older adults towards a better lifestyle","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-49065-2_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088749526&doi=10.1007%2f978-3-030-49065-2_2&partnerID=40&md5=1a62194f602971512a9ca4bd5e312c38","The population of people age 65 or over is increasing especially in Europe [3]. Granting to this target population a longer and healthier life is paramount for the European Community. In the context of the H2020 EU funded project “NESTORE” [11], an embodied and ubiquitous e-coach is being developed seeking to change the lifestyle of seniors in different domains of wellbeing. NESTORE e-coach is known as a personalized embodied and ubiquitous e-coach that plays three essential roles in elderly’s wellbeing: a coach, a friend and a companion. As a coach, NESTORE will give trainings and advice following a wellbeing path that is proposed by experts in wellbeing. As a friend, this e-coach knows and understands the user. As a companion, this e-coach has the ability to detect the user’s emotion and aims at building empathy with the user based by providing support throughout their daily training. The NESTORE e-coach is based on three different intervention medium: a mobile application, a chatbot and an embodied vocal assistant. These interfaces have different forms, different capabilities and different visions. Users can communicate with the NESTORE e-coach through different interfaces exclusively, sequentially, concurrently and synergistically. The interaction can be initiated from the user side to different interfaces and/or from the e-coach side. In this paper, we present the NESTORE’s full vision for building the three essential roles of this e-coach which are: a coach, a companion and a friend for seniors. Furthermore, we explain the NESTORE system design, architecture, capabilities and how the different interfaces of this E-coach contribute to make a multi-modal system. Finally, we conclude our work with the state of this H2020 project. © Springer Nature Switzerland AG 2020.","2020","2021-02-15 22:35:56","2021-02-15 22:35:56","","23-35","","","12183 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRBDTYPN","conferencePaper","2019","Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019","","","10.1109/RITAPP.2019.8932852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.","2019","2021-02-15 22:35:56","2021-02-15 22:35:56","","160-163","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLHK6GQK","journalArticle","2019","Powell, J.","Trust me, i'm a chatbot: How artificial intelligence in health care fails the turing test","Journal of Medical Internet Research","","","10.2196/16222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074230200&doi=10.2196%2f16222&partnerID=40&md5=f07051700ad8b816ddd71e05e867d094","Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. © 2019 John Powell.","2019","2021-02-15 22:35:56","2021-02-15 22:35:56","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2C8PH6B","conferencePaper","2019","Weisz, J.D.; Jain, M.; Joshi, N.N.; Johnson, J.; Lange, I.","BigBlueBot: Teaching strategies for successful human-agent interactions","International Conference on Intelligent User Interfaces, Proceedings IUI","","","10.1145/3301275.3302290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065584647&doi=10.1145%2f3301275.3302290&partnerID=40&md5=f65fcd8c30c030f91d0e8fa4ff25c7f7","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future. © 2019 Association for Computing Machinery.","2019","2021-02-15 22:35:56","2021-02-15 22:35:56","","448-459","","","Part F147615","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GLYDQYC7","journalArticle","2019","Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.","A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study","Journal of Medical Internet Research","","","10.2196/14658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2","Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.","2019","2021-02-15 22:35:56","2021-02-15 22:35:56","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVMSCMG7","journalArticle","2018","Liu, B.; Sundar, S.S.","Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot","Cyberpsychology, Behavior, and Social Networking","","","10.1089/cyber.2018.0110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055080779&doi=10.1089%2fcyber.2018.0110&partnerID=40&md5=6111bd02c236f7c8ae5e9e32b516323c","When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N = 158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N = 88) interacted with a real chatbot. We tested the effect of three types of empathic expression - sympathy, cognitive empathy, and affective empathy - on individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed. © Copyright 2018, Mary Ann Liebert, Inc., publishers.","2018","2021-02-15 22:35:56","2021-02-15 22:35:56","","625-636","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 37</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XN6IJW9","conferencePaper","2017","Xu, A.; Liu, Z.; Guo, Y.; Sinha, V.; Akkiraju, R.","A new chatbot for customer service on social media","Conference on Human Factors in Computing Systems - Proceedings","","","10.1145/3025453.3025496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454411&doi=10.1145%2f3025453.3025496&partnerID=40&md5=eb0554245b67f51b2c89e08ecccdd3ec","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric. © 2017 ACM.","2017","2021-02-15 22:35:56","2021-02-15 22:35:56","","3506-3510","","","2017-May","","","","","","","","","","","","","","","","","","<p>cited By 139</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WKR2JTQ","journalArticle","2021","Dollmat, K.S.; Abdullah, N.A.","Machine learning in emotional intelligence studies: a survey","Behaviour and Information Technology","","","10.1080/0144929X.2021.1877356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099954220&doi=10.1080%2f0144929X.2021.1877356&partnerID=40&md5=b645897ea31110c75104d7291155ee95","Research has proven that having high level of emotional intelligence (EI) can reduce the chance of getting mental illness. EI, and its component, can be improved with training, but currently the process is less flexible and very time-consuming. Machine learning (ML), on the other hand, can analyse huge amount of data to discover useful trends and patterns in shortest time possible. Despite the benefits, ML usage in EI training is scarce. In this paper, we studied 92 journal articles to discover the trend of the ML utilisation in the study of EI and its components. This survey aims to pave way for future studies that could lead to implementation of ML in EI training, and to rope in researchers in psychology and computer science to find possibilities of having a generic ML algorithm for every EI’s components. Our findings show an increasing trend to apply ML on EI components, and Support Vector Machine and Neural Network are the two most popular ML algorithms used in those researches. We also found that social skill and empathy are the least exposed EI components to ML. Finally, we provide recommendations for future research direction of ML in EI domain, and EI in ML. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","2021","2021-02-15 22:36:21","2021-02-15 22:36:21","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNNANXVP","journalArticle","2020","Wu, H.; Feng, C.; Lu, X.; Liu, X.; Liu, Q.","Oxytocin effects on the resting-state mentalizing brain network","Brain Imaging and Behavior","","","10.1007/s11682-019-00205-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078296284&doi=10.1007%2fs11682-019-00205-5&partnerID=40&md5=f30603b1709820ae105c35485f9a0096","Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual’s empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","2530-2541","","6","14","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBBKNTGV","conferencePaper","2020","Chromik, M.; Lachner, F.; Butz, A.","ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research","ACM International Conference Proceeding Series","","","10.1145/3419249.3420163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095825746&doi=10.1145%2f3419249.3420163&partnerID=40&md5=57bb98a9ac0c0565b43777fe83bbcc28","Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML's impact on current UXR activities and practitioners' predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users' emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research. © 2020 ACM.","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85YTTGUY","journalArticle","2020","Zwir, I.; Arnedo, J.; Del-Val, C.; Pulkki-Råback, L.; Konte, B.; Yang, S.S.; Romero-Zaliz, R.; Hintsanen, M.; Cloninger, K.M.; Garcia, D.; Svrakic, D.M.; Rozsa, S.; Martinez, M.; Lyytikäinen, L.-P.; Giegling, I.; Kähönen, M.; Hernandez-Cuervo, H.; Seppälä, I.; Raitoharju, E.; de Erausquin, G.A.; Raitakari, O.; Rujescu, D.; Postolache, T.T.; Sung, J.; Keltikangas-Järvinen, L.; Lehtimäki, T.; Cloninger, C.R.","Uncovering the complex genetics of human character","Molecular Psychiatry","","","10.1038/s41380-018-0263-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054357876&doi=10.1038%2fs41380-018-0263-6&partnerID=40&md5=cc28474ea2ceb53ab46558d20cfb0cd7","Human personality is 30–60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic–phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory. © 2018, The Author(s).","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","2295-2312","","10","25","","","","","","","","","","","","","","","","","","<p>cited By 22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTPHMBAB","journalArticle","2020","Sakamoto, T.; Yamashita, H.; Goto, M.; Iwanaga, J.","Model for relational analysis of posted articles and reactions on restaurant guide sites","Industrial Engineering and Management Systems","","","10.7232/iems.2020.19.3.669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093862693&doi=10.7232%2fiems.2020.19.3.669&partnerID=40&md5=fdb2e6a9bbce1d4cf8653879ff665693","Recently, restaurant guide sites providing restaurant information posted by users on the Internet have been widely used as effective tools for consumers. Users, on a restaurant guide site, utilize IDs to post their recommendation articles on restaurants, and these posted articles are a valuable information source for other users. Open users can search for restaurants and read recommendation articles posted by other users. Furthermore, they can react (e.g., “like”) to a recommendation article when they feel it is helpful or they feel like visiting the restaurant. On a target restaurant guide site, each post includes the user ID, restaurant name, recommendation sentences, etc., and the number of reactions is considered to depend on these posted contents. For users who post recommendation articles, the number of reactions to their posts represents the degree of empathy from other users and is an important motivation for posting. Therefore, posting users will benefit from guidelines on how to write good recommendation sentences to increase the number of reactions. Moreover, the number of reactions can be regarded as an important indicator of the activity level of the restaurant guide site from the viewpoint of the service operating company. Therefore, an analytical model developed using historical information such as posts and reactions by users would be useful for determining the relationship between posted contents and the number of reactions. Therefore, this paper proposes a model based on the machine learning approach to analyze the relation between the number of reactions and posted contents. Finally, we demonstrate the analysis based on the proposed model using practical data. © 2020 KIIE","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","669-679","","3","19","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IUXKTQ3","conferencePaper","2020","Toxtli, C.; Richmond-Fuller, A.; Savage, S.","Reputation Agent: Prompting Fair Reviews in Gig Markets","The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","","","10.1145/3366423.3380199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589321&doi=10.1145%2f3366423.3380199&partnerID=40&md5=8235c305e0974c8f0c5d3911f16d1058","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers. © 2020 ACM.","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","1228-1240","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LGNRPLA","journalArticle","2020","Leonardi, S.; Monti, D.; Rizzo, G.; Morisio, M.","Multilingual transformer-based personality traits estimation","Information (Switzerland)","","","10.3390/info11040179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085080344&doi=10.3390%2finfo11040179&partnerID=40&md5=590d131e1ea07c10f6d5c564ed07dc18","Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users' information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes Facebook posts from the myPersonality dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback-Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits. © 2020 by the authors.","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","","","4","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIAHXVTW","conferencePaper","2020","Dixit, R.; Chinnam, R.B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","IEEE Aerospace Conference Proceedings","","","10.1109/AERO47225.2020.9172612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092594173&doi=10.1109%2fAERO47225.2020.9172612&partnerID=40&md5=0e5e0dbad1bd51bfa0c0a6e225195406","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once 'trained,' can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to 'techies' from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further. © 2020 IEEE.","2020","2021-02-15 22:36:21","2021-02-15 22:36:21","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XP3E5WQQ","journalArticle","2020","Kumar, M.; Khatri, S.K.; Mohammadian, M.","Breast cancer identification and prognosis with machine learning techniques - An elucidative review","Journal of Interdisciplinary Mathematics","","","10.1080/09720502.2020.1731963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084855111&doi=10.1080%2f09720502.2020.1731963&partnerID=40&md5=63f81c27e48424c44143c5d87af974d3","Cancer is the principle wellspring of death around the globe with 2.09 million cases so far in 2018 [1]. Around 627000 deaths accounting to 6.6% are caused because of female breast cancer and it ranks five amongst the list of top causes for deaths, the prime reason being prognosis being favorable in developed countries. The timely empathy of breast cancer further makes the process of prognosis better hence improving the rates of survival, because this will indorse on time treatment which is given clinically to patients. When the classification is done in an accurate way for malignant and benign tumours, it stops the suffering of patients with excessive ailments. The best possible recognizable proof of breast cancer disease and the process of characterizing into benign and malignant groups is that the main concern of a ton of investigation and research. When thrown light on its particular advantages in significant alternatives recognition from the datasets of entangled breast cancer, the generally perceived option is Machine Learning, because of the philosophy of determination in breast cancer to arrange pattern and forecast modelling. This paper will in general, survey machine learning and assessment of this particular paper, WBCD: Wisconsin Breast Cancer Database has been used as the benchmark dataset. © 2020, © 2020 Taru Publications.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","503-521","","2","23","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AP9VEHZU","journalArticle","2020","Christov-Moore, L.; Reggente, N.; Douglas, P.K.; Feusner, J.D.; Iacoboni, M.","Predicting Empathy From Resting State Brain Connectivity: A Multivariate Approach","Frontiers in Integrative Neuroscience","","","10.3389/fnint.2020.00003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081050035&doi=10.3389%2ffnint.2020.00003&partnerID=40&md5=14a6c372c5d3617e327c91f2225d221e","Recent task fMRI studies suggest that individual differences in trait empathy and empathic concern are mediated by patterns of connectivity between self-other resonance and top-down control networks that are stable across task demands. An untested implication of this hypothesis is that these stable patterns of connectivity should be visible even in the absence of empathy tasks. Using machine learning, we demonstrate that patterns of resting state fMRI connectivity (i.e. the degree of synchronous BOLD activity across multiple cortical areas in the absence of explicit task demands) of resonance and control networks predict trait empathic concern (n = 58). Empathic concern was also predicted by connectivity patterns within the somatomotor network. These findings further support the role of resonance-control network interactions and of somatomotor function in our vicariously driven concern for others. Furthermore, a practical implication of these results is that it is possible to assess empathic predispositions in individuals without needing to perform conventional empathy assessments. © Copyright © 2020 Christov-Moore, Reggente, Douglas, Feusner and Iacoboni.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","","14","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IA4HFJJ","journalArticle","2020","Haarsma, G.; Davenport, S.; White, D.C.; Ormachea, P.A.; Sheena, E.; Eagleman, D.M.","Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software","Frontiers in Psychology","","","10.3389/fpsyg.2019.02926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079140899&doi=10.3389%2ffpsyg.2019.02926&partnerID=40&md5=d66fb33965d78c0e0dfa4f599eabf818","We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver–operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided. © Copyright © 2020 Haarsma, Davenport, White, Ormachea, Sheena and Eagleman.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","","10","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RI727WS3","journalArticle","2020","Wei, L.; Wu, G.-R.; Bi, M.; Baeken, C.","Effective connectivity predicts cognitive empathy in cocaine addiction: a spectral dynamic causal modeling study","Brain Imaging and Behavior","","","10.1007/s11682-020-00354-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088566060&doi=10.1007%2fs11682-020-00354-y&partnerID=40&md5=835728f0a909b8384890b1442ede8006","Social cognition plays a crucial role in the development and treatment of cocaine dependence. However, studies investigating social cognition, such as empathy and its underlying neural basis, are lacking. To explore the neural interactions among reward and memory circuits, we applied effective connectivity analysis on resting-state fMRI data collected from cocaine-dependent subjects. The relationship between effective connectivity within these two important circuits and empathy ability - evaluated with the Interpersonal Reactivity Index (IRI) - was assessed by machine learning algorithm using multivariate regression analysis. In accordance with the neurocircuitry disruptions of cocaine addiction, the results showed that cocaine-dependent subjects relative to healthy controls had altered resting state effective connectivity between parts of the memory and reward systems. Furthermore, effective connectivity between the memory and reward system could predict the fantasy empathy (FE) subscale scores in cocaine dependence. Overall, our findings provide further evidence for the neural substrates of social cognition in cocaine-dependent patients. These new insights could be useful for the development of new treatment programs for this substance dependency disorder. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6U35K9L9","journalArticle","2020","Rehman, F.; Munawar, A.; Iftikhar, A.; Hassan, J.; Samiullah, F.; Gilani, M.B.A.; Qasim, A.; Qasim, N.","Design and development of ai-based mirror neurons agent towards emotion and empathy","International Journal of Advanced Computer Science and Applications","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083223916&partnerID=40&md5=8442281cfab2a9fa3c207ade4eb4b124","Since numerous years, researchers have to outline keen operators to accomplish the Artificial General Intelligence. Each new science revelation is an open challenge to all researchers. More than twenty years prior to a group of researchers discovered exceptional cerebrum cells, called reflect neurons in monkeys. These cells gave off an impression of being actuated both when the monkey accomplished something itself and when the monkey basically watched another monkey do a similar thing. This new discovery opened a new door for a scientist because of Mirror Neurons functionalities that can be huge contribute to cognitive science, neuroscience, impacting on Artificial General Intelligence. Mirror neuron functionality improves the Machine's learning. This research paper develops models for social interaction in which a machine may have the ability to learn the next person emotional state using mirror neurons and show empathy towards emotions. © 2020, Science and Information Organization.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","386-395","","3","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWT5JTE8","journalArticle","2020","Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.","Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey","Digital Health","","","10.1177/2055207620968355","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094669527&doi=10.1177%2f2055207620968355&partnerID=40&md5=5e2909e410f68527e010deb3b1f9b7b3","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues. © The Author(s) 2020.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","","6","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQ6XMQZM","conferencePaper","2020","Diederich, S.; Janßen-Müller, M.; Brendel, A.B.; Morana, S.","Emulating empathetic behavior in online service encounters with sentiment-adaptive responses: Insights from an experiment with a conversational agent","40th International Conference on Information Systems, ICIS 2019","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084712323&partnerID=40&md5=3bac47ce26f79d1c1ad3069daa0798f2","Conversational agents currently attract strong interest for technology-based service provision due to increased capabilities driven by advances in machine learning and natural language processing. The interaction via natural language in combination with a human-like design promises service that is always available, fast, and with a consistent quality and at the same time resembles a human service encounter. However, current conversational agents exhibit the same inherent limitation that every interactive technology has, which is a lack of social skills. In this study, we make a first step towards overcoming this limitation by presenting a design approach that combines automatic sentiment analysis with adaptive responses to emulate empathy in a service encounter. By means of an experiment with 112 participants, we evaluate the approach and find empirical support that a CA with sentiment-adaptive responses is perceived as more empathetic, human-like, and socially present and, in particular, yields a higher service encounter satisfaction. © 40th International Conference on Information Systems, ICIS 2019. All rights reserved.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZQQZFQE","journalArticle","2020","Lima Dantas, D.; Filgueiras, L.V.L.; Brandão, A.A.F.; Machado Domingues, M.C.; Ferreira, M.R.","Detecting IoT Applications Opportunities and Requirements Elicitation: A Design Thinking Based Approach","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-50344-4_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740148&doi=10.1007%2f978-3-030-50344-4_7&partnerID=40&md5=82f5cd968cdecbc941b929dd7ba6216c","IoT development is complex. To reduce this complexity, IoT platforms provide a set of resources and functionalities to enable application development and support its execution. In this work, we present a human-centered approach for requirements elicitation and mapping them to application resources in IoT platforms, using empathy, definition and ideation methods. A previous study by the authors has identified 11 categories of resources provided by 47 IoT platforms to developers in their application layers. From this set, 6 categories were selected for this work: schedulers and triggers, message and notification triggers, big data and analytics, artificial intelligence and machine learning, dashboards, and services. We invited 18 members of 8 projects for a workshop and divided them in 4 teams, according their project areas, which are: Industry 4.0 (6 participants), Environmental Disasters (4 participants), Environmental Management (3 participants) and Pollution (5 participants). We divided the workshop in 3 phases: warm-up, with user journey mapping, requirements identification using “how might we” questions as a trigger and requirements clustering the questions by the 6 selected categories of resources or an extra category named “others” for those which could not be related to any previous category. Our contribution for the IoT application development is an approach for turning easier requirements elicitation using DT techniques, covering the stages of empathise, definition and ideation, with well-available materials and considering the resources present at application layer of IoT platforms. © 2020, Springer Nature Switzerland AG.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","85-100","","","12203 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5L9CKAC","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective intelligence: When, where and why","Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering","","","10.1109/Confluence47617.2020.9058000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083999561&doi=10.1109%2fConfluence47617.2020.9058000&partnerID=40&md5=dc43e7ffcf6adf8f724ffaf9d79a8e30","The term 'Collective' is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief. © 2020 IEEE.","2020","2021-02-15 22:36:22","2021-02-15 22:36:22","","805-810","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQ6RPE3N","journalArticle","2019","O’Connell, K.; Brethel-Haurwitz, K.M.; Rhoads, S.A.; Cardinale, E.M.; Vekaria, K.M.; Robertson, E.L.; Walitt, B.; VanMeter, J.W.; Marsh, A.A.","Increased similarity of neural responses to experienced and empathic distress in costly altruism","Scientific Reports","","","10.1038/s41598-019-47196-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069733023&doi=10.1038%2fs41598-019-47196-3&partnerID=40&md5=d20042af6e49a051649ad067549d4110","Empathy—affective resonance with others’ sensory or emotional experiences—is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists’ heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize. © 2019, The Author(s).","2019","2021-02-15 22:36:22","2021-02-15 22:36:22","","","","1","9","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6LKNSSF","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting future alleviation of mental illness in social media: An empathy-based social network perspective","Proceedings - 2019 IEEE Intl Conf on Parallel and Distributed Processing with Applications, Big Data and Cloud Computing, Sustainable Computing and Communications, Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085484201&doi=10.1109%2fISPA-BDCloud-SustainCom-SocialCom48970.2019.00230&partnerID=40&md5=b25cfa36d495be8d70325de2a2fd3932","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed. © 2019 IEEE.","2019","2021-02-15 22:36:22","2021-02-15 22:36:22","","1564-1571","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMEPQB46","journalArticle","2019","Krohne, L.G.; Wang, Y.; Hinrich, J.L.; Moerup, M.; Chan, R.C.K.; Madsen, K.H.","Classification of social anhedonia using temporal and spatial network features from a social cognition fMRI task","Human Brain Mapping","","","10.1002/hbm.24751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070672968&doi=10.1002%2fhbm.24751&partnerID=40&md5=a024b6f27ce7b57e61c0dcaee4172c31","Previous studies have suggested that the degree of social anhedonia reflects the vulnerability for developing schizophrenia. However, only few studies have investigated how functional network changes are related to social anhedonia. The aim of this fMRI study was to classify subjects according to their degree of social anhedonia using supervised machine learning. More specifically, we extracted both spatial and temporal network features during a social cognition task from 70 subjects, and used support vector machines for classification. Since impairment in social cognition is well established in schizophrenia-spectrum disorders, the subjects performed a comic strip task designed to specifically probe theory of mind (ToM) and empathy processing. Features representing both temporal (time series) and network dynamics were extracted using task activation maps, seed region analysis, independent component analysis (ICA), and a newly developed multi-subject archetypal analysis (MSAA), which here aimed to further bridge aspects of both seed region analysis and decomposition by incorporating a spotlight approach.We found significant classification of subjects with elevated levels of social anhedonia when using the times series extracted using MSAA, indicating that temporal dynamics carry important information for classification of social anhedonia. Interestingly, we found that the same time series yielded the highest classification performance in a task classification of the ToM condition. Finally, the spatial network corresponding to that time series included both prefrontal and temporal-parietal regions as well as insula activity, which previously have been related schizotypy and the development of schizophrenia. © 2019 Wiley Periodicals, Inc.","2019","2021-02-15 22:36:22","2021-02-15 22:36:22","","4965-4981","","17","40","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLKZYWF7","journalArticle","2019","Drimalla, H.; Landwehr, N.; Hess, U.; Dziobek, I.","From face to face: the contribution of facial mimicry to cognitive and emotional empathy","Cognition and Emotion","","","10.1080/02699931.2019.1596068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063194475&doi=10.1080%2f02699931.2019.1596068&partnerID=40&md5=bb539c57b010be437f0ec7ff35e632e7","Despite advances in the conceptualisation of facial mimicry, its role in the processing of social information is a matter of debate. In the present study, we investigated the relationship between mimicry and cognitive and emotional empathy. To assess mimicry, facial electromyography was recorded for 70 participants while they completed the Multifaceted Empathy Test, which presents complex context-embedded emotional expressions. As predicted, inter-individual differences in emotional and cognitive empathy were associated with the level of facial mimicry. For positive emotions, the intensity of the mimicry response scaled with the level of state emotional empathy. Mimicry was stronger for the emotional empathy task compared to the cognitive empathy task. The specific empathy condition could be successfully detected from facial muscle activity at the level of single individuals using machine learning techniques. These results support the view that mimicry occurs depending on the social context as a tool to affiliate and it is involved in cognitive as well as emotional empathy. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2019","2021-02-15 22:36:22","2021-02-15 22:36:22","","1672-1686","","8","33","","","","","","","","","","","","","","","","","","<p>cited By 14</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AHU3FC8X","conferencePaper","2019","Franzoni, V.; Milani, A.; Biondi, G.; Micheli, F.","A preliminary work on dog emotion recognition","Proceedings - 2019 IEEE/WIC/ACM International Conference on Web Intelligence Workshops, WI 2019 Companion","","","10.1145/3358695.3361750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074373338&doi=10.1145%2f3358695.3361750&partnerID=40&md5=28643a3c506d284761d30c4e16a889af","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence. © 2019 Copyright held by the owner/author(s).","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","91-96","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7GE99DS","journalArticle","2019","Clavelle, J.T.; Sweeney, C.D.; Swartwout, E.; Lefton, C.; Guney, S.","Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition","Journal of Nursing Administration","","","10.1097/NNA.0000000000000757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931093&doi=10.1097%2fNNA.0000000000000757&partnerID=40&md5=c67866ef50603649810f548af2d47672","Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented. © Wolters Kluwer Health, Inc. All rights reserved.","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","303-309","","6","49","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRZRANS8","journalArticle","2019","Imel, Z.E.; Pace, B.T.; Soma, C.S.; Tanana, M.; Hirsch, T.; Gibson, J.; Georgiou, P.; Narayanan, S.; Atkins, D.C.","Design feasibility of an automated, machine-learning based feedback system for motivational interviewing","Psychotherapy","","","10.1037/pst0000221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063985695&doi=10.1037%2fpst0000221&partnerID=40&md5=20d1cfc6e7033bf619a267c74e7e1fa9","Direct observation of psychotherapy and providing performance-based feedback is the gold-standard approach for training psychotherapists. At present, this requires experts and training human coding teams, which is slow, expensive, and labor intensive. Machine learning and speech signal processing technologies provide a way to scale up feedback in psychotherapy. We evaluated an initial proof of concept automated feedback system that generates motivational interviewing quality metrics and provides easy access to other session data (e.g., transcripts). The system automatically provides a report of session-level metrics (e.g., therapist empathy) and therapist behavior codes at the talk-turn level (e.g., reflections). We assessed usability, therapist satisfaction, perceived accuracy, and intentions to adopt. A sample of 21 novice (n = 10) or experienced (n = 11) therapists each completed a 10-min session with a standardized patient. The system received the audio from the session as input and then automatically generated feedback that therapists accessed via a web portal. All participants found the system easy to use and were satisfied with their feedback, 83% found the feedback consistent with their own perceptions of their clinical performance, and 90% reported they were likely to use the feedback in their practice. We discuss the implications of applying new technologies to evaluation of psychotherapy. © 2019 American Psychological Association.","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","318-328","","2","56","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ULJAJ4X","journalArticle","2019","Blease, C.; Kaptchuk, T.J.; Bernstein, M.H.; Mandl, K.D.; Halamka, J.D.; Desroches, C.M.","Artificial intelligence and the future of primary care: exploratory qualitative study of UK general practitioners' views","Journal of Medical Internet Research","","","10.2196/12802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063303215&doi=10.2196%2f12802&partnerID=40&md5=41136ee763c24454922fbdbed2e48d68","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPS') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPS' opinions about the likelihood of future technology to fully replace GPS in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPS also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPS believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPS considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPS' views. © 2019 Journal of Medical Internet Research. All rights reserved.","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","","","3","21","","","","","","","","","","","","","","","","","","<p>cited By 15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X998RJMF","conferencePaper","2019","Salaken, S.M.; Nahavandi, S.; McGinn, C.; Hossny, M.; Kelly, K.; Abobakr, A.; Nahavandi, D.; Iskander, J.","Development of a cloud-based computational framework for an empathetic robot","ACM International Conference Proceeding Series","","","10.1145/3313991.3314018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064612068&doi=10.1145%2f3313991.3314018&partnerID=40&md5=63ff43c5b27f0b4f09c443d56e71a480","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator’s voice is presented. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","102-108","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFCCS54R","conferencePaper","2019","Das, A.K.; Ashrafi, A.; Ahmmad, M.","Joint cognition of both human and machine for predicting criminal punishment in judicial system","2019 IEEE 4th International Conference on Computer and Communication Systems, ICCCS 2019","","","10.1109/CCOMS.2019.8821655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071115729&doi=10.1109%2fCCOMS.2019.8821655&partnerID=40&md5=c2141b9cb6d314f80753bcccba34ada4","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can’t only perform faster but also predict better than human. But a human has some qualities which can never be gained by a Machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to ‘Women and Children Repression Prevention Act, 2000’. We apply several Machine learning algorithms to make a Machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide Machine for judging a delinquent. © 2019 IEEE.","2019","2021-02-15 22:36:23","2021-02-15 22:36:23","","36-40","","","","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UF683J9Q","journalArticle","2018","Inkster, B.; Sarda, S.; Subramanian, V.","An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study","JMIR mHealth and uHealth","","","10.2196/12106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f","Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.","2018","2021-02-15 22:36:23","2021-02-15 22:36:23","","","","11","6","","","","","","","","","","","","","","","","","","<p>cited By 58</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXP3RPKI","journalArticle","2018","Vaughn, D.A.; Savjani, R.R.; Cohen, M.S.; Eagleman, D.M.","Empathic Neural Responses Predict Group Allegiance","Frontiers in Human Neuroscience","","","10.3389/fnhum.2018.00302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054818270&doi=10.3389%2ffnhum.2018.00302&partnerID=40&md5=b969317edbd81945e006fad82823c283","Watching another person in pain activates brain areas involved in the sensation of our own pain. Importantly, this neural mirroring is not constant; rather, it is modulated by our beliefs about their intentions, circumstances, and group allegiances. We investigated if the neural empathic response is modulated by minimally-differentiating information (e.g., a simple text label indicating another's religious belief), and if neural activity changes predict ingroups and outgroups across independent paradigms. We found that the empathic response was larger when participants viewed a painful event occurring to a hand labeled with their own religion (ingroup) than to a hand labeled with a different religion (outgroup). Counterintuitively, the magnitude of this bias correlated positively with the magnitude of participants' self-reported empathy. A multivariate classifier, using mean activity in empathy-related brain regions as features, discriminated ingroup from outgroup with 72% accuracy; the classifier's confidence correlated with belief certainty. This classifier generalized successfully to validation experiments in which the ingroup condition was based on an arbitrary group assignment. Empathy networks thus allow for the classification of long-held, newly-modified and arbitrarily-formed ingroups and outgroups. This is the first report of a single machine learning model on neural activation that generalizes to multiple representations of ingroup and outgroup. The current findings may prove useful as an objective diagnostic tool to measure the magnitude of one's group affiliations, and the effectiveness of interventions to reduce ingroup biases. © 2018 Vaughn, Savjani, Cohen and Eagleman.","2018","2021-02-15 22:36:23","2021-02-15 22:36:23","","","","","12","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SU6BWT5P","conferencePaper","2018","Bogatyreva, A.A.; Sovkov, A.D.; Tikhomirova, S.A.; Vinogradova, A.R.; Samsonovich, A.V.","Virtual pet powered by a socially-emotional BICA","Procedia Computer Science","","","10.1016/j.procs.2018.11.101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059446525&doi=10.1016%2fj.procs.2018.11.101&partnerID=40&md5=641bddc567abf82308667be9f87f06ff","Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents. © 2018 The Authors. Published by Elsevier B.V.","2018","2021-02-15 22:36:23","2021-02-15 22:36:23","","564-571","","","145","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5YFXHVAK","journalArticle","2018","Qureshi, S.; Hagelbäck, J.; Iqbal, S.M.Z.; Javaid, H.; Lindley, C.A.","Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS","Advances in Intelligent Systems and Computing","","","10.1007/978-3-030-01054-6_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206","With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.","2018","2021-02-15 22:36:24","2021-02-15 22:36:24","","347-363","","","868","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X67EMACV","journalArticle","2018","Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.","Towards empathetic human-robot interactions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-75487-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25","Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-02-15 22:36:24","2021-02-15 22:36:24","","173-193","","","9624 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKD5ZDNY","journalArticle","2018","Kajiwara, Y.; Kubo, Y.; Kimura, H.","Estimation of evocation of friendship based on similarity of pulse rate variability of users for event-based social networks","Sensors and Materials","","","10.18494/SAM.2018.1777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049905275&doi=10.18494%2fSAM.2018.1777&partnerID=40&md5=4bfc723f0e62ef5c77681b965445a2a1","In contrast to traditional social network services (SNSs), event-based social networks determine close friendships (CFs) of users who share experiences and emotions with candidate friends in offline events. However, we could not provide feedback to cyberspace regarding the place, time, and target of a user realizing friendship since there is no technique for conveniently measuring the evocation of friendship during offline events. In this research, we propose a method of estimating the evocation of friendship using the similarity in the pulse rate variabilities (PRVs) of users when empathy is evoked between them. The user can be made aware of friendship estimated automatically through machine learning by wearing a wristwatch-type pulsimeter. CFs are more likely to evoke empathy than superficial friendships (SFs). To demonstrate the usefulness of this method, we conducted an experiment assuming an event where a group of four people are enjoying their time in an amusement park. From the experimental results, we showed that the similarity of the PRVs in CFs is greater than that in SFs when the favorability rating is high and the users like each other. Moreover, we showed that the proposed method estimated the evocation of friendship during the attraction experience with an f-measure of 0.74 at maximum and during an offline event with a mean f-measure of 0.78. The results showed the usefulness and effectiveness of this method. © MYU K.K.","2018","2021-02-15 22:36:24","2021-02-15 22:36:24","","1407-1426","","7","30","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RI8ARM4E","conferencePaper","2018","Shetty, D.; Xu, J.","Strategies to address ""Design thinking"" in engineering curriculum","ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)","","","10.1115/IMECE2018-87816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060289006&doi=10.1115%2fIMECE2018-87816&partnerID=40&md5=c3c26deda706705f100c7d880ba1b9e2","It is suggested by many scholars that if the goal of engineering education is to produce engineers who can critically design and create, then providing students with early opportunities to engage in creative engineering design is important. While basic design is focused on the development of new products for the individual, working towards a more sustainable world demands greater attention to designing for and with communities. Improving design education and examining design-learning outcomes requires a kind of targeted approach that could match the best practices to personalize student learning. Design is complex and design includes balancing the needs of multiple stakeholders. However, there is a gap in the preparation of design education that will be needed in a challenging environment. This paper reviews the history of design thinking in the engineering curriculum. Design thinking education starts with an understanding of its importance with socioeconomic relevance. Through observation and empathy, mapping the designer uses the listening and learning tools for mapping users unarticulated needs, working in a team environment. The designer takes time to think carefully why a certain project is considered and details which aspects of machine learning application can be applied from functional to complete success for the end users. The availability of powerful virtual reality methodologies, have made it possible to consider the realistic needs and visualize scenarios and to explore the design alternatives with new ideas before full scale resource allocation on new ideas. Mid-to-advanced level courses with experimental assignments require that students apply through experimentation the principles and concepts learned in foundation courses. The basic design tools such as axiomatic thinking, theory of inventive problem solving, design iteration and simulation using hardware-in-the loop are discussed with case studies. Consideration of product sustainability with the thoughts of design for disassembly and disposal has emerged as a major part of design thinking. Senior engineering courses center on cross and interdisciplinary design and capstone experiences so that students experience fully guided practice of device design and problem solving, simulating what they are likely to experience in the world. This paper examines the critical issues of design thinking in a curriculum from observation, empathy mapping, validation of the idea, and improvement of idea by virtual reality and machine learning, optimization of the idea by tools such as axiomatic design, hardware in the loop simulation, and finally examining product sustainability causes. Copyright © 2018 ASME.","2018","2021-02-15 22:36:24","2021-02-15 22:36:24","","","","","5","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K3FP8TJ","conferencePaper","2018","Coman, A.C.; Zara, G.; Nechaev, Y.; Barlacchi, G.; Moschitti, A.","Exploiting deep neural networks for tweet-based emoji prediction","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057887474&partnerID=40&md5=05bb99e39d4261ed76708c15a4c0e94e","For many years now, emojis have been used in social networks and chat services in order to enrich written text with auxiliary graphical content, achieving a higher degree of empathy. In particular, given the wide use of this medium, emojis are now available in such a number and variety that every basic concept and mood is covered by at least one. For this reason, the connection between the emoji and its semantical meaning grows stronger. In this paper, we will be describing the work performed in order to develop a Machine Learning based tool that, given a tweet, predicts the most likely emoji associated with the text. The task resembles the one presented by Barbieri et al., [23], and is placed within the context of the International Workshop on Semantic Evaluation (SemEval) 2018. We designed a baseline with standard Support Vector Machines and another baseline based on fastText, which was provided as part of the Workshop. In addition, we implemented several models based on Neural Networks such as Bidirectional Long Short-Term Memory Recurrent Neural Networks and Convolutional Neural Networks. We found that the latter is the most effective since it outperformed all our models and ranks in the 6th position out of 47 total participants. Our work aims to illustrate the potential of simpler models, which, thanks to the fine-tuning of hyper-parameters, could achieve accuracy comparable to the more complex models of the challenge. © 2018 CEUR-WS. All rights reserved.","2018","2021-02-15 22:36:24","2021-02-15 22:36:24","","116-128","","","2244","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMJRPCT2","journalArticle","2017","Alvarez-Fernandez, S.; Brown, H.R.; Zhao, Y.; Raithel, J.A.; Bishop, S.L.; Kern, S.B.; Lord, C.; Petkova, E.; Di Martino, A.","Perceived social support in adults with autism spectrum disorder and attention-deficit/hyperactivity disorder","Autism Research","","","10.1002/aur.1735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019558593&doi=10.1002%2faur.1735&partnerID=40&md5=e545d47342863040e107738960f8fe69","Perceived social support (PSS) has been related to physical and mental well-being in typically developing individuals, but systematic characterizations of PSS in autism spectrum disorder (ASD) are limited. We compared self-report ratings of the multidimensional scale of PSS (MSPSS) among age- and IQ-matched groups of adults (18–58 years) with cognitively high-functioning ASD (N = 41), or attention-deficit/hyperactivity disorder (ADHD; N = 69), and neurotypical controls (NC; N = 69). Accompanying group comparisons, we used machine learning random forest (RF) analyses to explore predictors among a range of psychopathological and socio-emotional variables. Relative to both ADHD and NC, adults with ASD showed lower MSPSS ratings, specifically for the friends subscale (MSPSS-f). Across ASD and ADHD, interindividual differences in autism severity, affective empathy, symptoms of anxiety related to social interactions, hyperactivity/impulsivity, and somatization best predicted MSPSS-f. These relationships did not differ between clinical groups. While group comparisons demonstrated greater impairment in individuals with ASD, analyzing individuals' characteristics revealed cross-diagnoses similarities in regard to their MSPSS-f relationships. This is consistent with the Research Domain Criteria framework, supporting a trans-diagnostic approach as on the path toward “precision medicine.” Autism Res 2017, 10: 866–877. © 2017 International Society for Autism Research, Wiley Periodicals, Inc. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.","2017","2021-02-15 22:36:24","2021-02-15 22:36:24","","866-877","","5","10","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86MUNPVI","journalArticle","2017","Shimada, T.; Sakurai, A.","Recognition of empathy seeking questions in one of the largest woman CQA in Japan","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-54472-4_60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018617990&doi=10.1007%2f978-3-319-54472-4_60&partnerID=40&md5=001e186fe5d53db5baeeab37adfd42ee","Many questions are posted on community websites in the world. Some of these questions are actually asked in order to receive empathy for the feelings of questioners, instead of getting specific answers to the questions asked. However, it is difficult to receive answers for these questions compared with questions that are asked for seeking responses other than for empathy. If such questions that are asked for the purpose of receiving empathy can get responses, it serves as an important factor to increase satisfaction of users. This paper reports on our attempt to improve response rate to the questions by classifying those questions that are asked for seeking empathy and those that are not by using machine learning and showing the questions classified as the ones seeking empathy to the prospective respondents who have been answered to these questions with higher rate. © Springer International Publishing AG 2017.","2017","2021-02-15 22:36:24","2021-02-15 22:36:24","","641-650","","","10191 LNAI","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPAS9M8A","conferencePaper","2017","Ramaswamy, N.; MacDonald, E.","Telepathic product design for water conservation","Proceedings of the International Conference on Engineering Design, ICED","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029740073&partnerID=40&md5=0f5e5840bdf2bc50fe33cc19d5ccde90","Can a product that reads the user's mind behave more efficiently and eventually train the user to conserve? Here, as a first step to answering this big question, we present a design method for telepathic products applied to the case study of a kitchen faucet. The case study is used to illustrate the different steps of the design method: (A) Build cognitive empathy and define cognitive styles; (B) Define design requirements, articulate variables that will control performance, understand limitations and design physical product; (C) Design the machine learning algorithm, inputs, and outputs; and (D) Integration and refinement. This work-in-progress report highlights the intricacies of applying adaptive machinelearning behavior to physical products performance in the ""real world"" rather than to a website or device such as a smart phone. Interesting findings include that automatic response, typically associated with websites and phones, is not possible with plumbing as water cannot be instantly at the right temperature; and that cognitive styles indeed manifest in dish washing observations, with distinctly different styles in terms of patience, temperature sensitivity, and laziness.","2017","2021-02-15 22:36:24","2021-02-15 22:36:24","","169-178","","","1","","","","","","","","","","","","","","","","","Issue: DS87-1","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3IYMTVL","journalArticle","2016","López-Gil, J.-M.; Virgili-Gomá, J.; Gil, R.; García, R.","Method for improving EEG based emotion recognition by combining it with synchronized biometric and eye tracking technologies in a non-invasive and low cost way","Frontiers in Computational Neuroscience","","","10.3389/fncom.2016.00085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983514538&doi=10.3389%2ffncom.2016.00085&partnerID=40&md5=eccb032d2d09f3fb6cc015458abac70d","Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric, and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving forty-four people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals, and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self-regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods. © 2016 López-Gil, Virgili-Gomá, Gil and García.","2016","2021-02-15 22:36:24","2021-02-15 22:36:24","","","","AUG","10","","","","","","","","","","","","","","","","","","<p>cited By 20</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GI9Q6TSK","conferencePaper","2016","Kido, T.; Swan, M.","Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51","Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2016","2021-02-15 22:36:24","2021-02-15 22:36:24","","362-368","","","SS-16-01 - 07","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2KGZWQ8","journalArticle","2016","Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.","Machine learning and empathy: The Civil Rights CAPTCHA","Concurrency Computation","","","10.1002/cpe.3632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958909683&doi=10.1002%2fcpe.3632&partnerID=40&md5=458756a37cac7783f5c8ceeed964ed3f","Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7% of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are leaking too much information by unexpected ways, given non-evident design flaws. Copyright © 2015 John Wiley & Sons, Ltd.","2016","2021-02-15 22:36:24","2021-02-15 22:36:24","","1310-1323","","4","28","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EUVAVT38","conferencePaper","2016","Bertero, D.; Siddique, F.B.; Wu, C.-S.; Wan, Y.; Chan, R.H.Y.; Fung, P.","Real-time speech emotion and sentiment recognition for interactive dialogue systems","EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings","","","10.18653/v1/d16-1110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072837881&doi=10.18653%2fv1%2fd16-1110&partnerID=40&md5=cb47e47a58a6fe6643e7e847811cbdc0","In this paper, we describe our approach of enabling an interactive dialogue system to recognize user emotion and sentiment in real-time. These modules allow otherwise conventional dialogue systems to have “empathy” and answer to the user while being aware of their emotion and intent. Emotion recognition from speech previously consists of feature engineering and machine learning where the first stage causes delay in decoding time. We describe a CNN model to extract emotion from raw speech input without feature engineering. This approach even achieves an impressive average of 65.7% accuracy on six emotion categories, a 4.5% improvement when compared to the conventional feature based SVM classification. A separate, CNN-based sentiment analysis module recognizes sentiments from speech recognition results, with 82.5 F-measure on human-machine dialogues when trained with out-of-domain data. © 2016 Association for Computational Linguistics","2016","2021-02-15 22:36:24","2021-02-15 22:36:24","","1042-1047","","","","","","","","","","","","","","","","","","","","","<p>cited By 27</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZ7RMAZG","conferencePaper","2016","Kawahara, T.; Yamaguchi, T.; Inoue, K.; Takanashi, K.; Ward, N.","Prediction and generation of backchannel form for attentive listening systems","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","10.21437/Interspeech.2016-118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994351223&doi=10.21437%2fInterspeech.2016-118&partnerID=40&md5=0be540a15263f6c99286d45ff0b40cb6","In human-human dialogue, especially in attentive listening such as counseling, backchannels are important not only for smooth communication but also for establishing rapport. Despite several studies on when to backchannel, most of the current spoken dialogue systems generate the same pattern of backchannels, giving monotonous impressions to users. In this work, we investigate generation of a variety of backchannel forms according to the dialogue context. We first show the feasibility of choosing appropriate backchannel forms based on machine learning, and the synergy of using linguistic and prosodic features. For generation of backchannels, a framework based on a set of binary classifiers is adopted to effectively make a ""not-to-generate"" decision. The proposed model achieved better prediction accuracy than a baseline which always outputs the same backchannel form and another baseline which randomly generates backchannels. Finally, evaluations by human subjects demonstrate that the proposed method generates backchannels as naturally as human choices, giving impressions of understanding and empathy. Copyright © 2016 ISCA.","2016","2021-02-15 22:36:25","2021-02-15 22:36:25","","2890-2894","","","08-12-September-2016","","","","","","","","","","","","","","","","","","<p>cited By 15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPEEVBDY","journalArticle","2016","Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.","Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents","Transactions of the Japanese Society for Artificial Intelligence","","","10.1527/tjsai.C-G31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a","There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.","2016","2021-02-15 22:36:25","2021-02-15 22:36:25","","","","4","31","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJG8UUNI","conferencePaper","2015","Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.","Real-time sociometrics from audio-visual features for two-person dialogs","International Conference on Digital Signal Processing, DSP","","","10.1109/ICDSP.2015.7251991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961315280&doi=10.1109%2fICDSP.2015.7251991&partnerID=40&md5=447bee82a1f60ad7b9676da82921a344","This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus. © 2015 IEEE.","2015","2021-02-15 22:36:25","2021-02-15 22:36:25","","823-827","","","2015-September","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDU5GFBY","journalArticle","2015","Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.","A machine learning attack against the civil rights CAPTCHA","Studies in Computational Intelligence","","","10.1007/978-3-319-10422-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921532152&doi=10.1007%2f978-3-319-10422-5_26&partnerID=40&md5=c429dffc0b1e39cc4456d096362e8de0","Human Interactive Proofs (HIPs) are a basic security measure on the Internet to avoid several types of automatic attacks. Recently, a new HIP has been designed to increase security: the Civil Rights CAPTCHA. It employs the empathy capacity of humans to further strengthen the security of a well known OCR CAPTCHA, Securimage. In this paper, we analyse it from a security perspective, pointing out its design flaws. Then, we create a successful side-channel attack, leveraging some well-known machine learning algorithms. © Springer International Publishing Switzerland 2015.","2015","2021-02-15 22:36:25","2021-02-15 22:36:25","","239-248","","","570","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DE3V4NUZ","journalArticle","2014","Bedi, G.; Cecchi, G.A.; Slezak, D.F.; Carrillo, F.; Sigman, M.; De Wit, H.","A window into the intoxicated mind? Speech as an index of psychoactive drug effects","Neuropsychopharmacology","","","10.1038/npp.2014.80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906320793&doi=10.1038%2fnpp.2014.80&partnerID=40&md5=7ed580cdfca01c709a69f11704fd3729","Abused drugs can profoundly alter mental states in ways that may motivate drug use. These effects are usually assessed with self-report, an approach that is vulnerable to biases. Analyzing speech during intoxication may present a more direct, objective measure, offering a unique 'window' into the mind. Here, we employed computational analyses of speech semantic and topological structure after ±3,4-methylenedioxymethamphetamine (MDMA; 'ecstasy') and methamphetamine in 13 ecstasy users. In 4 sessions, participants completed a 10-min speech task after MDMA (0.75 and 1.5 mg/kg), methamphetamine (20 mg), or placebo. Latent Semantic Analyses identified the semantic proximity between speech content and concepts relevant to drug effects. Graph-based analyses identified topological speech characteristics. Group-level drug effects on semantic distances and topology were assessed. Machine-learning analyses (with leave-one-out cross-validation) assessed whether speech characteristics could predict drug condition in the individual subject. Speech after MDMA (1.5 mg/kg) had greater semantic proximity than placebo to the concepts friend, support, intimacy, and rapport. Speech on MDMA (0.75 mg/kg) had greater proximity to empathy than placebo. Conversely, speech on methamphetamine was further from compassion than placebo. Classifiers discriminated between MDMA (1.5 mg/kg) and placebo with 88% accuracy, and MDMA (1.5 mg/kg) and methamphetamine with 84% accuracy. For the two MDMA doses, the classifier performed at chance. These data suggest that automated semantic speech analyses can capture subtle alterations in mental state, accurately discriminating between drugs. The findings also illustrate the potential for automated speech-based approaches to characterize clinically relevant alterations to mental state, including those occurring in psychiatric illness. © 2014 American College of Neuropsychopharmacology.","2014","2021-02-15 22:36:25","2021-02-15 22:36:25","","2340-2348","","10","39","","","","","","","","","","","","","","","","","","<p>cited By 46</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFH2Z8R9","journalArticle","2011","Hong, Y.; Chintapalli, S.V.; Bhardwaj, G.; Zhang, Z.; Patterson, R.L.; Van Rossum, D.B.","Adaptive-BLAST: A user-defined platform for the study of proteins","Journal of Integrated OMICS","","","10.5584/jiomics.v1i1.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977578892&doi=10.5584%2fjiomics.v1i1.33&partnerID=40&md5=8a374620bfbb5cb5c870b18fd7ebba80","Profile-based protein-sequence analysis algorithms comprise some of the most powerful and user-friendly methods for exploring protein sequences to determine their structure, function, and/or evolution (1-4). PSI-BLAST (5, 6) and rps-BLAST (7) are two of the most popular profile-based algorithms ( 1,120 references to date), and have exceptional utility in the identification of homology between proteins, particularly for biological scientists who do not specialize in computational approaches. However, when the performance of these algorithms is compared to other methods [e.g. support-vector machine learning (SVM) (8), hidden-Markov models (HMMs) (9)], they often underperform in identifying the aforementioned protein properties (3, 9-11). We have previously demonstrated that the utility of BLAST algorithms can be significantly improved by: (i) adaptations to the profile libraries employed, (ii) adjustments to output formats, and (iii) alterations to BLAST algorithm itself (4, 6, 12-14). We present here Adaptive-BLAST (Ada-BLAST), which provides a simple user-defined platform for measuring and analyzing primary amino acid sequences. Within this platform, we developed a series of local BLAST applications (apps) that take advantage of the speed and sensitivity afforded by BLAST, while allowing for maximal user-definitions and flexible visualization. We tested the efficacy of these apps in control experiments, studying fold-recognition, in which we obtained >90% accuracy in highly divergent sequences (>25% identity). In addition, these same apps were proficient in classifying transmembrane proteins, identifying structural/functional determinants of ion-channels/receptors, and informing structural modeling algorithms. Indeed, these Ada-BLAST informed-structural models were useful in guiding our experimental research on the N-terminus of Transient Receptor Potential ion-channels (TRPs). Taken together, we propose that Ada-BLAST provides a powerful computational tool that is accessible to bench-scientists and computational biologists alike. The codes for Ada-BLAST are publicly available at: http://empathy.rcc.psu.edu/. © 2011, Proteomass Scientific Society. All rights reserved.","2011","2021-02-15 22:36:25","2021-02-15 22:36:25","","88-101","","1","1","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVV6SDHC","journalArticle","2021","Kiesow, H.; Spreng, R.N.; Holmes, A.J.; Chakravarty, M.M.; Marquand, A.F.; Yeo, B.T.T.; Bzdok, D.","Deep learning identifies partially overlapping subnetworks in the human social brain","Communications Biology","","","10.1038/s42003-020-01559-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099382680&doi=10.1038%2fs42003-020-01559-z&partnerID=40&md5=6fa716c14a9bf81828cfd5652c23f05f","Complex social interplay is a defining property of the human species. In social neuroscience, many experiments have sought to first define and then locate ‘perspective taking’, ‘empathy’, and other psychological concepts to specific brain circuits. Seldom, bottom-up studies were conducted to first identify explanatory patterns of brain variation, which are then related to psychological concepts; perhaps due to a lack of large population datasets. In this spirit, we performed a systematic de-construction of social brain morphology into its elementary building blocks, involving 10,000 UK Biobank participants. We explored coherent representations of structural co-variation at population scale within a recent social brain atlas, by translating autoencoder neural networks from deep learning. The learned subnetworks revealed essential patterns of structural relationships between social brain regions, with the nucleus accumbens, medial prefrontal cortex, and temporoparietal junction embedded at the core. Some of the uncovered subnetworks contributed to predicting examined social traits in general, while other subnetworks helped predict specific facets of social functioning, such as the experience of social isolation. As a consequence of our population-level evidence, spatially overlapping subsystems of the social brain probably relate to interindividual differences in everyday social life. © 2021, The Author(s).","2021","2021-02-15 22:36:59","2021-02-15 22:36:59","","","","1","4","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J39FXJPS","conferencePaper","2020","Toxtli, C.; Richmond-Fuller, A.; Savage, S.","Reputation Agent: Prompting Fair Reviews in Gig Markets","The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","","","10.1145/3366423.3380199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589321&doi=10.1145%2f3366423.3380199&partnerID=40&md5=8235c305e0974c8f0c5d3911f16d1058","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers. © 2020 ACM.","2020","2021-02-15 22:37:00","2021-02-15 22:37:00","","1228-1240","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LME39J8D","conferencePaper","2020","Sedoc, J.; Buechel, S.; Nachmany, Y.; Buffone, A.; Ungar, L.","Learning word ratings for empathy and distress from document-level user responses","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096597898&partnerID=40&md5=5c3de64d2b5ef62d84ba3bb9cec6e99e","Despite the excellent performance of black box approaches to modeling sentiment and emotion, lexica (sets of informative words and associated weights) that characterize different emotions are indispensable to the NLP community because they allow for interpretable and robust predictions. Emotion analysis of text is increasing in popularity in NLP; however, manually creating lexica for psychological constructs such as empathy has proven difficult. This paper automatically creates empathy word ratings from document-level ratings. The underlying problem of learning word ratings from higher-level supervision has to date only been addressed in an ad hoc fashion and has not used deep learning methods. We systematically compare a number of approaches to learning word ratings from higher-level supervision against a Mixed-Level Feed Forward Network (MLFFN), which we find performs best, and use the MLFFN to create the first-ever empathy lexicon. We then use Signed Spectral Clustering to gain insights into the resulting words. The empathy and distress lexica are publicly available at: http://www.wwbp.org/lexica.html. © European Language Resources Association (ELRA), licensed under CC-BY-NC","2020","2021-02-15 22:37:00","2021-02-15 22:37:00","","1664-1673","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAKH3KVR","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting future alleviation of mental illness in social media: An empathy-based social network perspective","Proceedings - 2019 IEEE Intl Conf on Parallel and Distributed Processing with Applications, Big Data and Cloud Computing, Sustainable Computing and Communications, Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085484201&doi=10.1109%2fISPA-BDCloud-SustainCom-SocialCom48970.2019.00230&partnerID=40&md5=b25cfa36d495be8d70325de2a2fd3932","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed. © 2019 IEEE.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","1564-1571","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4C83YRV","conferencePaper","2019","Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019","","","10.1109/RITAPP.2019.8932852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","160-163","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDH7SRU8","journalArticle","2019","Sena, J.R.; Cabatuan, M.","Deep learning-based facial expression recognition and analysis for filipino gamers","International Journal of Recent Technology and Engineering","","","10.35940/ijrte.B1027.078219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286","This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","1822-1827","","2","8","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLA2XAGL","conferencePaper","2019","Barbieri, F.; Guizzo, E.; Lucchesi, F.; Maffei, G.; Del Prado Martín, F.M.; Weyde, T.","Towards a multimodal time-based empathy prediction system","Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019","","","10.1109/FG.2019.8756532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070472384&doi=10.1109%2fFG.2019.8756532&partnerID=40&md5=68ba6051cdf7332258f7450ae3a6e899","We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community. © 2019 IEEE.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HFW6AR7X","journalArticle","2019","Piumatti, G.; Abbiati, M.; Baroffio, A.; Gerbase, M.W.","Associations between motivational factors for studying medicine, learning approaches and empathy among medical school candidates","Advances in Health Sciences Education","","","10.1007/s10459-018-9866-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056658658&doi=10.1007%2fs10459-018-9866-6&partnerID=40&md5=03617490c381649c560fcd1583bafa25","Previous research highlighted associations between students’ motivation for medical studies and their learning approaches on the one hand and empathy on the other. Internal motivational factors for studying medicine (e.g., care for patients, save lives) coupled with a deep approach to learning have been positively related to empathy in contrast to external motivational factors (e.g., future earning potential, prestige) and surface learning. However, assessments of these assumptions among medical school candidates are scarce. This study examined the relationship between different motivational factors and empathy among students enrolled in a selection year in medicine by testing the mediating role of learning approaches. A sample of 572 candidates for medical studies answered a self-reported questionnaire half way through their selection year. Measures included internal and external motivational factors for studying medicine, deep and surface learning approaches and empathy. Path-analysis tested the mediation effects of deep and surface approaches to learning on the relationship of internal and external motivational factors with empathy. The deep learning approach partially mediated the significant positive association between internal motivational factors and empathy, while the surface learning approach fully mediated the significant negative association between external motivational factors and empathy. These results suggest that learning approaches could be a pathway by which internal and external motives for studying medicine are related to empathy among medical school candidates. Pedagogical strategies and educational environments accounting for individual differences in motivation and learning may contribute to training students to become professional and caring doctors in the future. © 2018, Springer Nature B.V.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","287-300","","2","24","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KKML78KE","journalArticle","2019","Sanal, M.G.; Paul, K.; Kumar, S.; Ganguly, N.K.","Artificial intelligence and deep learning: The future of medicine and medical practice","Journal of Association of Physicians of India","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067569100&partnerID=40&md5=cc6799f54fa56c639d845a3e9b5806d1","Artificial Intelligence (AI) and access to “Big Data” together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (“wiki”) with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition. © 2019, Journal of Association of Physicians of India. All rights reserved.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","71-73","","May","67","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TI4TB5KF","conferencePaper","2019","Self, B.P.; Widmann, J.","Access for all: Promoting universal design thinking in a rehabilitation engineering course","Proceedings of the 8th Research in Engineering Education Symposium, REES 2019 - Making Connections","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071475285&partnerID=40&md5=6a52fd874b773b65de7b8084345f0ba4","Service learning is a high impact practice that can greatly increase motivation and promote deep learning. We have developed a project-based Rehabilitation Engineering course that included both Biomedical Engineering and Mechanical Engineering students. Projects were supplied by local non-profit community partners (for example Special Olympics), and focused on developing products for people with mobility impairments. In addition to the projects, student assignments included reflection prompts, four hours of community service (two of which had to involve direct contact with people of different abilities), and a sensory deprivation experience to develop empathy. Qualitative evaluation of student responses showed that students were able to develop some aspects of design empathy and understood the importance of accessibility and universal design. Copyright © 2019 Brian Self and Jim Widmann.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","369-377","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZEXMTGXJ","journalArticle","2019","Griffiths, D.B.","When David met Michel","Religious Studies and Theology","","","10.1558/RSTH.38299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071428686&doi=10.1558%2fRSTH.38299&partnerID=40&md5=8aff8e71418d01a4196fb32b0f3976e8","I entered the Department of Religious Studies in Vancouver in the Fall of 1974. Michel was a year or two advanced and the first person to befriend me and ""show me the robes."" He is a unique individual with generosity of Geist or empathy, and deep analytical skills, wide interests, lucid thinking. His books and many students are evidence of this. It has been a deep joy to be his friend through the years. He has always helped me with intellectual projects and been attentive to personal issues, and all this without a touch of pedantry or arrogance. In addition to his deep learning in Religious Studies and related topics, he has a gift for empathic listening, and a singular capacity to think on his feet and lecture with amazing lucidity. © Equinox Publishing Ltd. 2019.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","223-225","","1-2","38","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EB36HPFV","journalArticle","2019","Matsuyama, Y.; Asahi, Y.","High Sensitivity Layer Feature Analysis in Food Market","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-22649-7_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335","It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.","2019","2021-02-15 22:37:00","2021-02-15 22:37:00","","232-243","","","11570 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KP9F7FRY","conferencePaper","2018","Marda, M.; Economou, D.; Bouki, V.","Enhancing deeper learning using empathy and creativity in serious games role-play simulations","Proceedings of the European Conference on Games-based Learning","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058967153&partnerID=40&md5=756601e3f4f9ed506dd13d9e12ecdbfa","There is a shift in education towards adopting pedagogical approaches that nurture deeper learning. Educators recognise that effective and active approaches to teaching are more closely associated with deeper learning. These active approaches aim to develop higher order skills, encouraging learners’ critical thinking and decision-making as well as enhancing their capacity to be agile, flexible and adaptable. Among those active approaches stand serious games, which are powerful learning environments that are seen as an emergent and engaging new way of experiment situations and construct knowledge. Serious games, in the form of role-play simulations, are scenario-based games that are used to simulate real life situations. Although serious games and simulations have been widely used in serving educational purposes, there is little evidence on their use in achieving deeper learning. In addition, there is lack of guidelines or a framework for designing serious games to support learners achieve deep learning. This paper proposes a theoretical framework, based on Bloom’s educational model for Mastery Learning, which illustrates the design of instructional process adapted for serious games using empathy and creativity as an approach of designing serious games for achieving deeper learning. It describes an approach of evaluating this framework by designing a serious game focusing on raising awareness about domestic violence and abuse. © 2018, Dechema e.V. All rights reserved.","2018","2021-02-15 22:37:00","2021-02-15 22:37:00","","785-791","","","2018-October","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6UE4TSP","conferencePaper","2018","Asada, M.","Artificial pain: Empathy, morality, and ethics as a developmental process of consciousness","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059816137&partnerID=40&md5=0c3d169632da3fae45d6ce00852c1fc0","In this article, I propose a working hypothesis that the nervous system of pain sensation is a key component to shape robots' (artificial systems') conscious minds through the developmental process of empathy, morality, and ethics based on the MNS that promotes the emergence of concept of self (and others). First, the limitation of the current progress of AI focusing on deep learning is pointed out from a viewpoint of the emergence of consciousness. Next, the outline of ideological back-ground on issues of mind in a broad sense is shown. Then, cognitive developmental robotics (CDR) is introduced with two important concepts; physical embodiment and social interaction both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, an issue how robots (artificial systems) could be moral and legal agents is shown. © 2018 for the individual papers by the papers' authors. All rights reserved.","2018","2021-02-15 22:37:00","2021-02-15 22:37:00","","","","","2287","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THAHT5MD","journalArticle","2018","Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.","Towards empathetic human-robot interactions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-75487-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25","Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-02-15 22:37:00","2021-02-15 22:37:00","","173-193","","","9624 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HS8J5MBX","conferencePaper","2017","Xu, A.; Liu, Z.; Guo, Y.; Sinha, V.; Akkiraju, R.","A new chatbot for customer service on social media","Conference on Human Factors in Computing Systems - Proceedings","","","10.1145/3025453.3025496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454411&doi=10.1145%2f3025453.3025496&partnerID=40&md5=eb0554245b67f51b2c89e08ecccdd3ec","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric. © 2017 ACM.","2017","2021-02-15 22:37:00","2021-02-15 22:37:00","","3506-3510","","","2017-May","","","","","","","","","","","","","","","","","","<p>cited By 139</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WT2LJ33Z","journalArticle","2017","Chan, Z.C.Y.","Poetry writing and artistic ability in problem-based learning","International Journal on Disability and Human Development","","","10.1515/ijdhd-2016-0003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb","Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.","2017","2021-02-15 22:37:00","2021-02-15 22:37:00","","37-44","","1","16","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SP7CYYV","journalArticle","2016","Wiśniewska, M.; Grudowski, P.","High-quality academic teachers in business school. The case of The University of Gdańsk, Poland","Total Quality Management and Business Excellence","","","10.1080/14783363.2015.1064766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936966560&doi=10.1080%2f14783363.2015.1064766&partnerID=40&md5=0db7256a03085c4e979fe572a2f1f6ea","The Bologna process, the increasing number of higher education institutions, the mass education and the demographic problems make the quality of education and quality of the academic teachers a subject of wide public debate and concern. The aim of the paper is to identify the most preferred characteristics of a teacher working at a business school. The research problem was: What should a high-quality business school academic teacher be like? During the research, a six-stage qualitative survey design was proposed, and a letter questionnaire was applied as a free writing instrument and sent to second-year bachelor students of the Faculty of Management at The University of Gdańsk, Poland. To identify the most preferred characteristics, a content analysis and Pareto analysis were used. As a result, 32 characteristics were proposed and grouped into 5 categories, namely tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Based on this, several proposals and recommendations for the future were specified. The results obtained help not only to understand the needs of students, but also to prepare the most desired teaching environment in which deep learning outcomes are made possible for future managers in the context of modern economy. © 2015 Taylor & Francis.","2016","2021-02-15 22:37:00","2021-02-15 22:37:00","","1158-1170","","9-10","27","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLCRDVB8","conferencePaper","2016","Gibson, J.; Can, D.; Xiao, B.; Imel, Z.E.; Atkins, D.C.; Georgiou, P.; Narayanan, S.","A deep learning approach to modeling empathy in addiction counseling","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","10.21437/Interspeech.2016-554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994381542&doi=10.21437%2fInterspeech.2016-554&partnerID=40&md5=597e1b16131430e9c506dd9c234d9232","Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics. Copyright © 2016 ISCA.","2016","2021-02-15 22:37:01","2021-02-15 22:37:01","","1447-1451","","","08-12-September-2016","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTDWT5D8","conferencePaper","2016","Kido, T.; Swan, M.","Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing","AAAI Spring Symposium - Technical Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51","Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2016","2021-02-15 22:37:01","2021-02-15 22:37:01","","362-368","","","SS-16-01 - 07","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XSLDMKQ","journalArticle","2016","Abbiati, M.; Baroffio, A.; Gerbase, M.W.","Personal profile of medical students selected through a knowledge-based exam only: Are we missing suitable students?","Medical Education Online","","","10.3402/meo.v21.29705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007079343&doi=10.3402%2fmeo.v21.29705&partnerID=40&md5=f9afdbc35a30596a7a5ca8f19aee8413","Introduction: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. Methods: Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. Results: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. Conclusion: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile. © 2016 Milena Abbiati et al.","2016","2021-02-15 22:37:01","2021-02-15 22:37:01","","","","1","21","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82UWUSWI","conferencePaper","2013","Watkins Jr., D.W.; Paterson, K.G.; Barkdoll, B.D.","Educating engineers through international community engagement - What's it worth?","World Environmental and Water Resources Congress 2013: Showcasing the Future - Proceedings of the 2013 Congress","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887500608&partnerID=40&md5=a68db8ae1d9c1adcacd1e4db2970f879","International experiences have been promoted to better prepare students for the global and rapidly changing society in which we live, to help them realize the impacts of engineering solutions, and to help them develop a deeper empathy for their project stakeholders, often those living in developing countries. If the international experience incorporates serving others through a project of need, it is commonly believed that the students learn on a much deeper level than through the conventional learning approach of classroom lectures, homework problems, and tests. At Michigan Technological University, international community engagement (ICE) programs founded in engineering include an international senior (capstone) design program, a student chapter of Engineers Without Borders-USA, two Peace Corps Master's International programs, community-based participatory research programs, several social enterprises, an international sustainable development certificate, and many supportive classes. More than 500 students have participated in one or more of these programs in the last 15 years, and the vast majority of those surveyed have reported greater satisfaction with their education and a deeper learning experience compared to traditional on-campus learning. A more rigorous assessment program has more recently been adopted, permitting the examination of institutional, program, and student learning outcomes, among others. © 2013 American Society of Civil Engineers.","2013","2021-02-15 22:37:01","2021-02-15 22:37:01","","2155-2162","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PYAKTFK","conferencePaper","2013","Buckingham Shum, S.; De Laat, M.; De Liddo, A.; Ferguson, R.; Kirschner, P.; Ravenscroft, A.; Sándor, Á.; Whitelock, D.","DCLA13: 1st International Workshop on Discourse-Centric Learning Analytics","ACM International Conference Proceeding Series","","","10.1145/2460296.2460357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876484083&doi=10.1145%2f2460296.2460357&partnerID=40&md5=225eb84853168d852fc5766484f3ba1d","This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field. © 2013 Authors.","2013","2021-02-15 22:37:01","2021-02-15 22:37:01","","282","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGVZ3GJD","journalArticle","2012","Shepherd, R.-M.; Pinder, J.","Reflective practice in addiction studies: Promoting deeper learning and de-stigmatising myths about addictions","Reflective Practice","","","10.1080/14623943.2012.659098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863634090&doi=10.1080%2f14623943.2012.659098&partnerID=40&md5=015be0861ef77435a99d1fa7016ceb34","The following study was an exploratory journey to examine reflective practice amongst students taking the undergraduate paper 'Communities and Addiction'. This paper has been an elective paper within the Health Sciences for third year students at the University of Auckland for three years. The students were instructed to reflect on two assignments after they had written each one. The first assignment focused on addiction models and the second assignment focused on social marketing as a public health approach to potentially addictive behaviour (e.g. substance abuse, gambling, and eating disorders). The findings from the first assignment suggested that students developed (or enhanced) empathy towards sufferers of addiction. The findings from both of the assignments revealed that many of the students were developing reflective skills, though often this was at quite a basic level. These findings suggested that more guidance and feedback is needed to aid students in the reflective journey. © 2012 Copyright Taylor and Francis Group, LLC.","2012","2021-02-15 22:37:01","2021-02-15 22:37:01","","541-550","","4","13","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDX9EQQM","journalArticle","2011","Nordstrom, K.; Korpelainen, P.","Creativity and inspiration for problem solving in engineering education","Teaching in Higher Education","","","10.1080/13562517.2011.560379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957795995&doi=10.1080%2f13562517.2011.560379&partnerID=40&md5=94f753d604514090fc63ad97df5e76f9","Problem solving is a critical skill for engineering students and essential to development of creativity and innovativeness. Essential to such learning is an ease of communication and allowing students to address the issues at hand via the terminology, attitudes, humor and empathy, which is inherent to their frame of mind as novices, without the attempt to have to be the expert. Deep learning of scientific fact can be facilitated by using non-conventional tools for teaching, learning and presentation such as drama, video, posters, model making and other similar means. It may be time to break free of the PowerPoint tradition to generate successful approaches for establishing student engagement and maintaining such engagement. © 2011 Taylor & Francis.","2011","2021-02-15 22:37:01","2021-02-15 22:37:01","","439-450","","4","16","","","","","","","","","","","","","","","","","","<p>cited By 27</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEDKTWNF","journalArticle","2020","Rueda, J.; Lara, F.","Virtual Reality and Empathy Enhancement: Ethical Aspects","Frontiers in Robotics and AI","","","10.3389/frobt.2020.506984","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096676765&doi=10.3389%2ffrobt.2020.506984&partnerID=40&md5=4b19807309d5e5fc09617f353c543157","The history of humankind is full of examples that indicate a constant desire to make human beings more moral. Nowadays, technological breakthroughs might have a significant impact on our moral character and abilities. This is the case of Virtual Reality (VR) technologies. The aim of this paper is to consider the ethical aspects of the use of VR in enhancing empathy. First, we will offer an introduction to VR, explaining its fundamental features, devices and concepts. Then, we will approach the characterization of VR as an “empathy machine,” showing why this medium has aroused so much interest and why, nevertheless, we do not believe it is the ideal way to enhance empathy. As an alternative, we will consider fostering empathy-related abilities through virtual embodiment in avatars. In the conclusion, however, we will examine some of the serious concerns related to the ethical relevance of empathy and will defend the philosophical case for a reason-guided empathy, also suggesting specific guidelines for possible future developments of empathy enhancement projects through VR embodied experiences. © Copyright © 2020 Rueda and Lara.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","7","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AEDL2Y4D","journalArticle","2020","Patané, I.; Lelgouarch, A.; Banakou, D.; Verdelet, G.; Desoche, C.; Koun, E.; Salemme, R.; Slater, M.; Farnè, A.","Exploring the Effect of Cooperation in Reducing Implicit Racial Bias and Its Relationship With Dispositional Empathy and Political Attitudes","Frontiers in Psychology","","","10.3389/fpsyg.2020.510787","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095935756&doi=10.3389%2ffpsyg.2020.510787&partnerID=40&md5=792c83d8c15eb412507f81480740cbdb","Previous research using immersive virtual reality (VR) has shown that after a short period of embodiment by White people in a Black virtual body, their implicit racial bias against Black people diminishes. Here we tested the effects of some socio-cognitive variables that could contribute to enhancing or reducing the implicit racial bias. The first aim of the study was to assess the beneficial effects of cooperation within a VR scenario, the second aim was to provide preliminary testing of the hypothesis that empathy and political attitudes could contribute to implicit bias about race, while the third aim was to explore the relationship between political attitudes and empathy. We had (Caucasian) participants embodied in a Black virtual body and engaged either in a cooperative (Coop group) or in a non-cooperative (Neutral group) activity with a confederate experimenter embodying another Black avatar. Before and after VR, we measured participants’ implicit racial bias by means of Implicit Association Test (IAT) and their perceived closeness toward the confederate experimenter. Before VR we also assessed participants’ political attitudes and empathy traits. Results revealed that, as compared to the Neutral group, the Coop group showed lower IAT scores after the social interaction. Interestingly, in the Neutral but not the Coop group the perceived closeness toward the confederate experimenter was associated with the initial racial bias: the more the participants reduced their distance, the more they reduced their IAT score. Moreover, reported traits of empathy and political attitudes significantly explained the variance observed in the initial implicit bias, with perspective-taking, empathic concern, and personal distress being significant predictors of the IAT scores. Finally, there was a relationship between political attitudes and empathy: the more participants considered themselves as left-wing voters, the higher their perspective-taking and empathic concern scores. We discuss these findings within the neuroscientific and social cognition field and encourage scholars from different domains to further explore whether and under which conditions a given manipulation for reducing racial bias could be efficiently transposed in VR. © Copyright © 2020 Patané, Lelgouarch, Banakou, Verdelet, Desoche, Koun, Salemme, Slater and Farnè.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","11","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V8STG25R","conferencePaper","2020","Cinieri, S.; Kapralos, B.; Uribe-Quevedo, A.; Lamberti, F.","Eye Tracking and Speech Driven Human-Avatar Emotion-Based Communication","2020 IEEE 8th International Conference on Serious Games and Applications for Health, SeGAH 2020","","","10.1109/SeGAH49190.2020.9201874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092743436&doi=10.1109%2fSeGAH49190.2020.9201874&partnerID=40&md5=69a18548064c1ffc5d460cba2c56c51d","Feelings, emotions, and empathy play an important role in many daily activities including verbal and non-verbal communication. Their automatic recognition and interpretation is important in a variety of applications requiring communication skills that are difficult to reproduce in computer-simulated environments, including those involving human-avatar interactions. Our recent work has begun investigating the development of intelligent avatars capable of detecting user (human) emotions to allow for realistic human-avatar interactions within medical-based virtual simulations and serious games. In this paper, we present a system that couples eye tracking and dialogue interpretation to allow for intelligent and realistic human-avatar communication. Although formal testing is required, preliminary results are promising, showing the potential of the system. © 2020 IEEE.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQP46NP2","journalArticle","2020","Küster, D.; Swiderska, A.","Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes","International Journal of Psychology","","","10.1002/ijop.12715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090926311&doi=10.1002%2fijop.12715&partnerID=40&md5=93cd342d1b06662a239ccc999e6dde9d","According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation. © 2020 The Authors. International Journal of Psychology published by John Wiley & Sons Ltd on behalf of International Union of Psychological Science.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBQMYKXG","conferencePaper","2020","Guarese, R.; De Jesus Oliveira, V.; Calepso, A.; Valer, R.; Iquiapaza, Y.; Nedel, L.; MacIel, A.","E-mpathy and the phantom limb sensation: A multisensory experience for embodiment of amputation","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818321&partnerID=40&md5=9987bba9a555676ea0699ec2b68a35dd","In the context of promoting empathy among people without disabilities, we propose an application to allow users to experience having an amputated arm. By providing both visual and haptic feedback, our application offers a multisensory experience to enhance the sense of embodiment. The user of our application should still feel their real limb attached to their bodies, and yet see their virtual avatar and interact with the virtual environment as an amputee. A simple task of handling and positioning objects in a table is proposed for users to experience the difficulties of having a missing arm. Additionally, experiment participants are asked to answer a self-presence questionnaire regarding their embodiment of the virtual avatar. Copyright © 2020 for this paper by its authors.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","13-16","","","2618","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIHX4SCT","conferencePaper","2020","Luca, A.I.; Podina, I.R.","The influence of moral factors on bullying behaviors in adolescence: Theoretical considerations and proposal for a vr intervention to promote perspective-taking skills","eLearning and Software for Education Conference","","","10.12753/2066-026X-20-005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096480125&doi=10.12753%2f2066-026X-20-005&partnerID=40&md5=25daff84e3f0c87d7fb3307f68449e84","In the last decade, bullying and cyberbullying has known a rapid growth with worrisome consequences in regards to adolescent mental health. In the process of understanding the factors that influence bullying behaviours, researchers turned towards investigating moral factors, such as moral emotions, especially disgust and anger, and particularly a process called” moral disengagement” (MD; [22]). Moral disengagement is thought to contribute to the reason why some individuals, although they express disgust and anger in response to bullying behaviors, do not intervene in such situations. The objective of this research is to propose a VR based intervention aimed at increasing prosocial behaviour by improving perspective taking-skills and empathy concern. In the current paper, we suggest an interactive training simulation program where adolescent volunteers will take their own perspective or the perspective of the avatar in virtual reality, being instructed to try and understand its mental states. The situations encountered in VR are meant to trigger feelings of disgust, anger or elevation, the latter being an emotion elicited by witnessing acts of moral goodness. By increasing the propensity to take the perspective of the avatar, we aim to decrease the process of moral disengagement, especially in bullying and cyberbullying situations and increase prosocial behavior in adolescents. © 2020, National Defence University - Carol I Printing House. All rights reserved.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","415-476","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XQDPCCJQ","journalArticle","2020","Dorn, A.W.; Dawson, P.F.","Simulating Peace Operations: New Digital Possibilities for Training and Public Education","Simulation and Gaming","","","10.1177/1046878120968605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095452183&doi=10.1177%2f1046878120968605&partnerID=40&md5=fa1122832b21ccc429123ceace2be44d","Background and Motivation.: A plethora of warfighting games exist commercially, but there is a lack of digital games that deal with peace processes. Furthermore, none simulate actual peacekeeping. The United Nations currently deploys about 100,000 peacekeepers to some of the world’s most dangerous zones, where peacekeepers save lives, alleviate suffering, and help create conditions for peace. The United Nations and national militaries lack peacekeeping simulations to help train their soldiers. Additionally, the public needs to learn more about the way peacekeeping works. Thus, peacekeeping simulation and gaming are worth exploring, especially in the rapidly evolving digital space, which offers new avenues and benefits. Methods.: We review the meager literature on the subject and observe that there are few digital games to directly draw from. We build on previous work that argued the need for such development, but we now assess important design principles and parameters. We draw upon peacekeeping tabletop exercises that are already well developed. Results.: We conclude that excellent scenarios and simulation technologies exist that could be combined quite easily for effective peacekeeping training and public education. We find key materials and scenarios in exercises of the United Nations and of the Pearson Peacekeeping Centre. Highlighted areas for future digital design are the inclusion of non-military avatars, emphasis on soft skills development (especially empathy), and realistically complex links between actions and consequences. Conclusion.: While describing some UN exploration at a proof-of-concept stage, we suggest that both the United Nations and the gaming industry should explore the idea further to achieve synergies between institutional and entertainment applications. The growing capacity of digital technology allows significant innovation, yielding results that could be useful, ethical, enjoyable, and potentially profitable. © 2020 SAGE Publications.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FU6GEA5V","journalArticle","2020","Pribbenow, C.M.; Caldwell, K.E.H.; Dantzler, D.D.; Brown, Jr., P.; Carnes, M.","Decreasing Racial Bias Through A Facilitated Game and Workshop: The Case of Fair Play","Simulation and Gaming","","","10.1177/1046878120983384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098243099&doi=10.1177%2f1046878120983384&partnerID=40&md5=d34a04335f4fc627541d343be8135d8e","Introduction. Fair Play is an avatar-based role-playing video game in which Jamal Davis, a Black graduate student at a research university, navigates implicit forms of racial bias to reach the win-state of earning his PhD and becoming a professor. Fair Play was designed to educate players on the existence of racial bias in science, technology, engineering, mathematics, and medicine (STEMM) fields in an experiential way and to encourage perspective-taking. Research has found that taking the perspective of another can induce empathy, which improves the empathizer’s attitudes towards individuals and groups. Paired with a facilitated workshop, Fair Play was also designed to teach bias concepts to increase participants’ bias literacy. Intervention. Research on workshops to reduce gender bias suggests that it increased awareness of personal bias, the motivation and self-efficacy to practice bias-reducing strategies, and a more welcoming department climate and the hiring of more women faculty three years after the intervention. Capitalizing on these findings, a 3-hour workshop was developed to reduce race-based bias against Black/African Americans in STEMM using Fair Play. Conclusions. The facilitation of the workshops and Fair Play requires particular competencies due to its topic (racial bias) and player’s skepticism about the reality of the bias incidents. Our data suggest that participants who identify as a person of color are more likely to believe that bias exists compared to White players, which can lead to a discussion about how the incidents in the game were designed and scripted. The facilitator also needs to be versed in a number of intentional design choices, such as Jamal not having voiceover and his success. Finally, this paper describes the Facilitator Game, which was developed as a complement to the game and allows a facilitator to jump to bias incidents quickly while debriefing and discussing the game to further participant learning. © 2020 SAGE Publications.","2020","2021-02-15 22:37:38","2021-02-15 22:37:38","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NM2S3UX5","journalArticle","2019","Wilde, P.; Evans, A.","Empathy at play: Embodying posthuman subjectivities in gaming","Convergence","","","10.1177/1354856517709987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070362093&doi=10.1177%2f1354856517709987&partnerID=40&md5=aab7a0ce8378b091e336a622000c3483","In this article, we address the need for a posthuman account of the relationship between the avatar and player. We draw on a particular line of posthumanist theory associated closely with the work of Karen Barad, Rosi Braidotti and N. Katherine Hayles that suggests a constantly permeable, fluid and extended subjectivity, displacing the boundaries between human and other. In doing so, we propose a posthuman concept of empathy in gameplay, and we apply this concept to data from the first author’s 18-month ethnographic field notes of gameplay in the MMORPG World of Warcraft. Exploring these data through our analysis of posthuman empathy, we demonstrate the entanglement of avatar–player, machine–human relationship. We show how empathy allows us to understand this relationship as constantly negotiated and in process, producing visceral reactions in the intra-connected avatar–player subject as well as moments of co-produced in-game action that require ‘affective matching’ between subjective and embodied experiences. We argue that this account of the avatar–player relationship extends research in game culture, providing a horizontal, non-hierarchical discussion of its most necessary interaction. © The Author(s) 2017.","2019","2021-02-15 22:37:38","2021-02-15 22:37:38","","791-806","","5-6","25","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JRV5QBC","journalArticle","2019","Agopyan, H.; Griffet, J.; Poirier, T.; Bredin, J.","Modification of knee flexion during walking with use of a real-time personalized avatar","Heliyon","","","10.1016/j.heliyon.2019.e02797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074684962&doi=10.1016%2fj.heliyon.2019.e02797&partnerID=40&md5=7dafd73a008abab427e577e1f020b1af","Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed. © 2019 The Author(s)","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","11","5","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHBLVMN4","conferencePaper","2019","Roth, D.; Bloch, C.; Schmitt, J.; Frischlich, L.; Latoschik, M.E.; Bente, G.","Perceived Authenticity, Empathy, and Pro-social Intentions evoked through Avatar-mediated Self-disclosures","ACM International Conference Proceeding Series","","","10.1145/3340764.3340797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072795574&doi=10.1145%2f3340764.3340797&partnerID=40&md5=4d0f505abddc6a24356b7791c9830f61","Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one’s avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","21-30","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNRWKG6S","conferencePaper","2019","Degraen, D.; Kosmalla, F.; Krüger, A.","Overgrown: Supporting plant growth with an endoskeleton for ambient notifications","Conference on Human Factors in Computing Systems - Proceedings","","","10.1145/3290607.3312833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067302392&doi=10.1145%2f3290607.3312833&partnerID=40&md5=737e704d963e985c7fe9415be110f795","Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments. © 2019 Copyright held by the owner/author(s).","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDTH7SCM","journalArticle","2019","Küster, D.; Krumhuber, E.G.; Hess, U.","You are What You Wear: Unless You Moved—Effects of Attire and Posture on Person Perception","Journal of Nonverbal Behavior","","","10.1007/s10919-018-0286-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055966865&doi=10.1007%2fs10919-018-0286-3&partnerID=40&md5=dfd97f867726dfa1ea0958eb2409c58f","While first impressions are often based on appearance cues, little is known about how these interact with information from other channels. The present research aimed to investigate the impact of occupational stereotypes, evoked by attire, as well as posture on person perception. For this, computer animation was used to create avatars with different types of attire (nurse, military, casual) and posture (open, closed). In Study 1 (N = 164), participants attributed significantly more empathy to avatars wearing a nurse versus a military uniform or casual outfit. When adding posture as an additional cue, Study 2 (N = 312) showed that ratings of empathy and dominance were affected by both attire and posture. This effect was replicated in Study 3 (N = 163) for female avatars, in the sense that open postures in nurses increased empathy ratings and decreased dominance ratings, which both in turn led to greater perceived competence. By contrast, for male avatars, posture did not affect attributions of competence directly. Rather, attire predicted perceived dominance directly, as well as through perceived empathy. The present findings suggest that both posture, and occupational information evoked by attire, are used to infer personal characteristics. However, the strength of each cue may vary with the gender of the target. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","23-38","","1","43","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRI6W2FS","conferencePaper","2019","Takano, M.; Tsunoda, T.","Self-disclosure of bullying experiences and social support in avatar communication: Analysis of verbal and nonverbal communications","Proceedings of the 13th International Conference on Web and Social Media, ICWSM 2019","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070376669&partnerID=40&md5=c4980b3e2f1fec8b0a980aab67deb0fa","Avatar communication through the Internet has great potential to be an appropriate environment for self-disclosure and social support. Anonymity and ease of access drive self-disclosure of even the most serious problems. Rich nonverbal communication, co-presence, and real-time interaction increase emotional closeness. However, there has not been much research with regard to examining social support in avatar communication. In this paper, we aim to facilitate self-disclosure and social support for bullied people through avatar communication. For this purpose, we analyzed verbal and nonverbal communication about bullying experiences through an avatar communication service. We demonstrate that people who emotionally disclosed their bullying experiences received better social support. In addition, people who provided social support used emotional expressions to convey emotional empathy. These were observed in conversations with a few acquaintances in closed spaces. Our findings reveal areas where we can improve upon the design of avatar communication spaces for effective social support. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","473-481","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJRIFE5J","journalArticle","2019","Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.","A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study","Journal of Medical Internet Research","","","10.2196/14658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2","Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.","2019","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","10","21","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPACCNFV","journalArticle","2018","Swiderska, A.; Küster, D.","Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots","Perception","","","10.1177/0301006618809919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058656094&doi=10.1177%2f0301006618809919&partnerID=40&md5=2d29a1feddf28df7efb1c2f080d656ba","Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain. © The Author(s) 2018.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","1139-1152","","12","47","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNWZ3GLI","journalArticle","2018","Hamilton-Giachritsis, C.; Banakou, D.; Garcia Quiroga, M.; Giachritsis, C.; Slater, M.","Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment","Scientific Reports","","","10.1038/s41598-018-21036-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042078955&doi=10.1038%2fs41598-018-21036-2&partnerID=40&md5=fb96ebbd43cee03a0b332b62bfa1347d","The ability to perspective-take (cognitive awareness of another's state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a 'mother avatar', which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children. © 2018 The Author(s).","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","1","8","","","","","","","","","","","","","","","","","","<p>cited By 10</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REP27BNE","journalArticle","2018","Joyal, C.C.; Neveu, S.-M.; Boukhalfi, T.; Jackson, P.L.; Renaud, P.","Suppression of sensorimotor alpha power associated with pain expressed by an avatar: A preliminary EEG study","Frontiers in Human Neuroscience","","","10.3389/fnhum.2018.00273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054880498&doi=10.3389%2ffnhum.2018.00273&partnerID=40&md5=fc408903253633371b024fcb0042b21e","Several studies using functional magnetic resonance imaging (fMRI) showed that empathic capabilities are associated with the activation (and deactivation) of relatively specific neural circuits. A growing number of electroencephalography studies also suggest that it might be useful to assess empathy. The main goal of this study was to use quantitative electroencephalography (qEEG) to test whether observation of pain expressed by an avatar (virtual reality) induces a suppression of alpha waves over sensorimotor cortical areas, as it is observed with human stimuli. Not only was it the case, but also the magnitude of alpha suppression was correlated with perspective-taking capacity of participants. Both empathy levels and magnitude of sensorimotor alpha suppression (SAS) were significantly higher in women than men. Interestingly, a significant interaction emerged between levels of individual empathy and specificity of experimental instructions, where SAS in participants with good perspective-taking was higher during passive observation of the distressed avatar, while the opposite was true during an active (trying to understand) condition. These results suggest that: (1) synthetic characters are able to elicit SAS; (2) SAS is indeed associated with perspective-taking capacities; (3) Persons with poorer perspective-taking capacities can show significant SAS when proper instructions are provided. Therefore, qEEG represents a low-cost objective approach to measure perspective-taking abilities. © 2018 Joyal, Neveu, Boukhalfi, Jackson and Renaud.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","","12","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TLVVUT9","conferencePaper","2018","Raffe, W.L.; Garcia, J.A.","Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly","2018 IEEE 6th International Conference on Serious Games and Applications for Health, SeGAH 2018","","","10.1109/SeGAH.2018.8401371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050191845&doi=10.1109%2fSeGAH.2018.8401371&partnerID=40&md5=131e80406d278219c3234b216c481603","This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations. © 2018 IEEE.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","1-7","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U952IPXK","journalArticle","2018","Bernard, F.; Lemée, J.-M.; Aubin, G.; Ter Minassian, A.; Menei, P.","Using a Virtual Reality Social Network During Awake Craniotomy to Map Social Cognition: Prospective Trial","Journal of medical Internet research","","","10.2196/10332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053566924&doi=10.2196%2f10332&partnerID=40&md5=11f551d8d5e0a5da719d0fabbdaa2a5b","BACKGROUND: In awake craniotomy, it is possible to temporarily inactivate regions of the brain using direct electrical stimulation, while the patient performs neuropsychological tasks. If the patient shows decreased performance in a given task, the neurosurgeon will not remove these regions, so as to maintain all brain functions. OBJECTIVE: The objective of our study was to describe our experience of using a virtual reality (VR) social network during awake craniotomy and discuss its future applications for perioperative mapping of nonverbal language, empathy, and theory of mind. METHODS: This was a single-center, prospective, unblinded trial. During wound closure, different VR experiences with a VR headset were proposed to the patient. This project sought to explore interactions with the neuropsychologist's avatar in virtual locations using a VR social network as an available experience. RESULTS: Three patients experienced VR. Despite some limitations due to patient positioning during the operation and the limitation of nonverbal cues inherent to the app, the neuropsychologist, as an avatar, could communicate with the patient and explore gesture communication while wearing a VR headset. CONCLUSIONS: With some improvements, VR social networks can be used in the near future to map social cognition during awake craniotomy. TRIAL REGISTRATION: ClinicalTrials.gov NCT03010943; https://clinicaltrials.gov/ct2/show/NCT03010943 (Archived at WebCite at http://www.webcitation.org/70CYDil0P). ©Florian Bernard, Jean-Michel Lemée, Ghislaine Aubin, Aram Ter Minassian, Philippe Menei. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 26.06.2018.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","e10332","","6","20","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63UHEUNA","journalArticle","2018","Johnson, E.; Hervás, R.; Gutiérrez López de la Franca, C.; Mondéjar, T.; Ochoa, S.F.; Favela, J.","Assessing empathy and managing emotions through interactions with an affective avatar","Health Informatics Journal","","","10.1177/1460458216661864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046768759&doi=10.1177%2f1460458216661864&partnerID=40&md5=7d10b56caf5c71b81ef6a0d346406804","Assistive technologies can improve the quality of life of people diagnosed with different forms of social communication disorders. We report on the design and evaluation of an affective avatar aimed at engaging the user in a social interaction with the purpose of assisting in communication therapies. A human–avatar taxonomy is proposed to assist the design of affective avatars aimed at addressing social communication disorder. The avatar was evaluated with 30 subjects to assess how effectively it conveys the desired emotion and elicits empathy from the user. Results provide evidence that users become used to the avatar after a number of interactions, and they perceive the defined behavior as being logical. The users’ interactions with the avatar entail affective reactions, including the mimic emotions that users felt, and establish a preliminary ground truth about prototypic empathic interactions with avatars that is being used to train learning algorithms to support social communication disorder evaluation. © 2016, © The Author(s) 2016.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","182-193","","2","24","","","","","","","","","","","","","","","","","","<p>cited By 12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AUGEUDUE","journalArticle","2018","Felnhofer, A.; Kafka, J.X.; Hlavacs, H.; Beutl, L.; Kryspin-Exner, I.; Kothgassner, O.D.","Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents","Computers in Human Behavior","","","10.1016/j.chb.2017.11.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037057403&doi=10.1016%2fj.chb.2017.11.031&partnerID=40&md5=c6ba24850a8392df3ff56ebe5b4f75bd","Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the Media Equation Concept (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses. © 2017 Elsevier Ltd","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","399-406","","","80","","","","","","","","","","","","","","","","","","<p>cited By 12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3WF6W9YN","conferencePaper","2018","Kowatsch, T.; Nißen, M.; Rüegger, D.; Stieger, M.; Flückiger, C.; Allemand, M.; Von Wangenheim, F.","The impact of interpersonal closeness cues in text-based healthcare chatbots on attachment bond and the desire to continue interacting: An experimental design","26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052961056&partnerID=40&md5=ea614d0bfe759b29a1dc7f99a9de87b3","Working alliance describes an important relationship quality between health professionals and patients and is robustly linked to treatment success. However, due to limited resources of health professionals, working alliance cannot always be promoted just-in-time in a ubiquitous fashion. To address this scalability problem, we investigate the direct effect of interpersonal closeness cues of text-based healthcare chatbots (THCBs) on attachment bond from the working alliance construct and the indirect effect on the desire to continue interacting with THCBs. The underlying research model and hypotheses are informed by counselling psychology and research on conversational agents. In order to investigate the hypothesized effects, we first develop a THCB codebook with 12 design dimensions on interpersonal closeness cues that are categorized into visual cues (i.e. avatar), verbal cues (i.e. greetings, address, jargon, T-V-distinction), quasi-nonverbal cues (i.e. emoticons) and relational cues (i.e. small talk, self-disclosure, empathy, humor, meta-relational talk and continuity). In a second step, four distinct THCB designs are developed along the continuum of interpersonal closeness (i.e. institutional-like, expert-like, peer-like and myself-like THCBs) and a corresponding study design for an interactive THCB-based online experiment is presented to test our hypotheses. We conclude this work-in-progress by outlining our future work. © 26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018. All Rights Reserved.","2018","2021-02-15 22:37:39","2021-02-15 22:37:39","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YURJ6A3U","journalArticle","2017","Ferguson, C.J.; Donnellan, M.B.","Are Associations Between “Sexist” Video Games and Decreased Empathy Toward Women Robust? A Reanalysis of Gabbiadini et al. 2016","Journal of Youth and Adolescence","","","10.1007/s10964-017-0700-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021122350&doi=10.1007%2fs10964-017-0700-x&partnerID=40&md5=603ebd5a0a8567a347e39875ef17c332","Gabbiadini, A., Riva, P., Andrighetto, L., Volpato, C., &amp; Bushman, B, (PloS ONE, 2016) provided evidence for a connection between “sexist” video games and decreased empathy toward girls using an experimental paradigm. These claims are based on a moderated mediation model. They reported a three-way interaction between game condition, gender, and avatar identification when predicting masculine ideology in their original study. Masculine ideology was associated, in turn, with decreased empathy. However, there were no main experimental effects for video game condition on empathy. The current analysis considers the strength of the evidence for claims made in the original study on a sample of 153 adolescents (Mage = 16.812, SD = 1.241; 44.2% male). We confirmed that there was little evidence for an overall effect of game condition on empathy toward girls or women. We tested the robustness of the original reported moderated mediation models against other, theoretically derived alternatives, and found that effects differed based on how variables were measured (using alternatives in their public data file) and the statistical model used. The experimental groups differed significantly and substantially in terms of age suggesting that there might have been issues with the procedures used to randomly assign participants to conditions. These results highlight the need for preregistration of experimental protocols in video game research and raise some concerns about how moderated mediation models are used to support causal inferences. These results call into question whether use of “sexist” video games is a causal factor in the development of reduced empathy toward girls and women among adolescents. © 2017, Springer Science+Business Media New York.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","2446-2459","","12","46","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVG72GEI","conferencePaper","2017","Murphy, D.","Building a hybrid virtual agent for testing user empathy and arousal in response to avatar (micro-)expressions","Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","","","10.1145/3139131.3141217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038598502&doi=10.1145%2f3139131.3141217&partnerID=40&md5=c1d14dd71b245eeb29f6de44b13ffa26","This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR. © 2017 Copyright held by the owner/author(s).","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","","","","Part F131944","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNFZS64P","conferencePaper","2017","Lin, C.; Faas, T.; Dombrowski, L.; Brady, E.","Beyond cute: Exploring user types and design opportunities of virtual reality pet games","Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","","","10.1145/3139131.3139132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038583884&doi=10.1145%2f3139131.3139132&partnerID=40&md5=f83b808eee343e0466b0933a733a4d62","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, little is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games. © 2017 Copyright is held by the owner/author(s).","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","","","","Part F131944","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WDCESBS","conferencePaper","2017","Vieira, S.; Maritan, T.; Santos, A.; Aschoff, M.; Costa, R.; Veríssimo, V.","A study on the use of multiple avatars in 3D sign language dictionaries","WebMedia 2017 - Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web","","","10.1145/3126858.3126865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035022193&doi=10.1145%2f3126858.3126865&partnerID=40&md5=dc3f278f2adca9d4a8b9a0f54aad8165","Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors. © 2017 ACM.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","325-332","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVVA9FVF","journalArticle","2017","Chin, G.P.W.-H.","Observed bodies and tool selves: kinaesthetic empathy and the videogame avatar","Digital Creativity","","","10.1080/14626268.2017.1348363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025148899&doi=10.1080%2f14626268.2017.1348363&partnerID=40&md5=c7661dcdf2925cb93633714b0755ded6","This paper examines the field of Kinaesthetic Empathy and how it is studied in dance and film then interrogates whether this framework can be applied to the videogame avatar. I study the avatar as textually signifying, as an observed body, and as a prosthetic tool-limb using the works of Merleau-Ponty and Heidegger as theoretical support and Ian Bogost’s procedural style of videogame reading. I perform close readings of videogame-texts Metal Gear Solid 3 and Mirror’s Edge demonstrating how the former enacts a traditional kinaesthetic empathy in the same way as in dance or film and the latter complicates this observer/performer relation. My paper concludes that, though a player/reader may experience a kinaesthetic empathy that resembles the filmic mode of observer/performer kinaesthetic empathy, the videogame form engenders a deeper tool-based empathy, which is altogether different from traditional conceptions of kinaesthetic empathy. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","206-223","","3","28","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVLMEXAX","journalArticle","2017","van Rijn, B.; Cooper, M.; Jackson, A.; Wild, C.","Avatar-based therapy within prison settings: pilot evaluation","British Journal of Guidance and Counselling","","","10.1080/03069885.2015.1068273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937883419&doi=10.1080%2f03069885.2015.1068273&partnerID=40&md5=eea27491822516edfa435a9ecda8e06b","The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n = 4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","268-283","","3","45","","","","","","","","","","","","","","","","","","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S9YX9BE","conferencePaper","2017","Tong, X.; Ulas, S.; Jin, W.; Gromala, D.; Shaw, C.","The design and evaluation of a body-sensing video game to foster empathy towards chronic pain patients","ACM International Conference Proceeding Series","","","10.1145/3154862.3154869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055989941&doi=10.1145%2f3154862.3154869&partnerID=40&md5=5e5c7a5c80904cdcb2071e511384877a","Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations. © 2017 Association for Computing Machinery.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","244-250","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SYH2Q34","journalArticle","2017","Jarvis, L.","The Ethics of Mislocalized Selfhood: Proprioceptive drifting towards the virtual other","Performance Research","","","10.1080/13528165.2017.1348587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029772572&doi=10.1080%2f13528165.2017.1348587&partnerID=40&md5=c0fc49b30428a3e8f4e132804abaebbd","In Psychology, ‘proprioceptive drift’ is a term that originates from the rubber hand illusion paradigm to describe the ‘relative displacement of the perceived location of one’s own hand toward the location of the rubber hand’ (Wold et al, 2014). Correspondingly, drift measurements in science are used as a means of rating the intensity of a body-ownership illusion via which a participant in a controlled experiment perceives that an extracorporeal appendage, or virtual whole-body avatar is incorporated as part of one’s own body schema. In this research article, I will examine an applied performance by BeAnotherLab utilising the anti-disciplinary collective’s The Machine to Be Another as part of Good Chance’s Encampment project–this telepresence system produces a VR body illusion intended to increase empathy and reduce proximity between an immersant’s real body and that of a volunteer refugee counterpart. When scientifically-tested body illusions cross a paradigmatic boundary to be framed as immersive art, what are the ethical implications? Furthermore, are these kinds of virtual proprioceptive transactions across different kinds of social and political boundaries symptomatic of radical empathic acts, or a capitalistic desire for the acquisition of another’s experiences by virtual means? This article examines illusory bodily inhabitation through a Levinasian critical lens to consider the ethics of deterritorializing the immersant’s gaze and referring their sense of touch elsewhere to produce ‘narrative immersion’. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","30-37","","3","22","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LY6ERAUB","journalArticle","2017","Conway, J.R.; Lee, D.; Ojaghi, M.; Catmur, C.; Bird, G.","Submentalizing or mentalizing in a level 1 perspective-taking task: A cloak and goggles test","Journal of Experimental Psychology: Human Perception and Performance","","","10.1037/xhp0000319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001065631&doi=10.1037%2fxhp0000319&partnerID=40&md5=4574eab974dd54505c02084899d36262","It has been proposed that humans possess an automatic system to represent mental states ('implicit mentalizing'). The existence of an implicit mentalizing system has generated considerable debate however, centered on the ability of various experimental paradigms to demonstrate unambiguously such mentalizing. Evidence for implicit mentalizing has previously been provided by the 'dot perspective task,' where participants are slower to verify the number of dots they can see when an avatar can see a different number of dots. However, recent evidence challenged a mentalizing interpretation of this effect by showing it was unaltered when the avatar was replaced with an inanimate arrow stimulus. Here we present an extension of the dot perspective task using an invisibility cloaking device to render the dots invisible on certain trials. This paradigm is capable of providing unambiguous evidence of automatic mentalizing, but no such evidence was found. Two further well-powered experiments used opaque and transparent goggles to manipulate visibility but found no evidence of automatic mentalizing, nor of individual differences in empathy or perspective-taking predicting performance, contradicting previous studies using the same design. The results cast doubt on the existence of an implicit mentalizing system, suggesting that previous effects were due to domain-general processes. © 2016 The Author(s).","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","454-465","","3","43","","","","","","","","","","","","","","","","","","<p>cited By 31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZKKC2ST","conferencePaper","2017","Hervas, R.; Johnson, E.; Franca, C.G.L.D.L.; Bravo, J.; Mondejar, T.","A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars","Proceedings - 2016 15th International Conference on Ubiquitous Computing and Communications and 2016 8th International Symposium on Cyberspace and Security, IUCC-CSS 2016","","","10.1109/IUCC-CSS.2016.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015234516&doi=10.1109%2fIUCC-CSS.2016.021&partnerID=40&md5=fdd98a86252b4919bd70a2d0688561f0","Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability. © 2016 IEEE.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","93-100","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGCP8FME","journalArticle","2017","Johnson, E.; Hervás, R.; Gutiérrez-López-Franca, C.; Mondéjar, T.; Bravo, J.","Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar","Mobile Information Systems","","","10.1155/2017/7932529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021665183&doi=10.1155%2f2017%2f7932529&partnerID=40&md5=56f1d3d19d1da916c8444885ffcfd4a1","In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues. © 2017 Esperanza Johnson et al.","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","","","","2017","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHUNPDXM","conferencePaper","2017","Gabriel, S.","Teaching human rights with video games?","Proceedings of the 11th European Conference on Games Based Learning, ECGBL 2017","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036477671&partnerID=40&md5=e512018f6f44da07a412436d7d2a07c4","Serious games which deal with human rights topics have been on the rise for the last 15 years. Digital games show some unique properties that make them valuable for inducing social change. Some of the game elements that can be used to integrate values are as follows: Narration, which is one of the elements that is most obvious to players and is part of most of today's digital games, is a proper way of presenting human rights topics and can also include ideological messages. However, there are also other ways of creating empathy for certain groups as the example of Ayitii - The Cost of Life shows: If players feel responsible for the game characters, games can make players think about the topic presented. Being able to take meaningful decisions which influence the player's avatar, other non-playable characters, the narration or the game-world is a property of many recent games. Thus, ethical decisions are included in games and put players into the shoes of those who are oppressed or put in other situations where there is no easy way of deciding if something is right or wrong. Finally, the article also discusses if these serious games can affect players' real lives and change their way of thinking and attitudes. The serious game This War of Mine shows that some players think about their decisions and the topic of the game even after having stopped playing. However, there are also restrictions to transferring game contents into players' lives and induce social change. Quite often it is not enough just to play the game, teaching which must take place in a non-game context, is needed to make players aware of human rights (violations).","2017","2021-02-15 22:37:40","2021-02-15 22:37:40","","191-196","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8L8LQKUS","conferencePaper","2016","Hughes, D.E.; Vasquez, E.; Nicsinger, E.","Improving perspective taking and empathy in children with autism spectrum disorder","2016 IEEE International Conference on Serious Games and Applications for Health, SeGAH 2016","","","10.1109/SeGAH.2016.7586232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994711788&doi=10.1109%2fSeGAH.2016.7586232&partnerID=40&md5=bb23946086eb29ab2bf182f27c885055","This paper discusses the design, implementation, and evaluation of a serious game intended to reinforce applied behavior analysis (ABA) techniques used with children with autism spectrum disorder (ASD) by providing a low cost and easily accessible supplement to traditional methods. The goal is develop a safe environment for social exploration and learning that boosts the child's confidence while providing calming mechanisms. Games increase children's motivation and thus increase the rate of learning in computer mediated environments. Furthermore, children with ASD are able to understand basic emotions and facial expressions in avatars more easily than in real-world interactions. © 2016 IEEE.","2016","2021-02-15 22:37:40","2021-02-15 22:37:40","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9C3MEKK","conferencePaper","2016","Ishii, Y.; Watanabe, T.; Sejima, Y.","Development of an embodied avatar system using avatar-Shadow's color expressions with an interaction-activated communication model","HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction","","","10.1145/2974804.2980487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994531607&doi=10.1145%2f2974804.2980487&partnerID=40&md5=fa666452f49b11f978504b10566a6478","In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color. Copyright © 2016 ACM.","2016","2021-02-15 22:37:41","2021-02-15 22:37:41","","337-340","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHA57L4U","journalArticle","2016","Mattan, B.D.; Rotshtein, P.; Quinn, K.A.","Empathy and visual perspective-taking performance","Cognitive Neuroscience","","","10.1080/17588928.2015.1085372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953718172&doi=10.1080%2f17588928.2015.1085372&partnerID=40&md5=527ce22966ad81cb1010584fee7295be","This study examined the extent to which visual perspective-taking performance is modulated by trait-level empathy. Participants completed a third-person visual perspective-taking task in which they judged the perspectives of two simultaneously presented avatars, designated “Self” and “Other.” Depending on the trial, these avatars either held the same view (i.e., congruent) or a different view (i.e., incongruent). Analyses focused on the relationship between empathy and two perspective-taking phenomena: Selection between competing perspectives (i.e., perspective-congruence effects) and prioritization of the Self avatar’s perspective. Empathy was related to improved overall performance on this task and a reduced cost of selecting between conflicting perspectives (i.e., smaller perspective-congruence effects). This effect was asymmetric, with empathy (i.e., empathic concern) levels predicting reduced interference from a conflicting perspective, especially when adopting the Self (vs. Other) avatar’s perspective. Taken together, these results highlight the importance of the self–other distinction and mental flexibility components of empathy. © 2016 Taylor & Francis.","2016","2021-02-15 22:37:41","2021-02-15 22:37:41","","170-181","","1-4","7","","","","","","","","","","","","","","","","","","<p>cited By 14</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94KLMBT3","conferencePaper","2016","Marcu, G.; Dowshen, N.; Saha, S.; Sarreal, R.R.; Andalibi, N.","TreatYoSelf: Empathy-driven behavioral intervention for marginalized youth living with HIV","PervasiveHealth: Pervasive Computing Technologies for Healthcare","","","10.4108/eai.16-5-2016.2263336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046951092&doi=10.4108%2feai.16-5-2016.2263336&partnerID=40&md5=9c69c52491175e22e9a5c12cd82ac0f2","Behavioral intervention technologies are well suited to addressing health behavior such as medication adherence, but only if successfully integrated into a user's daily life. Little is known about how to design such technologies to be adoptable, adaptable, useful, and feasible in everyday life. We report on the design process for TreatYoSelf, a smartphone application designed to improve medication adherence among youth living with HIV through reminders and positive reinforcement. Using participatory design, our aim was to understand factors related to adoption and acceptance of behavioral intervention technology as part of daily life. Two challenges of living with HIV led to an empathy-driven approach in our design process: (1) HIV is a stigmatized condition, which (2) disproportionately affects the marginalized populations of young African American men who have sex with men and transgender women. We discuss five empathy-driven design strategies: positive and nonjudgmental tone; minimal, avatar-based gamification; motivational and corny messages; nondisclosure through neutral signifiers; and social support through camaraderie. Our approach enabled us to identify and work through factors, often related to stigma and marginalization, which would lead to rejection of TreatYoSelf use in daily life. © 2016 EAI.","2016","2021-02-15 22:37:41","2021-02-15 22:37:41","","","","","2016-May","","","","","","","","","","","","","","","","","","<p>cited By 11</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BLFMG24","journalArticle","2016","Tordo, F.; Binkley, C.","Auto-empathy or the others-in-oneself's evolution: Definition and clinic of virtual [L'auto-empathie, ou le devenir de l'autrui-en-soi: Définition et clinique du virtuel]","Evolution Psychiatrique","","","10.1016/j.evopsy.2014.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900883323&doi=10.1016%2fj.evopsy.2014.02.002&partnerID=40&md5=2772d143d98da8ff9a47bdfb519c12da","Objectives: The authors propose to explore a psychic phenomenon, the ""auto-empathy"", as implemented in the context of digital spaces and particularly in the situation of the player who embodies an avatar (a pixel figure) in a video game. Method: From the perspective of a theoretical opening both phenomenological and psychoanalytic, auto-empathy is the process in which, taking the position of the ""other-in-oneself"", we represent our subjective world - or the all states of our subjectivity (actions, emotions, thoughts) - by an empathic relationship with ourselves. The auto-empathy relationship is a process of distancing, and symbolic appropriation, in which we are divided into halves, implementing our innate ability to be both subject and object for ourselves. Results: The mediatization of auto-empathy in digital worlds can put ourselves instead of a figure that represents us - our avatar - so that our empathy is turned towards ourselves indirectly. This second time of empathy for a virtual figure of the self, called ""mediatized auto-empathy"" or ""virtual auto-empathy"", would contribute thirdly to the development of empathy for oneself. Finally, the development of empathy for others would be supported in a fourth time, by the attention the players are paying to each other in network games. Discussion: These four hypotheses, illustrated by clinical cases, open an interrogation concerning the frame of the psychoanalytical work. In the adolescent, the work of virtualisation, which consists in the creative anticipation of its subjective possibilities, seems regularly impeded. The mental duplicity is no longer in a position to operate a symbolizing distance between the real self and the virtual self, between the subjective self and the subjectivising self. The other-in-oneself is ineffective in proposing to the adolescent an empathic dialogue with oneself. Consequently, the autorepresentation flirts with the seizure, in particular in the subjective states of breaks. Nevertheless, the digital spaces could be indirect media of appropriation of subjective experiences for the teenager. Conclusion: Our reflections led us to think of auto-empathy as the realization of the other-in-oneself which allows us to represent our own subjective world. The auto-empathy mediatized by an avatar can thus be described as a representation by empathy of our subjective part that contains this character. From then on, the space of the video game appears as a space of subjectivation. © 2014 Elsevier Masson SAS.","2016","2021-02-15 22:37:41","2021-02-15 22:37:41","","293-308","","2","81","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWRKXUAU","conferencePaper","2016","Jestice, R.","Walking in someone's virtual shoes: Virtual worlds as a tool for developing empathy","AMCIS 2016: Surfing the IT Innovation Wave - 22nd Americas Conference on Information Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987668886&partnerID=40&md5=fcf90cdfb9ac4debe4a88d5a5f25d8ff","Empathy is an important skill for leaders. It is proposed that virtual worlds can be used effectively as a tool in developing empathy, especially perspective taking. This emerging stream of research explores the use of virtual worlds and avatar manipulation as a means to evoke perspective taking in leadership students. It is proposed that due to the Proteus Effect, virtual world users will change their behavior in a role-play based on their avatar's appearance. Further, it is proposed that this change in behaviors will lead to more insight into the perspectives of different others in a similar real world situation.","2016","2021-02-15 22:37:41","2021-02-15 22:37:41","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45SBXCCH","journalArticle","2015","Pablos, S.M.; García-Bermejo, J.G.; Zalama Casanova, E.; López, J.","Dynamic facial emotion recognition oriented to HCI applications","Interacting with Computers","","","10.1093/iwc/iwt057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928327868&doi=10.1093%2fiwc%2fiwt057&partnerID=40&md5=1830d1e522ce7a76abd9ccd267476889","As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176-192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human-computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response. © 2013 The Author. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.","2015","2021-02-15 22:37:41","2021-02-15 22:37:41","","99-119","","2","27","","","","","","","","","","","","","","","","","","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8STZDDA2","conferencePaper","2015","Andersen, J.S.; Schoenau-Fog, H.","Using role-taking and behavioral mimicking in games to increase awareness on the bystander effect","ACADEMICMINDTREK 2015 - Proceedings of the 19th International Academic Mindtrek Conference","","","10.1145/2818187.2818290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962875863&doi=10.1145%2f2818187.2818290&partnerID=40&md5=9bb92260b998ec261abfbb7a1ee9ae11","This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.","2015","2021-02-15 22:37:41","2021-02-15 22:37:41","","69-72","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVQG7XF2","journalArticle","2015","Sulpizio, V.; Committeri, G.; Metta, E.; Lambrey, S.; Berthoz, A.; Galati, G.","Visuospatial transformations and personality: evidence of a relationship between visuospatial perspective taking and self-reported emotional empathy","Experimental Brain Research","","","10.1007/s00221-015-4280-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930869966&doi=10.1007%2fs00221-015-4280-2&partnerID=40&md5=a758a2763261e0854cd1aabac0e34968","In the visuospatial domain, perspective taking is the ability to imagine how a visual scene appears from an external observer’s viewpoint, and can be studied by asking subjects to encode object locations in a visual scene where another individual is present and then detecting their displacement when seeing the scene from the other’s viewpoint. In the current study, we explored the relationship between visuospatial perspective taking and self-report measures of the cognitive and emotional components of empathy in young adults. To this aim, we employed a priming paradigm, in which the presence of an avatar allowed to anticipate the next perceived perspective on the visual scene. We found that the emotional dimension of empathy was positively correlated with the behavioral advantage provided by the presence of the avatar, relative to unprimed perspective changes. These data suggest a link between the tendency to vicariously experience the others’ emotions and the ability to perform self–other spatial transformations. © 2015, Springer-Verlag Berlin Heidelberg.","2015","2021-02-15 22:37:41","2021-02-15 22:37:41","","2091-2102","","7","233","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2U7C6CEK","journalArticle","2015","Jackson, P.L.; Michon, P.-E.; Geslin, E.; Carignan, M.; Beaudoin, D.","EEVEE: The Empathy-Enhancing Virtual Evolving Environment","Frontiers in Human Neuroscience","","","10.3389/fnhum.2015.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933673349&doi=10.3389%2ffnhum.2015.00112&partnerID=40&md5=c41939d6689a9860f5a08ac3f7ec4c58","Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar’s behavior to the observer’s neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar’s face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders. © 2015 Jackson, Michon, Geslin, Carignan and Beaudoin.","2015","2021-02-15 22:37:41","2021-02-15 22:37:41","","","","MAR","9","","","","","","","","","","","","","","","","","","<p>cited By 14</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBJRPXJF","journalArticle","2015","Tisseron, S.; Tordo, F.; Baddoura, R.","Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items","International Journal of Social Robotics","","","10.1007/s12369-014-0268-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924301513&doi=10.1007%2fs12369-014-0268-5&partnerID=40&md5=ae9ddda552ec58f57dc89db088c53239","The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-02-15 22:37:41","2021-02-15 22:37:41","","97-102","","1","7","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBBHY7BP","journalArticle","2015","Patel, H.; MacDorman, K.F.","Sending an avatar to do a human’s job: Compliance with authority persists despite the uncanny valley","Presence: Teleoperators and Virtual Environments","","","10.1162/PRES_a_00212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929302303&doi=10.1162%2fPRES_a_00212&partnerID=40&md5=19d56358034d04dcd1491d273a47bb96","Just as physical appearance affects social influence in human communication, it may also affect the processing of advice conveyed through avatars, computer-animated characters, and other human-like interfaces. Although the most persuasive computer interfaces are often the most human-like, they have been predicted to incur the greatest risk of falling into the uncanny valley, the loss of empathy attributed to characters that appear eerily human. Previous studies compared interfaces on the left side of the uncanny valley, namely, those with low human likeness. To examine interfaces with higher human realism, a between-groups factorial experiment was conducted through the internet with 426 midwestern U.S. undergraduates. This experiment presented a hypothetical ethical dilemma followed by the advice of an authority figure. The authority was manipulated in three ways: depiction (digitally recorded or computer animated), motion quality (smooth or jerky), and advice (disclose or refrain from disclosing sensitive information). Of these, only the advice changed opinion about the ethical dilemma, even though the animated depiction was significantly eerier than the human depiction. These results indicate that compliance with an authority persists even when using an uncannily realistic computeranimated double. © 2015 by the Massachusetts Institute of Technology.","2015","2021-02-15 22:37:42","2021-02-15 22:37:42","","1-23","","1","24","","","","","","","","","","","","","","","","","","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHPBJSLG","conferencePaper","2014","Sejima, Y.; Watanabe, T.; Jindai, M.","Development of an interaction-activated communication model based on a heat conduction equation in voice communication","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","","","10.1109/ROMAN.2014.6926356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937538530&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=91ef1fc789e5cfd5dd2329481e79a23e","In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication. © 2014 IEEE.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","832-837","","","2014-October","","","","","","","","","","","","","","","","","Issue: October","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCR63WRQ","journalArticle","2014","Kumar, A.","Satyamev Jayate: Return of the star as a sacrificial figure","South Asia: Journal of South Asia Studies","","","10.1080/00856401.2014.906087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903305515&doi=10.1080%2f00856401.2014.906087&partnerID=40&md5=8eeb748d4113326360347c7abe847f12","This paper attempts to make sense of Satyamev Jayate, a popular Indian television show hosted by film star Aamir Khan, in terms of its politics, Khan's stardom and the attempt to reframe the social on television. Grappling with the broad contours of the cultural economy of justice on national television in India, I suggest that the star descends upon television as an avatar promising empathy to a variety of victims of social injustice. In so doing, Khan converts crime news into emotional truths. The show has not only generated public debate, it also invites the public to return to a performative innocence. As television becomes the site of articulating moral authority, ritual participation and demanding social change, the political is re-assembled through Khan's stardom. The paper also enquires how and why the show compels narrative ingenuity towards what Aditya Nigam calls the implosion of the political-the erasure of the public from the street and its re-inscription in the studio. Equally notable here is the role film-stardom plays in rendering moral authority through the trope of the sacrificial. © 2014 South Asian Studies Association of Australia.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","239-254","","2","37","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSQ3FE3C","conferencePaper","2014","Sejima, Y.; Watanabe, T.; Jindai, M.","Development of an interaction-Activated communication model based on a heat conduction equation in voice communication","IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions","","","10.1109/ROMAN.2014.6926356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937573084&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=22e427095e4bdb9f1b57facf7adeb784","In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-Activated communication model based on the heat conduction equation in heat-Transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-Activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-Activated communication. © 2014 IEEE.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","832-837","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P55TKQWR","journalArticle","2014","Turkay, S.; Kinzer, C.K.","The effects of avatar: Based customization on player identification","International Journal of Gaming and Computer-Mediated Simulations","","","10.4018/ijgcms.2014010101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919481767&doi=10.4018%2fijgcms.2014010101&partnerID=40&md5=d1f48e10de40db92e9957d08a1cd57b9","Games allow players to perceive themselves in alternate ways in imagined worlds. Player identification is one of the outcomes of gameplay experiences in these worlds and has been shown to affect enjoyment and reduce self-discrepancy. Avatar-based customization has potential to impact player identification by shaping the relationship between the player and the character. This mixed method study aims to fill the gap in the identification literature by examining the effects of avatar-based customization on players' identification with and empathy towards their characters in a massively multiplayer online game, Lord of the Rings Online (LotRO). Participants (N = 66) played LotRO either in customization or in no-customization groups for about ten hours in four sessions over two weeks in a controlled lab setting. Data were collected through interviews, surveys and observations. Results showed both time and avatar-based customization positively impacted players' identification with their avatars. Self-Determination Theory is used to interpret results. Copyright © 2014, IGI Global.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","1-25","","1","6","","","","","","","","","","","","","","","","","","<p>cited By 22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9PR6H5G","journalArticle","2014","Thirioux, B.; Tandonnet, L.; Jaafari, N.; Berthoz, A.","Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia: A behavioural pilot-study using virtual reality technology","Brain and Cognition","","","10.1016/j.bandc.2014.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903940796&doi=10.1016%2fj.bandc.2014.06.006&partnerID=40&md5=d4a126273acdb3f6ce72c9bec2fd96f5","Behavioural and neuroimaging data have recently pointed out that empathy (feeling into someone else) is associated with mental imagery and transformation related to one's and other's visuo-spatial perspectives. Impairments of both empathic and visuo-spatial abilities have been observed in patients with schizophrenia. Especially, it has been suggested that schizophrenics are altered in spontaneously simulating another individual's first-person experience. However, there is so far only little evidence regarding the relationship between deficits in empathy and disturbances in spontaneous heterocentered coding in schizophrenia. In the present pilot-study, we tested with schizophrenic patients our behavioural paradigm that enables to measure from the bodily postures and movements whether individuals in ecologically more valid conditions are interacting with another individual by using egocentered - as in sympathy (feeling with someone else) - or heterocentered - as in empathy - visuo-spatial mechanisms. For that, ten patients and ten controls, standing and moving, interacted with a virtual tightrope walker, displayed life-sized, standing and moving as well. We show that patients with higher negative symptoms had, in most cases, deficits in spontaneously using heterocentered visuo-spatial mechanisms and employed preferentially an egocentered referencing to interact with the avatar. In contrast, preserved spontaneous heterocentered visuo-spatial strategies were not linked to a prevailing negative or positive symptomatology. Our data suggest that the severity of the negative symptoms in schizophrenia relates with disturbances of spontaneous (""on-line"") empathic processing in association with lower scoring self-reported trait cognitive empathy. © 2014 Elsevier Inc.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","87-99","","","90","","","","","","","","","","","","","","","","","","<p>cited By 10</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFJMYHEZ","journalArticle","2014","Menzel, N.; Willson, L.H.; Doolen, J.","Effectiveness of a poverty simulation in second life®: Changing nursing student attitudes toward poor people","International Journal of Nursing Education Scholarship","","","10.1515/ijnes-2013-0076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908608559&doi=10.1515%2fijnes-2013-0076&partnerID=40&md5=aa24ee301d7d65e4fc5c62935bf510cc","Social justice is a fundamental value of the nursing profession, challenging educators to instill this professional value when caring for the poor. This randomized controlled trial examined whether an interactive virtual poverty simulation created in Second Life® would improve nursing students' empathy with and attributions for people living in poverty, compared to a self-study module. We created a multi-user virtual environment populated with families and individual avatars that represented the demographics contributing to poverty and vulnerability. Participants (N = 51 baccalaureate nursing students) were randomly assigned to either Intervention or Control groups and completed the modified Attitudes toward Poverty Scale pre- and post-intervention. The 2.5-hour simulation was delivered three times over a 1-year period to students in successive community health nursing classes. The investigators conducted post-simulation debriefings following a script. While participants in the virtual poverty simulation developed significantly more favorable attitudes on five questions than the Control group, the total scores did not differ significantly. Whereas students readily learned how to navigate inside Second Life®, faculty facilitators required periodic coaching and guidance to be competent. While poverty simulations, whether virtual or face-to-face, have some ability to transform nursing student attitudes, faculty must incorporate social justice concepts throughout the curriculum to produce lasting change. © 2014, Walter de Gruyter GmbH. All rights reserved.","2014","2021-02-15 22:37:42","2021-02-15 22:37:42","","","","1","11","","","","","","","","","","","","","","","","","","<p>cited By 31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5MRXAJB","conferencePaper","2013","Plant, N.; Healey, P.G.T.","Surface Tension","Conference on Human Factors in Computing Systems - Proceedings","","","10.1145/2468356.2479589","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040727714&doi=10.1145%2f2468356.2479589&partnerID=40&md5=9a87b07b1b9698f79ac1c66418476b1c","The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?.","2013","2021-02-15 22:37:42","2021-02-15 22:37:42","","2979-2982","","","2013-April","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8C99KSHR","journalArticle","2013","Sieg, K.","Wii are family: Performing Race in Neo-liberal Europe","Theatre Research International","","","10.1017/S030788331200096X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878179286&doi=10.1017%2fS030788331200096X&partnerID=40&md5=2eb54b155cd8b567b6d69b17270600be","This article examines the flash mob dance Glow by the Afro-Norwegian duo Madcon, which was performed at the Eurovision Song Contest in Oslo, Norway, in 2010. The dance was modelled on the format of popular Wii dance games, and coordinated black and white dancers, families, mass publics and prerecorded and live footage in order to choreograph European 'unity in diversity'. The use of black dancers as avatars urging dancing crowds towards greater kinaesthetic sensitivity raises the questions of how race is figured in neo-liberal visions of cosmopolitan Europe, and what role gaming technology plays in facilitating cross-racial empathy and ethical responsiveness at a time when solidarity is fraying as a consequence of fiscal crises and austerity measures. Finally, the article considers Afro-European academic, activist and artistic practices as alternatives to neo-liberal regimes of race. © 2013 International Federation for Theatre Research.","2013","2021-02-15 22:37:42","2021-02-15 22:37:42","","20-33","","1","38","","","","","","","","","","","","","","","","","","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRGPEDAP","journalArticle","2013","Bouchard, S.; Bernier, F.; Boivin, E.; Dumoulin, S.; Laforest, M.; Guitard, T.; Robillard, G.; Monthuy-Blanc, J.; Renaud, P.","Empathy toward virtual humans depicting a known or unknown person expressing pain","Cyberpsychology, Behavior, and Social Networking","","","10.1089/cyber.2012.1571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872559512&doi=10.1089%2fcyber.2012.1571&partnerID=40&md5=842f525f29c1000eca7ba5c4b9140ddd","This study is about pain expressed by virtual humans and empathy in users immersed in virtual reality. It focuses on whether people feel more empathy toward the pain of a virtual human when the virtual human is a realistic representation of a known individual, as opposed to an unknown person, and if social presence is related to users' empathy toward a virtual human's pain. The 42 participants were immersed in virtual reality using a large immersive cube with images retro projected on all six faces (CAVE-Like system) where they can interact in real time with virtual characters. The first immersion (baseline/control) was with a virtual animal, followed by immersions involving discussions with a known virtual human (i.e., the avatar of a person they were familiar with) or an unknown virtual human. During the verbal exchanges in virtual reality, the virtual humans expressed acute and very strong pain. The pain reactions were identical in terms of facial expressions, and verbal and nonverbal behaviors. The Conditions by Time interactions in the repeated measures analyses of variance revealed that participants were empathic toward both virtual humans, yet more empathic toward the known virtual human. Multivariate regression analyses revealed that participants' feeling of social presence - impression that the known virtual character is really there, with them - was a significant predictor of empathy. © Mary Ann Liebert, Inc.","2013","2021-02-15 22:37:42","2021-02-15 22:37:42","","61-71","","1","16","","","","","","","","","","","","","","","","","","<p>cited By 29</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7E9JNJEI","journalArticle","2012","Chen, G.-D.; Lee, J.-H.; Wang, C.-Y.; Chao, P.-Y.; Li, L.-Y.; Lee, T.-Y.","An empathic avatar in a computer-aided learning program to encourage and persuade learners","Educational Technology and Society","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871544623&partnerID=40&md5=abcec5093589166e553e4712fd8692f0","Animated pedagogical agents with characteristics such as facial expressions, gestures, and human emotions, under an interactive user interface are attractive to students and have high potential to promote students' learning. This study proposes a convenient method to add an embodied empathic avatar into a computer-aided learning program; learners express their emotions by mouse-clicking while reading, and the avatar motivates them accordingly. This study designs empathic responses for avatars to encourage and persuade learners to make greater reading effort. This experiment examines emotional recognition, empathy transformation, and the effect of virtual human encouragement and persuasion. Subjects identify facial expressions of the avatar, especially those expressing positive facial emotions. Compared to the contrast group, the empathic avatar increases learners' willingness to continue reading and complete exercises. © International Forum of Educational Technology & Society (IFETS).","2012","2021-02-15 22:37:42","2021-02-15 22:37:42","","62-72","","2","15","","","","","","","","","","","","","","","","","","<p>cited By 25</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRFDZ97R","conferencePaper","2012","Karanian, B.A.; Eskandari, M.; Aggarwal, A.; Pincheira, F.; Krauthamer, R.R.; Kress, G.","Open process for entrepreneuring team collaboration: Parallels from an academic research team to the start up they studied","ASEE Annual Conference and Exposition, Conference Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029108723&partnerID=40&md5=d2304a42bf841bae627ab8aa9e09b813","Increasingly, student entrepreneurial ventures begin as emotional connections, artistic experiences, and expectations for delivering on research teams. This paper explores student team progress and responses to roadblocks while helping a maturing Silicon Valley start-up IMVU consider the role of avatars, creative expression and social interaction in the virtual world. Our goal was to seek a deep understanding of why users choose to spend their time and money to take part in the online community IMVU all the while creating a productive entrepreneurial team atmosphere. This paper explores the unique dynamics of the research team during the evolving investigation and delivery phase, all the while simultaneously examining the underlying emotions and motives of participants in one virtual community. We start with the belief that every new research team is like a start-up company and there are commonalities or differences between the student academic research environment and the company's organizational culture. Our collaborative research team includes members from areas of engineering, design, psychology, and communication. In this paper, we intend to correlate the factors that make the design team effective, utilize the findings to guide new student teams, and facilitate progress across the stages of the project. Two factors set the stage for insights on entrepreneuring: 1) evolving research team dynamics, and 2) the need-finding interactions with users both inside and outside the industry environment studied (IMVU). Surprising discoveries include a strong gender imbalance in the community as well as users reporting that online ""was basically real life."" A palette of stories abstractly parallels the student design team to the start-up they studied. Concepts include: self motivated, ambiguity readiness level, passion, and empathy. The team leader knowingly discussed using an open-process approach. Members noted a considerable lack of reluctance to prototype methods and team presentations; they also reported a deliberate lack of specific planning that they believe contributed to an entertaining and productive team ambiance. The full experiment offers stunning stories and compelling implications for creating effective design interventions in team-based engineering and design classes as well as for those pursuing the stories of compassion, empathy, and transformation in entrepreneuring. © 2012 American Society for Engineering Education.","2012","2021-02-15 22:37:42","2021-02-15 22:37:42","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4373CAG","conferencePaper","2011","Cheong, W.L.; Jung, Y.; Theng, Y.-L.","Avatar: A virtual face for the elderly","Proceedings of VRCAI 2011: ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications to Industry","","","10.1145/2087756.2087850","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856420993&doi=10.1145%2f2087756.2087850&partnerID=40&md5=1916f7bd55a0b5287eb6d86efa07d939","Studies in the field of human-computer interaction have demonstrated a significant impact of avatars and virtual environments on users' interaction experiences and behaviors. However, most of these studies are focused on the young users. With an aging population and more virtual environments built for the elderly, it is important to investigate the types of avatars elderly users prefer and hence provide them with a richer interaction experience through the use of avatars as virtual representations of themselves. In our exploratory study, 24 seniors aged 55 years and above evaluated 20 custom-created avatars. Results showed that the elderly participants were unable to identify with the avatars. However, the results showed a strong trust towards child avatars and an attraction towards animal and object avatars, which indicates a different form of identification or empathy. The paper concludes with discussion of avatar design for the elderly users. © 2011 ACM.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","491-498","","","","","","","","","","","","","","","","","","","","","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X45FVRM9","journalArticle","2011","Guadagno, R.E.; Swinth, K.R.; Blascovich, J.","Social evaluations of embodied agents and avatars","Computers in Human Behavior","","","10.1016/j.chb.2011.07.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052786398&doi=10.1016%2fj.chb.2011.07.017&partnerID=40&md5=52e853ef8a284bb0887a3e85bc716b0d","The purpose of this study was to examine social evaluations (i.e.; perceptions of empathy and positivity) following peoples' interactions with digital human representations. Female research participants engaged in a 3-min interaction while immersed in a 3-D immersive virtual environment with a ""peer counselor."" Participants were led to believe that the peer counselor was either an embodied agent (i.e.; computer algorithm) or an avatar (i.e.; another person). During the interaction, the peer counselor either smiled or not. As predicted, a digitally-rendered smile was found to affect participants' social evaluations. However, these effects were moderated by participants' beliefs about their interaction partner. Specifically, smiles enhanced social evaluations of embodied agents but degraded them for avatars. Although these results are consistent with other findings concerning the communicative realism of embodied agents and avatars they uniquely demonstrate that people's beliefs alone, rather than actual differences in virtual representations, can impact social evaluations. © 2011 Elsevier Ltd. All rights reserved.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","2380-2385","","6","27","","","","","","","","","","","","","","","","","","<p>cited By 38</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JME3KRWZ","journalArticle","2011","Jin, S.A.","My avatar behaves well and this feels right: Ideal and ought selves in video gaming","Social Behavior and Personality","","","10.2224/sbp.2011.39.9.1175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053987515&doi=10.2224%2fsbp.2011.39.9.1175&partnerID=40&md5=7b29b274723a8275cc2f3d2f34c20ac6","Prosocial and violent games were investigated in relation to empathy with avatars and amount of postgame donation. Participants who played a prosocial game demonstrated greater empathy, while those who played a violent game said they would donate a greater amount of money. Flow was found to be a function of the 3-way interaction between game type, self-perception, and regulatory focus. Higgins's (1987) regulatory focus and self-discrepancy (1997) theories are used to explain the underlying theoretical mechanisms behind these results. © Society for Personality Research.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","1175-1182","","9","39","","","","","","","","","","","","","","","","","","<p>cited By 12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6BYK9RS","journalArticle","2011","Taylor, L.D.","Avatars and emotional engagement in asynchronous online communication","Cyberpsychology, Behavior, and Social Networking","","","10.1089/cyber.2010.0083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79954618670&doi=10.1089%2fcyber.2010.0083&partnerID=40&md5=d37170855b520268ab7aae81c8286a05","The notion that an avatar can elicit a sense of emotional involvement or connection on the part of a user in asynchronous online communication was explored through a pair of content analyses of a popular online question-and-answer bulletin board. In the first study, questions accompanied by an avatar not only received more answers than questions without an avatar, but the answers were more likely to be characterized by expressions of empathy. In the second study, a preference for answering questions accompanied by an avatar was found to be associated with interpersonal, altruistic motives for answering questions. Results are discussed in terms of presence and alternative explanations, as well as practical implications. © Copyright 2010, Mary Ann Liebert, Inc.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","207-212","","4","14","","","","","","","","","","","","","","","","","","<p>cited By 19</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVNPCF85","conferencePaper","2011","Kress, G.; Getz-Kikuchi, R.; Price, T.; Karanian, B.; Nass, C.","Designing for social participation in the virtual universe","ASEE Annual Conference and Exposition, Conference Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029027110&partnerID=40&md5=1e06cdd5854e6e819c535957b7109374","Increasingly, our emotional connections, artistic experiences and playful escapes are migrating to the virtual world. Virtual environments and online communities are growing and becoming more commonplace in society; for many, they are already a primary means of social interaction. This experiment is a preliminary investigation into the underlying emotional motivation behind participants in the IMVU virtual universe. We seek a deep understanding of why these users choose to spend their time and money to take part in creating this online community. Our collaborative research team includes members from the areas of engineering, design, psychology and communication. Our need-finding interactions with users both inside and out of the IMVU environment have given us insight into the role of avatars, creative expression and social interaction in the virtual world. We assess how users manipulate their social identity and exercise their influence to achieve personal fulfillment online. The full experiment offers compelling implications for creating effective design interventions in team-based engineering and design classes, particularly those involving distributed collaboration, as well as for those pursuing compassion, empathy and social change by design. © 2011 American Society for Engineering Education.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ARGNVVZY","conferencePaper","2011","Szczesna, A.; Grudzinski, T.; Grudzinski, J.","Settings goals in psychology serious game for preschool children","Proceedings of the European Conference on Games-based Learning","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862487569&partnerID=40&md5=b715e8e0d0b4f3b2b1d58ef29f134efa","The term serious game is generally used for an application that is developed using a computer game technology and game design principles but is used for non-entertainment purposes. We can say that these applications are entertaining games with non-entertainment goals. The idea is that games could be used for more serious purposes such as education, simulating real world phenomenon and relations in the world, increasing life quality through health, rehabilitation and therapy applications or raising interest in the problems in our global world. This paper focuses on psychology serious games. Generally, in psychology games users are represented by their avatar and can interact with the world and other game characters. Like in storytelling or bibliotherapy, the story itself has a therapeutic component so much as it evokes identification, empathy, resistance, opposition and disclosure of many confusing emotions. This goal oriented gaming can be used in goal oriented therapy methods. The game is played according to a scenario where the user can observe and react to different situations. This acts as a powerful tool for helping users understand and reflect on their own behavior and gives them the opportunity to learn from this virtual experience. The next stage is testing the user's new abilities with new situations by applying different games goals. The innovative use of computer in the form of psychotherapeutic games may enhance patient cooperation. This can also help to attract and sustain the interest especially in children. This paper describes the main features of serious games used in psychology based on the prototype of the game Mission - Master Your Fear. This is a serious game based on a specialist scenario founded on bibliotherapy with some therapeutic goals. It deals with issues and problems of preschool children. The result is an interesting and absorbing game for children which may help them solve some problems.","2011","2021-02-15 22:37:43","2021-02-15 22:37:43","","567-572","","","2011-January","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SF4JHSC4","journalArticle","2010","Tordo, F.","Desire of intersubjectivity in the video game: Between virtual auto-empathy and real interpersonal relations [Désir d'intersubjectivité dans les jeux vidéo: Entre auto-empathie virtuelle et relations interpersonnelles réelles]","Psychotropes","","","10.3917/psyt.163.0179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951938920&doi=10.3917%2fpsyt.163.0179&partnerID=40&md5=c80ca5831e247cd3eed6c49450204800","Abstract: While it is routinely said that the body disappears in the video game for the sole benefit of sensory stimulations, the avatar, on the contrary, appears as a vehicle of action which engages the player's own corporeity. This action-motricity, which simulates the system of representation of action, is engaged in a process of virtual auto-empathy through corporal sensations felt by the player. A real intersubjective traffic between the characters-players is added, in the persistent worlds, where the virtual other is an already-existing. The dependent or excessive player would be the one to whom the intersubjective desire no longer succeed in going towards another player, preferring sensori-motor interactions, in a progressive indifferentiation of types of virtual objects.","2010","2021-02-15 22:37:43","2021-02-15 22:37:43","","179-191","","3-4","16","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7ZJA949","conferencePaper","2010","Van Looy, J.; Courtois, C.; De Vocht, M.","Player identification in online games: Validation of a scale for measuring identification in MMORPGs","ACM International Conference Proceeding Series","","","10.1145/1823818.1823832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249285281&doi=10.1145%2f1823818.1823832&partnerID=40&md5=cf2581b9b9b6c40e31605f68c8d4b973","In this paper, we present a Player Identification (PI) scale for measuring identification in MMORPGs. Three main dimensions were derived from the literature (1) Avatar (character) Identification, (2) Group (guild) Identification and (3) Game (community) Identification whereby Avatar Identification is a second-order factor consisting of (1a) Perceived Similarity, (1b) Wishful Identification and (1c) Embodied Presence. Based on the results of a cross-sectional survey of 544 World of Warcraft players the measurement instrument's proposed factorial structure was confirmed. Subsequently, the constructs were successfully tested both for convergent and discriminant validity. Finally, evidence for nomological validity was gathered by testing ten theoretically rooted hypotheses regarding the effects of Player Identification. The results showed that Avatar Identification positively predicts Empathy, Proteus effect and the motivations role-play, customization and escapism. Group Identification predicts socializing and relationship, and Game Identification predicts advancement, mechanics and escapism. © 2010 ACM.","2010","2021-02-15 22:37:43","2021-02-15 22:37:43","","126-134","","","","","","","","","","","","","","","","","","","","","<p>cited By 16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4QH6SKB","journalArticle","2020","Gramantieri, R.","Alexithymic personality in Philip K. Dick’s Do androids dream of electric sheep?","Neohelicon","","","10.1007/s11059-020-00544-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745112&doi=10.1007%2fs11059-020-00544-z&partnerID=40&md5=d7ae68506033a119722c578a57aa02bd","The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients’ comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novel Do androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commenting Do androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick. © 2020, Akadémiai Kiadó, Budapest, Hungary.","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","673-683","","2","47","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAEZK4JJ","journalArticle","2020","Sarkadi; Casmana, A.R.; Cahyana, U.; Paristiowati, M.","The Application of Mobile Learning for University Students in the Pancasila Education Modul in Developing Character of Students' Empathy","Universal Journal of Educational Research","","","10.13189/ujer.2020.080905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090322563&doi=10.13189%2fujer.2020.080905&partnerID=40&md5=6b590515ca55be0e70b759af8a00a634","The main purpose of this study is to improve students’ empathy attitudes in Pancasila education courses using applications in mobile phones. It is a tool application or media that is used by educators to be able to transfer knowledge to their students. This is used to be able to increase the interaction and learning motivation of students, so they can obtain maximum learning resources. The name of the application is Pancasila Mobile learning, and it is available on Playstore for Android users and web-based page. Meanwhile, the empathy characters need to be developed by the school to be able to grow in students. As such, this study focuses on growing empathy by using mobile learning applications. The research method used is quantitative. The data collection technique used was an online questionnaire, which was filled by 119 students at universities in Jakarta. They are students who have already or are studying Pancasila in college. The results of this study indicate that the use of mobile learning applications in learning Pancasila in the classroom can increase empathy attitudes towards students. They can carry out positive activities, and feel pleasure and comfort when using mobile learning applications in the learning process. Thus, the use of mobile learning needs to be continuously developed by educators both in universities and schools. Copyright ©2020 by authors, all rights reserved.","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","3825-3833","","9","8","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZZTSIZL","journalArticle","2020","de Kervenoael, R.; Hasan, R.; Schwob, A.; Goh, E.","Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots","Tourism Management","","","10.1016/j.tourman.2019.104042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075628508&doi=10.1016%2fj.tourman.2019.104042&partnerID=40&md5=f56ef158af2d44659553121590311519","Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies. © 2019 Elsevier Ltd","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","","","","78","","","","","","","","","","","","","","","","","","<p>cited By 18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EMJDEU3","journalArticle","2020","Bae, B.-C.; Kim, H.-J.","A cooperative storytelling card game for conflict resolution and empathy","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-030-50164-8_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088745007&doi=10.1007%2f978-3-030-50164-8_27&partnerID=40&md5=fcbbebb6f3c1f3a09c94bdbf6d0e5ece","In this paper we present a prototype for a cooperative storytelling card game focusing on the resolution of conflict and empathy in a narrative. The story-making process in the proposed prototype design is based on Maslow’s hierarchy of needs, and consists of five types of story cards(characters, setting, objects/actions, goals, and emotions) as its story elements. We have developed and tested a prototype game using Unity3D game engine on an Android platform with two play modes - single-player and multi-player. In the multi-player mode, three players can play together: each player is assigned the role of an initiator, a conflictor and a mediator in wireless network environments. Our ultimate goal is to encourage players to empathize with other players by letting them create and resolve (or mediate) emotional conflicts through the process of perspective-taking in a collaborative storytelling game. © Springer Nature Switzerland AG 2020.","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","375-384","","","12211 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QVM78JY","journalArticle","2020","Księżopolska, I.","Can Androids Write Science Fiction? Ian McEwan’s Machines like Me","Critique - Studies in Contemporary Fiction","","","10.1080/00111619.2020.1851165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096586219&doi=10.1080%2f00111619.2020.1851165&partnerID=40&md5=f654e96e86eeb1f62ef29028328451ef","McEwan’s novel Machines Like Me was met with lukewarm reviews and open hostility of the sci-fi genre adherents. It seemed to have appropriated some of the key issues of the genre discourse–the question of what constitutes humanity, of the possibility of coexistence between humans and AI, of the problems of morality and consent. It also made use of time-honored devices of alternative history without treating it too seriously. Instead, the characters are enmeshed in personal problems and conundrums of science and politics, justice and empathy–and love. McEwan’s commentary on the novel in various interviews only aggravated the critics who were all too ready to conclude that Machines Like Me offered little originality. This essay will demonstrate that the text is carefully layered as if to protect its own novelty hidden beneath rather conventional love triangle plot, ponderous political commentary, and genre-specific topicality. It will be an effort to understand the complex relation between the writer and conventions which come into play in his novel, and it will proceed to read the text against the authorial comments, finding suppressed hints that invite an interpretation of the text as narrated by its android hero rather than human subject. © 2020 Taylor & Francis Group, LLC.","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3SVBIB7","journalArticle","2020","Sulistiadi, W.; Nurhidayah, S.; Asyary, Al","Evaluating the management information system of integrated medical emergency care in batang regency, Indonesia","International journal of online and biomedical engineering","","","10.3991/ijoe.v16i07.14725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089019653&doi=10.3991%2fijoe.v16i07.14725&partnerID=40&md5=30a783d732c6318be26f5be2d426c911","An emergency can happen anywhere and anytime, especially in developing countries with a high potential for emergencies, such as Eastern European countries as well as Indonesia. This study aimed to find out the quality of PSC 119 Si Slamet as a prehospital emergency service innovation. The data collection in this study was carried out in a location, namely, Batang Regency, Indonesia, in May-June 2018. The qualitative data collection methods used in this study are in-depth interviews and document reviews. This study was using Service Quality (Servqual) questionnaire. The results show that PSC 119 Si Slamet provides easy access to emergency services to the community 24 hours a day and 7 days a week by simply calling 119 numbers, sending messages via SMS and WhatsApp, or using the Android-based application, with a maximum response time target of 10 minutes. Batang is one of the regencies (rural area) in Central Java province, located on the main coastline, with a hilly geographic condition with many derivatives, climbs, and sharp curves, which is one of the causes of the high number of traffic accidents in the area. This emergency care information systems, with Android-based application, was aimed at improving the quality of services in the health sector, especially emergency services. This service is of good quality as seen from the tangible, reliability, responsiveness, assurance, and empathy dimensions. However, in the implementation, the socialization aspect is not the best to some people. The recommendation given was the need to increase the PSC 119 socialization of Si Slamet not only regionally but also internationally to be massive, especially in developing countries. © 2020 Kassel University Press GmbH.","2020","2021-02-15 22:37:59","2021-02-15 22:37:59","","75-85","","7","16","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57DBHV9H","conferencePaper","2019","Anurrasyid, A.; Sumitra, I.D.","Elementary School Learning Media Application Based on Android with Customer Satisfaction Index Method","IOP Conference Series: Materials Science and Engineering","","","10.1088/1757-899X/662/2/022017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075879846&doi=10.1088%2f1757-899X%2f662%2f2%2f022017&partnerID=40&md5=7074184abbf3181463f02f03011d2907","The objective of this research is to understand customer satisfaction, which is an assessment of a product or service that aims to improve the quality and service of a product or services. In this study the measurement method used is the Customer Satisfaction Index (CSI) method. This method is used to determine how much the level of user satisfaction with learning media applications. The result shows that the calculation of the level of customer satisfaction based on Tangibles, Reliability, Responsiveness, Assurance, and Empathy. The percentage value obtained is based on these five attributes using the Likert Scale, which is a scale of 1-5. Based on the results of the research conducted, the satisfaction of use in the application shows the criteria of satisfaction. This calculation is useful to find out the quality of this learning application. By knowing the value of satisfaction, it can be concluded that this application can help the learning process of children, however this application still not forgetting some suggestions from respondents to evaluate and improve the application to be even better. © Published under licence by IOP Publishing Ltd.","2019","2021-02-15 22:37:59","2021-02-15 22:37:59","","","","","662","","","","","","","","","","","","","","","","","Issue: 2","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZDA87VN","journalArticle","2018","Shukla, S.; Sharma, P.","Emotions and Media Multitasking Behaviour among Indian College Students","Journal of Creative Communications","","","10.1177/0973258618790794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053427916&doi=10.1177%2f0973258618790794&partnerID=40&md5=aa44bb6595f8efc8632f378247c70b8e","Media multitasking, a simultaneous consumption of two or more media, is a ubiquitous and popular behaviour among the youth. One of the reasons for its increasing growth is the structural/market-level factors (known as media factors). Although India is a growing technology hub, there have been limited efforts to identify the media multitasking behaviour among the youth in this country. Thus, this study attempts to analyse the prevalence of media multitasking behaviour among the Indian college students and its relationship with their emotions through two methods: self-report and an android-based application known as ‘Affective Media Landscape Survey’ (AMLS). Previous studies have reported that continuous interaction with media diminishes face-to-face interaction, reduces empathy and increases the tendency to live in the virtual world. This raises the concern for emotional differences in everyday life, if any, between the high and low groups of media multitaskers. So the second objective of the study is to understand the emotional profile of the users that varies among media multitasking index. To achieve these objectives, the same two methods, the ‘self-report’ that involves questionnaires and AMLS (an android-based app to study the frequency of media multitasking behaviour and the emotions of the users) have been employed. The study gives an insight into the emerging behavioural patterns and hence is helpful for designing communities to cater to the growing needs of the young media users. © 2018 Mudra Institute of Communications, Ahmedabad, India.","2018","2021-02-15 22:37:59","2021-02-15 22:37:59","","197-211","","3","13","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6D8SADTT","conferencePaper","2018","Brueckner, S.","Empathy amulet: A wearable to connect with strangers","Proceedings - International Symposium on Wearable Computers, ISWC","","","10.1145/3267242.3267301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056848773&doi=10.1145%2f3267242.3267301&partnerID=40&md5=348865050bbc443fed58ea7b8b213996","The Empathy Amulet is a wearable interpretation of Philip K. Dick’s empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both hap-tically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today’s world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson’s theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4]. Copyright © 2018 ACM.","2018","2021-02-15 22:37:59","2021-02-15 22:37:59","","248-253","","","","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z59QC259","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness of Android-Based Mobile Robots for Children Asperger Syndrome","Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care","","","10.1109/ICAITI.2018.8686759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753069&doi=10.1109%2fICAITI.2018.8686759&partnerID=40&md5=af11f585df846db5c051b6434459ed42","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially. © 2018 IEEE.","2018","2021-02-15 22:37:59","2021-02-15 22:37:59","","208-212","","","","","","","","","","","","","","","","","","","","","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8CTZ2XD","journalArticle","2018","Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.","Towards empathetic human-robot interactions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-319-75487-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25","Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-02-15 22:37:59","2021-02-15 22:37:59","","173-193","","","9624 LNCS","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJQK5Y67","journalArticle","2017","Chikaraishi, T.; Yoshikawa, Y.; Ogawa, K.; Hirata, O.; Ishiguro, H.","Creation and staging of android theatre ""Sayonara"" towards developing highly human-like robots","Future Internet","","","10.3390/fi9040075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040790411&doi=10.3390%2ffi9040075&partnerID=40&md5=7741ec53279dea95f8e1cde8863ea639","Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world. © 2016 by the authors.","2017","2021-02-15 22:37:59","2021-02-15 22:37:59","","","","4","9","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QPU9QRNQ","journalArticle","2017","Lawrence, D.","More human than human","Cambridge Quarterly of Healthcare Ethics","","","10.1017/S0963180116001158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019997561&doi=10.1017%2fS0963180116001158&partnerID=40&md5=e3142c138b00fcf2ae2397005a02231c","Within the literature surrounding nonhuman animals on the one hand and cognitively disabled humans on the other, there is much discussion of where beings that do not satisfy the criteria for personhood fit in our moral deliberations. In the future, we may face a different but related problem: That we might create (or cause the creation of) beings that not only satisfy but exceed these criteria. The question becomes whether these are minimal criteria, or hierarchical, such that those who fulfill them to greater degree should be afforded greater consideration. This article questions the validity and necessity of drawing divisions among beings that satisfy the minimum requirements for personhood; considering how future beings - intelligent androids, synthezoids, even alternate-substrate sentiences - might fit alongside the baseline human. I ask whether these alternate beings ought to be considered different to us, and why this may or may not matter in terms of a notion of human community. The film Blade Runner, concerned in large part with humanity and its key synthezoid antagonist Roy Batty, forms a framing touchstone for my discussion. Batty is stronger, faster, more resilient, and more intelligent than Homo sapiens. His exploits, far beyond the capability of normal humans, are contrasted with his frailty and transient lifespan, his aesthetic appreciation of the sights he has seen, and his burgeoning empathy. Not for nothing does his creator within the mythos term him more human than human. © Cambridge University Press 2017.","2017","2021-02-15 22:37:59","2021-02-15 22:37:59","","476-490","","3","26","","","","","","","","","","","","","","","","","","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGTADHWF","conferencePaper","2016","Ranieri, C.M.; Romero, R.A.F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","Proceedings - 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016","","","10.1109/LARS-SBR.2016.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010416838&doi=10.1109%2fLARS-SBR.2016.13&partnerID=40&md5=48a1a71aed354854f322eb1a82dcc7eb","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness. © 2016 IEEE.","2016","2021-02-15 22:38:00","2021-02-15 22:38:00","","31-36","","","","","","","","","","","","","","","","","","","","","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6BZXGJ3J","journalArticle","2016","Lawson, L.; Cane, S.","Do conservators dream of electric sheep? Replicas and replication","Studies in Conservation","","","10.1080/00393630.2016.1181348","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988329847&doi=10.1080%2f00393630.2016.1181348&partnerID=40&md5=10144d954aca38ab318f4ec5ae973e82","The paper crosses the boundaries between different genres, drawing on key material and emphasising the philosophical challenges around decision-making and values in relation to replication and replicas. In 1968, Philip K. Dick wrote the book Do Androids Dream of Electric Sheep? which became the inspiration for the 1982 film Bladerunner. The book is set in Los Angeles in a post-apocalyptic future where mankind has left Earth, resulting in androids being created to develop new ‘off-world’ colonies. The book and film create a novel and interesting framework to discuss the subject of replicas and replication within contemporary conservation practice. Key themes are decay promoting replication, original versus replica, creating empathy in replication. The debate focuses on the case study of Naum Gabo's Construction in Space (Crystal) of 1937–39; which was the sculpture replicated in the most recent replication project at Tate, completed in July 2015. © 2016, © The International Institute for Conservation of Historic and Artistic Works 2016.","2016","2021-02-15 22:38:00","2021-02-15 22:38:00","","109-113","","","61","","","","","","","","","","","","","","","","","","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E655LYMW","journalArticle","2016","Sorbello, R.; Chella, A.; Giardina, M.; Nishio, S.; Ishiguro, H.","An architecture for Telenoid robot as empathic conversational android companion for elderly people","Advances in Intelligent Systems and Computing","","","10.1007/978-3-319-08338-4_68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974382&doi=10.1007%2f978-3-319-08338-4_68&partnerID=40&md5=284d20453f0caff779f01dbae2648464","In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user. © Springer International Publishing Switzerland 2016.","2016","2021-02-15 22:38:00","2021-02-15 22:38:00","","939-953","","","302","","","","","","","","","","","","","","","","","","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3M6C8YWF","journalArticle","2014","Hofree, G.; Ruvolo, P.; Bartlett, M.S.; Winkielman, P.","Bridging the mechanical and the human mind: Spontaneous mimicry of a physically present android","PLoS ONE","","","10.1371/journal.pone.0099934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904490592&doi=10.1371%2fjournal.pone.0099934&partnerID=40&md5=160e9e9b43fd8eecd3d04c3cb2e090d0","The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users. © 2014 Hofree et al.","2014","2021-02-15 22:38:00","2021-02-15 22:38:00","","","","7","9","","","","","","","","","","","","","","","","","","<p>cited By 25</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XN29U9FY","journalArticle","2013","Toth, J.","Do androids eat electric sheep?: Egotism, empathy, and the ethics of eating in the work of Philip K. Dick","LIT Literature Interpretation Theory","","","10.1080/10436928.2013.754238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876399832&doi=10.1080%2f10436928.2013.754238&partnerID=40&md5=bc0b2f2e0d0e89b48fbe1f5b48dd00dc","","2013","2021-02-15 22:38:00","2021-02-15 22:38:00","","65-85","","1","24","","","","","","","","","","","","","","","","","","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJU54EF6","journalArticle","2013","Urgen, B.A.; Plank, M.; Ishiguro, H.; Poizner, H.; Saygin, A.P.","EEG theta and Mu oscillations during perception of human and robot actions","Frontiers in Neurorobotics","","","10.3389/fnbot.2013.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899682291&doi=10.3389%2ffnbot.2013.00019&partnerID=40&md5=b4aae2154c5beca9ef9fffd9bde2d77a","The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin.","2013","2021-02-15 22:38:00","2021-02-15 22:38:00","","","","NOV","7","","","","","","","","","","","","","","","","","","<p>cited By 34</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
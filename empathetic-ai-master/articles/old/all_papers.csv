Key;Item Type;Publication Year;Author;Title;Publication Title;ISBN;ISSN;DOI;Url;Abstract Note;Date;Date Added;Date Modified;Access Date;Pages;Num Pages;Issue;Volume;Number Of Volumes;Journal Abbreviation;Short Title;Series;Series Number;Series Text;Series Title;Publisher;Place;Language;Rights;Type;Archive;Archive Location;Library Catalog;Call Number;Extra;Notes;File Attachments;Link Attachments;Manual Tags;Automatic Tags;Editor;Series Editor;Translator;Contributor;Attorney Agent;Book Author;Cast Member;Commenter;Composer;Cosponsor;Counsel;Interviewer;Producer;Recipient;Reviewed Author;Scriptwriter;Words By;Guest;Number;Edition;Running Time;Scale;Medium;Artwork Size;Filing Date;Application Number;Assignee;Issuing Authority;Country;Meeting Name;Conference Name;Court;References;Reporter;Legal Status;Priority Numbers;Programming Language;Version;System;Code;Code Number;Section;Session;Committee;History;Legislative Body;Database
AANIM2W4;conferencePaper;2013;"Jo, Doori; Han, Jooyun; Chung, Kyungmi; Lee, Sukhan";Empathy between human and robot?;Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction;978-1-4673-3055-8;NA;NA;NA;This paper aims at finding the answer to the essential question: Can people perceive a robot's presence as having a social existence? We attempt to apply a sociological and psychological approach to understand the influence of robot beings, by observing human emotion and perception changes while subjects watched a funny video clip in the presence of a robot or a human companion, each of which made their own typical laughing sounds. From this experiment, we found that the robot did not affect the human's positive emotions as much as a human companion did, but the robot did discourage negative emotions. However, the subjects were, in general, amused when they were watching the video with the robot. This amusement is similar to the contagious effect of sharing humor with another human being. Our findings suggest that the subjects accepted the robot's presence as a kind of existence empathically.;2013-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;151–152;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;Tokyo, Japan;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social robot; empathy; robot companion; human robot interaction; emotional contagion; presence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XRS6IWUN;conferencePaper;2014;"Tsuji, Yuichiro; Tsukamoto, Ami; Uchida, Takashi; Hattori, Yusuke; Nishida, Ryosuke; Fukada, Chie; Ozeki, Motoyuki; Omori, Takashi; Nagai, Takayuki; Oka, Natsuki";Experimental study of empathy and its behavioral indices in human-robot interaction;Proceedings of the second international conference on Human-agent interaction;978-1-4503-3035-0;NA;10.1145/2658861.2658933;https://doi.org/10.1145/2658861.2658933;Similar to relationships between humans, a person desiring to form a good relationship with a robot needs to be able to empathize with it. However, the specific kinds of human-robot interactions that would arouse and enhance empathy for the robot in the user's mind have not yet been clarified. In addition, the human behavioral traits that may be regarded as indices of empathy have not been investigated extensively. In an attempt to address these two issues, a preliminary experiment on empathy in human-robot interaction is conducted. The results suggest that the actions of naming or comforting a robot could contribute to enhancing its user's empathy and that eye fixation could be used as an index of empathy even when the use of a subjective index is inconclusive.;2014-10-29;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;245–248;NA;NA;NA;NA;NA;NA;HAI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; behavioral indices; visual fixation time";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
M5X69E3Q;conferencePaper;2014;"Mok, Brian K.; Yang, Stephen; Sirkin, David; Ju, Wendy";Empathy: interactions with emotive robotic drawers;Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction;978-1-4503-2658-2;NA;10.1145/2559636.2563720;https://doi.org/10.1145/2559636.2563720;The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.;2014-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;250–251;NA;NA;NA;NA;NA;Empathy;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human robot interactions; interaction design; interactive furniture; video prototyping; wizard of oz experiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3DGZDG4X;conferencePaper;2019;"Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji";The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot;Proceedings of the 7th International Conference on Human-Agent Interaction;978-1-4503-6922-0;NA;10.1145/3349537.3351891;https://doi.org/10.1145/3349537.3351891;We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.;2019-09-25;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;51–58;NA;NA;NA;NA;NA;NA;HAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; animism; robots' perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JQQUXI92;conferencePaper;2013;"Rosenthal-von der Pütten, Astrid Marieke; Schulte, Frank P.; Eimler, Sabrina C.; Hoffmann, Laura; Sobieraj, Sabrina; Maderwald, Stefan; Krämer, Nicole C.; Brand, Matthias";Neural correlates of empathy towards robots;Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction;978-1-4673-3055-8;NA;NA;NA;We conducted an fMRI study to investigate emotionality in human-robot interaction. Subjects (N=14) were presented videos showing a human, a robot and an unanimated object, being treated in either an affectionate or a violent way. Violent interaction towards both the robot and the human resulted in similar neural activation patterns in classic limbic structures indicating that both the robot and the human elicit similar emotional reactions. However, differences in neural activity suggest that participants show more negative empathetic concern for the human in a negative situation.;2013-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;215–216;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;Tokyo, Japan;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; experimental study; functional magnetic resonance imaging";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PJCE5FWN;conferencePaper;2010;"Cramer, Henriette; Goddijn, Jorrit; Wielinga, Bob; Evers, Vanessa";Effects of (in)accurate empathy and situational valence on attitudes towards robots;Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction;978-1-4244-4893-7;NA;NA;NA;Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.;2010-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;141–142;NA;NA;NA;NA;NA;NA;HRI '10;NA;NA;NA;IEEE Press;Osaka, Japan;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; social robots; emotional valence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L7R28TUC;conferencePaper;2014;"Obaid, Mohammad; Kuchenbrandt, Dieta; Bartneck, Christoph";Empathy and yawn contagion: can we (humans) catch yawns from robots?;Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction;978-1-4503-2658-2;NA;10.1145/2559636.2563702;https://doi.org/10.1145/2559636.2563702;Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.;2014-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;260–261;NA;NA;NA;NA;NA;Empathy and yawn contagion;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; robot; humanoid; yawn";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZF8UQNN8;conferencePaper;2015;"Zuckerman, Oren; Hoffman, Guy";Empathy Objects: Robotic Devices as Conversation Companions;Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction;978-1-4503-3305-4;NA;10.1145/2677199.2688805;https://doi.org/10.1145/2677199.2688805;"We present the notion of Empathy Objects, ambient robotic devices accompanying human-human interaction. Empathy Objects respond to human behavior using physical gestures as nonverbal expressions of their ""emotional states"". The goal is to increase people's self-awareness to the emotional state of others, leading to behavior change. We demonstrate an Empathy Object prototype, Kip1, a conversation companion designed to promote non-aggressive conversation between people.";2015-01-15;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;593–598;NA;NA;NA;NA;NA;Empathy Objects;TEI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social robots; tangible interfaces; ambient devices; behavior change; companion devices";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
H9FWTCUC;journalArticle;2019;"Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;ACM Transactions on Human-Robot Interaction;NA;NA;10.1145/3300188;https://doi.org/10.1145/3300188;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03-06;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T21:18:35Z;3:1–3:34;NA;1;8;NA;J. Hum.-Robot Interact.;Empathic Robot for Group Learning;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2019;NA;NA;NA;C:\Users\esben\Zotero\storage\8WK2EF8I\Alves-Oliveira et al. - 2019 - Empathic Robot for Group Learning A Field Study.pdf;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SKDHD9CA;conferencePaper;2015;"Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.";Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2883-8;NA;10.1145/2696454.2696471;https://doi.org/10.1145/2696454.2696471;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.";2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;125–132;NA;NA;NA;NA;NA;Poor Thing! Would You Feel Sorry for a Simulated Robot?;HRI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; robot embodiment; simulated interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9Q3XVL5X;conferencePaper;2016;"Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid";Map Reading with an Empathic Robot Tutor;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.;2016-03-07;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;567;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;Christchurch, New Zealand;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; robot-child interaction; robotic tutor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KSJQF22A;journalArticle;2017;"Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke";Empathy in Virtual Agents and Robots: A Survey;ACM Transactions on Interactive Intelligent Systems;NA;2160-6455;10.1145/2912150;https://doi.org/10.1145/2912150;This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.;2017-09-19;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T21:18:40Z;11:1–11:40;NA;3;7;NA;ACM Trans. Interact. Intell. Syst.;Empathy in Virtual Agents and Robots;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;October 2017;NA;NA;NA;NA;NA;NA;"virtual agents; empathy; affective computing; human-computer interaction; human-robot interaction; social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YREHDATV;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;Proceedings of the 2019 11th International Conference on Computer and Automation Engineering;978-1-4503-6287-0;NA;10.1145/3313991.3314018;https://doi.org/10.1145/3313991.3314018;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019-02-23;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;102–108;NA;NA;NA;NA;NA;NA;ICCAE 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PY4IZRD9;conferencePaper;2015;"Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana";The Empathic Robotic Tutor: Featuring the NAO Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702100;https://doi.org/10.1145/2701973.2702100;We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;285;NA;NA;NA;NA;NA;The Empathic Robotic Tutor;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"educational robotics; empathic robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KMKPTC6Z;conferencePaper;2012;"Leite, Iolanda; Castellano, Ginevra; Pereira, André; Martinho, Carlos; Paiva, Ana";Modelling empathic behaviour in a robotic game companion for children: an ethnographic study in real-world settings;Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction;978-1-4503-1063-5;NA;10.1145/2157689.2157811;https://doi.org/10.1145/2157689.2157811;The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with.;2012-03-05;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;367–374;NA;NA;NA;NA;NA;Modelling empathic behaviour in a robotic game companion for children;HRI '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"children; empathy; social robots; affect recognition";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KVYBEWRW;conferencePaper;2011;Leite, Iolanda;Using adaptive empathic responses to improve long-term interaction with social robots;Proceedings of the 19th international conference on User modeling, adaption, and personalization;978-3-642-22361-7;NA;NA;NA;The goal of this research is to investigate the effects of empathy and adaptive behaviour in long-term interaction between social robots and users. To address this issue, we propose an action selection mechanism that will allow a social robot to chose adaptive empathic responses, in the attempt to keep users engaged over several interactions.;2011-07-11;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;446–449;NA;NA;NA;NA;NA;NA;UMAP'11;NA;NA;NA;Springer-Verlag;Berlin, Heidelberg;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; social robots; adaptive feedback; affective user modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
78NAU3Q4;conferencePaper;2015;"Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Foster, Mary Ellen; Ribeiro, Tiago; Corrigan, Lee Joseph; Aylett, Ruth; Paiva, Ana; Papadopoulos, Fotios; Castellano, Ginevra";Empathic Robotic Tutors: Map Guide;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702693;https://doi.org/10.1145/2701973.2702693;In this demonstration we describe a scenario developed in the EMOTE project. The overall goal of the project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. We are aiming to develop an empathic robot tutor to teach map reading skills with this scenario on a touch-screen device.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;311;NA;NA;NA;NA;NA;Empathic Robotic Tutors;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
FB4B3Q6X;conferencePaper;2015;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe; Carofiglio, Valeria";Modeling and Simulating Empathic Behavior in Social Assistive Robots;Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter;978-1-4503-3684-0;NA;10.1145/2808435.2808445;https://doi.org/10.1145/2808435.2808445;Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living.;2015-09-28;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;110–117;NA;NA;NA;NA;NA;NA;CHItaly 2015;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Affective Computing; Social Assistive Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LHBHCPCS;conferencePaper;2014;"Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth";Towards a serious game playing empathic robotic tutorial dialogue system;Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction;978-1-4503-2658-2;NA;10.1145/2559636.2563707;https://doi.org/10.1145/2559636.2563707;There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.;2014-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;180–181;NA;NA;NA;NA;NA;NA;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"serious games; dialogue management; empathic robotic tutor; tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HSUY4Y68;journalArticle;2015;Leite, Iolanda;Long-term interactions with empathic social robots;AI Matters;NA;NA;10.1145/2735392.2735397;https://doi.org/10.1145/2735392.2735397;We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.;2015-03-10;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T21:18:51Z;13–15;NA;3;1;NA;AI Matters;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2015;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KC23H3EE;conferencePaper;2015;"Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro";An Empathic Robotic Tutor in a Map Application;Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems;978-1-4503-3413-6;NA;NA;NA;In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.;2015-05-04;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1923–1924;NA;NA;NA;NA;NA;NA;AAMAS '15;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
T3BP727I;conferencePaper;2019;"Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amélie; Lefort, Mathieu; Hassas, Salima";The RoPE scale: a measure of how empathic a robot is perceived;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.;2019-03-11;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;656–657;NA;NA;NA;NA;NA;The RoPE scale;HRI '19;NA;NA;NA;IEEE Press;Daegu, Republic of Korea;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-robot interaction; social robots; perceived empathy; psychometrics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KDAFW6FD;conferencePaper;2017;"Hieida, Chie; Nagai, Takayuki";A Model of Emotion for Empathic Communication;Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-4885-0;NA;10.1145/3029798.3038299;https://doi.org/10.1145/3029798.3038299;Most people believe that robots have no emotions, and nor do they need them. However, we strongly believe that having emotions is essential for robots to understand and sympathize with the feelings of people, thereby allowing them to be accepted into the human society. In this paper, we propose a model of emotion based on some neurological and psychological findings concerning empathic communication between humans and robots. Then, we examine a method for generating affect for given visual stimuli using a recurrent neural network as a first step.;2017-03-06;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;133–134;NA;NA;NA;NA;NA;NA;HRI '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathic human-robot interaction; model of emotion; recurrent-attention model";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EF3U5PU9;conferencePaper;2013;"Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth";Towards empathic artificial tutors;Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction;978-1-4673-3055-8;NA;NA;NA;In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.;2013-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;113–114;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;Tokyo, Japan;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DTWD89GB;bookSection;2020;"Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri";Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419900;Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.;2020-11-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;262–266;NA;NA;NA;NA;NA;Playing with the Opposite of Uncanny;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotional intelligence; human-computer interaction; child-robot interaction; human-animal interaction; playful learning; robot toys; social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6WRPPFGX;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems;978-1-4503-4239-1;NA;NA;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016-05-09;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;931–939;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-agent interaction; human-robot interaction; memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4W8E3RGE;conferencePaper;2020;"Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423864;https://doi.org/10.1145/3383652.3423864;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).;2020-10-20;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1–3;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; conversational agent; emotion detection; healthcare computing; pattern matching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BFD4D4HD;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor";He who hesitates is lost (...in thoughts over a robot);Proceedings of the Technology, Mind, and Society;978-1-4503-5420-2;NA;10.1145/3183654.3183703;https://doi.org/10.1145/3183654.3183703;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.;2018-04-05;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1–6;NA;NA;NA;NA;NA;NA;TechMindSociety '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6JCIVLLF;conferencePaper;2015;"Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani Sherman, Tal";Design and Evaluation of a Peripheral Robotic Conversation Companion;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2883-8;NA;10.1145/2696454.2696495;https://doi.org/10.1145/2696454.2696495;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;3–10;NA;NA;NA;NA;NA;NA;HRI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\MLNZIAL8\Hoffman et al. - 2015 - Design and Evaluation of a Peripheral Robotic Conv.pdf;NA;NA;"empathy; human-robot interaction; design; behavior change; ambient kinetic tangibles; robotic companions; smartphone robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
USK294DF;conferencePaper;2015;Franco, Gloria Adriana Mendoza;Evaluation of the emotional answer in HRI on a game situation;Proceedings of the Latin American Conference on Human Computer Interaction;978-1-4503-3960-5;NA;10.1145/2824893.2824897;https://doi.org/10.1145/2824893.2824897;This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.;2015-11-18;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1–7;NA;NA;NA;NA;NA;NA;CLIHC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; interaction design; HRI; Emocards; emotional evaluation; emotional reciprocity; lottery application";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TFYW6FRB;conferencePaper;2010;"Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Castellano, Ginevra; Martinho, Carlos; Prada, Rui; Paiva, Ana";Closing the loop: from affect recognition to empathic interaction;Proceedings of the 3rd international workshop on Affective interaction in natural environments;978-1-4503-0170-1;NA;10.1145/1877826.1877839;https://doi.org/10.1145/1877826.1877839;Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.;2010-10-29;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;43–48;NA;NA;NA;NA;NA;Closing the loop;AFFINE '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; affect recognition; artificial companions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IVTQ5GVJ;conferencePaper;2018;"Björling, Elin A.; Rose, Emma; Ren, Rachel";Teen-Robot Interaction: A Pilot Study of Engagement with a Low-fidelity Prototype;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177068;https://doi.org/10.1145/3173386.3177068;Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies.;2018-03-01;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;69–70;NA;NA;NA;NA;NA;Teen-Robot Interaction;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\RPVKZPA8\Björling et al. - 2018 - Teen-Robot Interaction A Pilot Study of Engagemen.pdf;NA;NA;"engagement; prototype; teen-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZH8PQFSM;conferencePaper;2018;"Kang, Dahyun; Kim, SunKyoung; Kwak, Sonya S.";The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177023;https://doi.org/10.1145/3173386.3177023;We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand.;2018-03-01;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;143–144;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; functional intimacy; knowledgeableness; physical contact; safety; sociability; social distance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XN5SS8TT;conferencePaper;2012;"Stienstra, Jelle; Marti, Patrizia";Squeeze me: gently please;Proceedings of the 7th Nordic Conference on Human-Computer Interaction: Making Sense Through Design;978-1-4503-1482-4;NA;10.1145/2399016.2399131;https://doi.org/10.1145/2399016.2399131;This paper presents the Squeeze Me, a research-through-design case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a double-layered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge.;2012-10-14;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;746–750;NA;NA;NA;NA;NA;Squeeze me;NordiCHI '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; interaction design; continuous mapping";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YTP6JBLY;conferencePaper;2015;"Jeong, Seongmi; Gu, Jihyang; Shin, Dong-Hee";I am Interested in What You are Saying: Role of Nonverbal Immediacy Cues in Listening;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702040;https://doi.org/10.1145/2701973.2702040;Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;129–130;NA;NA;NA;NA;NA;I am Interested in What You are Saying;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"hri; immediacy; nodding; nonverbal behavior; posture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ALXJ9M2S;conferencePaper;2015;"Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung";Design of Emotional Conversations with a Child for a Role Playing Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702009;https://doi.org/10.1145/2701973.2702009;The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;73–74;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotional role playing robot; human intervention device; human-robot-interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HUV5Y7SW;conferencePaper;2020;"Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vázquez, Marynel";Prompting Prosocial Human Interventions in Response to Robot Mistreatment;Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-6746-2;NA;10.1145/3319502.3374781;https://doi.org/10.1145/3319502.3374781;Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N=30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.;2020-03-09;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;211–220;NA;NA;NA;NA;NA;NA;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-robot interaction; prosocial behavior; robot abuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9ME7TVLW;conferencePaper;2014;"Fraga, Luís; Coelho, António; Branco, Pedro";Meet the Frumbles: a post-digital toy orchestra;Proceedings of the 11th Conference on Advances in Computer Entertainment Technology;978-1-4503-2945-3;NA;10.1145/2663806.2663813;https://doi.org/10.1145/2663806.2663813;"""Meet the Frumbles"" is a group of felt robotic characters that talk amongst themselves and interact with the audience. Empathy, cuteness and gags are explored as communicational facilitators and ludic interaction between a felt robot creature's orchestra and its human conductor. Creative coding using computer vision, electronic prototyping and physical actuators was used to implement the autonomous physical existence, sensing and behavior of creatures.";2014-11-11;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1–4;NA;NA;NA;NA;NA;Meet the Frumbles;ACE '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective computing; robotics; digital art; humor; post-digital; toys";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PF7WCYFM;conferencePaper;2018;"Lehmann, Hagen; Broz, Frank";Contagious Yawning in Human-Robot Interaction;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177063;https://doi.org/10.1145/3173386.3177063;This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data.;2018-03-01;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;173–174;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; behavior contagion; yawning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R7ZDSX5G;conferencePaper;2018;"de Jesus Santos, Fabrícia; de Almeida, Antonio Lucas; Santos, Breno Santana; de Souza, Caio César Alves; Santos, Marcos Neto";Empathic Computer Science: A Systematic Mapping;Proceedings of the 17th Brazilian Symposium on Human Factors in Computing Systems;978-1-4503-6601-4;NA;10.1145/3274192.3274238;https://doi.org/10.1145/3274192.3274238;Described as the capability to understand the emotional state of an individual and often express a response that resonates with it, empathy is a crucial factor for social interactions. However, the ability to express empathy diminishes as people rely more and more on technological resources to interact. Due to fact of being an essential component to become a more effective social relationship between humans and computers, there are several approaches, techniques, methods or mechanisms to promote empathy in these interactions. This paper proposes to identify and systematize mechanisms used in Computer Science to promote empathy. Thus, it was carried out a systematic mapping on the main research databases of the area. We identified the main approaches used to promote empathy, such as Empathic Robotic Agent/Device and Empathic Virtual Agent, as well as the countries that hold the most research in this line, especially the United Kingdom, Japan and USA. In addition, it was found that this area of research is still not being explored in any significant way.;2018-10-22;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;1–5;NA;NA;NA;NA;NA;Empathic Computer Science;IHC 2018;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Empathy; Rapport; Computer Science; Secondary Study; Systematic Mapping";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3KT8P3LP;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica";Good robot design or machiavellian? an in-the-wild robot leveraging minimal knowledge of passersby's culture;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019-03-11;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;382–391;NA;NA;NA;NA;NA;Good robot design or machiavellian?;HRI '19;NA;NA;NA;IEEE Press;Daegu, Republic of Korea;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5ZHVWYBB;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";The CoWriter Project: Teaching a Robot how to Write;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702091;https://doi.org/10.1145/2701973.2702091;"This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.";2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;269;NA;NA;NA;NA;NA;The CoWriter Project;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\V6E57X8C\Hood et al. - 2015 - The CoWriter Project Teaching a Robot how to Writ.pdf;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PD2Z2KZM;conferencePaper;2020;"Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon";Robots Teaching Recycling: Towards Improving Environmental Literacy of Children;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3379462;https://doi.org/10.1145/3371382.3379462;The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.;2020-03-23;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;615–616;NA;NA;NA;NA;NA;Robots Teaching Recycling;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"educational robotics; children robot interaction; eco-literacy; environmental literacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8Q2DHD67;conferencePaper;2018;"Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana";Group-based Emotions in Teams of Humans and Robots;Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-4953-6;NA;10.1145/3171221.3171252;https://doi.org/10.1145/3171221.3171252;Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.;2018-02-26;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;261–269;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotion; trust; group effects; identification; inter-group interactions; self-categorisation; human-robot teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
FJ5XJIZA;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2883-8;NA;10.1145/2696454.2696479;https://doi.org/10.1145/2696454.2696479;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015-03-02;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;83–90;NA;NA;NA;NA;NA;When Children Teach a Robot to Write;HRI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\65JNBIHW\Hood et al. - 2015 - When Children Teach a Robot to Write An Autonomou.pdf;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6EESENGZ;conferencePaper;2014;"Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei";The fugitive: a robot in the wild;Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction;978-1-4503-2658-2;NA;10.1145/2559636.2559653;https://doi.org/10.1145/2559636.2559653;The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building. The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not. The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on. The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol. The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.;2014-03-03;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;111;NA;NA;NA;NA;NA;The fugitive;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-robot interaction; social robotics; robots in the wild";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VA9KUW7C;conferencePaper;2019;Vertesi, Janet;Seeing like a rover: team work and human-robot relations;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;"How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go --- in search and rescue operations, ocean voyages, or even into space --- they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.";2019-03-11;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;152;NA;NA;NA;NA;NA;Seeing like a rover;HRI '19;NA;NA;NA;IEEE Press;Daegu, Republic of Korea;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-robot interaction; teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3I4JIGJK;conferencePaper;2010;"Beck, Aryel; Hiolle, Antoine; Mazel, Alexandre; Cañamero, Lola";Interpretation of emotional body language displayed by robots;Proceedings of the 3rd international workshop on Affective interaction in natural environments;978-1-4503-0170-1;NA;10.1145/1877826.1877837;https://doi.org/10.1145/1877826.1877837;"In order for robots to be socially accepted and generate empathy they must display emotions. For robots such as Nao, body language is the best medium available, as they do not have the ability to display facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should greatly improve its acceptance. This research investigates the creation of an ""Affect Space"" [1] for the generation of emotional body language that could be displayed by robots. An Affect Space is generated by ""blending"" (i.e. interpolating between) different emotional expressions to create new ones. An Affect Space for body language based on the Circumplex Model of emotions [2] has been created. The experiment reported in this paper investigated the perception of specific key poses from the Affect Space. The results suggest that this Affect Space for body expressions can be used to improve the expressiveness of humanoid robots. In addition, early results of a pilot study are described. It revealed that the context helps human subjects improve their recognition rate during a human-robot imitation game, and in turn this recognition leads to better outcome of the interactions.";2010-10-29;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;37–42;NA;NA;NA;NA;NA;NA;AFFINE '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotional body language; human robot interactions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MCIJ64R7;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3326596;https://doi.org/10.1145/3311927.3326596;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019-06-12;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T00:00:00Z;755–760;NA;NA;NA;NA;NA;EmotoTent;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PG9DLAZL;journalArticle;2012;"Beck, Aryel; Stevens, Brett; Bard, Kim A.; Cañamero, Lola";Emotional body language displayed by artificial agents;ACM Transactions on Interactive Intelligent Systems;NA;2160-6455;10.1145/2133366.2133368;https://doi.org/10.1145/2133366.2133368;Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots.;2012-03-20;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2021-02-15T21:19:32Z;2:1–2:29;NA;1;2;NA;ACM Trans. Interact. Intell. Syst.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2012;NA;NA;NA;C:\Users\esben\Zotero\storage\86VZVFZV\Beck et al. - 2012 - Emotional body language displayed by artificial ag.pdf;NA;NA;"emotional body language; Human computer interactions; human robot interactions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
B6UKMX4L;conferencePaper;2018;"Tan, Xiang Zhi; Vázquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron";Inducing Bystander Interventions During Robot Abuse with Social Mechanisms;Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-4953-6;NA;10.1145/3171221.3171247;https://doi.org/10.1145/3171221.3171247;We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant»s performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.;2018-02-26;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;169–177;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\FBKMMCQB\Tan et al. - 2018 - Inducing Bystander Interventions During Robot Abus.pdf;NA;NA;"robots; empathy; human-robot interaction; abuse; bullying; peer intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HWEVNDJN;conferencePaper;2017;Thompson, Jeff;I touch you and you touch me;SIGGRAPH Asia 2017 Art Gallery;978-1-4503-5401-1;NA;10.1145/3143748.3143753;https://doi.org/10.1145/3143748.3143753;A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.;2017-11-27;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1;NA;NA;NA;NA;NA;NA;SA '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9YQ7EMT4;conferencePaper;2016;Aylett, Ruth;Am I bovvered? Fifteen years of Empathic Agents;Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems;978-1-4503-4239-1;NA;NA;NA;"In 2001, the EU-funded project VICTEC pioneered the concept of an Empathic Agent. This was reported at AAMAS in 2004 in a well-cited paper 'Caring for Agents and Agents that Care: Building Empathic Relations with Synthetic Agents' (Paiva, Dias, Sobral, Aylett, Sobreperez, Woods, Zoll, Hall). It advanced two goals for embodied empathic agents: characters that, by their actions and behaviours, are able to show empathy (or not) for other characters; and characters that, by their appearance, situation, and behaviour, are able to trigger empathic reactions in the user. In this talk we discuss how far Embodied Empathic Agents - whether graphical or robotic - are succeeding; what we can now do, and what open research questions remain. What are the key theoretical and technological advances already made and which are still needed? What applications are Empathic Agents `good' for, and how do we know they are? And how do they relate to the broader field of social agents?";2016-05-09;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;4;NA;NA;NA;NA;NA;Am I bovvered?;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5UJRNGXU;conferencePaper;2019;Aubergé, Véronique;The Socio-Affective Robot: Aimed to Understand Human Links?;Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop;978-1-4503-6913-8;NA;10.1145/3347320.3357687;https://doi.org/10.1145/3347320.3357687;"Is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence, revealing some crucial aspects of social and cultural human processing? Among the smart objects, the social robot cannot be distinguished by precise and well defined technical or morphological cues. Even though no serious and discriminative attributes can be given by any science knowledge -- even the movement attribute, and the ""autonomous'' cognitive attribute are not clearly defined -- in order to understand how an object becomes, perceptively, a subject (social robot), it is a fact that the automatons and the talking artefacts are now named robot, which is particularly attractive for general public, for scientists and engineers. However, is it a socio-cultural desire or a technical need to add the augmentation of the social space to the ""augmented self'' (self body and self environment abilities)? In this talk we will explore some social space perturbations in ecological conditions, such as elderly people suffering from isolation and interacting with a robot that can emit solely non-verbal speech primitives. Long term interactions were collected and analysed using the concepts of the Dynamic Affective Network for Social Entities (D.A.N.S.E.) theory. We will try to show that non-verbal speech primitives, organised in the D.A.N.S.E.'s ""glue'' paradigm, permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance, but also to explore in particular an empathic dimension. Through a Living Lab method, evaluation of these hypotheses and building of an empathic socio-affective HRI were conducted together, within strong ethical constraints. In particular the development of frail robots for frail people will be proposed as possible ethical perspective.";2019-10-15;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1;NA;NA;NA;NA;NA;The Socio-Affective Robot;AVEC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"engagement; frail person; hri; living lab; social robot; socio-affective speech";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VX4TQXWM;conferencePaper;2016;"Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra";How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.;2016-03-07;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;423–424;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;Christchurch, New Zealand;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; robotic tutors; child-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
55ZWNUAG;conferencePaper;2015;"Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia";Designing a socially assistive robot for pediatric care;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771923;https://doi.org/10.1145/2771839.2771923;We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.;2015-06-21;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;387–390;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MGH4IF88;conferencePaper;2014;"Ribeiro, Tiago; Pereira, André; Deshmukh, Amol; Aylett, Ruth; Paiva, Ana";I'm the mayor: a robot tutor in enercities-2;Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems;978-1-4503-2738-1;NA;NA;NA;We are addressing the problem of creating empathic robot tutors to support school students studying geography topics on a multi-touch table. A multi-role serious game Enercities-2 has been developed from an earlier single-user version in which a Mayor, Economist and Environmentalist have control over differing resources. The game explores the tension between individual and collaborative success. A robot tutor, embodied as a NAO Torso robot, can play any one of these roles. This interactive demo using a large tablet and the NAO will allow attendees to play with the robot, which currently tries to maximize the collaborative score.;2014-05-05;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1675–1676;NA;NA;NA;NA;NA;I'm the mayor;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-robot interaction; social robots; serious games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QVKHPLBW;conferencePaper;2020;"Kim, Jinwook; Baek, Kyungwon; Jang, Jinkyu";Petbe: Projecting a Real Being onto a Social Robot Using Contextual Data for a Pet Monitoring Method;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3378236;https://doi.org/10.1145/3371382.3378236;The demand for pet monitoring devices is growing due to the increasing number of one-person households raising pets. However, current monitoring methods using video camera entail various problems, which may lead to discontinued usage. To overcome this problem, we propose Petbe, a social robot that projects your own pet using a context-aware approach based on BLE beacons and Raspberry Pis. The corresponding smartphone application provides various robot status updates (robot head) and movements (robot body). With the development of Petbe, we conducted an exploratory study to verify the advancement of the above issues on monitoring user's own pets with the following factors: privacy concern, companionship, awareness, connectivity, and satisfaction. The outcomes indicate that Petbe helps to reduce privacy concerns and build companionship through empathetic interaction.;2020-03-23;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;290–292;NA;NA;NA;NA;NA;Petbe;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social robot; context aware; pet monitoring; projection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JFI93J8V;conferencePaper;2013;"Plant, Nicola; Healey, Patrick G.T.";Surface tension;CHI '13 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-1952-2;NA;10.1145/2468356.2479589;https://doi.org/10.1145/2468356.2479589;"The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?";2013-04-27;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;2979–2982;NA;NA;NA;NA;NA;NA;CHI EA '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; embodied cognition; gesture; nonverbal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
88NLQ5DD;conferencePaper;2014;"Aghel Manesh, Setareh; Beran, Tanya; Sharlin, Ehud; Greenberg, Saul";Medi, human robot interaction in pediatric health;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2579529;https://doi.org/10.1145/2559206.2579529;When children go through a medical procedure (e.g. a blood draw), they often experience increased levels of anxiety and stress. We believe that having an empathetic robot companion during the procedure can help children cope with pain and improve their overall experience. The robot makes use of a set of behaviors derived from pain management literature and modeled on human behaviors and cognitive behavioral therapy. In order to investigate the role of the robot as social companion, we are currently performing a Wizard of Oz study at a children's hospital. Our results are preliminary, but so far we have observed - as illustrated in the video - that the robot can improve the experience for children as long as they are not highly agitated.;2014-04-26;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;153–154;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social robots; human robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7LUUP24Q;conferencePaper;2019;"Degraen, Donald; Kosmalla, Felix; Krüger, Antonio";Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications;Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5971-9;NA;10.1145/3290607.3312833;https://doi.org/10.1145/3290607.3312833;Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.;2019-05-02;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1–6;NA;NA;NA;NA;NA;Overgrown;CHI EA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"ambient notifications; empathic living media; focus group; ambient interfaces";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7I4CGC9S;bookSection;2020;"Pollmann, Kathrin; Ziegler, Daniel";Personal quizmaster: a pattern approach to personalized interaction experiences with the MiRo robot;Proceedings of the Conference on Mensch und Computer;978-1-4503-7540-5;NA;NA;https://doi.org/10.1145/3404983.3410414;In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes.;2020-09-06;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;485–489;NA;NA;NA;NA;NA;Personal quizmaster;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social robot; behavioral patterns; multimodal behavioral expressions; personalized human-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
63MKJYFJ;conferencePaper;2019;"Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher";Mutual reinforcement learning with robot trainers;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.;2019-03-11;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;572–573;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;Daegu, Republic of Korea;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5P4K95CC;conferencePaper;2016;"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia";Affect-Aware Student Models for Robot Tutors;Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems;978-1-4503-4239-1;NA;NA;NA;Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.;2016-05-09;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;864–872;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective computing; child-robot interaction; socially assistive robots; educational robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WEHRQMHM;conferencePaper;2018;"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia";A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.;2018-07-09;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1658–1666;NA;NA;NA;NA;NA;A Social Robot System for Modeling Children's Word Pronunciation;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\H6EJJB5Z\Spaulding et al. - 2018 - A Social Robot System for Modeling Children's Word.pdf;NA;NA;"social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LPJA645A;conferencePaper;2020;"Li, Yuanchao; Zhao, Tianyu; Shen, Xun";Attention-Based Multimodal Fusion for Estimating Human Emotion in Real-World HRI;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3378261;https://doi.org/10.1145/3371382.3378261;Toward empathetic and harmonious human-robot interaction (HRI), automatic estimation of human emotion has attracted increasing attention from multidisciplinary research fields. In this report, we propose an attention-based multimodal fusion approach that explores the space between traditional early and late fusion approaches, to deal with the problem of asynchronous multimodal inputs while considering their relatedness. The proposed approach enables the robot to align the human's visual and speech signals (more specifically, facial, acoustic, and lexical information) extracted by its cameras, microphones, and processing modules and is expected to achieve robust estimation performance in real-world HRI.;2020-03-23;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;340–342;NA;NA;NA;NA;NA;NA;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"attention mechanism; emotion estimation; human-robot interaction (hri); multimodal fusion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
79SDNDSF;conferencePaper;2010;"McDonnell, Rachel; Breidt, Martin";Face reality: investigating the Uncanny Valley for virtual faces;ACM SIGGRAPH ASIA 2010 Sketches;978-1-4503-0523-5;NA;10.1145/1899950.1899991;https://doi.org/10.1145/1899950.1899991;"The Uncanny Valley (UV) has become a standard term for the theory that near-photorealistic virtual humans often appear unintentionally erie or creepy. This UV theory was first hypothesized by robotics professor Masahiro Mori in the 1970's [Mori 1970] but is still taken seriously today by movie and game developers as it can stop audiences feeling emotionally engaged in their stories or games. It has been speculated that this is due to audiences feeling a lack of empathy towards the characters. With the increase in popularity of interactive drama video games (such as L.A. Noire or Heavy Rain), delivering realistic conversing virtual characters has now become very important in the real-time domain. Video game rendering techniques have advanced to a very high quality; however, most games still use linear blend skinning due to the speed of computation. This causes a mismatch between the realism of the appearance and animation, which can result in an uncanny character. Many game developers opt for a stylised rendering (such as cel-shading) to avoid the uncanny effect [Thompson 2004]. In this preliminary work, we begin to study the complex interaction between rendering style and perceived trust, in order to provide guidelines for developers for creating plausible virtual characters.";2010-12-15;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1–2;NA;NA;NA;NA;NA;Face reality;SA '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L47W28NI;conferencePaper;2020;"Troiano, Giovanni Maria; Wood, Matthew; Harteveld, Casper";"""And This, Kids, Is How I Met Your Mother"": Consumerist, Mundane, and Uncanny Futures with Sex Robots";Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6708-0;NA;10.1145/3313831.3376598;https://doi.org/10.1145/3313831.3376598;Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM;2020-04-21;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1–17;NA;NA;NA;NA;NA;"""And This, Kids, Is How I Met Your Mother""";CHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"ethics; human-robot interaction; research fiction; sex robots; sexual HCI; speculative design; story completion method";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XCZNNLQJ;conferencePaper;2015;Encinas, Enrique;Cyrafour: How Two Human Avatars Communicate With Each Other;Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-3146-3;NA;10.1145/2702613.2726962;https://doi.org/10.1145/2702613.2726962;Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.;2015-04-18;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;109–114;NA;NA;NA;NA;NA;Cyrafour;CHI EA '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MEFVKNRK;conferencePaper;2016;"Shinohara, Yumiko; Kubo, Katsuhiro; Nozawa, Momoyo; Yoshizaki, Misa; Takahashi, Tomomi; Hayakawa, Hirofumi; Hirota, Atsushi; Nishizaki, Yukiko; Oka, Natsuki";The Optimum Rate of Mimicry in Human-Agent Interaction;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2980506;https://doi.org/10.1145/2974804.2980506;The importance of building rapport between a human and an agent is increasing with the burgeoning development of robot technology. Several recent studies have focused on the chameleon effect, using psychological concepts to investigate human-agent interaction. However, the validity of the chameleon effect in human-agent interaction is controversial. Few studies have explored the influence of individual cognitive ability and the rate of mimicry on the human-agent interaction. We explored the optimal rate of mimicry and the relationship between mimicry rate and individual empathic ability. We controlled the amount of agent mimicry and examined the effect on participants classified as high- and low-perspective takers. We found that, overall, participants preferred agents that mimicked their behavior 83% of the time. Moreover, high-, but not low-, perspective takers tended to be influenced by the mimicry rate.;2016-10-04;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;367–370;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"human-agent interaction; perspective taking; mimicry; impression of robot; the chameleon effect";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MKE7CXBZ;conferencePaper;2018;"Hieida, Chie; Horii, Takato; Nagai, Takayuki";Decision-Making in Emotion Model;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177048;https://doi.org/10.1145/3173386.3177048;Having emotions is essential for robots to understand and sympathize with the feelings of people. In addition, it may allow the robots to be accepted into human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions based on various neurological and psychological findings that are related to empathic communication between humans and robots is proposed. Subsequently, a mechanism of decision-making that is based on affects using convolutional LSTM and deep Q-network is examined.;2018-03-01;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;127–128;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\UTR3MLNI\Hieida et al. - 2018 - Decision-Making in Emotion Model.pdf;NA;NA;"decision-making; model of emotion; empathic hri";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3L7FR3BN;conferencePaper;2018;Spaulding, Samuel;Personalized Robot Tutors that Learn from Multimodal Data;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.;2018-07-09;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;1781–1783;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\2748W25F\Spaulding - 2018 - Personalized Robot Tutors that Learn from Multimod.pdf;NA;NA;"human-robot interaction; social robotics; multimodal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HTWUJK4G;conferencePaper;2016;"Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka";Sharing Emotion Described as Text on the Internet by Changing Self-physiological Perception;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2974825;https://doi.org/10.1145/2974804.2974825;"Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.";2016-10-04;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;145–153;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HIJWLJTD;conferencePaper;2014;"Iacono, Iolanda; Marti, Patrizia";Engaging older people with participatory design;Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational;978-1-4503-2542-4;NA;10.1145/2639189.2670180;https://doi.org/10.1145/2639189.2670180;We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.;2014-10-26;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;859–864;NA;NA;NA;NA;NA;NA;NordiCHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; participatory design; older people; gaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
T3A6EKVT;conferencePaper;2019;"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania";Ballbit Adventure: A Physical Game for a Collaborative Racing;Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-6871-1;NA;10.1145/3341215.3356982;https://doi.org/10.1145/3341215.3356982;Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.;2019-10-17;2021-02-15T21:20:47Z;2021-02-15T21:20:47Z;2021-02-15T00:00:00Z;97–103;NA;NA;NA;NA;NA;Ballbit Adventure;CHI PLAY '19 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3TCKB9I5;conferencePaper;2015;"Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana";The Empathic Robotic Tutor: Featuring the NAO Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702100;https://doi.org/10.1145/2701973.2702100;We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.;2015-03-02;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;285;NA;NA;NA;NA;NA;The Empathic Robotic Tutor;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"educational robotics; empathic robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZYLA8JJ2;conferencePaper;2016;"Liu, Xin; London, Kati";T.A.I: A Tangible AI Interface to Enhance Human-Artificial Intelligence (AI) Communication Beyond the Screen;Proceedings of the 2016 ACM Conference on Designing Interactive Systems;978-1-4503-4031-1;NA;10.1145/2901790.2901896;https://doi.org/10.1145/2901790.2901896;Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.;2016-06-04;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;281–285;NA;NA;NA;NA;NA;T.A.I;DIS '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective communication; shape-changing interface; social agent; tangible interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4NXJC9PC;conferencePaper;2013;"Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria";3D animated agent for tutoring based on WebGL;Proceedings of the 18th International Conference on 3D Web Technology;978-1-4503-2133-4;NA;10.1145/2466533.2466534;https://doi.org/10.1145/2466533.2466534;"The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.";2013-06-20;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;129–134;NA;NA;NA;NA;NA;NA;Web3D '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"artificial intelligence; e-learning; virtual agents; Web3D technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
FURDLKM6;conferencePaper;2019;Shvo, Maayan;Towards Empathetic Planning and Plan Recognition;Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society;978-1-4503-6324-2;NA;10.1145/3306618.3314307;https://doi.org/10.1145/3306618.3314307;Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants.;2019-01-27;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;525–526;NA;NA;NA;NA;NA;NA;AIES '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"AI planning; plan recognition";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
GZC7HT38;conferencePaper;2019;"Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco";A Preliminary Work on Dog Emotion Recognition;IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume;978-1-4503-6988-6;NA;10.1145/3358695.3361750;https://doi.org/10.1145/3358695.3361750;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.;2019-10-14;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;91–96;NA;NA;NA;NA;NA;NA;WI '19 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CDHCLWXP;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3326596;https://doi.org/10.1145/3311927.3326596;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019-06-12;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;755–760;NA;NA;NA;NA;NA;EmotoTent;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
35PPCNN6;conferencePaper;2019;Aubergé, Véronique;The Socio-Affective Robot: Aimed to Understand Human Links?;Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop;978-1-4503-6913-8;NA;10.1145/3347320.3357687;https://doi.org/10.1145/3347320.3357687;"Is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence, revealing some crucial aspects of social and cultural human processing? Among the smart objects, the social robot cannot be distinguished by precise and well defined technical or morphological cues. Even though no serious and discriminative attributes can be given by any science knowledge -- even the movement attribute, and the ""autonomous'' cognitive attribute are not clearly defined -- in order to understand how an object becomes, perceptively, a subject (social robot), it is a fact that the automatons and the talking artefacts are now named robot, which is particularly attractive for general public, for scientists and engineers. However, is it a socio-cultural desire or a technical need to add the augmentation of the social space to the ""augmented self'' (self body and self environment abilities)? In this talk we will explore some social space perturbations in ecological conditions, such as elderly people suffering from isolation and interacting with a robot that can emit solely non-verbal speech primitives. Long term interactions were collected and analysed using the concepts of the Dynamic Affective Network for Social Entities (D.A.N.S.E.) theory. We will try to show that non-verbal speech primitives, organised in the D.A.N.S.E.'s ""glue'' paradigm, permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance, but also to explore in particular an empathic dimension. Through a Living Lab method, evaluation of these hypotheses and building of an empathic socio-affective HRI were conducted together, within strong ethical constraints. In particular the development of frail robots for frail people will be proposed as possible ethical perspective.";2019-10-15;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1;NA;NA;NA;NA;NA;The Socio-Affective Robot;AVEC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"engagement; frail person; hri; living lab; social robot; socio-affective speech";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XGRSSFNU;journalArticle;2020;"McDonald, Nora; Pan, Shimei";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proceedings of the ACM on Human-Computer Interaction;NA;NA;10.1145/3415218;https://doi.org/10.1145/3415218;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.;2020-10-14;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T21:25:13Z;147:1–147:19;NA;CSCW2;4;NA;Proc. ACM Hum.-Comput. Interact.;Intersectional AI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;October 2020;NA;NA;NA;NA;NA;NA;"artificial intelligence; ethics; algorithm bias; education; intersectionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
G4K2LKQ4;journalArticle;2016;"Katsimerou, Christina; Albeda, Joris; Huldtgren, Alina; Heynderickx, Ingrid; Redi, Judith A.";Crowdsourcing Empathetic Intelligence: The Case of the Annotation of EMMA Database for Emotion and Mood Recognition;ACM Transactions on Intelligent Systems and Technology;NA;2157-6904;10.1145/2897369;https://doi.org/10.1145/2897369;Unobtrusive recognition of the user's mood is an essential capability for affect-adaptive systems. Mood is a subtle, long-term affective state, often misrecognized even by humans. The challenge to train a machine to recognize it from, for example, a video of the user, is significant, and already begins with the lack of ground truth for supervised learning. Existing affective databases consist mainly of short videos, annotated in terms of expressed emotions rather than mood. In very few cases, we encounter perceived mood annotations, of questionable reliability, however, due to the subjectivity of mood estimation and the small number of coders involved. In this work, we introduce a new database for mood recognition from video. Our database contains 180 long, acted videos, depicting typical daily scenarios, and subtle facial and bodily expressions. The videos cover three visual modalities (face, body, Kinect data), and are annotated in terms of emotions (via G-trace) and mood (via the Self-Assessment Manikin and the AffectButton). To annotate the database exhaustively, we exploit crowdsourcing to reach out to an extensive number of nonexpert coders. We validate the reliability of our crowdsourced annotations by (1) adopting a number of criteria to filter out unreliable coders, and (2) comparing the annotations of a subset of our videos with those collected in a controlled lab setting.;2016-05-02;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T21:25:14Z;51:1–51:27;NA;4;7;NA;ACM Trans. Intell. Syst. Technol.;Crowdsourcing Empathetic Intelligence;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;July 2016;NA;NA;NA;NA;NA;NA;"emotion recognition; affective annotation; crowdsourcing; mood recognition; Multimodal database";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
X3WVULUQ;journalArticle;2017;"Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke";Empathy in Virtual Agents and Robots: A Survey;ACM Transactions on Interactive Intelligent Systems;NA;2160-6455;10.1145/2912150;https://doi.org/10.1145/2912150;This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.;2017-09-19;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T21:25:15Z;11:1–11:40;NA;3;7;NA;ACM Trans. Interact. Intell. Syst.;Empathy in Virtual Agents and Robots;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;October 2017;NA;NA;NA;NA;NA;NA;"virtual agents; empathy; affective computing; human-computer interaction; human-robot interaction; social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TI9V22TG;conferencePaper;2018;"Dudzik, Bernd; Hung, Hayley; Neerincx, Mark; Broekens, Joost";Artificial Empathic Memory: Enabling Media Technologies to Better Understand Subjective User Experience;Proceedings of the 2018 Workshop on Understanding Subjective Attributes of Data, with the Focus on Evoked Emotions;978-1-4503-5978-8;NA;10.1145/3267799.3267801;https://doi.org/10.1145/3267799.3267801;An essential part of being an individual is our personal history, in particular our episodic memories. Episodic memories revolve around events that took place in a person's past and are typically defined by a time, place, emotional associations, and other contextual information. They form an important driver for our emotional and cognitive interpretation of what is currently happening. This includes interactions with media technologies. However, current approaches for personalizing interactions with these technologies are neither aware of what episodic memories are triggered in users, nor of their emotional interpretations of those memories. We argue that this is a serious limitation, because it prevents applications from correctly estimating users' experiences. In short, such technologies lack empathy. In this position paper, we argue that media technologies need an Artificial Empathic Memory (AEM) of their users to address this issue. We propose a psychologically inspired architecture, examine the challenges to be solved, and highlight how existing research can become a starting point for overcoming them.;2018-10-15;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–8;NA;NA;NA;NA;NA;Artificial Empathic Memory;EE-USAD'18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective computing; empathic technology; episodic memory; media-evoked emotions; personalization; user modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LXEN89GW;conferencePaper;2013;"Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth";Towards empathic artificial tutors;Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction;978-1-4673-3055-8;NA;NA;NA;In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.;2013-03-03;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;113–114;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;Tokyo, Japan;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JC2UWZKT;conferencePaper;2010;"Saunier, Julien; Jones, Hazael; Lourdeaux, Domitile";Empathy and Placebo for Autonomous Agents;Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 02;978-0-7695-4191-4;NA;10.1109/WI-IAT.2010.255;https://doi.org/10.1109/WI-IAT.2010.255;Computational modeling of emotion, physiology and personality is a major challenge in order to design believable virtual humans. These factors have an impact on both the individual behavior and the collective one. This requires to take into account the empathy phenomenon. Furthermore, in a crisis simulation context where the virtual humans can be contaminated by radiological or chemical substances, empathy may lead to placebo or nocebo effects. Stemming from works in the multi-agent systems (MAS) domain, we consider that a virtual human has two parts, its mind and its body. The agent is influenced by the mind, but controlled by the environment which manages the empathy and nocebo process. We describe these mechanisms and show the results of several experiments.;2010-08-31;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;277–282;NA;NA;NA;NA;NA;NA;WI-IAT '10;NA;NA;NA;IEEE Computer Society;USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Personality; Emotions; Empathy; Multi-agent architecture; Placebo";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XT6MUJQP;conferencePaper;2016;Oduola, Cassandra;Assessing Empathy through Mixed Reality;Companion Publication of the 21st International Conference on Intelligent User Interfaces;978-1-4503-4140-0;NA;10.1145/2876456.2876466;https://doi.org/10.1145/2876456.2876466;"This research seeks to produce a new way of assessing empathy in individuals. The current widely used diagnostic tools are questionnaires. These questionnaires are easy to ""pass"" if the individual simply lies and chooses the answers that would be most beneficial to them. Furthermore, it is shown, assessing empathy is harder in a clinical setting because it is not the natural world, a person may purposely inhibit their behavior to seem more ""normal"". Finding methods that would assess affect while interacting with a computer could yield higher accuracy in diagnosis";2016-03-07;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;142–145;NA;NA;NA;NA;NA;NA;IUI '16 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective computing; virtual reality; mixed reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LYFHZM9H;conferencePaper;2018;"Richards, Deborah; Bilgin, Ayse Aysin; Ranjbartabar, Hedieh";Users' perceptions of empathic dialogue cues: A data-driven approach to provide tailored empathy;Proceedings of the 18th International Conference on Intelligent Virtual Agents;978-1-4503-6013-5;NA;10.1145/3267851.3267857;https://doi.org/10.1145/3267851.3267857;Understanding how and in what circumstances users respond to different verbal expressions of empathy will be important for designing Intelligent Virtual Agents able to influence the emotions and intrinsic motivations of users. We report a study to teach healthy study habits and tips involving 239 undergraduate students, 161 of which interacted with a character designed to express empathy through dialogue. We elicited participants' personality and psychological state (depression, anxiety and stress levels) and attitudes to study. In this paper we present a detailed analysis of participants' responses to specific empathic dialogue snippets designed to include one or more empathic cues to determine whether they found it helpful, stupid or empathic. We provide an example of how we have used data mining on our dataset to suggest which cues are most appropriate to which user types to enhance user models and improve agent decision-making regarding the expression of empathy.;2018-11-05;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;35–42;NA;NA;NA;NA;NA;Users' perceptions of empathic dialogue cues;IVA '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"data mining; empathic dialog; Intelligent Virtual Agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
P8ASJEL5;conferencePaper;2013;"Kim, Hyun-Jun; Choi, Young Sang";A Peak Detection Method for Understanding User States for Empathetic Intelligent Agents;Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 02;978-0-7695-5145-6;NA;10.1109/WI-IAT.2013.118;https://doi.org/10.1109/WI-IAT.2013.118;Recognition of facial expression is a useful and unobtrusive means for machines to understand users' internal states. However, most human facial expression is ambiguous or subtle to recognize resulting in poor accuracy. To overcome this limitation, we propose a peak detection method to select only meaningful images from image sequences which imply significant changes of facial expression by calculating differences between images. We believe this method will alleviate the accuracy degradation caused by different personal appearances and ambiguous facial expressions. When applied to commercial products, it can provides a suitable method for adaptation of the empathetic agent embedded in machines such as personal assistants on TV, smartphone and vehicles based on recognized facial expression of users. For experimental validation of the proposed method, we tested four different features for measuring image similarity with the extended Cohn-Kanade facial image dataset. As a result, we could get better recognition accuracy than the original image sequences. Moreover, we reduced the number of images that need to be recognized to 24.52% without degradation of accuracy.;2013-11-17;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;261–265;NA;NA;NA;NA;NA;NA;WI-IAT '13;NA;NA;NA;IEEE Computer Society;USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Empathetic Agent; Facial Expression; Image Processing; Peak Detection; Temporal Analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HT6ZJW86;conferencePaper;2019;"Urakami, Jacqueline; Moore, Billie Akwa; Sutthithatip, Sujitra; Park, Sung";Users' Perception of Empathic Expressions by an Advanced Intelligent System;Proceedings of the 7th International Conference on Human-Agent Interaction;978-1-4503-6922-0;NA;10.1145/3349537.3351895;https://doi.org/10.1145/3349537.3351895;The goal of this study was to examine user\textquoteright s perception of expressions of empathy by an autonomous system. In a survey eight different components of empathy identified in literature studies and prior tests (Expressing own feelings, Expressing to know what the other feels, Helping, Showing interest, Taking the others perspective, Displaying regard, Situational understanding, and Agreement) were compared to neutral expressions. Differences in participants evaluations were found across the components of empathy as well as individual differences were revealed. Expressions of cognitive empathy (Showing interest, situational understanding) and expressions of empathy of assistance (helping) were perceived positively by participants. However, expressions of affective empathy (expressing own feelings, expressing to know what the other feels) received mainly negative ratings. Cluster analysis revealed individual differences especially for items relating to affective empathy. Whereas one group of participants identified in the cluster analysis rated expressions of affective empathy negatively, a second group of participants rated these expressions positively. Furthermore, large differences across participants also existed for taking the other's perspective, a component of cognitive empathy. Integrating expressions of empathy in human-machine interaction is a sensitive issue and designers must carefully choose what components of empathy are adequate depending on the situational circumstances and the targeted user group.;2019-09-25;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;11–18;NA;NA;NA;NA;NA;NA;HAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; autonomous intelligent system; survey";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U2ZY979B;conferencePaper;2014;"Villarica, Ryan; Richards, Deborah";Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds;Proceedings of the 2014 Conference on Interactive Entertainment;978-1-4503-2790-9;NA;10.1145/2677758.2677761;https://doi.org/10.1145/2677758.2677761;"Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.";2014-12-02;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–9;NA;NA;NA;NA;NA;NA;IE2014;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Empathic Agents; Omosa; Virtual Learning Environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
M25V9VBT;conferencePaper;2010;"Evers, Vanessa; Kröse, Ben";Toward an ambient empathic health companion for self care in the intelligent home;Proceedings of the 28th Annual European Conference on Cognitive Ergonomics;978-1-60558-946-6;NA;10.1145/1962300.1962387;https://doi.org/10.1145/1962300.1962387;Motivation--This paper describes our work in progress to develop a personal monitoring system that can monitor the physical and emotional condition of a patient by using contextual information from a sensor network, provide the patient with feedback concerning their health status and motivate the patient to adopt behavior with a positive health impact (such as exercising or taking medication at the right moment). Research approach -- We will extend the capabilities of an existing robotic health buddy with a (DBN based) sensor network. Then we will carry out a series of controlled, long-term field experiments where we identify and evaluate the effects of various agent social communicative behaviours on the user's adoption of health improving lifestyle patterns. Findings/Design -- The findings of the experiments will inform the final design of the health buddy and it's behaviours. We will also realise system adaptivity of the data processing and data fusion methods as well as the health buddy adaptivity to the user's emotional state. Research limitations/Implications -- The project will limit itself to monitoring and motivating people who suffer from cardiovascular chronic conditions and to the home environment. Originality/Value -- The research makes a contribution to the needs of health monitoring for a specific user group. The health buddy will use social behaviours to motivate users over a long-term time period. Take away message -- Home health monitoring and self care can be more enjoyable and easier through motivating smart health buddies.;2010-08-25;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;365–366;NA;NA;NA;NA;NA;NA;ECCE '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective technology; embodied social agent; health buddy; sensor networks for health monitoring";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QHYA7364;conferencePaper;2020;"Yao, Heng; de Siqueira, Alexandre Gomes; Foster, Adriana; Galynker, Igor; Lok, Benjamin";Toward Automated Evaluation of Empathetic Responses in Virtual Human Interaction Systems for Mental Health Scenarios;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423916;https://doi.org/10.1145/3383652.3423916;This paper investigates the process of automating the evaluation of empathetic response levels in virtual human interaction systems implementing mental health scenarios. Two suicidal virtual patients were developed to collect clinician participants' empathetic responses. Before collecting clinicians' responses, we tested the virtual human interaction with healthcare trainees. Trainees' empathetic responses were evaluated by experts to use the ECCS scale based on the ECCS level (Empathetic Communication Coding System). We trained classifiers using trainees' empathetic responses with experts' coded empathy levels as the training dataset. Clinician participants' empathetic responses to virtual patients were evaluated by experts and the classifiers. The performance of the classifiers was evaluated using the experts' coded level of clinicians' empathetic responses as a test dataset. This work demonstrates the applicability of using virtual agents techniques to identify empathy levels of clinicians' responses automatically. This work shows the potential of using virtual human interaction to train clinicians' skills to show empathy. Corresponding feedback could be provided to clinicians based on the evaluation results. We hope this study motivates more research in using intelligent virtual agents in personal skills training in education.;2020-10-20;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–8;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"automated evaluation; empathetic response; suicidal virtual patient";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WP9WJNWN;conferencePaper;2014;Billinghurst, Mark;Using augmented reality to create empathic experiences;Proceedings of the 19th international conference on Intelligent User Interfaces;978-1-4503-2184-6;NA;10.1145/2557500.2568057;https://doi.org/10.1145/2557500.2568057;Intelligent user interfaces have traditionally been used to create systems that respond intelligently to user input. However there is a recent trend towards Empathic Interfaces that are designed to go beyond understanding user input and to recognize emotional state and user feelings. In this presentation we explore how Augmented Reality (AR) can be used to convey that emotional state and so allow users to capture and share emotional experiences. In this way AR not only overlays virtual imagery on the real world, but also can create deeper understanding of user's experience at particular locations and points in time. The recent emergence of truly wearable systems, such as Google Glass, provide a platform for Empathic Communication using AR. Examples will be shown from research conducted at the HIT Lab NZ and other research organizations, and key areas for future research described.;2014-02-24;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;5–6;NA;NA;NA;NA;NA;NA;IUI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"augmented reality; collaboration; empathic computing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
T3E2ZU7S;conferencePaper;2020;"Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423864;https://doi.org/10.1145/3383652.3423864;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).;2020-10-20;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–3;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; conversational agent; emotion detection; healthcare computing; pattern matching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BSC43SS7;conferencePaper;2019;"Tahara, Shunichi; Ikeda, Kazushi; Hoashi, Keiichiro";Empathic dialogue system based on emotions extracted from tweets;Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3302281;https://doi.org/10.1145/3301275.3302281;Empathic conversations have increasingly been important for dialogue systems to improve the users' experience, and increase their engagement with the system, which is difficult for many existing monotonous systems. Existing empathic dialogue systems are designed for limited domain dialogues. They respond fixed phrases toward observed user emotions. In open domain conversations, however, generating empathic responses for a wide variety of topics is required. In this paper, we draw on psychological studies about empathy, and propose an empathic dialogue system in open domain conversations. The proposed system generates empathic utterances based on observed emotions in user utterances, thus is able to build empathy with users. Our experiments have proven that users were able to feel more empathy from the proposed system, especially when their emotions were explicitly expressed in their utterances.;2019-03-17;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;52–56;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; dialogue system; social networking service";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
S6SL9SJT;conferencePaper;2020;"Samrose, Samiha; Anbarasu, Kavya; Joshi, Ajjen; Mishra, Taniya";Mitigating Boredom Using An Empathetic Conversational Agent;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423905;https://doi.org/10.1145/3383652.3423905;In spite of their ubiquity, our interactions with contemporary conversational agents (CA), such as Alexa, are still transactional in nature and lack the expressiveness of human-human communication. Conversational agents equipped with the ability to detect and address users' emotional and cognitive states could make our interactions with them more human. In this work, we investigate whether an empathetic CA can help mitigate boredom. We design a protocol in order to first elicit boredom in users, and explore strategies that attempt to mitigate their boredom with the help of two conversational agents, an empathetic agent and a non-empathetic agent, administered in a Wizard-of-Oz setting. We quantify their efficacy by measuring the effects on user mood and task performance. Our user study with 34 participants shows that the empathetic CA outperforms the non-empathetic CA with respect to modulating users' mood and performance.;2020-10-20;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–8;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Conversational Agent; Empathetic Agent; Boredom Mitigation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UQHZ6UFI;conferencePaper;2019;"Dupuy, Lucile; De Sevin, Etienne; Ballot, Orlane; Cassoudesalle, Hélène; Dehail, Patrick; Aouizerate, Bruno; Cuny, Emmanuel; Micoulaud-Franchi, Jean-Arthur; Philip, Pierre";A Virtual Patient to Train Semiology Extraction and Empathic Communication Skills for Psychiatric Interview;Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents;978-1-4503-6672-4;NA;10.1145/3308532.3329429;https://doi.org/10.1145/3308532.3329429;Psychiatric diagnostic relies on physician's ability to create an empathic interaction with the patient (i.e., engage the patient in the conversation with empathic sentences, while keeping an emotional distance) in order to accurately extract semiology (i.e., clinical manifestations). Virtual patients (VPs) offer new ways to train these skills but need to be validated in terms of accuracy to measure the skills of interest, and be perceived positively by its users. We recruited 34 medicine students, who interacted with a VP suffering from depressive disorders. Results suggest good abilities for the students to use empathic sentences to communicate with the VP, but results varied regarding semiology extraction, students having a specialty in psychiatry performing better than their counterparts. Additionally, results suggest that students managed to keep an emotional distance during the interaction with the VP, but they let their emotions out when answering semiology questions. Positive feedbacks and limitations raised by students during debriefing interviews provide suggestions for improvements and ideas for future works.;2019-07-01;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;188–190;NA;NA;NA;NA;NA;NA;IVA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"user experience; emotion detection; empathic communication skills; medical training; psychiatric interview; semiology; virtual patient";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZMXEKEHG;conferencePaper;2019;Zhou, Michelle X.;"Getting virtually personal: making responsible and empathetic ""her"" for everyone";Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3308445;https://doi.org/10.1145/3301275.3308445;Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world. Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent. I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.;2019-03-17;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;i;NA;NA;NA;NA;NA;Getting virtually personal;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\I73SJB6H\Zhou - 2019 - Getting virtually personal making responsible and.pdf;NA;NA;"computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
38D2Y6XP;conferencePaper;2016;"Feigenblat, Guy; Konopnicki, David; Shmueli-Scheuer, Michal; Herzig, Jonathan; Shkedi, Hen";I Understand Your Frustration;Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion;978-1-4503-3950-6;NA;10.1145/2818052.2874316;https://doi.org/10.1145/2818052.2874316;The use of emotional intelligence in a conversation has a significant positive effect on customer satisfaction and can help resolve difficult conflicts. Many enterprises use virtual agents that automatically interact with customers across a variety of interaction channels. However, these agents have no emotional intelligence and cannot express themselves in an empathic manner. This demo demonstrates the use of emotional intelligence in a technical conversation with a customer. The agent is augmented with emotion sensing capabilities, which allow him to detect expressed emotions, and reply in an appropriate manner by expressing empathy, for example.;2016-02-27;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;25–28;NA;NA;NA;NA;NA;NA;CSCW '16 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Emotions; Affective computing; Conversation; Dialog; Virtual agent";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3TYWMTNW;conferencePaper;2019;Davis, Claudia E.;Enhancing emotional intelligence in project management: strategies for better outcomes and community with limited financial overhead;ACM SIGGRAPH 2019 Talks;978-1-4503-6317-4;NA;10.1145/3306307.3328190;https://doi.org/10.1145/3306307.3328190;"During the SIGGRAPH 2018 BOF ""Emphasizing Empathy in Pipeline Project Management,"" group consensus stated that highly effective project management can only be achieved when emphasis is placed on demonstrated empathy for any and all project contributors at the project management level and when challenges are framed as opportunities to enhance both the team and the project manager's own emotional intelligence. The reality faced in the industry, however, can present unique challenges, specifically relating to toxic cultural folkways, lack of leadership support, and lack of designated monetary resources. Based on subsequent discussions borne from the initial presentation with industry professionals and team leaders, it seems imperative to address not only the theories of Emotional Intelligence in greater depth, but also to acknowledge the potential obstacles in applying this basic theory in the real world. This talk aims to illuminate opportunities for individual production professionals to both challenge their own perceptions of the industry culture and make effective changes pertaining to their management and communication styles to affect positive change in their work environment, increase employee morale, and build community, barring financial allotment, to the overall benefit of their team members and their project health.";2019-07-28;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–2;NA;NA;NA;NA;NA;Enhancing emotional intelligence in project management;SIGGRAPH '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"advocacy; community building; development; emotional intelligence; empathy; pipeline; professional development; project management; work-life balance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4CVY9DJX;bookSection;2020;Davis, Claudia E.;Making time for Emotional Intelligence in Production and Technology;ACM SIGGRAPH 2020 Talks;978-1-4503-7971-7;NA;NA;https://doi.org/10.1145/3388767.3407362;During the SIGGRAPH 2018 BOF ”Emphasizing Empathy in Pipeline Project Management,” group consensus stated that highly effective project management can only be achieved when emphasis is placed on demonstrated empathy for any and all project contributors at the project management level and when challenges are framed as opportunities to enhance both the team and the project manager’s own emotional intelligence. The reality faced in the industry, however, can present unique challenges, specifically relating to toxic cultural folkways, lack of leadership support, and lack of designated monetary resources. Based on subsequent discussions borne from the initial presentation with industry professionals and team leaders, it seems imperative to address not only the theories of Emotional Intelligence in greater depth, but also to acknowledge the potential obstacles in applying this basic theory in the real world specifically regarding the operational changes introduced to the working environment due to COVID-19 and current world events. A specific concern to address is that middle-tier management, for whom budget allocation is given and not guaranteed – want to improve their team environment, they are often not granted a financial allotment to do so most effectively for their specific teams. This talk aims to illuminate opportunities for individual production professionals to make effective changes pertaining to their management and communication styles to affect positive change in their work environment, increase employee morale, and build community, barring financial allotment, to the overall benefit of their team members and their project health.;2020-08-17;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–2;NA;NA;NA;NA;NA;NA;NA;10;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"advocacy; community building; development; emotional intelligence; empathy; pipeline; professional development; project management; work-life balance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U6NJUNEV;conferencePaper;2020;"Sankaran, Supraja; Zhang, Chao; Funk, Mathias; Aarts, Henk; Markopoulos, Panos";Do I have a say? Using conversational agents to re-imagine human-machine autonomy;Proceedings of the 2nd Conference on Conversational User Interfaces;978-1-4503-7544-3;NA;10.1145/3405755.3406135;https://doi.org/10.1145/3405755.3406135;With human-centered AI gaining traction, needs for algorithmic transparency, explainability, empathy and ethical considerations in artificial agents are forming core research issues. However, with intelligent agents getting increasingly independent and human-like, there is an increase in perceived threat to human autonomy. Will this perceived threat eventually become an actual threat where humans lose control over their own goals, decisions and actions? With this provocation paper, we want to urge researchers working on human-agent interactions and conversational agents (CAs) to explicitly consider the impact of intelligent agents on human autonomy. We present arguments and highlight the critical need to focus on human autonomy when interacting with CAs by presenting some core research considerations.;2020-07-22;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–3;NA;NA;NA;NA;NA;Do I have a say?;CUI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"conversational agents; human autonomy; human-agent interactions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KG77P9VK;conferencePaper;2019;Davis, Jr., Mark;How's your EQ? - Let's find out!;Proceedings of the 2019 ACM SIGUCCS Annual Conference;978-1-4503-5774-6;NA;10.1145/3347709.3347770;https://doi.org/10.1145/3347709.3347770;Do you understand the role your emotions play in how you see yourself and others? What role does Emotional Intelligence (EQ) play in successful leadership? How does EQ affect DEI (Diversity, Equity and Inclusion)? How much of an impact does emotional intelligence really have on your professional success and the relationships you build? The short answer: a lot! This interactive discussion will help us identify and assess our abilities in each of the EQ quadrants of self-awareness, self-regulation, empathy and social awareness. We will also discuss methods and strategies to help us embrace EQ at all levels and identify the influence it can have on creating a more Diverse, Equitable and Inclusive community.;2019-10-26;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;87–88;NA;NA;NA;NA;NA;How's your EQ?;SIGUCCS '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Empathy; Diversity Equity and inclusion; Emotional Intelligence; EQ Leadership; Self-Awareness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RIGNTCMX;conferencePaper;2018;"Hosseinpanah, Adineh; Krämer, Nicole C.; Straßmann, Carolin";Empathy for Everyone? The Effect of Age When Evaluating a Virtual Agent;Proceedings of the 6th International Conference on Human-Agent Interaction;978-1-4503-5953-5;NA;10.1145/3284432.3284442;https://doi.org/10.1145/3284432.3284442;The present study investigated the role of age in the perception of emotional nonverbal behaviors of a virtual assistant in a 2 (seniors vs young participants) x 2 (happy vs sad situations) x 4 (three emotional nonverbal behaviors related to each situation vs neutral behavior) mixed factorial design. In the study, a virtual agent acted as an assistant to review the imaginary monthly schedule of the participant. After uttering each schedule, the agent showed different emotional nonverbal behaviors to express empathy. The stimulus materials were presented to 60 participants (30 elderly people and 30 younger adults) in 25 videos. All participants had to rate the agent's friendliness, intelligence, empathy, trustworthiness, and helpfulness immediately after watching each video. The results indicated that in the presence of the emotional nonverbal behaviors the elderly rated the agent as more empathic and trustworthy compared to the younger adults. The data also revealed that there were differences with respect to rating specific emotional nonverbal behaviors as more empathic than others. Elderly people perceived Dropping the Arms plus Sad Face, Head down, Sad Face, Head Nod plus Smile, and Smile as more empathic, and the nonverbal behaviors perceived as most empathic for the younger adults were Dropping the Arms plus Sad Face, and Head down.;2018-12-04;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;184–190;NA;NA;NA;NA;NA;Empathy for Everyone?;HAI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; human-agent interaction; nonverbal-behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YX64TSYG;conferencePaper;2014;"Gonzalez-Sanchez, Javier; Chavez-Echeagaray, Maria E.; Atkinson, Robert K.; Burleson, Winslow";Multimodal detection of affective states: a roadmap through diverse technologies;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2567820;https://doi.org/10.1145/2559206.2567820;One important way for systems to adapt to their individual users is related to their ability to show empathy. Being empathetic implies that the computer is able to recognize a user's affective states and understand the implication of those states. Detection of affective states is a step forward to provide machines with the necessary intelligence to appropriately interact with humans. This course provides a description and demonstration of tools and methodologies for automatically detecting affective states with a multimodal approach.;2014-04-26;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1023–1024;NA;NA;NA;NA;NA;Multimodal detection of affective states;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affect-driven adaptation; affective states; emotion recognition; multimodal; sensors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MVHGIDH8;conferencePaper;2020;"Spitale, Micol; Garzotto, Franca";Towards Empathic Conversational Interaction;Proceedings of the 2nd Conference on Conversational User Interfaces;978-1-4503-7544-3;NA;10.1145/3405755.3406146;https://doi.org/10.1145/3405755.3406146;"In recent years, ""computational empathy"" has emerged as a new challenging research field. Computational empathy investigates how artificial agents can manifest empathic behaviours towards the user, and how they can elicit empathy during the human-agent interaction. Such ""empathic agents"" have the capacity to place themselves into the emotional position of a user (or another agent), and behave taking such emotional understanding into account. The paper explores a computational empathy approach in the context of conversational interaction, and presents an empathic conversational framework grounded on the empathy theory. The framework provides a conceptual tool for designing and evaluating empathic conversational agents. Overall, our research contributes to a deeper understanding of the role of empathy in conversational interaction.";2020-07-22;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–4;NA;NA;NA;NA;NA;NA;CUI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Empathy; Artificial Agents; Computational Empathy; Conversational Interaction; Framework";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LZTDQ55F;conferencePaper;2018;"Diallo, Saikou Y.; Lynch, Christopher J.; Rechowicz, Krzysztof J.; Zacharewicz, Gregory";How to create empathy and understanding: narrative analytics in agent-based modeling;Proceedings of the 2018 Winter Simulation Conference;NA;NA;NA;NA;In this paper we propose a different approach for interacting and analyzing agent-based models. The approach relies on creating empathy and understanding between physical agents in the physical world (people) and artificial agents in the simulated world (simulated agents). We propose a simulated empathy framework (SEF) in which artificial agents communicate directly with physical agents through verbal channels and social media. We argue that artificial agents should focus on the communication aspects between these two worlds, the ability to tell their story in a compelling way, and to read between the lines of physical agents speech. We present an implementation of the SEF and discuss challenges associated with implementing the framework in an artificial society.;2018-12-09;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1286–1297;NA;NA;NA;NA;NA;How to create empathy and understanding;WSC '18;NA;NA;NA;IEEE Press;Gothenburg, Sweden;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6DWJ7UCP;conferencePaper;2010;"van den Broek, Egon L.; Nijholt, Anton; Westerink, Joyce H. D. M.";Unveiling affective signals;Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research;978-1-60558-926-8;NA;10.1145/1931344.1931350;https://doi.org/10.1145/1931344.1931350;The ability to process and, subsequently, understand affective signals is the core of emotional intelligence and empathy. However, more than a decade of research in affective computing has shown that it is hard to develop computational models of this process. We pose that the solution for this problem lays in a better understanding of how to process these affective signals. This article introduces a symposium that brought together various approaches towards unveiling affective signals. As such, it is envisioned to be a springboard for affective computing.;2010-08-24;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–4;NA;NA;NA;NA;NA;NA;MB '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotion; methods; affective computing; affect; pattern recognition; signal processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JAUXUDRW;conferencePaper;2020;Narayanan, Shrikanth Shri;Human-centered Multimodal Machine Intelligence;Proceedings of the 2020 International Conference on Multimodal Interaction;978-1-4503-7581-8;NA;10.1145/3382507.3417974;https://doi.org/10.1145/3382507.3417974;Multimodal machine intelligence offers enormous possibilities for helping understand the human condition and in creating technologies to support and enhance human experiences [1, 2]. What makes such approaches and systems exciting is the promise they hold for adaptation and personalization in the presence of the rich and vast inherent heterogeneity, variety and diversity within and across people. Multimodal engineering approaches can help analyze human trait (e.g., age), state (e.g., emotion), and behavior dynamics (e.g., interaction synchrony) objectively, and at scale. Machine intelligence could also help detect and analyze deviation in patterns from what is deemed typical. These techniques in turn can assist, facilitate or enhance decision making by humans, and by autonomous systems. Realizing such a promise requires addressing two major lines of, oft intertwined, challenges: creating inclusive technologies that work for everyone while enabling tools that can illuminate the source of variability or difference of interest. This talk will highlight some of these possibilities and opportunities through examples drawn from two specific domains. The first relates to advancing health informatics in behavioral and mental health [3, 4]. With over 10% of the world's population affected, and with clinical research and practice heavily dependent on (relatively scarce) human expertise in diagnosing, managing and treating the condition, engineering opportunities in offering access and tools to support care at scale are immense. For example, in determining whether a child is on the Autism spectrum, a clinician would engage and observe a child in a series of interactive activities, targeting relevant cognitive, communicative and socio- emotional aspects, and codify specific patterns of interest e.g., typicality of vocal intonation, facial expressions, joint attention behavior. Machine intelligence driven processing of speech, language, visual and physiological data, and combining them with other forms of clinical data, enable novel and objective ways of supporting and scaling up these diagnostics. Likewise, multimodal systems can automate the analysis of a psychotherapy session, including computing treatment quality-assurance measures e.g., rating a therapist's expressed empathy. These technology possibilities can go beyond the traditional realm of clinics, directly to patients in their natural settings. For example, remote multimodal sensing of biobehavioral cues can enable new ways for screening and tracking behaviors (e.g., stress in workplace) and progress to treatment (e.g., for depression), and offer just in time support. The second example is drawn from the world of media. Media are created by humans and for humans to tell stories. They cover an amazing range of domains'from the arts and entertainment to news, education and commerce and in staggering volume. Machine intelligence tools can help analyze media and measure their impact on individuals and society. This includes offering objective insights into diversity and inclusion in media representations through robustly characterizing media portrayals from an intersectional perspective along relevant dimensions of inclusion: gender, race, gender, age, ability and other attributes, and in creating tools to support change [5,6]. Again this underscores the twin technology requirements: to perform equally well in characterizing individuals regardless of the dimensions of the variability, and use those inclusive technologies to shine light on and create tools to support diversity and inclusion.;2020-10-21;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;4–5;NA;NA;NA;NA;NA;NA;ICMI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotion; behavior; computational psychology; diversity and inclusion; human signals; language; media intelligence; mental health; speech";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
49WYJII3;conferencePaper;2019;"Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad";Multimodal Learning for Identifying Opportunities for Empathetic Responses;2019 International Conference on Multimodal Interaction;978-1-4503-6860-5;NA;10.1145/3340555.3353750;https://doi.org/10.1145/3340555.3353750;Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.;2019-10-14;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;95–104;NA;NA;NA;NA;NA;NA;ICMI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"machine learning; empathy; human behavior; multimodal sentiment; virtual human";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
V56D27QB;conferencePaper;2020;"Svanæs, Dag; Barkhuus, Louise";The Designer's Body as Resource in Design: Exploring Combinations of Point-of-view and Tense;Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6708-0;NA;10.1145/3313831.3376430;https://doi.org/10.1145/3313831.3376430;"The design of wearable, tangible and embedded interactive products requires a focus on bodily/kinesthetic aspects of the user experience, that is, how the product ""feels"" in use. Although best practice in user-centered design (such as iterative design, prototyping, user testing) also applies for this new type of product, the designer's skill set needs to be supplemented with design methods and practices that utilize bodily intelligence and empathy with the user. We present a framework for categorizing such body-centered design practices based on two dimensions: point-of-view (1st, 2nd, 3rd person) and tense (past, present, future). Inspired by Merleau-Ponty's phenomenology of the body, Shusterman's work on somaesthetics, and Buber's theories on intersubjectivity, the framework provides a language for talking about different ways designers and co-designers can utilize their body as a design resource. The intention is not to be prescriptive on method, but to provide guidance during planning, execution and analysis.";2020-04-21;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–13;NA;NA;NA;NA;NA;The Designer's Body as Resource in Design;CHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"body-centered design; design process; designer training; phenomenology; somaesthetics; user experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7R7NDIEJ;conferencePaper;2018;Fitzpatrick, Geraldine;Designing For Intelligence: Intelligence For Designing;Proceedings of the 4th International Conference on Human-Computer Interaction and User Experience in Indonesia, CHIuXiD '18;978-1-4503-6429-4;NA;10.1145/3205946.3205961;https://doi.org/10.1145/3205946.3205961;Intelligent technology is increasingly entangled in every aspect of our lives. As the designers/builders of these technologies, we wield considerable power, as is rightly being publicly scrutinized in recent debates around biased algorithms and (mis)use of social media data. Designing for intelligence is not just designing technology per se but designing ways of being human and negotiating complex choices. To do this well, engineering and design skills are not enough. We need better social, emotional, and existential intelligences to be critically reflective and empathic practitioners, able to negotiate contended values, engage with diverse user groups and stakeholders, and bring a values-based ethical lens to the choices we make.;2018-03-23;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;97–100;NA;NA;NA;NA;NA;Designing For Intelligence;CHIuXiD '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Existential intelligence; Social emotional intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QXMU8Q3M;journalArticle;2018;"Powell, Loreen; Hendon, Michalina";The need for an emotional intelligence for information technology course: framework for educators and academic institutions;Journal of Computing Sciences in Colleges;NA;1937-4771;NA;NA;Information Technology (IT) professionals are tasked with problem solving and educating the user on the solution at hand as well as assisting the organization with the correct use of technology to optimize business practices. The manner in which an IT professional communicates their knowledge and instructions for problem solving can be stifled through insufficient interpersonal skills. Currently, IT professionals use main sources of communication, such as email or a management system software tool, in which sufficient time can be taken to craft messages. However, when adequate time is not available to think about a response or read between the lines of a client's problem, the IT professional may find it challenging to communicate with empathy of the client's perspective, which can detract from the collaboration or problem-solving goal of the conversation. As such, organizations report that there is a vital need for IT students to understand and rely upon positive emotion intelligence (EI) to intergrade the interpersonal skills that allow the professional to be both a problem-solver and effective communicator. However, there is limited or nonexistent literature on the EI for IT courses, skills, and assessments. This research investigated current and past the employment needs by examining online IT job advertisements within the United States. Results revealed several key EI skills sought by IT employers. Based upon these results, a solid framework in support of an EI for IT course is offered. This research provides a solid framework for educators and higher education institutions to consider an emotional technology course within the IT curriculum.;2018-01-01;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;NA;72;NA;3;33;NA;J. Comput. Sci. Coll.;The need for an emotional intelligence for information technology course;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;January 2018;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QDA3SZRS;journalArticle;2018;"Cotler, Jami L.; Cusack, Matthew";Leveraging emotional intelligence (soft skills) to maximize career success for computer science students;Journal of Computing Sciences in Colleges;NA;1937-4771;NA;NA;With an industry focus on agile development practices, a premium has been put on communication and teamwork skills [21]. Software developers in the tech space will often need to interact with other developers, UX professionals, software testers, and perhaps even culturally diverse customers and clients. The capacity of professionals in this space need to meet customer expectations in a very competitive market centers around the ability of individuals to not only work collectively and as seamlessly as possible, but to also create synergies with a diverse group of professional colleagues. Individuals that have experience working in teams to accomplish goals tend to be more productive in meeting deliverables on agile software development projects [22]. Moreover, companies such as Google, Zappos, and Amazon, are using assessments of soft skills (or emotional intelligence) during the job search process to vet candidates [14]. Furthermore, Dr. Joseph Homan, former Chief Operating Officer at ZekiahTech in Maryland, tests for soft skills extensively when interviewing a new technical candidate and stated that he has noted that candidates with fewer soft skills are often perceived as having lower technical skills (personal communication, November 14, 2014). Another area where EI skills such as awareness of others and empathy is essential is in user experience. Being able to understand the user that technology is being designed for is vital to the ultimate success of the product. Based on these findings, a solid argument is made for the importance of teaching EI to Computer Science students at the undergraduate level.;2018-06-01;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;NA;148–153;NA;6;33;NA;J. Comput. Sci. Coll.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;June 2018;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L97BL5EQ;conferencePaper;2010;Regazzoni, Carlo S.;Emphatic human interaction analysis for cognitive environments;Proceedings of the first ACM international workshop on Analysis and retrieval of tracked events and motion in imagery streams;978-1-4503-0163-3;NA;10.1145/1877868.1877870;https://doi.org/10.1145/1877868.1877870;"Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment. Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available. Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation. Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world. Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it). Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.";2010-10-29;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;1–2;NA;NA;NA;NA;NA;NA;ARTEMIS '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"ambient intelligence; cognitive surveillance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NSWA8FQ9;conferencePaper;2010;"Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Castellano, Ginevra; Martinho, Carlos; Prada, Rui; Paiva, Ana";Closing the loop: from affect recognition to empathic interaction;Proceedings of the 3rd international workshop on Affective interaction in natural environments;978-1-4503-0170-1;NA;10.1145/1877826.1877839;https://doi.org/10.1145/1877826.1877839;Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.;2010-10-29;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;43–48;NA;NA;NA;NA;NA;Closing the loop;AFFINE '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; affect recognition; artificial companions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5IQPLR8J;journalArticle;2012;"Dinakar, Karthik; Jones, Birago; Havasi, Catherine; Lieberman, Henry; Picard, Rosalind";Common Sense Reasoning for Detection, Prevention, and Mitigation of Cyberbullying;ACM Transactions on Interactive Intelligent Systems;NA;2160-6455;10.1145/2362394.2362400;https://doi.org/10.1145/2362394.2362400;Cyberbullying (harassment on social networks) is widely recognized as a serious social problem, especially for adolescents. It is as much a threat to the viability of online social networks for youth today as spam once was to email in the early days of the Internet. Current work to tackle this problem has involved social and psychological studies on its prevalence as well as its negative effects on adolescents. While true solutions rest on teaching youth to have healthy personal relationships, few have considered innovative design of social network software as a tool for mitigating this problem. Mitigating cyberbullying involves two key components: robust techniques for effective detection and reflective user interfaces that encourage users to reflect upon their behavior and their choices. Spam filters have been successful by applying statistical approaches like Bayesian networks and hidden Markov models. They can, like Google’s GMail, aggregate human spam judgments because spam is sent nearly identically to many people. Bullying is more personalized, varied, and contextual. In this work, we present an approach for bullying detection based on state-of-the-art natural language processing and a common sense knowledge base, which permits recognition over a broad spectrum of topics in everyday life. We analyze a more narrow range of particular subject matter associated with bullying (e.g. appearance, intelligence, racial and ethnic slurs, social acceptance, and rejection), and construct BullySpace, a common sense knowledge base that encodes particular knowledge about bullying situations. We then perform joint reasoning with common sense knowledge about a wide range of everyday life topics. We analyze messages using our novel AnalogySpace common sense reasoning technique. We also take into account social network analysis and other factors. We evaluate the model on real-world instances that have been reported by users on Formspring, a social networking website that is popular with teenagers. On the intervention side, we explore a set of reflective user-interaction paradigms with the goal of promoting empathy among social network participants. We propose an “air traffic control”-like dashboard, which alerts moderators to large-scale outbreaks that appear to be escalating or spreading and helps them prioritize the current deluge of user complaints. For potential victims, we provide educational material that informs them about how to cope with the situation, and connects them with emotional support from others. A user evaluation shows that in-context, targeted, and dynamic help during cyberbullying situations fosters end-user reflection that promotes better coping strategies.;2012-09-01;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T21:25:55Z;18:1–18:30;NA;3;2;NA;ACM Trans. Interact. Intell. Syst.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;September 2012;NA;NA;NA;C:\Users\esben\Zotero\storage\X3V25YDG\Dinakar et al. - 2012 - Common Sense Reasoning for Detection, Prevention, .pdf;NA;NA;"artificial intelligence; affective computing; Common sense reasoning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TCAHZRLJ;journalArticle;2020;"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung";The Design and Implementation of XiaoIce, an Empathetic Social                     Chatbot;Computational Linguistics;NA;0891-2017;10.1162/coli_a_00368;https://doi.org/10.1162/coli_a_00368;This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.;2020-03-01;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T21:25:56Z;53–93;NA;1;46;NA;Comput. Linguist.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2020;NA;NA;NA;C:\Users\esben\Zotero\storage\PFU6QFLG\Zhou et al. - 2020 - The Design and Implementation of XiaoIce, an Empat.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3HX9WSXE;conferencePaper;2014;"Regenbrecht, H.; Müller, L.; Hoermann, S.; Langlotz, T.; Wagner, M.; Billinghurst, M.";Eye-to-eye contact for life-sized videoconferencing;Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: the Future of Design;978-1-4503-0653-9;NA;10.1145/2686612.2686632;https://doi.org/10.1145/2686612.2686632;Videoconferencing systems available for end users do not allow for eye-to-eye contact between participants. The different locations of video camera and video display make it impossible to directly look into each others eyes. This issue is known as the lack of mutual gaze. Combined with a lack of a life-sized video image of the communication partner videoconferencing becomes an artificial experience leading to decreased communication quality, empathy and trust. In this work, we present life-sized videoconferencing solution supporting mutual gaze and report on the experiences made with our system in empirical evaluations.;2014-12-02;2021-02-15T21:25:58Z;2021-02-15T21:25:58Z;2021-02-15T00:00:00Z;145–148;NA;NA;NA;NA;NA;NA;OzCHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"eye contact; mutual gaze; trust; videoconferencing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BXZLQU8P;conferencePaper;2017;"Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin";Beyond cute: exploring user types and design opportunities of virtual reality pet games;Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology;978-1-4503-5548-3;NA;10.1145/3139131.3139132;https://doi.org/10.1145/3139131.3139132;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.;2017-11-08;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1–10;NA;NA;NA;NA;NA;Beyond cute;VRST '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\BRY6FR4G\Lin et al. - 2017 - Beyond cute exploring user types and design oppor.pdf;NA;NA;"pet game; user types; virtual pet; virtual reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JZL7ELKK;conferencePaper;2019;"Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios";Smart, personalized and adaptive ICT solutions for active, healthy and productive ageing with enhanced workability;Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments;978-1-4503-6232-0;NA;10.1145/3316782.3322767;https://doi.org/10.1145/3316782.3322767;"Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""[email protected]"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.";2019-06-05;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;442–447;NA;NA;NA;NA;NA;NA;PETRA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\QEIESJJR\Giakoumis et al. - 2019 - Smart, personalized and adaptive ICT solutions for.pdf;NA;NA;"age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CQK2W4UG;journalArticle;2012;"Beck, Aryel; Stevens, Brett; Bard, Kim A.; Cañamero, Lola";Emotional body language displayed by artificial agents;ACM Transactions on Interactive Intelligent Systems;NA;2160-6455;10.1145/2133366.2133368;https://doi.org/10.1145/2133366.2133368;Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots.;2012-03-20;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T21:26:21Z;2:1–2:29;NA;1;2;NA;ACM Trans. Interact. Intell. Syst.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2012;NA;NA;NA;C:\Users\esben\Zotero\storage\SL26BPL9\Beck et al. - 2012 - Emotional body language displayed by artificial ag.pdf;NA;NA;"emotional body language; Human computer interactions; human robot interactions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BM6J97LK;bookSection;2020;"Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph";Reputation Agent: Prompting Fair Reviews in Gig Markets;Proceedings of The Web Conference 2020;978-1-4503-7023-3;NA;NA;https://doi.org/10.1145/3366423.3380199;"Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.";2020-04-20;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1228–1240;NA;NA;NA;NA;NA;Reputation Agent;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AVHJZR7V;conferencePaper;2016;"Oertel, Catharine; Lopes, José; Yu, Yu; Mora, Kenneth A. Funes; Gustafson, Joakim; Black, Alan W.; Odobez, Jean-Marc";Towards building an attentive artificial listener: on the perception of attentiveness in audio-visual feedback tokens;Proceedings of the 18th ACM International Conference on Multimodal Interaction;978-1-4503-4556-9;NA;10.1145/2993148.2993188;https://doi.org/10.1145/2993148.2993188;"Current dialogue systems typically lack a variation of audio-visual feedback tokens. Either they do not encompass feedback tokens at all, or only support a limited set of stereotypical functions. However, this does not mirror the subtleties of spontaneous conversations. If we want to be able to build an artificial listener, as a first step towards building an empathetic artificial agent, we also need to be able to synthesize more subtle audio-visual feedback tokens. In this study, we devised an array of monomodal and multimodal binary comparison perception tests and experiments to understand how different realisations of verbal and visual feedback tokens influence third-party perception of the degree of attentiveness. This allowed us to investigate i) which features (amplitude, frequency, duration...) of the visual feedback influences attentiveness perception; ii) whether visual or verbal backchannels are perceived to be more attentive iii) whether the fusion of unimodal tokens with low perceived attentiveness increases the degree of perceived attentiveness compared to unimodal tokens with high perceived attentiveness taken alone; iv) the automatic ranking of audio-visual feedback token in terms of conveyed degree of attentiveness.";2016-10-31;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;21–28;NA;NA;NA;NA;NA;Towards building an attentive artificial listener;ICMI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"backchannels; head nods; virtual agent";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2XT7Q3N5;conferencePaper;2016;"O'Leary, Ciarán; Mtenzi, Fred; McAvinia, Claire";Towards Reusable Personas for Everyday Design;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2892411;https://doi.org/10.1145/2851581.2892411;Personas are artificial character based representations of user goals, attitudes, motivations and abilities which enable designers to focus their design efforts on key, targeted users. The success of personas in design is due to their capacity to enable designers to empathize with users and understand user goals. Persona development is rooted in the rigorous collection and analysis of data specifically related to the design project being undertaken. New design projects thus require the development of new personas. Since redevelopment is not always achievable attention has turned towards reuse of personas and the underlying data. This paper reports on ongoing research into the development of reusable personas for use by non-expert, everyday designers. Such designers are regularly faced with small scale but diverse design challenges for which they cannot carry out user research and modelling. They can, however, make use of general, reusable personas developed independently of their current design project.;2016-05-07;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;2915–2922;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"everyday design; personas; practices; reuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9EQ9IMUK;conferencePaper;2017;"Valverde, Isabel; Cochrane, Todd";Senses Places: soma-tech mixed-reality participatory performance installation/environment;Proceedings of the 8th International Conference on Digital Arts;978-1-4503-5273-4;NA;10.1145/3106548.3106613;https://doi.org/10.1145/3106548.3106613;We present the latest developments of the art-tech research project Senses Places, a somatic-technological (soma-tech) mixed-reality participatory performance installation/environment, engaging expanded modes of embodied physical-virtual interaction. This ongoing somatic-technological dance/performance collaborative trans-disciplinary approach gathers artists and developer researchers, working remotely and physically in analogical-digital intermedia interfaces and their expanded experience design and choreography. The sensorial expansion and integration sought through human-computer interaction links participants, avatars, images and physical-virtual environments. They constitute different organic-artificial sensorial-expressive channels of visual, audio, tactile, and somatic/kinesthetic shared tuning/engagement/experience. At the core of this long-term intervention lies the common urging desire for more encompassing and empathic embodied interactivity among physical and remote subjects and places. With a cross-cultural somatic and dance practices, Senses Places critically experiments with different informational, communicational and biomedical technologies available, wishing to contribute to understand the world's and humans becoming through what we have been conceiving as posthuman corporealities [1] within a posthuman condition and emerging somatic epistemology [2].;2017-09-06;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;195–197;NA;NA;NA;NA;NA;Senses Places;ARTECH2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Dance-technology; Interaction design; Interactive art; Posthuman corporealities; Somatic epistemology; Somatics; Virtual and mixed-reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
F8N6SI9F;conferencePaper;2020;"Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef";Facial expression based satisfaction index for empathic buildings;Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers;978-1-4503-8076-8;NA;10.1145/3410530.3414443;https://doi.org/10.1145/3410530.3414443;In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.;2020-09-10;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;704–707;NA;NA;NA;NA;NA;NA;UbiComp-ISWC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"machine learning; empathic building; facial expressions; satisfaction index";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BSXEE8HF;conferencePaper;2017;"Portela, Manuel; Granell-Canut, Carlos";A new friend in our smartphone? observing interactions with chatbots in the search of emotional engagement;Proceedings of the XVIII International Conference on Human Computer Interaction;978-1-4503-5229-1;NA;10.1145/3123818.3123826;https://doi.org/10.1145/3123818.3123826;We present the findings of a quantitative and qualitative empirical research to understand the possibilities of engagement and affection in the use of conversational agents (chatbots). Based on an experiment with 13 participants, we explored on one hand the correlation between the user expectation, user experience and intended use and, on the other, whether users feel keen and engaged in having a personal, empathic relation with an intelligent system like chatbots. We used psychological questionnaires to semi-structured interviews for disentangle the meaning of the interaction. In particular, the personal psychological background of participants was found critical while the experience itself allowed them to imagine new possible relations with chatbots. Our results show some insights on how people understand and empathize with future interactions with conversational agents and other non-visual interfaces.;2017-09-25;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1–7;NA;NA;NA;NA;NA;A new friend in our smartphone?;"Interacci&#xf3;n '17";NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"conversational agents; emotional engagement; empathic relations; mixed-method analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZSKIQPDU;bookSection;2020;"Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri";Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419900;Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.;2020-11-02;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;262–266;NA;NA;NA;NA;NA;Playing with the Opposite of Uncanny;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"emotional intelligence; human-computer interaction; child-robot interaction; human-animal interaction; playful learning; robot toys; social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZUTKBH6E;conferencePaper;2014;"Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid";Werewolves, cheats, and cultural sensitivity;Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems;978-1-4503-2738-1;NA;NA;NA;MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.;2014-05-05;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1085–1092;NA;NA;NA;NA;NA;NA;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PRU458VQ;conferencePaper;2017;Cesar, Pablo;Sensing Engagement: Helping Performers to Evaluate their Impact;Proceedings of the 2017 ACM Workshop on Multimedia-based Educational and Knowledge Technologies for Personalized and Social Online Training;978-1-4503-5508-7;NA;10.1145/3132390.3132391;https://doi.org/10.1145/3132390.3132391;The keynote will provide an overview about different mechanisms to gather data by using wearable sensor technology for understanding the experience of people attending cultural events, public lectures, and courses. Through practical case studies in different areas of the creative industries and education, we will showcase our results and discuss about our failures. Based on realistic testing grounds, collaborating with several commercial and academic partners, we have deployed our technology and infrastructure in places such as the National Theatre of China in Shanghai. Our approach is to seamless connecting fashion and textiles with sensing technology, and with the environment. The final objective is to create intelligent and empathic systems that can react to the audience and their experience.;2017-10-27;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1;NA;NA;NA;NA;NA;Sensing Engagement;MultiEdTech '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\C7K7TEMJ\Cesar - 2017 - Sensing Engagement Helping Performers to Evaluate.pdf;NA;NA;"education; sensors; cultural experiences; data visualization; gsr; physical installation; shared experiences";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
URZVMLEC;conferencePaper;2019;"Torres, M. I.; Olaso, J. M.; Montenegro, C.; Santana, R.; Vázquez, A.; Justo, R.; Lozano, J. A.; Schlögl, S.; Chollet, G.; Dugan, N.; Irvine, M.; Glackin, N.; Pickard, C.; Esposito, A.; Cordasco, G.; Troncone, A.; Petrovska-Delacretaz, D.; Mtibaa, A.; Hmani, M. A.; Korsnes, M. S.; Martinussen, L. J.; Escalera, S.; Cantariño, C. Palmero; Deroo, O.; Gordeeva, O.; Tenorio-Laranga, J.; Gonzalez-Fraile, E.; Fernandez-Ruanova, B.; Gonzalez-Pinto, A.";The EMPATHIC project: mid-term achievements;Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments;978-1-4503-6232-0;NA;10.1145/3316782.3322764;https://doi.org/10.1145/3316782.3322764;The goal of active aging is to promote changes in the elderly community so as to maintain an active, independent and socially-engaged lifestyle. Technological advancements currently provide the necessary tools to foster and monitor such processes. This paper reports on mid-term achievements of the European H2020 EMPATHIC project, which aims to research, innovate, explore and validate new interaction paradigms and platforms for future generations of personalized virtual coaches to assist the elderly and their carers to reach the active aging goal, in the vicinity of their home. The project focuses on evidence-based, user-validated research and integration of intelligent technology, and context sensing methods through automatic voice, eye and facial analysis, integrated with visual and spoken dialogue system capabilities. In this paper, we describe the current status of the system, with a special emphasis on its components and their integration, the creation of a Wizard of Oz platform, and findings gained from user interaction studies conducted throughout the first 18 months of the project.;2019-06-05;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;629–638;NA;NA;NA;NA;NA;The EMPATHIC project;PETRA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\EXE3JMDI\Torres et al. - 2019 - The EMPATHIC project mid-term achievements.pdf;NA;NA;"assisted living; coaching; emotional artificial agents; spoken dialogue systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JDXJ36AF;conferencePaper;2017;Richards, Deborah;Intimately intelligent virtual agents: knowing the human beyond sensory input;Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents;978-1-4503-5558-2;NA;10.1145/3139491.3139505;https://doi.org/10.1145/3139491.3139505;Despite being in the era of Big Data, where our devices seem to anticipate and feed our every desire, intelligent virtual agents appear to lack intimate and important knowledge of their user. Current cognitive agent architectures usually include situation awareness that allows agents to sense their environment, including their human partner, and provide congruent empathic behaviours. Depending on the framework, agents may exhibit their own personality, culture, memories, goals and reasoning styles. However, tailored adaptive behaviours based on multi-dimensional and deep understanding of the human essential for enduring beneficial relationships in certain contexts are lacking. In this paper, examples are provided of what an agent may need to know about the human in the application domains of education, health and cybersecurity and the challenges around agent adaptation and acquisition of relevant data and knowledge.;2017-11-13;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;39–40;NA;NA;NA;NA;NA;Intimately intelligent virtual agents;ISIAA 2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Intelligent Virtual Agents; User Modelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
G5MN2YAM;conferencePaper;2016;Alyuz, Nese;Shaping the future of education with empathic companions;Proceedings of the 2nd workshop on Emotion Representations and Modelling for Companion Systems;978-1-4503-4558-3;NA;10.1145/3009960.3009964;https://doi.org/10.1145/3009960.3009964;With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.;2016-11-16;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;1–2;NA;NA;NA;NA;NA;NA;ERM4CT '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
B9SRHBKR;conferencePaper;2015;"Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia";Designing a socially assistive robot for pediatric care;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771923;https://doi.org/10.1145/2771839.2771923;We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.;2015-06-21;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;387–390;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
H3ECBJKL;conferencePaper;2016;"Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan";Semi-supervised model personalization for improved detection of learner's emotional engagement;Proceedings of the 18th ACM International Conference on Multimodal Interaction;978-1-4503-4556-9;NA;10.1145/2993148.2993166;https://doi.org/10.1145/2993148.2993166;Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.;2016-10-31;2021-02-15T21:26:45Z;2021-02-15T21:26:45Z;2021-02-15T00:00:00Z;100–107;NA;NA;NA;NA;NA;NA;ICMI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
27MD3NZR;conferencePaper;2020;"Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423864;https://doi.org/10.1145/3383652.3423864;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).;2020-10-20;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–3;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"empathy; conversational agent; emotion detection; healthcare computing; pattern matching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
W3UG9BHN;journalArticle;2020;"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung";The Design and Implementation of XiaoIce, an Empathetic Social                     Chatbot;Computational Linguistics;NA;0891-2017;10.1162/coli_a_00368;https://doi.org/10.1162/coli_a_00368;This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.;2020-03-01;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T21:29:04Z;53–93;NA;1;46;NA;Comput. Linguist.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;March 2020;NA;NA;NA;C:\Users\esben\Zotero\storage\NJMQ7QM9\Zhou et al. - 2020 - The Design and Implementation of XiaoIce, an Empat.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BTF9C3L8;conferencePaper;2020;"Harilal, Nidhin; Shah, Rushil; Sharma, Saumitra; Bhutani, Vedanta";CARO: An Empathetic Health Conversational Chatbot for People with Major Depression;Proceedings of the 7th ACM IKDD CoDS and 25th COMAD;978-1-4503-7738-6;NA;10.1145/3371158.3371220;https://doi.org/10.1145/3371158.3371220;There has been a rise in the number of patients suffering from major depression over the past decade. Most of the patients are reluctant and do not open up for councelling services. Conversational applications such as chatbots have been found efficient in overcoming alcohol addiction. Effective treatments can tackle depression, but only 10% of affected patients are able to avail such treatments mainly due to lack of resources and social stigma associated with mental disorders. We propose CARO, a chatbot app, which is capable of performing empathetic conversations and providing medical advice for people with major depression. CARO will be able to sense the conversational context, its intent and the associated emotions.;2020-01-05;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;349–350;NA;NA;NA;NA;NA;CARO;CoDS COMAD 2020;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Chatbot; Depression; Empathetic Response; Medical Advice";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SJWVSTXW;bookSection;2020;"Chen, Zhifa; Lu, Yichen; Nieminen, Mika P.; Lucero, Andrés";Creating a Chatbot for and with Migrants: Chatbot Personality Drives Co-Design Activities;Proceedings of the 2020 ACM Designing Interactive Systems Conference;978-1-4503-6974-9;NA;NA;https://doi.org/10.1145/3357236.3395495;Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria.;2020-07-03;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;219–230;NA;NA;NA;NA;NA;Creating a Chatbot for and with Migrants;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\3TMXBM4P\Chen et al. - 2020 - Creating a Chatbot for and with Migrants Chatbot .pdf;NA;NA;"chatbot; personality; avatar; co-design; conversation design; generative toolkit; migrants; probes; social integration";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EHY832P2;conferencePaper;2020;"Ravi, Akhilesh; Yadav, Amit Kumar Singh; Chauhan, Jainish; Dholakia, Jatin; Jain, Naman";SentEmoji: A Dataset to Generate Empathising Conversations;Proceedings of the 7th ACM IKDD CoDS and 25th COMAD;978-1-4503-7738-6;NA;10.1145/3371158.3371218;https://doi.org/10.1145/3371158.3371218;Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach.;2020-01-05;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;345–346;NA;NA;NA;NA;NA;SentEmoji;CoDS COMAD 2020;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NU77X2W5;conferencePaper;2019;"Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid";BigBlueBot: teaching strategies for successful human-agent interactions;Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3302290;https://doi.org/10.1145/3301275.3302290;Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.;2019-03-17;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;448–459;NA;NA;NA;NA;NA;BigBlueBot;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"conversational agents; explainable AI; mechanical turk";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6YYAZ5RD;bookSection;2018;"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama";Touch Your Heart: A Tone-aware Chatbot for Customer Care on Social Media;Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;978-1-4503-5620-6;NA;NA;https://doi.org/10.1145/3173574.3173989;Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.;2018-04-21;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–12;NA;NA;NA;NA;NA;Touch Your Heart;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"social media; deep learning; chatbot; customer care";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
P3CBCPGK;conferencePaper;2020;"De Nieva, Johan Oswin; Joaquin, Jose Andres; Tan, Chaste Bernard; Marc Te, Ruzel Khyvin; Ong, Ethel";"Investigating Students&#x2019; Use of a Mental Health Chatbot to Alleviate Academic Stress";6th International ACM In-Cooperation HCI and UX Conference;978-1-4503-8829-0;NA;10.1145/3431656.3431657;https://doi.org/10.1145/3431656.3431657;The amount of academic workload in schools can cause students to experience stress and become more susceptible to mental health problems. However, because of fear of societal stigma, students may find it more difficult to approach others about the stress they experience. A chatbot can provide an alternative avenue for students to freely share the stressful situations they are experiencing. In this study, we investigated the use of Woebot as a mechanism to help senior high school students alleviate stress from academic workload. 25 participants who engaged in daily conversations with Woebot for a two-week period rated the chatbot’s likeness to a human with a mean score of 5.56 out of 8, while its ability to understand the feelings of the participants and empathize with them had a mean score of 5.61. An analysis of the chat logs showed that the participants valued Woebot’s lessons and stories while they faced challenges in cases when the chatbot generated inappropriate responses. We discuss our findings and provide design suggestions that could make conversational agents like Woebot be more useful in helping the general student population cope with stress.;2020-10-21;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–10;NA;NA;NA;NA;NA;NA;CHIuXiD '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"Academic stress; Alleviating stress; Mental health chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RQ2VA39T;conferencePaper;2020;"Ahn, Yuna; Zhang, Yilin; Park, Yujin; Lee, Joonhwan";A Chatbot Solution to Chat App Problems: Envisioning a Chatbot Counseling System for Teenage Victims of Online Sexual Exploitation;Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6819-3;NA;10.1145/3334480.3383070;https://doi.org/10.1145/3334480.3383070;In recent years, online sexual exploitation targeting teenagers has been on the rise. Given teenagers' growing reluctance toward face-to-face communication, using a counseling chatbot could be a more effective way to provide teenage victims with necessary information and emotional support. There is a small number of counseling chatbots for victims of sexual crime, but none targeting teenagers specifically. This research suggests design guidelines for building a counseling chatbot for teenage victims of online sexual exploitation with a focus on establishing rapport by empathizing with their stories and providing them with the proper information. We conducted in-depth interviews with peer counselors at the Teenage Women's Human Rights Center, who have been consulting teenage victims in their age group using online messengers. The four key findings from our research suggested using open-ended questions, using teenager-friendly language, helping teenagers understand that they are victims and offering age-relevant information.;2020-04-25;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–7;NA;NA;NA;NA;NA;A Chatbot Solution to Chat App Problems;CHI EA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"rapport; counseling chatbot; online sexual exploitation; teenager";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6ZPXIYBT;conferencePaper;2020;"Xiao, Ziang; Zhou, Michelle X.; Chen, Wenxi; Yang, Huahai; Chi, Changyan";If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills;Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6708-0;NA;10.1145/3313831.3376131;https://doi.org/10.1145/3313831.3376131;Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks.;2020-04-21;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–14;NA;NA;NA;NA;NA;If I Hear You Correctly;CHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;C:\Users\esben\Zotero\storage\SQJIUGTJ\Xiao et al. - 2020 - If I Hear You Correctly Building and Evaluating I.pdf;NA;NA;"deep learning; conversational agents; active listening; ai chatbot; chatbot platform; interview chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8VBCNWPE;conferencePaper;2019;"Gu, Xiusen; Xu, Weiran; Zhang, Chao";Neural Emotional Response Generation via Adversarial Transfer Learning;Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence;978-1-4503-6128-6;NA;10.1145/3319921.3319933;https://doi.org/10.1145/3319921.3319933;Emotional response generation is a key step to build an empathetic chatbot. However, previous emotional chatting models mainly focus on single-turn conversation, and multi-turn context emotional response generation has not been explored. In this paper, we propose an adversarial transfer emotional chatting (ATEC) model for multi-turn conversation which is based on conditional variational autoencoders (CVAE). ATEC has two alternate training phases: supervised training and transfer training. In the supervised training stage, we train the CVAE model, a content discriminator and an emotional classifier based on ground truth corpus. And in the transfer training stage, we change the target emotion and use the content discriminator to force the model to transfer the multi-turn context information, while the emotional classifier regularizes the emotions expressed in the generated responses. Experiments show that the proposed approach achieves state of the art performance with diverse responses and accurate emotional expression.;2019-03-15;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;106–110;NA;NA;NA;NA;NA;NA;ICIAI 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"conditional variational autoencoders; emotion transfer; Emotional dialogue system";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Q66GR627;conferencePaper;2017;"Portela, Manuel; Granell-Canut, Carlos";A new friend in our smartphone? observing interactions with chatbots in the search of emotional engagement;Proceedings of the XVIII International Conference on Human Computer Interaction;978-1-4503-5229-1;NA;10.1145/3123818.3123826;https://doi.org/10.1145/3123818.3123826;We present the findings of a quantitative and qualitative empirical research to understand the possibilities of engagement and affection in the use of conversational agents (chatbots). Based on an experiment with 13 participants, we explored on one hand the correlation between the user expectation, user experience and intended use and, on the other, whether users feel keen and engaged in having a personal, empathic relation with an intelligent system like chatbots. We used psychological questionnaires to semi-structured interviews for disentangle the meaning of the interaction. In particular, the personal psychological background of participants was found critical while the experience itself allowed them to imagine new possible relations with chatbots. Our results show some insights on how people understand and empathize with future interactions with conversational agents and other non-visual interfaces.;2017-09-25;2021-02-15T21:29:19Z;2021-02-15T21:29:19Z;2021-02-15T00:00:00Z;1–7;NA;NA;NA;NA;NA;A new friend in our smartphone?;"Interacci&#xf3;n '17";NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;ACM Digital Library;NA;NA;NA;NA;NA;NA;"conversational agents; emotional engagement; empathic relations; mixed-method analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N9B6I9WU;conferencePaper;2017;Thompson, Jeff;I Touch You and You Touch Me;SIGGRAPH Asia 2017 Art Gallery;978-1-4503-5401-1;NA;10.1145/3143748.3143753;https://doi.org/10.1145/3143748.3143753;A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.;2017;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;NA;NA;NA;NA;NA;NA;NA;SA '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bangkok, Thailand;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WLT3R663;conferencePaper;2010;"Lee, Myunghee; Kim, Gerard J.";Empathetic Video Experience through Timely Multimodal Interaction;International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction;978-1-4503-0414-6;NA;10.1145/1891903.1891948;https://doi.org/10.1145/1891903.1891948;"In this paper, we describe a video playing system, named ""Empatheater,"" that is controlled by multimodal interaction. As the video is played, the user must interact and emulate predefined video ""events"" through multimodal guidance and whole body interaction (e.g. following the main character's motion or gestures). Without the timely interaction, the video stops. The system shows guidance information as how to properly react and continue the video playing. The purpose of such a system is to provide indirect experience (of the given video content) by eliciting the user to mimic and empathize with the main character. The user is given the illusion (suspended disbelief) of playing an active role in the unraveling video content. We discuss various features of the newly proposed interactive medium. In addition, we report on the results of the pilot study that was carried out to evaluate its user experience compared to passive video viewing and keyboard based video control.";2010;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;NA;NA;NA;NA;NA;NA;NA;ICMI-MLMI '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Beijing, China;NA;NA;NA;"empathy; user experience; interactive video; multimodality; user guidance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2WY87E8Q;conferencePaper;2018;Roberts, Jasmine;Using Affective Computing for Proxemic Interactions in Mixed-Reality;Proceedings of the Symposium on Spatial User Interaction;978-1-4503-5708-1;NA;10.1145/3267782.3274692;https://doi.org/10.1145/3267782.3274692;Immersive technologies have been touted as empathetic mediums. This capability has yet to be fully explored through machine learning integration. Our demo seeks to explore proxemics in mixed-reality (MR) human-human interactions.The author developed a system, where spatial features can be manipulated in real time by identifying emotions corresponding to unique combinations of facial micro-expressions and tonal analysis. The Magic Leap One is used as the interactive interface, the first commercial spatial computing head mounted (virtual retinal) display (HUD).A novel spatial user interface visualization element is prototyped that leverages the affordances of mixed-reality by introducing both a spatial and affective component to interfaces.;2018;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;176;NA;NA;NA;NA;NA;NA;SUI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Berlin, Germany;NA;NA;NA;"affective computing; augmented reality; mixed reality; Proxemics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TJT26LPR;conferencePaper;2020;"Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef";Facial Expression Based Satisfaction Index for Empathic Buildings;Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers;978-1-4503-8076-8;NA;10.1145/3410530.3414443;https://doi.org/10.1145/3410530.3414443;In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.;2020;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;704–707;NA;NA;NA;NA;NA;NA;UbiComp-ISWC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Mexico;NA;NA;NA;"machine learning; empathic building; facial expressions; satisfaction index";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MGRQZCE4;conferencePaper;2019;"Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco";A Preliminary Work on Dog Emotion Recognition;IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume;978-1-4503-6988-6;NA;10.1145/3358695.3361750;https://doi.org/10.1145/3358695.3361750;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications.The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.;2019;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;91–96;NA;NA;NA;NA;NA;NA;WI '19 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Thessaloniki, Greece;NA;NA;NA;"Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MLLXAIVM;bookSection;2020;"Chromik, Michael; Lachner, Florian; Butz, Andreas";ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research;Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society;978-1-4503-7579-5;NA;NA;https://doi.org/10.1145/3419249.3420163;Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML’s impact on current UXR activities and practitioners’ predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users’ emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research.;2020;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IV9NRRV6;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-Based Computational Framework for an Empathetic Robot;Proceedings of the 2019 11th International Conference on Computer and Automation Engineering;978-1-4503-6287-0;NA;10.1145/3313991.3314018;https://doi.org/10.1145/3313991.3314018;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;102–108;NA;NA;NA;NA;NA;NA;ICCAE 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Perth, WN, Australia;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3CQIKGI6;bookSection;2020;"Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph";Reputation Agent: Prompting Fair Reviews in Gig Markets;Proceedings of The Web Conference 2020;978-1-4503-7023-3;NA;NA;https://doi.org/10.1145/3366423.3380199;"Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.";2020;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;1228–1240;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UL4ZGBCU;conferencePaper;2017;"Frueh, Christian; Sud, Avneesh; Kwatra, Vivek";Headset Removal for Virtual and Mixed Reality;ACM SIGGRAPH 2017 Talks;978-1-4503-5008-2;NA;10.1145/3084363.3085083;https://doi.org/10.1145/3084363.3085083;Virtual Reality (VR) has advanced significantly in recent years and allows users to explore novel environments (both real and imaginary), play games, and engage with media in a way that is unprecedentedly immersive. However, compared to physical reality, sharing these experiences is difficult because the user's virtual environment is not easily observable from the outside and the user's face is partly occluded by the VR headset. Mixed Reality (MR) is a medium that alleviates some of this disconnect by sharing the virtual context of a VR user in a flat video format that can be consumed by an audience to get a feel for the user's experience.Even though MR allows audiences to connect actions of the VR user with their virtual environment, empathizing with them is difficult because their face is hidden by the headset. We present a solution to address this problem by virtually removing the headset and revealing the face underneath it using a combination of 3D vision, machine learning and graphics techniques. We have integrated our headset removal approach with Mixed Reality, and demonstrate results on several VR games and experiences.;2017;2021-02-15T21:31:17Z;2021-02-15T21:31:17Z;NA;NA;NA;NA;NA;NA;NA;NA;SIGGRAPH '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Los Angeles, California;NA;NA;NA;"virtual reality; mixed reality; facial synthesis; headset removal";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QVD84XWI;conferencePaper;2015;"Putnam, Cynthia; Dahman, Maria; Rose, Emma; Cheng, Jinghui; Bradford, Glenn";Teaching Accessibility, Learning Empathy;"Proceedings of the 17th International ACM SIGACCESS Conference on Computers &amp; Accessibility";978-1-4503-3400-6;NA;10.1145/2700648.2811365;https://doi.org/10.1145/2700648.2811365;"As information and communication technologies (ICTs) become more diffuse, the diversity of users that designers need to consider is growing; this includes people with disabilities and aging populations. As a result, computing education must provide students the means and inspiration to learn about inclusive design. This poster presents top-level findings from 18 interviews with professors from some of the top universities in the US. Our analysis yielded four categories of findings: (1) important student learning outcomes (the most common was for students to embrace diversity); (2) exercises and teaching materials (almost all focused on inclusion of people with disabilities in discovery and evaluation of ICTs); (3) frustrations and challenges (largely focused on how to engage students in accessibility topics); and (4) the importance of instructor initiative to include the topic of accessibility in their teaching. The unifying theme was the high importance of cultivating empathy with end users.";2015;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;333–334;NA;NA;NA;NA;NA;NA;ASSETS '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Lisbon, Portugal;NA;NA;NA;"accessibility; pedagogy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZGQ76ID7;conferencePaper;2020;Soleymani, Mohammad;Machine Understanding of Emotion and Sentiment;Companion Publication of the 2020 International Conference on Multimodal Interaction;978-1-4503-8002-7;NA;10.1145/3395035.3425321;https://doi.org/10.1145/3395035.3425321;Emotions are subjective experiences involving perceptual and con-textual factors [4]. There is no objective tool for precise measurement of emotions. However, we can anticipate an emotion's emergence through the knowledge of common responses to events in similar situations. We can also measure proxies of emotions by recognizing emotional expressions [3]. Studying emotional response to multimedia allows identifying expected emotions in users consuming the content. For example,abrupt loud voices are novel and unsettling which result in surprise and higher experience of arousal [2,6]. For a particular type of con-tent such as music, mid-level attributes such as rhythmic stability or melodiousness have strong association with expected emotions[1]. Given that such mid-level attributes are more related to the con-tent, their machine-perception is more straightforward. Moreover,their perception in combination with user models enables building person-specific emotion anticipation models.In addition to studying expected emotions, we can also observe users emotional reactions to understand emotion in multimedia.Typical methods of emotion recognition include recognizing emotions from facial or vocal expressions. Recognition of emotional expressions requires large amount of labeled data, expensive to produce. Hence, the most recent advances in machine-based emotion perception include methods that can leverage unlabeled data through self-supervised and semi-supervised learning [3, 5]. In this talk, I review the field and showcase methods for automatic modeling and recognition of emotions and sentiment indifferent contexts [3,8]. I show how we can identify underlying factors contributing to the construction of subjective experience of emotions [1,7]. Identification of these factors allows us to use them as mid-level attributes to build machine learning models for emotion and sentiment understanding. I also show how emotions and sentiment can be recognized from expressions with the goal of building empathetic autonomous agents [8].;2020;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;206–207;NA;NA;NA;NA;NA;NA;ICMI '20 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Netherlands;NA;NA;NA;"machine learning; emotion; affective computing; sentiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4KP8DBCM;conferencePaper;2014;Slovák, Petr;Supporting Teaching and Learning of Situational Empathy by Technology;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2559957;https://doi.org/10.1145/2559206.2559957;Detecting and supporting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, most of this work is still based primarily on single persons' data, and there is little research on supporting complex interpersonal aspects such as empathy. To address this gap, the goal of my PhD work is to explore ways in which technology can facilitate learning and teaching of situational empathy, with particular focus on counselling students.;2014;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;315–318;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"feedback; empathy; bio-sensors; mixed methods";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4YDHKCTA;conferencePaper;2017;"Polignano, Marco; Basile, Pierpaolo; Rossiello, Gaetano; de Gemmis, Marco; Semeraro, Giovanni";Learning Inclination to Empathy from Social Media Footprints;Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization;978-1-4503-4635-1;NA;10.1145/3079628.3079639;https://doi.org/10.1145/3079628.3079639;In recent years we are witnessing a growing spread of social media footprints, as the consequence of the wide use of applications such as Facebook, Twitter or LinkedIn, which allow people to share content that might provide information about personal preferences and aptitudes. Among the traits that can be inferred, empathy is the ability to feel and share another person's emotions and we consider it as a relevant aspect for the profiling and recommendation tasks. We propose a method that predicts its level for the user by exploiting her social media data and using linear regression algorithms. The results show which are the most relevant correlations among the different groups of user's features and the empathy level predicted.;2017;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;383–384;NA;NA;NA;NA;NA;NA;UMAP '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bratislava, Slovakia;NA;NA;NA;"machine learning; empathy; social medium footprint";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UMW857WB;conferencePaper;2019;"Bevan, Chris; Green, David Philip; Farmer, Harry; Rose, Mandy; Cater, Kirsten; Stanton Fraser, Danaë; Brown, Helen";"Behind the Curtain of the ""Ultimate Empathy Machine"": On the Composition of Virtual Reality Nonfiction Experiences";Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5970-2;NA;10.1145/3290605.3300736;https://doi.org/10.1145/3290605.3300736;"Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience created for consumption using panoramic ""Virtual Reality"" headsets. VRNF promises nonfiction content producers the potential to create new ways for audiences to experience ""the real""; allowing viewers to transition from passive spectators to active participants. Our current project is exploring VRNF through a series of ethnographic and experimental studies. In order to document the content available, we embarked on an analysis of VR documentaries produced to date. In this paper, we present an analysis of a representative sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64 characteristics of the medium over this period, discuss how producers are exploiting the affordances of VR, and shed light on new audience roles. Our findings provide insight into the current state of the art in VRNF and provide a digital resource for other researchers in this area.";2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;1–12;NA;NA;NA;NA;NA;NA;CHI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"virtual reality; interaction; immersive media; nonfiction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WDTBG6C2;book;2020;NA;HAI '20: Proceedings of the 8th International Conference on Human-Agent Interaction;NA;978-1-4503-8054-6;NA;NA;NA;"It is our great pleasure to welcome you to the Eighth International Conference on Human-Agent Interaction HAI 2020 (Virtual Conference); hosted by the Western Sydney University (Australia) and supported by Chalmers University of Technology (Sweden).The conference is a venue with an interdisciplinary nature to discuss and disseminate state-ofthe- art research on topics related to human interactions with a range of agent systems, including physical robots and humanoids, virtual agents, socially interactive agents, and Artificially Intelligent (AI) agents. The topical areas of the conference include user studies, frameworks, simulations, technical developments and more within Human Agent and Robotic Interaction. The conference brings together a large variety of multidisciplinary research groups, companies, and researchers looking into the broader area of agents and robotics across Australia, Japan and the rest of the world.The theme for HAI 2020 is ""Artificial Intelligence + Experience Design."" The recent advent of AI has motivated researchers to focus on several algorithmic prospects in developing intelligent robotic agents and their interactions. Progressively, AI advances are leading to exciting outcomes in the HAI field and, at the same time, are opening up for a wide perspective on how to design intelligent robotic agents. For example, how to combine artificial intelligence and user experience design approaches in human-agent interaction. We are looking forward to sharing the latest research results of HAI that contribute a broad range of disciplines.Three keynote talks are featured. The first is titled ""We're in This Together: Social Robots in Group, Organizational, and Community Interactions"", by Associate Prof. Selma Šabanović, Indiana University Bloomington, USA. The second is titled ""What kind of human-centric robotics do we need? Investigations from human-robot interactions in socially assistive scenarios"", by Prof. Ginevra Castellano, Uppsala University, Sweden. The third is an industry talk titled ""The rapid rise in drone technology"", by Sebastian Robertson, CEO of BIRDI, Australia. Their keynote talks will provide cross-disciplinary examples of novel HAI research and applications that are highly inspiring for the HAI audience and research community.This year's submissions have come from more than 25 countries and cover leading-edge topics including human and machine learning, conversational agents, empathy and trust of social robots, social drones, social presence, robot applications, virtual agent applications and novel perspectives of HAI. With an acceptance rate of 38% (25 papers out of 65 submissions), the program committee has again set a high quality standard. In addition, 26 out of the 35 latebreaking poster papers submissions were accepted.";2020;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
C2HLAH5R;journalArticle;2019;"Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;J. Hum.-Robot Interact.;NA;NA;10.1145/3300188;https://doi.org/10.1145/3300188;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WH3LS7JJ;conferencePaper;2017;De Lira, Carla;Improving the Learning Experiences of First-Year Computer Science Students with Empathetic IDEs;Proceedings of the 2017 ACM Conference on International Computing Education Research;978-1-4503-4968-0;NA;10.1145/3105726.3105742;https://doi.org/10.1145/3105726.3105742;Computer science has the highest dropout rate among undergraduate STEM degree programs. This is especially concerning, given that computer science-related jobs are projected to grow 12% in the next six years. One contributing factor is that media representations of computer science can lead underrepresented groups to perceive themselves as unfit for the discipline, and ultimately to drop out. To address this concern, I propose an empathetic IDE model that uses affective computing technologies to promote empathy among computer science students. A quasi-experimental research design will be used to evaluate the model's effectiveness in fostering a supportive community between instructors and students. By leveraging emotional learning process data as a form of constant feedback to both instructors and students, this research can gain new insights into how to improve learning environments for computer science students with or without affective computing technologies.;2017;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;293–294;NA;NA;NA;NA;NA;NA;ICER '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tacoma, Washington, USA;NA;NA;NA;"affective computing; computer science education; empathy in computer science; learning analytics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VESCDX8B;conferencePaper;2016;Bratitsis, Tharrenos;A Digital Storytelling Approach for Fostering Empathy Towards Autistic Children: Lessons Learned;Proceedings of the 7th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion;978-1-4503-4748-8;NA;10.1145/3019943.3019987;https://doi.org/10.1145/3019943.3019987;In this paper a case study in which interactive digital storytelling was exploited for fostering empathy towards children with Autism Spectrum Disorders (ASD) is presented. The research population consisted mainly by Kindergarten children. Based on the findings and the overall experience, even considering the design mistakes that occurred, this paper argues upon the deriving value of exploiting multimodal digital representations in the form of a story in order to cultivate empathy towards children with ASD and thus, facilitate social interaction and inclusion. This approach can be useful in mixed population classrooms, but in a wider educational context as well.;2016;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;301–308;NA;NA;NA;NA;NA;NA;DSAI 2016;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Vila Real, Portugal;NA;NA;NA;"Empathy; ASD; Digital Storytelling; Inclusion; Kindergarten; Social Interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NYAPZXTZ;conferencePaper;2019;"Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad";Multimodal Learning for Identifying Opportunities for Empathetic Responses;2019 International Conference on Multimodal Interaction;978-1-4503-6860-5;NA;10.1145/3340555.3353750;https://doi.org/10.1145/3340555.3353750;Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.;2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;95–104;NA;NA;NA;NA;NA;NA;ICMI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Suzhou, China;NA;NA;NA;"machine learning; empathy; human behavior; multimodal sentiment; virtual human";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
C97P2NM2;conferencePaper;2014;"Villarica, Ryan; Richards, Deborah";Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds;Proceedings of the 2014 Conference on Interactive Entertainment;978-1-4503-2790-9;NA;10.1145/2677758.2677761;https://doi.org/10.1145/2677758.2677761;"Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.";2014;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;1–9;NA;NA;NA;NA;NA;NA;IE2014;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Newcastle, NSW, Australia;NA;NA;NA;"Empathic Agents; Omosa; Virtual Learning Environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7RIZDZZ2;conferencePaper;2018;"Kroma, Assem; Lachman, Richard";Alzheimer's Eyes Challenge: The Gamification of Empathy Machines;Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-5968-9;NA;10.1145/3270316.3270320;https://doi.org/10.1145/3270316.3270320;"Demographic projections of many western democracies show them to be aging nations. To keep thriving we must ensure that our citizens are aging in a healthy manner without isolation from society. Alzheimer's disease is one of the most misunderstood conditions of our aging population, and is a problematic condition for caregivers and family members to support. This project seeks to build a mixed reality environment that allows users to experience some of the symptoms of Alzheimer's in the form of serious games. By gamifying the notion of the somewhat controversial notion of the ""empathy machine"", the project makes a novel social impact on the general population.";2018;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;329–336;NA;NA;NA;NA;NA;NA;CHI PLAY '18 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Melbourne, VIC, Australia;NA;NA;NA;"virtual reality; augmented reality; mixed reality; serious games; gamification; alzheimer's disease; empathy machines; extended realities; meaningful play";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EQ72S555;bookSection;2020;"Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri";Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419900;Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.;2020;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;262–266;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KAINJ4EL;conferencePaper;2019;"Urakami, Jacqueline; Moore, Billie Akwa; Sutthithatip, Sujitra; Park, Sung";Users' Perception of Empathic Expressions by an Advanced Intelligent System;Proceedings of the 7th International Conference on Human-Agent Interaction;978-1-4503-6922-0;NA;10.1145/3349537.3351895;https://doi.org/10.1145/3349537.3351895;The goal of this study was to examine usertextquoteright s perception of expressions of empathy by an autonomous system. In a survey eight different components of empathy identified in literature studies and prior tests (Expressing own feelings, Expressing to know what the other feels, Helping, Showing interest, Taking the others perspective, Displaying regard, Situational understanding, and Agreement) were compared to neutral expressions. Differences in participants evaluations were found across the components of empathy as well as individual differences were revealed. Expressions of cognitive empathy (Showing interest, situational understanding) and expressions of empathy of assistance (helping) were perceived positively by participants. However, expressions of affective empathy (expressing own feelings, expressing to know what the other feels) received mainly negative ratings. Cluster analysis revealed individual differences especially for items relating to affective empathy. Whereas one group of participants identified in the cluster analysis rated expressions of affective empathy negatively, a second group of participants rated these expressions positively. Furthermore, large differences across participants also existed for taking the other's perspective, a component of cognitive empathy. Integrating expressions of empathy in human-machine interaction is a sensitive issue and designers must carefully choose what components of empathy are adequate depending on the situational circumstances and the targeted user group.;2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;11–18;NA;NA;NA;NA;NA;NA;HAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Kyoto, Japan;NA;NA;NA;"empathy; autonomous intelligent system; survey";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6UX4K5HK;conferencePaper;2019;"Chen, Jize; Wang, Changhong";Reaching Cooperation Using Emerging Empathy and Counter-Empathy;Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems;978-1-4503-6309-9;NA;NA;NA;According to social neuropsychology, the cooperative behavior is largely influenced by empathy, which is deemed essential of emotional system and has wide impact on social interaction. In the work reported here, we believe that the emergence of empathy and counter-empathy is closely related to creatures' inertial impression on intragroup coexistence and competition. Based on this assumption, we establish a unified model of empathy and counter-empathy in light of Hebb's rule. We also present Adaptive Empathetic Learner (AEL), a training method for agents to enable affective utility evaluation and learning procedure in multi-agent system. In AEL, the empathy model is integrated into the adversarial bandit setting in order to achieve a high degree of versatility. Our algorithm is first verified in the survival game, which is designed to simulate the primitive hunting environment. In this game, empathy and cooperation emerge among agents with different power. In another test about Iterated Prisoners' Dilemma, cooperation was reached even between an AEL agent and a rational one. Moreover, when confronted with hostile, the AEL agent showed sufficient goodwill and vigilantly protected its safe payoffs. In the Ultimatum Game, it's worth mentioning that absolute fairness could be achieved on account of the self-adaptation of empathy and counter-empathy.;2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;746–753;NA;NA;NA;NA;NA;NA;AAMAS '19;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Montreal QC, Canada;NA;NA;NA;"cooperation; adversarial bandit; empathy and counter-empathy; multi-agent system";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WIRW8IWP;conferencePaper;2013;"Buckingham Shum, Simon; de Laat, Maarten; De Liddo, Anna; Ferguson, Rebecca; Kirschner, Paul; Ravenscroft, Andrew; Sándor, Ágnes; Whitelock, Denise";DCLA13: 1<sup>st</sup> International Workshop on Discourse-Centric Learning Analytics;Proceedings of the Third International Conference on Learning Analytics and Knowledge;978-1-4503-1785-6;NA;10.1145/2460296.2460357;https://doi.org/10.1145/2460296.2460357;This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field.;2013;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;282;NA;NA;NA;NA;NA;NA;LAK '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Leuven, Belgium;NA;NA;NA;"dialogue; learning analytics; argumentation; deliberation; discourse; visualization";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
FR4BXL8G;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3326596;https://doi.org/10.1145/3311927.3326596;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;755–760;NA;NA;NA;NA;NA;NA;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boise, ID, USA;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CWI6QL9M;conferencePaper;2019;Nakamura, Lisa;Virtual Reality and the Feeling of Virtue: Women of Color Narrators, Enforced Hospitality, and the Leveraging of Empathy;Proceedings of the 2019 on Designing Interactive Systems Conference;978-1-4503-5850-7;NA;10.1145/3322276.3325420;https://doi.org/10.1145/3322276.3325420;"Many researchers and evangelists argue that V.R. is fundamentally more ""moving"" than other media because of users' visual immersion in navigable worlds and their empathic identification with another visual perspective. (see Rubin, Bailenson). This essay will analyze women of color's labor as virtual reality's documentary subjects whose digital presence and hospitality within war-torn, emiserated, and inhospitable scenes such as a Lebanese refugee camp, a favela, and a cucumber farm enables a fantasy of virtuous empathy on the part of the viewer. Virtual reality's painstakingly created virtuous identity as the ""empathy machine"" satisfies desires for prosocial feelings of compassion, empathy, and identification that replace encounters with politics, unwelcome bodies, and protest. Global South women of color, non-white refugee women, and trans women are all virtual objects of identification in virtual reality and video games, platforms that are inextricably connected yet carry very different moral and ethical connotations.";2019;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;3;NA;NA;NA;NA;NA;NA;DIS '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Diego, CA, USA;NA;NA;NA;"empathy; virtual reality; hospitality; empathy machine; labor; women of color";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Q6WVS2PB;journalArticle;2016;McBride, Neil;The Ethics of Driverless Cars;SIGCAS Comput. Soc.;NA;0095-2737;10.1145/2874239.2874265;https://doi.org/10.1145/2874239.2874265;This paper critiques the idea of full autonomy, as illustrated by Oxford University's Robotcar. A fully autonomous driverless car relies on no external inputs, including GPS and solely learns from its environment using learning algorithms. These cars decide when they drive, learn from human drivers and bid for insurance in real time. Full autonomy is pitched as a good end in itself, fixing human inadequacies and creating safety and certainty by the elimination of human involvement. Using the ACTIVE ethics framework, an ethical response to the fully autonomous driverless cars is developed by addressing autonomy, community, transparency, identity, value and empathy. I suggest that the pursuit of full autonomy does not recognise the essential importance of interdependencies between humans and machines. The removal of human involvement should require the driverless car to be more connected with its environment, drawing all the information it can from infrastructure, internet and other road users. This requires a systemic view, which addresses systems and relationships, which recognises the place of driverless cars in a connected system, which is open to the study of complex relationships, both networked and hierarchical.;2016-01;2021-02-15T21:31:18Z;2021-02-15T21:31:18Z;NA;179–184;NA;3;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"ethics; driverless cars; full autonomy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SJRYL9WU;journalArticle;2017;"Otterbacher, Jahna; Ang, Chee Siang; Litvak, Marina; Atkins, David";Show Me You Care: Trait Empathy, Linguistic Style, and Mimicry on Facebook;ACM Trans. Internet Technol.;NA;1533-5399;10.1145/2996188;https://doi.org/10.1145/2996188;"Linguistic mimicry, the adoption of another’s language patterns, is a subconscious behavior with pro-social benefits. However, some professions advocate its conscious use in empathic communication. This involves mutual mimicry; effective communicators mimic their interlocutors, who also mimic them back. Since mimicry has often been studied in face-to-face contexts, we ask whether individuals with empathic dispositions have unique communication styles and/or elicit mimicry in mediated communication on Facebook. Participants completed Davis’s Interpersonal Reactivity Index and provided access to Facebook activity. We confirm that dispositional empathy is correlated to the use of particular stylistic features. In addition, we identify four empathy profiles and find correlations to writing style. When a linguistic feature is used, this often “triggers” use by friends. However, the presence of particular features, rather than participant disposition, best predicts mimicry. This suggests that machine-human communications could be enhanced based on recently used features, without extensive user profiling.";2017-02;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;NA;NA;1;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"social media; Affect; empathy; empathic response; interpersonal relations; linguistic alignment; linguistic mimicry; linguistic style";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BRENGSE2;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor";He Who Hesitates is Lost (...in Thoughts over a Robot);Proceedings of the Technology, Mind, and Society;978-1-4503-5420-2;NA;10.1145/3183654.3183703;https://doi.org/10.1145/3183654.3183703;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.;2018;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;NA;NA;NA;NA;NA;NA;NA;TechMindSociety '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Washington, DC, USA;NA;NA;NA;"Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XKUEZDYA;conferencePaper;2016;"Sturdee, Miriam; Coulton, Paul; Lindley, Joseph G.; Stead, Mike; Ali, Haider; Hudson-Smith, Andy";Design Fiction: How to Build a Voight-Kampff Machine;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2892574;https://doi.org/10.1145/2851581.2892574;Tyrell: Is this to be an empathy test? Capillary dilation of the so-called blush response? Fluctuation of the pupil. Involuntary dilation of the iris... Deckard: We call it Voight-Kampff for short. Design fiction is a broad term that occupies a space within the wider miscellany of speculative design approaches and is appearing as a nascent method for HCI research. The factor that differentiates and distinguishes design fiction from other approaches is its novel use of world building and in this paper we consider whether there is value in creating fictional research worlds through which we might consider future interactions. As an example we build a world in which algorithms for detecting empathy will become a major compnent of future communications. We take inspiration from the sci-fi film Blade Runner in order to consider what a plausible world, in which it is useful to build a Voight-Kampff machine, might be like.;2016;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;375–386;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Jose, California, USA;NA;NA;NA;"empathy; speculative design; blade runner; design fiction; research through design; Voight Kampff";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RXMUJJPN;conferencePaper;2020;"Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio";DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI;Proceedings of the International Conference on Advanced Visual Interfaces;978-1-4503-7535-1;NA;10.1145/3399715.3399820;https://doi.org/10.1145/3399715.3399820;Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.;2020;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;NA;NA;NA;NA;NA;NA;NA;AVI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salerno, Italy;NA;NA;NA;"Computer Vision; Deep Learning; User Emotions; User Experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6GWZDB4B;conferencePaper;2014;"Watanabe, Yukako; Okada, Yoshiko; Osawa, Hirotaka; Sugaya, Midori";Digital Play Therapy for Children with Learning Disabilities;Proceedings of the Second International Conference on Human-Agent Interaction;978-1-4503-3035-0;NA;10.1145/2658861.2658918;https://doi.org/10.1145/2658861.2658918;Children who are suffering on learning and developmental disabilities require daily trainings for social skills. However, such daily training is not provided occasionally because it requires interactive helps from therapists. In this paper, we propose a digital dollhouse that enhanced traditional psychological play therapy with digital sensors and computer graphics. The digital dollhouse provides immersive space to children which grows children's communication skill through their imaging play. This device allows non-professional like parents to make play therapy. In this paper, we show details about prototype of digital dollhouse. We also categorize requirements for digital play therapy that are given by psychological viewpoints based on the prototype. Interdisciplinary design process collaborating with engineers and psychologists shows the possibility that digital dollhouse is enough to enhance empathy of children and such empathy will be enhanced by creating immersive characters.;2014;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;185–188;NA;NA;NA;NA;NA;NA;HAI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tsukuba, Japan;NA;NA;NA;"human-agent interaction; human robot interaction; augmented human; emotional labor; human interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JUIM9W8U;conferencePaper;2019;"Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid";BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions;Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3302290;https://doi.org/10.1145/3301275.3302290;Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.;2019;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;448–459;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Marina del Ray, California;NA;NA;NA;"conversational agents; explainable AI; mechanical turk";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L68MHZKG;conferencePaper;2020;"El-Glaly, Yasmine; Shi, Weishi; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.";Presenting and Evaluating the Impact of Experiential Learning in Computing Accessibility Education;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;978-1-4503-7124-7;NA;10.1145/3377814.3381710;https://doi.org/10.1145/3377814.3381710;Studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. Compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. To address these issues, we have created five Accessibility Learning Labs (ALL) using an experiential learning structure. The labs are designed to educate and create awareness of accessibility needs in computing. The labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. The labs are hosted on our servers and require only a browser to be utilized.To demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. Our findings include: (I) The demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (II) The labs are effective in informing students about foundational accessibility topics (III) Empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. Created labs and project materials are publicly available on the project website: http://all.rit.edu;2020;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;49–60;NA;NA;NA;NA;NA;NA;ICSE-SEET '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, South Korea;NA;NA;NA;"accessibility education; computing accessibility; computing education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EFMJY97J;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;931–939;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"empathy; human-agent interaction; human-robot interaction; memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N34UW9K6;conferencePaper;2018;"Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Klapwijk, Remke";Developing Children's Empathy in Co-Design Activities: A Pilot Case Study;Proceedings of the 17th ACM Conference on Interaction Design and Children;978-1-4503-5152-2;NA;10.1145/3202185.3210797;https://doi.org/10.1145/3202185.3210797;This paper explores how co-design activities in schools can contribute to developing children's empathy. A pilot case study is presented in which eight 10- to 12-year-old children participated. The design theme was outdoor education. After discussing the co-design procedure, preliminary results about three empathic techniques are discussed: (1) reflection on the role of empathy in design, (2) storytelling to introduce the design challenge, and (3) defining the needs and wishes of the story's protagonists. The lessons learned are taken into account in a comprehensive follow-up study.;2018;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;669–674;NA;NA;NA;NA;NA;NA;IDC '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"children; empathy; storytelling; co-design; 21st century skills; schools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XK2R28MY;conferencePaper;2013;"Shanahan, Joseph; Marghitu, Daniela";Software Engineering Java Curriculum with Alice and Cloud Computing;Proceedings of Alice Symposium on Alice Symposium;978-1-4503-2250-8;NA;10.1145/2532333.2532337;https://doi.org/10.1145/2532333.2532337;Project Expression is a course designed to attract students into the field of computing. Participants are trained in Java programming and the art of multimedia production. By implementing a wide range of apps they learn cloud communication techniques in a software environment. The course focuses on a digital film project and participants are challenged with creating a movie that expresses an idea, opinion, or belief relative to society. The film project is a landscape for learning cloud-computer-programming and reaches across the computer spectrum with engaging activities that stimulate creative design. This study examines the curriculum's approach and measures its effectiveness to teach the cloud-computing mentality. It emphasizes the importance of empathy in a technology-based society. Furthermore, it investigates whether or not such a course is an effective method for attracting students into the field of computing.;2013;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;NA;NA;NA;NA;NA;NA;NA;ALICE '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Durham, NC, USA;NA;NA;NA;"3D animations; 3D Visualization; Computers and Empathy; K-12 Computer Science Curriculum; K12 Alice Curriculum; K12 Cloud Computing Curriculum; Movie-making";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
A7ALHCDW;conferencePaper;2019;"Muñoz, Diego; Ploderer, Bernd; Brereton, Margot";Position Exchange Workshops: A Method to Design for Each Other in Families;Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5970-2;NA;10.1145/3290605.3300339;https://doi.org/10.1145/3290605.3300339;"Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me &amp; You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships.";2019;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;1–14;NA;NA;NA;NA;NA;NA;CHI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"dialogicality; family relationships; parent-adult child relationship; position exchange; position exchange workshops; renegotiation of relationships";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RFQHYN9B;conferencePaper;2017;"Pantela, Nicoletta; Kyza, Eleni A.";The Investigation of Concept Mapping as a Scaffolding Tool in a Technologically-Mediated, Mobile Learning, Augmented Reality Environment;Proceedings of the 16th World Conference on Mobile and Contextual Learning;978-1-4503-5255-0;NA;10.1145/3136907.3136924;https://doi.org/10.1145/3136907.3136924;This study investigated concept maps as a form of support for primary school students' development of conceptual understanding, historical empathy, and for promoting collaborative learning. Students used the same historical learning augmented reality application on a mobile device, worked in pairs, and were divided in two conditions: the experimental group (n=12), supported by a tablet-based concept mapping tool, and the control group (n=11), who only used the learning application on the same mobile devices. The results showed that the experimental group students gained a deeper conceptual understanding after the visit, as evidenced by their concept maps and their discussions during their visit.;2017;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;NA;NA;NA;NA;NA;NA;NA;mLearn 2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Larnaca, Cyprus;NA;NA;NA;"informal learning; computer-supported collaborative learning; concept maps; Scaffolding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
D6ZA5TH5;conferencePaper;2012;"Stienstra, Jelle; Marti, Patrizia";Squeeze Me: Gently Please;Proceedings of the 7th Nordic Conference on Human-Computer Interaction: Making Sense Through Design;978-1-4503-1482-4;NA;10.1145/2399016.2399131;https://doi.org/10.1145/2399016.2399131;This paper presents the Squeeze Me, a research-through-design case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a double-layered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge.;2012;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;746–750;NA;NA;NA;NA;NA;NA;NordiCHI '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Copenhagen, Denmark;NA;NA;NA;"empathy; interaction design; continuous mapping";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EEZVBMES;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: A Living Media Interface for Speech Intervention;Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;978-1-4503-2473-1;NA;10.1145/2556288.2557402;https://doi.org/10.1145/2556288.2557402;Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.;2014;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;1817–1820;NA;NA;NA;NA;NA;NA;CHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"embedded computing; living media interfaces; speech intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
E45AXW5J;conferencePaper;2020;de Oliveira, Lariza Laura;Mapping Empathy in the Computer Science Classroom;Proceedings of the 2020 ACM Conference on International Computing Education Research;978-1-4503-7092-9;NA;10.1145/3372782.3408109;https://doi.org/10.1145/3372782.3408109;"Empathy is a humanistic skill, a capacity that allows us to perceive other people's emotions, putting ourselves under their perspective [1]. The study of empathy is highlighted as a tool to provide a better understanding of people's thoughts, feelings and how they affect behavior [2]. Being aware of that, a design company created the Empathy Map (EM), which is usually employed in the initial phase of the Design Thinking process to understand user's concerns, feelings and aspirations [3].Teaching practices known as student-centered, inherited from the constructivist school, are not new [4]. Several educators have applied these approaches inside the Computer Science (CS) classroom [5]. A key to success in CS education is the construction of the computational thinking [5]. Learning to program is not an easy task and the process is surrounded by several emotional reactions such as frustration, anxiety, happiness and others [6]. In this sense, EMs can be useful to capture student's feelings, guiding educators strategies during CS classes.Here, I describe the experience of using the EM inside the Computer Science classroom at the University Center Barão de Mauá. The process of building EMs involves the description of the persona, who, in this case, are the students of a given year in the CS course. In the center of EM, the picture of a student is drawn and the surrounding region is divided into 4 areas [3, 7]: 1) THINK and FEEL - What are the students thinking/feeling? 2) HEAR and SEE - What are the students hearing/seeing? 3) SAY and DO - What are the students saying/doing? 4) PAIN/CHALLENGES and GAINS - What are the challenges the students are facing? Is there anything painful to do? How do they measure success?The EM was performed in two different stages of the CS course: in the first and third years. The students were asked to build the EM, representing their feelings and aspirations about CS. The EM of the first year showed: 1) THINK and FEEL - ""thinking about the future"", ""feeling fear"", ""curiosity"", ""insecurity"", ""confusion"". 2) HEAR and SEE - "" hearing positive statements from family and friends"", ""seeing themselves in a trainee program"", ""working or doing a master's degree"", ""developing themselves"". They also reported to hear that CS is very difficult. 3) SAY and DO - They say learning is difficult, They do study and work; 4) PAIN/CHALLENGES - they report feeling insecure about finishing the course and find a position. The main challenge is to conciliate both working and studies. The students of the third year reported: 1) THINK and FEEL - ""thinking about the future"", ""feeling anxiety"", ""anger"", ""tiredness"", ""worry""; 2) HEAR and SEE - "" they hear that CS is a promising career"", ""see opportunities and/or lack of them"". They reported hear questions about what they will do in the future; 3) SAY and DO - ""procrastinating and working""; 4) PAIN/CHALLENGES - The pain reported refers to the anxiety of completing the course and the excessive procrastination. The main challenge reported was to set medium/short term goals as study to complete tasks in the CS course.As a conclusion, we highlight that the first year students were more motivated about their future, whereas the third year are tired and anxious about finishing the course. The EM construction was able to show student's feelings and pains about the course, allowing the educator to capture the student's perspectives. Based on that, it may be possible to conduct a more appropriate learning plan to manage how emotional aspects can influence the learning process. As a future work, EM will be used along with specific subjects in a qualitative study, considering subjects with highest failure rates in CS curriculum.";2020;2021-02-15T21:31:19Z;2021-02-15T21:31:19Z;NA;303;NA;NA;NA;NA;NA;NA;ICER '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, New Zealand;NA;NA;NA;"computer science education; empathy map";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
26CFIR4Z;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: A Living Media Interface for Learning Games;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2574772;https://doi.org/10.1145/2559206.2574772;Digital games can engage children in therapeutic and learning activities. Incorporating living media in these games can create feelings of empathy and caring in users and add more motivation and involvement to the gameplay. We present, Rafigh, a living media interface designed to motivate children to play learning games that involve repetitive and sometimes boring tasks. In the current implementation the interface is used for speech intervention games. During gameplay, children practice their speech and care for a living mushroom colony in the process. The mushroom's growth is used to communicate how much speech is used, as an indicator of degree of speech practice, during interaction.;2014;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;407–410;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"embedded computing; living media interfaces; speech intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6GVD2LGP;conferencePaper;2019;"Choi, Kyung Yun; Sumini, Valentina; Ishii, Hiroshi";ReSpire: Self-Awareness and Interpersonal Connectedness through Shape-Changing Fabric Display;Proceedings of the 2019 on Creativity and Cognition;978-1-4503-5917-7;NA;10.1145/3325480.3329176;https://doi.org/10.1145/3325480.3329176;reSpire lets people bring tangibility to their invisible physiological state through shape-changing fabric deformed by airflow. We explore a way to support mental wellness via improving a self-interaction and interpersonal connectedness. reSpire encourages not only people to focus on their connection to inner body but also to interact with others through playful tangible interactions in the same location and develop a empathy. We created a non-machine like interface responsive to users' respiration patterns and hand gestures using a fabric and its deformation by airflow control. We also introduce a computational model to simulate the deformation of fabric by the variance of airflow pres-sure and direction. Various interaction scenarios highlight its applications not only to health but also to interactive art installation.;2019;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;449–454;NA;NA;NA;NA;NA;NA;"C&amp;C '19";NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Diego, CA, USA;NA;NA;NA;"mental health; self-awareness; tangible interaction; mindfulness; shape-changing display; synchronization";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
GD3IFDIW;conferencePaper;2020;Vennekens, Joost;Service-Learning for Web Technology: Observations from a Small Case Study;Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education;978-1-4503-6874-2;NA;10.1145/3341525.3387414;https://doi.org/10.1145/3341525.3387414;"In the past academic year, we conducted an experiment at using service-learning in order to integrate learning of empathy and creativity into an undergraduate course on Web Technology. This was a small scale pilot project, conducted in collaboration with the service-learning team at our institute. In the project, students collaborated with WAI-NOT, a non-profit organization that develops an online platform for children with various kinds of (physical/mental) disabilities. The students developed new ""games"" for this platform, to teach the children basic computer skills (e.g., clicking, moving the mouse). Key in this project was the interaction between the students, the non-profit and the target audience. Due to the small size of the class, we did not conduct a quantitative evaluation of the project, but we do discuss the experiences and feedback from teachers, students and community.";2020;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;328–334;NA;NA;NA;NA;NA;NA;ITiCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"computer science education; service-learning; experience report";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3EBKFZYC;conferencePaper;2019;"Suzianti, Amalia; Atthousi, Hajid Naufal";Implementation of Design Thinking Approach In Designing Learning Support Tools In The Classroom For Hearing Impaired Person: Case Study: Elementary School Students in SLB-B Santi Rama;Proceedings of the 2019 5th International Conference on E-Business and Mobile Commerce;978-1-4503-7182-7;NA;10.1145/3332324.3332338;https://doi.org/10.1145/3332324.3332338;The absence of adequate accommodation for the hearing-impaired in the Education field is one of the problems in Indonesia nowadays. Teaching aids or learning support tools as accommodation can help the deaf to accelerate and improve the quality of their education. This research uses design thinking approach in designing the tool so that the result of the design is in accordance with the needs and desires of the users, which are deaf elementary students age 8-10. Started from the empathy phase until the define phase which obtained that the target users have a need and desire to learn the vocabulary with ease and fun then proceed with the ideation phase with stakeholders and prototyping to generate ideas and create the teaching aids in accordance with their needs and desires in the form of an arcade game with card of words and ended with the testing phase which shows that the tool is able to improve visual receptive language comprehension of 8.07% and visual expressive language of 77.74% in a fun way. This research has produced a teaching aids designed with design thinking approach which can improve the quality of their learning in school in accordance with the needs and desires of hearing-impaired elementary school students and has been validated by stakeholders.;2019;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;75–80;NA;NA;NA;NA;NA;NA;ICEMC 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Taichung, Taiwan;NA;NA;NA;"Design Thinking; Deaf Children; Hearing-impaired; Inclusive Design; Learning Support Tools; Persona";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DPUQSR5D;conferencePaper;2020;"Shi, Weishi; Khan, Saad; El-Glaly, Yasmine; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.";Experiential Learning in Computing Accessibility Education;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;978-1-4503-7122-3;NA;10.1145/3377812.3390901;https://doi.org/10.1145/3377812.3390901;Many developers don't understand how to, or recognize the need to develop accessible software. To address this, we have created five educational Accessibility Learning Labs (ALL) using an experiential learning structure. Each of these labs addresses a foundational concept in computing accessibility and both inform participants about foundational concepts in creating accessible software while also demonstrating the necessity of creating accessible software. The hosted labs provide a complete educational experience, containing materials such as lecture slides, activities, and quizzes.We evaluated the labs in ten sections of a CS2 course at our university, with 276 students participating. Our primary findings include: I) The labs are an effective way to inform participants about foundational topics in creating accessible software II) The labs demonstrate the potential benefits of our proposed experiential learning format in motivating participants about the importance of creating accessible software III) The labs demonstrate that empathy material increases learning retention. Created labs and project materials are publicly available on the project website: http://all.rit.edu;2020;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;250–251;NA;NA;NA;NA;NA;NA;ICSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, South Korea;NA;NA;NA;"accessibility education; computing accessibility; computing education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8UIMBXLV;conferencePaper;2014;"Gonzalez-Sanchez, Javier; Chavez-Echeagaray, Maria E.; Atkinson, Robert K.; Burleson, Winslow";Multimodal Detection of Affective States: A Roadmap through Diverse Technologies;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2567820;https://doi.org/10.1145/2559206.2567820;One important way for systems to adapt to their individual users is related to their ability to show empathy. Being empathetic implies that the computer is able to recognize a user's affective states and understand the implication of those states. Detection of affective states is a step forward to provide machines with the necessary intelligence to appropriately interact with humans. This course provides a description and demonstration of tools and methodologies for automatically detecting affective states with a multimodal approach.;2014;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;1023–1024;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"affect-driven adaptation; affective states; emotion recognition; multimodal; sensors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZQ72YESD;bookSection;2020;Tiwari, Divyanshu;Fostering Collaboration and Empathy Through Games;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419929;"Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.";2020;2021-02-15T21:31:20Z;2021-02-15T21:31:20Z;NA;91–93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
P3RN8VP7;bookSection;2020;Tiwari, Divyanshu;Fostering Collaboration and Empathy Through Games;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419929;"Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.";2020;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;91–93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KLPP4KC7;conferencePaper;2018;"Lyckvi, Sus; Torgersson, Olof";Privacy and Design Ethics vs Designing for Curiosity, Communication and Children: Lessons Learned;Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services;978-1-4503-5898-9;NA;10.1145/3229434.3229480;https://doi.org/10.1145/3229434.3229480;This paper describes the lessons learned when designing an empathy-oriented image-exchange app for fifth-grade pupils. The aim was to evoke curiosity and empathy towards someone living elsewhere or under different socio-economic circumstances. In addition, we strived to apply design ethics (e.g. protecting users from insults, humiliation, inappropriate content etc) and take users' privacy into account. By setting up these boundaries for this user group we found ourselves confronted with a set of conflicting design decisions which ultimately led to a lesser and different user experience than we had expected. Here, we discuss the interplay between our design decisions and the consequences thereof, and evaluate the mistakes we made. Moreover we discuss how to balance anonymity and curiosity, and comment on the benefits of making a pre-analysis of potential clashes related to intended UX and other core design decisions.;2018;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;NA;NA;NA;NA;NA;NA;NA;MobileHCI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"ethics; communication; empathy; curiosity; design for children; image sharing; privacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DHNZALJN;conferencePaper;2020;"Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon";Robots Teaching Recycling: Towards Improving Environmental Literacy of Children;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3379462;https://doi.org/10.1145/3371382.3379462;The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.;2020;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;615–616;NA;NA;NA;NA;NA;NA;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Cambridge, United Kingdom;NA;NA;NA;"educational robotics; children robot interaction; eco-literacy; environmental literacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9UAVYKRQ;conferencePaper;2015;"Lundgren, Sus; Torgersson, Olof; Björk, Staffan";Thrimage: An Empathy-Oriented Discussion Tool for Classroom Use;Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct;978-1-4503-3653-6;NA;10.1145/2786567.2792901;https://doi.org/10.1145/2786567.2792901;Thrimage is a class-application where pupils choose and rank images in relation to a given word or notion. In seeing who else chose similarly, as well as in a debriefing teacher-led discussion, pupils gain insight in others' way of thinking, and learn to argument for their own opinion but also to respect others, both of which supports the development of empathy and mutual understanding. The design is part of a long-running design exploration on designing of collaborative, co-located experiences using mobile devices, in combination with an educational need.;2015;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;628–635;NA;NA;NA;NA;NA;NA;MobileHCI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Copenhagen, Denmark;NA;NA;NA;"empathy; image sharing; Thrimage";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DETM34WT;conferencePaper;2015;"Ostrowski, S\lawomir; Rolczyński, Rafa\l; Pniewska, Joanna; Garnik, Igor";User-Friendly E-Learning Platform: A Case Study of a Design Thinking Approach Use;Proceedings of the Mulitimedia, Interaction, Design and Innnovation;978-1-4503-3601-7;NA;10.1145/2814464.2814483;https://doi.org/10.1145/2814464.2814483;"E-learning systems are very popular means to support the teaching process today. These systems are mainly used by universities as well as by commercial training centres. We analysed several popular e-learning platforms used in Polish universities and find them very unfriendly for the users. For this reason, the authors began the work on the creation of a new system that would be not only useful, but also usable for students, teachers and system administrators. This paper presents a case study of e-learning platform design process. We applied Design Thinking (DT) approach which puts a strong emphasis on the participation of end-users throughout the design process. Such an approach makes final product more user-friendly and better suited to end-users needs. An interdisciplinary team of designers implemented the design process in five stages: Empathizing - a thorough analysis of the problem and its context; Defining - synthesis of information obtained in the previous step and identifying user needs and insights; Ideating - generating solutions; Prototyping and Testing solutions proposed in the Ideating phase. During the design process the team used many additional methods, such as Empathy map, Stakeholders map, Value preposition canvas, personas, brainstorming, Card sorting and many more. As the result of design process we obtain an interactive prototype of designed e-learning platform. The prototype was tested by end-users and the feedback from the testers was collected. It confirmed that the use of the DT approach in design process allows to better fit designed product to the users' needs. The next step will be the implementation of tested and approved solutions to the real system what is planned in the nearest future.";2015;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;NA;NA;NA;NA;NA;NA;NA;MIDI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Warsaw, Poland;NA;NA;NA;"e-learning; Design Thinking; design process management";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2HCGJAZU;conferencePaper;2019;"Berzowska, Joanna; Mommersteeg, Alex; Rosero Grueso, Laura Isabel; Ducray, Eric; Rabo, Michael Patrick; Moisan, Geneviève";Baby Tango: Electronic Textile Toys for Full-Body Interaction;Proceedings of the Thirteenth International Conference on Tangible, Embedded, and Embodied Interaction;978-1-4503-6196-5;NA;10.1145/3294109.3300973;https://doi.org/10.1145/3294109.3300973;"We describe two prototypes from the Baby Tango project: electronic textile toys that enable soft, tangible, full-body interaction. It presents interaction techniques that bridge the physical, the digital, and the social, as well as a case study in constructing interactive composite textiles. Given that the softness of the toy is a central design constraint, most of the circuit, including the sensors, is embroidered directly on the surface of the artifact using technical threads (with varying electro-mechanical properties) and a digital embroidery/laying machine. This submission includes design and technical details, as well as initial interaction design scenarios. The next steps of this project will explore how these toys could support the development of empathy in toddlers through embodied play. Further work is needed in order to develop background research, collaborations with early childhood researchers, as well as empirical studies. Future work will include the development of these studies; iterating aspects of interaction and play through participatory design; and improving technical design to focus on reliability, robustness, and durability.";2019;2021-02-15T21:31:57Z;2021-02-15T21:31:57Z;NA;437–442;NA;NA;NA;NA;NA;NA;TEI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tempe, Arizona, USA;NA;NA;NA;"tangible interaction; electronic textiles; embroidered sensors; empathy.; interactive toys; soft user interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
T2TP4CQ6;conferencePaper;2019;"Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Södergren, Antonia Clasina";Children's Assessment of Co-Design Skills: Creativity, Empathy and Collaboration;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3325334;https://doi.org/10.1145/3311927.3325334;This paper presents a co-design project in a school with 16 children ages 10 to 11 in which three learning goals were defined upfront: creativity, empathy, and collaboration. The first part of the paper demonstrates how these co-design skills were implemented through an iterative process of explanation, practice, reflection, and application. Based on the results of post-interviews and short questionnaires, the second part discusses children's assessments of these skills. Whereas children reported fluctuations in applying these skills, the findings show an overall positive trend towards the end of the project. In future work, these findings will be triangulated with observational data.;2019;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;520–526;NA;NA;NA;NA;NA;NA;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boise, ID, USA;NA;NA;NA;"Empathy; Children; 21st Century Skills; Co-design; Collaboration; Creativity; Design-based Learning; Participatory Design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5NDRSVU2;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2883-8;NA;10.1145/2696454.2696479;https://doi.org/10.1145/2696454.2696479;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;83–90;NA;NA;NA;NA;NA;NA;HRI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NXRBIX28;bookSection;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems;978-1-4503-4655-9;NA;NA;https://doi.org/10.1145/3025453.3025496;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;3506–3510;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UTTZQASC;conferencePaper;2017;"Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin";Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games;Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology;978-1-4503-5548-3;NA;10.1145/3139131.3139132;https://doi.org/10.1145/3139131.3139132;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.;2017;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;NA;NA;NA;NA;NA;NA;NA;VRST '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gothenburg, Sweden;NA;NA;NA;"pet game; user types; virtual pet; virtual reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RUF4ALKA;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";The CoWriter Project: Teaching a Robot How to Write;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702091;https://doi.org/10.1145/2701973.2702091;"This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.";2015;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;269;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
P9QPEJM3;conferencePaper;2020;"Yu, Borou; Zhou, Tiange; Wang, Zeyu; Min, Jiajian";The World of Freedom;SIGGRAPH Asia 2020 Art Gallery;978-1-4503-8108-6;NA;10.1145/3414686.3427172;https://doi.org/10.1145/3414686.3427172;Indeed, people spend more time on deep thinking since 2020. The questions which ask mainly by the sociologists, now become the topics on the dining table. The debates on social and moral dilemmas are happening intensively 24 hours on the internet. We started to think more about who we are, where we are going, and how we will value the information we have received. Do we have freedom? Shall we believe absolute freedom? Sometimes people directly transform the idea of liberty into democracy. However, shall we also equal freedom to democracy? Since we are all inside this one pandemic bubble, after most people stay at home for a couple of months, we start emerging a global-size collective memory, which makes people more empathetically understand others' situations. Meanwhile, more and more people have to learn and take experience virtually. The attention of empathy and the new work-from-home mode evokes the initial idea of this virtual reality experience. We start to ask how people could learn and think more effectively in this brand new virtual age? Unity program makes this innovation possible. The innovative architecture modeling could permit a large group of people to experience personal space and sharing areas simultaneously. The sound design is specially designed for the various space sound and the audience's interactivities. We use this program to build up an immersive and empathetic space that embodies a hypothetical argument of a social dilemma into a virtual manifestation. People might be able to figure out the most meaningful answer by wearing the same shoes. The social distance could also be virtually controlled in this program by counting if the number of participates overload spaces.;2020;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;NA;NA;NA;NA;NA;NA;NA;SA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Republic of Korea;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MH868NN3;conferencePaper;2015;"Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung";Design of Emotional Conversations with a Child for a Role Playing Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702009;https://doi.org/10.1145/2701973.2702009;The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.;2015;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;73–74;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"emotional role playing robot; human intervention device; human-robot-interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8P9JPI7W;conferencePaper;2019;"Kawano, Atsuko; Motoyama, Yuji; Aoyama, Mikio";A LX (Learner EXperience)-Based Evaluation Method of the Education and Training Programs for Professional Software Engineers;Proceedings of the 2019 7th International Conference on Information and Education Technology;978-1-4503-6639-7;NA;10.1145/3323771.3323789;https://doi.org/10.1145/3323771.3323789;We propose a new design methodology to maximize the training effect in a corporate education and training for professional software engineers. Conventionally, the education and training programs have been designed in a top-down manner based on the long-term strategy on the business and engineering resources development. However, to draw out the learners' high performance from the education and training programs, we need to have an empathy with the learners, and to analyze their expectations and emotions in order to motivate them. Therefore, this paper proposes the learner-centered design methodology of the corporate education and training programs inspired by the design thinking and lean start-up concepts. We define the learning processes in the education and training programs as LX (Learner eXperience), and propose LJM (Learning Journey Map) as the LX evaluation method as an extension of CJM (Customer Journey Map) in UX (User eXperience) design. The LJM enables to evaluate training effect and communicate with stakeholders in the training design expressing the LX quantitatively in a visual form. We applied the proposed design methodology to the education and training programs for professional software engineers in a company to evaluate LX and elicit learner requirements to the programs. We applied the proposed LJM to the education and training program of two levels of the whole program and its LUs (Learning Units), and identified problems in the LX. From the empirical study, we confirm the effectiveness of the proposed methodology.;2019;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;151–159;NA;NA;NA;NA;NA;NA;ICIET 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aizu-Wakamatsu, Japan;NA;NA;NA;"Design thinking; Corporate education and training program; Journey map; Lean start-up; LX (Learner eXperience); Professional software engineer; UX (User eXperience)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
S7QFS78U;conferencePaper;2016;"Fan, Mingyue; Yu, Liyue; Bowler, Leanne";Feelbook: A Social Media App for Teens Designed to Foster Positive Online Behavior and Prevent Cyberbullying;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2892398;https://doi.org/10.1145/2851581.2892398;This project presents a prototype for a stand-alone social media application designed for teenage users in order to prevent and mitigate mean and cruel online behavior. The purpose of the app is to create a nurturing environment where teenagers use a variety of features designed to help raise self-awareness of their own online behavior, seek support when needed, and learn to control and, when possible, correct aggressive behavior. The prototype is framed by four design principles: design for reflection, design for empathy, design for empowerment, and design for the whole. We conclude by outlining the next steps in our project to develop an application that helps to improve the online experiences of young people. This work has implications for the CHI community because it applies software solutions to tackle a critical social problem that can affect the health and well being of young people.;2016;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;1187–1192;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Jose, California, USA;NA;NA;NA;"social media; empathy; cyberbullying; reflection; social computing; teens; young adults";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6IT7ZBLM;bookSection;2017;"Schaper, Marie-Monique; Santos, Maria; Malinverni, Laura; Pares, Narcis";Towards the Design of a Virtual Heritage Experience Based on the World-as-Support Interaction Paradigm;Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4656-6;NA;NA;https://doi.org/10.1145/3027063.3053089;We present the initial design stage of a Virtual Heritage experience for a bomb shelter built during the Spanish Civil War, namely Refugi 307. The shelter currently belongs to the History Museum of Barcelona which provides guided tours through the cultural heritage site for schools and the general public. The aim of the study was to define the requirements for the design of a first prototype based on the World-as-Support interaction paradigm. We conducted an ethnographic study and Participatory Design workshop to analyze different aspects of the requirements and to include multiple needs and viewpoints of the involved stakeholders. Based on the outcomes, we outline the potential for activities to foster (1) contextual-awareness between the learning content and the cultural heritage site, (2) environment-awareness in relation to missing objects in the physical space and (3) social-awareness to embody feelings related to solidarity and empathy.;2017;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;2034–2041;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8FBLPKSQ;journalArticle;2018;"Di Lascio, Elena; Gashi, Shkurta; Santini, Silvia";Unobtrusive Assessment of Students' Emotional Engagement during Lectures Using Electrodermal Activity Sensors;Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.;NA;NA;10.1145/3264913;https://doi.org/10.1145/3264913;Modern wearable devices enable the continuous and unobtrusive monitoring of human physiological parameters, including heart rate and electrodermal activity. Through the definition of adequate models these parameters allow to infer the wellbeing, empathy, or engagement of humans in different contexts. In this paper, we show that off-the-shelf wearable devices can be used to unobtrusively monitor the emotional engagement of students during lectures. We propose the use of several novel features to capture students' momentary engagement and use existing methods to characterize the general arousal of students and their physiological synchrony with the teacher. To evaluate our method we collect a data set that – after data cleaning – contains data from 24 students, 9 teachers, and 41 lectures. Our results show that non-engaged students can be identified with high reliability. Using a Support Vector Machine, for instance, we achieve a recall of 81% – which is a 25 percentage points improvement with respect to a Biased Random classifier. Overall, our findings may inform the design of systems that allow students to self-monitor their engagement and act upon the obtained feedback. Teachers could profit of information about non-engaged students too to perform self-reflection and to devise and evaluate methods to (re-)engage students.;2018-09;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;NA;NA;3;2;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"Engagement; Activity; Electrodermal; Students; Wearable";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2NAJBM6Y;journalArticle;2020;"Lin, Xin Yao; Saksono, Herman; Stowell, Elizabeth; Lachman, Margie E.; Castaneda-Sceppa, Carmen; Parker, Andrea G.";"Go&amp;Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia";Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415222;https://doi.org/10.1145/3415222;"Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&amp;Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&amp;Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&amp;Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.";2020-10;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"caregiver; exergame; intervention; people with dementia; physical activity; social connectedness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WBWYH2L9;journalArticle;2020;"Hwang, Amy S.; Jackson, Piper; Sixsmith, Andrew; Nygård, Louise; Astell, Arlene; Truong, Khai N.; Mihailidis, Alex";Exploring How Persons with Dementia and Care Partners Collaboratively Appropriate Information and Communication Technologies;ACM Trans. Comput.-Hum. Interact.;NA;1073-0516;10.1145/3389377;https://doi.org/10.1145/3389377;"Persons with dementia and their care partners have been found to adapt their own technological arrangements using commercially available information and communication technologies (ICTs). Yet, little is known about these processes of technology appropriation and how care practices are impacted. Adopting a relational perspective of care, we longitudinally examined how four family care networks appropriated a new commercial ICT service into their existing technological arrangements and care practices. Cross-case analysis interpreted collaborative appropriation to encompass two interrelated processes of creating and adapting technological practices and negotiating and augmenting care relationships. Four driving forces were also proposed: motivating meanings that actors ascribe to the technology and its use; the learnability of the technology and actors’ resourcefulness; the establishment of responsive and cooperative care practices; and the qualities of empathy and shared power in care relationships. The importance of technological literacy, learning, meaning-making, and the nature and quality of care relationships are discussed. Future work is urged to employ longitudinal and naturalistic approaches, and focus design efforts on promoting synergistic care relationships and care practices.";2020-11;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;NA;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"dementia; Alzheimer's disease; appropriation; care practices; care relationship; caregiving; case study; cognitive impairment; commercial product; family care; information and communication technologies; off-the-shelf";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
S5X89FXP;bookSection;2020;"Qiu, Lisong; Shiu, Yingwai; Lin, Pingping; Song, Ruihua; Liu, Yue; Zhao, Dongyan; Yan, Rui";What If Bots Feel Moods?;Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval;978-1-4503-8016-4;NA;NA;https://doi.org/10.1145/3397271.3401108;"For social bots, smooth emotional transitions are essential for delivering a genuine conversation experience to users. Yet, the task is challenging because emotion is too implicit and complicated to understand. Among previous studies in the domain of retrieval-based conversational model, they only consider the factors of semantic and functional dependencies of utterances. In this paper, to implement a more empathetic retrieval-based conversation system, we incorporate emotional factors into context-response matching from two aspects: 1) On top of semantic matching, we propose an emotion-aware transition network to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework; 2) We design several flexible controlling mechanisms to customize social bots in terms of emotion. Extensive experiments on two benchmark datasets indicate that the proposed model can effectively track the flow of emotions throughout a human-machine conversation and significantly improve response selection in dialogues over the state-of-the-art baselines. We also empirically validate the emotion-control effects of our proposed model on three different emotional aspects. Finally, we apply such functionalities to a real IoT application.";2020;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;1161–1170;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VDS4LM4S;bookSection;2020;"van den Berg, Carolien; Verster, Belinda";Co-Creating Social, Digital Innovation to Recognise Agency in Communities: A Learning Intervention: Research in Progress;Conference of the South African Institute of Computer Scientists and Information Technologists 2020;978-1-4503-8847-4;NA;NA;https://doi.org/10.1145/3410886.3410912;This paper presents findings from a pilot project, of an ongoing Design-Based Research (DBR) initiative, where students in an Information Systems (IS) module proposed social, digital innovations for complex problems within marginalised communities in Cape Town, South Africa. The aim of the pilot project was to develop digital innovations that recognise agency in communities through lived experiences and local knowledge. An urban planning perspective was introduced to contextualise socio-environmental challenges to ground social innovations in reality and encourage a sustainable uptake of digital innovations by communities. The IS student projects emphasised empathy, storytelling and prototyping as part of a design thinking process which both incorporated and influenced the conceptual model presented in this paper. This conceptual model informed by four design principles of - relationality, reflexivity, responsiveness and recognition - is offered as an enrichment for a learning environment. It foregrounds the development of competencies for collaborative problem solving and ultimately transdisciplinary knowledge creation.;2020;2021-02-15T21:31:58Z;2021-02-15T21:31:58Z;NA;85–93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HB4JJ3PR;conferencePaper;2017;"Köppe, Christian; Nørgård, Rikke Toft; Pedersen, Alex Young";Towards a Pattern Language for Hybrid Education;Proceedings of the VikingPLoP 2017 Conference on Pattern Languages of Program;978-1-4503-6342-6;NA;10.1145/3158491.3158504;https://doi.org/10.1145/3158491.3158504;In this paper we offer an initial framework for a pattern language of hybrid education. With the term hybrid education, we imply the use of educational design patterns that actively strive to cut across, circumventing or upheave traditional dichotomies within education such as physical-digital, academic-nonacademic, online-offline, formal-informal, learning-teaching and individual-collective. In doing so, hybrid education invites uncertainty, open-endedness, risk-taking, experimentation, critical creativity, disruption, dialogue and democracy (back) into the heart of education. Accordingly we see, within hybrid education, the promise to push against and circumvent current trends of marketization, managerialism and standardization in higher education today. Here, a pattern language for hybrid education presents an alternative way of designing for future higher education in ways that are not focused on teaching to the test, playing it safe, rankings or gaming the system approaches. Rather, hybrid education focuses on open-endedness, risk-taking, relational entanglements, experimentation, exploration and empathy. In this way, designing for hybrid education is in this paper achieved, partly by taking a decidedly value-based and vision-driven approach to learning design patterns based on philosophy in higher education and critical pedagogy, partly by working together in hybrid ways and across disciplines and domains in order to open up both the field of teaching and learning in higher education as well as the field of learning design and design patterns. The result is the almost 80 design patterns for hybrid education. The paper presents the pattern categories for hybrid education, the different design patterns contained in these. Furthermore, the pattern mining ground and workshop process, the outcome of the value workshop and the vision workshop as well as three example scenarios is described in order to show both the underlying value and vision foundation for the pattern language as well as how it plays out in concrete scenarios.;2017;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;NA;NA;NA;NA;NA;NA;NA;VikingPLoP '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Grube, Schleswig-Holstein, Germany;NA;NA;NA;"education; educational patterns; hybrid pedagogy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QJVED9WC;conferencePaper;2014;"Potter, Leigh Ellen; Korte, Jessica; Nielsen, Sue";Design with the Deaf: Do Deaf Children Need Their Own Approach When Designing Technology?;Proceedings of the 2014 Conference on Interaction Design and Children;978-1-4503-2272-0;NA;10.1145/2593968.2610464;https://doi.org/10.1145/2593968.2610464;In this paper, we focus on the question of design of technology for Deaf children, and whether the needs of these children are different from their hearing counterparts in a technology design setting. We present findings from literature together with our own observations to determine if there are distinguishing characteristics for Deaf children that may influence design sessions with them. We found that Deaf children generally have reduced literacy and slower academic progress, reduced social and emotional development, reduced empathy and a level of nervousness in novel situations, delayed language development, and limited or delayed spoken language. We also found that Deaf children are active and innovative in approaching communication, have sensitive visual attention in their peripheral vision, enhanced attention to small visual changes, and a capacity for visual learning. Finally, cultural issues within the Deaf community mean that Deaf children should be free to interact on their own terms in a design situation. We suggest that these differences merit the development of a design approach specific to the needs of Deaf children.;2014;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;249–252;NA;NA;NA;NA;NA;NA;IDC '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aarhus, Denmark;NA;NA;NA;"prototyping; child computer interaction; deaf children";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WNG7SDK3;conferencePaper;2020;Narayanan, Shrikanth Shri;Human-Centered Multimodal Machine Intelligence;Proceedings of the 2020 International Conference on Multimodal Interaction;978-1-4503-7581-8;NA;10.1145/3382507.3417974;https://doi.org/10.1145/3382507.3417974;Multimodal machine intelligence offers enormous possibilities for helping understand the human condition and in creating technologies to support and enhance human experiences [1, 2]. What makes such approaches and systems exciting is the promise they hold for adaptation and personalization in the presence of the rich and vast inherent heterogeneity, variety and diversity within and across people. Multimodal engineering approaches can help analyze human trait (e.g., age), state (e.g., emotion), and behavior dynamics (e.g., interaction synchrony) objectively, and at scale. Machine intelligence could also help detect and analyze deviation in patterns from what is deemed typical. These techniques in turn can assist, facilitate or enhance decision making by humans, and by autonomous systems. Realizing such a promise requires addressing two major lines of, oft intertwined, challenges: creating inclusive technologies that work for everyone while enabling tools that can illuminate the source of variability or difference of interest. This talk will highlight some of these possibilities and opportunities through examples drawn from two specific domains. The first relates to advancing health informatics in behavioral and mental health [3, 4]. With over 10% of the world's population affected, and with clinical research and practice heavily dependent on (relatively scarce) human expertise in diagnosing, managing and treating the condition, engineering opportunities in offering access and tools to support care at scale are immense. For example, in determining whether a child is on the Autism spectrum, a clinician would engage and observe a child in a series of interactive activities, targeting relevant cognitive, communicative and socio- emotional aspects, and codify specific patterns of interest e.g., typicality of vocal intonation, facial expressions, joint attention behavior. Machine intelligence driven processing of speech, language, visual and physiological data, and combining them with other forms of clinical data, enable novel and objective ways of supporting and scaling up these diagnostics. Likewise, multimodal systems can automate the analysis of a psychotherapy session, including computing treatment quality-assurance measures e.g., rating a therapist's expressed empathy. These technology possibilities can go beyond the traditional realm of clinics, directly to patients in their natural settings. For example, remote multimodal sensing of biobehavioral cues can enable new ways for screening and tracking behaviors (e.g., stress in workplace) and progress to treatment (e.g., for depression), and offer just in time support.The second example is drawn from the world of media. Media are created by humans and for humans to tell stories. They cover an amazing range of domains'from the arts and entertainment to news, education and commerce and in staggering volume. Machine intelligence tools can help analyze media and measure their impact on individuals and society. This includes offering objective insights into diversity and inclusion in media representations through robustly characterizing media portrayals from an intersectional perspective along relevant dimensions of inclusion: gender, race, gender, age, ability and other attributes, and in creating tools to support change [5,6]. Again this underscores the twin technology requirements: to perform equally well in characterizing individuals regardless of the dimensions of the variability, and use those inclusive technologies to shine light on and create tools to support diversity and inclusion.;2020;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;4–5;NA;NA;NA;NA;NA;NA;ICMI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Netherlands;NA;NA;NA;"emotion; behavior; computational psychology; diversity and inclusion; human signals; language; media intelligence; mental health; speech";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SLEDK7U3;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica";Good Robot Design or Machiavellian? An in-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;382–391;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
X2GRM27H;conferencePaper;2015;"Sobel, Kiley; O'Leary, Katie; Kientz, Julie A.";Maximizing Children's Opportunities with Inclusive Play: Considerations for Interactive Technology Design;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771844;https://doi.org/10.1145/2771839.2771844;Inclusive play, defined as play among children with and without disabilities, provides learning opportunities that challenge stereotypes, foster strong friendships, and help children develop empathy and other social and emotional skills. Designing technologies to support inclusive play are understudied in Human-Computer Interaction. We synthesized literature, conducted design ethnography in an inclusive classroom, and interviewed and surveyed parents and teachers to explore this problem. Our research contributes an empirical understanding of the current state of inclusive play and a characterization of the design space for interactive technologies that can support children and adults with inclusive play. We identify key facilitators of inclusive play: direct and embedded supports, transparency, adjustability, emphasis on children's interests and strengths, and current technology use. We also describe significant barriers to inclusive play: effort required to facilitate inclusive play, children's preferences, parental inexperience, and inappropriate technology. Through our discussion, we conclude that interactive technologies should be designed to harness the facilitators and help overcome the barriers in order to maximize children's opportunities with inclusive play.;2015;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;39–48;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boston, Massachusetts;NA;NA;NA;"children; human-centered design; assistive technology; inclusion; inclusive design; inclusive play; universal design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VIJN5U68;conferencePaper;2013;"Slegers, Karin; Wilkinson, Andrea; Hendriks, Niels";Active Collaboration in Healthcare Design: Participatory Design to Develop a Dementia Care App;CHI '13 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-1952-2;NA;10.1145/2468356.2468440;https://doi.org/10.1145/2468356.2468440;"This paper describes a research project aimed at developing a mealtime data registration tool for people with dementia. As to actively involve all stakeholders in this healthcare design project and to generate empathy and involvement, methods from participatory design were used. For each of the three research phases (ethnography, ideation &amp; conceptualization and prototyping) we describe our approach towards stakeholder involvement and active collaboration. We discuss lessons learned in terms of good practices and the issues we struggle with.";2013;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;475–480;NA;NA;NA;NA;NA;NA;CHI EA '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"dementia; participatory design; prototyping; healthcare";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9T4H9HCY;conferencePaper;2020;"Olson, Danielle Marie; Harrell, D. Fox, Ph.D.";“I Don't See Color”: Characterizing Players’ Racial Attitudes and Experiences via an Anti-Bias Simulation Videogame;International Conference on the Foundations of Digital Games;978-1-4503-8807-8;NA;10.1145/3402942.3409783;https://doi.org/10.1145/3402942.3409783;Videogames and learning/training applications that address racial discrimination have risen in popularity recently, coinciding with the rapid development of the field of serious (or impact) games [1, 2]. While there has been much focus on understanding the efficacy of these systems as interventions to reduce racial bias, there has been less attention paid to how individuals’ prior physical-world racial attitudes influence their experiences of such games about racial issues. Toward addressing this gap, the study presented here examines the relationships between PreK-12 educators’ colorblind racial attitudes and their game experience and narrative interpretations in narrative videogame modeling racial and ethnic socialization called Passage Home. Passage Home embeds a novel computational model and simulation informed by the Racial Encounter Coping Appraisal and Socialization Theory (RECAST) [3] to simulate a discriminatory racial encounter in a classroom setting. The system serves as a tool for assessing players’ racial and ethnic socialization (RES) experiences to support interventions for learning about racial bias. This paper presents the results of a user study deploying Passage Home with PreK-12 educators. Analysis revealed that players’ colorblind racial attitudes and ethnic identity were related to their in-game racial appraisal and feelings of competence, negative affect, and empathy in the game. Given the prevalence of colorblind racial ideology across racial and ethnic groups in the United States [4, 5], we propose an initial typology of players’ colorblind racial attitudes emerging from this analysis to aid in the future development of serious game interventions addressing racial discrimination.;2020;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;NA;NA;NA;NA;NA;NA;NA;FDG '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bugibba, Malta;NA;NA;NA;"human-computer interaction; Avatars; serious games; social identity; reflection; educational game; game design; identity; impact games; interactive narrative; racial discrimination; serious play; transformative education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2RUCF9G4;conferencePaper;2017;"Vieira, Suanny; Santos, Alexandre; Costa, Rostand; Maritan, Tiago; Aschoff, Manuella; Veríssimo, Vinícius";A Study on the Use of Multiple Avatars in 3D Sign Language Dictionaries;Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web;978-1-4503-5096-9;NA;10.1145/3126858.3126865;https://doi.org/10.1145/3126858.3126865;Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors.;2017;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;325–332;NA;NA;NA;NA;NA;NA;WebMedia '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gramado, RS, Brazil;NA;NA;NA;"accessibility; avatar; machine translation; retargeting; sign language";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QAISANGT;conferencePaper;2019;"Munteanu, Cosmin; Oviatt, Sharon";CHI 2019 Early Career Development Symposium;Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5971-9;NA;10.1145/3290607.3298999;https://doi.org/10.1145/3290607.3298999;The first few years after completing a PhD can be challenging to navigate. Job hunting, interviewing, navigating new contexts such as a junior academic position, applying for funding as a first time project investigator, learning to adapt to the culture of an industry-based workplace, supervising graduate students or full-time employees - these are just a few of the scenarios recent PhD graduates find themselves in. Within HCI, one may encounter more discipline-specific challenges, such as keeping up with the CHI publication cycles while taking on new administrative duties. The CHI community, however, strives to be collectively supportive and inclusive of researchers at all stages of their career - this is even more important as many of our design approaches are rooted in empathy for and empowerment of participants. By more actively supporting each other as researchers in our career paths, we can better grow as a community, and reflect it back into our collective body of practice. The Early Career Development Symposium has been proposed (and held yearly since 2016) to provide a more formal mentoring venue that reflects our aims as a community to more meaningfully support each other.;2019;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;1–5;NA;NA;NA;NA;NA;NA;CHI EA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"mentoring; early career; post phd";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MZPXICI2;conferencePaper;2020;"Groeneveld, Wouter; Jacobs, Hans; Vennekens, Joost; Aerts, Kris";Non-Cognitive Abilities of Exceptional Software Engineers: A Delphi Study;Proceedings of the 51st ACM Technical Symposium on Computer Science Education;978-1-4503-6793-6;NA;10.1145/3328778.3366811;https://doi.org/10.1145/3328778.3366811;Important building blocks of software engineering concepts are without a doubt technical. During the last decade, research and practical interest for non-technicalities has grown, revealing the building blocks to be various skills and abilities beside pure technical knowledge. Multiple attempts to categorise these blocks have been made, but so far little international studies have been performed that identify skills by asking experts from both the industrial and academic world: which abilities are needed for a developer to excel in the software engineering industry? To answer this question, we performed a Delphi study, inviting 36 experts from 11 different countries world-wide, affiliated with 21 internationally renowned institutions. This study presents the 55 identified and ranked skills as classified in four major areas: communicative skills (empathy, actively listening, etc.), collaborative skills (sharing responsibility, learning from each other, etc.), problem solving skills (verifying assumptions, solution-oriented thinking, etc.), and personal skills (curiosity, being open to ideas, etc.), of which a comparison has been made between opinions of technical experts, business experts, and academics. We hope this work inspires educators and practitioners to adjust their training programs, mitigating the gap between the industry and the academic world.;2020;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;1096–1102;NA;NA;NA;NA;NA;NA;SIGCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, OR, USA;NA;NA;NA;"delphi study; industry requirements; non-cognitive abilities; professional skills; software developer; software engineering edutation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4Z7VQTLX;conferencePaper;2014;Matsuzawa, Tetsuro;Evolution of Human Mind and Culture Viewed from the Study of Chimpanzees;"Proceedings of the 5th ACM International Conference on Collaboration across Boundaries: Culture, Distance &amp; Technology";978-1-4503-2557-8;NA;10.1145/2631488.2637432;https://doi.org/10.1145/2631488.2637432;"I have studied chimpanzees both in the wild and in the laboratory. My talk illustrates the evolutionary origins of human mind and culture. The human mother–infant relationship is characterized by physical separation, and the stable supine posture of infants; enabling face-to-face communication via facial expressions, vocal exchange, and manual gestures, and also demonstration of object manipulation. I have used the novel ""participant observation"" method in the laboratory and through ""field experiments"" in their natural habitat. There are several critical differences between the two species: chimpanzees lack the social referencing ability observed in human children and chimpanzees seldom engage in active teaching. Moreover, although young chimpanzees showed unique working memory capacity, often superior to that of human adults, they are less able to learning symbols. In sum, mind and culture in humans is fundamentally influenced by the manner of raising young children; characterized by collaboration among multiple adults. This aspect of human rearing may be linked to the development of empathy, altruistic behavior, reciprocity, understanding others? minds, and so on. Taken together, my talk presents evolutionary and ontogenetic explanations for the uniquely human cognition and culture.";2014;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;141;NA;NA;NA;NA;NA;NA;CABS '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Kyoto, Japan;NA;NA;NA;"evolution; culture; chimpanzees and human comparison";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
92SU6BNQ;conferencePaper;2018;McDonald, Heidi;IThirve Games Empathy Jam at DigiPen;Proceedings of the International Conference on Game Jams, Hackathons, and Game Creation Events;978-1-4503-6484-3;NA;10.1145/3196697.3196704;https://doi.org/10.1145/3196697.3196704;This Event Report concerns the Empathy Jam iThrive Games held in cooperation with DigiPen Institute of Technology in Seattle, WA, on September 15-17, 2017. iThrive Games is a nonprofit that exists to create meaningful opportunities for teens to enhance the knowledge, mindsets, and skills they need to thrive across development, to engage actively in their learning and in their community, and to be healthy. We embrace the positive potential of games, and find a strengths-based approach to be especially important to this work. Game Jams are an important way that iThrive can educate and perform developer outreach in accordance with our mission. We do game jams at universities and regional game festivals, with the goal of bringing together people to build games together using our science based, expert-developed design resources (available for free download at the iThrive Games website: www.ithrivegames.org) to help developers make games toward prosocial outcomes. Our jams not only demonstrate what kinds of games can result from these design concepts, but are also important events to foster ongoing collaboration and to facilitate mentoring relationships at multiple levels. These jams also allow us to test and refine our design resources with the help of the people they are intended for.;2018;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;28–33;NA;NA;NA;NA;NA;NA;ICGJ 2018;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Francisco, CA, USA;NA;NA;NA;"serious games; empathy games; games for teens; iThrive Games; jams for teens; kindness games; prosocial outcomes; social emotional learning; teen development; transformational frameworks; transformational games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JQQK8XLV;journalArticle;2019;"Not, Elena; Cavada, Dario; Maule, Stefano; Pisetti, Anna; Venturini, Adriano";Digital Augmentation of Historical Objects Through Tangible Interaction;J. Comput. Cult. Herit.;NA;1556-4673;10.1145/3297764;https://doi.org/10.1145/3297764;The technological advances brought about by the Internet of Things enable new opportunities for a more direct interaction among users, objects, and places. This is an extremely valuable innovation for the cultural heritage sector, as it allows a more transparent use of technology in the digital augmentation of museums and cultural heritage sites. The possibility to augment physical objects with sensors detecting when they are moved and manipulated enables scenarios where descriptive information about objects is presented to users at the very exact time they are looking at them, stimulating engagement. This article describes a collaborative research effort among cultural heritage professionals, human–computer interaction experts, and developers that was aimed at investigating the goals and constraints curators consider for a physical encounter between visitors and historic relics. In a case study, we co-designed an interactive plinth centred on tangible interaction and evaluated the impact on the user experience of combining digital information with a hands-on experience of relics of World War I. Our findings show that visitors value this type of tangible interaction with collection objects positively, as it allows the discovery of details and the learning of aspects that normally go unnoticed. The synergy between physical and digital aspects stimulates empathy with the original users of the object and fosters social interaction.;2019-06;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;NA;NA;3;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"internet of things; Digitally augmented objects; museum experience; tangible and embodied interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Z4MZTRTA;bookSection;2020;"Ranjbartabar, Hedieh; Richards, Deborah; Bilgin, Ayse Aysin; Kutay, Cat; Mascarenhas, Samuel";User-Models to Drive an Adaptive Virtual Advisor: Demonstration;Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems;978-1-4503-7518-4;NA;NA;NA;Agents that adapt to their user need to have knowledge of their user and expertise on how best to adapt to that type of user. In this paper we describe the addition of an agent's expertise and collection of machine-learnt user profiles to the proposed extended FAtiMA (Fearnot AffecTive Mind Architecture) cognitive agent architecture. A study to evaluate the extended architecture is presented which compares the benefit (i.e. reduced stress and increased rapport) of tailoring dialogue (i.e. empathic or neutral) to the specific user.;2020;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;2117–2119;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MWYH7UM2;conferencePaper;2017;Chapman, Gail;Inspire, Innovate, Improve! What Does This Mean for CS for All?;Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education;978-1-4503-4698-6;NA;10.1145/3017680.3025047;https://doi.org/10.1145/3017680.3025047;"In January 2016, President Obama unveiled the CS for All initiative. With all the attention and publicity surrounding CS for All and increased support from a variety of corners over the ensuing year, it is easy to become complacent and start believing that we have ""arrived"". During her 2016 SIGCSE keynote, Jan Cuny talked about catching the wave and using it to our advantage. This talk will focus on where we go from here. We caught the wave; now what do we do to ensure that we don't get swallowed by it? What lessons can be learned from an election that featured the likes of fake news, Wiki leaks, rogue email servers, runaway tweets and showed in stark relief the divides that exist in our country. Computer science represents one of those divides. Given this and the fact that addressing the educational inequities prevalent in computer science was front and center in the CS for All announcement, what better time is there to renew our commitment to broadening participation in computing? As educators we have a powerful opportunity and responsibility in the wake of the blowback from the election-to educate, to listen, to remind ourselves constantly that we live in a very diverse country. We have no shortage of innovation in computer science, but who are we inspiring, what impact are those innovations having, and what can we do to learn from the lessons of the past to improve CS education? And above all, how do we respond to the challenges before us with empathy for those who are impacted by the decisions we make?";2017;2021-02-15T21:31:59Z;2021-02-15T21:31:59Z;NA;1;NA;NA;NA;NA;NA;NA;SIGCSE '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seattle, Washington, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
G9ZXU3U2;journalArticle;2013;Andre, Elisabeth;Exploiting Unconscious User Signals in Multimodal Human-Computer Interaction;ACM Trans. Multimedia Comput. Commun. Appl.;NA;1551-6857;10.1145/2502433;https://doi.org/10.1145/2502433;This article presents the idea of empathic stimulation that relies on the power and potential of unconsciously conveyed attentive and emotional information to facilitate human-machine interaction. Starting from a historical review of related work presented at past ACM Multimedia conferences, we discuss challenges that arise when exploiting unconscious human signals for empathic stimulation, such as the real-time analysis of psychological user states and the smooth adaptation of the human-machine interface based on this analysis. A classical application field that might benefit from the idea of unconscious human-computer interaction is the exploration of massive datasets.;2013-10;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;NA;NA;1s;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"Emotion recognition; multimodal interfaces; social signal processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8MWVSUHK;conferencePaper;2019;Vertesi, Janet;Seeing like a Rover: Team Work and Human-Robot Relations;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;"How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go — in search and rescue operations, ocean voyages, or even into space — they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology.This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team.Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.";2019;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;152;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;"human-robot interaction; teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LR8TMACP;conferencePaper;2013;"Ramírez, Ricardo; Parthasarathy, Balaji; Gordon, Andrew";From Infomediaries to Infomediation at Public Access Venues: Lessons from a 3-Country Study;Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1;978-1-4503-1906-5;NA;10.1145/2516604.2516621;https://doi.org/10.1145/2516604.2516621;This study investigated the role of infomediaries to understand the process of infomediation in shaping outcomes for users at public access venues (PAVs) in Bangladesh, Chile and Lithuania. We examined the extent to which technical skills and empathy are relevant to and appreciated by different types of users, and whether differences in infomediaries are evident across different types of PAVs. We asked whether particular infomediary behaviours were associated with outcome differences as reported by PAV users. We learned that infomediaries provide the human face for the information age by taking on the functions of facilitation, coaching, referral and teaching, and by assuming the role of a trusted gatekeeper. The process of infomediation turned out to be of prominence, within which the infomediary is a key component. In the absence of infomediaries, those left behind (or excluded due to their age, socio-economic status, level of education/literacy, gender, disability or caste) will face additional, perhaps insurmountable, barriers.;2013;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;124–132;NA;NA;NA;NA;NA;NA;ICTD '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Cape Town, South Africa;NA;NA;NA;"empathy; information and communication technologies; brokering; ICTD; infomediary; infomediation; public access";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7AR7BEN8;conferencePaper;2020;"Branco, Karina da S. C.; Oliveira, Rhenara A.; Silva, Francisco L. Q. da; de H. Rabelo, Jacilane; Marques, Anna B. S.";Does This Persona Represent Me? Investigating an Approach for Automatic Generation of Personas Based on Questionnaires and Clustering;Proceedings of the 19th Brazilian Symposium on Human Factors in Computing Systems;978-1-4503-8172-7;NA;10.1145/3424953.3426648;https://doi.org/10.1145/3424953.3426648;"Personas are fictional representations of an end user based on data collected from a specific target audience. The creation of personas takes time, because part of the process is manual, which causes difficulties during the stages of data generation and analysis, if the data sample is large. The present work aims to investigate the results of the automatic generation of personas through a questionnaire and the Clustering method. Initially, a questionnaire was applied in order to outline the profile of students in the Computer Science and Software Engineering courses at the university Federal of Ceará. 130 responses were obtained from this applied questionnaire. The automatic generation of personas used the collected responses as a database, these data were applied to the Clustering method. From Clustering, using a specific tool for this purpose, it was possible to generate four personas automatically. In relation to the data generated from the personas, it was possible to identify some characteristics, such as: (a) course choice factor: the opportunity to work with new technologies, influence of family and friends and the possibility of living abroad; (b) factor of withdrawal from the course: lack of identification with the course, learning difficulties in the disciplines and finance; and, (c) area of interest: software engineering, human-computer interaction and computer graphics. A new questionnaire was applied in order to validate the personas generated in relation to credibility, empathy and similarity. Based on the results obtained, it was observed that two of the four personas generated achieved greater prominence in relation to the validation criteria, showing that the personas look like real people, students think like the personas and share similar interests.";2020;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;NA;NA;NA;NA;NA;NA;NA;IHC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Diamantina, Brazil;NA;NA;NA;"personas; clustering; automatic generation of personas; personas validation; questionnaire";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TKAFUXG6;conferencePaper;2014;"Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth";Towards a Serious Game Playing Empathic Robotic Tutorial Dialogue System;Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2658-2;NA;10.1145/2559636.2563707;https://doi.org/10.1145/2559636.2563707;There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.;2014;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;180–181;NA;NA;NA;NA;NA;NA;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bielefeld, Germany;NA;NA;NA;"serious games; dialogue management; empathic robotic tutor; tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PLWX2ZB5;conferencePaper;2010;"Rivera, Fiona; Watten, Phil; Holroyd, Patrick; Beacher, Felix; Mania, Katerina; Critchley, Hugo";Real-Time Compositing Framework for Interactive Stereo FMRI Displays;ACM SIGGRAPH 2010 Posters;978-1-4503-0393-4;NA;10.1145/1836845.1836862;https://doi.org/10.1145/1836845.1836862;This research concentrates on providing high fidelity animation, only achievable with offline rendering solutions, for interactive fMRI-based experiments. Virtual characters are well established within the film, game and research worlds, yet much remains to be learned about which design, stylistic or behavioural factors combine to make a believable character. The definition of believability depends on context. When designing and implementing characters for entertainment, the concern is making believable characters that the audience will engage with. When using virtual characters in experiments, the aim is to create characters and synthetic spaces that people respond to in a similar manner to their real world counterparts. Research has shown that users show empathy for virtual characters. However, uncanny valley effects – ie dips in user impressions – can arise: behavioural fidelity expectations increase alongside increases in visual fidelity and vice versa. Often, characters used within virtual environments tend to be of fairly low fidelity due to technological constraints including rendering in real-time (Garau et al. 2003). This problem is addressed here by using non-linear playback and compositing of pre-rendered high fidelity sequences.;2010;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;NA;NA;NA;NA;NA;NA;NA;SIGGRAPH '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Los Angeles, California;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JTPBR4DN;conferencePaper;2019;"Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios";Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability;Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments;978-1-4503-6232-0;NA;10.1145/3316782.3322767;https://doi.org/10.1145/3316782.3322767;"Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.";2019;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;442–447;NA;NA;NA;NA;NA;NA;PETRA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Rhodes, Greece;NA;NA;NA;"age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TJKU3A9E;conferencePaper;2020;"Bastos, João Antonio D. M.; de Mello, Rafael Maiani; Garcia, Alessandro";Colloquy: A Method for Conversational API Design;Proceedings of the 34th Brazilian Symposium on Software Engineering;978-1-4503-8753-8;NA;10.1145/3422392.3422468;https://doi.org/10.1145/3422392.3422468;APIs (application programming interfaces) play a key role in software development. Virtually, all programmers are potential users of third-party APIs. From the perspective of the theory of Semiotic Engineering, we may characterize an API as an artifact mediating the communication between two types of developers: the API designers and its users. During the construction of an API, the designers should establish proper dialogues with the users. These dialogues will enable the conversation of these actors at the interaction time. In this way, we define a conversational API as an API capable of offering effective dialogues to its users. In this paper, we introduce Colloquy, a method for supporting the design of conversational APIs. Colloquy results from the lessons learnt during an action research conducted for redesigning a real and complex API. The set of Colloquy resources allow API designers to go beyond conventional concerns with usability. We also report in this paper a case study in which Colloquy was used for redesigning a refactoring API. The study findings indicate the method helped the designer creating empathy with the API users, as well as better reflecting and depicting the requirements and the conversations that the API should attend to the different user profiles.;2020;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;514–519;NA;NA;NA;NA;NA;NA;SBES '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Natal, Brazil;NA;NA;NA;"API Conversacional; Engenharia Semiótica; Método de Design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NKBNUKME;conferencePaper;2018;"Bosch, Esther; Oehl, Michael; Jeon, Myounghoon; Alvarez, Ignacio; Healey, Jennifer; Ju, Wendy; Jallais, Christophe";Emotional GaRage: A Workshop on In-Car Emotion Recognition and Regulation;Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications;978-1-4503-5947-4;NA;10.1145/3239092.3239098;https://doi.org/10.1145/3239092.3239098;In-car emotion detection and regulation have become an emerging and important branch of research within the automotive domain. Different emotional states can greatly influence human driving performance and user experience both in manual and automated driving conditions. The monitoring and regulation of relevant emotional states is therefore important to avoid critical driving scenarios with the human driver being in charge, and to ensure comfort and acceptance in autonomous driving. In this workshop we want to discuss the empathic user interface research to address challenges and opportunities and to reveal new research directions for future work. This workshop provides a forum for exchange and discussion on empathic user interfaces, including methods for emotion recognition and regulation, empathic automotive human-machine interaction design, user evaluation and measurements, and subsequent improvement of autonomous driving experience.;2018;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;44–49;NA;NA;NA;NA;NA;NA;AutomotiveUI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, ON, Canada;NA;NA;NA;"user acceptance; Driver state assessment; emotion recognition and regulation; empathic vehicles";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U2ZKL2B4;conferencePaper;2016;"Chisik, Yoram; Mancini, Clara";Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans;Proceedings of the 14th Participatory Design Conference: Short Papers, Interactive Exhibitions, Workshops - Volume 2;978-1-4503-4136-3;NA;10.1145/2948076.2948093;https://doi.org/10.1145/2948076.2948093;Participatory Design strives to broaden the perspective of and increase empathy in design by giving specific and often under represented user groups, such as children or older people, a voice in the design process. The exact nature of the role played by such participants in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the participatory design community. The emerging field of Animal Computer Interaction, which seeks to empower animals through user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.;2016;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;123–124;NA;NA;NA;NA;NA;NA;PDC '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aarhus, Denmark;NA;NA;NA;"children; participatory design; ACI; animal computer interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NSCCK2J5;conferencePaper;2014;"Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei";The Fugitive: A Robot in the Wild;Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2658-2;NA;10.1145/2559636.2559653;https://doi.org/10.1145/2559636.2559653;The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building.The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not.The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on.The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol.The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.;2014;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;111;NA;NA;NA;NA;NA;NA;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bielefeld, Germany;NA;NA;NA;"human-robot interaction; social robotics; robots in the wild";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DCPACUQQ;bookSection;2017;"Chisik, Yoram; Mancini, Clara";Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans;Proceedings of the 2017 Conference on Interaction Design and Children;978-1-4503-4921-5;NA;NA;https://doi.org/10.1145/3078072.3081311;Participatory Design with children strives to broaden the perspective of and increase empathy in design for the needs and desires of children by giving children a voice in the design process. The exact nature of the role played by children in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the IDC community. The emerging field of Animal Computer Interaction, which seeks to empower animals through the participatory design of user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.;2017;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;753–756;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LANF7YV8;bookSection;2017;"Cole, Amelia W.; Quesnel, Denise T.; Pekçetin, Serkan; Gromala, Diane; O'Brien, Heather; Antle, Alissa N.; Riecke, Bernhard E.";Integrating Affective Responses and Gamification into Early Reading Acquisition Software Applications;Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play;978-1-4503-5111-9;NA;NA;https://doi.org/10.1145/3130859.3131433;Sisu is a gamified learning application designed to assist school-aged children who are struggling to read. Sisu utilizes readily-available technology to promote learning at home, with unique elements tied to the learning experience: (1) a spelling game with (2) an empathic agent, and (3) a mini-game. The empathic agent utilizes a facial action coding system (FACS) to recognize core expressions of the child user and respond to the child's affect in-game. We anticipate that Sisu's accessible and affective nature will not only support children's emotional needs, but the addition of gamified elements will motivate them to practice reading and assist them in their learning objectives.;2017;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;73–85;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XYPYV5TS;conferencePaper;2018;Spaulding, Samuel;Personalized Robot Tutors That Learn from Multimodal Data;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.;2018;2021-02-15T21:32:00Z;2021-02-15T21:32:00Z;NA;1781–1783;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"human-robot interaction; social robotics; multimodal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ENQLCA5E;journalArticle;2020;"McDonald, Nora; Pan, Shimei";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415218;https://doi.org/10.1145/3415218;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.;2020-10;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"artificial intelligence; ethics; algorithm bias; education; intersectionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2K9T9V3Z;conferencePaper;2019;"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania";Ballbit Adventure: A Physical Game for a Collaborative Racing;Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-6871-1;NA;10.1145/3341215.3356982;https://doi.org/10.1145/3341215.3356982;Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.;2019;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;97–103;NA;NA;NA;NA;NA;NA;CHI PLAY '19 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NB5BCB6K;conferencePaper;2013;"Wagner, Johannes; Lingenfelser, Florian; André, Elisabeth; Mazzei, Daniele; Tognetti, Alessandro; Lanatà, Antonio; De Rossi, Danilo; Betella, Alberto; Zucca, Riccardo; Omedas, Pedro; Verschure, Paul F. M. J.";A Sensing Architecture for Empathetic Data Systems;Proceedings of the 4th Augmented Human International Conference;978-1-4503-1904-1;NA;10.1145/2459236.2459253;https://doi.org/10.1145/2459236.2459253;Today's increasingly large and complex databases require novel and machine aided ways of exploring data. To optimize the selection and presentation of data, we suggest an unconventional approach. Instead of exclusively relying on explicit user input to specify relevant information or to navigate through a data space, we exploit the power and potential of the users' unconscious processes in addition. To this end, the user is immersed in a mixed reality environment while his bodily reactions are captured using unobtrusive wearable devices. The users' reactions are analyzed in real-time and mapped onto higher-level psychological states, such as surprise or boredom, in order to trigger appropriate system responses that direct the users' attention to areas of potential interest in the visualizations. The realization of such a close experience-based human-machine loop raises a number of technical challenges, such as the real-time interpretation of psychological user states. The paper at hand describes a sensing architecture for empathetic data systems that has been developed as part of such a loop and how it tackles the diverse challenges.;2013;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;96–99;NA;NA;NA;NA;NA;NA;AH '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Stuttgart, Germany;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8JRJXDJX;conferencePaper;2016;"Lim, Mei Yii; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Hall, Lynne";A Treasure Hunt With An Empathic Virtual Tutor: (Demonstration);"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;"We present a demonstration of a Treasure Hunt Application with an Empathic Virtual Tutor. During the treasure hunt, this empathic agent adapts its interaction based on the affective state of the user to improve learning experience. We demonstrate the application domain; the technology used; and the app focusing on the empathic strategies applied.";2016;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;1477–1478;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"human-agent interaction; valence; arousal; empathic agent; treasure hunt";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KEWTXP46;journalArticle;2020;"Cotler, Jami L.; Villa, Luis; Burshteyn, Dmitry; Bult, Zachary; Grant, Garrison; Tanski, Michael; Parente, Anthony";An Interdisciplinary Approach to Detecting Empathy through Emotional Analytics and Eye Tracking;J. Comput. Sci. Coll.;NA;1937-4771;NA;NA;"The aim of this interdisciplinary study was to bring together different perspectives to discover if detecting empathetic emotional reactions is possible. This area of research has received recent attention from the computer science, human-computer interaction and psychological research communities. The research team consisted of three students; a computer science, sociology and marketing major. The team worked to understand the complexities of detecting emotions based on facial movement. The team collected time stamped facial emotional data from 210 participants as they watched a video clip from the popular movie depicting bullying behavior towards a disabled person. The results demonstrated significant before-and- after mean differences in emotions that are characterized as empathic towards the main character for the bullying events, which is a promising start to detecting empathic reactions. Each student brought a different perspective from their majors resulting in an educational experience that transcended learning about emotional analytics.";2020-04;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;87–95;NA;8;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8P3SUXZG;conferencePaper;2016;"Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan";Semi-Supervised Model Personalization for Improved Detection of Learner's Emotional Engagement;Proceedings of the 18th ACM International Conference on Multimodal Interaction;978-1-4503-4556-9;NA;10.1145/2993148.2993166;https://doi.org/10.1145/2993148.2993166;Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.;2016;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;100–107;NA;NA;NA;NA;NA;NA;ICMI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QEIAI35R;conferencePaper;2015;"Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana";The Empathic Robotic Tutor: Featuring the NAO Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702100;https://doi.org/10.1145/2701973.2702100;We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.;2015;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;285;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"educational robotics; empathic robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8TX7WJGS;conferencePaper;2019;Tchetgen, Pierre-Valery Njenji;DRUMBALL: Multimodal Meaning Production through Digital Drum Talk;Proceedings of the 2019 on Creativity and Cognition;978-1-4503-5917-7;NA;10.1145/3325480.3326544;https://doi.org/10.1145/3325480.3326544;In this demonstration, I present an interactive prototype of the Drumball system, an embodied learning environment that allows for drum patterns to be turned into and used as letters, words or phrases. The system acts as a transducer of rhythmic input into multimodal output, and was designed to investigate the affordances of this embodied learning approach on the early literacy skills acquisition of children. The project follows a design thinking process (empathize, define, ideate, prototype, test) to explore cultural systems as a grounding for learning technologies design. The session provides a space to think beyond the traditional keypad interface and its reliance on alphabetic input, to explore how the application of the talking drum cultural system in the domain of human-computer interaction can be used to transform children's early experiences with literacy. I will demonstrate creating sequences of letters and words using the system by playing drum tones of varying pitches (tone, slap and bass).;2019;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;513–517;NA;NA;NA;NA;NA;NA;"C&amp;C '19";NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Diego, CA, USA;NA;NA;NA;"embodied learning; culturally-grounded pedagogies and technologies; drum language; haptic devices; interaction paradigm; literacy development";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3LLRH42Z;conferencePaper;2019;"Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher";Mutual Reinforcement Learning with Robot Trainers;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.;2019;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;572–573;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N5ASQKE6;conferencePaper;2016;Alyuz, Nese;Shaping the Future of Education with Empathic Companions;Proceedings of the 2nd Workshop on Emotion Representations and Modelling for Companion Systems;978-1-4503-4558-3;NA;10.1145/3009960.3009964;https://doi.org/10.1145/3009960.3009964;With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.;2016;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;NA;NA;NA;NA;NA;NA;NA;ERM4CT '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XPQY3WKM;conferencePaper;2010;Regazzoni, Carlo S.;Emphatic Human Interaction Analysis for Cognitive Environments;Proceedings of the First ACM International Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams;978-1-4503-0163-3;NA;10.1145/1877868.1877870;https://doi.org/10.1145/1877868.1877870;"Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment.Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available.Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation.Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world.Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it).Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.";2010;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;1–2;NA;NA;NA;NA;NA;NA;ARTEMIS '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Firenze, Italy;NA;NA;NA;"ambient intelligence; cognitive surveillance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7S2N4L7P;conferencePaper;2019;"Gu, Xiusen; Xu, Weiran; Li, Si";Towards Automated Emotional Conversation Generation with Implicit and Explicit Affective Strategy;Proceedings of the 2019 International Symposium on Signal Processing Systems;978-1-4503-6241-2;NA;10.1145/3364908.3365288;https://doi.org/10.1145/3364908.3365288;Building an empathic conversation machine in open-domain is a promising research topic in natural language processing. However, most current approaches rely on designated emotions to conduct generating responses and lack the ability to decide the appropriate emotion strategy. In this paper, we propose a dialogue model of jointly predicting and generating emotions called DRCVAE, which stands for Decoupled Representations of Conditional Variational Autoencoders.More specifically, the model separates the latent variable in conditional variational autoencoders (CVAE) into two parts: emotion and content. Then the latent emotional strategy (implicit) is further forced to predict the target emotion probability distribution (explicit). By using implicit and explicit emotional strategy, a newly designed paired decoder incorporates rich control information to decode the response. Experiment results demonstrate that DRCVAE provides an effective way to infer target emotions and generate high-quality responses simultaneously.;2019;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;125–130;NA;NA;NA;NA;NA;NA;SSPS 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Beijing, China;NA;NA;NA;"Emotional dialogue system; CVAE; decoupled representations; paired decoder";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R5RRH8P2;conferencePaper;2011;"Lee, Jung-Joo; Vaajakallio, Kirsikka; Mattelmäki, Tuuli";Tracing Situated Effects of Innovative Design Methods: Inexperienced Designers' Practices;Procedings of the Second Conference on Creativity and Innovation in Design;978-1-4503-0754-3;NA;10.1145/2079216.2079231;https://doi.org/10.1145/2079216.2079231;"In recent years the design research community has been active in developing new methods for user involvement and collaboration in the design process. The new methods, often called innovative design methods, correspond more to designer's genuine ways of thinking and working than do traditional user-centered ones. The entire purpose of innovative method is to allow for designer's creativity in the design of method and reflective learning, instead of relying on predefined rules of method. For this reason, codification and scientific evaluation are often regarded very challenging, if meaningful at all. This leads us to raise a question; what could be relevant ways of framing and communicating innovative design methods to better capture their nature and value?As one attempt to explore this question, our study takes a close look at inexperienced designers' practices with innovative methods, such as probes or co-design workshops. We chose students as research subjects because their situated actions – and the challenges they face in understanding and applying these methods – reveal just kind of knowledge about the innovative methods that needs to be communicated. To do this, we analyzed students' learning diaries written during the design course. When the students reported uncertainties and disappointments due to 'ill-defined' nature of such methods, we were able to trace the reasons for disappointments. We also found that the innovative design methods in fact supported the students for empathic learning and design inspiration from the making process of the methods.";2011;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;103–113;NA;NA;NA;NA;NA;NA;DESIRE '11;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Eindhoven, Netherlands;NA;NA;NA;"empathic design; co-design; design education; innovative design methods";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
INHM4BIB;conferencePaper;2013;"Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria";3D Animated Agent for Tutoring Based on WebGL;Proceedings of the 18th International Conference on 3D Web Technology;978-1-4503-2133-4;NA;10.1145/2466533.2466534;https://doi.org/10.1145/2466533.2466534;"The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.";2013;2021-02-15T21:33:24Z;2021-02-15T21:33:24Z;NA;129–134;NA;NA;NA;NA;NA;NA;Web3D '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Sebastian, Spain;NA;NA;NA;"artificial intelligence; e-learning; virtual agents; Web3D technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JIMUS7EW;conferencePaper;2017;"Ranjbartabar, Hedieh; Richards, Deborah";Student Designed Virtual Teacher Feedback;Proceedings of the 9th International Conference on Computer and Automation Engineering;978-1-4503-4809-6;NA;10.1145/3057039.3057083;https://doi.org/10.1145/3057039.3057083;Interactive virtual learning environments (VLEs) have significant potential to influence students' learning achievements. Characters in these VLEs can act as a virtual peers and teachers by providing empathic responses tailored to the affective state of the students. Designing appropriate dialogues and feedback will be important in achieving the desired outcomes such as increased engagement, motivation and achievement. In this paper we report our findings from a study with 19 girls in Year 8 and 9 at high school using the Omosa VLE. The study investigated student responses to the initial dialogues we designed to elicit their emotional state and provide support. Analysis of responses and alternative dialogues offered by the students revealed that the feedback provided by our characters was mostly acceptable, but further improvements should be made to include elements such as self-disclosure and more helpful dialogue.;2017;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;26–30;NA;NA;NA;NA;NA;NA;ICCAE '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Sydney, Australia;NA;NA;NA;"Omosa; empathic virtual agent; Virtual learning environment; virtual world";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LHP9296W;journalArticle;2020;"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung";The Design and Implementation of XiaoIce, an Empathetic Social Chatbot;Comput. Linguist.;NA;0891-2017;10.1162/coli_a_00368;https://doi.org/10.1162/coli_a_00368;This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human–machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.;2020-03;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;53–93;NA;1;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: Cambridge, MA, USA Publisher: MIT Press;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6826YGWH;conferencePaper;2020;"Latulipe, Celine; Provencal, Sarah; Frevert, Tonya";Challenging Social Exclusion in Computing via 'Theatre of the Oppressed' Pedagogy;Proceedings of the 51st ACM Technical Symposium on Computer Science Education;978-1-4503-6793-6;NA;10.1145/3328778.3367008;https://doi.org/10.1145/3328778.3367008;Micro-aggressions, hostile climates, and intersectional discrimination contribute to students feeling excluded from fully participating in Computer Science or other STEM programs. To address this exclusion, students need to empathize with each other, and for that we need them to be having frank, open conversations about difficult situations. This is hard to achieve, as people do not typically want to talk about difficult situations with strangers. Computer Science faculty may shy away from these difficult conversations, as they may feel they lack the expertise to address social issues effectively. To address this issue, we have been conducting 'Exclusion Response Workshops' based on the 'Theatre of the Oppressed' methodology of rehearsing social change. This involves students anonymously contributing scenarios of micro-aggressions they have experienced or witnessed and then roleplaying alternate outcomes. These workshops create an empathetic environment for frank and open discussion of difficult issues. We have been scaling this effort by conducting workshops with all freshmen and transfer students in our College of Computing and Informatics. In this SIGCSE workshop, attendees will participate in an Exclusion Response Workshop, then have an open discussion about the workshop experience, workshop logistics, and pros and cons of running this workshop as a mandatory class activity versus a voluntary activity. Participants will learn about the workshop structure, and the Theatre of the Oppressed methodology. This workshop is a taste of a 3-day, train-the-trainer workshop that we will be conducting at our institution in May 2020. Supported by NSF IUSE/RED Award #151960.;2020;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1395;NA;NA;NA;NA;NA;NA;SIGCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, OR, USA;NA;NA;NA;"diversity; inclusion; participatory-theatre; theatre-of-the-oppressed";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SZFVN6KC;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: An Edible Living Media Installation;Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction;978-1-4503-2635-3;NA;10.1145/2540930.2555209;https://doi.org/10.1145/2540930.2555209;In the face of increasing urbanization and lack of contact with nature, it is important to design systems that facilitate a re-connection or at least dialogue around our interaction with living beings. Rafigh, an empathetic living media interface, is designed to motivate children and adults to care for a living mushroom colony by engaging in collaborative and learning activies.;2014;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;345–346;NA;NA;NA;NA;NA;NA;TEI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Munich, Germany;NA;NA;NA;"embedded computing; living media interfaces";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MBVEMG8X;conferencePaper;2016;"Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid";Map Reading with an Empathic Robot Tutor;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.;2016;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;567;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Christchurch, New Zealand;NA;NA;NA;"empathy; robot-child interaction; robotic tutor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DMBNDYP7;conferencePaper;2015;"Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro";An Empathic Robotic Tutor in a Map Application;Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems;978-1-4503-3413-6;NA;NA;NA;In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.;2015;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1923–1924;NA;NA;NA;NA;NA;NA;AAMAS '15;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Istanbul, Turkey;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CYQ3M8KW;conferencePaper;2012;Taylor, Jason;The Trade Aid Computer Kiosk: Inclusive and Human Centred Design Technology at the Point of Sale;Proceedings of the 13th International Conference of the NZ Chapter of the ACM's Special Interest Group on Human-Computer Interaction;978-1-4503-1474-9;NA;10.1145/2379256.2379275;https://doi.org/10.1145/2379256.2379275;We present a computer kiosk for learning in the retail space connecting producers and consumers through Fair Trade. The project has explored reactions to simple, inclusive technology focusing on the human narrative within not for profit trade and empathic human centered design toward all stakeholders.;2012;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;91;NA;NA;NA;NA;NA;NA;CHINZ '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Dunedin, New Zealand;NA;NA;NA;"empathic design; computer kiosk; fair trade; human centred; rapid prototype; retail";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
59WVUKXJ;conferencePaper;2016;André, Elisabeth;Socially-Sensitive Interfaces: From Offline Studies to Interactive Experiences;Proceedings of the 21st International Conference on Intelligent User Interfaces;978-1-4503-4137-0;NA;10.1145/2856767.2856799;https://doi.org/10.1145/2856767.2856799;Recent years have initiated a paradigm shift from pure taskbased human-machine interfaces towards socially-sensitive interaction. In addition to what users explicitly say or gesture at, socially-sensitive interfaces are able to sense more subtle human cues, such as head postures and movements, to infer psychological user states, such as attention and affect, and also to enrich system responses with social signals. However, most approaches focus on offline analysis of previously recorded data limiting the investigation to prototypical behaviors in laboratory-like settings. In my presentation, I will focus on challenges that arise when integrating social signal processing techniques into interactive systems designed for real-world applications. From a technical perspective, this requires effective tools able to synchronize, process, and analyze relevant signals in online mode. From a user perspective, appropriate strategies need to be defined to respond to social signals at the right moment in time without disturbing the flow of interaction. I will discuss two interaction styles for socially-sensitive interfaces. In the area of information retrieval, the concept of empathic stimulation has been used to optimize the selection and presentation of data. The basic idea is to exploit sensory data on the users' emotional state to provide them with cues that inspire their curiosity during the data exploration task. In the domain of social coaching, the concept of social augmentation has been employed to give people ambient feedback on their behavior while being engaged in a social interaction. The presentation will be illustrated by examples from various national and international projects following these two interaction styles.;2016;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;305;NA;NA;NA;NA;NA;NA;IUI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Sonoma, California, USA;NA;NA;NA;"affective computing; social signal processing; empathic stimulation; social augmentation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MV2HY4P6;journalArticle;2015;Leite, Iolanda;Long-Term Interactions with Empathic Social Robots;AI Matters;NA;NA;10.1145/2735392.2735397;https://doi.org/10.1145/2735392.2735397;We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.;2015-03;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;13–15;NA;3;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U6RKLMVX;conferencePaper;2014;"Nazir, Asad; Aylett, Ruth S.; Lim, Mei Yii; Endrass, Birgit; Hall, Lynne; Ritter, Christopher";MIXER: Why the Difference?;Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems;978-1-4503-2738-1;NA;NA;NA;This interactive demo features MIXER, a Virtual Learning Environment (VLE) consisting of synthetic characters representing the various actors in a scenario group difference scenario. MIXER creates virtual dramas by using interactive narrative with those characters. The goal is to enable children to identify social rule differences, by interacting with one of the characters to which they become empathic. MIXER is evaluated in the UK and Germany with children aged 9 to 11 years. The video for the demo content can be found at: http://youtu.be/jKIndn5NPaQ;2014;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1687–1688;NA;NA;NA;NA;NA;NA;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"artificial intelligence; applications; virtual learning environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EZYEBLMS;conferencePaper;2016;"Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra";How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.;2016;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;423–424;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Christchurch, New Zealand;NA;NA;NA;"empathy; robotic tutors; child-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BFWTXSYE;conferencePaper;2019;"Noortman, Renee; Schulte, Britta F.; Marshall, Paul; Bakker, Saskia; Cox, Anna L.";HawkEye - Deploying a Design Fiction Probe;Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5970-2;NA;10.1145/3290605.3300652;https://doi.org/10.1145/3290605.3300652;This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.;2019;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1–14;NA;NA;NA;NA;NA;NA;CHI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"design fiction; dementia care; future scenarios; informal caregiving; monitoring technologies; technology probes";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U4FVUYYG;conferencePaper;2020;"Bourdin, Pierre; Calvet, Laura; Tesconi, Susanna; Arnedo-Moreno, Joan";Reflecting on Attitudes Towards Death Through the Use of Immersive Virtual Reality Commercial Video Games;Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality;978-1-4503-8850-4;NA;10.1145/3434780.3436559;https://doi.org/10.1145/3434780.3436559;Video games can be an invaluable learning tool beyond pure skill acquisition, such as teaching us how to empathize with others or even self-reflecting on basic existential concerns: isolation, freedom, meaninglessness or death. This is further emphasized with the use of immersive technologies and becomes especially relevant when the experience itself is very difficult to replicate, when not impossible, in the real world. On that regard, this paper analyzes the impact of virtual reality (VR) commercial video games on the existential concern of one's own death. Participants (N 30) played one of three games for 15 minutes and the aftermath was examined using questionnaires and the implicit relational assessment procedure (IRAP). Our results show that there is no difference in the game experience, despite the different gameplay. However, IRAP results seem to indicate that players of the action game have a different attitude towards death.;2020;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;640–647;NA;NA;NA;NA;NA;NA;TEEM'20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salamanca, Spain;NA;NA;NA;"Virtual reality; serious games; death-evaluation; death-identity; existential games; immersive player experiences; Implicit Relational Assessment Procedure; video games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WXQBZFCP;bookSection;2018;"Giglitto, Danilo; Lazem, Shaimaa; Preston, Anne";In the Eye of the Student: An Intangible Cultural Heritage Experience, with a Human-Computer Interaction Twist;Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;978-1-4503-5620-6;NA;NA;https://doi.org/10.1145/3173574.3173864;We critically engage with CHI communities emerging outside the global North (ArabHCI and AfriCHI) to explore how participation is configured and enacted within socio-cultural and political contexts fundamentally different from Western societies. We contribute to recent discussions about postcolonialism and decolonization of HCI by focusing on non-Western future technology designers. Our lens was a course designed to engage Egyptian students with a local yet culturally-distant community to design applications for documenting intangible heritage. Through an action research, the instructors reflect on selected students' activities. Despite deploying a flexible learning curriculum that encourages greater autonomy, the students perceived themselves with less agency than other institutional stakeholders involved in the project. Further, some of them struggled to empathize with the community as the impact of the cultural differences on configuring participation was profound. We discuss the implications of the findings on HCI education and in international cross-cultural design projects.;2018;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1–12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EC6VCP4U;bookSection;2018;"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama";Touch Your Heart: A Tone-Aware Chatbot for Customer Care on Social Media;Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;978-1-4503-5620-6;NA;NA;https://doi.org/10.1145/3173574.3173989;Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.;2018;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1–12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LVZQ4UUY;conferencePaper;2020;"Chapko, Dorota; Frumiento, Pino; Edwards, Nalini; Emeh, Lizzie; Kennedy, Donald; McNicholas, David; Overton, Michaela; Snead, Mark; Steward, Robyn; Sutton, Jenny M.; Jeffreys, Evie; Long, Catherine; Croll-Knight, Jess; Connors, Ben; Castell-Ward, Sam; Coke, David; McPeake, Bethany; Renel, William; McGinley, Chris; Remington, Anna; Whittuck, Dora; Kieffer, John; Ewans, Sarah; Williams, Mark; Grierson, Mick";"""We Have Been Magnified for Years - Now You Are under the Microscope!"": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities";Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6708-0;NA;10.1145/3313831.3376278;https://doi.org/10.1145/3313831.3376278;Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.;2020;2021-02-15T21:33:25Z;2021-02-15T21:33:25Z;NA;1–17;NA;NA;NA;NA;NA;NA;CHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Honolulu, HI, USA;NA;NA;NA;"attitudes; design; disability; survey; participatory/inclusive research; video";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XC5EI4AH;conferencePaper;2020;"Carrasco, Romina; A. Baker, Felicity; A. Bukowska, Anna; N. Clark, Imogen; M. Flynn, Libby; McMahon, Kate; Odell-Miller, Helen; Stensaeth, Karette; Tamplin, Jeanette; Vieira Sousa, Tanara; Waycott, Jenny; Wosch, Thomas";Empowering Caregivers of People Living with Dementia to Use Music Therapeutically at Home: Design Opportunities;32nd Australian Conference on Human-Computer Interaction;978-1-4503-8975-4;NA;10.1145/3441000.3441082;https://doi.org/10.1145/3441000.3441082;Human-computer interaction researchers have explored how to design technologies to support people with dementia (PwD) and their caregivers, but limited attention has been given to how to facilitate music therapy in dementia care. The use of music to help manage the symptoms of dementia is often guided by a music therapist who adapts the intervention to respond to the changing needs of the person living with dementia. However, as the incidence of dementia increases worldwide, individualised therapy programs are less feasible, making it valuable to consider technology-based approaches. In this paper, we analyze data from case studies of home-based music therapy training interventions with two families. The findings show that embodied interactions supported the therapist in responding to the needs of the PwD and built an empathic environment that empowered the caregivers’ learning. We discuss opportunities and challenges for designing technologies that support family caregivers’ therapy-informed music use in dementia care.;2020;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;198–209;NA;NA;NA;NA;NA;NA;OzCHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Sydney, NSW, Australia;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
35PCZLWM;conferencePaper;2014;"Iacono, Iolanda; Marti, Patrizia";Engaging Older People with Participatory Design;Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational;978-1-4503-2542-4;NA;10.1145/2639189.2670180;https://doi.org/10.1145/2639189.2670180;We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.;2014;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;859–864;NA;NA;NA;NA;NA;NA;NordiCHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Helsinki, Finland;NA;NA;NA;"empathy; participatory design; older people; gaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HMWC9PT6;conferencePaper;2012;Khaled, Rilla;Muse-Based Game Design;Proceedings of the Designing Interactive Systems Conference;978-1-4503-1210-3;NA;10.1145/2317956.2318065;https://doi.org/10.1145/2317956.2318065;Game design and user experience (UX) design both centre on the design of experiences. But whereas it is par for the course for end-user perspectives to be included during early design stages in UX, there is little methodological support or research into how to incorporate player perspectives into early stages of game design. In this paper, we introduce muse-based game design, an experimental empathic design approach foregrounding a dialogic artist – muse relationship between a game designer and player. Following a user research stage focused on learning about the player, the designer forms idiosyncratic design constraints inspired by and relating to the player, which are then used to inspire ideation. To understand the consequences, advantages, and disadvantages of this approach, we discuss findings from two years of application of this style of game design in a Master's-level class of game design students at the IT University of Copenhagen.;2012;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;721–730;NA;NA;NA;NA;NA;NA;DIS '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Newcastle Upon Tyne, United Kingdom;NA;NA;NA;"empathic design; game design; design processes; player-centred design; player-centric design; reflective design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AX32U7PG;conferencePaper;2019;"W. Bennett, Gregory; Canner, Liz";Lost City of Mer;SIGGRAPH Asia 2019 XR;978-1-4503-6947-3;NA;10.1145/3355355.3361897;https://doi.org/10.1145/3355355.3361897;Lost City of Mer is a virtual reality (VR) game experience combined with a smartphone app that immerses players in a fantasy undersea civilization devastated by ecological disaster caused by global warning. The project aims to harness the immersive and empathetic potential of VR to address climate change and create a sense of urgency in the player with regard to their personal carbon footprint.Players are invited to help rebuild the lost world of Mer and its devastated ecosystem in VR by re-establishing its unique flora and fauna, and fighting ongoing dangers and threats, with the aim of bringing back to life its mysterious Mer-people inhabitants. Guided by a solitary seal spirit named Athina – the last of its kind in a dying ocean – players try to save the Mer population from extinction. They tend to secret gardens of coral threatened by pollution, create habitats for Mer-people, and explore the destroyed civilization, in the process learning how their real-world actions impact the world around them.The project was developed with the input of environmental scientists from Harvard University and Dartmouth College. The experience is based on real science, but told through fantasy, as it draws on the cross-cultural myth of the mermaid to appeal to people across the globe.;2019;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;25–26;NA;NA;NA;NA;NA;NA;SA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Brisbane, QLD, Australia;NA;NA;NA;"climate change; virtual reality; serious games; VR navigation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YK7BB9PX;conferencePaper;2013;"Kim, Hyun-Jun; Choi, Young Sang";A Peak Detection Method for Understanding User States for Empathetic Intelligent Agents;Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 02;978-0-7695-5145-6;NA;10.1109/WI-IAT.2013.118;https://doi.org/10.1109/WI-IAT.2013.118;Recognition of facial expression is a useful and unobtrusive means for machines to understand users' internal states. However, most human facial expression is ambiguous or subtle to recognize resulting in poor accuracy. To overcome this limitation, we propose a peak detection method to select only meaningful images from image sequences which imply significant changes of facial expression by calculating differences between images. We believe this method will alleviate the accuracy degradation caused by different personal appearances and ambiguous facial expressions. When applied to commercial products, it can provides a suitable method for adaptation of the empathetic agent embedded in machines such as personal assistants on TV, smartphone and vehicles based on recognized facial expression of users. For experimental validation of the proposed method, we tested four different features for measuring image similarity with the extended Cohn-Kanade facial image dataset. As a result, we could get better recognition accuracy than the original image sequences. Moreover, we reduced the number of images that need to be recognized to 24.52% without degradation of accuracy.;2013;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;261–265;NA;NA;NA;NA;NA;NA;WI-IAT '13;NA;NA;NA;IEEE Computer Society;USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathetic Agent; Facial Expression; Image Processing; Peak Detection; Temporal Analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
E94QU5H2;conferencePaper;2018;"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia";A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.;2018;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;1658–1666;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WPFMNUD6;conferencePaper;2018;"Corral, Luis; Fronza, Ilenia";Design Thinking and Agile Practices for Software Engineering: An Opportunity for Innovation;Proceedings of the 19th Annual SIG Conference on Information Technology Education;978-1-4503-5954-2;NA;10.1145/3241815.3241864;https://doi.org/10.1145/3241815.3241864;"Commonly, the instruction of Software Engineering implements processes that are inherent to the theory and practice of software development. Traditional and Agile methods lay the foundation for building ""functional software products"" that meet the requirements of a system of a larger scope. However, if we consider software as a product that frequently has the mission of satisfying the needs of human users, we can go beyond the typical ""analysis - design - implementation - testing"" process, to reinterpret it with the ""empathize - define - ideate - prototype - testing"" proposed by Design Thinking, a development methodology commonly used in creative and innovative professional settings. In this work, we study the use of Design Thinking as a methodological approach for the instruction of Software Engineering at undergraduate level, in courses that have the particular aim of creating innovative software products from scratch. We describe the similarities and differences between Design Thinking and Software Development Processes, taking as instance Agile Practices. We compare evidence on methods and deliverables produced by students in their learning path using Agile Practices and Design Thinking in two different educational environments. Finally, we discuss coincidences, weaknesses, and opportunities to keep investigating in this topic as a research subject, toward finding practices to promote in students both creativity and technical discipline to develop innovative software solutions";2018;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;26–31;NA;NA;NA;NA;NA;NA;SIGITE '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Fort Lauderdale, Florida, USA;NA;NA;NA;"education; creativity; agile; design thinking; software engineering";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TSXQTEJ5;conferencePaper;2019;Zhou, Michelle X.;"Getting Virtually Personal: Making Responsible and Empathetic ""Her"" for Everyone";Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3308445;https://doi.org/10.1145/3301275.3308445;Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world.Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent.I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.;2019;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;i;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Marina del Ray, California;NA;NA;NA;"computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AD7GUG88;book;2014;NA;IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces;NA;978-1-4503-2184-6;NA;NA;NA;"It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.";2014;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZL23V7LB;book;2014;NA;IUI Companion '14: Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces;NA;978-1-4503-2729-9;NA;NA;NA;"It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.";2014;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
93TB99BB;conferencePaper;2016;"Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Moncur, Wendy; McNaney, Roisin; Vines, John; Branham, Stacy";Ethical Encounters in Human-Computer Interaction;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2856498;https://doi.org/10.1145/2851581.2856498;In the HCI community, there is growing recognition that a reflective and empathetic approach is needed to conduct ethical research in sensitive settings with people who might be considered vulnerable or marginalized. At our CHI 2015 workshop on ethical encounters, researchers shared personal stories of the challenges and tensions they have faced when conducting HCI research in complex settings such as hospitals, with young mental health patients, in schools for children with disabilities, and with homeless people. These research contexts can present significant challenges for HCI researchers who would not typically receive the training that other professionals working in these environments would normally receive. From our discussions with attendees at the CHI 2015 workshop, we identified a number of ethical issues that researchers are grappling with. In this follow-up workshop we aim to build on the lessons learned and to generate pragmatic but sensitive solutions to manage complex ethical issues for HCI researchers working in challenging settings.;2016;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;3387–3394;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Jose, California, USA;NA;NA;NA;"ethics; sensitive settings; vulnerable participants";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RVYNGD5F;bookSection;2017;"Van Mechelen, Maarten; Høiseth, Marikken; Baykal, Gökçe Elif; Van Doorn, Fenne; Vasalou, Asimina; Schut, Alice";Analyzing Children's Contributions and Experiences in Co-Design Activities: Synthesizing Productive Practices;Proceedings of the 2017 Conference on Interaction Design and Children;978-1-4503-4921-5;NA;NA;https://doi.org/10.1145/3078072.3081314;Today, it has been broadly acknowledged in the CCI community that children are not only active learners and users of technology, but can also actively participate in the design process. However, it remains challenging to analyze children's experiences and creative contributions resulting from co-design activities (e.g. stories, paper prototypes, enacted ideas). Broadly speaking, a distinction can be made between researchers looking for inspiration in the form of useful design ideas, and researchers that take a more interpretative stance by looking beyond the surface level of children's ideas to better understand and empathize with them. This knowledge about children is often used to more accurately define the problem space at the early stages of design. Both perspectives to co-design can be seen as the opposite ends of the same continuum, and many researchers combine aspects of both depending on where they are in the design process (e.g. defining the design problem, prototyping stage). This workshop will explore different ways to analyze children's (0 to 18 years) experiences and contributions in co-design activities, the perceived benefits and challenges of these approaches, and will serve as a venue for synthesizing productive practices that will move the CCI community forward.;2017;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;769–772;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CWRXC629;journalArticle;2014;Tracey, Ryan;The Agony or the Empathy? An Interview with Anne Bartlett-Bragg;ELearn;NA;NA;10.1145/2578511.2576869;https://doi.org/10.1145/2578511.2576869;Anne Bartlett-Bragg holds a unique space in eLearning as both a researcher and a practitioner. In this interview, Anne discusses the importance of immersion. By empathizing with the learner, one can truly design the best solution.;2014-02;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;NA;NA;2;2014;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KFC2DJVR;conferencePaper;2018;"Itenge-Wheeler, Helvi; Winschiers-Theophilus, Heike; Soro, Alessandro; Brereton, Margot";Child Designers Creating Personas to Diversify Design Perspectives and Concepts for Their Own Technology Enhanced Library;Proceedings of the 17th ACM Conference on Interaction Design and Children;978-1-4503-5152-2;NA;10.1145/3202185.3202760;https://doi.org/10.1145/3202185.3202760;We report on a participatory design project that explored the use of child-created Personas to enable child designers to empathize with other children thereby contributing multiple divergent perspectives. The ongoing project aims to promote reading and creative writing skills among young children in Namibia. For decades libraries worldwide have been the key actors in fostering reading. Hence, in order to maintain their relevance, they are being re-conceptualized to cater for new needs and aspirations in the 21st century. In Namibia, dysfunctional public and school library services are lagging behind in this renovation effort, and are not contributing to the promotion of a reading culture. In an ongoing collaboration with a school in Windhoek, to design and implement an interactive tech library, 19 young learners engaged in weekly participatory design workshops to redesign their own school library. The children first created four distinct Personas for which they then modelled spaces and technologies. This paper reflects on the techniques used to enable children to become active design partners and to gain an understanding of designing for other children.;2018;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;381–388;NA;NA;NA;NA;NA;NA;IDC '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"children; design; participatory design; interactive tech library; Namibia; persona; reading experiences";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BGBJ8FFX;bookSection;2017;"Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Branham, Stacy; Moncur, Wendy; McNaney, Roisin; Vines, John";Ethical Encounters in HCI: Implications for Research in Sensitive Settings;Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4656-6;NA;NA;https://doi.org/10.1145/3027063.3027089;This workshop builds on the success of prior workshops that brought together HCI researchers to share stories about ethical challenges faced when conducting research in sensitive settings. There is growing recognition that reflective and empathetic approaches are needed to conduct ethical research in settings involving people who might be considered vulnerable or marginalized. At our previous workshops, researchers discussed personal experiences and described the complex challenges they have faced in research as diverse as designing information systems for families of children in palliative care to analyzing social media posts about mental health. In this follow-up workshop we aim to extend opportunities for knowledge-sharing, build on the lessons learned, and generate a range of resources to help HCI researchers manage complex ethical issues when working in sensitive settings.;2017;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;518–525;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R74UT9CI;conferencePaper;2015;"Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia";Designing a Socially Assistive Robot for Pediatric Care;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771923;https://doi.org/10.1145/2771839.2771923;We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.;2015;2021-02-15T21:33:26Z;2021-02-15T21:33:26Z;NA;387–390;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boston, Massachusetts;NA;NA;NA;"child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LFQ5FV3D;conferencePaper;2016;"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia";Affect-Aware Student Models for Robot Tutors;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration.In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models.These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.;2016;2021-02-15T21:33:27Z;2021-02-15T21:33:27Z;NA;864–872;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"affective computing; child-robot interaction; socially assistive robots; educational robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WW8G3BZS;conferencePaper;2010;"Chen, Yu-Chung; Lee, Sangyoon; Hur, HyeJung; Leigh, Jason; Johnson, Andrew; Renambot, Luc";Case Study: Designing an Advanced Visualization System for Geological Core Drilling Expeditions;CHI '10 Extended Abstracts on Human Factors in Computing Systems;978-1-60558-930-5;NA;10.1145/1753846.1754206;https://doi.org/10.1145/1753846.1754206;"We present the design and process of an interactive high-resolution visualization system for diverse and distributed real-world geological core drilling expeditions. The high domain knowledge barrier makes it difficult for a person who is outside this field to imagine the user experience, and the globally distributed core drilling community imposes more design constraints in space and time. In addition to activities proposed in prior literatures, we used the ""immersive empathic design"" approach of having a computer scientist trained as a junior core technician. Through in-situ observation and interview evaluations from on-going expeditions, we present the system and the lesson learned in the process. It makes the best use of precious co-located opportunities. It allows the developer to build up domain knowledge efficiently. It establishes a trust relationship between the developer and scientists. The system designed through this approach formed a sustainable foundation that was adapted in the following design iterations. This process allows the software developer to experience authentic user activities. The designed system is innovative and helps scientists solving real-world problems. This approach can be a useful example to HCI practitioners who work with potential users or communities that share similar properties.";2010;2021-02-15T21:33:27Z;2021-02-15T21:33:27Z;NA;4645–4660;NA;NA;NA;NA;NA;NA;CHI EA '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Atlanta, Georgia, USA;NA;NA;NA;"empathic design; visualization; hci";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JHYV6K9N;conferencePaper;2014;"Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid";Werewolves, Cheats, and Cultural Sensitivity;Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems;978-1-4503-2738-1;NA;NA;NA;MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.;2014;2021-02-15T21:33:27Z;2021-02-15T21:33:27Z;NA;1085–1092;NA;NA;NA;NA;NA;NA;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YSLE727F;conferencePaper;2013;"Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth";Towards Empathic Artificial Tutors;Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction;978-1-4673-3055-8;NA;NA;NA;In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.;2013;2021-02-15T21:33:27Z;2021-02-15T21:33:27Z;NA;113–114;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CKXXA6DI;conferencePaper;2020;"Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio";DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI;Proceedings of the International Conference on Advanced Visual Interfaces;978-1-4503-7535-1;NA;10.1145/3399715.3399820;https://doi.org/10.1145/3399715.3399820;Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.;2020;2021-02-15T21:34:46Z;2021-02-15T21:34:46Z;NA;NA;NA;NA;NA;NA;NA;NA;AVI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salerno, Italy;NA;NA;NA;"Computer Vision; Deep Learning; User Emotions; User Experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5K5HDB4A;bookSection;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems;978-1-4503-4655-9;NA;NA;https://doi.org/10.1145/3025453.3025496;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-02-15T21:34:46Z;2021-02-15T21:34:46Z;NA;3506–3510;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZC7YBD3E;bookSection;2018;"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama";Touch Your Heart: A Tone-Aware Chatbot for Customer Care on Social Media;Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;978-1-4503-5620-6;NA;NA;https://doi.org/10.1145/3173574.3173989;Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.;2018;2021-02-15T21:34:46Z;2021-02-15T21:34:46Z;NA;1–12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MYLEZU3Q;bookSection;2020;"Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph";Reputation Agent: Prompting Fair Reviews in Gig Markets;Proceedings of The Web Conference 2020;978-1-4503-7023-3;NA;NA;https://doi.org/10.1145/3366423.3380199;"Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.";2020;2021-02-15T21:34:46Z;2021-02-15T21:34:46Z;NA;1228–1240;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EJEKT9CE;conferencePaper;2019;Zhou, Michelle X.;"Getting Virtually Personal: Making Responsible and Empathetic ""Her"" for Everyone";Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3308445;https://doi.org/10.1145/3301275.3308445;Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world.Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent.I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.;2019;2021-02-15T21:34:46Z;2021-02-15T21:34:46Z;NA;i;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Marina del Ray, California;NA;NA;NA;"computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5NSIHTE8;conferencePaper;2015;"Putnam, Cynthia; Dahman, Maria; Rose, Emma; Cheng, Jinghui; Bradford, Glenn";Teaching Accessibility, Learning Empathy;"Proceedings of the 17th International ACM SIGACCESS Conference on Computers &amp; Accessibility";978-1-4503-3400-6;NA;10.1145/2700648.2811365;https://doi.org/10.1145/2700648.2811365;"As information and communication technologies (ICTs) become more diffuse, the diversity of users that designers need to consider is growing; this includes people with disabilities and aging populations. As a result, computing education must provide students the means and inspiration to learn about inclusive design. This poster presents top-level findings from 18 interviews with professors from some of the top universities in the US. Our analysis yielded four categories of findings: (1) important student learning outcomes (the most common was for students to embrace diversity); (2) exercises and teaching materials (almost all focused on inclusion of people with disabilities in discovery and evaluation of ICTs); (3) frustrations and challenges (largely focused on how to engage students in accessibility topics); and (4) the importance of instructor initiative to include the topic of accessibility in their teaching. The unifying theme was the high importance of cultivating empathy with end users.";2015;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;333–334;NA;NA;NA;NA;NA;NA;ASSETS '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Lisbon, Portugal;NA;NA;NA;"accessibility; pedagogy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JPVGNEH2;conferencePaper;2014;Slovák, Petr;Supporting Teaching and Learning of Situational Empathy by Technology;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2559957;https://doi.org/10.1145/2559206.2559957;Detecting and supporting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, most of this work is still based primarily on single persons' data, and there is little research on supporting complex interpersonal aspects such as empathy. To address this gap, the goal of my PhD work is to explore ways in which technology can facilitate learning and teaching of situational empathy, with particular focus on counselling students.;2014;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;315–318;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"feedback; empathy; bio-sensors; mixed methods";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HADPMHHX;conferencePaper;2017;"Polignano, Marco; Basile, Pierpaolo; Rossiello, Gaetano; de Gemmis, Marco; Semeraro, Giovanni";Learning Inclination to Empathy from Social Media Footprints;Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization;978-1-4503-4635-1;NA;10.1145/3079628.3079639;https://doi.org/10.1145/3079628.3079639;In recent years we are witnessing a growing spread of social media footprints, as the consequence of the wide use of applications such as Facebook, Twitter or LinkedIn, which allow people to share content that might provide information about personal preferences and aptitudes. Among the traits that can be inferred, empathy is the ability to feel and share another person's emotions and we consider it as a relevant aspect for the profiling and recommendation tasks. We propose a method that predicts its level for the user by exploiting her social media data and using linear regression algorithms. The results show which are the most relevant correlations among the different groups of user's features and the empathy level predicted.;2017;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;383–384;NA;NA;NA;NA;NA;NA;UMAP '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bratislava, Slovakia;NA;NA;NA;"machine learning; empathy; social medium footprint";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
S682VLKW;journalArticle;2019;"Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;J. Hum.-Robot Interact.;NA;NA;10.1145/3300188;https://doi.org/10.1145/3300188;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
M368LV3J;conferencePaper;2019;"Tavabi, Leili; Stefanov, Kalin; Nasihati Gilani, Setareh; Traum, David; Soleymani, Mohammad";Multimodal Learning for Identifying Opportunities for Empathetic Responses;2019 International Conference on Multimodal Interaction;978-1-4503-6860-5;NA;10.1145/3340555.3353750;https://doi.org/10.1145/3340555.3353750;Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users’ emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard-of-Oz setting, using the wizard’s empathetic responses and annotations collected on Amazon Mechanical Turk as ground-truth labels. Our model outperforms a text-based baseline achieving F1-score of 0.71 on a three-class classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.;2019;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;95–104;NA;NA;NA;NA;NA;NA;ICMI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Suzhou, China;NA;NA;NA;"machine learning; empathy; human behavior; multimodal sentiment; virtual human";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
52QT45DQ;conferencePaper;2017;De Lira, Carla;Improving the Learning Experiences of First-Year Computer Science Students with Empathetic IDEs;Proceedings of the 2017 ACM Conference on International Computing Education Research;978-1-4503-4968-0;NA;10.1145/3105726.3105742;https://doi.org/10.1145/3105726.3105742;Computer science has the highest dropout rate among undergraduate STEM degree programs. This is especially concerning, given that computer science-related jobs are projected to grow 12% in the next six years. One contributing factor is that media representations of computer science can lead underrepresented groups to perceive themselves as unfit for the discipline, and ultimately to drop out. To address this concern, I propose an empathetic IDE model that uses affective computing technologies to promote empathy among computer science students. A quasi-experimental research design will be used to evaluate the model's effectiveness in fostering a supportive community between instructors and students. By leveraging emotional learning process data as a form of constant feedback to both instructors and students, this research can gain new insights into how to improve learning environments for computer science students with or without affective computing technologies.;2017;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;293–294;NA;NA;NA;NA;NA;NA;ICER '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tacoma, Washington, USA;NA;NA;NA;"affective computing; computer science education; empathy in computer science; learning analytics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IDAMGN22;conferencePaper;2016;Bratitsis, Tharrenos;A Digital Storytelling Approach for Fostering Empathy Towards Autistic Children: Lessons Learned;Proceedings of the 7th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion;978-1-4503-4748-8;NA;10.1145/3019943.3019987;https://doi.org/10.1145/3019943.3019987;In this paper a case study in which interactive digital storytelling was exploited for fostering empathy towards children with Autism Spectrum Disorders (ASD) is presented. The research population consisted mainly by Kindergarten children. Based on the findings and the overall experience, even considering the design mistakes that occurred, this paper argues upon the deriving value of exploiting multimodal digital representations in the form of a story in order to cultivate empathy towards children with ASD and thus, facilitate social interaction and inclusion. This approach can be useful in mixed population classrooms, but in a wider educational context as well.;2016;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;301–308;NA;NA;NA;NA;NA;NA;DSAI 2016;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Vila Real, Portugal;NA;NA;NA;"Empathy; ASD; Digital Storytelling; Inclusion; Kindergarten; Social Interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
X4VQ2Q34;conferencePaper;2014;"Villarica, Ryan; Richards, Deborah";Intelligent and Empathic Agent to Support Student Learning in Virtual Worlds;Proceedings of the 2014 Conference on Interactive Entertainment;978-1-4503-2790-9;NA;10.1145/2677758.2677761;https://doi.org/10.1145/2677758.2677761;"Virtual worlds potentially provide students with a simulated environment that can provide exposure to situations and contexts not possible in reality and allow exploration of concepts, objects and phenomena that is safe both in terms of removing any physical danger or risk of failure if poor choices are made. This is certainly true in science education. However, the exploratory nature of virtual worlds can result in a lack of focus or direction in the learning. Observation of trials with the science-based Omosa Virtual 3D world has revealed that some students lose motivation. This project aims to personalise the learning experience of science-related skills through the incorporation of intelligent agents and asks ""How can intelligent agents apply educational scaffolding to the demotivated student to maximise their time and enhance their 3D virtual learning experiences?"" Building on the findings of previous studies involving agent-based virtual worlds, adaptive collaborative learning and intelligent agents, an intelligent virtual agent has been designed and partially prototyped so that it provides educational scaffolding to the student learning.";2014;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;1–9;NA;NA;NA;NA;NA;NA;IE2014;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Newcastle, NSW, Australia;NA;NA;NA;"Empathic Agents; Omosa; Virtual Learning Environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8CHIIKML;conferencePaper;2010;"Lee, Myunghee; Kim, Gerard J.";Empathetic Video Experience through Timely Multimodal Interaction;International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction;978-1-4503-0414-6;NA;10.1145/1891903.1891948;https://doi.org/10.1145/1891903.1891948;"In this paper, we describe a video playing system, named ""Empatheater,"" that is controlled by multimodal interaction. As the video is played, the user must interact and emulate predefined video ""events"" through multimodal guidance and whole body interaction (e.g. following the main character's motion or gestures). Without the timely interaction, the video stops. The system shows guidance information as how to properly react and continue the video playing. The purpose of such a system is to provide indirect experience (of the given video content) by eliciting the user to mimic and empathize with the main character. The user is given the illusion (suspended disbelief) of playing an active role in the unraveling video content. We discuss various features of the newly proposed interactive medium. In addition, we report on the results of the pilot study that was carried out to evaluate its user experience compared to passive video viewing and keyboard based video control.";2010;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;NA;NA;NA;NA;NA;ICMI-MLMI '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Beijing, China;NA;NA;NA;"empathy; user experience; interactive video; multimodality; user guidance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
V6JBDVST;bookSection;2020;"Heljakka, Katriina Irja; Ihamäki, Pirita Johanna; Lamminen, Anu Inkeri";Playing with the Opposite of Uncanny: Empathic Responses to Learning with a Companion-Technology Robot Dog vs. Real Dog;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419900;Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies.;2020;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;262–266;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
T5AHCI4R;conferencePaper;2020;"Spitale, Micol; Garzotto, Franca";Towards Empathic Conversational Interaction;Proceedings of the 2nd Conference on Conversational User Interfaces;978-1-4503-7544-3;NA;10.1145/3405755.3406146;https://doi.org/10.1145/3405755.3406146;"In recent years, ""computational empathy"" has emerged as a new challenging research field. Computational empathy investigates how artificial agents can manifest empathic behaviours towards the user, and how they can elicit empathy during the human-agent interaction. Such ""empathic agents"" have the capacity to place themselves into the emotional position of a user (or another agent), and behave taking such emotional understanding into account. The paper explores a computational empathy approach in the context of conversational interaction, and presents an empathic conversational framework grounded on the empathy theory. The framework provides a conceptual tool for designing and evaluating empathic conversational agents. Overall, our research contributes to a deeper understanding of the role of empathy in conversational interaction.";2020;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;NA;NA;NA;NA;NA;CUI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bilbao, Spain;NA;NA;NA;"Empathy; Artificial Agents; Computational Empathy; Conversational Interaction; Framework";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IW9PVKNW;conferencePaper;2017;"Pantela, Nicoletta; Kyza, Eleni A.";The Investigation of Concept Mapping as a Scaffolding Tool in a Technologically-Mediated, Mobile Learning, Augmented Reality Environment;Proceedings of the 16th World Conference on Mobile and Contextual Learning;978-1-4503-5255-0;NA;10.1145/3136907.3136924;https://doi.org/10.1145/3136907.3136924;This study investigated concept maps as a form of support for primary school students' development of conceptual understanding, historical empathy, and for promoting collaborative learning. Students used the same historical learning augmented reality application on a mobile device, worked in pairs, and were divided in two conditions: the experimental group (n=12), supported by a tablet-based concept mapping tool, and the control group (n=11), who only used the learning application on the same mobile devices. The results showed that the experimental group students gained a deeper conceptual understanding after the visit, as evidenced by their concept maps and their discussions during their visit.;2017;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;NA;NA;NA;NA;NA;mLearn 2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Larnaca, Cyprus;NA;NA;NA;"informal learning; computer-supported collaborative learning; concept maps; Scaffolding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XVQSVE6I;conferencePaper;2020;"Yu, Borou; Zhou, Tiange; Wang, Zeyu; Min, Jiajian";The World of Freedom;SIGGRAPH Asia 2020 Art Gallery;978-1-4503-8108-6;NA;10.1145/3414686.3427172;https://doi.org/10.1145/3414686.3427172;Indeed, people spend more time on deep thinking since 2020. The questions which ask mainly by the sociologists, now become the topics on the dining table. The debates on social and moral dilemmas are happening intensively 24 hours on the internet. We started to think more about who we are, where we are going, and how we will value the information we have received. Do we have freedom? Shall we believe absolute freedom? Sometimes people directly transform the idea of liberty into democracy. However, shall we also equal freedom to democracy? Since we are all inside this one pandemic bubble, after most people stay at home for a couple of months, we start emerging a global-size collective memory, which makes people more empathetically understand others' situations. Meanwhile, more and more people have to learn and take experience virtually. The attention of empathy and the new work-from-home mode evokes the initial idea of this virtual reality experience. We start to ask how people could learn and think more effectively in this brand new virtual age? Unity program makes this innovation possible. The innovative architecture modeling could permit a large group of people to experience personal space and sharing areas simultaneously. The sound design is specially designed for the various space sound and the audience's interactivities. We use this program to build up an immersive and empathetic space that embodies a hypothetical argument of a social dilemma into a virtual manifestation. People might be able to figure out the most meaningful answer by wearing the same shoes. The social distance could also be virtually controlled in this program by counting if the number of participates overload spaces.;2020;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;NA;NA;NA;NA;NA;SA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Republic of Korea;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UPM6ZWUT;conferencePaper;2011;"Adams, Anne; Coughlan, Tim; Lea, John; Rogers, Yvonne; Davies, Sarah; Collins, Trevor";Designing Interconnected Distributed Resources for Collaborative Inquiry Based Science Education;Proceedings of the 11th Annual International ACM/IEEE Joint Conference on Digital Libraries;978-1-4503-0744-4;NA;10.1145/1998076.1998152;https://doi.org/10.1145/1998076.1998152;This paper describes the design and evaluation of a distributed information resource system (IRS) shared between field and laboratory settings for higher education geology students. An investigation of geo-science scholarship and technical pilot studies highlighted the importance of situational specific and distributed information usage. To advance our understanding of novel resource approaches (i.e. from tabletops to tablets) and collaborative learning, two in-depth field trials evaluated 21 students' information journeys (i.e. initiating information needs, facilitating information and collaborative interpretation). Analysis identified how a designing for a varied device ecology supported information filtering and empathy between locations provoking deeper reflection and abstract understanding in the field, while live collaborative remote interaction provided an engaging yet distinct learning experience for those in the laboratory.;2011;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;395–396;NA;NA;NA;NA;NA;NA;JCDL '11;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Ottawa, Ontario, Canada;NA;NA;NA;"e-learning; design; collaborative information environment; mobile; tabletop";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L6QENL6B;conferencePaper;2019;"Chen, Jize; Wang, Changhong";Reaching Cooperation Using Emerging Empathy and Counter-Empathy;Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems;978-1-4503-6309-9;NA;NA;NA;According to social neuropsychology, the cooperative behavior is largely influenced by empathy, which is deemed essential of emotional system and has wide impact on social interaction. In the work reported here, we believe that the emergence of empathy and counter-empathy is closely related to creatures' inertial impression on intragroup coexistence and competition. Based on this assumption, we establish a unified model of empathy and counter-empathy in light of Hebb's rule. We also present Adaptive Empathetic Learner (AEL), a training method for agents to enable affective utility evaluation and learning procedure in multi-agent system. In AEL, the empathy model is integrated into the adversarial bandit setting in order to achieve a high degree of versatility. Our algorithm is first verified in the survival game, which is designed to simulate the primitive hunting environment. In this game, empathy and cooperation emerge among agents with different power. In another test about Iterated Prisoners' Dilemma, cooperation was reached even between an AEL agent and a rational one. Moreover, when confronted with hostile, the AEL agent showed sufficient goodwill and vigilantly protected its safe payoffs. In the Ultimatum Game, it's worth mentioning that absolute fairness could be achieved on account of the self-adaptation of empathy and counter-empathy.;2019;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;746–753;NA;NA;NA;NA;NA;NA;AAMAS '19;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Montreal QC, Canada;NA;NA;NA;"cooperation; adversarial bandit; empathy and counter-empathy; multi-agent system";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WSGN2K9I;conferencePaper;2013;"Buckingham Shum, Simon; de Laat, Maarten; De Liddo, Anna; Ferguson, Rebecca; Kirschner, Paul; Ravenscroft, Andrew; Sándor, Ágnes; Whitelock, Denise";DCLA13: 1<sup>st</sup> International Workshop on Discourse-Centric Learning Analytics;Proceedings of the Third International Conference on Learning Analytics and Knowledge;978-1-4503-1785-6;NA;10.1145/2460296.2460357;https://doi.org/10.1145/2460296.2460357;This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field.;2013;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;282;NA;NA;NA;NA;NA;NA;LAK '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Leuven, Belgium;NA;NA;NA;"dialogue; learning analytics; argumentation; deliberation; discourse; visualization";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AWAS7NI2;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3326596;https://doi.org/10.1145/3311927.3326596;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;755–760;NA;NA;NA;NA;NA;NA;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boise, ID, USA;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5DH7Z8JS;conferencePaper;2016;"Zhang, Emma Yann; Cheok, Adrian David; Nishiguchi, Shogo; Morisawa, Yukihiro";Kissenger: Development of a Remote Kissing Device for Affective Communication;Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology;978-1-4503-4773-0;NA;10.1145/3001773.3001831;https://doi.org/10.1145/3001773.3001831;As human communication is rapidly migrating from the physical world to the digital world, it is crucial to develop affective communication systems to enable the expression of intimacy, emotion and empathy over the Internet, as these are essential elements in forming social relationships. A multisensory, real-time kissing device, Kissenger, is developed to transmit multisensory kissing sensations remotely using mobile phones. The aim is to provide an intimate communication channel for families and friends to physically interact with each other remotely, in order to effectively convey deep emotions and intimacy through a multisensory internet communication experience.;2016;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;NA;NA;NA;NA;NA;NA;NA;ACE '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Osaka, Japan;NA;NA;NA;"affective communication; haptics; kiss transmission; multimodal communication";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
45X22KPU;conferencePaper;2014;"Vermeeren, Arnold P.O.S.; van Beusekom, Josje; Rozendaal, Marco C.; Giaccardi, Elisa";Design for Complex Persuasive Experiences: Helping Parents of Hospitalized Children Take Care of Themselves;Proceedings of the 2014 Conference on Designing Interactive Systems;978-1-4503-2902-6;NA;10.1145/2598510.2598548;https://doi.org/10.1145/2598510.2598548;In this paper we analyzed a case of designing for persuasive experiences. It concerns designing for the complex persuasive situation of helping parents of hospitalized children take better care of themselves. Our focus was on the experiences, on how these were designed to be persuasive, and on the design process needed to achieve that. We conclude that designing for complex persuasive experiences requires a design approach that allows for designers to gradually develop a rich understanding of the situation and develop empathy for the people they design for. We found that the persuasion should focus on a combination of starting a new practice, sustaining it, starting activities within the practice, and extending the duration of the activities. For such a complex persuasive situation a rich palette of experiences was needed. The design of those experiences was inspired by universal human needs and by gaining a deep and empathetic understanding of the situation.;2014;2021-02-15T21:34:47Z;2021-02-15T21:34:47Z;NA;335–344;NA;NA;NA;NA;NA;NA;DIS '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Vancouver, BC, Canada;NA;NA;NA;"behavior change; design approach; experience design; persuasive experiences; persuasive technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BYFT5TTP;conferencePaper;2019;Vertesi, Janet;Seeing like a Rover: Team Work and Human-Robot Relations;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;"How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go — in search and rescue operations, ocean voyages, or even into space — they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology.This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team.Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.";2019;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;152;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;"human-robot interaction; teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZV9BNLEA;conferencePaper;2017;Thompson, Jeff;I Touch You and You Touch Me;SIGGRAPH Asia 2017 Art Gallery;978-1-4503-5401-1;NA;10.1145/3143748.3143753;https://doi.org/10.1145/3143748.3143753;A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.;2017;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;NA;NA;NA;NA;NA;NA;NA;SA '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bangkok, Thailand;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
GN3G5D8H;conferencePaper;2014;"Watanabe, Yukako; Okada, Yoshiko; Osawa, Hirotaka; Sugaya, Midori";Digital Play Therapy for Children with Learning Disabilities;Proceedings of the Second International Conference on Human-Agent Interaction;978-1-4503-3035-0;NA;10.1145/2658861.2658918;https://doi.org/10.1145/2658861.2658918;Children who are suffering on learning and developmental disabilities require daily trainings for social skills. However, such daily training is not provided occasionally because it requires interactive helps from therapists. In this paper, we propose a digital dollhouse that enhanced traditional psychological play therapy with digital sensors and computer graphics. The digital dollhouse provides immersive space to children which grows children's communication skill through their imaging play. This device allows non-professional like parents to make play therapy. In this paper, we show details about prototype of digital dollhouse. We also categorize requirements for digital play therapy that are given by psychological viewpoints based on the prototype. Interdisciplinary design process collaborating with engineers and psychologists shows the possibility that digital dollhouse is enough to enhance empathy of children and such empathy will be enhanced by creating immersive characters.;2014;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;185–188;NA;NA;NA;NA;NA;NA;HAI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tsukuba, Japan;NA;NA;NA;"human-agent interaction; human robot interaction; augmented human; emotional labor; human interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
689N7F5Q;conferencePaper;2019;"Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid";BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions;Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3302290;https://doi.org/10.1145/3301275.3302290;Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.;2019;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;448–459;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Marina del Ray, California;NA;NA;NA;"conversational agents; explainable AI; mechanical turk";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Y48LUS7T;conferencePaper;2020;"El-Glaly, Yasmine; Shi, Weishi; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.";Presenting and Evaluating the Impact of Experiential Learning in Computing Accessibility Education;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;978-1-4503-7124-7;NA;10.1145/3377814.3381710;https://doi.org/10.1145/3377814.3381710;Studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. Compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. To address these issues, we have created five Accessibility Learning Labs (ALL) using an experiential learning structure. The labs are designed to educate and create awareness of accessibility needs in computing. The labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. The labs are hosted on our servers and require only a browser to be utilized.To demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. Our findings include: (I) The demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (II) The labs are effective in informing students about foundational accessibility topics (III) Empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. Created labs and project materials are publicly available on the project website: http://all.rit.edu;2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;49–60;NA;NA;NA;NA;NA;NA;ICSE-SEET '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, South Korea;NA;NA;NA;"accessibility education; computing accessibility; computing education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
38XZ5IMH;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;931–939;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"empathy; human-agent interaction; human-robot interaction; memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TS6L6YW2;conferencePaper;2020;Liu, Qinyuan;Let's Chat like This;SIGGRAPH Asia 2020 Art Gallery;978-1-4503-8108-6;NA;10.1145/3414686.3427118;https://doi.org/10.1145/3414686.3427118;"""Let's Chat Like This"" is an interactive system that allows two people to observe each others' moods through interacting with a shared interactively generated image. The moving image changes according to the two people's facial expressions. Different from traditional ways of communication, ""Let's Chat Like This"" focuses more on the emotional aspect of communication. It shows a visualization of the complexity of human emotion and boosts people's emotional communication in a creative no-verbal way. When experiencing this work, people's emotions are bound together with the same moving image they see. The moving image changes depending on their moods. They will be aware of their current moods as well as the other's, the intimacy and empathy between them will be increased.This is not only a ""social distancing"" art installation that helps us connect emotionally during the COVID-19 pandemic, but also my hypothesis of what future emotional communication will be like. I hope this artwork can evoke deep thinking and maybe cheer people up in this challenging time.";2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;NA;NA;NA;NA;NA;NA;NA;SA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Republic of Korea;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
FZB3FZPM;conferencePaper;2018;"Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Klapwijk, Remke";Developing Children's Empathy in Co-Design Activities: A Pilot Case Study;Proceedings of the 17th ACM Conference on Interaction Design and Children;978-1-4503-5152-2;NA;10.1145/3202185.3210797;https://doi.org/10.1145/3202185.3210797;This paper explores how co-design activities in schools can contribute to developing children's empathy. A pilot case study is presented in which eight 10- to 12-year-old children participated. The design theme was outdoor education. After discussing the co-design procedure, preliminary results about three empathic techniques are discussed: (1) reflection on the role of empathy in design, (2) storytelling to introduce the design challenge, and (3) defining the needs and wishes of the story's protagonists. The lessons learned are taken into account in a comprehensive follow-up study.;2018;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;669–674;NA;NA;NA;NA;NA;NA;IDC '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"children; empathy; storytelling; co-design; 21st century skills; schools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
296ZIL5L;conferencePaper;2013;"Shanahan, Joseph; Marghitu, Daniela";Software Engineering Java Curriculum with Alice and Cloud Computing;Proceedings of Alice Symposium on Alice Symposium;978-1-4503-2250-8;NA;10.1145/2532333.2532337;https://doi.org/10.1145/2532333.2532337;Project Expression is a course designed to attract students into the field of computing. Participants are trained in Java programming and the art of multimedia production. By implementing a wide range of apps they learn cloud communication techniques in a software environment. The course focuses on a digital film project and participants are challenged with creating a movie that expresses an idea, opinion, or belief relative to society. The film project is a landscape for learning cloud-computer-programming and reaches across the computer spectrum with engaging activities that stimulate creative design. This study examines the curriculum's approach and measures its effectiveness to teach the cloud-computing mentality. It emphasizes the importance of empathy in a technology-based society. Furthermore, it investigates whether or not such a course is an effective method for attracting students into the field of computing.;2013;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;NA;NA;NA;NA;NA;NA;NA;ALICE '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Durham, NC, USA;NA;NA;NA;"3D animations; 3D Visualization; Computers and Empathy; K-12 Computer Science Curriculum; K12 Alice Curriculum; K12 Cloud Computing Curriculum; Movie-making";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
L3ANZ9SI;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: A Living Media Interface for Speech Intervention;Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;978-1-4503-2473-1;NA;10.1145/2556288.2557402;https://doi.org/10.1145/2556288.2557402;Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.;2014;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;1817–1820;NA;NA;NA;NA;NA;NA;CHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"embedded computing; living media interfaces; speech intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
X67QZBM7;conferencePaper;2020;de Oliveira, Lariza Laura;Mapping Empathy in the Computer Science Classroom;Proceedings of the 2020 ACM Conference on International Computing Education Research;978-1-4503-7092-9;NA;10.1145/3372782.3408109;https://doi.org/10.1145/3372782.3408109;"Empathy is a humanistic skill, a capacity that allows us to perceive other people's emotions, putting ourselves under their perspective [1]. The study of empathy is highlighted as a tool to provide a better understanding of people's thoughts, feelings and how they affect behavior [2]. Being aware of that, a design company created the Empathy Map (EM), which is usually employed in the initial phase of the Design Thinking process to understand user's concerns, feelings and aspirations [3].Teaching practices known as student-centered, inherited from the constructivist school, are not new [4]. Several educators have applied these approaches inside the Computer Science (CS) classroom [5]. A key to success in CS education is the construction of the computational thinking [5]. Learning to program is not an easy task and the process is surrounded by several emotional reactions such as frustration, anxiety, happiness and others [6]. In this sense, EMs can be useful to capture student's feelings, guiding educators strategies during CS classes.Here, I describe the experience of using the EM inside the Computer Science classroom at the University Center Barão de Mauá. The process of building EMs involves the description of the persona, who, in this case, are the students of a given year in the CS course. In the center of EM, the picture of a student is drawn and the surrounding region is divided into 4 areas [3, 7]: 1) THINK and FEEL - What are the students thinking/feeling? 2) HEAR and SEE - What are the students hearing/seeing? 3) SAY and DO - What are the students saying/doing? 4) PAIN/CHALLENGES and GAINS - What are the challenges the students are facing? Is there anything painful to do? How do they measure success?The EM was performed in two different stages of the CS course: in the first and third years. The students were asked to build the EM, representing their feelings and aspirations about CS. The EM of the first year showed: 1) THINK and FEEL - ""thinking about the future"", ""feeling fear"", ""curiosity"", ""insecurity"", ""confusion"". 2) HEAR and SEE - "" hearing positive statements from family and friends"", ""seeing themselves in a trainee program"", ""working or doing a master's degree"", ""developing themselves"". They also reported to hear that CS is very difficult. 3) SAY and DO - They say learning is difficult, They do study and work; 4) PAIN/CHALLENGES - they report feeling insecure about finishing the course and find a position. The main challenge is to conciliate both working and studies. The students of the third year reported: 1) THINK and FEEL - ""thinking about the future"", ""feeling anxiety"", ""anger"", ""tiredness"", ""worry""; 2) HEAR and SEE - "" they hear that CS is a promising career"", ""see opportunities and/or lack of them"". They reported hear questions about what they will do in the future; 3) SAY and DO - ""procrastinating and working""; 4) PAIN/CHALLENGES - The pain reported refers to the anxiety of completing the course and the excessive procrastination. The main challenge reported was to set medium/short term goals as study to complete tasks in the CS course.As a conclusion, we highlight that the first year students were more motivated about their future, whereas the third year are tired and anxious about finishing the course. The EM construction was able to show student's feelings and pains about the course, allowing the educator to capture the student's perspectives. Based on that, it may be possible to conduct a more appropriate learning plan to manage how emotional aspects can influence the learning process. As a future work, EM will be used along with specific subjects in a qualitative study, considering subjects with highest failure rates in CS curriculum.";2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;303;NA;NA;NA;NA;NA;NA;ICER '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, New Zealand;NA;NA;NA;"computer science education; empathy map";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
3Q73QDE3;conferencePaper;2019;Liu, Fannie;Expressive Biosignals: Authentic Social Cues for Social Connection;Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5971-9;NA;10.1145/3290607.3299081;https://doi.org/10.1145/3290607.3299081;My research introduces expressive biosignals as a novel social cue to improve interpersonal communication. Expressive biosignals are sensed physiological data revealed between people to provide a deeper understanding of each other's psychological states. My prior work has shown the potential for these cues to provide authentic and validating emotional expression, while fostering awareness and social connection between people. In my proposed research, I expand on this work by exploring how social responses to biosignals can benefit communication through empathy-building and social support. This work will scope the design space for expressive biosignals and inform future interventions for a variety of social contexts, including interpersonal relationships and mental health.;2019;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;1–5;NA;NA;NA;NA;NA;NA;CHI EA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"social cues; biosignals; interpersonal communication; physiological sensing; social connection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
A4ZVLSQU;journalArticle;2020;"McDonald, Nora; Pan, Shimei";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415218;https://doi.org/10.1145/3415218;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.;2020-10;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"artificial intelligence; ethics; algorithm bias; education; intersectionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TB6GNWYZ;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: A Living Media Interface for Learning Games;CHI '14 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-2474-8;NA;10.1145/2559206.2574772;https://doi.org/10.1145/2559206.2574772;Digital games can engage children in therapeutic and learning activities. Incorporating living media in these games can create feelings of empathy and caring in users and add more motivation and involvement to the gameplay. We present, Rafigh, a living media interface designed to motivate children to play learning games that involve repetitive and sometimes boring tasks. In the current implementation the interface is used for speech intervention games. During gameplay, children practice their speech and care for a living mushroom colony in the process. The mushroom's growth is used to communicate how much speech is used, as an indicator of degree of speech practice, during interaction.;2014;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;407–410;NA;NA;NA;NA;NA;NA;CHI EA '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Toronto, Ontario, Canada;NA;NA;NA;"embedded computing; living media interfaces; speech intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZMZ4J7F5;conferencePaper;2012;Benkler, Yochai;The Penguin and the Leviathan: Towards Cooperative Human Systems Design;Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work;978-1-4503-1086-4;NA;10.1145/2145204.2145206;https://doi.org/10.1145/2145204.2145206;"A decade ago, Wikipedia burst into a world not ready to comprehend it. Thousands of people cooperating effectively, without price signals to offer 'incentives' or managerial hierarchy to direct efforts, was an impossibility. And yet, it moves. And as it moved it combined with a deep shift across many disciplines, from biology and neuroscience to organizational sociology, experimental economics, and social psychology to paint a very different view of who we are as human beings. Slowly pushing back against decades of ever-refined analyses based on self-interested rationality, we begin to see that we are diverse beings; that a majority of us responds cooperatively to cooperative settings–we tend to treat well those who have treated us well, rather than take advantage of them; we tend to do what we think is right and fair, when it is clear in the setting what that is; we experience empathy, and it makes us more generous and trustworthy; we experience solidarity with others, and that makes us contributed more willingly to the group's goals. Moreover, explicit payments, the touchstone of mechanism design under universal self-interested rationality, turns out to have a much more complex relationship with motivation than simple addition. All this work in basic behavioral sciences combines with observations from organizational sociology, political science, and management studies combines with social software to provide an increasingly better articulated basis on which to develop a field of cooperative human systems design.";2012;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;1–2;NA;NA;NA;NA;NA;NA;CSCW '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seattle, Washington, USA;NA;NA;NA;cooperative human systems design;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
F7X2N6UI;conferencePaper;2020;Vennekens, Joost;Service-Learning for Web Technology: Observations from a Small Case Study;Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education;978-1-4503-6874-2;NA;10.1145/3341525.3387414;https://doi.org/10.1145/3341525.3387414;"In the past academic year, we conducted an experiment at using service-learning in order to integrate learning of empathy and creativity into an undergraduate course on Web Technology. This was a small scale pilot project, conducted in collaboration with the service-learning team at our institute. In the project, students collaborated with WAI-NOT, a non-profit organization that develops an online platform for children with various kinds of (physical/mental) disabilities. The students developed new ""games"" for this platform, to teach the children basic computer skills (e.g., clicking, moving the mouse). Key in this project was the interaction between the students, the non-profit and the target audience. Due to the small size of the class, we did not conduct a quantitative evaluation of the project, but we do discuss the experiences and feedback from teachers, students and community.";2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;328–334;NA;NA;NA;NA;NA;NA;ITiCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"computer science education; service-learning; experience report";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JS6KKSH9;conferencePaper;2019;"Suzianti, Amalia; Atthousi, Hajid Naufal";Implementation of Design Thinking Approach In Designing Learning Support Tools In The Classroom For Hearing Impaired Person: Case Study: Elementary School Students in SLB-B Santi Rama;Proceedings of the 2019 5th International Conference on E-Business and Mobile Commerce;978-1-4503-7182-7;NA;10.1145/3332324.3332338;https://doi.org/10.1145/3332324.3332338;The absence of adequate accommodation for the hearing-impaired in the Education field is one of the problems in Indonesia nowadays. Teaching aids or learning support tools as accommodation can help the deaf to accelerate and improve the quality of their education. This research uses design thinking approach in designing the tool so that the result of the design is in accordance with the needs and desires of the users, which are deaf elementary students age 8-10. Started from the empathy phase until the define phase which obtained that the target users have a need and desire to learn the vocabulary with ease and fun then proceed with the ideation phase with stakeholders and prototyping to generate ideas and create the teaching aids in accordance with their needs and desires in the form of an arcade game with card of words and ended with the testing phase which shows that the tool is able to improve visual receptive language comprehension of 8.07% and visual expressive language of 77.74% in a fun way. This research has produced a teaching aids designed with design thinking approach which can improve the quality of their learning in school in accordance with the needs and desires of hearing-impaired elementary school students and has been validated by stakeholders.;2019;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;75–80;NA;NA;NA;NA;NA;NA;ICEMC 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Taichung, Taiwan;NA;NA;NA;"Design Thinking; Deaf Children; Hearing-impaired; Inclusive Design; Learning Support Tools; Persona";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JFRR6FNB;conferencePaper;2020;"Shi, Weishi; Khan, Saad; El-Glaly, Yasmine; Malachowsky, Samuel; Yu, Qi; Krutz, Daniel E.";Experiential Learning in Computing Accessibility Education;Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;978-1-4503-7122-3;NA;10.1145/3377812.3390901;https://doi.org/10.1145/3377812.3390901;Many developers don't understand how to, or recognize the need to develop accessible software. To address this, we have created five educational Accessibility Learning Labs (ALL) using an experiential learning structure. Each of these labs addresses a foundational concept in computing accessibility and both inform participants about foundational concepts in creating accessible software while also demonstrating the necessity of creating accessible software. The hosted labs provide a complete educational experience, containing materials such as lecture slides, activities, and quizzes.We evaluated the labs in ten sections of a CS2 course at our university, with 276 students participating. Our primary findings include: I) The labs are an effective way to inform participants about foundational topics in creating accessible software II) The labs demonstrate the potential benefits of our proposed experiential learning format in motivating participants about the importance of creating accessible software III) The labs demonstrate that empathy material increases learning retention. Created labs and project materials are publicly available on the project website: http://all.rit.edu;2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;250–251;NA;NA;NA;NA;NA;NA;ICSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, South Korea;NA;NA;NA;"accessibility education; computing accessibility; computing education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SALDPL5B;bookSection;2020;Tiwari, Divyanshu;Fostering Collaboration and Empathy Through Games;Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play;978-1-4503-7587-0;NA;NA;https://doi.org/10.1145/3383668.3419929;"Kids who can easily collaborate with their peers are often up to a great start in their adult life. For effective collaboration, the collaborating individuals must be empathetic enough to be able to understand each other well and resolve conflicts as and when they arise. However, such abstract concepts are difficult to teach in classrooms since they do not always adhere to the boundaries that theoretical definitions place on them. A much better way to explain such concepts lies in practicing them, and one of the key ways in which these skills can be practiced and taught in classrooms is through games. Games serve as an excellent learning tool since they make learning fun and help students pay attention and stay focused on the subject. For this reason, we have designed and developed a novel dual-player game called ""Two Shapes"" that makes use of its in-game mechanics as a tool to teach children the essential skills of collaboration and empathy. The game has been designed in such a way that the two players are required to recognize each other's strengths and abilities to overcome obstacles in their paths by leveraging them.";2020;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;91–93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LMY3TEIV;conferencePaper;2018;"Lyckvi, Sus; Torgersson, Olof";Privacy and Design Ethics vs Designing for Curiosity, Communication and Children: Lessons Learned;Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services;978-1-4503-5898-9;NA;10.1145/3229434.3229480;https://doi.org/10.1145/3229434.3229480;This paper describes the lessons learned when designing an empathy-oriented image-exchange app for fifth-grade pupils. The aim was to evoke curiosity and empathy towards someone living elsewhere or under different socio-economic circumstances. In addition, we strived to apply design ethics (e.g. protecting users from insults, humiliation, inappropriate content etc) and take users' privacy into account. By setting up these boundaries for this user group we found ourselves confronted with a set of conflicting design decisions which ultimately led to a lesser and different user experience than we had expected. Here, we discuss the interplay between our design decisions and the consequences thereof, and evaluate the mistakes we made. Moreover we discuss how to balance anonymity and curiosity, and comment on the benefits of making a pre-analysis of potential clashes related to intended UX and other core design decisions.;2018;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;NA;NA;NA;NA;NA;NA;NA;MobileHCI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"ethics; communication; empathy; curiosity; design for children; image sharing; privacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9DUSU9YP;journalArticle;2016;McBride, Neil;The Ethics of Driverless Cars;SIGCAS Comput. Soc.;NA;0095-2737;10.1145/2874239.2874265;https://doi.org/10.1145/2874239.2874265;This paper critiques the idea of full autonomy, as illustrated by Oxford University's Robotcar. A fully autonomous driverless car relies on no external inputs, including GPS and solely learns from its environment using learning algorithms. These cars decide when they drive, learn from human drivers and bid for insurance in real time. Full autonomy is pitched as a good end in itself, fixing human inadequacies and creating safety and certainty by the elimination of human involvement. Using the ACTIVE ethics framework, an ethical response to the fully autonomous driverless cars is developed by addressing autonomy, community, transparency, identity, value and empathy. I suggest that the pursuit of full autonomy does not recognise the essential importance of interdependencies between humans and machines. The removal of human involvement should require the driverless car to be more connected with its environment, drawing all the information it can from infrastructure, internet and other road users. This requires a systemic view, which addresses systems and relationships, which recognises the place of driverless cars in a connected system, which is open to the study of complex relationships, both networked and hierarchical.;2016-01;2021-02-15T21:34:48Z;2021-02-15T21:34:48Z;NA;179–184;NA;3;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"ethics; driverless cars; full autonomy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Q8MIHI8I;conferencePaper;2019;"Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco";A Preliminary Work on Dog Emotion Recognition;IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume;978-1-4503-6988-6;NA;10.1145/3358695.3361750;https://doi.org/10.1145/3358695.3361750;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications.The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.;2019;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;91–96;NA;NA;NA;NA;NA;NA;WI '19 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Thessaloniki, Greece;NA;NA;NA;"Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4HJW356N;conferencePaper;2020;"Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon";Robots Teaching Recycling: Towards Improving Environmental Literacy of Children;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3379462;https://doi.org/10.1145/3371382.3379462;The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.;2020;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;615–616;NA;NA;NA;NA;NA;NA;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Cambridge, United Kingdom;NA;NA;NA;"educational robotics; children robot interaction; eco-literacy; environmental literacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N3HKLLJX;conferencePaper;2015;"Lundgren, Sus; Torgersson, Olof; Björk, Staffan";Thrimage: An Empathy-Oriented Discussion Tool for Classroom Use;Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct;978-1-4503-3653-6;NA;10.1145/2786567.2792901;https://doi.org/10.1145/2786567.2792901;Thrimage is a class-application where pupils choose and rank images in relation to a given word or notion. In seeing who else chose similarly, as well as in a debriefing teacher-led discussion, pupils gain insight in others' way of thinking, and learn to argument for their own opinion but also to respect others, both of which supports the development of empathy and mutual understanding. The design is part of a long-running design exploration on designing of collaborative, co-located experiences using mobile devices, in combination with an educational need.;2015;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;628–635;NA;NA;NA;NA;NA;NA;MobileHCI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Copenhagen, Denmark;NA;NA;NA;"empathy; image sharing; Thrimage";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YG9I8DJW;conferencePaper;2015;"Ostrowski, S\lawomir; Rolczyński, Rafa\l; Pniewska, Joanna; Garnik, Igor";User-Friendly E-Learning Platform: A Case Study of a Design Thinking Approach Use;Proceedings of the Mulitimedia, Interaction, Design and Innnovation;978-1-4503-3601-7;NA;10.1145/2814464.2814483;https://doi.org/10.1145/2814464.2814483;"E-learning systems are very popular means to support the teaching process today. These systems are mainly used by universities as well as by commercial training centres. We analysed several popular e-learning platforms used in Polish universities and find them very unfriendly for the users. For this reason, the authors began the work on the creation of a new system that would be not only useful, but also usable for students, teachers and system administrators. This paper presents a case study of e-learning platform design process. We applied Design Thinking (DT) approach which puts a strong emphasis on the participation of end-users throughout the design process. Such an approach makes final product more user-friendly and better suited to end-users needs. An interdisciplinary team of designers implemented the design process in five stages: Empathizing - a thorough analysis of the problem and its context; Defining - synthesis of information obtained in the previous step and identifying user needs and insights; Ideating - generating solutions; Prototyping and Testing solutions proposed in the Ideating phase. During the design process the team used many additional methods, such as Empathy map, Stakeholders map, Value preposition canvas, personas, brainstorming, Card sorting and many more. As the result of design process we obtain an interactive prototype of designed e-learning platform. The prototype was tested by end-users and the feedback from the testers was collected. It confirmed that the use of the DT approach in design process allows to better fit designed product to the users' needs. The next step will be the implementation of tested and approved solutions to the real system what is planned in the nearest future.";2015;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;NA;NA;NA;NA;NA;MIDI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Warsaw, Poland;NA;NA;NA;"e-learning; Design Thinking; design process management";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QWIFUKA4;conferencePaper;2019;"Van Mechelen, Maarten; Schut, Alice; Gielen, Mathieu; Södergren, Antonia Clasina";Children's Assessment of Co-Design Skills: Creativity, Empathy and Collaboration;Proceedings of the 18th ACM International Conference on Interaction Design and Children;978-1-4503-6690-8;NA;10.1145/3311927.3325334;https://doi.org/10.1145/3311927.3325334;This paper presents a co-design project in a school with 16 children ages 10 to 11 in which three learning goals were defined upfront: creativity, empathy, and collaboration. The first part of the paper demonstrates how these co-design skills were implemented through an iterative process of explanation, practice, reflection, and application. Based on the results of post-interviews and short questionnaires, the second part discusses children's assessments of these skills. Whereas children reported fluctuations in applying these skills, the findings show an overall positive trend towards the end of the project. In future work, these findings will be triangulated with observational data.;2019;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;520–526;NA;NA;NA;NA;NA;NA;IDC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boise, ID, USA;NA;NA;NA;"Empathy; Children; 21st Century Skills; Co-design; Collaboration; Creativity; Design-based Learning; Participatory Design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WSMPEFBN;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2883-8;NA;10.1145/2696454.2696479;https://doi.org/10.1145/2696454.2696479;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;83–90;NA;NA;NA;NA;NA;NA;HRI '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
I7R8TVJH;bookSection;2020;"Chromik, Michael; Lachner, Florian; Butz, Andreas";ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research;Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society;978-1-4503-7579-5;NA;NA;https://doi.org/10.1145/3419249.3420163;Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML’s impact on current UXR activities and practitioners’ predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users’ emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research.;2020;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PJU73DT3;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";The CoWriter Project: Teaching a Robot How to Write;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702091;https://doi.org/10.1145/2701973.2702091;"This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.";2015;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;269;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
F9GKDGWZ;conferencePaper;2017;"Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin";Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games;Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology;978-1-4503-5548-3;NA;10.1145/3139131.3139132;https://doi.org/10.1145/3139131.3139132;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.;2017;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;NA;NA;NA;NA;NA;VRST '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gothenburg, Sweden;NA;NA;NA;"pet game; user types; virtual pet; virtual reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IPKGJSC4;conferencePaper;2015;"Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung";Design of Emotional Conversations with a Child for a Role Playing Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702009;https://doi.org/10.1145/2701973.2702009;The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.;2015;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;73–74;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"emotional role playing robot; human intervention device; human-robot-interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9F3UJ6HN;conferencePaper;2019;"Kawano, Atsuko; Motoyama, Yuji; Aoyama, Mikio";A LX (Learner EXperience)-Based Evaluation Method of the Education and Training Programs for Professional Software Engineers;Proceedings of the 2019 7th International Conference on Information and Education Technology;978-1-4503-6639-7;NA;10.1145/3323771.3323789;https://doi.org/10.1145/3323771.3323789;We propose a new design methodology to maximize the training effect in a corporate education and training for professional software engineers. Conventionally, the education and training programs have been designed in a top-down manner based on the long-term strategy on the business and engineering resources development. However, to draw out the learners' high performance from the education and training programs, we need to have an empathy with the learners, and to analyze their expectations and emotions in order to motivate them. Therefore, this paper proposes the learner-centered design methodology of the corporate education and training programs inspired by the design thinking and lean start-up concepts. We define the learning processes in the education and training programs as LX (Learner eXperience), and propose LJM (Learning Journey Map) as the LX evaluation method as an extension of CJM (Customer Journey Map) in UX (User eXperience) design. The LJM enables to evaluate training effect and communicate with stakeholders in the training design expressing the LX quantitatively in a visual form. We applied the proposed design methodology to the education and training programs for professional software engineers in a company to evaluate LX and elicit learner requirements to the programs. We applied the proposed LJM to the education and training program of two levels of the whole program and its LUs (Learning Units), and identified problems in the LX. From the empirical study, we confirm the effectiveness of the proposed methodology.;2019;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;151–159;NA;NA;NA;NA;NA;NA;ICIET 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aizu-Wakamatsu, Japan;NA;NA;NA;"Design thinking; Corporate education and training program; Journey map; Lean start-up; LX (Learner eXperience); Professional software engineer; UX (User eXperience)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R8SS987J;conferencePaper;2016;"Fan, Mingyue; Yu, Liyue; Bowler, Leanne";Feelbook: A Social Media App for Teens Designed to Foster Positive Online Behavior and Prevent Cyberbullying;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2892398;https://doi.org/10.1145/2851581.2892398;This project presents a prototype for a stand-alone social media application designed for teenage users in order to prevent and mitigate mean and cruel online behavior. The purpose of the app is to create a nurturing environment where teenagers use a variety of features designed to help raise self-awareness of their own online behavior, seek support when needed, and learn to control and, when possible, correct aggressive behavior. The prototype is framed by four design principles: design for reflection, design for empathy, design for empowerment, and design for the whole. We conclude by outlining the next steps in our project to develop an application that helps to improve the online experiences of young people. This work has implications for the CHI community because it applies software solutions to tackle a critical social problem that can affect the health and well being of young people.;2016;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;1187–1192;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Jose, California, USA;NA;NA;NA;"social media; empathy; cyberbullying; reflection; social computing; teens; young adults";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
D9KXDAWP;bookSection;2017;"Schaper, Marie-Monique; Santos, Maria; Malinverni, Laura; Pares, Narcis";Towards the Design of a Virtual Heritage Experience Based on the World-as-Support Interaction Paradigm;Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4656-6;NA;NA;https://doi.org/10.1145/3027063.3053089;We present the initial design stage of a Virtual Heritage experience for a bomb shelter built during the Spanish Civil War, namely Refugi 307. The shelter currently belongs to the History Museum of Barcelona which provides guided tours through the cultural heritage site for schools and the general public. The aim of the study was to define the requirements for the design of a first prototype based on the World-as-Support interaction paradigm. We conducted an ethnographic study and Participatory Design workshop to analyze different aspects of the requirements and to include multiple needs and viewpoints of the involved stakeholders. Based on the outcomes, we outline the potential for activities to foster (1) contextual-awareness between the learning content and the cultural heritage site, (2) environment-awareness in relation to missing objects in the physical space and (3) social-awareness to embody feelings related to solidarity and empathy.;2017;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;2034–2041;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YBY8S5UL;journalArticle;2020;"Hwang, Amy S.; Jackson, Piper; Sixsmith, Andrew; Nygård, Louise; Astell, Arlene; Truong, Khai N.; Mihailidis, Alex";Exploring How Persons with Dementia and Care Partners Collaboratively Appropriate Information and Communication Technologies;ACM Trans. Comput.-Hum. Interact.;NA;1073-0516;10.1145/3389377;https://doi.org/10.1145/3389377;"Persons with dementia and their care partners have been found to adapt their own technological arrangements using commercially available information and communication technologies (ICTs). Yet, little is known about these processes of technology appropriation and how care practices are impacted. Adopting a relational perspective of care, we longitudinally examined how four family care networks appropriated a new commercial ICT service into their existing technological arrangements and care practices. Cross-case analysis interpreted collaborative appropriation to encompass two interrelated processes of creating and adapting technological practices and negotiating and augmenting care relationships. Four driving forces were also proposed: motivating meanings that actors ascribe to the technology and its use; the learnability of the technology and actors’ resourcefulness; the establishment of responsive and cooperative care practices; and the qualities of empathy and shared power in care relationships. The importance of technological literacy, learning, meaning-making, and the nature and quality of care relationships are discussed. Future work is urged to employ longitudinal and naturalistic approaches, and focus design efforts on promoting synergistic care relationships and care practices.";2020-11;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"dementia; Alzheimer's disease; appropriation; care practices; care relationship; caregiving; case study; cognitive impairment; commercial product; family care; information and communication technologies; off-the-shelf";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
LBT6NB79;journalArticle;2020;"Lin, Xin Yao; Saksono, Herman; Stowell, Elizabeth; Lachman, Margie E.; Castaneda-Sceppa, Carmen; Parker, Andrea G.";"Go&amp;Grow: An Evaluation of a Pervasive Social Exergame for Caregivers of Loved Ones with Dementia";Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415222;https://doi.org/10.1145/3415222;"Caregivers of persons with dementia (PWD) experience higher rates of stress, social isolation, and poor mental and physical health compared to non-caregiving populations. There is a vital need for engaging, sustainable, and scalable resources to support social, physical, and emotional wellbeing amongst caregivers of PWD. To explore this open design space, we designed and conducted a 6-week mixed-method evaluation of Go&amp;Grow, a pervasive social exergame in which flowers grow as users increase physical activity and interact with other caregivers of PWD. Our findings showed that using Go&amp;Grow helped participants relieve stress, increase physical activity, and develop empathy for and patience towards the loved one with dementia that they cared for. At the same time, tension arose as some caregivers desired to learn about the life challenges that Go&amp;Grow users faced, while others hesitated to share such content. We discuss our findings and recommendations for future technology that promotes caregivers? time for themselves, understanding of PWD, and connections with other caregivers.";2020-10;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"caregiver; exergame; intervention; people with dementia; physical activity; social connectedness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5K5H8BDF;bookSection;2020;"van den Berg, Carolien; Verster, Belinda";Co-Creating Social, Digital Innovation to Recognise Agency in Communities: A Learning Intervention: Research in Progress;Conference of the South African Institute of Computer Scientists and Information Technologists 2020;978-1-4503-8847-4;NA;NA;https://doi.org/10.1145/3410886.3410912;This paper presents findings from a pilot project, of an ongoing Design-Based Research (DBR) initiative, where students in an Information Systems (IS) module proposed social, digital innovations for complex problems within marginalised communities in Cape Town, South Africa. The aim of the pilot project was to develop digital innovations that recognise agency in communities through lived experiences and local knowledge. An urban planning perspective was introduced to contextualise socio-environmental challenges to ground social innovations in reality and encourage a sustainable uptake of digital innovations by communities. The IS student projects emphasised empathy, storytelling and prototyping as part of a design thinking process which both incorporated and influenced the conceptual model presented in this paper. This conceptual model informed by four design principles of - relationality, reflexivity, responsiveness and recognition - is offered as an enrichment for a learning environment. It foregrounds the development of competencies for collaborative problem solving and ultimately transdisciplinary knowledge creation.;2020;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;85–93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5ASGR7RR;conferencePaper;2017;"Köppe, Christian; Nørgård, Rikke Toft; Pedersen, Alex Young";Towards a Pattern Language for Hybrid Education;Proceedings of the VikingPLoP 2017 Conference on Pattern Languages of Program;978-1-4503-6342-6;NA;10.1145/3158491.3158504;https://doi.org/10.1145/3158491.3158504;In this paper we offer an initial framework for a pattern language of hybrid education. With the term hybrid education, we imply the use of educational design patterns that actively strive to cut across, circumventing or upheave traditional dichotomies within education such as physical-digital, academic-nonacademic, online-offline, formal-informal, learning-teaching and individual-collective. In doing so, hybrid education invites uncertainty, open-endedness, risk-taking, experimentation, critical creativity, disruption, dialogue and democracy (back) into the heart of education. Accordingly we see, within hybrid education, the promise to push against and circumvent current trends of marketization, managerialism and standardization in higher education today. Here, a pattern language for hybrid education presents an alternative way of designing for future higher education in ways that are not focused on teaching to the test, playing it safe, rankings or gaming the system approaches. Rather, hybrid education focuses on open-endedness, risk-taking, relational entanglements, experimentation, exploration and empathy. In this way, designing for hybrid education is in this paper achieved, partly by taking a decidedly value-based and vision-driven approach to learning design patterns based on philosophy in higher education and critical pedagogy, partly by working together in hybrid ways and across disciplines and domains in order to open up both the field of teaching and learning in higher education as well as the field of learning design and design patterns. The result is the almost 80 design patterns for hybrid education. The paper presents the pattern categories for hybrid education, the different design patterns contained in these. Furthermore, the pattern mining ground and workshop process, the outcome of the value workshop and the vision workshop as well as three example scenarios is described in order to show both the underlying value and vision foundation for the pattern language as well as how it plays out in concrete scenarios.;2017;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;NA;NA;NA;NA;NA;NA;NA;VikingPLoP '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Grube, Schleswig-Holstein, Germany;NA;NA;NA;"education; educational patterns; hybrid pedagogy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ULXGNCRI;conferencePaper;2014;"Potter, Leigh Ellen; Korte, Jessica; Nielsen, Sue";Design with the Deaf: Do Deaf Children Need Their Own Approach When Designing Technology?;Proceedings of the 2014 Conference on Interaction Design and Children;978-1-4503-2272-0;NA;10.1145/2593968.2610464;https://doi.org/10.1145/2593968.2610464;In this paper, we focus on the question of design of technology for Deaf children, and whether the needs of these children are different from their hearing counterparts in a technology design setting. We present findings from literature together with our own observations to determine if there are distinguishing characteristics for Deaf children that may influence design sessions with them. We found that Deaf children generally have reduced literacy and slower academic progress, reduced social and emotional development, reduced empathy and a level of nervousness in novel situations, delayed language development, and limited or delayed spoken language. We also found that Deaf children are active and innovative in approaching communication, have sensitive visual attention in their peripheral vision, enhanced attention to small visual changes, and a capacity for visual learning. Finally, cultural issues within the Deaf community mean that Deaf children should be free to interact on their own terms in a design situation. We suggest that these differences merit the development of a design approach specific to the needs of Deaf children.;2014;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;249–252;NA;NA;NA;NA;NA;NA;IDC '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aarhus, Denmark;NA;NA;NA;"prototyping; child computer interaction; deaf children";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DD2GNFAW;conferencePaper;2013;"Slegers, Karin; Wilkinson, Andrea; Hendriks, Niels";Active Collaboration in Healthcare Design: Participatory Design to Develop a Dementia Care App;CHI '13 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-1952-2;NA;10.1145/2468356.2468440;https://doi.org/10.1145/2468356.2468440;"This paper describes a research project aimed at developing a mealtime data registration tool for people with dementia. As to actively involve all stakeholders in this healthcare design project and to generate empathy and involvement, methods from participatory design were used. For each of the three research phases (ethnography, ideation &amp; conceptualization and prototyping) we describe our approach towards stakeholder involvement and active collaboration. We discuss lessons learned in terms of good practices and the issues we struggle with.";2013;2021-02-15T21:34:49Z;2021-02-15T21:34:49Z;NA;475–480;NA;NA;NA;NA;NA;NA;CHI EA '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"dementia; participatory design; prototyping; healthcare";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SZXVDZC6;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica";Good Robot Design or Machiavellian? An in-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;382–391;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
Y843R339;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-Based Computational Framework for an Empathetic Robot;Proceedings of the 2019 11th International Conference on Computer and Automation Engineering;978-1-4503-6287-0;NA;10.1145/3313991.3314018;https://doi.org/10.1145/3313991.3314018;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;102–108;NA;NA;NA;NA;NA;NA;ICCAE 2019;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Perth, WN, Australia;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
GMSK565K;conferencePaper;2015;"Sobel, Kiley; O'Leary, Katie; Kientz, Julie A.";Maximizing Children's Opportunities with Inclusive Play: Considerations for Interactive Technology Design;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771844;https://doi.org/10.1145/2771839.2771844;Inclusive play, defined as play among children with and without disabilities, provides learning opportunities that challenge stereotypes, foster strong friendships, and help children develop empathy and other social and emotional skills. Designing technologies to support inclusive play are understudied in Human-Computer Interaction. We synthesized literature, conducted design ethnography in an inclusive classroom, and interviewed and surveyed parents and teachers to explore this problem. Our research contributes an empirical understanding of the current state of inclusive play and a characterization of the design space for interactive technologies that can support children and adults with inclusive play. We identify key facilitators of inclusive play: direct and embedded supports, transparency, adjustability, emphasis on children's interests and strengths, and current technology use. We also describe significant barriers to inclusive play: effort required to facilitate inclusive play, children's preferences, parental inexperience, and inappropriate technology. Through our discussion, we conclude that interactive technologies should be designed to harness the facilitators and help overcome the barriers in order to maximize children's opportunities with inclusive play.;2015;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;39–48;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boston, Massachusetts;NA;NA;NA;"children; human-centered design; assistive technology; inclusion; inclusive design; inclusive play; universal design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JKHYJZ4K;conferencePaper;2020;"Olson, Danielle Marie; Harrell, D. Fox, Ph.D.";“I Don't See Color”: Characterizing Players’ Racial Attitudes and Experiences via an Anti-Bias Simulation Videogame;International Conference on the Foundations of Digital Games;978-1-4503-8807-8;NA;10.1145/3402942.3409783;https://doi.org/10.1145/3402942.3409783;Videogames and learning/training applications that address racial discrimination have risen in popularity recently, coinciding with the rapid development of the field of serious (or impact) games [1, 2]. While there has been much focus on understanding the efficacy of these systems as interventions to reduce racial bias, there has been less attention paid to how individuals’ prior physical-world racial attitudes influence their experiences of such games about racial issues. Toward addressing this gap, the study presented here examines the relationships between PreK-12 educators’ colorblind racial attitudes and their game experience and narrative interpretations in narrative videogame modeling racial and ethnic socialization called Passage Home. Passage Home embeds a novel computational model and simulation informed by the Racial Encounter Coping Appraisal and Socialization Theory (RECAST) [3] to simulate a discriminatory racial encounter in a classroom setting. The system serves as a tool for assessing players’ racial and ethnic socialization (RES) experiences to support interventions for learning about racial bias. This paper presents the results of a user study deploying Passage Home with PreK-12 educators. Analysis revealed that players’ colorblind racial attitudes and ethnic identity were related to their in-game racial appraisal and feelings of competence, negative affect, and empathy in the game. Given the prevalence of colorblind racial ideology across racial and ethnic groups in the United States [4, 5], we propose an initial typology of players’ colorblind racial attitudes emerging from this analysis to aid in the future development of serious game interventions addressing racial discrimination.;2020;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;NA;NA;NA;NA;NA;NA;NA;FDG '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bugibba, Malta;NA;NA;NA;"human-computer interaction; Avatars; serious games; social identity; reflection; educational game; game design; identity; impact games; interactive narrative; racial discrimination; serious play; transformative education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NZWRS7AS;conferencePaper;2020;"Groeneveld, Wouter; Jacobs, Hans; Vennekens, Joost; Aerts, Kris";Non-Cognitive Abilities of Exceptional Software Engineers: A Delphi Study;Proceedings of the 51st ACM Technical Symposium on Computer Science Education;978-1-4503-6793-6;NA;10.1145/3328778.3366811;https://doi.org/10.1145/3328778.3366811;Important building blocks of software engineering concepts are without a doubt technical. During the last decade, research and practical interest for non-technicalities has grown, revealing the building blocks to be various skills and abilities beside pure technical knowledge. Multiple attempts to categorise these blocks have been made, but so far little international studies have been performed that identify skills by asking experts from both the industrial and academic world: which abilities are needed for a developer to excel in the software engineering industry? To answer this question, we performed a Delphi study, inviting 36 experts from 11 different countries world-wide, affiliated with 21 internationally renowned institutions. This study presents the 55 identified and ranked skills as classified in four major areas: communicative skills (empathy, actively listening, etc.), collaborative skills (sharing responsibility, learning from each other, etc.), problem solving skills (verifying assumptions, solution-oriented thinking, etc.), and personal skills (curiosity, being open to ideas, etc.), of which a comparison has been made between opinions of technical experts, business experts, and academics. We hope this work inspires educators and practitioners to adjust their training programs, mitigating the gap between the industry and the academic world.;2020;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;1096–1102;NA;NA;NA;NA;NA;NA;SIGCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, OR, USA;NA;NA;NA;"delphi study; industry requirements; non-cognitive abilities; professional skills; software developer; software engineering edutation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VM2GUPI9;conferencePaper;2019;"Munteanu, Cosmin; Oviatt, Sharon";CHI 2019 Early Career Development Symposium;Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5971-9;NA;10.1145/3290607.3298999;https://doi.org/10.1145/3290607.3298999;The first few years after completing a PhD can be challenging to navigate. Job hunting, interviewing, navigating new contexts such as a junior academic position, applying for funding as a first time project investigator, learning to adapt to the culture of an industry-based workplace, supervising graduate students or full-time employees - these are just a few of the scenarios recent PhD graduates find themselves in. Within HCI, one may encounter more discipline-specific challenges, such as keeping up with the CHI publication cycles while taking on new administrative duties. The CHI community, however, strives to be collectively supportive and inclusive of researchers at all stages of their career - this is even more important as many of our design approaches are rooted in empathy for and empowerment of participants. By more actively supporting each other as researchers in our career paths, we can better grow as a community, and reflect it back into our collective body of practice. The Early Career Development Symposium has been proposed (and held yearly since 2016) to provide a more formal mentoring venue that reflects our aims as a community to more meaningfully support each other.;2019;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;1–5;NA;NA;NA;NA;NA;NA;CHI EA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"mentoring; early career; post phd";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SXA3SM6W;conferencePaper;2014;Matsuzawa, Tetsuro;Evolution of Human Mind and Culture Viewed from the Study of Chimpanzees;"Proceedings of the 5th ACM International Conference on Collaboration across Boundaries: Culture, Distance &amp; Technology";978-1-4503-2557-8;NA;10.1145/2631488.2637432;https://doi.org/10.1145/2631488.2637432;"I have studied chimpanzees both in the wild and in the laboratory. My talk illustrates the evolutionary origins of human mind and culture. The human mother–infant relationship is characterized by physical separation, and the stable supine posture of infants; enabling face-to-face communication via facial expressions, vocal exchange, and manual gestures, and also demonstration of object manipulation. I have used the novel ""participant observation"" method in the laboratory and through ""field experiments"" in their natural habitat. There are several critical differences between the two species: chimpanzees lack the social referencing ability observed in human children and chimpanzees seldom engage in active teaching. Moreover, although young chimpanzees showed unique working memory capacity, often superior to that of human adults, they are less able to learning symbols. In sum, mind and culture in humans is fundamentally influenced by the manner of raising young children; characterized by collaboration among multiple adults. This aspect of human rearing may be linked to the development of empathy, altruistic behavior, reciprocity, understanding others? minds, and so on. Taken together, my talk presents evolutionary and ontogenetic explanations for the uniquely human cognition and culture.";2014;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;141;NA;NA;NA;NA;NA;NA;CABS '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Kyoto, Japan;NA;NA;NA;"evolution; culture; chimpanzees and human comparison";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TAG3R7M3;conferencePaper;2018;McDonald, Heidi;IThirve Games Empathy Jam at DigiPen;Proceedings of the International Conference on Game Jams, Hackathons, and Game Creation Events;978-1-4503-6484-3;NA;10.1145/3196697.3196704;https://doi.org/10.1145/3196697.3196704;This Event Report concerns the Empathy Jam iThrive Games held in cooperation with DigiPen Institute of Technology in Seattle, WA, on September 15-17, 2017. iThrive Games is a nonprofit that exists to create meaningful opportunities for teens to enhance the knowledge, mindsets, and skills they need to thrive across development, to engage actively in their learning and in their community, and to be healthy. We embrace the positive potential of games, and find a strengths-based approach to be especially important to this work. Game Jams are an important way that iThrive can educate and perform developer outreach in accordance with our mission. We do game jams at universities and regional game festivals, with the goal of bringing together people to build games together using our science based, expert-developed design resources (available for free download at the iThrive Games website: www.ithrivegames.org) to help developers make games toward prosocial outcomes. Our jams not only demonstrate what kinds of games can result from these design concepts, but are also important events to foster ongoing collaboration and to facilitate mentoring relationships at multiple levels. These jams also allow us to test and refine our design resources with the help of the people they are intended for.;2018;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;28–33;NA;NA;NA;NA;NA;NA;ICGJ 2018;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Francisco, CA, USA;NA;NA;NA;"serious games; empathy games; games for teens; iThrive Games; jams for teens; kindness games; prosocial outcomes; social emotional learning; teen development; transformational frameworks; transformational games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
F24SYU87;journalArticle;2019;"Not, Elena; Cavada, Dario; Maule, Stefano; Pisetti, Anna; Venturini, Adriano";Digital Augmentation of Historical Objects Through Tangible Interaction;J. Comput. Cult. Herit.;NA;1556-4673;10.1145/3297764;https://doi.org/10.1145/3297764;The technological advances brought about by the Internet of Things enable new opportunities for a more direct interaction among users, objects, and places. This is an extremely valuable innovation for the cultural heritage sector, as it allows a more transparent use of technology in the digital augmentation of museums and cultural heritage sites. The possibility to augment physical objects with sensors detecting when they are moved and manipulated enables scenarios where descriptive information about objects is presented to users at the very exact time they are looking at them, stimulating engagement. This article describes a collaborative research effort among cultural heritage professionals, human–computer interaction experts, and developers that was aimed at investigating the goals and constraints curators consider for a physical encounter between visitors and historic relics. In a case study, we co-designed an interactive plinth centred on tangible interaction and evaluated the impact on the user experience of combining digital information with a hands-on experience of relics of World War I. Our findings show that visitors value this type of tangible interaction with collection objects positively, as it allows the discovery of details and the learning of aspects that normally go unnoticed. The synergy between physical and digital aspects stimulates empathy with the original users of the object and fosters social interaction.;2019-06;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;NA;NA;3;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"internet of things; Digitally augmented objects; museum experience; tangible and embodied interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BJIB7QI2;conferencePaper;2017;Chapman, Gail;Inspire, Innovate, Improve! What Does This Mean for CS for All?;Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education;978-1-4503-4698-6;NA;10.1145/3017680.3025047;https://doi.org/10.1145/3017680.3025047;"In January 2016, President Obama unveiled the CS for All initiative. With all the attention and publicity surrounding CS for All and increased support from a variety of corners over the ensuing year, it is easy to become complacent and start believing that we have ""arrived"". During her 2016 SIGCSE keynote, Jan Cuny talked about catching the wave and using it to our advantage. This talk will focus on where we go from here. We caught the wave; now what do we do to ensure that we don't get swallowed by it? What lessons can be learned from an election that featured the likes of fake news, Wiki leaks, rogue email servers, runaway tweets and showed in stark relief the divides that exist in our country. Computer science represents one of those divides. Given this and the fact that addressing the educational inequities prevalent in computer science was front and center in the CS for All announcement, what better time is there to renew our commitment to broadening participation in computing? As educators we have a powerful opportunity and responsibility in the wake of the blowback from the election-to educate, to listen, to remind ourselves constantly that we live in a very diverse country. We have no shortage of innovation in computer science, but who are we inspiring, what impact are those innovations having, and what can we do to learn from the lessons of the past to improve CS education? And above all, how do we respond to the challenges before us with empathy for those who are impacted by the decisions we make?";2017;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;1;NA;NA;NA;NA;NA;NA;SIGCSE '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seattle, Washington, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JUN9MTAL;conferencePaper;2018;"Hieida, Chie; Horii, Takato; Nagai, Takayuki";Decision-Making in Emotion Model;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177048;https://doi.org/10.1145/3173386.3177048;Having emotions is essential for robots to understand and sympathize with the feelings of people. In addition, it may allow the robots to be accepted into human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions based on various neurological and psychological findings that are related to empathic communication between humans and robots is proposed. Subsequently, a mechanism of decision-making that is based on affects using convolutional LSTM and deep Q-network is examined.;2018;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;127–128;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Chicago, IL, USA;NA;NA;NA;"decision-making; model of emotion; empathic hri";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
563DSPXU;conferencePaper;2013;"Ramírez, Ricardo; Parthasarathy, Balaji; Gordon, Andrew";From Infomediaries to Infomediation at Public Access Venues: Lessons from a 3-Country Study;Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1;978-1-4503-1906-5;NA;10.1145/2516604.2516621;https://doi.org/10.1145/2516604.2516621;This study investigated the role of infomediaries to understand the process of infomediation in shaping outcomes for users at public access venues (PAVs) in Bangladesh, Chile and Lithuania. We examined the extent to which technical skills and empathy are relevant to and appreciated by different types of users, and whether differences in infomediaries are evident across different types of PAVs. We asked whether particular infomediary behaviours were associated with outcome differences as reported by PAV users. We learned that infomediaries provide the human face for the information age by taking on the functions of facilitation, coaching, referral and teaching, and by assuming the role of a trusted gatekeeper. The process of infomediation turned out to be of prominence, within which the infomediary is a key component. In the absence of infomediaries, those left behind (or excluded due to their age, socio-economic status, level of education/literacy, gender, disability or caste) will face additional, perhaps insurmountable, barriers.;2013;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;124–132;NA;NA;NA;NA;NA;NA;ICTD '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Cape Town, South Africa;NA;NA;NA;"empathy; information and communication technologies; brokering; ICTD; infomediary; infomediation; public access";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TSUZ6V88;conferencePaper;2020;"Branco, Karina da S. C.; Oliveira, Rhenara A.; Silva, Francisco L. Q. da; de H. Rabelo, Jacilane; Marques, Anna B. S.";Does This Persona Represent Me? Investigating an Approach for Automatic Generation of Personas Based on Questionnaires and Clustering;Proceedings of the 19th Brazilian Symposium on Human Factors in Computing Systems;978-1-4503-8172-7;NA;10.1145/3424953.3426648;https://doi.org/10.1145/3424953.3426648;"Personas are fictional representations of an end user based on data collected from a specific target audience. The creation of personas takes time, because part of the process is manual, which causes difficulties during the stages of data generation and analysis, if the data sample is large. The present work aims to investigate the results of the automatic generation of personas through a questionnaire and the Clustering method. Initially, a questionnaire was applied in order to outline the profile of students in the Computer Science and Software Engineering courses at the university Federal of Ceará. 130 responses were obtained from this applied questionnaire. The automatic generation of personas used the collected responses as a database, these data were applied to the Clustering method. From Clustering, using a specific tool for this purpose, it was possible to generate four personas automatically. In relation to the data generated from the personas, it was possible to identify some characteristics, such as: (a) course choice factor: the opportunity to work with new technologies, influence of family and friends and the possibility of living abroad; (b) factor of withdrawal from the course: lack of identification with the course, learning difficulties in the disciplines and finance; and, (c) area of interest: software engineering, human-computer interaction and computer graphics. A new questionnaire was applied in order to validate the personas generated in relation to credibility, empathy and similarity. Based on the results obtained, it was observed that two of the four personas generated achieved greater prominence in relation to the validation criteria, showing that the personas look like real people, students think like the personas and share similar interests.";2020;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;NA;NA;NA;NA;NA;NA;NA;IHC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Diamantina, Brazil;NA;NA;NA;"personas; clustering; automatic generation of personas; personas validation; questionnaire";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
GUZKUKIJ;conferencePaper;2017;Richards, Deborah;Intimately Intelligent Virtual Agents: Knowing the Human beyond Sensory Input;Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents;978-1-4503-5558-2;NA;10.1145/3139491.3139505;https://doi.org/10.1145/3139491.3139505;Despite being in the era of Big Data, where our devices seem to anticipate and feed our every desire, intelligent virtual agents appear to lack intimate and important knowledge of their user. Current cognitive agent architectures usually include situation awareness that allows agents to sense their environment, including their human partner, and provide congruent empathic behaviours. Depending on the framework, agents may exhibit their own personality, culture, memories, goals and reasoning styles. However, tailored adaptive behaviours based on multi-dimensional and deep understanding of the human essential for enduring beneficial relationships in certain contexts are lacking. In this paper, examples are provided of what an agent may need to know about the human in the application domains of education, health and cybersecurity and the challenges around agent adaptation and acquisition of relevant data and knowledge.;2017;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;39–40;NA;NA;NA;NA;NA;NA;ISIAA 2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, UK;NA;NA;NA;"Intelligent Virtual Agents; User Modelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VV9CNDM6;conferencePaper;2014;"Janarthanam, Srinivasan; Hastie, Helen; Deshmukh, Amol; Aylett, Ruth";Towards a Serious Game Playing Empathic Robotic Tutorial Dialogue System;Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2658-2;NA;10.1145/2559636.2563707;https://doi.org/10.1145/2559636.2563707;There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.;2014;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;180–181;NA;NA;NA;NA;NA;NA;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bielefeld, Germany;NA;NA;NA;"serious games; dialogue management; empathic robotic tutor; tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RTDRF4FQ;conferencePaper;2010;"Rivera, Fiona; Watten, Phil; Holroyd, Patrick; Beacher, Felix; Mania, Katerina; Critchley, Hugo";Real-Time Compositing Framework for Interactive Stereo FMRI Displays;ACM SIGGRAPH 2010 Posters;978-1-4503-0393-4;NA;10.1145/1836845.1836862;https://doi.org/10.1145/1836845.1836862;This research concentrates on providing high fidelity animation, only achievable with offline rendering solutions, for interactive fMRI-based experiments. Virtual characters are well established within the film, game and research worlds, yet much remains to be learned about which design, stylistic or behavioural factors combine to make a believable character. The definition of believability depends on context. When designing and implementing characters for entertainment, the concern is making believable characters that the audience will engage with. When using virtual characters in experiments, the aim is to create characters and synthetic spaces that people respond to in a similar manner to their real world counterparts. Research has shown that users show empathy for virtual characters. However, uncanny valley effects – ie dips in user impressions – can arise: behavioural fidelity expectations increase alongside increases in visual fidelity and vice versa. Often, characters used within virtual environments tend to be of fairly low fidelity due to technological constraints including rendering in real-time (Garau et al. 2003). This problem is addressed here by using non-linear playback and compositing of pre-rendered high fidelity sequences.;2010;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;NA;NA;NA;NA;NA;NA;NA;SIGGRAPH '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Los Angeles, California;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2Y52A48Y;conferencePaper;2020;"Bastos, João Antonio D. M.; de Mello, Rafael Maiani; Garcia, Alessandro";Colloquy: A Method for Conversational API Design;Proceedings of the 34th Brazilian Symposium on Software Engineering;978-1-4503-8753-8;NA;10.1145/3422392.3422468;https://doi.org/10.1145/3422392.3422468;APIs (application programming interfaces) play a key role in software development. Virtually, all programmers are potential users of third-party APIs. From the perspective of the theory of Semiotic Engineering, we may characterize an API as an artifact mediating the communication between two types of developers: the API designers and its users. During the construction of an API, the designers should establish proper dialogues with the users. These dialogues will enable the conversation of these actors at the interaction time. In this way, we define a conversational API as an API capable of offering effective dialogues to its users. In this paper, we introduce Colloquy, a method for supporting the design of conversational APIs. Colloquy results from the lessons learnt during an action research conducted for redesigning a real and complex API. The set of Colloquy resources allow API designers to go beyond conventional concerns with usability. We also report in this paper a case study in which Colloquy was used for redesigning a refactoring API. The study findings indicate the method helped the designer creating empathy with the API users, as well as better reflecting and depicting the requirements and the conversations that the API should attend to the different user profiles.;2020;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;514–519;NA;NA;NA;NA;NA;NA;SBES '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Natal, Brazil;NA;NA;NA;"API Conversacional; Engenharia Semiótica; Método de Design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NX5S99ZV;conferencePaper;2016;"Chisik, Yoram; Mancini, Clara";Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans;Proceedings of the 14th Participatory Design Conference: Short Papers, Interactive Exhibitions, Workshops - Volume 2;978-1-4503-4136-3;NA;10.1145/2948076.2948093;https://doi.org/10.1145/2948076.2948093;Participatory Design strives to broaden the perspective of and increase empathy in design by giving specific and often under represented user groups, such as children or older people, a voice in the design process. The exact nature of the role played by such participants in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the participatory design community. The emerging field of Animal Computer Interaction, which seeks to empower animals through user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.;2016;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;123–124;NA;NA;NA;NA;NA;NA;PDC '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aarhus, Denmark;NA;NA;NA;"children; participatory design; ACI; animal computer interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NMJ5BVVF;conferencePaper;2014;"Williams, Mary-Anne; Wang, Xun; Parajuli, Pramod; Abedi, Shaukat; Youssef, Michelle; Wang, Wei";The Fugitive: A Robot in the Wild;Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-2658-2;NA;10.1145/2559636.2559653;https://doi.org/10.1145/2559636.2559653;The aim of the movie is to highlight some of the key challenges facing social robots in the wild. The opening scene shows a PR2 leaving a research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building.The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is assigned menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not.The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on.The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but chastising a male-human for not observing this important social protocol.The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceitfully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.;2014;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;111;NA;NA;NA;NA;NA;NA;HRI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Bielefeld, Germany;NA;NA;NA;"human-robot interaction; social robotics; robots in the wild";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DMIHMXLI;bookSection;2017;"Cole, Amelia W.; Quesnel, Denise T.; Pekçetin, Serkan; Gromala, Diane; O'Brien, Heather; Antle, Alissa N.; Riecke, Bernhard E.";Integrating Affective Responses and Gamification into Early Reading Acquisition Software Applications;Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play;978-1-4503-5111-9;NA;NA;https://doi.org/10.1145/3130859.3131433;Sisu is a gamified learning application designed to assist school-aged children who are struggling to read. Sisu utilizes readily-available technology to promote learning at home, with unique elements tied to the learning experience: (1) a spelling game with (2) an empathic agent, and (3) a mini-game. The empathic agent utilizes a facial action coding system (FACS) to recognize core expressions of the child user and respond to the child's affect in-game. We anticipate that Sisu's accessible and affective nature will not only support children's emotional needs, but the addition of gamified elements will motivate them to practice reading and assist them in their learning objectives.;2017;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;73–85;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UQYZSGWB;bookSection;2017;"Chisik, Yoram; Mancini, Clara";Of Kittens and Kiddies: Reflections on Participatory Design with Small Animals and Small Humans;Proceedings of the 2017 Conference on Interaction Design and Children;978-1-4503-4921-5;NA;NA;https://doi.org/10.1145/3078072.3081311;Participatory Design with children strives to broaden the perspective of and increase empathy in design for the needs and desires of children by giving children a voice in the design process. The exact nature of the role played by children in the design process (e.g. user, informant, co-designer) and how much voice they are actually given has been the subject of a long and heated debate in the IDC community. The emerging field of Animal Computer Interaction, which seeks to empower animals through the participatory design of user-centered technology, offers an interesting opportunity for a comparative analysis. Indeed, working with animals poses many of the challenges also posed by working with children, due to similarities with regards to cognitive capabilities or attention span at particular developmental stages, and with regards to the designer's ability to communicate with them. This workshop aims to bring together researchers from the fields of animal and child computer interaction to explore similarities and difference in the challenges they face, the methods they use and the lessons they have learnt, to date, with the objective of gaining a better understanding of these important aspects and setting an agenda for further collaboration and study between the two communities.;2017;2021-02-15T21:34:50Z;2021-02-15T21:34:50Z;NA;753–756;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UY8CGHHZ;conferencePaper;2018;Spaulding, Samuel;Personalized Robot Tutors That Learn from Multimodal Data;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.;2018;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;1781–1783;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"human-robot interaction; social robotics; multimodal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4EZ4JE7P;conferencePaper;2019;"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania";Ballbit Adventure: A Physical Game for a Collaborative Racing;Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-6871-1;NA;10.1145/3341215.3356982;https://doi.org/10.1145/3341215.3356982;Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.;2019;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;97–103;NA;NA;NA;NA;NA;NA;CHI PLAY '19 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RVVZ9JQU;book;2020;NA;HAI '20: Proceedings of the 8th International Conference on Human-Agent Interaction;NA;978-1-4503-8054-6;NA;NA;NA;"It is our great pleasure to welcome you to the Eighth International Conference on Human-Agent Interaction HAI 2020 (Virtual Conference); hosted by the Western Sydney University (Australia) and supported by Chalmers University of Technology (Sweden).The conference is a venue with an interdisciplinary nature to discuss and disseminate state-ofthe- art research on topics related to human interactions with a range of agent systems, including physical robots and humanoids, virtual agents, socially interactive agents, and Artificially Intelligent (AI) agents. The topical areas of the conference include user studies, frameworks, simulations, technical developments and more within Human Agent and Robotic Interaction. The conference brings together a large variety of multidisciplinary research groups, companies, and researchers looking into the broader area of agents and robotics across Australia, Japan and the rest of the world.The theme for HAI 2020 is ""Artificial Intelligence + Experience Design."" The recent advent of AI has motivated researchers to focus on several algorithmic prospects in developing intelligent robotic agents and their interactions. Progressively, AI advances are leading to exciting outcomes in the HAI field and, at the same time, are opening up for a wide perspective on how to design intelligent robotic agents. For example, how to combine artificial intelligence and user experience design approaches in human-agent interaction. We are looking forward to sharing the latest research results of HAI that contribute a broad range of disciplines.Three keynote talks are featured. The first is titled ""We're in This Together: Social Robots in Group, Organizational, and Community Interactions"", by Associate Prof. Selma Šabanović, Indiana University Bloomington, USA. The second is titled ""What kind of human-centric robotics do we need? Investigations from human-robot interactions in socially assistive scenarios"", by Prof. Ginevra Castellano, Uppsala University, Sweden. The third is an industry talk titled ""The rapid rise in drone technology"", by Sebastian Robertson, CEO of BIRDI, Australia. Their keynote talks will provide cross-disciplinary examples of novel HAI research and applications that are highly inspiring for the HAI audience and research community.This year's submissions have come from more than 25 countries and cover leading-edge topics including human and machine learning, conversational agents, empathy and trust of social robots, social drones, social presence, robot applications, virtual agent applications and novel perspectives of HAI. With an acceptance rate of 38% (25 papers out of 65 submissions), the program committee has again set a high quality standard. In addition, 26 out of the 35 latebreaking poster papers submissions were accepted.";2020;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JPF8JCEB;conferencePaper;2014;Billinghurst, Mark;Using Augmented Reality to Create Empathic Experiences;Proceedings of the 19th International Conference on Intelligent User Interfaces;978-1-4503-2184-6;NA;10.1145/2557500.2568057;https://doi.org/10.1145/2557500.2568057;Intelligent user interfaces have traditionally been used to create systems that respond intelligently to user input. However there is a recent trend towards Empathic Interfaces that are designed to go beyond understanding user input and to recognize emotional state and user feelings. In this presentation we explore how Augmented Reality (AR) can be used to convey that emotional state and so allow users to capture and share emotional experiences. In this way AR not only overlays virtual imagery on the real world, but also can create deeper understanding of user's experience at particular locations and points in time. The recent emergence of truly wearable systems, such as Google Glass, provide a platform for Empathic Communication using AR. Examples will be shown from research conducted at the HIT Lab NZ and other research organizations, and key areas for future research described.;2014;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;5–6;NA;NA;NA;NA;NA;NA;IUI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Haifa, Israel;NA;NA;NA;"augmented reality; collaboration; empathic computing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PND2KN2D;conferencePaper;2016;"Lim, Mei Yii; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Hall, Lynne";A Treasure Hunt With An Empathic Virtual Tutor: (Demonstration);"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;"We present a demonstration of a Treasure Hunt Application with an Empathic Virtual Tutor. During the treasure hunt, this empathic agent adapts its interaction based on the affective state of the user to improve learning experience. We demonstrate the application domain; the technology used; and the app focusing on the empathic strategies applied.";2016;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;1477–1478;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"human-agent interaction; valence; arousal; empathic agent; treasure hunt";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
E7IPRR6J;journalArticle;2020;"Cotler, Jami L.; Villa, Luis; Burshteyn, Dmitry; Bult, Zachary; Grant, Garrison; Tanski, Michael; Parente, Anthony";An Interdisciplinary Approach to Detecting Empathy through Emotional Analytics and Eye Tracking;J. Comput. Sci. Coll.;NA;1937-4771;NA;NA;"The aim of this interdisciplinary study was to bring together different perspectives to discover if detecting empathetic emotional reactions is possible. This area of research has received recent attention from the computer science, human-computer interaction and psychological research communities. The research team consisted of three students; a computer science, sociology and marketing major. The team worked to understand the complexities of detecting emotions based on facial movement. The team collected time stamped facial emotional data from 210 participants as they watched a video clip from the popular movie depicting bullying behavior towards a disabled person. The results demonstrated significant before-and- after mean differences in emotions that are characterized as empathic towards the main character for the bullying events, which is a promising start to detecting empathic reactions. Each student brought a different perspective from their majors resulting in an educational experience that transcended learning about emotional analytics.";2020-04;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;87–95;NA;8;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R78C9MHI;conferencePaper;2016;"Alyuz, Nese; Okur, Eda; Oktay, Ece; Genc, Utku; Aslan, Sinem; Mete, Sinem Emine; Arnrich, Bert; Esme, Asli Arslan";Semi-Supervised Model Personalization for Improved Detection of Learner's Emotional Engagement;Proceedings of the 18th ACM International Conference on Multimodal Interaction;978-1-4503-4556-9;NA;10.1145/2993148.2993166;https://doi.org/10.1145/2993148.2993166;Affective states play a crucial role in learning. Existing Intelligent Tutoring Systems (ITSs) fail to track affective states of learners accurately. Without an accurate detection of such states, ITSs are limited in providing truly personalized learning experience. In our longitudinal research, we have been working towards developing an empathic autonomous 'tutor' closely monitoring students in real-time using multiple sources of data to understand their affective states corresponding to emotional engagement. We focus on detecting learning related states (i.e., 'Satisfied', 'Bored', and 'Confused'). We have collected 210 hours of data through authentic classroom pilots of 17 sessions. We collected information from two modalities: (1) appearance, which is collected from the camera, and (2) context-performance, that is derived from the content platform. The learning content of the content platform consists of two section types: (1) instructional where students watch instructional videos and (2) assessment where students solve exercise questions. Since there are individual differences in expressing affective states, the detection of emotional engagement needs to be customized for each individual. In this paper, we propose a hierarchical semi-supervised model adaptation method to achieve highly accurate emotional engagement detectors. In the initial calibration phase, a personalized context-performance classifier is obtained. In the online usage phase, the appearance classifier is automatically personalized using the labels generated by the context-performance model. The experimental results show that personalization enables performance improvement of our generic emotional engagement detectors. The proposed semi-supervised hierarchical personalization method result in 89.23% and 75.20% F1 measures for the instructional and assessment sections respectively.;2016;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;100–107;NA;NA;NA;NA;NA;NA;ICMI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"affective computing; personalization; adaptive learning; intelligent tutoring systems; Emotional engagement detection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
UXU4ZPGP;conferencePaper;2015;"Ribeiro, Tiago; Alves-Oliveira, Patrícia; Di Tullio, Eugenio; Petisca, Sofia; Sequeira, Pedro; Deshmukh, Amol; Janarthanam, Srinivasan; Foster, Mary Ellen; Jones, Aidan; Corrigan, Lee J.; Papadopoulos, Fotios; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Paiva, Ana";The Empathic Robotic Tutor: Featuring the NAO Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702100;https://doi.org/10.1145/2701973.2702100;We present an autonomous empathic robotic tutor to be used in classrooms as a peer in a virtual learning environment. The system merges a virtual agent design with HRI features, consisting of a robotic embodiment, a multimedia interactive learning application and perception sensors that are controlled by an artificial intelligence agent.;2015;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;285;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"educational robotics; empathic robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
899G3SHM;conferencePaper;2019;Tchetgen, Pierre-Valery Njenji;DRUMBALL: Multimodal Meaning Production through Digital Drum Talk;Proceedings of the 2019 on Creativity and Cognition;978-1-4503-5917-7;NA;10.1145/3325480.3326544;https://doi.org/10.1145/3325480.3326544;In this demonstration, I present an interactive prototype of the Drumball system, an embodied learning environment that allows for drum patterns to be turned into and used as letters, words or phrases. The system acts as a transducer of rhythmic input into multimodal output, and was designed to investigate the affordances of this embodied learning approach on the early literacy skills acquisition of children. The project follows a design thinking process (empathize, define, ideate, prototype, test) to explore cultural systems as a grounding for learning technologies design. The session provides a space to think beyond the traditional keypad interface and its reliance on alphabetic input, to explore how the application of the talking drum cultural system in the domain of human-computer interaction can be used to transform children's early experiences with literacy. I will demonstrate creating sequences of letters and words using the system by playing drum tones of varying pitches (tone, slap and bass).;2019;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;513–517;NA;NA;NA;NA;NA;NA;"C&amp;C '19";NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Diego, CA, USA;NA;NA;NA;"embodied learning; culturally-grounded pedagogies and technologies; drum language; haptic devices; interaction paradigm; literacy development";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RRGASSTP;conferencePaper;2020;"Sohrab, Fahad; Raitoharju, Jenni; Gabbouj, Moncef";Facial Expression Based Satisfaction Index for Empathic Buildings;Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers;978-1-4503-8076-8;NA;10.1145/3410530.3414443;https://doi.org/10.1145/3410530.3414443;In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.;2020;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;704–707;NA;NA;NA;NA;NA;NA;UbiComp-ISWC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Mexico;NA;NA;NA;"machine learning; empathic building; facial expressions; satisfaction index";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NH84IDQX;conferencePaper;2016;Alyuz, Nese;Shaping the Future of Education with Empathic Companions;Proceedings of the 2nd Workshop on Emotion Representations and Modelling for Companion Systems;978-1-4503-4558-3;NA;10.1145/3009960.3009964;https://doi.org/10.1145/3009960.3009964;With the advances in computing technologies, we have been undergoing a shift towards a digital world. As an inevitable result of this shift, the technology penetrates into education in myriad forms. Intelligent tutoring systems (ITS) are essential outcomes of this penetration, emerging to satisfy the needs of learners and instructors. Their working principle is based on collecting and processing data of all students through various modalities to understand the strengths and needs of learners. Yet, more important is that ITSs untangle the overlooked problem of traditional education: One size does not fit all, and there is a need for personalized tutoring for each individual. It is well known that that learning is emotional as well as intellectual. To truly meet the needs of education, we need empathic companions, ones that are affectively aware and thus can accompany the learner for an enhanced learning experience.;2016;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;NA;NA;NA;NA;NA;NA;NA;ERM4CT '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"machine learning; affective computing; empathic computing; adaptive learning; intelligent tutoring systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9LDX4MLE;conferencePaper;2019;"Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher";Mutual Reinforcement Learning with Robot Trainers;Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction;978-1-5386-8555-6;NA;NA;NA;The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.;2019;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;572–573;NA;NA;NA;NA;NA;NA;HRI '19;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Daegu, Republic of Korea;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IU5GTDXB;conferencePaper;2010;Regazzoni, Carlo S.;Emphatic Human Interaction Analysis for Cognitive Environments;Proceedings of the First ACM International Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams;978-1-4503-0163-3;NA;10.1145/1877868.1877870;https://doi.org/10.1145/1877868.1877870;"Understanding the dynamic evolution of complex scenes where multiple patterns interact according to a hidden semantic goal is an issue of current intelligent environments. This issue is made somehow more complex due to the more spread and intensive use of camera systems to help human operators in the monitoring task. Analyzing multimedia data provided by wide set of cameras simultaneously monitoring different environments makes it necessary not only to focus the attention of human operators on relevant occurring events, but also to actively support their decision about optimal reactions to be taken to manage abnormal situations. Cognitive tasks to be modeled in integrated intelligent systems become not only multisensor data processing and scene understanding, but also proactive decision making: a recognized abnormal interactive situation occurring in the scene must be possibly controlled in such a way that divergence from normal event flow can not compromise security level of an environment.Cognitive environments often aim at friendly improving the usefulness of a given physical space by humans according to a given paradigm and objective of use. To this end, they often employ pervasive communications tools to send messages to cooperative humans in a given environment to help me in real time situations they are living, in order to help them to accomplish their tasks in a more smooth and effective way. To do so, they can use situation assessment tools interpreting available sensor data in terms of dynamic state and events generated by objects present in their scene and their interactions. In many cases, assessed situation can be not only estimated but also predicted, if dynamic models of it are available.Capability of predicting behavior of objects along a given interaction situation can be interpreted as a way to directly evaluate not only evolution of actions of a given object in a contextual framework determined by the interacting object, but also as a way to estimate and to predict (based on a indirect observation and an appropriate model) the subjective emotional and motivational hidden variables that carried the object to decide a certain action to be performed on the basis of subjectively sensed data. Therefore, if appropriate models are available a sort of empathic interaction analysis can be performed that should allow a cognitive environment to be ""immersively"" connected with interacting entities, being able to predict actions they will take in given contextual situation.Cognitive environments can take advantage of such an empathic interaction analysis in case they can be in communication with some of the humans involved in a given interaction, for example by using wireless terminals or varying message panels in a physical environment. In this case it comes out that it becomes interesting to study which architecture and processing methods can be used to design cognitive environments intelligence as a set of concurring continuous loops closing the gap between sensing and acting on real time evolving world.Based on the explanation of such premises, In this talk, attention will be paid to human interaction video analysis methods that are based on data representations suitable for allowing ""immersive"" estimation and prediction by an observing intelligent environment. Examples will be discussed of Bayesian approaches to representation and learning of interactions from video scene examples currently studied in our research group (www.isip40.it).Such approaches span from video tracking and behavior understanding issues, aiming at provide a robust basic vocabulary of video processing tools to detect and analyze human motion at finer resolution scales (i.e. multiple feature dynamic shape analysis), to development of methods to represent empathic models of interactions at coarser trajectory based scales. Coupled Dynamic Bayesian Networks are used in both cases as a problem representation guideline. In the latter case of coarser scale of analysis at the trajectory level, interaction structure is also learned by using bio-inspired principles. In both cases incremental adaptation is obtained as a result of the followed Bayesian approach. Architectural schemes and examples will be provided in the talk of the use of such techniques within cognitive systems where cooperative humans can be helped in performing a given interaction tasks by predictions obtained by empathic interaction models.";2010;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;1–2;NA;NA;NA;NA;NA;NA;ARTEMIS '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Firenze, Italy;NA;NA;NA;"ambient intelligence; cognitive surveillance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4XCMGBNM;conferencePaper;2011;"Lee, Jung-Joo; Vaajakallio, Kirsikka; Mattelmäki, Tuuli";Tracing Situated Effects of Innovative Design Methods: Inexperienced Designers' Practices;Procedings of the Second Conference on Creativity and Innovation in Design;978-1-4503-0754-3;NA;10.1145/2079216.2079231;https://doi.org/10.1145/2079216.2079231;"In recent years the design research community has been active in developing new methods for user involvement and collaboration in the design process. The new methods, often called innovative design methods, correspond more to designer's genuine ways of thinking and working than do traditional user-centered ones. The entire purpose of innovative method is to allow for designer's creativity in the design of method and reflective learning, instead of relying on predefined rules of method. For this reason, codification and scientific evaluation are often regarded very challenging, if meaningful at all. This leads us to raise a question; what could be relevant ways of framing and communicating innovative design methods to better capture their nature and value?As one attempt to explore this question, our study takes a close look at inexperienced designers' practices with innovative methods, such as probes or co-design workshops. We chose students as research subjects because their situated actions – and the challenges they face in understanding and applying these methods – reveal just kind of knowledge about the innovative methods that needs to be communicated. To do this, we analyzed students' learning diaries written during the design course. When the students reported uncertainties and disappointments due to 'ill-defined' nature of such methods, we were able to trace the reasons for disappointments. We also found that the innovative design methods in fact supported the students for empathic learning and design inspiration from the making process of the methods.";2011;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;103–113;NA;NA;NA;NA;NA;NA;DESIRE '11;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Eindhoven, Netherlands;NA;NA;NA;"empathic design; co-design; design education; innovative design methods";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2VVP6PUC;conferencePaper;2013;"Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria";3D Animated Agent for Tutoring Based on WebGL;Proceedings of the 18th International Conference on 3D Web Technology;978-1-4503-2133-4;NA;10.1145/2466533.2466534;https://doi.org/10.1145/2466533.2466534;"The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.";2013;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;129–134;NA;NA;NA;NA;NA;NA;Web3D '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Sebastian, Spain;NA;NA;NA;"artificial intelligence; e-learning; virtual agents; Web3D technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
IPWR87LU;conferencePaper;2017;"Ranjbartabar, Hedieh; Richards, Deborah";Student Designed Virtual Teacher Feedback;Proceedings of the 9th International Conference on Computer and Automation Engineering;978-1-4503-4809-6;NA;10.1145/3057039.3057083;https://doi.org/10.1145/3057039.3057083;Interactive virtual learning environments (VLEs) have significant potential to influence students' learning achievements. Characters in these VLEs can act as a virtual peers and teachers by providing empathic responses tailored to the affective state of the students. Designing appropriate dialogues and feedback will be important in achieving the desired outcomes such as increased engagement, motivation and achievement. In this paper we report our findings from a study with 19 girls in Year 8 and 9 at high school using the Omosa VLE. The study investigated student responses to the initial dialogues we designed to elicit their emotional state and provide support. Analysis of responses and alternative dialogues offered by the students revealed that the feedback provided by our characters was mostly acceptable, but further improvements should be made to include elements such as self-disclosure and more helpful dialogue.;2017;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;26–30;NA;NA;NA;NA;NA;NA;ICCAE '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Sydney, Australia;NA;NA;NA;"Omosa; empathic virtual agent; Virtual learning environment; virtual world";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2NJUF5TN;conferencePaper;2020;"Latulipe, Celine; Provencal, Sarah; Frevert, Tonya";Challenging Social Exclusion in Computing via 'Theatre of the Oppressed' Pedagogy;Proceedings of the 51st ACM Technical Symposium on Computer Science Education;978-1-4503-6793-6;NA;10.1145/3328778.3367008;https://doi.org/10.1145/3328778.3367008;Micro-aggressions, hostile climates, and intersectional discrimination contribute to students feeling excluded from fully participating in Computer Science or other STEM programs. To address this exclusion, students need to empathize with each other, and for that we need them to be having frank, open conversations about difficult situations. This is hard to achieve, as people do not typically want to talk about difficult situations with strangers. Computer Science faculty may shy away from these difficult conversations, as they may feel they lack the expertise to address social issues effectively. To address this issue, we have been conducting 'Exclusion Response Workshops' based on the 'Theatre of the Oppressed' methodology of rehearsing social change. This involves students anonymously contributing scenarios of micro-aggressions they have experienced or witnessed and then roleplaying alternate outcomes. These workshops create an empathetic environment for frank and open discussion of difficult issues. We have been scaling this effort by conducting workshops with all freshmen and transfer students in our College of Computing and Informatics. In this SIGCSE workshop, attendees will participate in an Exclusion Response Workshop, then have an open discussion about the workshop experience, workshop logistics, and pros and cons of running this workshop as a mandatory class activity versus a voluntary activity. Participants will learn about the workshop structure, and the Theatre of the Oppressed methodology. This workshop is a taste of a 3-day, train-the-trainer workshop that we will be conducting at our institution in May 2020. Supported by NSF IUSE/RED Award #151960.;2020;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;1395;NA;NA;NA;NA;NA;NA;SIGCSE '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, OR, USA;NA;NA;NA;"diversity; inclusion; participatory-theatre; theatre-of-the-oppressed";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ITTJNNDL;conferencePaper;2014;"Hamidi, Foad; Baljko, Melanie";Rafigh: An Edible Living Media Installation;Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction;978-1-4503-2635-3;NA;10.1145/2540930.2555209;https://doi.org/10.1145/2540930.2555209;In the face of increasing urbanization and lack of contact with nature, it is important to design systems that facilitate a re-connection or at least dialogue around our interaction with living beings. Rafigh, an empathetic living media interface, is designed to motivate children and adults to care for a living mushroom colony by engaging in collaborative and learning activies.;2014;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;345–346;NA;NA;NA;NA;NA;NA;TEI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Munich, Germany;NA;NA;NA;"embedded computing; living media interfaces";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
QBFC8RFC;conferencePaper;2016;"Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Alves Oliveira, Patrícia; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid";Map Reading with an Empathic Robot Tutor;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.;2016;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;567;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Christchurch, New Zealand;NA;NA;NA;"empathy; robot-child interaction; robotic tutor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
57JQMV22;conferencePaper;2015;"Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra; Ellen Foster, Mary; Corrigan, Lee J.; Papadopoulos, Fotios; Di Tullio, Eugenio; Sequeira, Pedro";An Empathic Robotic Tutor in a Map Application;Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems;978-1-4503-3413-6;NA;NA;NA;In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.;2015;2021-02-15T21:34:51Z;2021-02-15T21:34:51Z;NA;1923–1924;NA;NA;NA;NA;NA;NA;AAMAS '15;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Istanbul, Turkey;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RAREYWJ9;conferencePaper;2012;Taylor, Jason;The Trade Aid Computer Kiosk: Inclusive and Human Centred Design Technology at the Point of Sale;Proceedings of the 13th International Conference of the NZ Chapter of the ACM's Special Interest Group on Human-Computer Interaction;978-1-4503-1474-9;NA;10.1145/2379256.2379275;https://doi.org/10.1145/2379256.2379275;We present a computer kiosk for learning in the retail space connecting producers and consumers through Fair Trade. The project has explored reactions to simple, inclusive technology focusing on the human narrative within not for profit trade and empathic human centered design toward all stakeholders.;2012;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;91;NA;NA;NA;NA;NA;NA;CHINZ '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Dunedin, New Zealand;NA;NA;NA;"empathic design; computer kiosk; fair trade; human centred; rapid prototype; retail";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RQTP5Q42;journalArticle;2015;Leite, Iolanda;Long-Term Interactions with Empathic Social Robots;AI Matters;NA;NA;10.1145/2735392.2735397;https://doi.org/10.1145/2735392.2735397;We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.;2015-03;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;13–15;NA;3;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
2C4C2Y2Y;conferencePaper;2020;Soleymani, Mohammad;Machine Understanding of Emotion and Sentiment;Companion Publication of the 2020 International Conference on Multimodal Interaction;978-1-4503-8002-7;NA;10.1145/3395035.3425321;https://doi.org/10.1145/3395035.3425321;Emotions are subjective experiences involving perceptual and con-textual factors [4]. There is no objective tool for precise measurement of emotions. However, we can anticipate an emotion's emergence through the knowledge of common responses to events in similar situations. We can also measure proxies of emotions by recognizing emotional expressions [3]. Studying emotional response to multimedia allows identifying expected emotions in users consuming the content. For example,abrupt loud voices are novel and unsettling which result in surprise and higher experience of arousal [2,6]. For a particular type of con-tent such as music, mid-level attributes such as rhythmic stability or melodiousness have strong association with expected emotions[1]. Given that such mid-level attributes are more related to the con-tent, their machine-perception is more straightforward. Moreover,their perception in combination with user models enables building person-specific emotion anticipation models.In addition to studying expected emotions, we can also observe users emotional reactions to understand emotion in multimedia.Typical methods of emotion recognition include recognizing emotions from facial or vocal expressions. Recognition of emotional expressions requires large amount of labeled data, expensive to produce. Hence, the most recent advances in machine-based emotion perception include methods that can leverage unlabeled data through self-supervised and semi-supervised learning [3, 5]. In this talk, I review the field and showcase methods for automatic modeling and recognition of emotions and sentiment indifferent contexts [3,8]. I show how we can identify underlying factors contributing to the construction of subjective experience of emotions [1,7]. Identification of these factors allows us to use them as mid-level attributes to build machine learning models for emotion and sentiment understanding. I also show how emotions and sentiment can be recognized from expressions with the goal of building empathetic autonomous agents [8].;2020;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;206–207;NA;NA;NA;NA;NA;NA;ICMI '20 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Netherlands;NA;NA;NA;"machine learning; emotion; affective computing; sentiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XY8SSMIW;conferencePaper;2014;"Nazir, Asad; Aylett, Ruth S.; Lim, Mei Yii; Endrass, Birgit; Hall, Lynne; Ritter, Christopher";MIXER: Why the Difference?;Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems;978-1-4503-2738-1;NA;NA;NA;This interactive demo features MIXER, a Virtual Learning Environment (VLE) consisting of synthetic characters representing the various actors in a scenario group difference scenario. MIXER creates virtual dramas by using interactive narrative with those characters. The goal is to enable children to identify social rule differences, by interacting with one of the characters to which they become empathic. MIXER is evaluated in the UK and Germany with children aged 9 to 11 years. The video for the demo content can be found at: http://youtu.be/jKIndn5NPaQ;2014;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1687–1688;NA;NA;NA;NA;NA;NA;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"artificial intelligence; applications; virtual learning environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
DHLVYCSD;conferencePaper;2016;"Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra";How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment;The Eleventh ACM/IEEE International Conference on Human Robot Interaction;978-1-4673-8370-7;NA;NA;NA;We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.;2016;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;423–424;NA;NA;NA;NA;NA;NA;HRI '16;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Christchurch, New Zealand;NA;NA;NA;"empathy; robotic tutors; child-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6699IAAP;conferencePaper;2018;Roberts, Jasmine;Using Affective Computing for Proxemic Interactions in Mixed-Reality;Proceedings of the Symposium on Spatial User Interaction;978-1-4503-5708-1;NA;10.1145/3267782.3274692;https://doi.org/10.1145/3267782.3274692;Immersive technologies have been touted as empathetic mediums. This capability has yet to be fully explored through machine learning integration. Our demo seeks to explore proxemics in mixed-reality (MR) human-human interactions.The author developed a system, where spatial features can be manipulated in real time by identifying emotions corresponding to unique combinations of facial micro-expressions and tonal analysis. The Magic Leap One is used as the interactive interface, the first commercial spatial computing head mounted (virtual retinal) display (HUD).A novel spatial user interface visualization element is prototyped that leverages the affordances of mixed-reality by introducing both a spatial and affective component to interfaces.;2018;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;176;NA;NA;NA;NA;NA;NA;SUI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Berlin, Germany;NA;NA;NA;"affective computing; augmented reality; mixed reality; Proxemics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
VZJM9Y88;conferencePaper;2019;"Noortman, Renee; Schulte, Britta F.; Marshall, Paul; Bakker, Saskia; Cox, Anna L.";HawkEye - Deploying a Design Fiction Probe;Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5970-2;NA;10.1145/3290605.3300652;https://doi.org/10.1145/3290605.3300652;This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.;2019;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1–14;NA;NA;NA;NA;NA;NA;CHI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"design fiction; dementia care; future scenarios; informal caregiving; monitoring technologies; technology probes";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AR5SNDRX;conferencePaper;2020;"Bourdin, Pierre; Calvet, Laura; Tesconi, Susanna; Arnedo-Moreno, Joan";Reflecting on Attitudes Towards Death Through the Use of Immersive Virtual Reality Commercial Video Games;Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality;978-1-4503-8850-4;NA;10.1145/3434780.3436559;https://doi.org/10.1145/3434780.3436559;Video games can be an invaluable learning tool beyond pure skill acquisition, such as teaching us how to empathize with others or even self-reflecting on basic existential concerns: isolation, freedom, meaninglessness or death. This is further emphasized with the use of immersive technologies and becomes especially relevant when the experience itself is very difficult to replicate, when not impossible, in the real world. On that regard, this paper analyzes the impact of virtual reality (VR) commercial video games on the existential concern of one's own death. Participants (N 30) played one of three games for 15 minutes and the aftermath was examined using questionnaires and the implicit relational assessment procedure (IRAP). Our results show that there is no difference in the game experience, despite the different gameplay. However, IRAP results seem to indicate that players of the action game have a different attitude towards death.;2020;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;640–647;NA;NA;NA;NA;NA;NA;TEEM'20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salamanca, Spain;NA;NA;NA;"Virtual reality; serious games; death-evaluation; death-identity; existential games; immersive player experiences; Implicit Relational Assessment Procedure; video games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
8SMN2NFR;bookSection;2018;"Giglitto, Danilo; Lazem, Shaimaa; Preston, Anne";In the Eye of the Student: An Intangible Cultural Heritage Experience, with a Human-Computer Interaction Twist;Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;978-1-4503-5620-6;NA;NA;https://doi.org/10.1145/3173574.3173864;We critically engage with CHI communities emerging outside the global North (ArabHCI and AfriCHI) to explore how participation is configured and enacted within socio-cultural and political contexts fundamentally different from Western societies. We contribute to recent discussions about postcolonialism and decolonization of HCI by focusing on non-Western future technology designers. Our lens was a course designed to engage Egyptian students with a local yet culturally-distant community to design applications for documenting intangible heritage. Through an action research, the instructors reflect on selected students' activities. Despite deploying a flexible learning curriculum that encourages greater autonomy, the students perceived themselves with less agency than other institutional stakeholders involved in the project. Further, some of them struggled to empathize with the community as the impact of the cultural differences on configuring participation was profound. We discuss the implications of the findings on HCI education and in international cross-cultural design projects.;2018;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1–12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
U8CSL74E;bookSection;2020;"Qiu, Lisong; Shiu, Yingwai; Lin, Pingping; Song, Ruihua; Liu, Yue; Zhao, Dongyan; Yan, Rui";What If Bots Feel Moods?;Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval;978-1-4503-8016-4;NA;NA;https://doi.org/10.1145/3397271.3401108;"For social bots, smooth emotional transitions are essential for delivering a genuine conversation experience to users. Yet, the task is challenging because emotion is too implicit and complicated to understand. Among previous studies in the domain of retrieval-based conversational model, they only consider the factors of semantic and functional dependencies of utterances. In this paper, to implement a more empathetic retrieval-based conversation system, we incorporate emotional factors into context-response matching from two aspects: 1) On top of semantic matching, we propose an emotion-aware transition network to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework; 2) We design several flexible controlling mechanisms to customize social bots in terms of emotion. Extensive experiments on two benchmark datasets indicate that the proposed model can effectively track the flow of emotions throughout a human-machine conversation and significantly improve response selection in dialogues over the state-of-the-art baselines. We also empirically validate the emotion-control effects of our proposed model on three different emotional aspects. Finally, we apply such functionalities to a real IoT application.";2020;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1161–1170;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
7WEGCQNR;conferencePaper;2020;"Chapko, Dorota; Frumiento, Pino; Edwards, Nalini; Emeh, Lizzie; Kennedy, Donald; McNicholas, David; Overton, Michaela; Snead, Mark; Steward, Robyn; Sutton, Jenny M.; Jeffreys, Evie; Long, Catherine; Croll-Knight, Jess; Connors, Ben; Castell-Ward, Sam; Coke, David; McPeake, Bethany; Renel, William; McGinley, Chris; Remington, Anna; Whittuck, Dora; Kieffer, John; Ewans, Sarah; Williams, Mark; Grierson, Mick";"""We Have Been Magnified for Years - Now You Are under the Microscope!"": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities";Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;978-1-4503-6708-0;NA;10.1145/3313831.3376278;https://doi.org/10.1145/3313831.3376278;Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.;2020;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1–17;NA;NA;NA;NA;NA;NA;CHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Honolulu, HI, USA;NA;NA;NA;"attitudes; design; disability; survey; participatory/inclusive research; video";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
E7KP5ECK;conferencePaper;2020;"Carrasco, Romina; A. Baker, Felicity; A. Bukowska, Anna; N. Clark, Imogen; M. Flynn, Libby; McMahon, Kate; Odell-Miller, Helen; Stensaeth, Karette; Tamplin, Jeanette; Vieira Sousa, Tanara; Waycott, Jenny; Wosch, Thomas";Empowering Caregivers of People Living with Dementia to Use Music Therapeutically at Home: Design Opportunities;32nd Australian Conference on Human-Computer Interaction;978-1-4503-8975-4;NA;10.1145/3441000.3441082;https://doi.org/10.1145/3441000.3441082;Human-computer interaction researchers have explored how to design technologies to support people with dementia (PwD) and their caregivers, but limited attention has been given to how to facilitate music therapy in dementia care. The use of music to help manage the symptoms of dementia is often guided by a music therapist who adapts the intervention to respond to the changing needs of the person living with dementia. However, as the incidence of dementia increases worldwide, individualised therapy programs are less feasible, making it valuable to consider technology-based approaches. In this paper, we analyze data from case studies of home-based music therapy training interventions with two families. The findings show that embodied interactions supported the therapist in responding to the needs of the PwD and built an empathic environment that empowered the caregivers’ learning. We discuss opportunities and challenges for designing technologies that support family caregivers’ therapy-informed music use in dementia care.;2020;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;198–209;NA;NA;NA;NA;NA;NA;OzCHI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Sydney, NSW, Australia;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4BNFP56I;conferencePaper;2012;Khaled, Rilla;Muse-Based Game Design;Proceedings of the Designing Interactive Systems Conference;978-1-4503-1210-3;NA;10.1145/2317956.2318065;https://doi.org/10.1145/2317956.2318065;Game design and user experience (UX) design both centre on the design of experiences. But whereas it is par for the course for end-user perspectives to be included during early design stages in UX, there is little methodological support or research into how to incorporate player perspectives into early stages of game design. In this paper, we introduce muse-based game design, an experimental empathic design approach foregrounding a dialogic artist – muse relationship between a game designer and player. Following a user research stage focused on learning about the player, the designer forms idiosyncratic design constraints inspired by and relating to the player, which are then used to inspire ideation. To understand the consequences, advantages, and disadvantages of this approach, we discuss findings from two years of application of this style of game design in a Master's-level class of game design students at the IT University of Copenhagen.;2012;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;721–730;NA;NA;NA;NA;NA;NA;DIS '12;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Newcastle Upon Tyne, United Kingdom;NA;NA;NA;"empathic design; game design; design processes; player-centred design; player-centric design; reflective design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WH7556LY;conferencePaper;2014;"Iacono, Iolanda; Marti, Patrizia";Engaging Older People with Participatory Design;Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational;978-1-4503-2542-4;NA;10.1145/2639189.2670180;https://doi.org/10.1145/2639189.2670180;We present a design case focusing on participatory design (PD) with older people. We experimented with PD techniques to foster engagement with participants in development of a graphical user interface (GUI) for controlling a robotic system in a smart home environment. The tenet of our approach is that to engage older people in the design of future systems, it is of paramount importance to increment and reinforce knowledge using different techniques and materials, and to create an empathic and trusted relationship between participants and designers. We experimented with different techniques for achieving this, from video-based scenario evaluation to hands-on and gaming activity in which participants had to evaluate the dynamics of a context-dependent interface using an expression-rich modality of interaction. This permitted exploration of experiential elements of design, to reduce the need for the participants to engage in abstract thought and to collect insights on design solutions while having fun together. The entire procedure implied incremental PD cycles in which knowledge was shared and consolidated through a learning process based on doing and playing together. The final reflections highlight a number of recommendations that demand consideration when undertaking research and design work with older people.;2014;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;859–864;NA;NA;NA;NA;NA;NA;NordiCHI '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Helsinki, Finland;NA;NA;NA;"empathy; participatory design; older people; gaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4JW5AKTN;conferencePaper;2019;"W. Bennett, Gregory; Canner, Liz";Lost City of Mer;SIGGRAPH Asia 2019 XR;978-1-4503-6947-3;NA;10.1145/3355355.3361897;https://doi.org/10.1145/3355355.3361897;Lost City of Mer is a virtual reality (VR) game experience combined with a smartphone app that immerses players in a fantasy undersea civilization devastated by ecological disaster caused by global warning. The project aims to harness the immersive and empathetic potential of VR to address climate change and create a sense of urgency in the player with regard to their personal carbon footprint.Players are invited to help rebuild the lost world of Mer and its devastated ecosystem in VR by re-establishing its unique flora and fauna, and fighting ongoing dangers and threats, with the aim of bringing back to life its mysterious Mer-people inhabitants. Guided by a solitary seal spirit named Athina – the last of its kind in a dying ocean – players try to save the Mer population from extinction. They tend to secret gardens of coral threatened by pollution, create habitats for Mer-people, and explore the destroyed civilization, in the process learning how their real-world actions impact the world around them.The project was developed with the input of environmental scientists from Harvard University and Dartmouth College. The experience is based on real science, but told through fantasy, as it draws on the cross-cultural myth of the mermaid to appeal to people across the globe.;2019;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;25–26;NA;NA;NA;NA;NA;NA;SA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Brisbane, QLD, Australia;NA;NA;NA;"climate change; virtual reality; serious games; VR navigation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
9U8HYFLE;conferencePaper;2018;"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia";A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.;2018;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;1658–1666;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
J8YW9QFF;conferencePaper;2017;"Frueh, Christian; Sud, Avneesh; Kwatra, Vivek";Headset Removal for Virtual and Mixed Reality;ACM SIGGRAPH 2017 Talks;978-1-4503-5008-2;NA;10.1145/3084363.3085083;https://doi.org/10.1145/3084363.3085083;Virtual Reality (VR) has advanced significantly in recent years and allows users to explore novel environments (both real and imaginary), play games, and engage with media in a way that is unprecedentedly immersive. However, compared to physical reality, sharing these experiences is difficult because the user's virtual environment is not easily observable from the outside and the user's face is partly occluded by the VR headset. Mixed Reality (MR) is a medium that alleviates some of this disconnect by sharing the virtual context of a VR user in a flat video format that can be consumed by an audience to get a feel for the user's experience.Even though MR allows audiences to connect actions of the VR user with their virtual environment, empathizing with them is difficult because their face is hidden by the headset. We present a solution to address this problem by virtually removing the headset and revealing the face underneath it using a combination of 3D vision, machine learning and graphics techniques. We have integrated our headset removal approach with Mixed Reality, and demonstrate results on several VR games and experiences.;2017;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;NA;NA;NA;NA;NA;NA;NA;SIGGRAPH '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Los Angeles, California;NA;NA;NA;"virtual reality; mixed reality; facial synthesis; headset removal";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HK3HTASI;conferencePaper;2018;"Corral, Luis; Fronza, Ilenia";Design Thinking and Agile Practices for Software Engineering: An Opportunity for Innovation;Proceedings of the 19th Annual SIG Conference on Information Technology Education;978-1-4503-5954-2;NA;10.1145/3241815.3241864;https://doi.org/10.1145/3241815.3241864;"Commonly, the instruction of Software Engineering implements processes that are inherent to the theory and practice of software development. Traditional and Agile methods lay the foundation for building ""functional software products"" that meet the requirements of a system of a larger scope. However, if we consider software as a product that frequently has the mission of satisfying the needs of human users, we can go beyond the typical ""analysis - design - implementation - testing"" process, to reinterpret it with the ""empathize - define - ideate - prototype - testing"" proposed by Design Thinking, a development methodology commonly used in creative and innovative professional settings. In this work, we study the use of Design Thinking as a methodological approach for the instruction of Software Engineering at undergraduate level, in courses that have the particular aim of creating innovative software products from scratch. We describe the similarities and differences between Design Thinking and Software Development Processes, taking as instance Agile Practices. We compare evidence on methods and deliverables produced by students in their learning path using Agile Practices and Design Thinking in two different educational environments. Finally, we discuss coincidences, weaknesses, and opportunities to keep investigating in this topic as a research subject, toward finding practices to promote in students both creativity and technical discipline to develop innovative software solutions";2018;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;26–31;NA;NA;NA;NA;NA;NA;SIGITE '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Fort Lauderdale, Florida, USA;NA;NA;NA;"education; creativity; agile; design thinking; software engineering";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JGYYMFI6;conferencePaper;2019;"Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios";Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability;Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments;978-1-4503-6232-0;NA;10.1145/3316782.3322767;https://doi.org/10.1145/3316782.3322767;"Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.";2019;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;442–447;NA;NA;NA;NA;NA;NA;PETRA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Rhodes, Greece;NA;NA;NA;"age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N3LZXM2G;book;2014;NA;IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces;NA;978-1-4503-2184-6;NA;NA;NA;"It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.";2014;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4U8UTHWD;book;2014;NA;IUI Companion '14: Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces;NA;978-1-4503-2729-9;NA;NA;NA;"It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round.The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles ""From Touch through Air to Brain"" ""Learning and Skills"", ""Intelligent Visual Interaction"", ""Users and Motion"", ""Leveraging Social Competencies"", ""Adaptive User Interfaces"" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on ""Multiadaptive Interfaces to Cyber-Physical Environments"", Professor Noam Tractinsky's second day keynote is on ""Visual Aesthetics of Interactive Technologies"" and the last day keynote, by Professor Mark Billinghurst is on ""Using AR to Create Empathic Experiences"". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: ""Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech"". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.";2014;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
PDWWFJUV;conferencePaper;2016;"Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Moncur, Wendy; McNaney, Roisin; Vines, John; Branham, Stacy";Ethical Encounters in Human-Computer Interaction;Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4082-3;NA;10.1145/2851581.2856498;https://doi.org/10.1145/2851581.2856498;In the HCI community, there is growing recognition that a reflective and empathetic approach is needed to conduct ethical research in sensitive settings with people who might be considered vulnerable or marginalized. At our CHI 2015 workshop on ethical encounters, researchers shared personal stories of the challenges and tensions they have faced when conducting HCI research in complex settings such as hospitals, with young mental health patients, in schools for children with disabilities, and with homeless people. These research contexts can present significant challenges for HCI researchers who would not typically receive the training that other professionals working in these environments would normally receive. From our discussions with attendees at the CHI 2015 workshop, we identified a number of ethical issues that researchers are grappling with. In this follow-up workshop we aim to build on the lessons learned and to generate pragmatic but sensitive solutions to manage complex ethical issues for HCI researchers working in challenging settings.;2016;2021-02-15T21:34:52Z;2021-02-15T21:34:52Z;NA;3387–3394;NA;NA;NA;NA;NA;NA;CHI EA '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Jose, California, USA;NA;NA;NA;"ethics; sensitive settings; vulnerable participants";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
S3QBK3GV;bookSection;2017;"Van Mechelen, Maarten; Høiseth, Marikken; Baykal, Gökçe Elif; Van Doorn, Fenne; Vasalou, Asimina; Schut, Alice";Analyzing Children's Contributions and Experiences in Co-Design Activities: Synthesizing Productive Practices;Proceedings of the 2017 Conference on Interaction Design and Children;978-1-4503-4921-5;NA;NA;https://doi.org/10.1145/3078072.3081314;Today, it has been broadly acknowledged in the CCI community that children are not only active learners and users of technology, but can also actively participate in the design process. However, it remains challenging to analyze children's experiences and creative contributions resulting from co-design activities (e.g. stories, paper prototypes, enacted ideas). Broadly speaking, a distinction can be made between researchers looking for inspiration in the form of useful design ideas, and researchers that take a more interpretative stance by looking beyond the surface level of children's ideas to better understand and empathize with them. This knowledge about children is often used to more accurately define the problem space at the early stages of design. Both perspectives to co-design can be seen as the opposite ends of the same continuum, and many researchers combine aspects of both depending on where they are in the design process (e.g. defining the design problem, prototyping stage). This workshop will explore different ways to analyze children's (0 to 18 years) experiences and contributions in co-design activities, the perceived benefits and challenges of these approaches, and will serve as a venue for synthesizing productive practices that will move the CCI community forward.;2017;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;769–772;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BCWWIFQI;journalArticle;2014;Tracey, Ryan;The Agony or the Empathy? An Interview with Anne Bartlett-Bragg;ELearn;NA;NA;10.1145/2578511.2576869;https://doi.org/10.1145/2578511.2576869;Anne Bartlett-Bragg holds a unique space in eLearning as both a researcher and a practitioner. In this interview, Anne discusses the importance of immersion. By empathizing with the learner, one can truly design the best solution.;2014-02;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;NA;NA;2;2014;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
XS77SBCG;bookSection;2020;"Ranjbartabar, Hedieh; Richards, Deborah; Bilgin, Ayse Aysin; Kutay, Cat; Mascarenhas, Samuel";User-Models to Drive an Adaptive Virtual Advisor: Demonstration;Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems;978-1-4503-7518-4;NA;NA;NA;Agents that adapt to their user need to have knowledge of their user and expertise on how best to adapt to that type of user. In this paper we describe the addition of an agent's expertise and collection of machine-learnt user profiles to the proposed extended FAtiMA (Fearnot AffecTive Mind Architecture) cognitive agent architecture. A study to evaluate the extended architecture is presented which compares the benefit (i.e. reduced stress and increased rapport) of tailoring dialogue (i.e. empathic or neutral) to the specific user.;2020;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;2117–2119;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JQKP7XPV;conferencePaper;2018;"Itenge-Wheeler, Helvi; Winschiers-Theophilus, Heike; Soro, Alessandro; Brereton, Margot";Child Designers Creating Personas to Diversify Design Perspectives and Concepts for Their Own Technology Enhanced Library;Proceedings of the 17th ACM Conference on Interaction Design and Children;978-1-4503-5152-2;NA;10.1145/3202185.3202760;https://doi.org/10.1145/3202185.3202760;We report on a participatory design project that explored the use of child-created Personas to enable child designers to empathize with other children thereby contributing multiple divergent perspectives. The ongoing project aims to promote reading and creative writing skills among young children in Namibia. For decades libraries worldwide have been the key actors in fostering reading. Hence, in order to maintain their relevance, they are being re-conceptualized to cater for new needs and aspirations in the 21st century. In Namibia, dysfunctional public and school library services are lagging behind in this renovation effort, and are not contributing to the promotion of a reading culture. In an ongoing collaboration with a school in Windhoek, to design and implement an interactive tech library, 19 young learners engaged in weekly participatory design workshops to redesign their own school library. The children first created four distinct Personas for which they then modelled spaces and technologies. This paper reflects on the techniques used to enable children to become active design partners and to gain an understanding of designing for other children.;2018;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;381–388;NA;NA;NA;NA;NA;NA;IDC '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Trondheim, Norway;NA;NA;NA;"children; design; participatory design; interactive tech library; Namibia; persona; reading experiences";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
HZTNHDTH;bookSection;2017;"Waycott, Jenny; Munteanu, Cosmin; Davis, Hilary; Thieme, Anja; Branham, Stacy; Moncur, Wendy; McNaney, Roisin; Vines, John";Ethical Encounters in HCI: Implications for Research in Sensitive Settings;Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-4656-6;NA;NA;https://doi.org/10.1145/3027063.3027089;This workshop builds on the success of prior workshops that brought together HCI researchers to share stories about ethical challenges faced when conducting research in sensitive settings. There is growing recognition that reflective and empathetic approaches are needed to conduct ethical research in settings involving people who might be considered vulnerable or marginalized. At our previous workshops, researchers discussed personal experiences and described the complex challenges they have faced in research as diverse as designing information systems for families of children in palliative care to analyzing social media posts about mental health. In this follow-up workshop we aim to extend opportunities for knowledge-sharing, build on the lessons learned, and generate a range of resources to help HCI researchers manage complex ethical issues when working in sensitive settings.;2017;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;518–525;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CTBHRCVN;conferencePaper;2015;"Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia";Designing a Socially Assistive Robot for Pediatric Care;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771923;https://doi.org/10.1145/2771839.2771923;We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.;2015;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;387–390;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boston, Massachusetts;NA;NA;NA;"child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
86DCU99N;conferencePaper;2014;"Aylett, Ruth; Hall, Lynne; Tazzyman, Sarah; Endrass, Birgit; André, Elisabeth; Ritter, Christopher; Nazir, Asad; Paiva, Ana; Höfstede, GertJan; Kappas, Arvid";Werewolves, Cheats, and Cultural Sensitivity;Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems;978-1-4503-2738-1;NA;NA;NA;MIXER (Moderating Interactions for Cross-Cultural Empathic Relationships), which applies a novel approach to the education of children in cultural sensitivity. MIXER incorporates intelligent affective and interactive characters, including a model of a Theory of Mind mechanism, in a simulated virtual world. We discuss the relevant pedagogical approaches, related work, the underlying mind model used for MIXER agents as well as its innovative interaction interface utilising a tablet computer and a pictorial interaction language. We then consider the evaluation of the system, whether this shows it met its pedagogical objectives, and what can be learned from our results.;2014;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;1085–1092;NA;NA;NA;NA;NA;NA;AAMAS '14;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"empathy; cultural sensitivity; emotion and social/cultural behaviour; intelligent virtual agents; models of personality; synthetic characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5RP2Y9HQ;conferencePaper;2013;"Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth";Towards Empathic Artificial Tutors;Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction;978-1-4673-3055-8;NA;NA;NA;In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.;2013;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;113–114;NA;NA;NA;NA;NA;NA;HRI '13;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Tokyo, Japan;NA;NA;NA;"empathy; human-robot interaction; robotic tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
5XVIX84U;conferencePaper;2016;"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia";Affect-Aware Student Models for Robot Tutors;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration.In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models.These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.;2016;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;864–872;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"affective computing; child-robot interaction; socially assistive robots; educational robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
TPTAVIA8;conferencePaper;2010;"Chen, Yu-Chung; Lee, Sangyoon; Hur, HyeJung; Leigh, Jason; Johnson, Andrew; Renambot, Luc";Case Study: Designing an Advanced Visualization System for Geological Core Drilling Expeditions;CHI '10 Extended Abstracts on Human Factors in Computing Systems;978-1-60558-930-5;NA;10.1145/1753846.1754206;https://doi.org/10.1145/1753846.1754206;"We present the design and process of an interactive high-resolution visualization system for diverse and distributed real-world geological core drilling expeditions. The high domain knowledge barrier makes it difficult for a person who is outside this field to imagine the user experience, and the globally distributed core drilling community imposes more design constraints in space and time. In addition to activities proposed in prior literatures, we used the ""immersive empathic design"" approach of having a computer scientist trained as a junior core technician. Through in-situ observation and interview evaluations from on-going expeditions, we present the system and the lesson learned in the process. It makes the best use of precious co-located opportunities. It allows the developer to build up domain knowledge efficiently. It establishes a trust relationship between the developer and scientists. The system designed through this approach formed a sustainable foundation that was adapted in the following design iterations. This process allows the software developer to experience authentic user activities. The designed system is innovative and helps scientists solving real-world problems. This approach can be a useful example to HCI practitioners who work with potential users or communities that share similar properties.";2010;2021-02-15T21:34:53Z;2021-02-15T21:34:53Z;NA;4645–4660;NA;NA;NA;NA;NA;NA;CHI EA '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Atlanta, Georgia, USA;NA;NA;NA;"empathic design; visualization; hci";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JUEXYV2P;conferencePaper;2019;"Roth, Daniel; Bloch, Carola; Schmitt, Josephine; Frischlich, Lena; Latoschik, Marc Erich; Bente, Gary";Perceived Authenticity, Empathy, and Pro-Social Intentions Evoked through Avatar-Mediated Self-Disclosures;Proceedings of Mensch Und Computer 2019;978-1-4503-7198-8;NA;10.1145/3340764.3340797;https://doi.org/10.1145/3340764.3340797;Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one's avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support.;2019;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;21–30;NA;NA;NA;NA;NA;NA;MuC'19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Hamburg, Germany;NA;NA;NA;"Empathy; Avatars; Social Perception; Virtual Characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
AY746YDJ;conferencePaper;2017;Murphy, Dooley;Building a Hybrid Virtual Agent for Testing User Empathy and Arousal in Response to Avatar (Micro-)Expressions;Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology;978-1-4503-5548-3;NA;10.1145/3139131.3141217;https://doi.org/10.1145/3139131.3141217;This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR.;2017;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;NA;NA;NA;NA;NA;NA;NA;VRST '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gothenburg, Sweden;NA;NA;NA;"virtual reality; social presence; avatar capture; social plausibility";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
NT3G869D;conferencePaper;2016;"Ishii, Yutaka; Watanabe, Tomio; Sejima, Yoshihiro";Development of an Embodied Avatar System Using Avatar-Shadow's Color Expressions with an Interaction-Activated Communication Model;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2980487;https://doi.org/10.1145/2974804.2980487;In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color.;2016;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;337–340;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Biopolis, Singapore;NA;NA;NA;"avatar-mediated communication; embodied interaction; avatar's shadow; color expression.; virtual face-to-face communication";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
JKXALRVS;conferencePaper;2010;"Van Looy, Jan; Courtois, Cédric; De Vocht, Melanie";Player Identification in Online Games: Validation of a Scale for Measuring Identification in MMORPGs;Proceedings of the 3rd International Conference on Fun and Games;978-1-60558-907-7;NA;10.1145/1823818.1823832;https://doi.org/10.1145/1823818.1823832;In this paper, we present a Player Identification (PI) scale for measuring identification in MMORPGs. Three main dimensions were derived from the literature (1) Avatar (character) Identification, (2) Group (guild) Identification and (3) Game (community) Identification whereby Avatar Identification is a second-order factor consisting of (1a) Perceived Similarity, (1b) Wishful Identification and (1c) Embodied Presence. Based on the results of a cross-sectional survey of 544 World of Warcraft players the measurement instrument's proposed factorial structure was confirmed. Subsequently, the constructs were successfully tested both for convergent and discriminant validity. Finally, evidence for nomological validity was gathered by testing ten theoretically rooted hypotheses regarding the effects of Player Identification. The results showed that Avatar Identification positively predicts Empathy, Proteus effect and the motivations role-play, customization and escapism. Group Identification predicts socializing and relationship, and Game Identification predicts advancement, mechanics and escapism.;2010;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;126–134;NA;NA;NA;NA;NA;NA;Fun and Games '10;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Leuven, Belgium;NA;NA;NA;"identification; avatar; MMORPG; World of Warcraft; measurement scale";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
N84LURWE;conferencePaper;2017;"Vieira, Suanny; Santos, Alexandre; Costa, Rostand; Maritan, Tiago; Aschoff, Manuella; Veríssimo, Vinícius";A Study on the Use of Multiple Avatars in 3D Sign Language Dictionaries;Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web;978-1-4503-5096-9;NA;10.1145/3126858.3126865;https://doi.org/10.1145/3126858.3126865;Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors.;2017;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;325–332;NA;NA;NA;NA;NA;NA;WebMedia '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gramado, RS, Brazil;NA;NA;NA;"accessibility; avatar; machine translation; retargeting; sign language";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
BZL8ZQZD;conferencePaper;2011;"Cheong, Wei Lun; Jung, Younbo; Theng, Yin-Leng";Avatar: A Virtual Face for the Elderly;Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry;978-1-4503-1060-4;NA;10.1145/2087756.2087850;https://doi.org/10.1145/2087756.2087850;Studies in the field of human-computer interaction have demonstrated a significant impact of avatars and virtual environments on users' interaction experiences and behaviors. However, most of these studies are focused on the young users. With an aging population and more virtual environments built for the elderly, it is important to investigate the types of avatars elderly users prefer and hence provide them with a richer interaction experience through the use of avatars as virtual representations of themselves. In our exploratory study, 24 seniors aged 55 years and above evaluated 20 custom-created avatars. Results showed that the elderly participants were unable to identify with the avatars. However, the results showed a strong trust towards child avatars and an attraction towards animal and object avatars, which indicates a different form of identification or empathy. The paper concludes with discussion of avatar design for the elderly users.;2011;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;491–498;NA;NA;NA;NA;NA;NA;VRCAI '11;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Hong Kong, China;NA;NA;NA;"avatars; elderly";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
CIC6T3I3;conferencePaper;2017;"Tong, Xin; Ulas, Servet; Jin, Weina; Gromala, Diane; Shaw, Chris";The Design and Evaluation of a Body-Sensing Video Game to Foster Empathy towards Chronic Pain Patients;Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare;978-1-4503-6363-1;NA;10.1145/3154862.3154869;https://doi.org/10.1145/3154862.3154869;"Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations.";2017;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;244–250;NA;NA;NA;NA;NA;NA;PervasiveHealth '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"empathy; serious games; body-sensing games; chronic pain; embodied simulation; gaming for a purpose";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
RLMYBW2V;conferencePaper;2015;"Andersen, Josephine Soegaard; Schoenau-Fog, Henrik";Using Role-Taking and Behavioral Mimicking in Games to Increase Awareness on the Bystander Effect;Proceedings of the 19th International Academic Mindtrek Conference;978-1-4503-3948-3;NA;10.1145/2818187.2818290;https://doi.org/10.1145/2818187.2818290;This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.;2015;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;69–72;NA;NA;NA;NA;NA;NA;AcademicMindTrek '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Tampere, Finland;NA;NA;NA;"behavioral mimicking; bystander effect; mimetic activity; proteus effect; role playing; role-taking; serious game; simulations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
WPWE3GD5;conferencePaper;2019;"Degraen, Donald; Kosmalla, Felix; Krüger, Antonio";Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications;Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems;978-1-4503-5971-9;NA;10.1145/3290607.3312833;https://doi.org/10.1145/3290607.3312833;Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.;2019;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;1–6;NA;NA;NA;NA;NA;NA;CHI EA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Glasgow, Scotland Uk;NA;NA;NA;"ambient notifications; empathic living media; focus group; ambient interfaces";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ZU7TZZ27;conferencePaper;2015;Encinas, Enrique;Cyrafour: How Two Human Avatars Communicate With Each Other;Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-3146-3;NA;10.1145/2702613.2726962;https://doi.org/10.1145/2702613.2726962;Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.;2015;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;109–114;NA;NA;NA;NA;NA;NA;CHI EA '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, Republic of Korea;NA;NA;NA;"embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KRC9FWGY;conferencePaper;2017;"Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin";Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games;Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology;978-1-4503-5548-3;NA;10.1145/3139131.3139132;https://doi.org/10.1145/3139131.3139132;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.;2017;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;NA;NA;NA;NA;NA;NA;NA;VRST '17;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Gothenburg, Sweden;NA;NA;NA;"pet game; user types; virtual pet; virtual reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
K88BLLSK;conferencePaper;2013;"Plant, Nicola; Healey, Patrick G.T.";Surface Tension;CHI '13 Extended Abstracts on Human Factors in Computing Systems;978-1-4503-1952-2;NA;10.1145/2468356.2479589;https://doi.org/10.1145/2468356.2479589;"The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?";2013;2021-02-15T21:35:37Z;2021-02-15T21:35:37Z;NA;2979–2982;NA;NA;NA;NA;NA;NA;CHI EA '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Paris, France;NA;NA;NA;"empathy; embodied cognition; gesture; nonverbal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
6F9NWBT6;conferencePaper;2014;Gasselseder, Hans-Peter;Dynamic Music and Immersion in the Action-Adventure an Empirical Investigation;Proceedings of the 9th Audio Mostly: A Conference on Interaction With Sound;978-1-4503-3032-9;NA;10.1145/2636879.2636908;https://doi.org/10.1145/2636879.2636908;Aiming to immerse players into a new realm of drama experience, a growing number of video games utilize interactive, 'dynamic' music that reacts adaptively to game events. Though little is known about the involved perceptual processes, the design rationale of enhanced immersive experiences is taken over by public discussion including scientific accounts, despite lacking empirical validation. The present paper intends to fill this gap by hypothesizing facilitatory effects of dynamic music on attention allocation in the matching of expected and incoming expressive characteristics of concurrent stimuli. Moreover, personality constructs are investigated in mediating the decoding and sensing of experiences linked to immersion, presence, and emotion. The experiment explored experiential states of immersion, emotional valence/arousal as well as trait music empathizing and emotional involvement in the context of dynamic and non-dynamic music. 60 subjects answered self-report questionnaires each time after playing a 3rd-person action-adventure in one of three conditions accounting for (1) dynamic music, (2) non-dynamic music/low arousal potential and (3) non-dynamic music/high arousal potential, in this way aiming to manipulate structural-temporal alignment, emotional arousal and resulting congruency of nondiegetic music. Shedding light on the implications of music dramaturgy within a semantic ecology, different layers of mind sets between the player, avatar, and game environment are assumed to moderate a continuous regulatory modulation of emotional response achieved by context effects of dynamic music.;2014;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;NA;NA;NA;NA;NA;NA;NA;AM '14;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Aalborg, Denmark;NA;NA;NA;"emotion; presence; immersion; dynamic music; games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
ECF5R9TU;conferencePaper;2019;"Giakoumis, Dimitrios; Votis, Konstantinos; Altsitsiadis, Efthymios; Segkouli, Sofia; Paliokas, Ioannis; Tzovaras, Dimitrios";Smart, Personalized and Adaptive ICT Solutions for Active, Healthy and Productive Ageing with Enhanced Workability;Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments;978-1-4503-6232-0;NA;10.1145/3316782.3322767;https://doi.org/10.1145/3316782.3322767;"Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the ""Ageing@work"" project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production.";2019;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;442–447;NA;NA;NA;NA;NA;NA;PETRA '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Rhodes, Greece;NA;NA;NA;"age-friendly workforce management; ageing workforce; eHealth; virtual user models; workability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
R9AUWELX;conferencePaper;2015;"Encinas, Enrique; Mitchell, Robb";Cyrafour: An Experiential Activity Facilitating Empathic Distant Communication among Copresent Individuals;Proceedings of the 6th Augmented Human International Conference;978-1-4503-3349-8;NA;10.1145/2735711.2735815;https://doi.org/10.1145/2735711.2735815;Distant communication relies mostly on a non-embodied representation of participants (e.g. textual in chats, photographic in videoconference, auditory in telephony, etc) that lessens the sensory richness of conversational interactions. Cyrafour is a novel activity that explores the implications of using human avatars (cyranoids) for empathic interpersonal remote communication. An unscripted conversation between two individuals (the sources) is transmitted through radio waves and reproduced by two copresent subjects (the cyranoids) following certain conversational guidelines. In particular, the Sources were invited to discuss about a topic, play a conversation game and comment on an opinionated video. All Cyrafour sessions were video-taped and participants interviewed afterwards in order to support analysis and discussion. Cyrafour could be considered as a playful embodied identity game in which cyranoids are simultaneously together in and aside from a conversation generated elsewhere. This puzzling circumstance seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised.;2015;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;165–166;NA;NA;NA;NA;NA;NA;AH '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"embodied cognition; serious games; copresence; cyranoids; human avatars; telepresence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
MR225G7U;conferencePaper;2019;"Zelenskaya, Maria; Harvey, Louise";Virtual Avatars as a Tool for Audience Engagement;The 17th International Conference on Virtual-Reality Continuum and Its Applications in Industry;978-1-4503-7002-8;NA;10.1145/3359997.3365717;https://doi.org/10.1145/3359997.3365717;Modern motion capture tools can be used to animate sophisticated digital characters in real time. Through these virtual avatars human performers can communicate with live audience, creating a promising new area of application for public engagement. This study describes a social experiment where a real-time multimedia setup was used to facilitate an interaction between a digital character and visitors at a public venue. The technical implementation featured some innovative elements, such as using iPhone TrueDepth Camera as part of the performance capture pipeline. The study examined public reactions during the experiment in order to explore the empathic potential of virtual avatars and assess their ability to engage live audience.;2019;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;NA;NA;NA;NA;NA;NA;NA;VRCAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Brisbane, QLD, Australia;NA;NA;NA;"audience engagement; Real-time motion capture; virtual avatar";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
EZTLTK4H;conferencePaper;2016;"Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka";Sharing Emotion Described as Text on the Internet by Changing Self-Physiological Perception;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2974825;https://doi.org/10.1145/2974804.2974825;"Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.";2016;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;145–153;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Biopolis, Singapore;NA;NA;NA;"emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
YJVWHGZG;conferencePaper;2017;"Valverde, Isabel; Cochrane, Todd";Senses Places: Soma-Tech Mixed-Reality Participatory Performance Installation/Environment;Proceedings of the 8th International Conference on Digital Arts;978-1-4503-5273-4;NA;10.1145/3106548.3106613;https://doi.org/10.1145/3106548.3106613;We present the latest developments of the art-tech research project Senses Places, a somatic-technological (soma-tech) mixed-reality participatory performance installation/environment, engaging expanded modes of embodied physical-virtual interaction. This ongoing somatic-technological dance/performance collaborative trans-disciplinary approach gathers artists and developer researchers, working remotely and physically in analogical-digital intermedia interfaces and their expanded experience design and choreography. The sensorial expansion and integration sought through human-computer interaction links participants, avatars, images and physical-virtual environments. They constitute different organic-artificial sensorial-expressive channels of visual, audio, tactile, and somatic/kinesthetic shared tuning/engagement/experience. At the core of this long-term intervention lies the common urging desire for more encompassing and empathic embodied interactivity among physical and remote subjects and places. With a cross-cultural somatic and dance practices, Senses Places critically experiments with different informational, communicational and biomedical technologies available, wishing to contribute to understand the world's and humans becoming through what we have been conceiving as posthuman corporealities [1] within a posthuman condition and emerging somatic epistemology [2].;2017;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;195–197;NA;NA;NA;NA;NA;NA;ARTECH2017;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Macau, China;NA;NA;NA;"Dance-technology; Interaction design; Interactive art; Posthuman corporealities; Somatic epistemology; Somatics; Virtual and mixed-reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KS4TE2MZ;conferencePaper;2013;"Diez, Helen V.; García, Sara; Sánchez, Jairo R.; del Puy Carretero, Maria";3D Animated Agent for Tutoring Based on WebGL;Proceedings of the 18th International Conference on 3D Web Technology;978-1-4503-2133-4;NA;10.1145/2466533.2466534;https://doi.org/10.1145/2466533.2466534;"The goal of the work presented in this paper is to develop a 3D web based online tutoring system that enhances the motivation and cognitive development of students. To achieve this, a virtual assistant will be integrated to the e-learning platform; this 3D modeled e-tutor will evaluate each student individually, it will react to their learning progress by empathetic gestures and it will guide them through the lectures according to their personal needs. The accomplishment of these tasks will imply a thorough study of the latest techniques on artificial intelligence, multi-agent architectures and their representation by means of 3D emotional avatars.";2013;2021-02-15T21:35:38Z;2021-02-15T21:35:38Z;NA;129–134;NA;NA;NA;NA;NA;NA;Web3D '13;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: San Sebastian, Spain;NA;NA;NA;"artificial intelligence; e-learning; virtual agents; Web3D technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
4TSJD4SI;conferencePaper;2016;"Kim, Jungwoo; Kim, Hyesook; Choi, Jaeboong";Development of Smart Product, DUET Using SQFD and Storytelling;Proceedings of HCI Korea;978-89-6848-791-0;NA;10.17210/hcik.2016.01.298;https://doi.org/10.17210/hcik.2016.01.298;This paper presents a smart product design process for a wearable device to provide empathy and fun to users. As the first step, keywords were extracted using open-coding methods from text WebData of online sites for wearable devices, Smardi, Sblog, and Wsite. The Smart Quality Function Deployment (SQFD) was then applied to prioritize the keywords and corresponding user requirements. The key user requirements such as 'separable band from core module' and 'function for media control' were then materialized into a wearable band, DUET, using rapid prototyping, and refined through three stages of user evaluation. DUET connectable to iOS and Android smartphones was introduced by a storytelling transmedia videoclip by experts with a theme of empathy and fun. It was also advertised on a cloud funding site, Indiegogo, and through a PPL in S entertainment program, and received positive responses. Further detailed analysis of user responses was performed for 72 days through the operation of facebook-DUET site and for 10 days through Google keyword marketing which derived various levels of user activities.;2016;2021-02-15T21:36:05Z;2021-02-15T21:36:05Z;NA;298–306;NA;NA;NA;NA;NA;NA;HCIK '16;NA;NA;NA;Hanbit Media, Inc.;Seoul, KOR;NA;NA;NA;NA;NA;NA;NA;event-place: Jeongseon, Republic of Korea;NA;NA;NA;"RP; SQFD";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
KD9RUDW8;conferencePaper;2018;Brueckner, Sophia;Empathy Amulet: A Wearable to Connect with Strangers;Proceedings of the 2018 ACM International Symposium on Wearable Computers;978-1-4503-5967-2;NA;10.1145/3267242.3267301;https://doi.org/10.1145/3267242.3267301;The Empathy Amulet is a wearable interpretation of Philip K. Dick's empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both haptically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today's world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson's theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4].;2018;2021-02-15T21:36:05Z;2021-02-15T21:36:05Z;NA;248–253;NA;NA;NA;NA;NA;NA;ISWC '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"embodied cognition; haptic I/O; internet of things; prototyping; wearable electronics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACM
SWTYWWPW;conferencePaper;2011;"Polajnar, J.; Dalvandi, B.; Polajnar, D.";Does empathy between artificial agents improve agent teamwork?;IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11);NA;NA;10.1109/COGINF.2011.6016126;NA;Both everyday experience and scientific studies indicate that emotional intelligence in general, and empathy in particular, improve the effectiveness of human teamwork. Research in affective computing confirms their significance in systems where humans and artificial agents interact. This paper explores the notion of empathy between artificial agents that has so far received little attention, and argues that it could have significant impact on the design of robust and resilient agent teams. Combining the formal framework of Emotional BDI agents with the principles underlying the leading model of empathy in psychology and neuroscience, we define a hierarchy of affective and behavioral responses, integrated into an algorithm that formalizes the interactions between the subject and object of empathy in the domain of artificial practical reasoning agents.;2011-08;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;96-102;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\72F6GM85\6016126.html;NA;NA;"Humans; Cognition; neurophysiology; emotional intelligence; empathy; affective computing; neuroscience; affective responses; agent teamwork; artificial agents; artificial practical reasoning agents; behavioral responses; Computer science; Electronic mail; Emotional BDI agents; human teamwork; inference mechanisms; multi-agent systems; Neuroscience; psychology; resilient agent team design; robust agent team design; Robustness; Teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
NUJXZSXP;conferencePaper;2020;"Nehra, V.; Nagpal, R.; Sehgal, R.";Collective Intelligence: When, Where and Why;2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence);NA;NA;10.1109/Confluence47617.2020.9058000;NA;The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.;2020-01;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;805-810;NA;NA;NA;NA;NA;Collective Intelligence;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\7EW9HMRQ\9058000.html;NA;NA;"artificial intelligence; learning (artificial intelligence); machine learning; Collective Intelligence; Aggregates; Artificial Intellegence; collective intelligence; Collective intelligence; Organizations; Particle swarm optimization; smart organization; Social network services; software agents; Standards organizations; Swarm Intelligence; virtual artificially intelligent agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
NT4RQEAS;conferencePaper;2020;"Dixit, R.; Chinnam, R. B.; Singh, H.";Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations;2020 IEEE Aerospace Conference;NA;NA;10.1109/AERO47225.2020.9172612;NA;Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.;2020-03;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;1-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1095-323X;NA;C:\Users\esben\Zotero\storage\YB9ESVJG\9172612.html;NA;NA;"artificial intelligence; learning (artificial intelligence); ML; AI; neural nets; human intelligence; ample data; ample time; answer-key; artificial Intelligence techniques; cross-disciplinary decision engine; current research streams; data-rich situations; decision algorithms; decision making; defined decision-basis; experienced practitioners; informed decisions; logical formulations; logical outcome; machine Learning; neural techniques; operational decision scenarios; real-time decision making; sparse-data environments; strategic decision scenarios; successful training; sufficient learning; tactical, decision scenarios; typical implementations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 IEEE Aerospace Conference;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
CBG7D925;conferencePaper;2020;Wang, Z.;Future Challenges in the Next Generation of Voice User Interface;2020 International Conference on Computing and Data Science (CDS);NA;NA;10.1109/CDS49703.2020.00045;NA;With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI.;2020-08;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;191-193;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\R7MYADZR\9276008.html;NA;NA;"artificial intelligence; ethics; empathy; accessibility; artificial intelligence technology; artificial interactions; complex interaction scenarios; core technics; Data science; disabled interaction scenarios; key elements; user interface; user interfaces; voice user interface; VUI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 International Conference on Computing and Data Science (CDS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
TPW8YUM9;conferencePaper;2019;Chiu, K. C.;Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation;2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM);NA;NA;10.1109/IEEM44572.2019.8978876;NA;This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence.;2019-12;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;1516-1520;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2157-362X;NA;C:\Users\esben\Zotero\storage\QQLZFV4Z\8978876.html;NA;NA;"artificial intelligence; Artificial Intelligence; data mining; Dream Consultation; Knowledge Management; Text Mining; psychology; abstract affective words; affective expression; behavioural sciences computing; dream consultation; dream log; Semantic Analytics; text analysis; text mining";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
EAFXY2C5;conferencePaper;2014;"Majot, A. M.; Yampolskiy, R. V.";AI safety engineering through introduction of self-reference into felicific calculus via artificial pain and pleasure;2014 IEEE International Symposium on Ethics in Science, Technology and Engineering;NA;NA;10.1109/ETHICS.2014.6893398;NA;In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of “moral mathematics” felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed.;2014-05;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;1-6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\7U4WB6YD\6893398.html;NA;NA;"learning (artificial intelligence); Ethics; Artificial intelligence; Computers; Concept Learning; Intelligent Agents; Machine Learning; Perceptual Reasoning; AI safety engineering; artificial intelligent agents; artificial pain; artificial pleasure; calculus; Calculus; felicific calculus; moral mathematics; morality system; Pain; Philosophical Foundations; Safety; self-reference; Senior citizens; utilitarianism movement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2014 IEEE International Symposium on Ethics in Science, Technology and Engineering;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
ZGUSU9B3;conferencePaper;2015;"Headleand, C. J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L. A.";Does the Perceived Identity of Non-player Characters Change How We Interact with Them?;2015 International Conference on Cyberworlds (CW);NA;NA;10.1109/CW.2015.35;NA;Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it.;2015-10;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;145-152;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\D8PIUTPC\7398406.html;NA;NA;"artificial intelligence; Visualization; Artificial intelligence; Computers; Robots; behavioural sciences computing; Ash; Avatars; CASA; computer games; Games; Games AI; Human Agent Interaction; Identity; nonplayer character perceived identity; NPC; online game; player behavior; unarmed NPC companion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 International Conference on Cyberworlds (CW);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
PJ4BZJVQ;conferencePaper;2019;"Das, A. K.; Ashrafi, A.; Ahmmad, M.";Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System;2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS);NA;NA;10.1109/CCOMS.2019.8821655;NA;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.;2019-02;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;36-40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\489Y55XX\8821655.html;NA;NA;"learning (artificial intelligence); Task analysis; Decision making; cognition; Law; Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment; advanced artificial intelligence system; criminal punishment prediction; Forecasting; judicial system; law administration; Machine intelligence; machine learning algorithms; Machine learning algorithms; Predictive models; Women and Children Repression Prevention Act 2000";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
CCJN75SK;conferencePaper;2017;"Restrepo, E. G. y; Boticario, J. G.";Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future;2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC);NA;NA;10.1109/ICE.2017.8280067;NA;This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society.;2017-06;2021-02-11T02:07:21Z;2021-02-11T02:07:21Z;NA;1552-1558;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\KL8B7BY3\8280067.html;NA;NA;"artificial intelligence; Education; Artificial Intelligence; Empathy; Accessibility; Diversity; ACACIA European project; Afective computing; Assistive technology; Cultural differences; Economics; educational institutions; further education; Gesture recognition; higher education; intelligent systems; Intelligent systems; noninclusive design tendencies";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3AFCZK2M;conferencePaper;2013;"Kwak, S. S.; Kim, Y.; Kim, E.; Shin, C.; Cho, K.";What makes people empathize with an emotional robot?: The impact of agency and physical embodiment on human empathy for a robot;2013 IEEE RO-MAN;NA;NA;10.1109/ROMAN.2013.6628441;NA;As empathy is important for the emotional interaction between a human and a robot, the design factors which induce human empathy toward robots need to be explored. Human empathy toward a robot can be affected by the presence of a robot. Thus, we focused on the levels of agency and the physical embodiment of a robot, which are influential factors pertaining to social presence, by executing two experiments. In the first experiment, in a 2 (levels of agency: mediated vs. simulated) between-participants experiment, participants interacted with either a mediated robot which delivers the emotional state of a remote user or a simulated robot which expresses its own emotion. Participants empathized more with the mediated robot than with the simulated robot, demonstrating that the proper form of an emotional robot is as a mediator during emotional interaction between people. In the second study, in a 2 (physical embodiment: physically embodied vs. physically disembodied) between-participants experiment design, participants interacted with either a physically embodied robot or a physically disembodied robot. The results showed that participants empathized more with a physically embodied robot than with a physically disembodied robot, indicating the impact of physical embodiment on human empathy. Implications for the design of human-robot interactions are discussed.;2013-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;180-185;NA;NA;NA;NA;NA;What makes people empathize with an emotional robot?;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\SG9A724T\6628441.html;NA;NA;"robots; human robot interactions; Educational institutions; Human-robot interaction; Conferences; Emotion recognition; emotional interaction; emotional robot; emotional state; Face; human computer interaction; human empathy; mediated robot; physical embodiment; Service robots; simulated robot; social presence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2013 IEEE RO-MAN;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
UHSZTWEW;conferencePaper;2015;"Darling, K.; Nandy, P.; Breazeal, C.";Empathic concern and the effect of stories in human-robot interaction;2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/ROMAN.2015.7333675;NA;People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.;2015-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;770-775;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;"C:\Users\esben\Zotero\storage\YDIPVRXE\7333675.html; C:\Users\esben\Zotero\storage\FIJGMB3Y\Darling et al. - 2015 - Empathic concern and the effect of stories in huma.pdf";NA;NA;"Media; human-robot interaction; Human-robot interaction; Robots; Atmospheric measurements; behavior indicative; empathic concern; empathic responses; human factors; Indexes; Particle measurements; people hesitation; people trait empathy; robotic object; stories; Videos";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
5RVDI8IC;conferencePaper;2019;"Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.";Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming;2019 Systems and Information Engineering Design Symposium (SIEDS);NA;NA;10.1109/SIEDS.2019.8735613;NA;The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.;2019-04;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1-6;NA;NA;NA;NA;NA;Ideal Warrior and Robot Relations;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\8MLL84IJ\8735613.html;NA;NA;"Stress; Task analysis; empathy; human-robot interaction; robot design; Human-robot interaction; Robots; multi-agent systems; behavioural sciences computing; human computer interaction; Atmospheric measurements; Particle measurements; automated teammate; automated technologies; Battery charge measurement; battlefield; effect stress; human-machine team; Human-machine teaming; human-robot teaming; humanoid robots; ideal warrior; man-machine systems; Military aircraft; military computing; military context; military systems; military training; mobile robots; multi-robot systems; Pepper robot; social sciences computing; United States Military";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 Systems and Information Engineering Design Symposium (SIEDS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
Z6SSRQPX;conferencePaper;2015;"Seo, S. H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J. E.";Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. Categories and Subject Descriptors H.5.2 [User Interfaces]: evaluation/methodology General Terms Experimentation and Human Factors.";2015-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;125-132;NA;NA;NA;NA;NA;Poor Thing! Would You Feel Sorry for a Simulated Robot?;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\3G68AIAH\8520653.html;NA;NA;"Computational modeling; Programming; Psychology; empathy; human-robot interaction; Human-robot interaction; Robots; simulated robot; human factors; Videos; human-robot interactions; Instruments; physical robot; robot embodiment; simulated HRI work; simulated interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
UW6JCP5K;conferencePaper;2017;"Burns, H. D.; Lesseig, K.";Empathy in middle school engineering design process;2017 IEEE Frontiers in Education Conference (FIE);NA;NA;10.1109/FIE.2017.8190669;NA;This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.;2017-10;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1-4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\D5VZT9H4\8190669.html;NA;NA;"empathy; design process; educational institutions; further education; 5G mobile communication; after-school 4-H Science Club; after-school science club; all-girls after-school STEM program; Computer bugs; educational courses; emotional intelligence model; empathy in engineering; empathy need; empathy study; empathy-based lessons; engineering; engineering education; engineering problem; k-12 schools; middle school; middle school engineering design process; middle-school engineering design pedagogy; science technology engineering and mathematics; teaching; university programs";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 IEEE Frontiers in Education Conference (FIE);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
6HMCSB64;conferencePaper;2019;"Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.";Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition;2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019);NA;NA;10.1109/FG.2019.8756517;NA;The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.;2019-05;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1-5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\49F68DSC\8756517.html;NA;NA;"feature extraction; emotion recognition; human-robot interaction; actor-listener interactions; bidirectional long short-term memory network; CCC; concordance correlation coefficient; empathy perception; interpersonal relationships; intra-subject dependencies; multimodal valence-based empathy models; OMG; one-minute gradual; personalised multimodal model; unimodal valence-based empathy models; valence-based empathy recognition; visual feature extraction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
6GL3IBCJ;conferencePaper;2014;"Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.";People help robots who help others, not robots who help themselves;The 23rd IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2014.6926262;NA;Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot.;2014-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;255-260;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\AUUA3WKW\6926262.html;NA;NA;"Timing; human-robot interaction; Games; Atmospheric measurements; Particle measurements; humanoid robots; Analysis of variance; antipathy; behavioural sciences; control condition; counting game; emotional dialogue events; empathy-generating robot dialogue; externally-directed condition; externally-directed petitions; negative social effects; nonanthropomorphic social robot; participant motivation; participant performance; programmer; robot programming; Robot sensing systems; self-directed condition; social behaviors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;The 23rd IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
Y2EF3VF4;conferencePaper;2018;"James, J.; Watson, C. I.; MacDonald, B.";Artificial Empathy in Social Robots: An analysis of Emotions in Speech;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/ROMAN.2018.8525652;NA;Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.;2018-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;632-637;NA;NA;NA;NA;NA;Artificial Empathy in Social Robots;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\FF2FJEI5\8525652.html;NA;NA;"Task analysis; Medical services; robots; emotion recognition; human-robot interaction; social robots; Human-robot interaction; service robots; artificial empathy; Robot sensing systems; Anthropomorphism; appropriate emotions; artificial speech; control engineering computing; empathetic speech; empathetically interacting robot; human perception experiment; Human Robot Interaction; human subjects; human users; humans; robot interacting; robot speech; speech synthesis; speech synthesizers; standard robotic voice; Standards";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
JQ4W25YL;conferencePaper;2018;"Mollahosseini, A.; Abdollahi, H.; Mahoor, M. H.";Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/ROMAN.2018.8525777;NA;Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.;2018-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;783-789;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\RWCHIVS9\8525777.html;NA;NA;"Task analysis; robots; empathy; emotion recognition; human-robot interaction; social robots; Robots; Videos; affect-aware Ryan; automated affect perception; automated facial expression recognition system; automated FER system; emotional capabilities; empathic expression; empathic social agents; face recognition; Face recognition; human-robot-interaction experiments; likable as when facial expression; Mirrors; Observers; robot vision; social capabilities; social/interactive aspects; Speech recognition; spoken dialog";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
NZ5K66H7;conferencePaper;2020;"Corretjer, M. G.; Ros, R.; Martin, F.; Miralles, D.";The Maze of Realizing Empathy with Social Robots;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/RO-MAN47096.2020.9223466;NA;Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.;2020-08;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1334-1339;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\A94MSCLY\9223466.html;NA;NA;"affective states; human-robot interaction; social robots; software agents; mobile robots; empathy model; empathy test-bed; fun collaborative scenario; intelligent agents; intelligent robots; maze; social robot work";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
UVGNDT3F;conferencePaper;2014;"Williams, M.; Wang, X.; Parajuli, P.; Abedi, S.; Youssef, M.; Wang, W.";The Fugitive : A Robot In the Wild;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;The aim of the movie is to highlight some of the key challenges facing so-cial robots in the wild. The opening scene shows a PR2 leaving research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building. The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is as-signed menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not. The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on. The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but also chastising a male-human for not observing this important social protocol. The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceit-fully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.;2014-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;111-111;NA;NA;NA;NA;NA;The Fugitive;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\RP4DBHRM\8542525.html;NA;NA;"human-robot interaction; Australia; service robots; social interaction; teaching; Robot sensing systems; Buildings; critically important skills; Dairy products; glass walls; highly sophisticated cognitive skill; hot steaming liquids; Human-Robot Interaction; important research questions highlighting problems; important social protocol; Lighting; menial tasks; Motion pictures; opening scene; peanut butter; PR2 leaving research laboratory venturing; PR2 robots; recaptured robot; research problem; Robots in the Wild; security of data; service robot; so-cial robots; social aspects of automation; social etiquette; Social Robotics; social service robotics; subsequent scene";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
EJ4YR36F;conferencePaper;2016;"Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.";A laughing-driven pupil response system for inducing empathy;2016 IEEE/SICE International Symposium on System Integration (SII);NA;NA;10.1109/SII.2016.7844051;NA;Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.;2016-12;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;520-525;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2474-2325;NA;C:\Users\esben\Zotero\storage\HWQYN8ZX\7844051.html;NA;NA;"Timing; empathy; affective computing; human-robot interaction; Robots; Computer science; affective response; communication system; hemispherical display; human communication; human interaction; laughing-driven pupil response system; laughter sharing; Mathematical model; media representation; Solid modeling; Speech; Three-dimensional displays";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2016 IEEE/SICE International Symposium on System Integration (SII);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
HEW8LKKT;conferencePaper;2019;Vertesi, J.;Seeing Like a Rover: Team Work and Human-Robot Relations;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;10.1109/HRI.2019.8673224;NA;How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.;2019-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;152-152;NA;NA;NA;NA;NA;Seeing Like a Rover;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2148;NA;C:\Users\esben\Zotero\storage\2M67AUTG\8673224.html;NA;NA;"cognition; human-robot interaction; Teamwork; Human-Robot Interaction; aerospace robotics; group interactions; human cognition; human team; human-robot relations; Mars; Mars Exploration Rover; NASA; planetary rovers; rescue operations; robotic spacecraft missions; robotic spacecraft teams; team work; team working";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
PICWCQ4D;conferencePaper;2011;"Gonsior, B.; Sosnowski, S.; Mayer, C.; Blume, J.; Radig, B.; Wollherr, D.; Kühnlenz, K.";Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions;2011 RO-MAN;NA;NA;10.1109/ROMAN.2011.6005294;NA;In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application “Akinator” serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode.;2011-07;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;350-356;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\KDA2EQPZ\6005294.html;NA;NA;"human-robot interaction; Computers; Robots; computer games; control engineering computing; face recognition; robot vision; Speech; Actuators; Akinator Web-based gaming application; EDDIE robot head; HRI empathy performance; HRI subjective performance; human facial expression; Loudspeakers; Microphones; Neck; social awareness psychological model";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2011 RO-MAN;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
EUC9XK3X;conferencePaper;2014;"Chumkamon, S.; Hayashi, E.";ConBe robot: The development of self-perception and expression in face-to-face interaction;2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS);NA;NA;10.1109/SCIS-ISIS.2014.7044703;NA;In social robot development of interaction system robot, it is necessary to develop the fundamental function such as the robot perception. Due to the robot should correctly interpret a behavior or mental expression of the human. If the robot has a good emotional insight of the human, it is the advantage for the robot perception. In this paper, we implement the significant technique that take an advantage to the robot such as the human detection, face detection and recognition. Basically, these techniques could further enable the robot capability of intelligent empathy from the expression of human. We intensively study the vision method for facial expression recognition (FER) to understanding the human emotion and interacting by the robot expression in particular case. The robot interaction is based on the interested person that the robot can recognize with their emotional expression. We also experiment the system in term of face-to-face between robot and user with demonstrate using the head robot along with the result, such as the performance of the perception and the behavior expression of the robot.;2014-12;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;769-775;NA;NA;NA;NA;NA;ConBe robot;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\USYWARD9\7044703.html;NA;NA;"social robot; emotion recognition; human-robot interaction; face recognition; robot vision; ConBe robot; face detection; face-to-face interaction; facial expression recognition; FER; human detection; human emotion; social robot development";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
Q6FSFLIX;conferencePaper;2016;"Sin, Y. M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.; Miyake, Y.";Evaluation of a head motion synchronization system in the communicative process between human and robot;2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE);NA;NA;10.1109/SICE.2016.7749252;NA;An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.;2016-09;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1514-1519;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\7WGHAWT6\7749252.html;NA;NA;"human-robot interaction; social robots; assisted living; Human-robot interaction; Robots; Senior citizens; Acceleration; Accelerometers; Aging; assistive system; elderly rehabilitation; Head motion synchronization; head motion synchronization system; leader-follower relationship; mutual entrainment; neurocognitive impairments; one-way face-to-face human-robot communication experiments; Synchronization";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
6MMH7QBB;conferencePaper;2015;"Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani-Sherman, T.";Design and Evaluation of a Peripheral Robotic Conversation Companion;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote nonaggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to-human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.;2015-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;3-10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\SIT2UBQ9\8520619.html;NA;NA;"Monitoring; Empathy; human-robot interaction; design process; Human-robot interaction; human factors; humanoid robots; Robot sensing systems; Ambient kinetic tangibles; Animation; Behavior change; Design; design goals; gaze attention; gesture recognition; human-human interaction; interactive systems; Kinetic theory; Kip1; nonaggressive conversation; peripheral empathy-evoking robotic conversation companion; reacting robot; robot autonomous behavior; Robotic companions; robotic devices; Shape; Smartphone robots.; social human character traits";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
N8GQS2ZK;conferencePaper;2020;"Sönmez, E. B.; Köse, H.; Barkana, D. E.";Towards a New Computational Affective System for Personal Assistive Robots;2020 28th Signal Processing and Communications Applications Conference (SIU);NA;NA;10.1109/SIU49456.2020.9302238;NA;The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively.;2020-10;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1-4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2165-0608;NA;C:\Users\esben\Zotero\storage\63LICFIK\9302238.html;NA;NA;"Computational modeling; emotion recognition; affective computing; virtual human; Robots; facial expression; Face recognition; Three-dimensional displays; Faces; Feature extraction; Mood";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 28th Signal Processing and Communications Applications Conference (SIU);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
BPW7ZFLC;conferencePaper;2019;"Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.";The RoPE Scale: a Measure of How Empathic a Robot is Perceived;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;10.1109/HRI.2019.8673082;NA;To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.;2019-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;656-657;NA;NA;NA;NA;NA;The RoPE Scale;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2148;NA;C:\Users\esben\Zotero\storage\5AUM3L57\8673082.html;NA;NA;"Psychology; Psychometrics; cognition; human-robot interaction; Indexes; Robot sensing systems; Human-Robot Interaction; emotional behaviors; empathic behaviors; interaction partners; Measurement; Perceived Empathy; RoPE scale; Social Robots; Software reliability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
IEGQ7ERR;conferencePaper;2019;"Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.";Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals;2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/RO-MAN46459.2019.8956353;NA;Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.;2019-10;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\XW5RD9GG\8956353.html;NA;NA;"empathy; emotion recognition; human-robot interaction; facial expression; face recognition; robot vision; biological signals; emotion estimation system; human-robot; reflected emotion; robot expression; uncontrollable emotion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
BW3IB68E;conferencePaper;2014;"Obaid, M.; Kuchenbrandt, D.; Bartneck, C.";Empathy and Yawn Contagion: Can we (Humans) Catch Yawns from Robots?;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.;2014-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;260-261;NA;NA;NA;NA;NA;Empathy and Yawn Contagion;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\YPV8NIVJ\8542627.html;NA;NA;"Psychology; Task analysis; robots; Empathy; empathy; Human-robot interaction; Humanoid robots; human computer interaction; Atmospheric measurements; Particle measurements; humanoid robots; Humanoid; Robot; social closeness; Yawn; yawn contagion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
VIBQDQAF;conferencePaper;2018;"Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri";Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;10.1109/ICAITI.2018.8686759;NA;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.;2018-09;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;208-212;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\NSYFQM36\8686759.html;NA;NA;"handicapped aids; Mobile Robot; social interaction; psychology; mobile robots; Android; Android-based mobile robots; Asperger syndrome; Asperger Syndrome disorder; autistic disorder; data analysis; mobile computing; paediatrics; patient treatment; Pekanbaru children; play therapy; Rank Wilcoxon; robot control tool; smart phones; wheel-shaped robot; wheeled robot; wheels";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
B6PR6HZT;conferencePaper;2018;"Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.";Band of Brothers and Bolts: Caring About Your Robot Teammate;2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);NA;NA;10.1109/IROS.2018.8594324;NA;It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.;2018-10;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;1853-1858;NA;NA;NA;NA;NA;Band of Brothers and Bolts;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2153-0866;NA;C:\Users\esben\Zotero\storage\JGEW9345\8594324.html;NA;NA;"human-robot interaction; Robots; computer games; Atmospheric measurements; Particle measurements; Computer bugs; Bonding; consequential behavioral pattern; empathic response; robot companion; robot teammate; Time measurement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
5ZP86ULF;conferencePaper;2017;"Anshar, M.; Williams, M.";Evolving artificial pain from fault detection through pattern data analysis;2017 IEEE International Conference on Real-time Computing and Robotics (RCAR);NA;NA;10.1109/RCAR.2017.8311945;NA;Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.;2017-07;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;694-699;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;"C:\Users\esben\Zotero\storage\HZL343LQ\8311945.html; C:\Users\esben\Zotero\storage\B5MNBMHD\Anshar and Williams - 2017 - Evolving artificial pain from fault detection thro.pdf";NA;NA;"robots; Pain; Robot sensing systems; data analysis; appropriate artificial pain; artificial pain generation; artificial robot pain; biomechanics; body machinery aspects; Data analysis; evolving artificial pain; extensive research works; fault detection approach; fault diagnosis; Machinery; pattern data analysis; Planning; sophisticated social skills; synthetic pain classes";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 IEEE International Conference on Real-time Computing and Robotics (RCAR);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
CCPE44P7;conferencePaper;2019;"Sanoubari, E.; Seo, S. H.; Garcha, D.; Young, J. E.; Loureiro-Rodríguez, V.";Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;10.1109/HRI.2019.8673326;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019-03;2021-02-11T03:17:10Z;2021-02-11T03:17:10Z;NA;382-391;NA;NA;NA;NA;NA;Good Robot Design or Machiavellian?;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2148;NA;C:\Users\esben\Zotero\storage\MUTHQCVK\8673326.html;NA;NA;"learning (artificial intelligence); Ethics; Task analysis; culture; human-robot interaction; social robots; robot design; Robots; Cultural differences; mobile robots; Shape; Mood; body language; Global communication; human-like communication techniques; in the wild; in-the-wild robot; minimal information; passersby culture; persuasive robots; Sam; social signals; social techniques";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3UZRKRCE;conferencePaper;2020;"Ye, S.; Feigh, K.; Howard, A.";Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/RO-MAN47096.2020.9223437;NA;Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.;2020-08;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;1186-1189;NA;NA;NA;NA;NA;Learning in Motion;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\FWTXNISG\9223437.html;NA;NA;"cognition; human-robot interaction; computer games; humanoid robots; human-robot interactions; cognitive science literature; dance motion; dynamic interactions; embodied cognition; human perspective; human-robot interaction games trust; humanoid robot; social empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
JWA5FAS3;conferencePaper;2016;"Ranieri, C. M.; Romero, R. A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR);NA;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\EJTCU8NI\7783498.html;NA;NA;"Emotions; Affective computing; empathy; human-robot interaction; social robots; Robots; Social robots; control engineering computing; smart phones; Android application; embodied virtual agent; emotion-aware interaction strategy; emotional reactions; facial expressions analysis; human-robot interaction improvement; Mobile devices; pleasantness; virtual character";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
QLM7V8GL;conferencePaper;2015;"Chumkamon, S.; Masato, K.; Hayashi, E.";Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot;2015 IEEE International Conference on Systems, Man, and Cybernetics;NA;NA;10.1109/SMC.2015.45;NA;This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).;2015-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;185-190;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\EWETKWNI\7379177.html;NA;NA;"Animals; human-robot interaction; artificial consciousness; social interaction; Face; face recognition; robot vision; human communication; Mathematical model; facial expression recognition; Shape; animal behavior; animal robot; artificial neurotransmitter; CBA; cross-creature communication development; cross-expression; cross-perception; emotional motivation; Facial Expression Recognition; human expression; Human-Robot Interactio; Manipulators; Neurotransmitters; pet robot; phylogenesis; social cognitive; Social Robot; user expression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 IEEE International Conference on Systems, Man, and Cybernetics;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
VV6V86VF;conferencePaper;2020;"Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.";Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/RO-MAN47096.2020.9223442;NA;In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.;2020-08;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;653-658;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;"C:\Users\esben\Zotero\storage\62CHVINT\9223442.html; C:\Users\esben\Zotero\storage\Y28DJKT2\Mitsuno et al. - 2020 - Robot-on-Robot Gossiping to Improve Sense of Human.pdf";NA;NA;"social robot; human-robot interaction; man-machine systems; control engineering computing; conversation experiment; data privacy; dialogue strategy; human-robot conversation; Likert scale evaluation; long-term user interest; natural language interfaces; privacy issue; privacy problems; robot empathy; robot-on-robot gossiping";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
UU2NCDW4;conferencePaper;2018;"Iranzo, R. M. G.; Padilla-Zea, N.; Paderewski-Rodríguez, P.; González-González, C. S.";Empathy and virtual agents for learning applications in symbiotic systems;2018 IEEE Global Engineering Education Conference (EDUCON);NA;NA;10.1109/EDUCON.2018.8363298;NA;Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges.;2018-04;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;694-697;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2165-9567;NA;C:\Users\esben\Zotero\storage\5CGFADEA\8363298.html;NA;NA;"Ethics; ethics; robots; virtual agents; empathy; human-robot interaction; Robots; robot; human computer interaction; human factors; mobile robots; multi-robot systems; Observers; Biometrics (access control); bot; bots; Guidelines; HCI communication challenges; Privacy; Symbiosis; symbiotic agents; symbiotic domain; symbiotic systems; transparency; valuable asset";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 IEEE Global Engineering Education Conference (EDUCON);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
MRDX7LXN;conferencePaper;2018;"Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 International Joint Conference on Neural Networks (IJCNN);NA;NA;10.1109/IJCNN.2018.8489158;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018-07;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;1-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2161-4407;NA;C:\Users\esben\Zotero\storage\BLWAF4EI\8489158.html;NA;NA;"learning (artificial intelligence); Neurons; emotion recognition; human-robot interaction; social robots; Adaptation models; Emotion recognition; humanoid robots; Robot sensing systems; face recognition; Mood; affective modulations; Convolution; deep hybrid neural model; empathy-driven emotion expressions; facial expression representations; interaction design; internal affective model; internal emotions; intrinsic affective states; multimodal affect recognition; natural interaction experience; neuro-inspired companion robot; neurocontrollers; NICO robot; reinforcement learning model; self-organising feature maps; self-organising network models";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
26UNSF46;conferencePaper;2010;"Beck, A.; Cañamero, L.; Bard, K. A.";Towards an Affect Space for robots to display emotional body language;19th International Symposium in Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598649;NA;In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex.;2010-09;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;464-469;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\ZJFWIRJ4\5598649.html;NA;NA;"robots; emotion recognition; facial expressions; Robots; Atmospheric measurements; Particle measurements; Analysis of variance; control engineering computing; affect space; emotional body language display; Head; head position; Joints; Nao; pose estimation; Position measurement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;19th International Symposium in Robot and Human Interactive Communication;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
TLRVRR93;conferencePaper;2012;"Gonsior, B.; Buß, M.; Sosnowski, S.; Wollherr, D.; Kühnlenz, K.; Buss, M.";Towards transferability of theories on prosocial behavior from Social Psychology to HRI;2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO);NA;NA;10.1109/ARSO.2012.6213407;NA;This paper describes the transfer of theories on prosocial behavior from Social Psychology to human-robot interaction (HRI) in terms of helpfulness shown by humans towards a robot. Theoretical foundations are given, and relevant influence factors for prosocial behavior are defined. The paper provides an overview on how these factors can be transferred to HRI and are implemented in two experimental settings. In a first experiment, situational empathy towards a robot is increased. In a second experiment, similarity is induced by means of emotional adaption to the mood of the user. Results show that helpfulness towards a robot can be increased by this approach, thus, re-evaluating the transferability of theories from Social Psychology to HRI.;2012-05;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;101-103;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2162-7576;NA;"C:\Users\esben\Zotero\storage\QKR369EX\6213407.html; C:\Users\esben\Zotero\storage\GGJGKRS2\Gonsior et al. - 2012 - Towards transferability of theories on prosocial b.pdf";NA;NA;"Context; Humans; human-robot interaction; Robots; prosocial behavior; psychology; Games; Face; Mood; emotional adaption; situational empathy; social psychology; theory transferability; user mood";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
P3JX5VPQ;conferencePaper;2012;"Leite, I.; Castellano, G.; Pereira, A.; Martinho, C.; Paiva, A.";Modelling empathic behaviour in a robotic game companion for children: An ethnographic study in real-world settings;2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;10.1145/2157689.2157811;NA;The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the “degree of empathy” that social robots should be endowed with.;2012-03;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;367-374;NA;NA;NA;NA;NA;Modelling empathic behaviour in a robotic game companion for children;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2148;NA;C:\Users\esben\Zotero\storage\I98RL3UA\6249581.html;NA;NA;"children; Empathy; human-robot interaction; Educational institutions; Games; Feature extraction; Social Robots; Affect Recognition; autonomous social robots; Children; elementary school; empathic behaviour modelling; Encoding; ethnographic study; Interviews; real-world settings; Robot kinematics; robotic game companion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
WPAAE397;conferencePaper;2017;"Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.";Learning human behavior for emotional body expression in socially assistive robotics;2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI);NA;NA;10.1109/URAI.2017.7992882;NA;Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots.;2017-06;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;45-50;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\E3F6IU6Q\7992882.html;NA;NA;"learning (artificial intelligence); Neurons; Psychology; Training; empathy; human-robot interaction; Human-robot interaction; Robots; humanoid robots; intelligent robots; emotional behaviors; self-organising feature maps; clustering; emotional behavior expression; emotional behavior samples; emotional body expression; emotional body expressions; emotional situations; human partners; imitation learning; infant emotional development; infant social development; Kernel; public human action dataset; self-organized neural networks; Skeleton; social referencing; socially assistive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3TCX3P9X;conferencePaper;2018;"Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.";Counseling Robot Implementation and Evaluation;2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC);NA;NA;10.1109/SMC.2018.00297;NA;"A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called ""unazuki"" in Japanese, a kind of nodding to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared.";2018-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;1716-1722;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2577-1655;NA;C:\Users\esben\Zotero\storage\JN5FRZZ8\8616293.html;NA;NA;"human-robot interaction; natural language processing; psychology; human factors; Robot sensing systems; interactive systems; Robot; body language; appropriate nodding behavior; context preserving way; context respectful counseling agent; Counseling; counseling robot implementation; CRECA; Dialog Promotion; dialog promotion nodding; dialog sentence input; Dictionaries; employee welfare; Employee welfare; enhanced experimental evaluation; industrial psychology; Japanese onomatopoeia; Natural languages; Nodding; nodding feature; occupational stress; Ontologies; psychological distress; quantitative evaluation; Reflection; reflection context; robot implementation; robot nods; unazuki; workers";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
G7VM5P8U;conferencePaper;2018;"Tuyen, N. T. Viet; Jeong, S.; Chong, N. Y.";Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction;2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);NA;NA;10.1109/IROS.2018.8593974;NA;Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.;2018-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;2008-2013;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2153-0866;NA;C:\Users\esben\Zotero\storage\HVCMCU4H\8593974.html;NA;NA;"learning (artificial intelligence); Neurons; Training; social robot; emotion recognition; human-robot interaction; Robot kinematics; Collision avoidance; cultural background; culturally competent robots; emotional bodily expressions; habitual emotional behaviors; imitated robot motions; incremental learning model; long term human-robot interaction; multiculture society; Self-organizing feature maps; Trajectory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
N8M3QWUR;conferencePaper;2018;"Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.";Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/ROMAN.2018.8525515;NA;Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.;2018-08;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;275-281;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\VAMUX9K3\8525515.html;NA;NA;"Task analysis; human-robot interaction; user experience; Robots; humanoid robots; Anthropomorphism; Mood; Color; Communication channels; emotional adaptation; explicit emotional adaptation condition; facial action units; human user; human-robot dialog scenario; named objects; NAO; prior robot contact; prior robot experience; robotic interaction partners; social cues; user study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
NR6Q8AAM;conferencePaper;2018;"Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.";Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression;2018 15th International Conference on Ubiquitous Robots (UR);NA;NA;10.1109/URAI.2018.8441767;NA;Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.;2018-06;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;377-382;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\L3964R4L\8441767.html;NA;NA;"learning (artificial intelligence); Neurons; Psychology; neural nets; Training; emotion recognition; human-robot interaction; social robots; Human-robot interaction; Robots; Cultural differences; humanoid robots; socially assistive robots; incremental learning model; Self-organizing feature maps; human emotional behavior; neural network model; social robot emotional body expression; user cultural traits";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 15th International Conference on Ubiquitous Robots (UR);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
U4RRJPT8;conferencePaper;2010;"Cramer, H.; Goddijn, J.; Wielinga, B.; Evers, V.";Effects of (in)accurate empathy and situational valence on attitudes towards robots;2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;10.1109/HRI.2010.5453224;NA;Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3×2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.;2010-03;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;141-142;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2148;NA;"C:\Users\esben\Zotero\storage\FXA8V2GD\5453224.html; C:\Users\esben\Zotero\storage\42LQJRP5\Cramer et al. - 2010 - Effects of (in)accurate empathy and situational va.pdf";NA;NA;"Appraisal; empathy; human-robot interaction; social robots; Games; Emotion recognition; empathic responses; Videos; Analysis of variance; control engineering computing; between-subject video-based survey; emotional valence; Human robot interaction; Mobile robots; negative valence condition; Online Communities/Technical Collaboration; Silicon carbide; situational valence; Testing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
B8CQ297I;conferencePaper;2015;"Hood, D.; Lemaignan, S.; Dillenbourg, P.";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.By leveraging simulated handwriting on a synchronised tablet display, a NAo humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models.Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015-03;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;83-90;NA;NA;NA;NA;NA;When Children Teach a Robot to Write;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\P5UC9XZF\8520635.html;NA;NA;"feedback; Education; cognition; empathy; human-robot interaction; Humanoid robots; psychology; educational institutions; humanoid robots; mobile robots; teaching; Mathematical model; Shape; adult-written letter trajectories; autonomous teachable humanoid; computer aided instruction; deformed letters; embodied handwriting partner; human-led handwriting interventions; meta-cognition; motor capabilities; motor mimicry; NAo humanoid robot; notebook computers; optimal parameters; primary school classes; principal component analysis; Principal component analysis; robotic partner; self-esteem; simulated handwriting; statistical shape models; synchronised tablet display; teaching paradigm; user demonstrations; Writing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
F8WTWJ89;conferencePaper;2017;"Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.";Design of Counseling Robot for Production by 3D Printer;2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS);NA;NA;10.1109/SITIS.2017.20;NA;Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling.;2017-12;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;56-62;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\IU6WAU5J\8334725.html;NA;NA;"Psychology; Cognition; human-robot interaction; Robots; psychology; Emotion recognition; human factors; Robot; context respectful counseling agent; Counseling; CRECA; Dialog Promotion; dialog sentence input; employee welfare; Employee welfare; industrial psychology; Japanese onomatopoeia; Nodding; occupational stress; psychological distress; Reflection; robot nods; unazuki; 3D printer; CA; counseling robot; newly developed robot; Problem-solving; social problems; unazuki-dialog promotion nodding robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
T74BZXI4;conferencePaper;2014;"Mok, B.; Yang, S.; Sirkin, D.; Ju, W.";Empathy: Interactions with Emotive Robotic Drawers;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.;2014-03;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;250-251;NA;NA;NA;NA;NA;Empathy;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2167-2121;NA;C:\Users\esben\Zotero\storage\4Z2UWCI8\8542481.html;NA;NA;"emotion recognition; human-robot interaction; Human-robot interaction; Robot sensing systems; Animation; DC motors; displayed emotions; emotive robotic drawers; empathetic drawers; Human Robot Interactions; Interaction Design; Interactive Furniture; Prototypes; Telepresence; Video Prototyping; video signal processing; video-prototype; Wizard of Oz Experiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
AQAG4WRN;conferencePaper;2019;"Costantini, S.; Gasperis, G. De; Migliarini, P.";Multi-agent System Engineering for Emphatic Human-Robot Interaction;2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE);NA;NA;10.1109/AIKE.2019.00015;NA;Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy.;2019-06;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;36-42;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\IK3VZP4P\8791734.html;NA;NA;"perception; emotions; communication; empathy; human-robot interaction; affect; multi-agent systems; Face; human empathy; mobile robots; Face recognition; Speech recognition; intelligent agents; Robot kinematics; body posture; daily robotic interaction; emotional exchange; emphatic communication aspects; emphatic human-robot interaction; face muscles; human robot interaction; human-robot communication use cases; logic; logical agents; Multi-agent systems; multiagent system engineering; natural multimodal bidirectional communication model; Skin; skin responses; verbal exchange; voice modulation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
GHXMWXAV;conferencePaper;2016;"Lewandowska-Tomaszczyk, B.; Wilson, P. A.";Compassion, empathy and sympathy expression features in affective robotics;2016 7th IEEE International Conference on Cognitive Infocommunications (CogInfoCom);NA;NA;10.1109/CogInfoCom.2016.7804526;NA;"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents.";2016-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;000065-000070;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\WVGNCA2A\7804526.html;NA;NA;"Context; emotions; robots; empathy; expressiveness; Robot sensing systems; Robot kinematics; action tendencies; affective robotics; British English; British English compassion; cognitive corpus linguistics; cognitive infocommunication; compassion; compassion expression features; cultural aspects; culture-specific emotion models; empathy expression features; empatia; English empathy; false negative; false positive; GRID; online sorting; Polish; Polish empatia; Polish współczucie; Pragmatics; Resonant frequency; responsiveness; sensory infocommunication; socially interactive robots; Sorting; sympathy; sympathy expression features; sympatia; valence; współczucie";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2016 7th IEEE International Conference on Cognitive Infocommunications (CogInfoCom);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
A3BWXBB4;conferencePaper;2014;"Sejima, Y.; Watanabe, T.; Jindai, M.";Development of an interaction-activated communication model based on a heat conduction equation in voice communication;The 23rd IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2014.6926356;NA;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication.;2014-08;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;832-837;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\MK39E9WN\6926356.html;NA;NA;"human-robot interaction; Robots; control engineering computing; Mathematical model; Speech; avatar-mediated communication; avatars; Equations; heat conduction equation; Heat engines; Heating; human interaction analysis; interaction-activated communication model; Modeling; partial differential equations; speech overlap; virtual communication system; voice communication";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;The 23rd IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
QRBUW3CW;conferencePaper;2019;"Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;10.1109/RITAPP.2019.8932852;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019-11;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\JDBQ42X2\8932852.html;NA;NA;"cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
QSFW2Z6R;journalArticle;2014;"Boucenna, S.; Gaussier, P.; Hafemeister, L.";Development of First Social Referencing Skills: Emotional Interaction as a Way to Regulate Robot Behavior;IEEE Transactions on Autonomous Mental Development;NA;1943-0612;10.1109/TAMD.2013.2284065;NA;In this paper, we study how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensory-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some “empathy” or at least “resonate” with the robot head (low level emotional resonance). Hence, we advocate the idea that social referencing can be bootstrapped from a simple sensory-motor system not dedicated to social interactions.;2014-03;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;42-55;NA;1;6;NA;NA;Development of First Social Referencing Skills;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;Conference Name: IEEE Transactions on Autonomous Mental Development;NA;C:\Users\esben\Zotero\storage\KWMF7MKR\6672018.html;NA;NA;"Emotion; Neurons; human-robot interaction; Emotion recognition; emotional interaction; Face; Robot sensing systems; Face recognition; facial expression recognition; Feature extraction; social referencing; complex behaviors; emotional resonance; emotional stimuli; human partner; human–robot interaction; robot behavior; sensory–motor architecture; social interactions; social referencing skills";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
M9L3JQ3M;conferencePaper;2017;"Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.";Context respectful counseling agent integrated with robot nodding for dialog promotion;2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC);NA;NA;10.1109/SMC.2017.8122833;NA;"Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling.";2017-10;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;1540-1545;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\SIK6X8DH\8122833.html;NA;NA;"Cognition; human-robot interaction; Robots; natural language processing; psychology; interactive systems; Robot; body language; context respectful counseling agent; Counseling; CRECA; Dialog Promotion; Dictionaries; Employee welfare; Japanese onomatopoeia; Nodding; occupational stress; Ontologies; psychological distress; Reflection; reflection context; robot nods; unazuki; Problem-solving; client reflection; context preserving; dialogue promotion; IT personnel; ontologies (artificial intelligence); robot nodding; ubiquitous computing; unazuki dialog promotion nodding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
MYHND69Z;conferencePaper;2011;"Mazzei, D.; Lazzeri, N.; Billeci, L.; Igliozzi, R.; Mancini, A.; Ahluwalia, A.; Muratori, F.; Rossi, D. De";Development and evaluation of a social robot platform for therapy in autism;2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society;NA;NA;10.1109/IEMBS.2011.6091119;NA;People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred ”affective” state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training.;2011-08;2021-02-11T03:17:51Z;2021-02-11T03:17:51Z;NA;4515-4518;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1558-4615;NA;C:\Users\esben\Zotero\storage\PJA3WKC3\6091119.html;NA;NA;"Humans; medical robotics; Robotics; emotions; empathy; human-robot interaction; Humanoid robots; Face; interpersonal relationships; Human Robot Interaction; patient treatment; Androids; Autism; Autism Spectrum Disorders; autism therapy; Autistic Disorder; common life social situations; FACE humanoid robot; Human Machine Interaction; medical disorders; Protocols; psychologist; social interlocutor; social robot platform; social skills training; Variable speed drives";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
M9BKRFUH;journalArticle;2016;"Roudposhti, K. K.; Nunes, U.; Dias, J.";Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns;IEEE Transactions on Pattern Analysis and Machine Intelligence;NA;1939-3539;10.1109/TPAMI.2015.2496209;NA;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.;2016-08;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;1679-1691;NA;8;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence;NA;C:\Users\esben\Zotero\storage\JUG4F78V\7312488.html;NA;NA;"feature extraction; Humans; Movement; Algorithms; human-robot interaction; Human-robot interaction; behavioural sciences; Three-dimensional displays; Shape; Feature extraction; Analytical models; Bayes methods; Bayes Theorem; Bayesian approach; body motion-based features analysis; body motion-based patterns; DBN technique; frequency domain; Histograms; human behavior analysis; human movement analysis; human movement descriptor; IB; interpersonal behaviors; laban movement analysis; LMA; Models, Statistical; Motion; multilayer dynamic Bayesian network technique; pattern classification; Pattern Recognition, Automated; probabilistic social behavior analysis; Social Behavior; social context; social role; Social signal processing; SR";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
CVREQ6U6;conferencePaper;2010;"Mayer, C.; Sosnowski, S.; Kühnlenz, K.; Radig, B.";Towards robotic facial mimicry: System development and evaluation;19th International Symposium in Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598629;NA;We introduce a facial mimicry system, which combines facial expression analysis and synthesis on a robot, utilizing the facial action coding system. The activation of action units on a user's face is automatically extracted from a video stream and mapped to the robot, thus mirroring the facial expression. As a novel approach, a user study quantifies the congruence of the initial human facial expression with the robotic facial expression. The evaluation shows that the robotic facial expression is perceived to be close to the human facial expression, from which it is derived. This is a fundamental aspect for a mimicry system, providing a basis for future research on empathy and emotional closed loop control.;2010-09;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;198-203;NA;NA;NA;NA;NA;Towards robotic facial mimicry;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\WAERVZFR\5598629.html;NA;NA;"Humans; emotion recognition; Robots; Face; humanoid robots; face recognition; Face recognition; Feature extraction; emotional closed loop control; Eyelids; facial action coding system; facial expression analysis; robotic facial expression; robotic facial mimicry; video stream; video streaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;19th International Symposium in Robot and Human Interactive Communication;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
YSHVJH9T;conferencePaper;2015;"Rasool, Z.; Masuyama, N.; Islam, M. N.; Loo, C. K.";Empathic Interaction Using the Computational Emotion Model;2015 IEEE Symposium Series on Computational Intelligence;NA;NA;10.1109/SSCI.2015.26;NA;This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.;2015-12;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;109-116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\7Q3PX9SC\7376599.html;NA;NA;"Computational modeling; emotion recognition; human-robot interaction; Robots; Face; Face recognition; facial expression recognition; Shape; Mood; empathic response; Clustering algorithms; computational emotion model; computational emotional model; empathic appraisal stage; empathic expression stage; empathic interaction; empathy oriented human-robot interaction model; fuzzy logic; perception stage; pleasure-arousal scaling model; robot mood factor; robot personality; virtual facial expression simulator";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 IEEE Symposium Series on Computational Intelligence;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
KPNL3P73;conferencePaper;2010;"Mazzei, D.; Billeci, L.; Armato, A.; Lazzeri, N.; Cisternino, A.; Pioggia, G.; Igliozzi, R.; Muratori, F.; Ahluwalia, A.; Rossi, D. De";The FACE of autism;19th International Symposium in Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598683;NA;People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented.;2010-09;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;791-796;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\YBTZKIQR\5598683.html;NA;NA;"medical robotics; Medical treatment; autism; Humanoid robots; Face; humanoid robots; Robot sensing systems; patient treatment; humanoid robot; Androids; Autism; Variable speed drives; adaptive therapeutic platform; adaptive therapy; FACE; facial automation for conveying emotions; therapeutic ambient; wearable sensors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;19th International Symposium in Robot and Human Interactive Communication;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
RDBXJ2CA;journalArticle;2020;"Rafique, M.; Hassan, M. A.; Jaleel, A.; Khalid, H.; Bano, G.";A Computation Model for Learning Programming and Emotional Intelligence;IEEE Access;NA;2169-3536;10.1109/ACCESS.2020.3015533;NA;Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.;2020;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;149616-149629;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;Conference Name: IEEE Access;NA;"C:\Users\esben\Zotero\storage\J8HNML8U\Rafique et al. - 2020 - A Computation Model for Learning Programming and E.pdf; C:\Users\esben\Zotero\storage\UMGRXDVS\9163380.html";NA;NA;"Computational modeling; Education; cognition; Robots; Emotional intelligence; teaching; basic programming; cognitive skills; computational model; computational thinking; computer science education; early education; emotional intelligence skills; empathy emotions; fundamental programming constructs; kid emotional intelligence; logical thinking; programming; programming concepts; programming instructions; Programming profession; robots based learning; screen-free interface; screen-free student interface; self-awareness; Sequential analysis; social-awareness; teaching methods; Tools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
FAUQADH3;conferencePaper;2020;"Perusquía-Hernández, M.; Balda, M. C.; Jáuregui, D. A. Gómez; Paez-Granados, D.; Dollack, F.; Salazar, J. V.";Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User’s Physiological Affective States;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;10.1109/RO-MAN47096.2020.9223598;NA;Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.;2020-08;2021-02-11T03:18:13Z;2021-02-11T03:18:13Z;NA;1328-1333;NA;NA;NA;NA;NA;Robot Mirroring;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1944-9437;NA;C:\Users\esben\Zotero\storage\EGCC5BLL\9223598.html;NA;NA;"Visualization; physiology; feedback; Robots; embodiment; multi-agent systems; mobile robots; Robot sensing systems; control engineering computing; artificial agent; empathy and intersubjectivity; facial body cues; haptic feedback; haptic interfaces; Haptic interfaces; haptic interoceptive patterns; health care; Heart rate; heart-rate levels; human-machine interaction; integrated visuo-haptic representations; interoceptive feedback; Physiology; robot mirroring wearable systems; self-tracking feedback; users physiological affective states; Vibrations; visual feedback; visual representations; wearable pet; wearable prototype; wearable robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
8ELE8GDE;conferencePaper;2020;"Malik, P.; Gautam, S.; Srivastava, S.";A Study on Behaviour Intention for using Chatbots;2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO);NA;NA;10.1109/ICRITO48877.2020.9197782;NA;The present study uses the primary research to find out the behavior intention of an individual to use chatbots. The study has taken the five dimensions viz., reliability, responsiveness, assurance, empathy and tangibility and find out their association with behavior intention of an individual to use the chatbots. The sample of 270 respondents are taken to conclude the findings. It was concluded that out of these five dimensions, three dimensions are significantly associated with intention of using chatbots. These are reliability, empathy and tangibility.;2020-06;2021-02-11T03:35:05Z;2021-02-11T03:35:05Z;NA;332-338;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\KFP96LED\9197782.html;NA;NA;"Artificial intelligence; Task analysis; Empathy; empathy; Chatbots; chatbots; Organizations; human computer interaction; human factors; Assurance; behaviour intention; Behaviour Intention; Customer satisfaction; Internet; reliability; Reliability; Responsiveness; tangibility; Tangibility";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
7KCMLT52;conferencePaper;2019;"Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;10.1109/RITAPP.2019.8932852;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019-11;2021-02-11T03:35:05Z;2021-02-11T03:35:05Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\HBY89XII\8932852.html;NA;NA;"cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
KIUAFYUD;conferencePaper;2020;"Shin, J.; Xu, P.; Madotto, A.; Fung, P.";Generating Empathetic Responses by Looking Ahead the User’s Sentiment;ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);NA;NA;10.1109/ICASSP40776.2020.9054379;NA;An important aspect of human conversation difficult for machines is conversing with empathy, which is to understand the user's emotion and respond appropriately. Recent neural conversation models that attempted to generate empathetic responses either focused on conditioning the output to a given emotion, or incorporating the current user emotional state. However, these approaches do not factor in how the user would feel towards the generated response. Hence, in this paper, we propose Sentiment Look-ahead, which is a novel perspective for empathy that models the future user emotional state. In short, Sentiment Look-ahead is a reward function under a reinforcement learning framework that provides a higher reward to the generative model when the generated utterance improves the user's sentiment. We implement and evaluate three different possible implementations of sentiment look-ahead and empirically show that our proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning.;2020-05;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;7989-7993;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2379-190X;NA;C:\Users\esben\Zotero\storage\UHMQP6TS\9054379.html;NA;NA;"generative model; learning (artificial intelligence); empathy; emotion recognition; Dialogue Systems; Empathetic Chatbots; generated utterance; human conversation difficult; Natural Language Processing; recent neural conversation models; reinforcement learning framework; sentiment look-ahead; Sentiment Look-ahead; speech processing; user emotional state";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
8V3RT8SW;conferencePaper;2020;"Dixit, R.; Chinnam, R. B.; Singh, H.";Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations;2020 IEEE Aerospace Conference;NA;NA;10.1109/AERO47225.2020.9172612;NA;Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.;2020-03;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;1-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1095-323X;NA;C:\Users\esben\Zotero\storage\IB4HZZN2\9172612.html;NA;NA;"artificial intelligence; learning (artificial intelligence); ML; AI; neural nets; human intelligence; ample data; ample time; answer-key; artificial Intelligence techniques; cross-disciplinary decision engine; current research streams; data-rich situations; decision algorithms; decision making; defined decision-basis; experienced practitioners; informed decisions; logical formulations; logical outcome; machine Learning; neural techniques; operational decision scenarios; real-time decision making; sparse-data environments; strategic decision scenarios; successful training; sufficient learning; tactical, decision scenarios; typical implementations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 IEEE Aerospace Conference;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
A5X7X98D;conferencePaper;2019;"Das, A. K.; Ashrafi, A.; Ahmmad, M.";Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System;2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS);NA;NA;10.1109/CCOMS.2019.8821655;NA;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.;2019-02;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;36-40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\UZI6YCGQ\8821655.html;NA;NA;"learning (artificial intelligence); Task analysis; Decision making; cognition; Law; Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment; advanced artificial intelligence system; criminal punishment prediction; Forecasting; judicial system; law administration; Machine intelligence; machine learning algorithms; Machine learning algorithms; Predictive models; Women and Children Repression Prevention Act 2000";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
4YCJ8W38;conferencePaper;2019;"Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.";Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;NA;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.;2019-12;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;1564-1571;NA;NA;NA;NA;NA;Predicting Future Alleviation of Mental Illness in Social Media;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\Q2UZENB5\9047291.html;NA;NA;"learning (artificial intelligence); Big Data; data mining; psychology; decision making; Cloud computing; Distributed processing; dynamic feature-rich networks; Electromagnetic interference; empathic interactions identification; empathy-based social network perspective; Erbium; future alleviation prediction; human psychological characteristics; hybrid deep learning algorithm; information sources; machine learning detectors; mental illness; Social computing; social media posts; social media, mental illness, social network, deep learning, online empathy.; social networking (online); therapeutic decision making; time dynamics; time-aware social networks; user behaviour; users posts";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
9KMJXA67;conferencePaper;2007;"Rett, J.; Dias, J.";Human-robot interface with anticipatory characteristics based on Laban Movement Analysis and Bayesian models;2007 IEEE 10th International Conference on Rehabilitation Robotics;NA;NA;10.1109/ICORR.2007.4428436;NA;In this work we contribute to the field of human-machine interaction with a system that anticipates human movements using the concept of Laban Movement Analysis (LMA). The implementation uses a Bayesian model for learning and classification and results are presented for the application to online gesture recognition. The merging of assistive robotics and socially interactive robotics has recently led to the definition of socially assistive robotics. What is necessary and we found still missing are socially interactive robots with a higher level cognitive system which analyzes deeply the observed human movement. In this article we provide a framework for cognitive processes to be implemented in human-machine-interfaces based on nowadays technologies. We present LMA as a concept that helps to identify useful low-level features, defines a framework of mid-level descriptors for movement-properties and helps to develop a classifier of expressive actions. Our interface anticipates a performed action observed from a stream of monocular camera images by using a Bayesian framework. With this work we define the required qualities and characteristics of future embodied agents in terms of social interaction with humans. This article searches for human qualities like anticipation and empathy and presents possible ways towards implementation in the cognitive system of a social robot. We present results through its embodiment in the social robot 'Nicole' in the context of a person performing gestures and 'Nicole' reacting by means of audio output and robot movement.;2007-06;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;257-268;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 1945-7901;NA;C:\Users\esben\Zotero\storage\253W5PWM\4428436.html;NA;NA;"medical robotics; Rehabilitation robotics; Robot sensing systems; gesture recognition; Shape; Human robot interaction; Mobile robots; Bayes methods; anticipatory characteristics; audio output; Bayesian methods; Bayesian models; Cameras; Cognitive robotics; Face detection; human-robot interface; Laban movement analysis; Merging; monocular camera images; robot movement; robot Nicole";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2007 IEEE 10th International Conference on Rehabilitation Robotics;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
MHLE5UTL;conferencePaper;2015;"Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.";Real-time sociometrics from audio-visual features for two-person dialogs;2015 IEEE International Conference on Digital Signal Processing (DSP);NA;NA;10.1109/ICDSP.2015.7251991;NA;This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.;2015-07;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;823-827;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2165-3577;NA;C:\Users\esben\Zotero\storage\Q24CF4Y2\7251991.html;NA;NA;"feature extraction; learning (artificial intelligence); machine learning; Visualization; emotion recognition; Conferences; behavioural sciences; Speech; Feature extraction; Accuracy; audio-visual features; audio-visual recordings; audio-visual systems; audiovisual analysis; automatic inference; dialog; image recognition; machine learning algorithm; Microsoft kinect device; real time sociometrics; real-time; Real-time systems; Signal processing; social behavior analysis; social indicators; social sciences; sociometrics; speech cues; speech recognition; two person dialogs; visual cues";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2015 IEEE International Conference on Digital Signal Processing (DSP);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3PT2A366;conferencePaper;2020;"Nehra, V.; Nagpal, R.; Sehgal, R.";Collective Intelligence: When, Where and Why;2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence);NA;NA;10.1109/Confluence47617.2020.9058000;NA;The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.;2020-01;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;805-810;NA;NA;NA;NA;NA;Collective Intelligence;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\2X25LSI2\9058000.html;NA;NA;"artificial intelligence; learning (artificial intelligence); machine learning; Collective Intelligence; Aggregates; Artificial Intellegence; collective intelligence; Collective intelligence; Organizations; Particle swarm optimization; smart organization; Social network services; software agents; Standards organizations; Swarm Intelligence; virtual artificially intelligent agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
YUSKQ853;conferencePaper;2020;"Filho, L. A. D. Lusquino; Oliveira, L. F. R.; Carneiro, H. C. C.; Guarisa, G. P.; Filho, A. L.; França, F. M. G.; Lima, P. M. V.";A weightless regression system for predicting multi-modal empathy;2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020);NA;NA;10.1109/FG47880.2020.00086;NA;This work takes into account the benefits of machine learning in order to estimate the valence of emotions on the OMG Empathy dataset, considering the information obtained from face expressions and dialogue of interlocutors. RegressionWiSARD and ClusRegressionWiSARD n-tuple regressors and its ensembles were employed to this end. The best performance achieved among all the combinations of weightless neural models considered (evaluated using the CCC metric) was 0.25 in validation set of the Personalized Track.;2020-11;2021-02-11T03:37:19Z;2021-02-11T03:37:19Z;NA;657-661;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\MYT8Z9TA\9320218.html;NA;NA;"Computational modeling; Training; Predictive models; Videos; Bagging; empathy prediction; Mel frequency cepstral coefficient; Random access memory; regression wisard; weightless artificial neural network; wisard";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
BUUZC68R;conferencePaper;2019;"Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;10.1109/RITAPP.2019.8932852;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019-11;2021-02-11T03:38:02Z;2021-02-11T03:38:02Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\XLBJ99JY\8932852.html;NA;NA;"cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
VTDQURZT;conferencePaper;2019;"Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.";Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;NA;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.;2019-12;2021-02-11T03:38:02Z;2021-02-11T03:38:02Z;NA;1564-1571;NA;NA;NA;NA;NA;Predicting Future Alleviation of Mental Illness in Social Media;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\KB6VH64S\9047291.html;NA;NA;"learning (artificial intelligence); Big Data; data mining; psychology; decision making; Cloud computing; Distributed processing; dynamic feature-rich networks; Electromagnetic interference; empathic interactions identification; empathy-based social network perspective; Erbium; future alleviation prediction; human psychological characteristics; hybrid deep learning algorithm; information sources; machine learning detectors; mental illness; Social computing; social media posts; social media, mental illness, social network, deep learning, online empathy.; social networking (online); therapeutic decision making; time dynamics; time-aware social networks; user behaviour; users posts";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
J3REWPG2;conferencePaper;2018;"Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 International Joint Conference on Neural Networks (IJCNN);NA;NA;10.1109/IJCNN.2018.8489158;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018-07;2021-02-11T03:38:02Z;2021-02-11T03:38:02Z;NA;1-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2161-4407;NA;C:\Users\esben\Zotero\storage\H2PMJEZV\8489158.html;NA;NA;"learning (artificial intelligence); Neurons; emotion recognition; human-robot interaction; social robots; Adaptation models; Emotion recognition; humanoid robots; Robot sensing systems; face recognition; Mood; affective modulations; Convolution; deep hybrid neural model; empathy-driven emotion expressions; facial expression representations; interaction design; internal affective model; internal emotions; intrinsic affective states; multimodal affect recognition; natural interaction experience; neuro-inspired companion robot; neurocontrollers; NICO robot; reinforcement learning model; self-organising feature maps; self-organising network models";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3C3TY3KV;conferencePaper;2005;"Broadway, F. S.; Qammar, H. K.; Evans, E. A.; Spickard-Prettyman, S.";The use of reflective journals for student learning and development;Proceedings Frontiers in Education 35th Annual Conference;NA;NA;10.1109/FIE.2005.1612042;NA;For three years, undergraduate freshman through senior participants were required to submit a reflective journal each week during a design project. In our first implementation, we found that reflective journals were meaningful as assessment tools because they communicated how the participants learned. We show in this three-year study how subsequent use of reflective journaling leads to intellectual development on the part of one student. The form of this paper is a first-person autobiographical narrative of a third year (junior) student through which different and multiple identities and knowledge unfold. The authors of the study create a narrator based on knowledge, experiences, concepts, and ideas that a chemical engineering student constructed, reconstructed, and deconstructed in his journal entries. Through these stories, the student showed a deep understanding of teamwork, developed empathy and a sense of belonging, and demonstrated the ability to explain, interpret and apply chemical engineering content knowledge;2005-10;2021-02-11T03:38:02Z;2021-02-11T03:38:02Z;NA;F2C-13;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;ISSN: 2377-634X;NA;C:\Users\esben\Zotero\storage\P6G7DFXG\1612042.html;NA;NA;"project management; Educational institutions; design; Teamwork; Calculus; team working; Testing; Assimilative learning; Autobiographical narrative; chemical engineering; Chemical engineering; chemical engineering student; content knowledge; content management; design project; educational aids; Engineering profession; first-person autobiographical narrative; intellectual development; knowledge management; Project management; Reflective journal; reflective journals; student development; student learning; teamwork";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Proceedings Frontiers in Education 35th Annual Conference;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
VIBLHL73;journalArticle;2015;Runciman, B.;Bladerunner Begins;ITNOW;NA;1746-5710;10.1093/itnow/bwv086;NA;Without getting too tabloidy, Volume 27 Issue 4 of Interacting with Computers is looking at the emotion that played a key role in Philip K Dick’s Do Androids Dream of Electric Sheep - empathy. Brian Runciman MBCS reports.;2015-09;2021-02-11T03:39:00Z;2021-02-11T03:39:00Z;NA;65-65;NA;3;57;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;Conference Name: ITNOW;NA;C:\Users\esben\Zotero\storage\3EHI9B8L\8138959.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
3M6UDCJ3;conferencePaper;2018;"Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri";Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;10.1109/ICAITI.2018.8686759;NA;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.;2018-09;2021-02-11T03:39:00Z;2021-02-11T03:39:00Z;NA;208-212;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\CNYN5SYA\8686759.html;NA;NA;"handicapped aids; Mobile Robot; social interaction; psychology; mobile robots; Android; Android-based mobile robots; Asperger syndrome; Asperger Syndrome disorder; autistic disorder; data analysis; mobile computing; paediatrics; patient treatment; Pekanbaru children; play therapy; Rank Wilcoxon; robot control tool; smart phones; wheel-shaped robot; wheeled robot; wheels";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
UDJGURWP;conferencePaper;2016;"Ranieri, C. M.; Romero, R. A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR);NA;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016-10;2021-02-11T03:39:00Z;2021-02-11T03:39:00Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore;NA;NA;NA;C:\Users\esben\Zotero\storage\8XWF58QB\7783498.html;NA;NA;"Emotions; Affective computing; empathy; human-robot interaction; social robots; Robots; Social robots; control engineering computing; smart phones; Android application; embodied virtual agent; emotion-aware interaction strategy; emotional reactions; facial expressions analysis; human-robot interaction improvement; Mobile devices; pleasantness; virtual character";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Xplore
MJXKCLPJ;webpage;2016;"Jenkins, Ryan; Purves, Duncan";A Dilemma for Moral Deliberation in AI;International Journal of Applied Philosophy;NA;NA;NA;https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=ijap&id=ijap_2016_0030_0002_0313_0335;Many social trends are conspiring to drive the adoption of greater automation in society, and we will certainly see a greater offloading of human decisionmaking to robots in the future. Many of these decisions are morally salient, including decisions about how benefits and burdens are distributed. Roboticists and ethicists have begun to think carefully about the moral decision making apparatus for machines. Their concerns often center around the plausible claim that robots will lack many of the mental capacities that are indispensable in human moral decision making, such as empathy. To the extent that robots may be robustly artificially intelligent, these concerns subside, but they give way to new worries about creating artificial agents to do our bidding, if those artificial agents have moral standing. We suggest that the question of AI consciousness poses a dilemma. Whether artificially intelligent agents will be conscious or not, we will face serious difficulties in programming them to reliably make moral decisions.;17075;2021-02-10T15:31:36Z;2021-02-10T15:31:56Z;2021-02-10T15:31:36Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: 2 Pages: 313-335 Volume: 30 DOI: 10.5840/ijap201712375;NA;C:\Users\esben\Zotero\storage\CKY9LXQF\ijap_2016_0030_0002_0313_0335.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;PCBnet
VS3AUFHL;webpage;2015;Harvey, Charles;Sex Robots and Solipsism: Towards a Culture of Empty Contact;Philosophy in the Contemporary World;NA;NA;NA;https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=pcw&id=pcw_2015_0022_0002_0080_0093;NA;16709;2021-02-15T19:33:46Z;2021-02-15T19:33:50Z;2021-02-15T19:33:46Z;NA;NA;NA;NA;NA;NA;Sex Robots and Solipsism;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: 2 Pages: 80-93 Volume: 22 DOI: 10.5840/pcw201522216;NA;C:\Users\esben\Zotero\storage\KPZ6YVSB\pcw_2015_0022_0002_0080_0093.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;PCBnet
VBN6YTP6;webpage;2020;Gruenwald, Oskar;Taming the Digital Behemoth: Rethinking the Digital-Human Divide (Editorial);Journal of Interdisciplinary Studies;NA;NA;NA;https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=jis&id=jis_2020_0032_0001_0001_0016;This essay explores the digital challenge, how to humanize technology, and the need to rethink the digital-human divide. This is imperative in view of superintelligent Al, which may escape human control. The information age poses quandaries regarding the uses and abuses of technology. A major critique concerns the commercial design of digital technologies that engenders compulsive behavior. All technologies affect humans in a reciprocal way. The new digital technologies-from smartphones to the Internet—where humans are tethered to machines, can impair our autonomy, hijack attention, rewire the brain, and diminish concentration, empathy, knowledge, and wisdom. The remedy is to restore deep reading, human interactions, personal conversations, real friendships, and respect for autonomy and privacy, building a nurturing culture of tolerance, coupled with transcendent norms and ideals worthy of a creature created in the image and likeness of God. This aspiration should be at the center of a new interdisciplinary field of inquiry—a phenomenology of communications.;18590;2021-02-15T19:38:25Z;2021-02-15T19:38:25Z;2021-02-15T19:38:25Z;NA;NA;NA;NA;NA;NA;Taming the Digital Behemoth;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: 1/2 Pages: 1-16 Volume: 32 DOI: 10.5840/jis2020321/21;NA;C:\Users\esben\Zotero\storage\HYTGLTLF\jis_2020_0032_0001_0001_0016.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;PCBnet
JYXB7KXM;webpage;2015;Emerick, Barrett;Perceptual Failure and a Life of Moral Endeavor;Social Philosophy Today;NA;NA;NA;https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=socphiltoday&id=socphiltoday_2015_0031_0129_0139;Over the course of her career, Jean Harvey argued that as agents engaged in a “life of moral endeavor,” we should understand ourselves and others to be moral works in progress, always possessing the potential to grow beyond and become more than the sum of our past wrongs. In this paper I will follow Harvey and argue that in order to live a life of moral endeavor, it is not enough merely to know about injustice. Instead, we must engage in the difficult and often painful task of overcoming deep-seated cognitive biases that cause us to fail to perceive the ubiquitous injustice that pervades our world. I will conclude by arguing that education, empathy, and love can each help us to increase our perceptual awareness of injustice and so should be recognized to be crucial parts of a life of moral endeavor.;16617;2021-02-15T19:38:28Z;2021-02-15T19:38:28Z;2021-02-15T19:38:28Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Pages: 129-139 Volume: 31 DOI: 10.5840/socphiltoday20157619;NA;C:\Users\esben\Zotero\storage\UQ6XBZDF\socphiltoday_2015_0031_0129_0139.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;PCBnet
BP6ZKNXI;journalArticle;2020;"Barnett, Anthony; Savic, Michael; Pienaar, Kiran; Carter, Adrian; Warren, Narelle; Sandral, Emma; Manning, Victoria; Lubman, Dan I.";Enacting ‘more-than-human’ care: Clients’ and counsellors’ views on the multiple affordances of chatbots in alcohol and other drug counselling;International Journal of Drug Policy;NA;09553959;10.1016/j.drugpo.2020.102910;https://linkinghub.elsevier.com/retrieve/pii/S0955395920302498;Forms of artificial intelligence (AI), such as chatbots that provide automated online counselling, promise to revolutionise alcohol and other drug treatment. Although the replacement of human counsellors remains a speculative prospect, chatbots for ‘narrow AI’ tasks (e.g., assessment and referral) are increasingly being used to augment clinical practice. Little research has addressed the possibilities for care that chatbots may generate in the future, particularly in the context of alcohol and other drug counselling. To explore these issues, we draw on the concept of technological ‘affordances’ and identify the range of possibilities for care that emerging chatbot interventions may afford and foreclose depending on the contexts in which they are implemented. Our analysis is based on qualitative data from interviews with clients (n=20) and focus group discussions with counsellors (n=8) conducted as part of a larger study of an Australian online alcohol and other drug counselling service. Both clients and counsellors expressed a concern that chatbot interventions lacked a ‘human’ element, which they valued in empathic care encounters. Most clients reported that they would share less information with a chatbot than a human counsellor, and they viewed this as constraining care. However, clients and counsellors suggested that the use of narrow AI might afford possibilities for performing discrete tasks, such as screening, triage or referral. In the context of what we refer to as ‘more-than-human’ care, our findings reveal complex views about the types of affordances that chatbots may produce and foreclose in online care encounters. We conclude by discussing implications for the potential ‘addiction futures’ and care trajectories that AI technologies offer, focussing on how they might inform alcohol and other drug policy, and the design of digital healthcare.;2020-10;2021-02-15T21:44:16Z;2021-02-15T21:44:16Z;2021-02-15T21:44:16Z;102910;NA;NA;NA;NA;International Journal of Drug Policy;Enacting ‘more-than-human’ care;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\VWZHGT2F\Barnett et al. - 2020 - Enacting ‘more-than-human’ care Clients’ and coun.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
ZKHUVNYC;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Koike, Masato";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;Biologically Inspired Cognitive Architectures;NA;2212683X;10.1016/j.bica.2016.09.004;https://linkinghub.elsevier.com/retrieve/pii/S2212683X1630072X;"Companion or ‘pet’ robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots’ behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artiﬁcial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a crosscommunication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user’s expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like ‘emotion’ and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artiﬁcial consciousness based on the complexity level and a robot’s social expressions that are designed to enhance the users afﬁnity with the robot.";2016-10;2021-02-15T21:44:20Z;2021-02-15T21:44:20Z;2021-02-15T21:44:20Z;51-67;NA;NA;18;NA;Biologically Inspired Cognitive Architectures;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\E8NHB9UF\Chumkamon et al. - 2016 - Intelligent emotion and behavior based on topologi.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
WCQPQTJ8;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;Tourism Management;NA;02615177;10.1016/j.tourman.2019.104042;https://linkinghub.elsevier.com/retrieve/pii/S0261517719302407;Social robots have become pervasive in the tourism and hospitality service environments. The empirical un­ derstanding of the drivers of visitors’ intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations’ attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors’ intentions to use social robots in hospitality services. With data collected in Singapore’s hospitality settings, we found visitors’ intentions to use social robots stem from the effects of technology acceptance vari­ ables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions’ importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-02-15T21:44:27Z;2021-02-15T21:44:28Z;2021-02-15T21:44:27Z;104042;NA;NA;78;NA;Tourism Management;Leveraging human-robot interaction in hospitality services;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\KS2WFL6T\de Kervenoael et al. - 2020 - Leveraging human-robot interaction in hospitality .pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
KFE6Q38S;journalArticle;2017;"Stein, Jan-Philipp; Ohler, Peter";Venturing into the uncanny valley of mind—The influence of mind attribution on the acceptance of human-like characters in a virtual reality setting;Cognition;NA;00100277;10.1016/j.cognition.2016.12.010;https://linkinghub.elsevier.com/retrieve/pii/S0010027716303055;For more than 40 years, the uncanny valley model has captivated researchers from various ﬁelds of expertise. Still, explanations as to why slightly imperfect human-like characters can evoke feelings of eeriness remain the subject of controversy. Many experiments exploring the phenomenon have emphasized speciﬁc visual factors in connection to evolutionary psychological theories or an underlying categorization conﬂict. More recently, studies have also shifted away focus from the appearance of human-like entities, instead exploring their mental capabilities as basis for observers’ discomfort. In order to advance this perspective, we introduced 92 participants to a virtual reality (VR) chat program and presented them with two digital characters engaged in an emotional and empathic dialogue. Using the same prerecorded 3D scene, we manipulated the perceived control type of the depicted characters (humancontrolled avatars vs. computer-controlled agents), as well as their alleged level of autonomy (scripted vs. self-directed actions). Statistical analyses revealed that participants experienced signiﬁcantly stronger eeriness if they perceived the empathic characters to be autonomous artiﬁcial intelligences. As human likeness and attractiveness ratings did not result in signiﬁcant group differences, we present our results as evidence for an ‘‘uncanny valley of mind‘‘ that relies on the attribution of emotions and social cognition to non-human entities. A possible relationship to the philosophy of anthropocentrism and its ‘‘threat to human distinctiveness” concept is discussed.;2017-03;2021-02-15T21:44:31Z;2021-02-15T21:44:31Z;2021-02-15T21:44:31Z;43-50;NA;NA;160;NA;Cognition;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\IK2DKCQ4\Stein and Ohler - 2017 - Venturing into the uncanny valley of mind—The infl.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
TIS56CFR;journalArticle;2018;"Yalcin, Ӧzge Nilay; DiPaola, Steve";A computational model of empathy for interactive agents;Biologically Inspired Cognitive Architectures;NA;2212683X;10.1016/j.bica.2018.07.010;https://linkinghub.elsevier.com/retrieve/pii/S2212683X18300719;Empathy has been deﬁned in the scientiﬁc literature as the capacity to relate another’s emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to reﬁne the deﬁned functions of empathy to reach a working deﬁnition and a model of empathy. Recently, cognitive science and artiﬁcial intelligence communities made attempts to model empathy in artiﬁcial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artiﬁcial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various ﬁelds, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018-10;2021-02-15T21:44:35Z;2021-02-15T21:44:35Z;2021-02-15T21:44:35Z;20-25;NA;NA;26;NA;Biologically Inspired Cognitive Architectures;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\XWVHL9M5\Yalcin and DiPaola - 2018 - A computational model of empathy for interactive a.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
UNG4SEF2;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;Artificial Intelligence in Medicine;NA;09333657;10.1016/j.artmed.2019.101753;https://linkinghub.elsevier.com/retrieve/pii/S0933365719306505;Background: Futurists have predicted that new autonomous technologies, embedded with artiﬁcial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective: To characterize the global psychiatrist community’s opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design: Cross sectional, random stratiﬁed sample of psychiatrists registered with Sermo, a global networking platform open to veriﬁed and licensed physicians. Main outcome measures: We measured opinions about the likelihood that AI/ML tools would be able to fully replace – not just assist – the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist’s perceptions about whether beneﬁts of AI/ML would outweigh the risks. Results: Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Paciﬁc. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and USbased doctors were more uncertain that the beneﬁts of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions: Our ﬁndings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020-01;2021-02-15T21:44:38Z;2021-02-15T21:44:38Z;2021-02-15T21:44:38Z;101753;NA;NA;102;NA;Artificial Intelligence in Medicine;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\R4HF47EC\Doraiswamy et al. - 2020 - Artificial intelligence and the future of psychiat.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
HWTSL9E8;journalArticle;2020;"Aeschlimann, Sara; Bleiker, Marco; Wechner, Michael; Gampe, Anja";Communicative and social consequences of interactions with voice assistants;Computers in Human Behavior;NA;07475632;10.1016/j.chb.2020.106466;https://linkinghub.elsevier.com/retrieve/pii/S0747563220302181;The growing prevalence of artificial intelligence and digital media in children’s lives provides them with the opportunity to interact with novel non-human agents such as robots and voice assistants. Previous studies show that children eagerly adopt and interact with these technologies, but we have only limited evidence of children’s distinction between artificial intelligence and humans. In this study, the communication patterns and prosocial outcomes of interactions with voice assistants were investigated. Children between 5 and 6 years (N ¼ 72) of age solved a treasure hunt in either a human or voice assistant condition. During the treasure hunt, the interaction partner supplied information either about their knowledge of or experience with the objects. Afterwards, chil­ dren were administered a sharing task and a helping task. Results revealed that children provided voice assistants with less information than humans and that only the type of information given by a human interaction partner was related to children’s information selection. Sharing was influenced by an interaction between type of in­ formation and interaction partner, showing that the type of information shared influenced children’s decisions more when interacting with a human, but less when interacting with a voice assistant. Children in all conditions enjoyed the treasure hunt with the interaction partner. Overall, these results suggest that children do not impose the same expectations on voice assistants as they do on humans. Consequently, cooperation between humans and cooperation between humans and computers differ.;2020-11;2021-02-15T21:44:44Z;2021-02-15T21:44:44Z;2021-02-15T21:44:44Z;106466;NA;NA;112;NA;Computers in Human Behavior;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\38SIT63H\Aeschlimann et al. - 2020 - Communicative and social consequences of interacti.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
MFZ4QQIH;journalArticle;2019;"Lee, Yeonjoo; Ha, Miyeon; Kwon, Sujeong; Shim, Yealin; Kim, Jinwoo";Egoistic and altruistic motivation: How to induce users’ willingness to help for imperfect AI;Computers in Human Behavior;NA;07475632;10.1016/j.chb.2019.06.009;https://linkinghub.elsevier.com/retrieve/pii/S0747563219302274;Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI.;2019-12;2021-02-15T21:44:48Z;2021-02-15T21:44:48Z;2021-02-15T21:44:48Z;180-196;NA;NA;101;NA;Computers in Human Behavior;Egoistic and altruistic motivation;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\986766G3\Lee et al. - 2019 - Egoistic and altruistic motivation How to induce .pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
3MASWSQF;journalArticle;2020;"Aeschlimann, Sara; Bleiker, Marco; Wechner, Michael; Gampe, Anja";Communicative and social consequences of interactions with voice assistants;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2020.106466;https://www.sciencedirect.com/science/article/pii/S0747563220302181;The growing prevalence of artificial intelligence and digital media in children’s lives provides them with the opportunity to interact with novel non-human agents such as robots and voice assistants. Previous studies show that children eagerly adopt and interact with these technologies, but we have only limited evidence of children’s distinction between artificial intelligence and humans. In this study, the communication patterns and prosocial outcomes of interactions with voice assistants were investigated. Children between 5 and 6 years (N = 72) of age solved a treasure hunt in either a human or voice assistant condition. During the treasure hunt, the interaction partner supplied information either about their knowledge of or experience with the objects. Afterwards, children were administered a sharing task and a helping task. Results revealed that children provided voice assistants with less information than humans and that only the type of information given by a human interaction partner was related to children’s information selection. Sharing was influenced by an interaction between type of information and interaction partner, showing that the type of information shared influenced children’s decisions more when interacting with a human, but less when interacting with a voice assistant. Children in all conditions enjoyed the treasure hunt with the interaction partner. Overall, these results suggest that children do not impose the same expectations on voice assistants as they do on humans. Consequently, cooperation between humans and cooperation between humans and computers differ.;2020;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;106466;NA;NA;112;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;C:\Users\esben\Zotero\storage\32ZPR8GH\Aeschlimann et al. - 2020 - Communicative and social consequences of interacti.pdf;NA;"Communication; Artificial intelligence; Cooperation; Social; Voice assistants";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
BQAY5LI2;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Koike, Masato";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;Biologically Inspired Cognitive Architectures;NA;2212-683X;https://doi.org/10.1016/j.bica.2016.09.004;https://www.sciencedirect.com/science/article/pii/S2212683X1630072X;"Companion or ‘pet’ robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots’ behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross-communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user’s expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like ‘emotion’ and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot’s social expressions that are designed to enhance the users affinity with the robot.";2016;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;51-67;NA;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Behavior; Human-robot interaction; Emotional intelligence; Companion robot; Consciousness based architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
QUQXYKXU;journalArticle;2011;"Trappl, Robert; Krajewski, Markus; Ruttkay, Zsófia; Widrich, Virgil";Robots as Companions: What can we Learn from Servants and Companions in Literature, Theater, and Film?;Procedia Computer Science;NA;1877-0509;https://doi.org/10.1016/j.procs.2011.12.029;https://www.sciencedirect.com/science/article/pii/S1877050911006946;Many researchers are working on developing robots into adequate partners, be it at the working place, be it at home or in leisure activities, or enabling elder persons to lead a self-determined, independent life. While quite some progress has been made in e.g. speech or emotion understanding, processing and expressing, the relations between humans and robots are usually only short-term. In order to build long-term, i.e. social relations, qualities like empathy, trust building, dependability, non-patronizing, and others will be required. But these are just terms and as such no adequate starting points to “program” these capacities even more how to avoid the problems and pitfalls in interactions between humans and robots. However, a rich source for doing this is available, unused until now for this purpose: artistic productions, namely literature, theater plays, not to forget operas, and films with their multitude of examples. Poets, writers, dramatists, screen-writers, etc. have studied for centuries the facets of interactions between persons, their dynamics, and the related snags. And since we wish for human-robot relations as master-servant relations - the human obviously being the master - the study of these relations will be prominent. A procedure is proposed, with four consecutive steps, namely Selection, Analysis, Categorization, and Integration. Only if we succeed in developing robots which are seen as servants we will be successful in supporting and helping humans through robots.;2011;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;96-98;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)</p>;C:\Users\esben\Zotero\storage\NVAPKYM5\Trappl et al. - 2011 - Robots as Companions What can we Learn from Serva.pdf;NA;"robots; companions; film; literature; servants; theater";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
9GU6IVJZ;journalArticle;2010;"Looije, Rosemarijn; Neerincx, Mark A.; Cnossen, Fokie";Persuasive robotic assistant for health self-management of older adults: Design and evaluation of social behaviors;International Journal of Human-Computer Studies;NA;1071-5819;https://doi.org/10.1016/j.ijhcs.2009.08.007;https://www.sciencedirect.com/science/article/pii/S107158190900113X;"Daily health self-management, such as the harmonization of food, exercise and medication, is a major problem for a large group of older adults with obesity or diabetics. Computer-based personal assistance can help to behave healthy by persuading and guiding older adults. For effective persuasion, the assistant should express social behaviors (e.g., turn taking, emotional expressions) to be trustworthy and show empathy. From the motivational interviewing method and synthetic assistants’ literature, we derived a set of social behaviors, and implemented a subset in a physical character, a virtual character and a text interface. The first behavior type concerns conversing with high-level dialogue (semantics, intentions), which could be implemented in all 3 assistants. The other behavior types could only be implemented in the characters: showing natural cues (e.g., gaze, posture), expressing emotions (e.g., compassionate face), and accommodating social conversations (e.g., turn taking). In an experiment, 24 older adults (45–65) interacted with the text interface and one of the characters, conform a “one-week diabetics scenario”. They experienced the virtual and physical character as more empathic and trustworthy than the text-based assistant, and expressed more conversational behavior with the characters. However, it seems that the preference of interacting with the character or the text interface was influenced by the conscientiousness of the participant; more conscientious people liked the text interface better. Older adults responded more negative to the characters that lacked the social behaviors than to the text interface. Some differences between the virtual and physical character probably occurred due to the specific constraints of the physical character.";2010;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;386-397;NA;6;68;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Human-Computer Interaction for Medicine and Health care (HCI4MED): Towards making Information usable</p>;NA;NA;"Health-care; Persuasive computing; Human–robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
LZTLJ8JR;journalArticle;2012;"Anelli, Filomena; Borghi, Anna M.; Nicoletti, Roberto";Grasping the pain: Motor resonance with dangerous affordances;Consciousness and Cognition;NA;1053-8100;https://doi.org/10.1016/j.concog.2012.09.001;https://www.sciencedirect.com/science/article/pii/S1053810012001961;"Two experiments, one on school-aged children and one on adults, explored the mechanisms underlying responses to an image prime (hand vs. control object) followed by graspable objects that were, in certain cases, dangerous. Participants were presented with different primes (a male, a female and a robotic grasping-hand; a male and a female static-hand; a control stimulus) and objects representing two risk levels (neutral and dangerous). The task required that a natural/artifact categorization task be performed by pressing different keys. In both adults and children graspable objects activated a facilitating motor response, while dangerous objects evoked aversive affordances, generating an interference-effect. Both children and adults were sensitive to the distinction between biological and non-biological hands, however detailed resonant mechanisms related to the hand-prime gender emerged only in adults. Implications for how the concept of “dangerous object” develops and the relationship between resonant mechanisms and perception of danger are discussed.";2012;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;1627-1639;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Affordances; Dangerous objects; Motor resonance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
XWL9Y67Z;journalArticle;2020;"Kervenoael, Ronan de; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;Tourism Management;NA;0261-5177;https://doi.org/10.1016/j.tourman.2019.104042;https://www.sciencedirect.com/science/article/pii/S0261517719302407;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;104042;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
H7A7NXXC;journalArticle;2014;"Stahl, Bernd Carsten; McBride, Neil; Wakunuma, Kutoma; Flick, Catherine";The empathic care robot: A prototype of responsible research and innovation;Technological Forecasting and Social Change;NA;0040-1625;https://doi.org/10.1016/j.techfore.2013.08.001;https://www.sciencedirect.com/science/article/pii/S0040162513001698;Science fiction prototypes are often used to visualise or represent novel technologies or other techno-scientific innovations. The present paper follows this tradition and describes a prototype of a care robot that is endowed with affective capabilities. The paper describes some of the potential ethical problems arising from such a technology. This aspect of the paper is based on prior research in a European-funded technology foresight project that explored the ethical issues of emerging ICTs. The paper goes beyond the description of technical innovation and its ethical consequences. The recognition of the ethical relevance of research and innovation has spawned a discourse around responsible research and innovation. The paper draws on this discourse, which aims at anticipatory technology governance to ensure the social acceptability and desirability of technologies. The prototype vignette of the paper explores how responsible research and innovation could be realised in practice and how it could be used to address ethical issues such as those of affective care robots. The paper reflects the likely controversies that responsible research and innovation is likely to create and it uses the ethical dilemma of the care robot to draw the reader's attention to possible theoretical and practical conclusions.;2014;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;74-85;NA;NA;84;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Robotics; Ethics; Creative prototyping; Emerging technology; ICT; Responsible research and innovation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
NM8U6CEJ;journalArticle;2016;"Mazzei, Daniele; Maria, Carmelo De; Vozzi, Giovanni";Touch sensor for social robots and interactive objects affective interaction;Sensors and Actuators A: Physical;NA;0924-4247;https://doi.org/10.1016/j.sna.2016.10.006;https://www.sciencedirect.com/science/article/pii/S0924424716306331;The recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human–robot affective interaction. Most of these sensors, implemented as matrix of pressure sensors, are rigid, cannot be fabricated in complex shapes, cannot be subjected to large deformations, and usually allow to capture only the contact event, without any information about the interaction context. This paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns. The sensor is made of alternate layers of sensitive and insulating silicone: the soft nature of the sensor makes it adaptable to complex and deformable bodies. The main features from electrical signals are extracted with the principal component analysis, and a self-organising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture. The results open to interesting applications, which span from toy manufacturing, to human-robot interaction, and even to sport and biomedical equipment and applications.;2016;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;92-99;NA;NA;251;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;C:\Users\esben\Zotero\storage\BF5SE7J7\Mazzei et al. - 2016 - Touch sensor for social robots and interactive obj.pdf;NA;"Affective robotics; Flexible silicone sensor; Tactile interaction; Touch sensor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
V268ENES;journalArticle;2021;"Chang, Wenwen; Wang, Hong; Yan, Guanghui; Lu, Zhiguo; Liu, Chong; Hua, Chengcheng";EEG based functional connectivity analysis of human pain empathy towards humans and robots;Neuropsychologia;NA;0028-3932;https://doi.org/10.1016/j.neuropsychologia.2020.107695;https://www.sciencedirect.com/science/article/pii/S0028393220303675;Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots.;2021;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;107695;NA;NA;151;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"EEG; Functional connectivity; Empathy; Human-robot interaction; Empathy index; Mutual information";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
4BRRSXXS;journalArticle;2010;"Severson, Rachel L.; Carlson, Stephanie M.";Behaving as or behaving as if? Children’s conceptions of personified robots and the emergence of a new ontological category;Neural Networks;NA;0893-6080;https://doi.org/10.1016/j.neunet.2010.08.014;https://www.sciencedirect.com/science/article/pii/S0893608010001656;Imagining another’s perspective is an achievement in social cognition and underlies empathic concern and moral regard. Imagination is also within the realm of fantasy, and may take the form of imaginary play in children and imaginative production in adults. Yet, an interesting and provocative question emerges in the case of personified robots: How do people conceive of life-like robots? Do people imagine about robots’ experiences? If so, do these imaginings reflect their actual or pretend beliefs about robots? The answers to these questions bear on the possibility that personified robots represent the emergence of a new ontological category. We draw on simulation theory as a framework for imagining others’ internal states as well as a means for imaginative play. We then turn to the literature on people’s and, in particular, children’s conceptions of personified technologies and raise the question of the veracity of children’s beliefs about personified robots (i.e., are they behaving as or behaving as if?). Finally, we consider the suggestion that such personified technologies represent the emergence of a new ontological category and offer some suggestions for future research in this important emerging area of social cognition.;2010;2021-02-15T21:45:52Z;2021-02-15T21:45:52Z;NA;1099-1103;NA;8;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Social Cognition: From Babies to Robots</p>;NA;NA;"Robots; Children; Ontological category; Pretense; Simulation theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
M6U8GFHM;journalArticle;2013;"Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Martinho, Carlos; Prada, Rui; Paiva, Ana";The influence of empathy in human–robot relations;International Journal of Human-Computer Studies;NA;1071-5819;https://doi.org/10.1016/j.ijhcs.2012.09.005;https://www.sciencedirect.com/science/article/pii/S1071581912001681;The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human–robot interaction.;2013;2021-02-15T21:45:53Z;2021-02-15T21:45:53Z;NA;250-260;NA;3;71;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;C:\Users\esben\Zotero\storage\T695PACG\Leite et al. - 2013 - The influence of empathy in human–robot relations.pdf;NA;"Empathy; Social robots; Affective interactions; Artificial companions; Friendship";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
MMUHFSDL;journalArticle;2015;Nijholt, Anton;Designing Humor for Playable Cities;Procedia Manufacturing;NA;2351-9789;https://doi.org/10.1016/j.promfg.2015.07.358;https://www.sciencedirect.com/science/article/pii/S2351978915003595;Smartness, made possible by intelligent sensors and actuators, is invading our home, office and public environments. This smartness monitors, anticipates and supports our activities, increasing efficiency of our activities. Smartness is usually associated with efficiency, but it also allows environments, virtual humans and social robots to display emotions, empathy and provide environments to introduce and support humorous events. We review examples of playful and humorous street furniture in ‘playable’ cities and projects that allow residents and visitors to interact with objects and environments in playful and humorous ways. We add observations on humor theory, in particular observations that deal with physical, visual and multimodal humor. Our emphasis is on introducing incongruities and on exploring different forms of incongruities in order to introduce humorous situations. Inventories of incongruities are explored. These inventories have been obtained from observing humor in everyday situations, in comedies, in movies, and in TV commercials. Shortcomings of these inventories from the point of view of multimodal and interaction humor are discussed and some preliminary views on additional approaches are provided.;2015;2021-02-15T21:45:53Z;2021-02-15T21:45:53Z;NA;2175-2182;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015</p>;C:\Users\esben\Zotero\storage\ZWF4NI8A\Nijholt - 2015 - Designing Humor for Playable Cities.pdf;NA;"Human-computer interaction; Computational humor; Incongruities; Playable cities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
WRJQJ2TN;journalArticle;2015;"Balint, Tibor S.; Hall, Ashley";Humanly space objects—Perception and connection with the observer;Acta Astronautica;NA;0094-5765;https://doi.org/10.1016/j.actaastro.2015.01.010;https://www.sciencedirect.com/science/article/pii/S0094576515000144;Expanding humanity into space is an inevitable step in our quest to explore our world. Yet space exploration is costly, and the awaiting environment challenges us with extreme cold, heat, vacuum and radiation, unlike anything encountered on Earth. Thus, the few pioneers who experience it needed to be well protected throughout their spaceflight. The resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life. Such connections may occur via sensory inputs, namely vision, touch, sound, smell, and taste. This then follows the process of sensing, interpreting, and recognizing familiar patterns, or learning from new experiences. The desire to connect could even transfer to observed objects, if their movements and characteristics trigger the appropriate desires from the observer. When ordered in a familiar way, for example visual stimuli from lights and movements of an object, it may create a perceived real bond with an observer, and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable. These behavior patterns can be designed into an object and performed autonomously in front of an observer, in our case an astronaut. The experience may introduce multiple responses, including communication, connection, empathy, order, and disorder. While emotions are clearly evoked in the observer and may seem one sided, in effect the object itself provides a decoupled bond, connectivity and communication between the observer and the artist-designer of the object. In this paper we will discuss examples from the field of arts and other domains, including robotics, where human perception through object interaction was explored, and investigate the starting point for new innovative design concepts and future prototype designs, that extend these experiences beyond the boundaries of Earth, while taking advantage of remoteness and the zero gravity environment. Through a form of emotional connection and design, these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a co-located observer in spaceflight. We conclude that beyond providing creative expressions for humanly contacts, these experiences may also provide further insights into human perception in spaceflight, and could be tested on the International Space Station, and serve as a stepping-stone towards use on long-duration spaceflight to Mars.;2015;2021-02-15T21:45:53Z;2021-02-15T21:45:53Z;NA;129-144;NA;NA;110;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Dynamics and Control of Space Systems</p>;C:\Users\esben\Zotero\storage\BDGGBX84\Balint and Hall - 2015 - Humanly space objects—Perception and connection wi.pdf;NA;"Perception; Cognition; Affordances; Design; Art; Cybernetics; Tacit-knowledge";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
GY56FLIS;journalArticle;2014;"Pütten, Astrid M. Rosenthal-von der; Schulte, Frank P.; Eimler, Sabrina C.; Sobieraj, Sabrina; Hoffmann, Laura; Maderwald, Stefan; Brand, Matthias; Krämer, Nicole C.";Investigations on empathy towards humans and robots using fMRI;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2014.01.004;https://www.sciencedirect.com/science/article/pii/S0747563214000090;Although robots are starting to enter into our professional and private lives, little is known about the emotional effects they elicit. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots, we conducted a study that provides further insights into the question of whether humans show emotional reactions towards a robot and whether these reactions differ from those towards a human. To explore emotionality in human–robot interaction we conducted an fMRI study (n=14). Participants were presented videos showing a human, a robot and an inanimate object, being treated in either an affectionate or in a violent way. Self-reported emotional states and functional imaging data revealed that participants indeed reacted emotionally when seeing the affectionate and violent videos. While no different neural activation patterns emerged for the affectionate interaction towards both, the robot and the human, we found differences in neural activity when comparing only the videos showing abusive behavior indicating that participants experience more emotional distress and show negative empathetic concern for the human in the abuse condition. This was supported by similar findings with regard to participant’s self-reported emotional states.;2014;2021-02-15T21:45:53Z;2021-02-15T21:45:53Z;NA;201-212;NA;NA;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Functional magnetic resonance imaging; Empathy; Experimental study; Psychophysiological measures; Human–robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
INEZ6HT2;journalArticle;2020;"Ionta, Silvio; Costantini, Marcello; Ferretti, Antonio; Galati, Gaspare; Romani, Gian Luca; Aglioti, Salvatore M.";Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain;Cortex;NA;0010-9452;https://doi.org/10.1016/j.cortex.2020.09.028;https://www.sciencedirect.com/science/article/pii/S0010945220303737;Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by low- and high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively.;2020;2021-02-15T21:45:53Z;2021-02-15T21:45:53Z;NA;295-308;NA;NA;133;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"fMRI; Empathy; Pain; Affective; Sensorimotor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
988I9E8G;journalArticle;2020;"Barnett, Anthony; Savic, Michael; Pienaar, Kiran; Carter, Adrian; Warren, Narelle; Sandral, Emma; Manning, Victoria; Lubman, Dan I.";Enacting ‘more-than-human’ care: Clients’ and counsellors’ views on the multiple affordances of chatbots in alcohol and other drug counselling;International Journal of Drug Policy;NA;09553959;10.1016/j.drugpo.2020.102910;https://linkinghub.elsevier.com/retrieve/pii/S0955395920302498;Forms of artificial intelligence (AI), such as chatbots that provide automated online counselling, promise to revolutionise alcohol and other drug treatment. Although the replacement of human counsellors remains a speculative prospect, chatbots for ‘narrow AI’ tasks (e.g., assessment and referral) are increasingly being used to augment clinical practice. Little research has addressed the possibilities for care that chatbots may generate in the future, particularly in the context of alcohol and other drug counselling. To explore these issues, we draw on the concept of technological ‘affordances’ and identify the range of possibilities for care that emerging chatbot interventions may afford and foreclose depending on the contexts in which they are implemented. Our analysis is based on qualitative data from interviews with clients (n=20) and focus group discussions with counsellors (n=8) conducted as part of a larger study of an Australian online alcohol and other drug counselling service. Both clients and counsellors expressed a concern that chatbot interventions lacked a ‘human’ element, which they valued in empathic care encounters. Most clients reported that they would share less information with a chatbot than a human counsellor, and they viewed this as constraining care. However, clients and counsellors suggested that the use of narrow AI might afford possibilities for performing discrete tasks, such as screening, triage or referral. In the context of what we refer to as ‘more-than-human’ care, our findings reveal complex views about the types of affordances that chatbots may produce and foreclose in online care encounters. We conclude by discussing implications for the potential ‘addiction futures’ and care trajectories that AI technologies offer, focussing on how they might inform alcohol and other drug policy, and the design of digital healthcare.;2020-10;2021-02-15T21:48:48Z;2021-02-15T21:48:48Z;2021-02-15T21:48:48Z;102910;NA;NA;NA;NA;International Journal of Drug Policy;Enacting ‘more-than-human’ care;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\VBFNEFR8\Barnett et al. - 2020 - Enacting ‘more-than-human’ care Clients’ and coun.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
2W85QYR4;journalArticle;2017;"Karamshuk, Dmytro; Shaw, Frances; Brownlie, Julie; Sastry, Nishanth";Bridging big data and qualitative methods in the social sciences: A case study of Twitter responses to high profile deaths by suicide;Online Social Networks and Media;NA;2468-6964;https://doi.org/10.1016/j.osnem.2017.01.002;https://www.sciencedirect.com/science/article/pii/S2468696416300076;With the rise of social media, a vast amount of new primary research material has become available to social scientists, but the sheer volume and variety of this make it difficult to access through the traditional approaches: close reading and nuanced interpretations of manual qualitative coding and analysis. This paper sets out to bridge the gap by developing semi-automated replacements for manual coding through a mixture of crowdsourcing and machine learning, seeded by the development of a careful manual coding scheme from a small sample of data. To show the promise of this approach, we attempt to create a nuanced categorisation of responses on Twitter to several recent high profile deaths by suicide. Through these, we show that it is possible to code automatically across a large dataset to a high degree of accuracy (71%), and discuss the broader possibilities and pitfalls of using Big Data methods for Social Science.;2017;2021-02-15T21:49:29Z;2021-02-15T21:49:29Z;NA;33-43;NA;NA;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Natural language processing; Crowd-sourcing; Crowdflower; Emotional distress; High-profile suicides; Public empathy; Social media; Social science";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
RWV477TJ;journalArticle;2018;"Bogatyreva, Anastasia A.; Sovkov, Andrei D.; Tikhomirova, Svetlana A.; Vinogradova, Anna R.; Samsonovich, Alexei V.";Virtual pet powered by a socially-emotional BICA;Procedia Computer Science;NA;1877-0509;https://doi.org/10.1016/j.procs.2018.11.101;https://www.sciencedirect.com/science/article/pii/S1877050918323895;Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents.;2018;2021-02-15T21:49:29Z;2021-02-15T21:49:29Z;NA;564-571;NA;NA;145;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic</p>;NA;NA;"emotional intelligence; virtual character; cognitive architecture; reinforcement learning; semantic space";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
37VH3W2F;journalArticle;2021;"Park, Jihyun; Jindal, Abhishek; Kuo, Patty; Tanana, Michael; Lafata, Jennifer Elston; Tai-Seale, Ming; Atkins, David C.; Imel, Zac E.; Smyth, Padhraic";Automated rating of patient and physician emotion in primary care visits;Patient Education and Counseling;NA;0738-3991;https://doi.org/10.1016/j.pec.2021.01.004;https://www.sciencedirect.com/science/article/pii/S0738399121000045;Objective Train machine learning models that automatically predict emotional valence of patient and physician in primary care visits. Methods Using transcripts from 353 primary care office visits with 350 patients and 84 physicians (Cook, 2002 [1], Tai-Seale et al., 2015 [2]), we developed two machine learning models (a recurrent neural network with a hierarchical structure and a logistic regression classifier) to recognize the emotional valence (positive, negative, neutral) (Posner et al., 2005 [3]) of each utterance. We examined the agreement of human-generated ratings of emotional valence with machine learning model ratings of emotion. Results The agreement of emotion ratings from the recurrent neural network model with human ratings was comparable to that of human-human inter-rater agreement. The weighted-average of the correlation coefficients for the recurrent neural network model with human raters was 0.60, and the human rater agreement was also 0.60. Conclusions The recurrent neural network model predicted the emotional valence of patients and physicians in primary care visits with similar reliability as human raters. Practice implications As the first machine learning-based evaluation of emotion recognition in primary care visit conversations, our work provides valuable baselines for future applications that might help monitor patient emotional signals, supporting physicians in empathic communication, or examining the role of emotion in patient-centered care.;2021;2021-02-15T21:49:29Z;2021-02-15T21:49:29Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Machine learning; Sentiment analysis; Natural language processing; Doctor-patient communication; Doctor-patient conversation; Emotion classification; Patient-physician communication; Primary care visit";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
VBBBA2FU;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;Artificial Intelligence in Medicine;NA;0933-3657;https://doi.org/10.1016/j.artmed.2019.101753;https://www.sciencedirect.com/science/article/pii/S0933365719306505;Background Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective To characterize the global psychiatrist community’s opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures We measured opinions about the likelihood that AI/ML tools would be able to fully replace – not just assist – the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist’s perceptions about whether benefits of AI/ML would outweigh the risks. Results Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020;2021-02-15T21:49:29Z;2021-02-15T21:49:29Z;NA;101753;NA;NA;102;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Deep learning; Empathy; Autonomous agents; Mental health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
2L5BCMVA;journalArticle;2012;"Roxburgh, Michelle; Conlon, Margaret; Banks, Debbie";Evaluating Hub and Spoke models of practice learning in Scotland, UK: A multiple case study approach;Nurse Education Today;NA;0260-6917;https://doi.org/10.1016/j.nedt.2012.05.004;https://www.sciencedirect.com/science/article/pii/S0260691712001347;"Summary Background Most of UK students' practice learning experience is based on a rotational placement model which often leads to students lacking confidence and feeling anxious about the complexities of the care environment. Objectives To evaluate the impact of Hub and Spoke model(s) of clinical practice placement across geographically diverse locations, with a particular focus on enhancing the student practice learning experience. Design Multiple case study design. Setting & Participants Comprised undergraduate student nurses from Adult, Learning Disability and Mental Health programmes from 3 Scottish Schools of Nursing. Methods A mixed methods approach which included quantitative and qualitative date tools. Results All three Hub and Spoke models shared two broad findings:1)In the three Hub and Spoke models detailed in this paper, there is a continuum of student led learning which supports the process with opportunities for individual students to be positively innovative and creative in their learning approaches. Depth of learning was achieved in two ways; a) the method in which Hub placements are organised, managed and structured and, b) the depth of empathy and sensitivity to the individual at the centre of the care.2)Placement capacity is increased: The classification of placements is reviewed to produce broader categories, Engagement of mentors/enhanced student/mentor relationship. Conclusions Practice Learning must be seen as an academic endeavour that promotes deep, meaningful, person-centred learning rather than superficial, compartmentalised placement-centred learning.";2012;2021-02-15T21:49:58Z;2021-02-15T21:49:58Z;NA;782-789;NA;7;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Selected papers from NET2011: The 22nd International Networking for Healthcare Education Conference, 6-8 September, 2011, Cambridge, UK</p>;NA;NA;"Belongingness; Learning environments; Practice Learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
NHJIJEKL;journalArticle;2019;"Petty, Julia; Jarvis, Joy; Thomas, Rebecca";Listening to the parent voice to inform person-centred neonatal care;Journal of Neonatal Nursing;NA;1355-1841;https://doi.org/10.1016/j.jnn.2019.01.005;https://www.sciencedirect.com/science/article/pii/S1355184118302138;"Family integrated care (FIC), where parents are an integral part of their baby's care and decision-making can enhance parental involvement and empowerment, contributing to decreased parental separation and stress. It follows that parents can also be a central part of neonatal education for staff in the neonatal speciality. This paper focuses on what students and staff can learn from parents about what they feel is important to make their experience better. A narrative, interpretive approach was undertaken to collect and analyse parent interview narratives. A specific question was posed to a purposive sample of parents who have had premature babies about what health professionals can learn from them. Thematic analysis revealed five key themes relating to the importance of: communicating; listening; empathising; acknowledging (the parent's role); realising (what matters to parents). These elements were incorporated into a framework named by the mnemonic, ‘CLEAR’. This highlights what parents want staff to be cognisant of when caring for them and their babies. Learning from the parents in our care enables a greater understanding of their experiences at difficult and challenging times. Having a deeper understanding of parents' experiences can contribute to enhanced empathic learning.";2019;2021-02-15T21:49:58Z;2021-02-15T21:49:58Z;NA;121-126;NA;3;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Family-integrated learning; Narrative inquiry; Neonatal education; Parent experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
8ALUT64Z;journalArticle;2014;"Stone, Teresa E.; Levett-Jones, Tracy";A comparison of three types of stimulus material in undergraduate mental health nursing education;Nurse Education Today;NA;0260-6917;https://doi.org/10.1016/j.nedt.2013.07.014;https://www.sciencedirect.com/science/article/pii/S0260691713002657;"Summary Aims and objectives The paper discusses an innovative educational approach that compared the use of different textual forms as stimulus materials in the teaching of an introductory mental health course. Background Practitioners in many disciplines, including nursing, appreciate the value of narratives in making sense of experiences, challenging assumptions and enhancing learning: they enable exploration of reality from different perspectives and create an emotional resonance. Narratives help nursing students to uncover embedded meanings, values and beliefs; they can include written texts, illustrated texts or picture books. Participants 180 students enrolled in an elective undergraduate nursing course. Method This project afforded students the choice of critically analysing (a) a chapter from one of two autobiographies, (b) an illustrated text, or (c) an illustration from a picture book. Each text was a narrative account from a personal or carer's perspective of the experience of mental illness. Their written submissions were then analysed by means of a qualitative descriptive approach. Results In analysis of the autobiographies students tended to paraphrase the authors' words and summarise their experiences. Those choosing the illustrated text were able to link the images and text, and provide a deeper and more insightful level of interpretation, albeit influenced by the author's personal account and expressed emotions; however, those analysing a picture book illustration demonstrated a surprising level of critical and creative thinking, and their interpretations were empathetic, insightful and thoughtful. Conclusion The use of picture books, although not a common approach in nursing education, appears to engage students, challenge them to think more deeply, and stimulate their imagination.";2014;2021-02-15T21:49:58Z;2021-02-15T21:49:58Z;NA;586-591;NA;4;34;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Education; Empathy; Mental health; Nursing student; Picture books; Therapeutic engagement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
9UBNAUYR;journalArticle;2017;"Toivonen, Asta Kristiina; Lindblom-Ylänne, Sari; Louhiala, Pekka; Pyörälä, Eeva";Medical students’ reflections on emotions concerning breaking bad news;Patient Education and Counseling;NA;0738-3991;https://doi.org/10.1016/j.pec.2017.05.036;https://www.sciencedirect.com/science/article/pii/S0738399117303427;Objectives To gain a deeper understanding of fourth year medical students’ reflections on emotions in the context of breaking bad news (BBN). Methods During the years 2010–2012, students reflected on their emotions concerning BBN in a learning assignment at the end of the communications skills course. The students were asked to write a description of how they felt about a BBN case. The reflections were analysed using qualitative content analysis. Results 351 students agreed to participate in the study. We recognized ten categories in students’ reflections namely empathy, insecurity, anxiety, sadness, ambivalence, guilt, hope, frustration, gratefulness and emotional detachment. Most students expressed empathy, but there was a clear tension between feeling empathy and retaining professional distance by emotional detachment. Conclusions Students experience strong and perplexing emotions during their studies, especially in challenging situations. A deeper understanding of students' emotions is valuable for supporting students’ professional development and coping in their work in the future. Practice implications Medical students need opportunities to reflect on emotional experiences during their education to find strategies for coping with them. Emotions should be actively discussed in studies where the issues of BBN are addressed. Teachers need education in attending emotional issues constructively.;2017;2021-02-15T21:49:58Z;2021-02-15T21:49:58Z;NA;1903-1909;NA;10;100;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Emotions; Empathy; Reflection; Content analysis; Breaking bad news; Medical students; Undergraduate medical education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
SSXK4BK6;journalArticle;2014;Kuroda, Ariyabhorn;Contemplative Education Approaches to Teaching Teacher Preparation Program;Procedia - Social and Behavioral Sciences;NA;1877-0428;https://doi.org/10.1016/j.sbspro.2014.01.405;https://www.sciencedirect.com/science/article/pii/S1877042814004224;"The purpose of this research was to developing instructions for Teacher Preparation Program in Khon Kaen University. The main intention is to make the learner's mind more aware of the human condition and to improve program objectives and learning through contemplative approaches. The 4 courses target in the first semester of 2012 academic year were students in Art Education Program and Teaching Japanese Program; Aesthetic Education,Art for Special-Needs Children, Introduction to Educational Philosophy and Ethics for Profession Teaching. The study was involving qualitative method, contemplative education approaches were used through mindfulness, deep listening, storytelling, sharing experiences together with dialogue, world café technique, drawing and reflection journaling. The results from reflective papers, observation and focus group were analyzed by content analysis. The research findings found that the contemplative teaching can support the development of attention, insight, emotional self- regulation, empathy, compassion for self and others and action in order to encourage and transform self-learning, deepens learning and builds inner strengths and skills. Through these approaches they were learning to reduce stress, enhance and improve classroom climates, and were helping students to calm their bodies and minds, focus their attention, and even open their hearts by exchange of learning ideas. The contemplative education approach is enabled students to recognize and properly tend to behavioural patterns and enabled students to process facts which led to contemplation and ultimately to wisdom.";2014;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;1400-1404;NA;NA;116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>5th World Conference on Educational Sciences</p>;NA;NA;"Contemplative Education Approaches; Teacher Preparation Programs";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
26JCIDA2;journalArticle;2020;Mount, Mallory;P73 Dietetics Experiential Learning at Diabetes Camp: Findings through Photovoice & Qualitative Analysis;Journal of Nutrition Education and Behavior;NA;1499-4046;https://doi.org/10.1016/j.jneb.2020.04.119;https://www.sciencedirect.com/science/article/pii/S1499404620302864;"Background Experiential learning provides an opportunity for students to develop hands-on experience and apply didactic learning to real-life situations. Diabetes camp is a setting that provides experiential learning on a topic that is crucial for future dietitians. Objective The objective of this study was to explore whether and how educational experiences at a residential camp for children with type 1 diabetes changes knowledge, perceptions, confidence, and empathy of the disease for dietetics students. Qualitative research methods were used to explore and understand participants’ experience of hands-on involvement with type one diabetes. Study Design, Setting, Participants This study was a qualitative, 2-year longitudinal case study at Camp Kno-Koma, the Diabetes Camp of West Virginia. Four dietetic students were recruited to participate in this study through convenience sampling. Students were in varying stages of their dietetics education. Measurable Outcome/Analysis Multiple qualitative methods were used to collect data: interviews; observations; Photovoice, a type of participatory action research in which photographs identified significant learning experiences; journaling; and focus groups. Thematic analysis was used to identify emerging themes and summarize findings through triangulation. Results Qualitative data analysis revealed that experiential learning at diabetes camp provides an opportunity for dietetics students to experience in-depth learning, including: increase in knowledge of the disease, perceptions of living with the disease, confidence in treating the disease, and empathy for those who have been diagnosed. While attending camp for one week is beneficial for experiential learning, returning for another week the following year provided a deeper understanding of the disease process. Students identified wearing an insulin pump and “living with diabetes” were their best learning experiences. Conclusions This study adds to the limited body of knowledge concerning dietetics students’ experiential learning at diabetes camps. The study's greatest contribution is the ability for educators to understand how experiential learning opportunities at diabetes camp provide in-depth education and how these learning experiences can be incorporated into dietetics curricula.";2020;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;S50-S51;NA;7, Supplement;52;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>What Food Future?</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
R95WV3W8;journalArticle;2017;"Wadsworth, Pamela; Colorafi, Karen; Shearer, Nelma";Using Narratives to Enhance Nursing Practice and Leadership: What Makes a Good Nurse?;Teaching and Learning in Nursing;NA;1557-3087;https://doi.org/10.1016/j.teln.2016.08.001;https://www.sciencedirect.com/science/article/pii/S1557308716300750;"Storytelling is an ancient practice that has functioned to maintain history, deepen empathy and understanding, and empower groups and individuals. Unfortunately, nurses are not encouraged to share their stories of contributions to patient care. In this article, 3 nurses share stories about learning to be good nurses, even while going against long-held nursing ideals. The authors argue that narratives can lead to a deeper understanding of nursing as a practice and discipline. The authors also contend that narratives facilitate the empowerment in nurses and patients using narratives; nurses recognize their power and facilitate their patients' recognition of power.";2017;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;28-31;NA;1;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empowerment; Good nurse; Group oppression; Leadership; Narratives";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
DLYXISXQ;journalArticle;2012;Terry, Louise M.;Service user involvement in nurse education: A report on using online discussions with a service user to augment his digital story;Nurse Education Today;NA;0260-6917;https://doi.org/10.1016/j.nedt.2011.06.006;https://www.sciencedirect.com/science/article/pii/S026069171100147X;Summary Service user involvement is a key element within current pre- and post-registration nurse education in the U.K. but achieving this is challenging. Most service user involvement is through classroom visits. Digital stories, film and audio are alternatives but lack the interactivity and development of reflection that can be achieved through face-to-face contact. This report reviews the background to service user involvement in healthcare professional education then provides a reflective account of a novel initiative whereby a spinal-injured patient was involved in creating a digital story around some of his in-hospital experiences and then engaged in online discussions with post-registration nursing (degree) and practice educator (masters) students. These discussions provided a richer experience for the students enabling them to reflect more deeply on how nursing care is delivered and perceived by service users. The report concludes that digital stories can be used with repeated groups to inspire discussion and reflection. Augmenting such digital stories with online discussions with the service user whose story is told helps practitioners develop greater empathy, insight and understanding which are beneficial for improving service delivery and nursing care.;2012;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;161-166;NA;2;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"<p>Service User &amp; Education</p>";NA;NA;"Digital stories; E-learning; Nurse education; Service user involvement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
SQNCPKMD;journalArticle;2017;"Rouzrokh, Mahsa; Muldoon, Meghan; Torabian, Pooneh; Mair, Heather";The memory-work sessions: Exploring critical pedagogy in tourism;Journal of Hospitality, Leisure, Sport & Tourism Education;NA;1473-8376;https://doi.org/10.1016/j.jhlste.2017.08.006;https://www.sciencedirect.com/science/article/pii/S1473837617301776;The paper reports on a pedagogical ‘experiment’ undertaken by scholars aiming to critically reflect on tourism and tourism studies. Memory-work, a feminist, qualitative methodology, was chosen because it centres critical tourism inquiry within the context of sharing meaningful, personal experiences. The team met regularly to engage in supportive, critical dialogue about their memories and to spark critical reflections about tourism more broadly. Four substantive themes (embodied remembering, gendered bodies, racialized bodies, and embodying the gaze) were developed from collective analyses of initial discussions. A deeper reflection on the potential of this approach for engendering critical tourism pedagogy was also undertaken to explore its potential as critical tourism pedagogy. Five pedagogical themes (building safe spaces and developing trust, creating empathy, engaging tourism literature in ‘real life’, opening doors for ongoing reflection, and decentring power and knowledge) were identified. The paper concludes with recommendations for adapting this approach to their own tourism teaching and learning endeavours.;2017;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;163-173;NA;NA;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Critical Perspectives in Hospitality, Leisure, Sport and Tourism Education</p>;NA;NA;"Critical tourism pedagogy; Embodiment; Memory-work; Transformational learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
NFV8TRE8;journalArticle;2015;"Ene, Ionel; Barna, Iuliana";Religious Education and Teachers’ Role in Students’ Formation towards Social Integration;Procedia - Social and Behavioral Sciences;NA;1877-0428;https://doi.org/10.1016/j.sbspro.2015.02.081;https://www.sciencedirect.com/science/article/pii/S1877042815014123;Religious education is a demanding area of pedagogical education, as there is no universal method to systematically insert religious principles in the children's education. The theory and methodology of the curriculum, instruction and evaluation require certain skills from teachers, such as: a great interest in the adequacy of the training process to the needs of each individual, the ability to adjust to different situations, a holistic assessment of the students’ performance, the involvement of the students in the learning process, etc. These skills are equally indispensable for the teacher of Religion, who must have greater sensitivity and empathy, and also deep religious convictions, reflected in their behaviour and in their way of relating with the student.;2015;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;30-35;NA;NA;180;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>The 6th International Conference Edu World 2014 “Education Facing Contemporary World Issues”, 7th - 9th November 2014</p>;NA;NA;"methods; competences; religious education; social phenomenon";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
3J63L4AP;journalArticle;2017;"Giacomo, E. Di; Clerici, M.";Intergenerational transmission of antisocial personality disorder: Maternal role and its declination;European Psychiatry;NA;0924-9338;https://doi.org/10.1016/j.eurpsy.2017.01.887;https://www.sciencedirect.com/science/article/pii/S0924933817309021;Antisocial personality disorder is a well-established disease which features space from cruelty to lack of empathy and remorse. Its etiology has been deeply analyzed both for genetic and environmental implications. The role of family context has been underlined throughout the whole psychopathology as an explanation to the etiological conflict between nature and nurture. Even if this conflict seems to be apparently solved, it is still possible to ponder about family implications in terms of causes and consequences. In the antisocial field, maternal role may offer interesting and surprising food for thought. Even if it is commonly believed an intergenerational transmission of aberrant behaviors, particularly in terms of learning behaviors and lack of empathy assimilation, it exists a side part of maternal pathological expression that may play a role in the intergenerational transmission and it is extremely difficult to be detected. Female declination of this disorder may be expressed also through somatic implications and complaints, leading to the hypothesis of a self-reflection of the lack of consideration for other's needs, which is distinctive. It is of extreme importance, particularly in terms of prevention, to consider and identify these connotations of the disorder to be able to try to interrupt the cycle of transmission through generations.;2017;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;S586;NA;NA;41;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Abstract of the 25th European Congress of Psychiatry</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
VXJZ3VYC;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;Artificial Intelligence in Medicine;NA;0933-3657;https://doi.org/10.1016/j.artmed.2019.101753;https://www.sciencedirect.com/science/article/pii/S0933365719306505;Background Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective To characterize the global psychiatrist community’s opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures We measured opinions about the likelihood that AI/ML tools would be able to fully replace – not just assist – the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist’s perceptions about whether benefits of AI/ML would outweigh the risks. Results Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020;2021-02-15T21:49:59Z;2021-02-15T21:49:59Z;NA;101753;NA;NA;102;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Deep learning; Empathy; Autonomous agents; Mental health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
DZWHE6RC;journalArticle;2010;Kocoska, Jasminka;The influence of the simulation strategy over the improvement of the classroom climate;Procedia - Social and Behavioral Sciences;NA;1877-0428;https://doi.org/10.1016/j.sbspro.2010.03.583;https://www.sciencedirect.com/science/article/pii/S1877042810006233;"The school climate is a process, structure of values and norms that canalize the teachers and the pupils in a direction of successful teaching and learning, increasing the effectiveness of the organizational set of the school building. The main aim of the simulation strategy is creating as much as possible closer situation to the real life or the pupils’ life experience. Through this strategy the pupils learn certain principles, skills of understanding and cognitive thinking, psychomotor skills and values/ ways of behavior, connected with certain certification, influences, readiness, alertness and empathy. The aim of this research is directed to assessment of the influence of the simulation strategy over the improvement of the classroom climate. From the actions, in this research were used observant field notes, that enabled an insight of the event through direct listening and looking by the pupils, and conceptual field notes that enabled making conclusions from the observation. From the instruments for registering the data was used a protocol for observation, aimed to the students, the pupils were observed during the classes and during the break. Another instrument that was used for the research is the questionnaire, aimed to the teachers and the experts. The use of the simulation strategy has a great influence over the creation of a positive climate in the class that it isn’t limited only in the process of classes realization, but it has broader and deeper dimension. It influences the positive dimension of the pupil's personality too as well as the development and straightening of the educational function of the school. That is why; in the future the teachers should continue to use this strategy and to specialize in this field so they can qualify the present and the future generations, in a quicker and easier way to solve the problems on personal, interpersonal, local and global level.";2010;2021-02-15T21:50:00Z;2021-02-15T21:50:00Z;NA;3751-3754;NA;2;2;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Innovation and Creativity in Education</p>;NA;NA;"classroom climate; influence; pupil; Simulation strategy; teachers";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
6F9J5WZM;journalArticle;2020;"Rivlin, Katherine; Sedlander, Erica; Cepin, Ana";“It Allows You to Challenge Your Beliefs”: Examining Medical Students’ Reactions to First Trimester Abortion;Women's Health Issues;NA;1049-3867;https://doi.org/10.1016/j.whi.2020.06.004;https://www.sciencedirect.com/science/article/pii/S1049386720300487;Background Abortion is a common medical procedure, integral to women's health, and a core educational topic for medical students. Medical schools often rely on brief clinical exposure to abortion during the obstetrics and gynecology clerkship to provide this learning. Abortion is also a highly politicized and stigmatized procedure. Given this potential conflict, we examine medical student reactions to their observation of abortion care. Study Design Medical students in their second and third years at an academic medical center who observed in a first trimester abortion clinic completed open-ended, written questionnaires. Questionnaires explored student reactions to participating in the abortion clinic. We used applied thematic analysis to code and qualitatively analyze 78 questionnaires. Results We identified the following five themes: (1) students found participating in abortion care deeply worthwhile, (2) some were challenged by their reactions, particularly when reactions conflicted with prior beliefs, (3) some demonstrated empathy for the patient, but (4) some expressed judgment of both the patient and the abortion provider, and (5) students reported a desire for curricular change around abortion education, requesting more time for reflection, and some felt that their abortion observation might better prepare them to serve future patients. Conclusions Observing in an abortion clinic is a valued experience that allows students to challenge their existing beliefs and may build empathy. Educators should provide students with adequate time for preparation and reflection around this topic and address areas of misunderstanding that may perpetuate abortion stigma. These findings may inform medical student curriculum changes around abortion.;2020;2021-02-15T21:50:00Z;2021-02-15T21:50:00Z;NA;353-358;NA;5;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
6TGZ8BHB;journalArticle;2020;"Calvert, James; Abadia, Rhodora";Impact of immersing university and high school students in educational linear narratives using virtual reality technology;Computers & Education;NA;0360-1315;https://doi.org/10.1016/j.compedu.2020.104005;https://www.sciencedirect.com/science/article/pii/S0360131520302037;"Immersive Virtual Reality (VR) is in its early days of educational adoption. This research aims to explain the benefits of VR in transforming learning and student experiences in classrooms. The experiment involved students using an educational VR experience that features an immersive narrative that puts students in the centre of a historical moment in World War Two. Two separate studies were conducted. One with high school students in Australia who would normally be studying the topic. And the other, University students in India, with no prior knowledge or awareness of the topic. Student participants used one of two different versions of Kokoda VR; six-degrees of freedom virtual reality or 360° video. Both the university and high school students using the virtual reality condition reported higher engagement, presence, empathy and better knowledge mastery than the 360° video groups. These features were also slightly higher in the university student group than in the high school student group except for the knowledge mastery where the high school students performed better. These findings indicate there is potential for immersive narrative VR experiences to provide students with new experiences and provide both cognitive and affective benefits.";2020;2021-02-15T21:50:00Z;2021-02-15T21:50:00Z;NA;104005;NA;NA;159;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Augmented and virtual reality; Post-secondary education; Secondary education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
9VYDHEL4;journalArticle;2020;"Lee, DongIl; Park, JaeHong";The relationship between a charity crowdfunding project's contents and donors' participation: An empirical study with deep learning methodologies;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2020.106261;https://www.sciencedirect.com/science/article/pii/S0747563220300170;NA;2020;2021-02-15T21:50:00Z;2021-02-15T21:50:00Z;NA;106261;NA;NA;106;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
XCARTQS7;journalArticle;2018;"Gardner, Janet; Emory, Jan";Changing students’ perceptions of the homeless: A community service learning experience;Nurse Education in Practice;NA;1471-5953;https://doi.org/10.1016/j.nepr.2018.01.001;https://www.sciencedirect.com/science/article/pii/S1471595317302743;The homeless are an underserved, local vulnerable population that can benefit from a service learning clinical practicum experience for baccalaureate prepared nursing students. Negative attitudes and disrespect among healthcare workers has been identified by the homeless as a barrier to healthcare. A service learning experience with a vulnerable population has been shown to change nursing students’ attitudes and beliefs. A large university in a southern city partnered with a community based organization that provided services to the homeless to educate senior nursing students in a service learning experience. The goal of this project was to examine attitudes and perceptions of nursing students toward the homeless population before and after participation in a service learning clinical practicum experience. This case study utilized a pre and post experience questionnaire to collect qualitative data for the purposes of the project. The findings revealed students demonstrated a decrease in fear, an increase in empathy, and a deeper understanding of the advocacy role of nurses for people experiencing homelessness. Nurse educators are challenged to engage students with vulnerable populations to change the attitudes and perceptions for improvement in the overall health of communities served worldwide. Partnerships and service learning experiences can benefit all.;2018;2021-02-15T21:50:00Z;2021-02-15T21:50:00Z;NA;133-136;NA;NA;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Homeless; Nursing education; Service learning; Vulnerable populations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
48GPMTQQ;journalArticle;2019;"Agopyan, H.; Griffet, J.; Poirier, T.; Bredin, J.";Modification of knee flexion during walking with use of a real-time personalized avatar;Heliyon;NA;2405-8440;https://doi.org/10.1016/j.heliyon.2019.e02797;https://www.sciencedirect.com/science/article/pii/S2405844019364576;Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed.;2019;2021-02-15T21:50:14Z;2021-02-15T21:50:14Z;NA;e02797;NA;11;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Rehabilitation; Empathy; Neuroscience; Sympathy; Avatar; Adaptation; Biomedical engineering; Knee flexion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
74LT9YSR;journalArticle;2018;"Felnhofer, Anna; Kafka, Johanna X.; Hlavacs, Helmut; Beutl, Leon; Kryspin-Exner, Ilse; Kothgassner, Oswald D.";Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2017.11.031;https://www.sciencedirect.com/science/article/pii/S0747563217306696;Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the Media Equation Concept (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses.;2018;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;399-406;NA;NA;80;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Virtual reality; Empathy; Prosocial behavior; Avatar; Agent; Social presence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
HCY4THM6;journalArticle;2019;MacDorman, Karl F.;In the uncanny valley, transportation predicts narrative enjoyment more than empathy, but only for the tragic hero;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2019.01.011;https://www.sciencedirect.com/science/article/pii/S0747563219300202;"The uncanny valley is a term used to describe the phenomenon that human simulations that are nearly but not quite realistic often give viewers an uneasy, eerie feeling. Given the prevalence of computer-animated human characters and a narrative framework in videogames, serious games, and health-related scenarios, it is important to examine how the uncanny valley influences narrative empathy and enjoyment. In a 2 × 2 × 2 between-groups posttest-only experiment, 738 participants took the role of a patient in a virtual consultation with a doctor; the consultation varied in the doctor's character (hero or villain), its subplot ending (happy or tragic), and its depiction (computer animated or real). The participants' posttest results showed greater emotional empathy and enjoyment in the hero condition and no significant difference in emotional empathy for the computer animation but greater narrative enjoyment and persuasion. Just endings (hero rewarded, villain punished) elicited much greater pleasure than unjust endings. In comparing computer animation with recorded video, emotional empathy was a significantly stronger predictor of narrative enjoyment than transportation only for the real hero with a tragic ending. The enjoyment and persuasiveness of the computer-animated doctor–patient consultation bodes well for the use of animation in interactive visual narratives.";2019;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;140-153;NA;NA;94;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Uncanny valley; Avatars; Anthropomorphism; Computer animation; Emotional empathy; Interactive narratives";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
3H542CFK;journalArticle;2020;"Bonnardel, Nathalie; Pichot, Nicolas";Enhancing collaborative creativity with virtual dynamic personas;Applied Ergonomics;NA;0003-6870;https://doi.org/10.1016/j.apergo.2019.102949;https://www.sciencedirect.com/science/article/pii/S0003687018305623;In many sectors, designers have to develop products that are creative, and thus both new and adapted to the context. They can use a variety of methods to favor their creative design activities, including a new one that we have developed, featuring dynamic personas. This method allows participants to interact in real time in a virtual space with an avatar that represents an archetypal future user and provides them with information about this future user throughout the interactions. In the present experimental study, we compared this method with the classic (or static) persona method, by asking 102 participants to perform a creative design task. Results revealed statistical differences between the use of the static and dynamic persona methods, and highlighted the advantages of the dynamic method over the static one. We discuss the prospects for using this method in an ecological setting and identify the aspects to be improved.;2020;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;102949;NA;NA;82;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Design; Creativity; Personas";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
MFKEWSIH;journalArticle;2017;"Stein, Jan-Philipp; Ohler, Peter";Venturing into the uncanny valley of mind—The influence of mind attribution on the acceptance of human-like characters in a virtual reality setting;Cognition;NA;0010-0277;https://doi.org/10.1016/j.cognition.2016.12.010;https://www.sciencedirect.com/science/article/pii/S0010027716303055;For more than 40years, the uncanny valley model has captivated researchers from various fields of expertise. Still, explanations as to why slightly imperfect human-like characters can evoke feelings of eeriness remain the subject of controversy. Many experiments exploring the phenomenon have emphasized specific visual factors in connection to evolutionary psychological theories or an underlying categorization conflict. More recently, studies have also shifted away focus from the appearance of human-like entities, instead exploring their mental capabilities as basis for observers' discomfort. In order to advance this perspective, we introduced 92 participants to a virtual reality (VR) chat program and presented them with two digital characters engaged in an emotional and empathic dialogue. Using the same pre-recorded 3D scene, we manipulated the perceived control type of the depicted characters (human-controlled avatars vs. computer-controlled agents), as well as their alleged level of autonomy (scripted vs. self-directed actions). Statistical analyses revealed that participants experienced significantly stronger eeriness if they perceived the empathic characters to be autonomous artificial intelligences. As human likeness and attractiveness ratings did not result in significant group differences, we present our results as evidence for an “uncanny valley of mind“ that relies on the attribution of emotions and social cognition to non-human entities. A possible relationship to the philosophy of anthropocentrism and its “threat to human distinctiveness” concept is discussed.;2017;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;43-50;NA;NA;160;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Virtual reality; Artificial intelligence; Anthropocentrism; Social cognition; Theory of mind; Uncanny valley";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
BLEDN2ML;journalArticle;2017;"Leménager, T.; Dieter, J.; Hill, H.; Mann, K.; Kiefer, F.";Internet addiction and the virtual self-image;European Psychiatry;NA;0924-9338;https://doi.org/10.1016/j.eurpsy.2017.01.136;https://www.sciencedirect.com/science/article/pii/S0924933817301414;Background Internet gaming disorder appears to be associated with self-concept deficits and increased identification with one's avatar. For increased social network use, the few existing studies suggest striatal-related positive social feedback as an underlying factor. Furthermore, few study findings indicate that internet addicts generally have problems in emotional inhibitory control processing. Methods Pathological and addicted internet gamers as well as social network users were compared with healthy controls regarding psychometric and neurobiological measures of self-concept-related characteristics, avatar identification and emotional inhibitory control processing. Results and conclusion Psychometric results indicated that both subgroups showed higher self-concept deficits compared to healthy controls. Neurobiologically, different brain activation patterns were observed in the subgroups during self-knowledge retrieval and inhibition of emotional stimuli. Furthermore, addicted internet gamers showed a higher identification with the own avatar, mirrored in an increased left angular gyrus activation, a region functionally associated with identification processing and feelings of empathy. These findings provide a starting point for the deduction of specific psychotherapeutic treatment approaches for addicted internet gamers and social network users.;2017;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;S26;NA;NA;41;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Abstract of the 25th European Congress of Psychiatry</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
9GB9DIUF;journalArticle;2015;Lemenager, T.;Psychological and Neurobiological Mechanisms of Pathological Internet Use;European Psychiatry;NA;0924-9338;https://doi.org/10.1016/S0924-9338(15)30102-4;https://www.sciencedirect.com/science/article/pii/S0924933815301024;Background Studies on internet gaming disorders indicate that especially online role-playing games have a high addictive potential in particular in male adolescents. These games enable the parallel gaming of multiple users in online virtual worlds with or against each other via their graphical agent (avatar). Recent findings suggest online role-playing addicts to have a deficient self-concept. The latter's potential compensation by means of a higher identification with the own avatar might be an etiological factor in the development of an online role-playing game addiction. On a neurobiological level, especially the left Angular Gyrus (AG) seems to be associated with identification and empathy processes. An according fMRI-based study on long-term gamers of online role-playing games indicated increased brain activations in the left AG during the rating of personality traits referring to the avatar relative to self-referencing and the referencing of close others (Ganesh et al., 2011). However, the extent to which these results represent specific neurobiological mechanisms that are associated with self-concept deficits or a stronger identification with the own avatar in the development of online role-playing game addiction remains unknown to date. Methods N=16 addicted and n=17 regular gamers of online role-playing games (mean age=28 and 26 years, respectively) underwent functional Magnetic Resonance Imaging (fMRI) while 1) completing a Giessen-Test (GT)-derived paradigm assessing participants’ concepts of self, ideal and avatar and 2) while viewing and evaluating images of the own person, the own avatar as well as unknown persons. Additionally, a questionnaire referring to the own body image and a Visual Analogue Scale (VAS) for the evaluation of the own as well as avatar's attractiveness, sympathy and gender identity were applied. Results Addicts of online role-playing games rated their body image, gender identity and social response (i.e. social popularity) significantly lower. Neurobiologically, they showed increased left AG activations during the reflection about their avatar (relative to their ideal and/or their self) compared to non-addicted gamers. Furthermore, within-group differences revealed left AG response during the perception of images showing their avatar (relative to images of themselves). In addition, addicted gamers had hypoactivations in the bilateral AG during the perception of images of their own person compared to the perception of unknown persons. The left-lateral AG hypoactivation positively correlated with the degree of the gender identity. Discussion In line with previous findings, our results indicate self-concept deficits in online role-playing game addicts and a stronger identification with the own avatar, which might neurobiologically be reflected in AG activations. The results could point towards problems in the formation of an own identity as a cause for online role-playing game addiction development. Longitudinal studies may shed light on these potentially causal relations.;2015;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;123;NA;NA;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Abstracts of the 23rd European Congress of Psychiatry</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
N3XDLEVX;journalArticle;2016;"Tordo, Frédéric; Binkley, Caroline";L’auto-empathie, ou le devenir de l’autrui-en-soi : définition et clinique du virtuel;L'Évolution Psychiatrique;NA;0014-3855;https://doi.org/10.1016/j.evopsy.2014.02.002;https://www.sciencedirect.com/science/article/pii/S001438551400036X;Résumé Objectifs Les auteurs se proposent d’explorer un phénomène psychique, l’« auto-empathie », tel qu’il est mis en œuvre dans le contexte des espaces numériques et singulièrement dans la situation du joueur qui incarne un avatar (une figure de pixel) dans un jeu vidéo. Méthode Dans la perspective d’une ouverture théorique à la fois phénoménologique et psychanalytique, l’auto-empathie est le processus au cours duquel, en prenant la position de l’« autrui-en-soi », nous nous représentons notre monde subjectif – soit l’ensemble de nos états de subjectivité (actions, émotions, pensées) –, par relation empathique avec nous-mêmes. Cette relation d’auto-empathie correspond à une opération de distanciation, et d’appropriation symbolique, au cours de laquelle nous nous dédoublons, en mettant en œuvre notre faculté innée d’être à la fois sujet et objet pour nous-mêmes. Résultats La médiatisation de l’auto-empathie dans les mondes numériques permet de nous mettre à la place d’une figure qui nous représente – notre avatar –, de sorte que notre empathie est tournée vers nous-mêmes indirectement. Ce second temps d’empathie pour une figure virtuelle de soi, nommé « auto-empathie médiatisée » ou « auto-empathie virtuelle », favoriserait dans un troisième temps le développement d’une empathie pour soi. Enfin, le développement d’une empathie pour autrui serait soutenu dans un quatrième temps, par l’attention que les joueurs se portent les uns aux autres dans les jeux en réseau. Discussion Ces quatre hypothèses, illustrées par des cas cliniques, ouvrent une interrogation portant sur le cadre en psychanalyse. À l’adolescence, le travail de virtualisation, qui consiste en l’anticipation créatrice de ses possibilités subjectives, apparaît régulièrement contrarié. La duplicité psychique n’est plus à même d’opérer une distance symbolisante entre le soi réel et le soi virtuel, entre le soi subjectif et le soi subjectivant. L’autrui-en-soi est inefficace à proposer à l’adolescence un dialogue empathique avec soi-même. En conséquence, l’autoreprésentation flirte avec l’effondrement, en particulier dans les états de cassures subjectives. Or, les espaces numériques pourraient bien être pour l’adolescent des supports indirects d’appropriation d’expériences subjectives. Conclusion Nos réflexions ont conduit à penser l’auto-empathie comme la réalisation de l’autrui-en-soi qui permet de nous représenter notre propre monde subjectif. L’auto-empathie médiatisée par un avatar peut donc être décrite comme une représentation par empathie de notre part subjective contenue par ce personnage. Dès lors, l’espace du jeu vidéo se présente comme un espace de subjectivation. Objectives The authors propose to explore a psychic phenomenon, the “auto-empathy”, as implemented in the context of digital spaces and particularly in the situation of the player who embodies an avatar (a pixel figure) in a video game. Method From the perspective of a theoretical opening both phenomenological and psychoanalytic, auto-empathy is the process in which, taking the position of the “other-in-oneself”, we represent our subjective world – or the all states of our subjectivity (actions, emotions, thoughts) – by an empathic relationship with ourselves. The auto-empathy relationship is a process of distancing, and symbolic appropriation, in which we are divided into halves, implementing our innate ability to be both subject and object for ourselves. Results The mediatization of auto-empathy in digital worlds can put ourselves instead of a figure that represents us – our avatar – so that our empathy is turned towards ourselves indirectly. This second time of empathy for a virtual figure of the self, called “mediatized auto-empathy” or “virtual auto-empathy”, would contribute thirdly to the development of empathy for oneself. Finally, the development of empathy for others would be supported in a fourth time, by the attention the players are paying to each other in network games. Discussion These four hypotheses, illustrated by clinical cases, open an interrogation concerning the frame of the psychoanalytical work. In the adolescent, the work of virtualisation, which consists in the creative anticipation of its subjective possibilities, seems regularly impeded. The mental duplicity is no longer in a position to operate a symbolizing distance between the real self and the virtual self, between the subjective self and the subjectivising self. The other-in-oneself is ineffective in proposing to the adolescent an empathic dialogue with oneself. Consequently, the autorepresentation flirts with the seizure, in particular in the subjective states of breaks. Nevertheless, the digital spaces could be indirect media of appropriation of subjective experiences for the teenager. Conclusion Our reflections led us to think of auto-empathy as the realization of the other-in-oneself which allows us to represent our own subjective world. The auto-empathy mediatized by an avatar can thus be described as a representation by empathy of our subjective part that contains this character. From then on, the space of the video game appears as a space of subjectivation.;2016;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;293-308;NA;2;81;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Phenomenology; Auto-empathy; MMORPG; Video games; Others-in-oneself; Psychoanalysis; Reflexiveness; Subjectivation; Theoretical study; Auto-empathie; Autrui-en-soi; Empathie; Étude théorique; Jeu vidéo; Phénoménologie; Psychanalyse; Réflexivité";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
RYRT4ZDG;journalArticle;2014;"Thirioux, Bérangère; Tandonnet, Louis; Jaafari, Nematollah; Berthoz, Alain";Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia: A behavioural pilot-study using virtual reality technology;Brain and Cognition;NA;0278-2626;https://doi.org/10.1016/j.bandc.2014.06.006;https://www.sciencedirect.com/science/article/pii/S0278262614001031;Behavioural and neuroimaging data have recently pointed out that empathy (feeling into someone else) is associated with mental imagery and transformation related to one’s and other’s visuo-spatial perspectives. Impairments of both empathic and visuo-spatial abilities have been observed in patients with schizophrenia. Especially, it has been suggested that schizophrenics are altered in spontaneously simulating another individual’s first-person experience. However, there is so far only little evidence regarding the relationship between deficits in empathy and disturbances in spontaneous heterocentered coding in schizophrenia. In the present pilot-study, we tested with schizophrenic patients our behavioural paradigm that enables to measure from the bodily postures and movements whether individuals in ecologically more valid conditions are interacting with another individual by using egocentered – as in sympathy (feeling with someone else) – or heterocentered – as in empathy – visuo-spatial mechanisms. For that, ten patients and ten controls, standing and moving, interacted with a virtual tightrope walker, displayed life-sized, standing and moving as well. We show that patients with higher negative symptoms had, in most cases, deficits in spontaneously using heterocentered visuo-spatial mechanisms and employed preferentially an egocentered referencing to interact with the avatar. In contrast, preserved spontaneous heterocentered visuo-spatial strategies were not linked to a prevailing negative or positive symptomatology. Our data suggest that the severity of the negative symptoms in schizophrenia relates with disturbances of spontaneous (“on-line”) empathic processing in association with lower scoring self-reported trait cognitive empathy.;2014;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;87-99;NA;NA;90;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Negative symptoms; Schizophrenia; Empathy; Sympathy; Executive functions; Inhibitory processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
UMV9X92K;journalArticle;2019;"Fusaro, M.; Tieri, G.; Aglioti, S. M.";Influence of cognitive stance and physical perspective on subjective and autonomic reactivity to observed pain and pleasure: An immersive virtual reality study;Consciousness and Cognition;NA;1053-8100;https://doi.org/10.1016/j.concog.2018.11.010;https://www.sciencedirect.com/science/article/pii/S1053810018303477;Observing others’ pain may induce a reaction called personal distress that may be influenced by top-down (imagine self or other in pain, i.e., self- vs other-oriented stance) and bottom-up (physical perspective of those who suffer, i.e., first vs third person perspective- 1PP vs 3PP) processes. The different contributions of these processes have not been teased apart. By capitalizing on the power of Immersive Virtual Reality, we explored how behavioural (subjective ratings) and physiological reactivity (skin conductance reactivity, SCR) to pain and pleasure delivered to an avatar was influenced by Cognitive stance and Physical perspective. Taking an Other-Oriented stance leads to attributing higher congruent valence (i.e. pain rated as unpleasant and pleasure as pleasant) and intensity to the stimuli and induces reduced SCR. Ownership over the virtual limb was maximal in 1PP where physiological reactivity to the stimuli was comparable. Our results highlight different components underpinning reactivity to pain and pleasure.;2019;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;86-97;NA;NA;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Cognitive and physical perspective-taking; Feeling of Ownership; Immersive Virtual Reality; Pleasant touch; Vicarious Pain";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
5H8CH9VT;journalArticle;2011;"Guadagno, Rosanna E.; Swinth, Kimberly R.; Blascovich, Jim";Social evaluations of embodied agents and avatars;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2011.07.017;https://www.sciencedirect.com/science/article/pii/S0747563211001555;The purpose of this study was to examine social evaluations (i.e., perceptions of empathy and positivity) following peoples’ interactions with digital human representations. Female research participants engaged in a 3-min interaction while immersed in a 3-D immersive virtual environment with a “peer counselor.” Participants were led to believe that the peer counselor was either an embodied agent (i.e., computer algorithm) or an avatar (i.e., another person). During the interaction, the peer counselor either smiled or not. As predicted, a digitally-rendered smile was found to affect participants’ social evaluations. However, these effects were moderated by participants’ beliefs about their interaction partner. Specifically, smiles enhanced social evaluations of embodied agents but degraded them for avatars. Although these results are consistent with other findings concerning the communicative realism of embodied agents and avatars they uniquely demonstrate that people’s beliefs alone, rather than actual differences in virtual representations, can impact social evaluations.;2011;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;2380-2385;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Avatars; Facial expressions; Collaborative virtual environments; Embodied agents; Nonverbal behavior; Social interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
C9Y32NBK;journalArticle;2016;Ceranoglu, Tolga Atila;46.2 AUTISM SPECTRUM DISORDERS AND ELECTRONIC MEDIA USE: EMPATHY WITH AVATARS;Journal of the American Academy of Child & Adolescent Psychiatry;NA;0890-8567;https://doi.org/10.1016/j.jaac.2016.07.714;https://www.sciencedirect.com/science/article/pii/S0890856716310632;NA;2016;2021-02-15T21:50:15Z;2021-02-15T21:50:15Z;NA;S70;NA;10, Supplement;55;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"<p>AACAP&apos;s 63rd Annual Meeting</p>";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
5FTWICZT;journalArticle;2020;"Kervenoael, Ronan de; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;Tourism Management;NA;0261-5177;https://doi.org/10.1016/j.tourman.2019.104042;https://www.sciencedirect.com/science/article/pii/S0261517719302407;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020;2021-02-15T21:50:34Z;2021-02-15T21:50:34Z;NA;104042;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Science Direct
ZXV4N2ZU;journalArticle;2021;Irfan, F.;Artificial intelligence: Help or hindrance for family physicians?;Pakistan Journal of Medical Sciences;NA;NA;10.12669/pjms.37.1.3351;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096989073&doi=10.12669%2fpjms.37.1.3351&partnerID=40&md5=c41326d8fd2999819e37ec0e1a8eb331;"The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician’s new assistant; AI-physician combinations can act like models of ‘peaceful co-existence’. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician’s diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients’ frustration. © 2021, Professional Medical Publications. All rights reserved.";2021;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;1-4;NA;1;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9RVTE2H9;journalArticle;2021;"Bilewicz, M.; Tempska, P.; Leliwa, G.; Dowgiałło, M.; Tańska, M.; Urbaniak, R.; Wroczyński, M.";Artificial intelligence against hate: Intervention reducing verbal aggression in the social network environment;Aggressive Behavior;NA;NA;10.1002/ab.21948;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100209523&doi=10.1002%2fab.21948&partnerID=40&md5=9c486d6fb70ead5dab93d1c932aada1c;This article presents a quasi-experimental intervention study designed to reduce the level of verbal aggression on a social networking service (Reddit). The interventions were based on three psychological mechanisms: induction of a descriptive norm, induction of a prescriptive norm, and empathy induction. Each intervention was generated using a communicating bot. Participants exposed to these interventions were compared with a control group that received no intervention. The bot-generated normative communications (both the ones priming descriptive and the ones priming prescriptive norms), as well as the empathizing intervention, reduced the proportion of verbal aggression posted by Reddit accounts. All three interventions proved effective in reducing verbal violence when compared with the control condition. © 2021 Wiley Periodicals LLC;2021;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3DW4KCRX;journalArticle;2021;"Hashiguchi, T.; Yamamoto, T.; Fujita, S.; Ohshima, H.";Searching for distress of similar situation from CQA content;Transactions of the Japanese Society for Artificial Intelligence;NA;NA;10.1527/tjsai.36-1_WI2-B;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099157569&doi=10.1527%2ftjsai.36-1_WI2-B&partnerID=40&md5=c5003c12ca7efda18147f000346742c2;In this study, we tackle the problem of retrieving questions from a corpus archived in a Community Question Answering service that a consultant having distress can feel empathy with them. We hypothesize that the consultant feels empathy with the questions having a similar situation with that of the consultant’s distress, and propose a method of retrieving similar sentences focusing on the situation of the distress. Specifically, we propose two approaches to fine-tuning the pre-trained BERT model so that the learned model better captures the similarity of the situation between distress. One tries to extract only the words representing the situation of the distress, the other tries to predict whether the two sentences show the same situation. The data for training the models are gathered by the crowdsourcing task where the workers are asked to gather the sentences whose situation is similar to the given sentence and to annotate the words in the sentences that represent the situation. The data is then used to fine-tune the BERT model. The effectiveness of the proposed methods is evaluated with the baselines such as TF-IDF, Okapi BM25, and the pre-trained BERT. The results of the experiment with 20 queries showed that one of our methods achieved the highest nDCG@5 while we could not observe any significant differences among the methods. © 2021, Japanese Society for Artificial Intelligence. All rights reserved.;2021;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;WI2-B_1-WI2-B_13;NA;1;36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8KY6AV5D;journalArticle;2020;Schmetkamp, S.;Understanding A.I. — Can and Should we Empathize with Robots?;Review of Philosophy and Psychology;NA;NA;10.1007/s13164-020-00473-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083955575&doi=10.1007%2fs13164-020-00473-x&partnerID=40&md5=8c5a1a9139fa546337a1ecdeea7e1f49;Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding. © 2020, Springer Nature B.V.;2020;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;881-897;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VS6NZGTH;journalArticle;2020;"Liao, J.; Hansen, P.; Chai, C.";A framework of artificial intelligence augmented design support;Human-Computer Interaction;NA;NA;10.1080/07370024.2020.1733576;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084312865&doi=10.1080%2f07370024.2020.1733576&partnerID=40&md5=098f22d0398c863d6ad804592ff100f6;Recent advances in Artificial Intelligence raise interest in its participation in design activity, which is commonly considered to be complex and human-dominated. In this work, we aim to examine AI roles in early design stages. The human ideation components and design tools related to AI are discussed in a framework of AI-augmented design support. The framework develops a hierarchy of design cognition (basis), approaches and principles. The cognitive models are constructed in an empirical study of 30 designers (26 for analysis, 4 for pilot study) by concurrent Think-Aloud protocol and behavior analysis. The process of producing new design ideas is explained by a transparent analysis of designers’ language and behaviors. Three strategies to organize cognitive activities in design ideation are summarized: develop structured consideration, relate to a scenario, and stick-to designing. These strategies suggest AI could act as (1) representation creation, (2) empathy trigger and (3) engagement, in principles of “knowledge-driven” and “decompose-and-integrate”. The design support with AI provides new perspectives on computer-based design tools that limit to well-defined design variables. The framework is built on a generic notion of design activity and “mimic” human design rationales, expected to benefit research of domain-independent computational design supports and cognitive supports. © 2020 Taylor & Francis Group, LLC.;2020;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;511-544;NA;5-6;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
A87JHFBH;journalArticle;2020;"Baki Kocaballi, A.; Ijaz, K.; Laranjo, L.; Quiroz, J.C.; Rezazadegan, D.; Tong, H.L.; Willcock, S.; Berkovsky, S.; Coiera, E.";Envisioning an artificial intelligence documentation assistant for future primary care consultations: A co-design study with general practitioners;Journal of the American Medical Informatics Association;NA;NA;10.1093/jamia/ocaa131;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096355732&doi=10.1093%2fjamia%2focaa131&partnerID=40&md5=8bfdd5fbd3064e7bb5b25a8cc185ccb9;Objective: The study sought to understand the potential roles of a future artificial intelligence (AI) documentation assistant in primary care consultations and to identify implications for doctors, patients, healthcare system, and technology design from the perspective of general practitioners. Materials and Methods: Co-design workshops with general practitioners were conducted. The workshops focused on (1) understanding the current consultation context and identifying existing problems, (2) ideating future solutions to these problems, and (3) discussing future roles for AI in primary care. The workshop activities included affinity diagramming, brainwriting, and video prototyping methods. The workshops were audio-recorded and transcribed verbatim. Inductive thematic analysis of the transcripts of conversations was performed. Results: Two researchers facilitated 3 co-design workshops with 16 general practitioners. Three main themes emerged: professional autonomy, human-AI collaboration, and new models of care. Major implications identified within these themes included (1) concerns with medico-legal aspects arising from constant recording and accessibility of full consultation records, (2) future consultations taking place out of the exam rooms in a distributed system involving empowered patients, (3) human conversation and empathy remaining the core tasks of doctors in any future AI-enabled consultations, and (4) questioning the current focus of AI initiatives on improved efficiency as opposed to patient care. Conclusions: AI documentation assistants will likely to be integral to the future primary care consultations. However, these technologies will still need to be supervised by a human until strong evidence for reliable autonomous performance is available. Therefore, different human-AI collaboration models will need to be designed and evaluated to ensure patient safety, quality of care, doctor safety, and doctor autonomy. © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.;2020;2021-02-15T22:33:58Z;2021-02-15T22:33:58Z;NA;1695-1704;NA;11;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5M8AN3LD;journalArticle;2020;"McDonald, N.; Pan, S.";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proceedings of the ACM on Human-Computer Interaction;NA;NA;10.1145/3415218;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094204706&doi=10.1145%2f3415218&partnerID=40&md5=e91f074cfe55852594702ade8fcff795;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course. © 2020 ACM.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CBWE5JR2;conferencePaper;2020;Wang, Z.;Future challenges in the next generation of voice user interface;Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020;NA;NA;10.1109/CDS49703.2020.00045;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098868220&doi=10.1109%2fCDS49703.2020.00045&partnerID=40&md5=5242ff50af9fa8ad1855ea7df90463e7;With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI. © 2020 IEEE;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;191-193;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QEAC3WRM;journalArticle;2020;Kerasidou, A.;Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare [L'intelligence artificielle et le besoin constant d’empathie, de compassion et de confiance dans le secteur de la santé] [La inteligencia artificial y la continua necesidad de empatía, compasión y confianza en la atención sanitaria];Bulletin of the World Health Organization;NA;NA;10.2471/BLT.19.237198;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083246717&doi=10.2471%2fBLT.19.237198&partnerID=40&md5=cb5246773745079c64d8a27e85022353;Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote. © 2020, World Health Organization. All rights reserved.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;245-250;NA;4;98;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FJINAGBK;conferencePaper;2020;"Dixit, R.; Chinnam, R.B.; Singh, H.";Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations;IEEE Aerospace Conference Proceedings;NA;NA;10.1109/AERO47225.2020.9172612;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092594173&doi=10.1109%2fAERO47225.2020.9172612&partnerID=40&md5=0e5e0dbad1bd51bfa0c0a6e225195406;Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once 'trained,' can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to 'techies' from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further. © 2020 IEEE.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KV34A3NB;journalArticle;2020;"Kim, H.C.; Cha, M.C.; Ji, Y.G.";The effect of empathy on human-agent interaction;ICIC Express Letters, Part B: Applications;NA;NA;10.24507/icicelb.11.06.551;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085004414&doi=10.24507%2ficicelb.11.06.551&partnerID=40&md5=2a2ed44f0075def60a3d405839efaab1;Technology development and information communication have led to an in-crease of human-agent communication and provided an opportunity to overcome the ex-isting limitation human-human communication. Psychological counseling studies suggest conventional face-to-face counseling method can replace the role of a counselor by ap-plying agent technology. The present study has been established to identify the effects of empathy in human-agent interaction. In order to do so, we designed and conducted a pilot study of a prototype of counseling conversation based on psychological counseling theory. We have found that empathic agents resulted in lower score on counselor’s as-sessment and lower level of empathy perceived by the subjects. The simple empathy used in this study may have given the participants a sense of imitating a clumsy human be-ing and have caused a higher level of displeasure and discomfort compared to the agents without empathy response. This study is meaningful in that it provides basic data for developing and improving an artificial intelligence-based psychological counseling system by designing artificial intelligence counseling agents and varying levels of empathy. © ICIC International 2020.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;551-557;NA;6;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9YU4SKFN;journalArticle;2020;"Erden, Y.J.; Hummerstone, H.; Rainey, S.";Automating autism assessment: What AI can bring to the diagnostic process;Journal of Evaluation in Clinical Practice;NA;NA;10.1111/jep.13527;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097612678&doi=10.1111%2fjep.13527&partnerID=40&md5=e4fff3517d81410cf748b34bfdb6bf25;This paper examines the use of artificial intelligence (AI) for the diagnosis of autism spectrum disorder (ASD, hereafter autism). In so doing we examine some problems in existing diagnostic processes and criteria, including issues of bias and interpretation, and on concepts like the ‘double empathy problem’. We then consider how novel applications of AI might contribute to these contexts. We're focussed specifically on adult diagnostic procedures as childhood diagnosis is already well covered in the literature. © 2020 The Authors. Journal of Evaluation in Clinical Practice published by John Wiley & Sons Ltd.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
REX3BB4I;journalArticle;2020;Ostherr, K.;Artificial Intelligence and Medical Humanities;Journal of Medical Humanities;NA;NA;10.1007/s10912-020-09636-4;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088927968&doi=10.1007%2fs10912-020-09636-4&partnerID=40&md5=53ea81de6d941d02b11180d7678fa092;"The use of artificial intelligence in healthcare has led to debates about the role of human clinicians in the increasingly technological contexts of medicine. Some researchers have argued that AI will augment the capacities of physicians and increase their availability to provide empathy and other uniquely human forms of care to their patients. The human vulnerabilities experienced in the healthcare context raise the stakes of new technologies such as AI, and the human dimensions of AI in healthcare have particular significance for research in the humanities. This article explains four key areas of concern relating to AI and the role that medical/health humanities research can play in addressing them: definition and regulation of “medical” versus “health” data and apps; social determinants of health; narrative medicine; and technological mediation of care. Issues include data privacy and trust, flawed datasets and algorithmic bias, racial discrimination, and the rhetoric of humanism and disability. Through a discussion of potential humanities contributions to these emerging intersections with AI, this article will suggest future scholarly directions for the field. © 2020, The Author(s).";2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BINWUHBM;journalArticle;2020;"Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;Digital Health;NA;NA;10.1177/2055207620968355;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094669527&doi=10.1177%2f2055207620968355&partnerID=40&md5=5e2909e410f68527e010deb3b1f9b7b3;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues. © The Author(s) 2020.";2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8ZBRW28B;conferencePaper;2020;"Nobles, A.L.; Leas, E.C.; Dredze, M.; Ayers, J.W.";Examining peer-to-peer and patient-provider interactions on a social media community facilitating ask the doctor services;Proceedings of the 14th International AAAI Conference on Web and Social Media, ICWSM 2020;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099601301&partnerID=40&md5=6cd8f112b367c90578389a21573a3e13;Ask the Doctor (AtD) services provide patients the opportunity to seek medical advice using online platforms. While these services represent a new mode of healthcare delivery, study of these online health communities and how they are used is limited. In particular, it is unknown if these platforms replicate existing barriers and biases in traditional healthcare delivery across demographic groups. We present an analysis of AskDocs, a subreddit that functions as a public AtD platform on social media. We examine the demographics of users, the health topics discussed, if biases present in offline healthcare settings exist on this platform, and how empathy is expressed in interactions between users and physicians. Our findings suggest a number of implications to enhance and support peer-to-peer and patient-provider interactions on online platforms. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;464-475;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZGDYPP4J;conferencePaper;2020;Baggio, B.;AI and education reborn;ICSIT 2020 - 11th International Conference on Society and Information Technologies, Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085913813&partnerID=40&md5=c04d7d1a2cb21e5464fb3932a7117e19;AI (Artificial Intelligence) will have enormous impacts on education, learning and talent development in K-12, higher Education and workplace learning. AIEd has barely scratched the surface. It will redefine the role of the teacher and support creative and human acts that provide ingenuity and empathy in support of learning. The gold is in the data. As AI interprets data, examines the role of the teacher or expert, supports classroom evolution and provides one on one tutoring, AIEd will be inextricably linked to the future of AI. AI comes with opportunities and many challenges. The adoption rate of new AI technologies seems to be on a path unprecedented in history. AI will need to provide insight in to learning and measure innate characteristics like curiosity and creativity. New pedagogies, research into existing learning sciences and learning contexts are needed. © 2020 by the International Institute of Informatics and Systemics. All rights reserved.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;34-39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
T4N8I938;conferencePaper;2020;"Nehra, V.; Nagpal, R.; Sehgal, R.";Collective intelligence: When, where and why;Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering;NA;NA;10.1109/Confluence47617.2020.9058000;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083999561&doi=10.1109%2fConfluence47617.2020.9058000&partnerID=40&md5=dc43e7ffcf6adf8f724ffaf9d79a8e30;The term 'Collective' is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief. © 2020 IEEE.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;805-810;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KXVJ77TF;journalArticle;2020;"Chiang, A.-H.; Trimi, S.";Impacts of service robots on service quality;Service Business;NA;NA;10.1007/s11628-020-00423-8;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089085301&doi=10.1007%2fs11628-020-00423-8&partnerID=40&md5=845fde74db3c352ab9c164b287bcc23f;With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZJSLLXTJ;journalArticle;2020;Davis, A.E.;The future of law firms (and lawyers) in the age of artificial intelligence [O Futuro dos escritorios de advocacia (e dos advogados) na era da inteligencia artificial];Revista Direito GV;NA;NA;10.1590/2317-6172201945;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090527121&doi=10.1590%2f2317-6172201945&partnerID=40&md5=fc37caa4e681a8f07c4ae6a46375adb7;"This article explores the future for lawyers and law firms in the light of the changes that Artificial Intelligence (""AI"") is already bringing to the universe of legal services. Part I briefly describes some of the ways AI is already in use in ordinary life-from facial recognition, through medical diagnosis to translation services. Part II describes how AI is transforming what it means to provide legal services in six primary areas: Litigation review; expertise automation; legal research; contract analytics; contract and litigation document generation; and predictive analytics. Part III explores who are the providers of these AI driven legal services-often non-lawyer legal service providers-and how these providers are replacing at least some of what clients have traditionally sought from lawyers. Part III also discusses the implications of all these changes both for the future role of lawyers individually, and in particular what services will clients still need lawyers to perform: Judgment, empathy, creativity and adaptability. In turn, this Part examines what will these changes mean for the size, shape, composition and economic model of law firms, as well as the implications of these changes for legal education and lawyer training. Part IV identifies the principal legal, ethical, regulatory and risk management issues raised by the use of AI in the provision of legal services. Finally, in Part V the article considers who will be the likely providers of AI based services other than law firms: Legal publishers, major accounting firms and venture capital funded businesses. © 2020 Fundacao Getulio Vargas, Escola de Direito de Sao Paulo. All rights reserved.";2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;1DUMMT;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VXKMY2Y5;journalArticle;2020;Johnson, J.;Delegating strategic decision-making to machines: Dr. Strangelove Redux?;Journal of Strategic Studies;NA;NA;10.1080/01402390.2020.1759038;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084253030&doi=10.1080%2f01402390.2020.1759038&partnerID=40&md5=6b22890c802c9b5864b40f003515f307;Will the use of artificial intelligence (AI) in strategic decision-making be stabilizing or destabilizing? What are the risks and trade-offs of pre-delegating military force (or automating escalation) to machines? How might non-nuclear state and non-state actors leverage AI to put pressure on nuclear states? This article analyzes the impact of strategic stability of the use of AI in the strategic decision-making process, in particular, the risks and trade-offs of pre-delegating military force (or automating escalation) to machines. It argues that AI-enabled decision support tools, by substituting the role of human critical thinking, empathy, creativity, and intuition in the strategic decision-making process, will be fundamentally destabilizing if defense planners come to view AI’s ‘support’ function as a panacea for the cognitive fallibilities and human analysis and decision-making. The article also considers the nefarious use of AI-enhanced fake news, deepfakes, bots, and other forms of social media by non-state actors and state proxy actors, which might cause states to exaggerate a threat from ambiguous or manipulated information, increasing instability. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
J5K2PRFU;journalArticle;2020;"Lima Dantas, D.; Filgueiras, L.V.L.; Brandão, A.A.F.; Machado Domingues, M.C.; Ferreira, M.R.";Detecting IoT Applications Opportunities and Requirements Elicitation: A Design Thinking Based Approach;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-50344-4_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740148&doi=10.1007%2f978-3-030-50344-4_7&partnerID=40&md5=82f5cd968cdecbc941b929dd7ba6216c;IoT development is complex. To reduce this complexity, IoT platforms provide a set of resources and functionalities to enable application development and support its execution. In this work, we present a human-centered approach for requirements elicitation and mapping them to application resources in IoT platforms, using empathy, definition and ideation methods. A previous study by the authors has identified 11 categories of resources provided by 47 IoT platforms to developers in their application layers. From this set, 6 categories were selected for this work: schedulers and triggers, message and notification triggers, big data and analytics, artificial intelligence and machine learning, dashboards, and services. We invited 18 members of 8 projects for a workshop and divided them in 4 teams, according their project areas, which are: Industry 4.0 (6 participants), Environmental Disasters (4 participants), Environmental Management (3 participants) and Pollution (5 participants). We divided the workshop in 3 phases: warm-up, with user journey mapping, requirements identification using “how might we” questions as a trigger and requirements clustering the questions by the 6 selected categories of resources or an extra category named “others” for those which could not be related to any previous category. Our contribution for the IoT application development is an approach for turning easier requirements elicitation using DT techniques, covering the stages of empathise, definition and ideation, with well-available materials and considering the resources present at application layer of IoT platforms. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;85-100;NA;NA;12203 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Q8HJJHMU;journalArticle;2019;"Lee, Y.; Ha, M.; Kwon, S.; Shim, Y.; Kim, J.";Egoistic and altruistic motivation: How to induce users’ willingness to help for imperfect AI;Computers in Human Behavior;NA;NA;10.1016/j.chb.2019.06.009;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069643866&doi=10.1016%2fj.chb.2019.06.009&partnerID=40&md5=28cafea9d01522cf0bc054743c000c61;Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI. © 2019;2019;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;180-196;NA;NA;101;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
NH8ZSMQ7;conferencePaper;2019;Chiu, K.C.;Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation;IEEE International Conference on Industrial Engineering and Engineering Management;NA;NA;10.1109/IEEM44572.2019.8978876;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079589864&doi=10.1109%2fIEEM44572.2019.8978876&partnerID=40&md5=9e2b70a2e94f2f185efda9854aa1323f;This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence. © 2019 IEEE.;2019;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;1516-1520;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FD3V8R64;conferencePaper;2019;"Franzoni, V.; Milani, A.; Biondi, G.; Micheli, F.";A preliminary work on dog emotion recognition;Proceedings - 2019 IEEE/WIC/ACM International Conference on Web Intelligence Workshops, WI 2019 Companion;NA;NA;10.1145/3358695.3361750;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074373338&doi=10.1145%2f3358695.3361750&partnerID=40&md5=28643a3c506d284761d30c4e16a889af;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence. © 2019 Copyright held by the owner/author(s).;2019;2021-02-15T22:33:59Z;2021-02-15T22:33:59Z;NA;91-96;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BS8HS2CZ;journalArticle;2019;Bristol, R.C.;An Essay on Narrative, Reality, and Imagination;Psychoanalytic Inquiry;NA;NA;10.1080/07351690.2019.1659025;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074169447&doi=10.1080%2f07351690.2019.1659025&partnerID=40&md5=e63ea1dc96732323847d76ffb96ead71;"Narrative is a verbal account, a story of related events which can be factual, fictional or both. Life experience and imagination are as essential to narrative as narrative is to mankind. The phylogenic perspective of literature suggests an inborn capacity for empathy, intelligence and inventiveness, whereas the ontological example is variable. Western knowledge, politics and ethics have evolved from their narrative of Greek myth, epic and drama, the few medieval writers, singularly by the Elizabethan theater, importantly the Arthurian legend and romance stories, English and Russian novels, and uniquely the American short story. This heritage progressively demarcated such life themes as the hero, maiden and adversary; love, hate and indifference; loyalty, deception and betrayal; desire, achievement and loss. These characterizations of self and other remain relevant to the contemporary novel, cinema/TV, and theater, as well as the news, commentary, and real life. Conversely, postmodern assumptions challenge that individual subjectivity determines what is real, valid or authentic, consequently the relativism of traditional, institutional and historical precedents of the truth. Further, the computer, gaming, smart device, and artificial intelligence have changed the content and function of customary narrative. Nonetheless, narrative — real and imagined, ancient and new — retains the meaning of a story about connected events which variously transcends the boundaries of difference. ©, Copyright © Melvin Bornstein, Joseph Lichtenberg, Donald Silver.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;476-484;NA;7;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WL23FZWH;journalArticle;2019;Powell, J.;Trust me, i'm a chatbot: How artificial intelligence in health care fails the turing test;Journal of Medical Internet Research;NA;NA;10.2196/16222;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074230200&doi=10.2196%2f16222&partnerID=40&md5=f07051700ad8b816ddd71e05e867d094;Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. © 2019 John Powell.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WE7NX3IC;journalArticle;2019;"Gong, C.; Lin, F.; Zhou, X.; Lu, X.";Amygdala-inspired affective computing: To realize personalized intracranial emotions with accurately observed external emotions;China Communications;NA;NA;10.23919/JCC.2019.08.011;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072068065&doi=10.23919%2fJCC.2019.08.011&partnerID=40&md5=3572d915fbee1668aed2dea06ab6916b;Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected. © 2013 China Institute of Communications.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;115-129;NA;8;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RB6G29YR;journalArticle;2019;"Brocker, L.; Fazilleau, C.; Naudin, D.";Artificial intelligence in medicine: benefits and limits [L'intelligence artificielle en médecine: intérêts et limites];Oxymag;NA;NA;10.1016/j.oxy.2019.06.003;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074056912&doi=10.1016%2fj.oxy.2019.06.003&partnerID=40&md5=57183ca6f74749e13959cc6e9b952387;Artificial intelligence (AI) has been developed in the field of healthcare in order to help professionals improve their efficiency, their productivity and their consistency in the quality of care provided to patients. The use of artificial intelligence in fields such as imaging or medicines management has proved to be effective. There is no doubt that it exceeds the analysis capability of humans. Nevertheless, in many other fields, AI cannot equal human intelligence as the latter's complexity cannot be copied. The brain's ability to adapt, consciousness and subjectivity as well as qualities essential for decision-making such as empathy still remain unique to humans. © 2019 Elsevier Masson SAS L’intelligence artificielle a été développée dans le domaine de la santé afin d’aider les professionnels à améliorer leur efficacité, leur productivité et leur constance dans la qualité des soins apportés aux patients Ses applications dans des domaines tels que l’imagerie ou la gestion des médicaments ont montré son efficacité Sans nul doute, l’intelligence artificielle dépasse la capacité d’analyse humaine Dans bien d’autres domaines, elle ne peut pourtant égaler l’intelligence humaine dont la complexité ne peut être copiée La capacité du cerveau à s’adapter, à laquelle s’ajoutent la conscience et la subjectivité, ainsi que les qualités essentielles à la prise de décision comme l’empathie, restent encore le propre de l’homme. © 2019 Elsevier Masson SAS;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;8-13;NA;167;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X85UMYPW;conferencePaper;2019;"Antle, A.N.; Sadka, O.; Radu, I.; Gong, B.; Cheung, V.; Baishya, U.";Emototent: Reducing school violence through embodied empathy games;Proceedings of the 18th ACM International Conference on Interaction Design and Children, IDC 2019;NA;NA;10.1145/3311927.3326596;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068777726&doi=10.1145%2f3311927.3326596&partnerID=40&md5=97a693937d75a70c18a1fc709fe74d36;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being. © 2019 Association for Computing Machinery.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;755-760;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
T9HQSWJM;journalArticle;2019;Hueso, L.C.;Ethics in design for the development of an artificial intelligence, trustworthy robotics and big data and their utility for the law [Ética en el diseño para el desarrollo de una inteligencia artificial, robótica y big data confiables y su utilidad desde el derecho];Revista Catalana de Dret Public;NA;NA;10.2436/rcdp.i58.2019.3303;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602971&doi=10.2436%2frcdp.i58.2019.3303&partnerID=40&md5=863eada5a2fd83cae50e563f874c41e9;"The study deals with the ethics of artificial intelligence (AI). Firstly, we explain the proclamation of the ethics and its necessity in the different international reference documents, although the analysis is focused on the actions carried out in the European Union. It is precisely in the EU where there is a special commitment to developing an ethics for a trustworthy AI in design and made in Europe, to position itself in front of United States and especially China, two countries that don’t pay much attention to the issue. Firstly, we describe the content of ethics of AI and its essential principles from the point of view of the dignity and rights; second, we describe the main five principles contained in the international declarations. Third, we include other basic principles which arise from the demands of empathy with humans. From a somewhat sceptical perspective, we argue the potential utilities of ethics of AI for the law: it is considered to be an especially preventive instrument and that an ethical governance of AI can be developed, following the examples of policies and frameworks on public ethics and institutional integrity. The phases to be followed are described in this regard. We explain in detail the opportunity and the basic content of codes of conduct and committees and other control systems. Finally, we make an appeal for the design of algorithms that serve as guardians of regulatory compliance and the ethics of AI. © 2019, Public Administration School of Catalonia. All rights reserved.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;29-48;NA;58;2019;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GLS97G4J;journalArticle;2019;"Clavelle, J.T.; Sweeney, C.D.; Swartwout, E.; Lefton, C.; Guney, S.";Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition;Journal of Nursing Administration;NA;NA;10.1097/NNA.0000000000000757;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931093&doi=10.1097%2fNNA.0000000000000757&partnerID=40&md5=c67866ef50603649810f548af2d47672;Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented. © Wolters Kluwer Health, Inc. All rights reserved.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;303-309;NA;6;49;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BMINYE3Y;journalArticle;2019;"Sanal, M.G.; Paul, K.; Kumar, S.; Ganguly, N.K.";Artificial intelligence and deep learning: The future of medicine and medical practice;Journal of Association of Physicians of India;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067569100&partnerID=40&md5=cc6799f54fa56c639d845a3e9b5806d1;Artificial Intelligence (AI) and access to “Big Data” together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (“wiki”) with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition. © 2019, Journal of Association of Physicians of India. All rights reserved.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;71-73;NA;May;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FFHSAZL4;journalArticle;2019;Arnar, D.O.;Digital cardiology, artificial intelligence and the value of empathy;Laeknabladid;NA;NA;10.17992/lbl.2019.04.223;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064007194&doi=10.17992%2flbl.2019.04.223&partnerID=40&md5=f8dffc44ae531b62aa2fa71d2f556f75;NA;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;159;NA;4;105;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HD3NRUL7;journalArticle;2019;"Blease, C.; Kaptchuk, T.J.; Bernstein, M.H.; Mandl, K.D.; Halamka, J.D.; Desroches, C.M.";Artificial intelligence and the future of primary care: exploratory qualitative study of UK general practitioners' views;Journal of Medical Internet Research;NA;NA;10.2196/12802;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063303215&doi=10.2196%2f12802&partnerID=40&md5=41136ee763c24454922fbdbed2e48d68;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPS') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPS' opinions about the likelihood of future technology to fully replace GPS in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPS also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPS believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPS considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPS' views. © 2019 Journal of Medical Internet Research. All rights reserved.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;NA;NA;3;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 15</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
IM4NTZK6;journalArticle;2019;"Wartman, S.A.; Combs, C.D.";Reimagining medical education in the age of AI;AMA Journal of Ethics;NA;NA;10.1001/amajethics.2019.146;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061990597&doi=10.1001%2famajethics.2019.146&partnerID=40&md5=eb1325df514ae1ebc5c6e2532c89d224;Available medical knowledge exceeds the organizing capacity of the human mind, yet medical education remains based on information acquisition and application. Complicating this information overload crisis among learners is the fact that physicians' skill sets now must include collaborating with and managing artificial intelligence (AI) applications that aggregate big data, generate diagnostic and treatment recommendations, and assign confidence ratings to those recommendations. Thus, an overhaul of medical school curricula is due and should focus on knowledge management (rather than information acquisition), effective use of AI, improved communication, and empathy cultivation. ©2019 American Medical Association.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;146-152;NA;2;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 21</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UVJDY829;conferencePaper;2019;"Das, A.K.; Ashrafi, A.; Ahmmad, M.";Joint cognition of both human and machine for predicting criminal punishment in judicial system;2019 IEEE 4th International Conference on Computer and Communication Systems, ICCCS 2019;NA;NA;10.1109/CCOMS.2019.8821655;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071115729&doi=10.1109%2fCCOMS.2019.8821655&partnerID=40&md5=c2141b9cb6d314f80753bcccba34ada4;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can’t only perform faster but also predict better than human. But a human has some qualities which can never be gained by a Machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to ‘Women and Children Repression Prevention Act, 2000’. We apply several Machine learning algorithms to make a Machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide Machine for judging a delinquent. © 2019 IEEE.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;36-40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZPTHVNYX;conferencePaper;2019;Shvo, M.;Towards empathetic planning and plan recognition;AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society;NA;NA;10.1145/3306618.3314307;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070635759&doi=10.1145%2f3306618.3314307&partnerID=40&md5=69bd49013c7283146e3d8efb1d0c94a9;Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants. © 2019 Copyright held by the owner/author(s).;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;525-526;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZBI5F9NV;journalArticle;2019;"Varlamov, O.O.; Chuvikov, D.A.; Adamova, L.E.; Petrov, M.A.; Zabolotskaya, I.K.; Zhilina, T.N.";Logical, philosophical and ethical aspects of AI in medicine;International Journal of Machine Learning and Computing;NA;NA;10.18178/ijmlc.2019.9.6.885;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077569724&doi=10.18178%2fijmlc.2019.9.6.885&partnerID=40&md5=b1dc5825375f976debfee3cffa094d4c;"The logical type of Artificial Intelligence is presented in the article. MIVAR (Multidimensional Informational Variable Adaptive Reality) technology is based on the gnoseological triplet concept ""Thing - Property - Relationship."" The unlimited number of MIVAR units fill the MIVAR space that makes it communicatory, discrete, and scalable. MIVAR information processing allows creating complicated algorithms for medicine. We have chosen the clinical model of pain in the heart for preparation ontology for doctors. Knowledge expert model MIVAR WiMi ""Chest Pain"" is shown. The logical Artificial Intelligence (expert model) can help doctors fast, precisely and in the best way in the decision-making process. Except medical ontology Artificial Intelligence must have an empathic, emotional experience, without that medical care cannot be imagined. MIVAR technology is the closest to human thinking among other Artificial Intelligence technologies; it differs from the Artificial network of Mirror neurons, related to emotional perception, but MIVAR space with rules and constraints can imitate emotions and empathy. © 2019 International Association of Computer Science and Information Technology.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;868-873;NA;6;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UMZHKZ72;journalArticle;2019;Solé, J.P.;Artificial intelligence, administrative law and mankind reservation: algorithms and due technological process [Inteligencia artificial, derecho administrativo y reserva de humanidad: algoritmos y procedimiento administrativo debido tecnológico];Revista General de Derecho Administrativo;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068589087&partnerID=40&md5=e4350872b2bcf9ffdc0e541e5080fcba;After analyzing the situation in Spain, it suggests some regulatory improvements in accordance to international ideas and regulations. The study recommends a reservation for human intervention in the case of discretionary powers due to the need of human empathy for their proper exercise. It includes some measures against opacity of algorithms to guarantee the right to good administration and specially its expressions as a right to understand public decisions. © 2019 Revista General de Derecho Administrativo. All rights reserved.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;NA;NA;50;2019;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3LZ5ZRWW;conferencePaper;2019;"Takano, M.; Tsunoda, T.";Self-disclosure of bullying experiences and social support in avatar communication: Analysis of verbal and nonverbal communications;Proceedings of the 13th International Conference on Web and Social Media, ICWSM 2019;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070376669&partnerID=40&md5=c4980b3e2f1fec8b0a980aab67deb0fa;Avatar communication through the Internet has great potential to be an appropriate environment for self-disclosure and social support. Anonymity and ease of access drive self-disclosure of even the most serious problems. Rich nonverbal communication, co-presence, and real-time interaction increase emotional closeness. However, there has not been much research with regard to examining social support in avatar communication. In this paper, we aim to facilitate self-disclosure and social support for bullied people through avatar communication. For this purpose, we analyzed verbal and nonverbal communication about bullying experiences through an avatar communication service. We demonstrate that people who emotionally disclosed their bullying experiences received better social support. In addition, people who provided social support used emotional expressions to convey emotional empathy. These were observed in conversations with a few acquaintances in closed spaces. Our findings reveal areas where we can improve upon the design of avatar communication spaces for effective social support. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;473-481;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CHI9ZAIM;journalArticle;2019;Bhalla, N.;The 3S process: A framework for teaching AI strategy in business education;Technology Innovation Management Review;NA;NA;10.22215/timreview/1290;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082424709&doi=10.22215%2ftimreview%2f1290&partnerID=40&md5=71f1e049ab206f1122d9f31a5dba4ee8;"A gap has emerged in teaching artificial intelligence (AI) in business education, where a style of curriculum based on strategy is missing. This article presents a new framework, the 3S Process, as a method for teaching leaders how to strategically adopt AI within their organizations. At a high-level, the 3S Process consists of three stages (Story, Strategy, and Solution), which are described in detail in the article. Stage 1: Story in the process is inspired by the Harvard Case Method to provide context for a problem. Stage 2: Strategy uses Design Thinking to produce candidate solutions. The substage of Empathy in Design Thinking plays a crucial role to reduce bias in designing AI. Virtualization technology is a tool for students to experience hands-on learning in prototype development. Stage 3: Solution is where students advocate for their conceptual AI solution in the context of the case study. AI is a type of complex system; therefore, students should consider feedback loops and the potential for unintended biases to enter a deployed solution. The presentation of the 3S Process in this article is conceptual. Further empirical studies, including evaluations of the 3S Process in classroom settings, will be considered in the future. © 2019 Carleton University. All Rights Reserved.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;36-42;NA;12;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HY49NUYS;journalArticle;2019;"Franzoni, V.; Milani, A.";Emotion Recognition for Self-aid in Addiction Treatment, Psychotherapy, and Nonviolent Communication;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-24296-1_32;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069166203&doi=10.1007%2f978-3-030-24296-1_32&partnerID=40&md5=9fd3cca43de6e1c5747776bab3c03cf0;"This position paper aims to highlight possible future directions of applications for Affective Computing (AC) and Emotion Recognition (ER) for self-aid applications, as they emerge from the experience of the ACER-EMORE Workshops Series. ER in Artificial Intelligence offers a growing number of problem-solving multidisciplinary opportunities. Most current AC and ER applications are focused on a somewhat controversial enterprise-centered approach, i.e., recognizing user emotions to enable a third-party to achieve its own goals, in areas such as e-commerce, cybersecurity, behavior profiling, user experience. In this work we propose to explore a human-centered research direction, aiming at using AC/ER to enhance user consciousness of emotional states, ultimately supporting the development of self-aid applications. The use of facial ER and text ER to help forms of assistive technologies in the fields of Psychotherapy and Communication is an example of such a human-centered approach. A general framework for ER in Self-aid is depicted, and some relevant application domains are suggested and discussed: dependencies treatment (DT) (e.g., workaholism, sexaholism); non-violent communication (NVC) for people in leading roles using e-mail or chat communication; empathy learning for parents and teachers in the circle-of-security (COS) caring environment. Far from being complete and comprehensive, the purpose of this work is to trigger discussions and ideas for feasible studies and applications of ER in self-aid, which we hope to see published in the future editions of our workshops, believing that it may be one of the drops needed in the ocean of a better world. © 2019, Springer Nature Switzerland AG.";2019;2021-02-15T22:34:00Z;2021-02-15T22:34:00Z;NA;391-404;NA;NA;11620 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DS75ZP5V;journalArticle;2019;"Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.";A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study;Journal of Medical Internet Research;NA;NA;10.2196/14658;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.;2019;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
368532YI;journalArticle;2018;Weber, A.S.;Emerging medical ethical issues in healthcare and medical robotics;International Journal of Mechanical Engineering and Robotics Research;NA;NA;10.18178/ijmerr.7.6.604-607;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056576175&doi=10.18178%2fijmerr.7.6.604-607&partnerID=40&md5=497839d4cdb779d178e34f97ca54283a;Due to the increasing sophistication and complexity of autonomous machines, Artificial Intelligence, Computerized Decision Support Systems (CDSS), natural language question-answering robots, and social / emotive medical robots, new medical ethics conundrums are arising. Unresolved questions revolve around autonomy, responsibility, empathy, trust, moral agency and the social and economic impacts of medical robots. © 2018 Int. J. Mech. Eng. Rob. Res.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;604-607;NA;6;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HSMDWS93;journalArticle;2018;"Inkster, B.; Sarda, S.; Subramanian, V.";An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study;JMIR mHealth and uHealth;NA;NA;10.2196/12106;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f;"Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.";2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;NA;NA;11;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 58</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
J4X7J8ZW;journalArticle;2018;"Yalcin, O.N.; Dipaola, S.";A computational model of empathy for interactive agents;Biologically Inspired Cognitive Architectures;NA;NA;10.1016/j.bica.2018.07.010;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050357957&doi=10.1016%2fj.bica.2018.07.010&partnerID=40&md5=6cb0808ca3ac7e67ad477c8fee67392d;Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents. © 2018 Elsevier B.V. All rights reserved.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;20-25;NA;NA;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SHZS93I8;journalArticle;2018;Johnston, S.C.;Anticipating and Training the Physician of the Future: The Importance of Caring in an Age of Artificial Intelligence;Academic medicine : journal of the Association of American Medical Colleges;NA;NA;10.1097/ACM.0000000000002175;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050403831&doi=10.1097%2fACM.0000000000002175&partnerID=40&md5=ba7c843dd7d3e8f51b8914002c463db1;Artificial intelligence and other forms of information technology are only just beginning to change the practice of medicine. The pace of change is expected to accelerate as tools improve and as demands for analyzing a rapidly growing body of knowledge and array of data increase. The medical students of today will practice in a world where information technology is sophisticated and omnipresent. In this world, the tasks of memorization and analysis will be less important to them as practicing physicians. On the other hand, the nonanalytical, humanistic aspects of medicine-most importantly, the art of caring-will remain a critical function of the physician, and facility with improving systems of care will be required. Communication, empathy, shared decision making, leadership, team building, and creativity are all skills that will continue to gain importance for physicians. These skills should be further prioritized in medical school curricula to produce an even more effective physician for the future.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;1105-1106;NA;8;93;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 18</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HXBXX8PN;conferencePaper;2018;"Y Restrepo, E.G.; Boticario, J.G.";Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future;2017 International Conference on Engineering, Technology and Innovation: Engineering, Technology and Innovation Management Beyond 2020: New Challenges, New Approaches, ICE/ITMC 2017 - Proceedings;NA;NA;10.1109/ICE.2017.8280067;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047627034&doi=10.1109%2fICE.2017.8280067&partnerID=40&md5=dcfa25236d464d9783d4a9c0c7675df2;This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society. © 2017 IEEE.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;1552-1558;NA;NA;2018-January;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
F7HFMQPT;conferencePaper;2018;Kouzov, O.;Art, social and culture education supported by artificial intelligence tools;Digital Presentation and Preservation of Cultural and Scientific Heritage;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063348999&partnerID=40&md5=4ee842958b24c16cf7fad0f082796b2c;The use of tools, based on AI, will become a regular practice in education due to the dynamic social development. The role of the artificial intelligence in social sciences, arts and culture is key to the achievement of emotional empathy of people in view of the future symbiosis of man and machine. © 2018 Digital Presentation and Preservation of Cultural and Scientific Heritage.All Rights Reserved.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;111-119;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
I62ICQN8;journalArticle;2018;Kolonin, A.;Resource-constrained social evidence based cognitive model for empathy-driven artificial intelligence;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-97676-1_10;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051425417&doi=10.1007%2f978-3-319-97676-1_10&partnerID=40&md5=10c85a843431a41274b2e5042aaa682a;Working model of social aspects of human and non-human intelligence is required for social embodiment of artificial general intelligence systems to explain, predict and manage behavioral patterns in multi-agent communities. For this purpose, we propose implementation of resource-constrained social evidence based model and discuss possible implications of its application. © 2018, Springer Nature Switzerland AG.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;100-108;NA;NA;10999 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
W78X3X2D;journalArticle;2018;"Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.";Approaches for generating empathy: A systematic mapping;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-319-54978-1_89;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f;Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;715-722;NA;NA;558;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X94CZTTJ;conferencePaper;2018;"Jaidka, K.; Guntuku, S.C.; Ungar, L.H.";Facebook versus twitter: Cross-platform differences in self-disclosure and trait prediction;12th International AAAI Conference on Web and Social Media, ICWSM 2018;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050628739&partnerID=40&md5=056ed358ec0669149b0e51c0ffbec73d;This study compares self-disclosure on Facebook and Twitter through the lens of demographic and psychological traits. Predictive evaluation reveals that language models trained on Facebook posts are more accurate at predicting age, gender, stress, and empathy than those trained on Twitter posts. Qualitative analyses of the underlying linguistic and demographic differences reveal that users are significantly more likely to disclose information about their family, personal concerns, and emotions and provide a more 'honest' self-representation on Facebook. On the other hand, the same users significantly preferred to disclose their needs, drives, and ambitions on Twitter. The higher predictive performance of Facebook is also partly due to the greater volume of language on Facebook than Twitter - Facebook and Twitter are equally good at predicting user traits when the same-sized language samples are used to train language models. We explore the implications of these differences in cross-platform user trait prediction. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;141-150;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4C5FKSCZ;journalArticle;2018;"Tory Toole, J.; Kurian, P.; Craddock, T.J.A.";Coherent energy transfer and the potential implications for consciousness;Journal of Cognitive Science;NA;NA;10.17791/jcs.2018.19.2.115;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050143668&doi=10.17791%2fjcs.2018.19.2.115&partnerID=40&md5=ceeeecd1e033f898418e72908f6fc7cc;"The argument that biological systems are too ""warm and wet"" to support quantum effects is becoming increasingly antiquated as research in the field of quantum biology progresses. In fact, not only is it becoming apparent that quantum processes may regularly take place in biological systems, but these processes may underlie the mechanisms of consciousness and propel our models of conceptualizing the human brain into the next era of scientific understanding. The phenomena of consciousness have allured scientists and philosophers for thousands of years, while a precise technical understanding has remained elusive. If possible, developing this understanding will likely be one of humanity's greatest achievements. Knowing the fundamental processes that create conscious experience has far-reaching implications, from the potential birth of true artificial intelligence to a better understanding of mental health disorder etiologies and treatments. One major challenge in the mental health professions, and, ultimately, in empathy of any kind, is being able to see from and appreciate another person's unique, subjective experience. Discoveries in the field of consciousness could help bridge this gap. © 2018 Institute for Cognitive Science, Seoul National University.";2018;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;115-124;NA;2;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7BS7FKYM;journalArticle;2017;Moritz, J.;Augmented humanity;Technoetic Arts;NA;NA;10.1386/tear.15.3.341_1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042419209&doi=10.1386%2ftear.15.3.341_1&partnerID=40&md5=6a9d2d151fb5d856a706e0b47ec99161;Augmented Reality (AR) is commonly defined as a digital layer of information viewed on top of the physical world through a smartphone, tablet or eyewear. Increasingly, this understanding of AR is shifting to a dynamic framework of 'smart things', including wearable technology, sensors and artificial intelligence (AI), with the ability to intercede in key moments and to deliver contextual and meaningful experiences. The things that come into context are the logical next steps in an evolutionary development towards computers that are better able to show empathy in relation to people: even more human-oriented, anticipative and ubiquitous. Thus, this outsourcing of meaning to empathic technologies points to one of the fundamental questions concerning the relation of human and technology - the nature of the trust that users place in technology. © 2017 Intellect Ltd.;2017;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;341-352;NA;3;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TDEPVMTR;conferencePaper;2017;"Abdul-Mageed, M.; Buffone, A.; Peng, H.; Giorgi, S.; Eichstaedt, J.; Ungar, L.";Recognizing pathogenic empathy in social media;Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453209&partnerID=40&md5=7649bbca2c296ce3a22690e6454b92c3;"Empathy is an integral part of human social life, as people care about and for others who experience adversity. However, a specific ""pathogenic"" form of empathy, marked by automatic contagion of negative emotions, can lead to stress and burnout. This is particularly detrimental for individuals in caregiving professions who experience empathic states more frequently, because it can result in illness and high costs for health systems. Automatically recognizing pathogenic empathy from text is potentially valuable to identify at-risk individuals and monitor burnout risk in caregiving populations. We build a model to predict this type of empathy from social media language on a data set we collected of users' Facebook posts and their answers to a new questionnaire measuring empathy. We obtain promising results in identifying individuals' empathetic states from their social media (Pearson r = 0.252, p < 0.003). © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.";2017;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;448-451;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MPZWESIA;journalArticle;2017;Boella, L.;How to do the best without emotions?;Notizie di Politeia;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031102019&partnerID=40&md5=02472ddee9b8e3ba675d6a7b498143df;"From the richness of Harris' consideration of the main aspects of the contemporary debate - the nature of good, the question of the ""human"", post-human and of non-human animals, of freedom as being master of our lives, of Artificial Intelligence - I draw out the building block of the morality as ""trying to be good"". To be a good person implies insight, sympathy, empathy, understanding and knowledge to build clear ideas of what might conduce to the good.";2017;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;184-186;NA;127;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
IZMUPFAB;conferencePaper;2016;"Liu, X.; London, K.";T.A.I: A tangible AI interface to enhance human-artificial intelligence (AI) communication beyond the screen;DIS 2016 - Proceedings of the 2016 ACM Conference on Designing Interactive Systems: Fuse;NA;NA;10.1145/2901790.2901896;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978646804&doi=10.1145%2f2901790.2901896&partnerID=40&md5=0872ed99d2fa2b941be3307017eb6085;Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.;2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;281-285;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
U2UVRBUV;conferencePaper;2016;"Headleand, C.J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L.A.";Does the Perceived Identity of Non-player Characters Change How We Interact with Them?;Proceedings - 2015 International Conference on Cyberworlds, CW 2015;NA;NA;10.1109/CW.2015.35;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964255469&doi=10.1109%2fCW.2015.35&partnerID=40&md5=0e24ff4477d953ab395db33157d255bf;Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it. © 2015 IEEE.;2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;145-152;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4YQY6NYT;conferencePaper;2016;"Kido, T.; Swan, M.";Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51;"Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.";2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;362-368;NA;NA;SS-16-01 - 07;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CWE9PAAU;journalArticle;2016;"Mototake, Y.-I.; Fukuda, H.; Ueda, K.";Creating an in-group relation between humans and agents;Transactions of the Japanese Society for Artificial Intelligence;NA;NA;10.1527/tjsai.AI30-J;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994593462&doi=10.1527%2ftjsai.AI30-J&partnerID=40&md5=e45a827b07fe39236bdc7097263cb4cc;The purpose answer the question whether an artificial agent can build or not an in-group relation with a human. To answer this, we created a three-way discussion setting between a participant and two artificial agents: One agent took the same opinion as a participant while the other did the opposite. This resulted in a feeling of group identity between the participant and the first agent, i.e. the same side. This feeling of group identity was shown to be detected using error-related negativity (ERN), a component of an event-related potential that accompanies errors in speeded performance. We found that amplitude of ERN was bigger for the same side agent’s failure than for the other side’s. We also found ERN difference correlated to an empathy ability detected by a questionnaire. From these results, we can say that a person can form an in-group relation between an artificial agent, which can be detected by ERN. © 2016, Japanese Society for Artificial Intelligence. All rights reserved.;2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;NA;NA;6;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
I4P8FQRC;journalArticle;2016;"Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.";Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents;Transactions of the Japanese Society for Artificial Intelligence;NA;NA;10.1527/tjsai.C-G31;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a;There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.;2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;NA;NA;4;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X7IQBZ76;conferencePaper;2016;Lok, B.;Training with virtual operating room teammates to influence team behaviors;Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016;NA;NA;10.1109/CTS.2016.115;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016990802&doi=10.1109%2fCTS.2016.115&partnerID=40&md5=43b8f2a891be99dc9798e92fe575cfde;Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care? In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room. We will examine the latest research into simulating healthcare teams with mixed reality humans. Mixed reality humans are virtual humans that can share the same physical space as the user. These virtual humans combine interactive graphics, natural language processing, artificial intelligence, human-computer interaction, and data mining to create in situ learning experiences. In these learning experiences, critical care personnel can work to improve teamwork with life-sized interactive virtual team-mates [1]. These learning experiences can also help implement best-practices to address address difficult teamwork concepts such as authority gradients, conflict negotiation, empathy and critical thinking [2][3]. Our research team (Samsun Lampotang, Anesthesia Department, University of Florida, Adam Wendling, Anesthesia Department, University of Florida, and Casey White, College of Medicine, University of Virginia) has developed VR hardware and software platforms to create compelling experiences for users to work on teams with mixed reality humans (MRHs). MRHs are virtual humans that can inhabit the user's physical space [4]. The MRH virtual team members can respond to the user's speech and actions and respond with natural speech and gestures. The virtual team members cannot physically interact with the environment. However, they can present realistic personalities and role-play the roles of operating room teammates, such as surgeons, anesthesiologists, nurses, and surgical technicians. The virtual team members combine the benefits of dynamic visuals of virtual humans with the physicality of mannequins (Figure 1). (Figure Presented) The virtual teammates are composed of comprise a minitower desktop for computation, networking, and rendering, a 40′ TV for display, and a Microsoft Kinect® (version 2) for tracking. All of these components are mounted onto a TV stand. Additionally, a Sennheiser DW-Pro 1 wireless headset is used for speech capture. ANDI's torso, arms, and head are rendered using a virtual human model from Autodesk's Character Generator. The virtual teammate's legs were physical and were composed of shoes and pants filled with stuffing. The physical props were used to integrate the virtual teammate into the user's space. A series of studies evaluated the social presence impact of ANDI design decisions and the current system configuration was shown to provide a virtual teammate with which participants reported a high sense of presence [5]. The virtual teammates' audio responses are pre-recorded by voice talent, and gestures are generated using motion capture and professionally key-framed animations. The virtual teammates can gaze at whoever is speaking, and intermittently glance at the other team members. They also blink and mimic idle motions when not speaking. We will examine results from studies evaluating the perception of virtual teammates, lessons learned in integrating such systems into hospital training, and areas for future research. © 2016 IEEE.;2016;2021-02-15T22:34:01Z;2021-02-15T22:34:01Z;NA;615-616;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SM73UZ9B;journalArticle;2015;"Vallverdú, J.; Casacuberta, D.";Ethical and technical aspects of emotions to create empathy in medical machines;Intelligent Systems, Control and Automation: Science and Engineering;NA;NA;10.1007/978-3-319-08108-3_20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e;This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;341-362;NA;NA;74;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QLIHZWYJ;journalArticle;2015;"Ceschi, A.; Scalco, A.; Dickert, S.; Sartori, R.";Compassion and prosocial behavior. Is it possible to simulate them virtually?;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-319-19629-9_23;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946410442&doi=10.1007%2f978-3-319-19629-9_23&partnerID=40&md5=1d820a863bf587f7f0f85fe86d00561e;In the field of artificial intelligence, a question dealing with computer and cognitive science is arising and becoming more and more crucial: Can we design agents so sophisticated that they are capable of mimicking emotional behaviors in general as well as specific emotions like compassion or empathy? Despite the production of different computational models, their integration with cognitive and psychological theories remains a central problem. Reasons are both methodological and theoretical. Primarily, it is difficult to quantify the impact of such factors as individual differences, inclinations and personality traits. In addition, Agent-Based Models (ABMs) often use linear dynamics, even in describing emotions, without considering the basis of psychophysics. Bearing in mind this and focusing on compassion as a particular emotion, the paper aims to present a “Decalogue” for those interested in designing agents capable of mimicking human emotional behaviors. In the paper, compassion will be translated as prosocial behavior. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;207-214;NA;NA;372;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8EIQDB4F;journalArticle;2015;"Gil, P.; Rossi, C.; Coral, W.";Biophilic evolutionary buildings that restore the experience of animality in the city;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-22979-9_47;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947104679&doi=10.1007%2f978-3-319-22979-9_47&partnerID=40&md5=906ff7465fc2103a0556f85aed9a7a97;In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible –or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa¸cade that learns optimal configurations according to the perception of aggressiveness and calmness. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;465-472;NA;NA;9222;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
E86CUKZ2;conferencePaper;2014;"Tasse, D.; Hong, J.";Finding a city's activity bubbles in geotagged social media;AAAI Workshop - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974839179&partnerID=40&md5=3e5a9de773f53deb957cb6edd66ebbb1;"Bill Bishop popularized the idea that we all live in a self-curated world of bubbles in his book, ""The Big Sort"" (Bishop 2009). People often spend most of their time in completely different places from their neighbors, and this fragmentation of society leads to reduced empathy, policy quarrels, and even violence. People may not even be aware that they are segregating themselves so dramatically. Fortunately, thanks to the abundance of available geotagged social media data, we can easily and cheaply detect these social bubbles and give people a greater insight into their activity patterns. Understanding how we spend our time can be the first step in changing from isolated citizens into a connected community. © Copyright 2014. Association for the Advancement of Artificial Intelligence (www.aaai.org).All rights reserved.";2014;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;33-34;NA;NA;WS-14-20;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LVAY9BYE;conferencePaper;2014;"Rzepka, R.; Araki, K.";Experience of crowds as a guarantee for safe artificial self;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904869125&partnerID=40&md5=8fd797ff6e2f229cb3b785a938a3df20;In this paper we introduce an approach for achieving a self that is able to simulate average ethical intuitions by retrieving knowledge about human behavior from the Internet resources. We show how applying text mining techniques could be useful for virtual and physical agents which base their knowledge on natural language. We discuss the importance of empathy and pros and cons of crowd experience based algorithm, then we introduce our thoughts on possibility of manufacturing agents for particular purposes as behavior analyzers or moral advisors which could refer to millions of different experiences had by people in various cultures. We think such systems could lead to selves that are capable to non-biased decisions morally superior to these of average human. Copyright © 2014, Association for the Advancement of Artificial Intelligence. All rights reserved.;2014;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;40-44;NA;NA;SS-14-03;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GVMX9VX3;conferencePaper;2014;"Majot, A.M.; Yampolskiy, R.V.";AI safety engineering through introduction of self-reference into felicific calculus via artificial pain and pleasure;2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, ETHICS 2014;NA;NA;10.1109/ETHICS.2014.6893398;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929249460&doi=10.1109%2fETHICS.2014.6893398&partnerID=40&md5=394f38624e7a494b0cae76589c4ef386;"In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of ""moral mathematics"" felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed. © 2014 IEEE.";2014;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5THALCUF;conferencePaper;2013;"Kido, T.; Swan, M.";Exploring the mind with the aid of personal genome - Citizen science genetics to promote positive weil-being;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883338761&partnerID=40&md5=faa8ca187f27af10799d276c75cfc596;"Understanding the human mind and increasing individual happiness are important goals in Artificial Intelligence (AI) and well-being science. The recent revolution in portable self-tracking devices in the data-driven wellness movement and participatory-driven wellness communities, such as the Quantified Self community, provides us with new opportunities to collect psychological or physiological data for understanding the human mind. While new technologies make it possible to track our daily behavior and various biological signals such as physiological or genetic data more easily, one of the important remaining challenges is to discover our own truly meaningful personal values. Citizen science, scientific research by crowdsourcing or human-based computation, is a new and challenging framework that promotes interdisciplinary research in the fields of computer science, life/brain science, and social psychological/ behavioral science, which may introduce new paradigms to the AI community. We have been working on citizen science projects related to the area of personal genomics and have developed a personal genomics information environment named MyFinder. The developed platform supports the search for our inherited talents and maximizes our potential for a meaningful life. In particular, we are interested in the human mind and the personal genome. In this paper, we introduce our MyFinder Project and present the results of a recent study on ""social intelligence genomics and empathy building"", and discuss issues involved in exploring our mind within the context of personal genomics. Copyright © 2013 Association for the Advancement of Artificial Intelligence.";2013;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;12-17;NA;NA;SS-13-03;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
J5QDAA6E;journalArticle;2013;Kile, F.;Artificial intelligence and society: A furtive transformation;AI and Society;NA;NA;10.1007/s00146-012-0396-0;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873145024&doi=10.1007%2fs00146-012-0396-0&partnerID=40&md5=4ad4d8b9e4c078e460a94d6e29ca7896;"During the 1950s, there was a burst of enthusiasm about whether artificial intelligence might surpass human intelligence. Since then, technology has changed society so dramatically that the focus of study has shifted toward society's ability to adapt to technological change. Technology and rapid communications weaken the capacity of society to integrate into the broader social structure those people who have had little or no access to education. (Most of the recent use of communications by the excluded has been disruptive, not integrative.) Interweaving of socioeconomic activity and large-scale systems had a dehumanizing effect on people excluded from social participation by these trends. Jobs vanish at an accelerating rate. Marketing creates demand for goods which stress the global environment, even while the global environment no longer yields readily accessible resources. Mining and petroleum firms push into ever more challenging environments (e. g., deep mines and seabed mining) to meet resource demands. These activities are expensive, and resource prices rise rapidly, further excluding groups that cannot pay for these resources. The impact of large-scale systems on society leads to mass idleness, with the accompanying threat of violent reaction as unemployed masses seek to blame both people in power as well as the broader social structure for their plight. Perhaps, the impact of large-scale systems on society has already eroded essential qualities of humanness. Humans, when they feel ""socially useless,"" are dehumanized. (At the same time, machines (at any scale) seem incapable of emotion or empathy.) Has the cost of technological progress been too high to pay? These issues are addressed in this paper. © 2012 Springer-Verlag London Limited.";2013;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;107-115;NA;1;28;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FUAZ8M3T;journalArticle;2012;"Coronato, A.; De Pietro, G.";Detection of motion disorders of patients with autism spectrum disorders;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-35395-6_56;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870956015&doi=10.1007%2f978-3-642-35395-6_56&partnerID=40&md5=81b35f0220892de5cae29a9e80af4fe3;"The autistic spectrum disorders (ASD) are behaviorally-defined developmental disorders of the immature brain which affect three domains of behavior: sociability and empathy; communication, language and imagination; and mental flexibility and range of interests. Main symptoms include motion disorders and stereotyped behaviors. This paper presents an approach based on Artificial Intelligence techniques and Ambient Intelligence technologies for the detection of stereotyped motion disorders of patients with ASD. Specifically, monitoring is realized by means of tri-axis accelerometers applied to the patient's wrists. Signals obtained by accelerometers are pre-processed to obtain features that, in turn, are passed to classifiers that classifies the current observation in order to detect stereotyped motions. Results are under validation at the Department of Child Psychiatry at Children's Hospital Santobono-Pausilipon in Naples. © 2012 Springer-Verlag.";2012;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;415-422;NA;NA;7657 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
A783KSMV;conferencePaper;2012;Kanai, R.;Brain structure and individual differences in social behaviors;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865016334&partnerID=40&md5=afa9d1ce5a52c454a1d658998348810f;Brain structure exhibits systematic relationships with a variety of an individual's cognitive abilities and such relationships can be captured by voxel-based morphometry (VBM) that computes regional gray matter volume based on anatomical MRIs. This method has been successfully used to reveal brain regions that are associated with individual differences in a broad range of contexts such as perceptual performance, attention control, face recognition, introspection and personality traits (Kanai & Rees 2011). Here, we show that such relationships with brain structure extend to complex social behaviors by presenting our recent VBM studies that examined the relationships between brain structure and diverse aspects of socio-cognitive behavioral traits. Specifically, we identified brain regions in which individual differences in gray matter volumes were associated with political orientation, moral sentiment, empathy and loneliness. These findings suggest that information derived from standard MRI scans could be used to extract information about an individual's real-world and online social behavior. Unlike conventional functional neuroimaging research, our structural neuroimaging approach does not require a virtual environment that emulates social interactions and thus can directly link brain structure to real-world human behavior. As such, our approach based on individual differences in brain structure and behavior provides an important anchor point that integrates genetic and environmental factors determining diversity of human cognition and behavior. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.;2012;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;24-25;NA;NA;SS-12-05;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EV2CVZFC;conferencePaper;2011;"Green, N.L.; Stadler, B.; Kimbrough, J.";Adding affective argumentation to the GenIE assistant;AAAI Workshop - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054905660&partnerID=40&md5=54c17dc65a39c8f3a755c41b930970c8;This paper presents preliminary results of an empirical study to investigate effects of adding affective argumentation to the GenIE Assistant, an implemented proof-of-concept computational model of normative biomedical argument generation. The Assistant has been implemented in the domain of genetic counseling, a domain where human writers are advised to show empathy in addition to presenting clinical arguments for the diagnosis and source of a patient's condition. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.;2011;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;16-19;NA;NA;WS-11-10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PRDZA8B5;conferencePaper;2010;Duhaut, D.;A way to put empathy in a Robot;Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866108268&partnerID=40&md5=b7aefa120587dbd4e227a2ab51730e20;A report on the experiments carried out with our robot in the Emotirob project is given in this paper, in which we show how we build emotion and personality in the robot. With children, the results of interaction with the robot are quite satisfactory in a short-term experiment. However, it was noted that during long-term interaction between the children and the robot, the relationship changes as a kind of lassitude sets up. Thus, the question addressed here is, how can we make a robot acceptable for long-term interaction? We propose to explain why empathy is a part of the solution and what the key points are for artificial intelligence to solve this new problem.;2010;2021-02-15T22:34:02Z;2021-02-15T22:34:02Z;NA;549-554;NA;NA;2;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
S2XEK9TK;journalArticle;2021;"Chang, W.; Wang, H.; Yan, G.; Lu, Z.; Liu, C.; Hua, C.";EEG based functional connectivity analysis of human pain empathy towards humans and robots;Neuropsychologia;NA;NA;10.1016/j.neuropsychologia.2020.107695;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097757961&doi=10.1016%2fj.neuropsychologia.2020.107695&partnerID=40&md5=95c990a62e5739f884d45547193f3cab;Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots. © 2020 Elsevier Ltd;2021;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;NA;NA;NA;151;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
P2MGPPE5;journalArticle;2020;Wales, J.J.;Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots;Frontiers in Artificial Intelligence and Applications;NA;NA;10.3233/FAIA200906;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65;According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.;2020;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;114-124;NA;NA;335;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4T36ILIF;journalArticle;2020;Malinowska, J.K.;The Growing Need for Reliable Conceptual Analysis in HRI Studies: The Example of the Term 'Empathy';Frontiers in Artificial Intelligence and Applications;NA;NA;10.3233/FAIA200904;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098855262&doi=10.3233%2fFAIA200904&partnerID=40&md5=212a39f56d6ab3af3994b8e30aee16c6;Due to its interdisciplinary nature, the field of HRI uses many concepts typical of the social sciences and humanities, in addition to terms that are usually associated with technology. In this paper, I analyse the problems that arise when we use the term âempathy' to describe and explain the interaction between robots and humans. I argue that this not only raises questions about the possibility of applying this term in situations in which only one of the participants of the interaction is a traditionally understood social subject but also requires answers to questions about such problematic concepts as values and culture. © 2020 The authors and IOS Press. All rights reserved.;2020;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;96-104;NA;NA;335;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
F2DHJR4U;journalArticle;2020;Schmetkamp, S.;Understanding A.I. — Can and Should we Empathize with Robots?;Review of Philosophy and Psychology;NA;NA;10.1007/s13164-020-00473-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083955575&doi=10.1007%2fs13164-020-00473-x&partnerID=40&md5=8c5a1a9139fa546337a1ecdeea7e1f49;Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding. © 2020, Springer Nature B.V.;2020;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;881-897;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ICK3UPDK;journalArticle;2020;"Konijn, E.A.; Hoorn, J.F.";Differential facial articulacy in robots and humans elicit different levels of responsiveness, empathy, and projected feelings;Robotics;NA;NA;10.3390/robotics9040092;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096119375&doi=10.3390%2frobotics9040092&partnerID=40&md5=16358e35deb385522e159e206aa5199e;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot’s face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot’s face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) × 2 (treatment: affectionate vs. maltreated). Participants (N = 265; Mage = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of ‘because I feel, I believe it’s real,’ despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of ‘it is just a robot’ fades into the background and appears not relevant anymore. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.";2020;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;1-17;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
INAJJCKA;journalArticle;2020;"Giannopulu, I.; Etournaud, A.; Terada, K.; Velonaki, M.; Watanabe, T.";Ordered interpersonal synchronisation in ASD children via robots;Scientific Reports;NA;NA;10.1038/s41598-020-74438-6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092659030&doi=10.1038%2fs41598-020-74438-6&partnerID=40&md5=ba25cca4d93dfcc0d9b69aa2ee0148d5;Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping. © 2020, The Author(s).;2020;2021-02-15T22:35:16Z;2021-02-15T22:35:16Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SAPE98PC;journalArticle;2020;Gramantieri, R.;Alexithymic personality in Philip K. Dick’s Do androids dream of electric sheep?;Neohelicon;NA;NA;10.1007/s11059-020-00544-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745112&doi=10.1007%2fs11059-020-00544-z&partnerID=40&md5=d7ae68506033a119722c578a57aa02bd;"The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients’ comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novel Do androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commenting Do androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick. © 2020, Akadémiai Kiadó, Budapest, Hungary.";2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;673-683;NA;2;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VHEYS5UH;journalArticle;2020;"Bagheri, E.; Esteban, P.G.; Cao, H.-L.; Beir, A.D.; Lefeber, D.; Vanderborght, B.";An autonomous cognitive empathy model responsive to users' facial emotion expressions;ACM Transactions on Interactive Intelligent Systems;NA;NA;10.1145/3341198;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097225306&doi=10.1145%2f3341198&partnerID=40&md5=6b3056773f580546273a9ec06bea4681;Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot. © 2020 ACM.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;3;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XYR4P2X5;conferencePaper;2020;"Daher, K.; Casas, J.; Khaled, O.A.; Mugellini, E.";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020;NA;NA;10.1145/3383652.3423864;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096965302&doi=10.1145%2f3383652.3423864&partnerID=40&md5=fe8b298b7d7e4ba7330d713c3261bfca;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12). © 2020 Owner/Author.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5JGPCMWQ;conferencePaper;2020;"Sonmez, E.B.; Kose, H.; Barkana, D.E.";Towards a New Computational Affective System for Personal Assistive Robots;2020 28th Signal Processing and Communications Applications Conference, SIU 2020 - Proceedings;NA;NA;10.1109/SIU49456.2020.9302238;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100292356&doi=10.1109%2fSIU49456.2020.9302238&partnerID=40&md5=1c6d4cdda7d6442c842e9caac9ed4e0b;The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively. © 2020 IEEE.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4LQ2P4BM;journalArticle;2020;"Pepito, J.A.; Ito, H.; Betriana, F.; Tanioka, T.; Locsin, R.C.";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations;Nursing Philosophy;NA;NA;10.1111/nup.12318;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088269058&doi=10.1111%2fnup.12318&partnerID=40&md5=9764df20ca03d74991df8a514f7e7133;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology. © 2020 John Wiley & Sons Ltd";2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
L344UH4D;conferencePaper;2020;"Desolda, G.; Deufemia, V.; Gena, C.; Matera, M.; Paternò, F.; Treccani, B.";EMPATHY: Empowering People in Dealing with Internet of Things Ecosystems (Workshop);ACM International Conference Proceeding Series;NA;NA;10.1145/3399715.3400870;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093077722&doi=10.1145%2f3399715.3400870&partnerID=40&md5=355e1750764d9f345807dfcd6785474d;The Internet of Things is a pervasive technology widely adopted in several contexts ranging from smart homes to automotive cars. In this context, the End User Development is gaining momentum: different solutions support non-technical users to define the smart objects behavior to better satisfy their needs. This workshop aimed to stimulates participants in providing discussions in line with the workshop themes and goals, for example, user mental models, acceptance of EUD solutions, the role of AI in EUD tools, humanoid robots were discussed. © 2020 Owner/Author.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RZ2KQM77;journalArticle;2020;"Sakurai, E.; Kurashige, K.; Tsuruta, S.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.; Frati, F.";Embodiment matters: toward culture-specific robotized counselling;Journal of Reliable Intelligent Environments;NA;NA;10.1007/s40860-020-00109-y;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087487620&doi=10.1007%2fs40860-020-00109-y&partnerID=40&md5=bbf9e8b747887c35e9498c0749840555;In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;129-139;NA;3;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
N77XTZ4V;journalArticle;2020;"Ivkov, M.; Blešić, I.; Dudić, B.; Bartáková, G.P.; Dudić, Z.";Are future professionals willing to implement service robots? Attitudes of hospitality and tourism students towards service robotization;Electronics (Switzerland);NA;NA;10.3390/electronics9091442;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093903132&doi=10.3390%2felectronics9091442&partnerID=40&md5=0042f4d6afbcca5932415c05a7c3f97f;This paper aims to examine attitudes of hospitality and tourism students, as future professionals, towards willingness to implement service robots. The study proposes a new theoretical conceptual model that includes new constructs and items, differentiating it from the others. The model was formed based on the extensive literature review and the interview with an eight-member focus group (hotel managers and academic researchers). Data collection was performed in two stages, pilot research based on 82 respondents and the main study, with the final number of respondents being 236. The initial results of the exploratory factor analysis were further tested using the confirmatory factor analysis. After the exclusion of several items due to low factor loadings and in order to improve model validity, analyses further suggested a nine-dimensional solution with 45 items. The study findings reveal a positive relationship between seven constructs and students’ willingness to implement service robots, with the expected business outcome being the most influencing one. On the other hand, positive relation was not found for empathy and social influence constructs. Theoretical contributions and practical implications are discussed in the paper. In conclusion, study limitations and future research suggestions are provided. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;1-16;NA;9;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GW2ZG3PP;conferencePaper;2020;"Corretjer, M.G.; Ros, R.; Martin, F.; Miralles, D.";The Maze of Realizing Empathy with Social Robots;29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020;NA;NA;10.1109/RO-MAN47096.2020.9223466;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095760531&doi=10.1109%2fRO-MAN47096.2020.9223466&partnerID=40&md5=0898316eb3582aa6430fa85f72edb83b;Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy. © 2020 IEEE.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;1334-1339;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9LLGVU3Z;conferencePaper;2020;"Ye, S.; Feigh, K.; Howard, A.";Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games;29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020;NA;NA;10.1109/RO-MAN47096.2020.9223437;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095735091&doi=10.1109%2fRO-MAN47096.2020.9223437&partnerID=40&md5=74bfb142371d9fab0e75afbaa05d3b0c;Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device. © 2020 IEEE.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;1186-1189;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2ES5KW2P;conferencePaper;2020;"Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.";Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation;29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020;NA;NA;10.1109/RO-MAN47096.2020.9223442;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095730396&doi=10.1109%2fRO-MAN47096.2020.9223442&partnerID=40&md5=ac2ec563cda67bf4704bb20f32ef0b07;In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction. © 2020 IEEE.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;653-658;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GR2AQ9XW;conferencePaper;2020;"Perusquia-Hemandez, M.; Balda, M.C.; Gomez Jauregui, D.A.; Paez-Granados, D.; Dollack, F.; Salazar, J.V.";Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States;29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020;NA;NA;10.1109/RO-MAN47096.2020.9223598;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095745482&doi=10.1109%2fRO-MAN47096.2020.9223598&partnerID=40&md5=f2b4aa17536e3404041a17e644e85abf;Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization. © 2020 IEEE.;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;1328-1333;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RCTSADAA;journalArticle;2020;"de Kervenoael, R.; Hasan, R.; Schwob, A.; Goh, E.";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;Tourism Management;NA;NA;10.1016/j.tourman.2019.104042;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075628508&doi=10.1016%2fj.tourman.2019.104042&partnerID=40&md5=f56ef158af2d44659553121590311519;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies. © 2019 Elsevier Ltd;2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 18</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
72X8ATSE;journalArticle;2020;"Rossi, S.; Conti, D.; Garramone, F.; Santangelo, G.; Staffa, M.; Varrasi, S.; Di Nuovo, A.";The role of personality factors and empathy in the acceptance and performance of a social robot for psychometric evaluations;Robotics;NA;NA;10.3390/ROBOTICS9020039;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086668483&doi=10.3390%2fROBOTICS9020039&partnerID=40&md5=c2ec5388361d460022f6c3d10f29ebcb;"Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the ""openness to experience"", on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests. © 2020 by the authors.";2020;2021-02-15T22:35:17Z;2021-02-15T22:35:17Z;NA;NA;NA;2;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
55PK4C7S;conferencePaper;2020;"Arnett, M.; Luo, Z.; Paladugula, P.K.; Cardenas, I.S.; Kim, J.-H.";Robots teaching recycling: Towards improving environmental literacy of children;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3371382.3379462;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083168399&doi=10.1145%2f3371382.3379462&partnerID=40&md5=f2c5deecfbb5b7dbc8343530bb6d2c03;The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle. © 2020 ACM.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;615-616;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZTXRNVQS;conferencePaper;2020;"Bhardwaj, P.; Joseph, C.V.; Shah, A.; Yadava, S.K.";Juno: An interactive storytelling robot for early constructive childhood intervention;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3371382.3379458;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083253085&doi=10.1145%2f3371382.3379458&partnerID=40&md5=a7d0171aec43f7ddceb928a2de07709c;Early life adversity is a major risk factor for the development of psychological and behavioral problems in adult life. Traumatic experiences in childhood are linked to higher rates of depression, anxiety disorders and a range of mental health issues.[4] Additionally, stories form the basis of understanding in children and help develop empathy and cultivate imaginative and divergent thinking in them. In this paper, we expound on the idea of leveraging the potential of storytelling through an interactive toy i.e. transitional object as a means of intentful intervention to help children understand and cope better with stressors in developmental ages. © 2020 ACM.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;617-618;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MME7VL5C;conferencePaper;2020;"Connolly, J.; Mocz, V.; Salomons, N.; Valdez, J.; Tsoi, N.; Scassellati, B.; Vazquez, M.";Prompting prosocial human interventions in response to robot mistreatment;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3319502.3374781;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082005598&doi=10.1145%2f3319502.3374781&partnerID=40&md5=5ca37572e421853f75ed741b638c5e9a;Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 betweensubjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI. © 2020 Association for Computing Machinery.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;211-220;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
M4E9Q4MQ;journalArticle;2020;McBride, N.;Robot Enhanced Therapy for Autistic Children: An Ethical Analysis;IEEE Technology and Society Magazine;NA;NA;10.1109/MTS.2020.2967493;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082031020&doi=10.1109%2fMTS.2020.2967493&partnerID=40&md5=7ee555189c1a7a2bf1f6ae1bc24dce07;The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in <italic>IEEE Technology and Society Magazine</italic>, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions. © 1982-2012 IEEE.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;51-60;NA;1;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DLDCYDG7;journalArticle;2020;"Björling, E.A.; Thomas, K.; Rose, E.J.; Cakmak, M.";Exploring Teens as Robot Operators, Users and Witnesses in the Wild;Frontiers in Robotics and AI;NA;NA;10.3389/frobt.2020.00005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081700133&doi=10.3389%2ffrobt.2020.00005&partnerID=40&md5=b3727eb4331051d6aa27b67a53ab255c;As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot. © Copyright © 2020 Björling, Thomas, Rose and Cakmak.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6MB2U92P;journalArticle;2020;"Bagheri, E.; Roesler, O.; Cao, H.-L.; Vanderborght, B.";A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots;International Journal of Social Robotics;NA;NA;10.1007/s12369-020-00683-4;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091144365&doi=10.1007%2fs12369-020-00683-4&partnerID=40&md5=f3b6bad671fdea58d1e7adfee9eb2754;Robots that express human’s social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better. © 2020, Springer Nature B.V.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
YU9LKP23;journalArticle;2020;"James, J.; Balamurali, B.T.; Watson, C.I.; MacDonald, B.";Empathetic Speech Synthesis and Testing for Healthcare Robots;International Journal of Social Robotics;NA;NA;10.1007/s12369-020-00691-4;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090755646&doi=10.1007%2fs12369-020-00691-4&partnerID=40&md5=e6d2fbb614c296ba7d803a31715e7357;One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot’s voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people’s acceptance of social robots. © 2020, Springer Nature B.V.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZXM72SSP;journalArticle;2020;"Trost, M.J.; Chrysilla, G.; Gold, J.I.; Matarić, M.";Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children;Pain Research and Management;NA;NA;10.1155/2020/7935215;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083881603&doi=10.1155%2f2020%2f7935215&partnerID=40&md5=ea3dec2f225f6047f5a5282c0de25503;"Objectives. Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods. We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot's empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with NCT02840942. Results. Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions. Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management. © 2020 Margaret J Trost et al.";2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;NA;NA;NA;2020;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BTYJ3QW7;journalArticle;2020;"Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.";Emotion Synchronization Method for Robot Facial Expression;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-49062-1_44;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20;Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;644-653;NA;NA;12182 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZVFS7HWS;journalArticle;2020;"Ho, J.C.F.; Ng, R.";Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion;Behaviour and Information Technology;NA;NA;10.1080/0144929X.2020.1864018;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098553464&doi=10.1080%2f0144929X.2020.1864018&partnerID=40&md5=78bc6d559d259fece1c757b340b9b1ba;This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters–NPCs in a prosocial VR game–influences players’ in-game empathy towards NPCs and game immersion. Participants first experienced either a robot’s perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants’ game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players’ weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed. © 2020 Informa UK Limited, trading as Taylor & Francis Group.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DB8D4YGF;conferencePaper;2020;"Buono, P.; Castellano, G.; Decarolis, B.; MacChiarulo, N.";Social assistive robots in elderly care: Exploring the role of empathy;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094831887&partnerID=40&md5=9c71a17ac85c7fe16e8b3521eec02d0e;The COVID-19 emergency has shown that elderly people living in Assisted Living Houses (ALHs) have been highly exposed to the virus. Besides health problems, during the social distancing restrictions, the elderly were also strongly affected by loneliness due to a lack of contact with their loved ones. Innovative solutions for ALH based on Social Assistive Robotics can reduce the risk of infection and, at the same time, improve the quality of life of elderly people. In this work, after a brief overview on the Pepper4Elderly project, we focus on the role of empathy and affective behaviors in human-robot interaction when the robot is used as a caring agent to assist and entertain the elderly guests of ALHs. © 2020 CEUR-WS. All rights reserved.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;12-19;NA;NA;2702;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CGA5ZMFC;conferencePaper;2020;"Ito, K.; Murata, M.; Ohno, T.; Matsubara, S.";Relation between degree of empathy for narrative speech and type of responsive utterance in attentive listening;LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512903&partnerID=40&md5=1ff80d168c8d91743e767819a0d7b887;Nowadays, spoken dialogue agents such as communication robots and smart speakers listen to narratives of humans. In order for such an agent to be recognized as a listener of narratives and convey the attitude of attentive listening, it is necessary to generate responsive utterances. Moreover, responsive utterances can express empathy to narratives and showing an appropriate degree of empathy to narratives is significant for enhancing speaker's motivation. The degree of empathy shown by responsive utterances is thought to depend on their type. However, the relation between responsive utterances and degrees of the empathy has not been explored yet. This paper describes the classification of responsive utterances based on the degree of empathy in order to explain that relation. In this research, responsive utterances are classified into five levels based on the effect of utterances and literature on attentive listening. Quantitative evaluations using 37,995 responsive utterances showed the appropriateness of the proposed classification. © European Language Resources Association (ELRA), licensed under CC-BY-NC;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;696-701;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5PHU38FM;journalArticle;2020;"Perugia, G.; Paetzel, M.; Castellano, G.";On the Role of Personality and Empathy in Human-Human, Human-Agent, and Human-Robot Mimicry;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-62056-1_11;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097197855&doi=10.1007%2f978-3-030-62056-1_11&partnerID=40&md5=95f5dab4e658c63f6012ff6fc072f43a;Facial mimicry is crucial in social interactions as it communicates the intent to bond with another person. While human-human mimicry has been extensively studied, human-agent and human-robot mimicry have been addressed only recently, and the individual characteristics that affect them are still unknown. This paper explores whether the humanlikeness and embodiment of an agent affect human facial mimicry and which personality and empathy traits are related to facial mimicry of human and artificial agents. We exposed 46 participants to the six basic emotions displayed by a video-recorded human and three artificial agents (a physical robot, a video-recorded robot, and a virtual agent) differing in humanlikeness (humanlike, characterlike, and a morph between the two). We asked participants to recognize the facial expressions performed by each agent and measured their facial mimicry using automatic detection of facial action unit activation. Results showed that mimicry was affected by the agents’ embodiment, but not by their humanlikeness, and that it correlated both with individual traits denoting sociability and sympathy and with traits advantageous for emotion recognition. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;120-131;NA;NA;12483 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
R64E9VLC;journalArticle;2020;"Sejima, Y.; Sato, Y.; Watanabe, T.";Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-030-20441-9_11;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b;Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:18Z;2021-02-15T22:35:18Z;NA;95-102;NA;NA;952;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Q93WGLHK;journalArticle;2020;"Hickton, L.; Lewis, M.; Cañamero, L.";Expression of Grounded Affect: How Much Emotion Can Arousal Convey?;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-63486-5_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231;In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;234-248;NA;NA;12228 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7XSFLKF5;journalArticle;2020;"Chiang, A.-H.; Trimi, S.";Impacts of service robots on service quality;Service Business;NA;NA;10.1007/s11628-020-00423-8;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089085301&doi=10.1007%2fs11628-020-00423-8&partnerID=40&md5=845fde74db3c352ab9c164b287bcc23f;With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7T52K2WI;journalArticle;2020;"Johanson, D.L.; Ahn, H.S.; Broadbent, E.";Improving Interactions with Healthcare Robots: A Review of Communication Behaviours in Social and Healthcare Contexts;International Journal of Social Robotics;NA;NA;10.1007/s12369-020-00719-9;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095992051&doi=10.1007%2fs12369-020-00719-9&partnerID=40&md5=f3f195ead2052764e3a972a247dbf24f;A growing shortfall exists between the number of older individuals who require healthcare support and the number of qualified healthcare professionals who can provide this. Robots offer the potential to provide healthcare support to patients both at home and in healthcare settings. However, in order for robots to be successfully implemented in these environments, they need to behave in ways that are appropriate and acceptable to human users. One way to identify appropriate social behaviours for healthcare robots is to model their behaviour on interactions between healthcare professionals and patients. This literature review aimed to inform healthcare robotics research by highlighting communication behaviours that are important within the context of healthcare. The review focussed on relevant research in human clinical interactions, followed by a review of similar factors in social robotics research. Three databases were searched for terms relating to healthcare professional communication behaviours associated with patient outcomes. The results identified key communication behaviours that can convey clinical empathy, including humour, self-disclosure, facial expressions, eye gaze, body posture, and gestures. A further search was conducted to identify research examining these key behaviours within the context of social and healthcare robotics. Research into these factors in human–robot interaction in healthcare is limited to date, and this review provides a useful guide for future research. © 2020, Springer Nature B.V.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Z2IDNUPI;journalArticle;2020;"Chung, S.-E.; Ryoo, H.-Y.";Gesture design attribute and level value of social robot: A user experience based study;Journal of System and Management Sciences;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3;"This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.";2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;108-121;NA;2;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZVYJ2WPT;journalArticle;2020;"Küster, D.; Swiderska, A.";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;International Journal of Psychology;NA;NA;10.1002/ijop.12715;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090926311&doi=10.1002%2fijop.12715&partnerID=40&md5=93cd342d1b06662a239ccc999e6dde9d;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation. © 2020 The Authors. International Journal of Psychology published by John Wiley & Sons Ltd on behalf of International Union of Psychological Science.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JA9ZZ6WG;journalArticle;2020;"Balistreri, M.; Casile, F.";Care Robots: From Tools of Care to Training Opportunities. Moral Considerations;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-030-23884-1_3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068643881&doi=10.1007%2f978-3-030-23884-1_3&partnerID=40&md5=ddeacd68dcfb7fbd19f08f5b10213563;New technology should not perceived as a threat: on the contrary, it is a resource. It is our job to use it in the most appropriate way. Moreover, new technology can make a significant contribution to nurse training: for example, immersion into virtual reality with a visor and a simple application does not only allow one to experience fantastic adventures, but also to enjoy a relationship with the patient through simulation. Also, virtual reality can promote patient/teacher interaction: both, for example, can be projected or immersed in virtual reality, or the teacher can project his ‘virtual’ image into a real scenario. However, robots too could contribute to training nursing staff: health operator training courses today widely use dummies which are appropriately planned for standing training. They are increasingly true-to-life, favouring empathy with the clinical situation simulated each time and allowing the student to exercise not only technical abilities, but also critical thinking, the ability to work in a team and communication skills. We shall examine some moral questions linked to the increasingly frequent use of human-faceted robots to train nursing staff. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;18-25;NA;NA;1008;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JATUII48;journalArticle;2020;Andreotta, A.J.;The hard problem of AI rights;AI and Society;NA;NA;10.1007/s00146-020-00997-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085877284&doi=10.1007%2fs00146-020-00997-x&partnerID=40&md5=bd9018524171b9ac98aa2157ae1ac084;In the past few years, the subject of AI rights—the thesis that AIs, robots, and other artefacts (hereafter, simply ‘AIs’) ought to be included in the sphere of moral concern—has started to receive serious attention from scholars. In this paper, I argue that the AI rights research program is beset by an epistemic problem that threatens to impede its progress—namely, a lack of a solution to the ‘Hard Problem’ of consciousness: the problem of explaining why certain brain states give rise to experience. To motivate this claim, I consider three ways in which to ground AI rights—namely: superintelligence, empathy, and a capacity for consciousness. I argue that appeals to superintelligence and empathy are problematic, and that consciousness should be our central focus, as in the case of animal rights. However, I also argue that AI rights is disanalogous from animal rights in an important respect: animal rights can proceed without a solution to the ‘Hard Problem’ of consciousness. Not so with AI rights, I argue. There we cannot make the same kinds of assumptions that we do about animal consciousness, since we still do not understand why brain states give rise to conscious mental states in humans. © 2020, Springer-Verlag London Ltd., part of Springer Nature.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EERPITEC;journalArticle;2020;Bergen, J.P.;Love(rs) in the making: Moral subjectivity in the face of sexbots;Paladyn;NA;NA;10.1515/pjbr-2020-0016;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088011901&doi=10.1515%2fpjbr-2020-0016&partnerID=40&md5=a1955bd5c3aa900399f2f1c1ffd6180d;This article offers a novel reading of the criticisms of sex robots put forward by the Campaign Against Sex Robots (CASR). Focusing on the implication of a loss of empathy, it structures CASR's worries as an argument from moral degradation centered around the potential effects on sexbot users' sexual and moral subjectivity. This argument is subsequently explored through the combined lenses of postphenomenology and the ethical phenomenology of Emmanuel Levinas. In so doing, it describes the type of human-technology relations that sexbots invite, identifying alterity as a central feature. It also highlights how alterity, responsibility, and subjectivity are intimately connected. However, that connection is distinctly different in sexual circumstances, making current versions of Levinasian roboethics largely inapplicable for the ethics of sexbots. To overcome this, the article delves into Levinas' phenomenology of Eros and identifies voluptuousness as a type of enjoyment of the Other that is different from the enjoyment invited by current sexbots and is compatible with responsibility. Based on this, the article provides examples of how this phenomenology of Eros can inspire the design of future sexbots in ways that alleviate some of CASR's concerns. © 2020 Jan Peter Bergen, published by De Gruyter 2020.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;284-300;NA;1;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5A5H4IXW;journalArticle;2020;Karpov, V.E.;Can a robot be a moral agent?;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-59535-7_5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092173472&doi=10.1007%2f978-3-030-59535-7_5&partnerID=40&md5=d8316768b923311d1b05807222c77b02;Issues of the ethically aligned design of intelligent/autonomous systems have now moved into the fields of normative and technical regulation. If a system must make ethically determined decisions, then it must be recognized as a moral agent. This paper provides a list of the properties of a moral agent and shows not only that an artificial agent can have such properties, but also that they are technically determined as manifestations of adaptive mechanisms. In particular, it is shown that mechanisms such as the presence of the “I” component in the sign-oriented picture of the agent’s world, the presence of an emotional-needs architecture, and the mechanism for comparing the observed conspecific with the “I” make it possible to realize the phenomena of social learning and a property such as empathy. © Springer Nature Switzerland AG 2020.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;61-70;NA;NA;12412 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LLQLAX8I;journalArticle;2020;"Rafique, M.; Hassan, M.A.; Jaleel, A.; Khalid, H.; Bano, G.";A Computation Model for Learning Programming and Emotional Intelligence;IEEE Access;NA;NA;10.1109/ACCESS.2020.3015533;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091848953&doi=10.1109%2fACCESS.2020.3015533&partnerID=40&md5=184fadf767e187ea5ac11feef75422fd;Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface. © 2013 IEEE.;2020;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;149616-149629;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QZ4FPF5F;journalArticle;2019;"Carlson, Z.; Lemmon, L.; Higgins, M.C.; Frank, D.; Salek Shahrezaie, R.; Feil-Seifer, D.";Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers;International Journal of Social Robotics;NA;NA;10.1007/s12369-019-00599-8;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074582945&doi=10.1007%2fs12369-019-00599-8&partnerID=40&md5=cda66cf87d85769abf9cea41a774b3cf;"Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable. © 2019, The Author(s).";2019;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;727-739;NA;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GDDKQ8W7;journalArticle;2019;"Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farnè, A.; Dominey, P.F.; Pavani, F.";Embodiment into a robot increases its acceptability;Scientific Reports;NA;NA;10.1038/s41598-019-46528-7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069005120&doi=10.1038%2fs41598-019-46528-7&partnerID=40&md5=c7b84e03aa3b4bd20eb345fc595e7e4e;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects’ head movements. As a result, participants saw themselves as a robot. When participant’ and robot’s head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots’ humanoid’s appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable. © 2019, The Author(s).;2019;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;NA;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
YI9T738F;conferencePaper;2019;"Esfandbod, A.; Rokhi, Z.; Taheri, A.; Alemi, M.; Meghdari, A.";Human-Robot Interaction based on Facial Expression Imitation;ICRoM 2019 - 7th International Conference on Robotics and Mechatronics;NA;NA;10.1109/ICRoM48714.2019.9071837;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084358069&doi=10.1109%2fICRoM48714.2019.9071837&partnerID=40&md5=ae795b1eb257f51d3eebb251402352f6;Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database., which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants, viewpoints on the imitation capability of the robot of 4.1 out of 5. © 2019 IEEE.;2019;2021-02-15T22:35:19Z;2021-02-15T22:35:19Z;NA;69-73;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
D6UJ6DSB;conferencePaper;2019;"Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019;NA;NA;10.1109/RITAPP.2019.8932852;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JTK53AIG;conferencePaper;2019;"Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.";Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals;2019 28th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2019;NA;NA;10.1109/RO-MAN46459.2019.8956353;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078837141&doi=10.1109%2fRO-MAN46459.2019.8956353&partnerID=40&md5=7d59754dade81e0ffa2bdbd5efe9a98a;Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CDCLWG9X;journalArticle;2019;"Johanson, D.L.; Ahn, H.S.; MacDonald, B.A.; Ahn, B.K.; Lim, J.; Hwang, E.; Sutherland, C.J.; Broadbent, E.";The effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction: Randomized controlled trial;Journal of Medical Internet Research;NA;NA;10.2196/13667;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072908937&doi=10.2196%2f13667&partnerID=40&md5=244df67bd1698544f060020541459c91;Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings. © Deborah L Johanson, Ho Seok Ahn, Bruce A MacDonald, Byeong Kyu Ahn, JongYoon Lim, Euijun Hwang, Craig J Sutherland, Elizabeth Broadbent.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QNG734GQ;conferencePaper;2019;"Okanda, M.; Taniguchi, K.; Itakura, S.";The role of animism tendencies and empathy in adult evaluations of robot;HAI 2019 - Proceedings of the 7th International Conference on Human-Agent Interaction;NA;NA;10.1145/3349537.3351891;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077124144&doi=10.1145%2f3349537.3351891&partnerID=40&md5=e9499c2611c38d3507959f62e604ef78;We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness. © 2019 ACM.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;51-58;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CJEG36BW;journalArticle;2019;"Rincon, J.A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.";A new emotional robot assistant that facilitates human interaction and persuasion;Knowledge and Information Systems;NA;NA;10.1007/s10115-018-1231-9;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049128718&doi=10.1007%2fs10115-018-1231-9&partnerID=40&md5=5c66a64dc9959c1533168f3b8df3e72e;The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare center in the northern area of Portugal. © 2018, Springer-Verlag London Ltd., part of Springer Nature.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;363-383;NA;1;60;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FWH3JPP2;conferencePaper;2019;"Costantini, S.; De Gasperis, G.; Migliarini, P.";Multi-agent system engineering for emphatic human-robot interaction;Proceedings - IEEE 2nd International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2019;NA;NA;10.1109/AIKE.2019.00015;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071453043&doi=10.1109%2fAIKE.2019.00015&partnerID=40&md5=3f40048836bffb6e0cc5a9b52df01a87;Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;36-42;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LSV5CART;conferencePaper;2019;"Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.";Performance analysis of unimodal and multimodal models in valence-based empathy recognition;Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019;NA;NA;10.1109/FG.2019.8756517;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070455625&doi=10.1109%2fFG.2019.8756517&partnerID=40&md5=cf50721db883d29dc85761df97f9ee76;The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, humanrobot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KWKTAUA8;journalArticle;2019;"Cross, E.S.; Riddoch, K.A.; Pratts, J.; Titone, S.; Chaudhury, B.; Hortensius, R.";A neurocognitive investigation of the impact of socializing with a robot on empathy for pain;Philosophical Transactions of the Royal Society B: Biological Sciences;NA;NA;10.1098/rstb.2018.0034;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062693788&doi=10.1098%2frstb.2018.0034&partnerID=40&md5=2571e9a19730d18d3a12e4bda31d9487;To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'. © 2019 The Author(s) Published by the Royal Society. All rights reserved.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;1771;374;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5KRKNFPU;conferencePaper;2019;"Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.";Ideal warrior and robot relations: Stress and empathy's role in human-robot teaming;2019 Systems and Information Engineering Design Symposium, SIEDS 2019;NA;NA;10.1109/SIEDS.2019.8735613;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068571842&doi=10.1109%2fSIEDS.2019.8735613&partnerID=40&md5=ccc21f2fe0c8fc29e283088fe64aa7f2;The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7IZN6GK9;conferencePaper;2019;"Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.";The RoPE Scale: A Measure of How Empathic a Robot is Perceived;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1109/HRI.2019.8673082;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063988065&doi=10.1109%2fHRI.2019.8673082&partnerID=40&md5=bb92abeea2fde8a7291997b624203491;To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;656-657;NA;NA;2019-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6I7YLZCR;conferencePaper;2019;"Sanoubari, E.; Seo, S.H.; Garcha, D.; Young, J.E.; Loureiro-Rodriguez, V.";Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1109/HRI.2019.8673326;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064013532&doi=10.1109%2fHRI.2019.8673326&partnerID=40&md5=790f12ed481e2a7fd36f88f62a4c702b;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable? © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;382-391;NA;NA;2019-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MMGXANE8;conferencePaper;2019;Vertesi, J.;Seeing Like a Rover: Team Work and Human-Robot Relations;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1109/HRI.2019.8673224;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064000114&doi=10.1109%2fHRI.2019.8673224&partnerID=40&md5=8408e02463168815ec87397c3fa3c02f;How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' 'eyes' on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life. © 2019 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;152;NA;NA;2019-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4ARPBDNT;journalArticle;2019;"Alves-Oliveira, P.; Sequeira, P.; Melo, F.S.; Castellano, G.; Paiva, A.";Empathic Robot for Group Learning: A Field Study;ACM Transactions on Human-Robot Interaction;NA;NA;10.1145/3300188;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068536369&doi=10.1145%2f3300188&partnerID=40&md5=38936e838e88debca3eecfa94296497b;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning. © 2019 ACM.";2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 18</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WR2EXC58;conferencePaper;2019;"Salaken, S.M.; Nahavandi, S.; McGinn, C.; Hossny, M.; Kelly, K.; Abobakr, A.; Nahavandi, D.; Iskander, J.";Development of a cloud-based computational framework for an empathetic robot;ACM International Conference Proceeding Series;NA;NA;10.1145/3313991.3314018;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064612068&doi=10.1145%2f3313991.3314018&partnerID=40&md5=63ff43c5b27f0b4f09c443d56e71a480;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator’s voice is presented. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;102-108;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
L7V7B5C2;conferencePaper;2019;"Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.";Counseling Robot Implementation and Evaluation;Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018;NA;NA;10.1109/SMC.2018.00297;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062214049&doi=10.1109%2fSMC.2018.00297&partnerID=40&md5=430fc180d5787ab662d9003595001288;A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called 'unazuki' in Japanese, a kind of nodding to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared. © 2018 IEEE.;2019;2021-02-15T22:35:20Z;2021-02-15T22:35:20Z;NA;1716-1722;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QNFZV2MC;journalArticle;2019;"Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.";Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects;Lecture Notes in Electrical Engineering;NA;NA;10.1007/978-3-030-04672-9_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f;The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;101-113;NA;NA;540;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RWVNNDS4;conferencePaper;2019;"Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.";Digital empathy secures Frankenstein’s monster;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210;People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;335-349;NA;NA;2348;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HJ6B2BSV;journalArticle;2019;"Vanman, E.J.; Kappas, A.";“Danger, Will Robinson!” The challenges of social robots for intergroup relations;Social and Personality Psychology Compass;NA;NA;10.1111/spc3.12489;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070056360&doi=10.1111%2fspc3.12489&partnerID=40&md5=df6ade6d0336dd74942733c534399eb2;Society's increasing reliance on robots in everyday life provides exciting opportunities for social psychologists to work with engineers in the nascent field of social robotics. In contrast to industrial robots that, for example, may be used on an assembly line, social robots are designed specifically to interact with humans and/or other robots. People tend to perceive social robots as autonomous and capable of having a mind. As such, they are also more likely to be subject to social categorization by humans. As social robots become more human like, people may also feel greater empathy for them and treat robots more like (human) ingroup members. On the other hand, as they become more human like, robots also challenge our human distinctiveness, threaten our identity, and elicit suspicion about their ability to deceive us with their human-like qualities. We review relevant research to explore this apparent paradox, particularly from an intergroup relations perspective. We discuss these findings and propose three research questions that we believe social psychologists are ideally suited to address. © 2019 John Wiley & Sons Ltd;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;NA;NA;8;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PDXJJSNK;journalArticle;2019;"Omokawa, R.; Kobayashi, M.; Matsuura, S.";Expressing the Personality of a Humanoid Robot as a Talking Partner in an Elementary School Classroom;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-23560-4_36;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069875511&doi=10.1007%2f978-3-030-23560-4_36&partnerID=40&md5=6fcb8f37cfa76597c0643f0aa6619d9d;A humanoid robot NAO was introduced as a talking partner of teaching AI and robot to the elementary school students to stimulate empathy for the intelligent machines. Two dialog types were defined. First, the query type dialog was defined as a robot’s answer to human questioning. Second, the phatic type dialogs were defined to express the personality of the robot. While the former type dialog is initiated by formulated questioning, the latter type response can even be induced by misrecognition of human speech. Applying this simple method, the same unit sessions for each of the three classrooms on AI and robot were conducted. During the sessions, students’ burst of laughter was induced at 83% of the phatic type dialog, and the laughing response was found at 44% of the query type dialogs. By this representation, it became easier for the students to empathize with the robot. After this session, a questionnaire survey on the preference of robot pet, on what the students wanted to talk with the robot that dreams at night, and on their view of life if AI robots replaced human workers was conducted. The results suggested that the students got to imagine a virtual subjectivity of the intelligent machines and considered a better life for the human with them. © 2019, Springer Nature Switzerland AG.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;494-506;NA;NA;11572 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QGQ6BJEA;conferencePaper;2019;"Gemeinboeck, P.; Saunders, R.";Exploring social co-presence through movement in human-robot encounters;2019 AISB Convention;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075273167&partnerID=40&md5=25ec4efb84ecdc0459bba9ce60def3df;This paper explores the social capacity of robots as an emergent phenomenon of the exchange between humans and robots, rather than an intrinsic property of robots as is often assumed in social robotics research. Using our Performative Body Mapping (PBM) approach, we have developed a robotic object for studying how social meaning is enacted when movement qualities meet kinesthetic empathy. In this paper we introduce PBM and how it harnesses performers' kinesthetic imagination and movement expertise for designing the movement potential and movement qualities of abstract, non-humanlike robots. We then present our recent study of how the social presence of our robotic object-in-motion emerges in an encounter, involving experts from performance and design. Preliminary results of this study show that our robotic object can successfully convey movement qualities and their intended expressions as embodied by a dancer as part of the PBM process. Finally, we discuss how our observations can shift our focus from attributing qualities to the object to an emergence of qualities, propelled by the encounter. We believe our study provides a glimpse into the dynamic enactment of agency and how it requires both sides to 'give' for the robotic object's characteristics and the participants' experience to evolve. © 2019 AISB Convention.All right reserved.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;31-37;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JPS4J34L;journalArticle;2019;"Zhang, Y.; Qi, S.";User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-22335-9_24;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825;With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;350-366;NA;NA;11588 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GFLH4K8Q;conferencePaper;2019;"Arriaga, O.; Valdenegro-Toro, M.; Plöger, P.G.";Real-time convolutional neural networks for emotion and gender classification;ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2;Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.;2019;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;221-226;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BWLQGLGP;conferencePaper;2018;"Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.";Band of Brothers and Bolts: Caring about Your Robot Teammate;IEEE International Conference on Intelligent Robots and Systems;NA;NA;10.1109/IROS.2018.8594324;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062974656&doi=10.1109%2fIROS.2018.8594324&partnerID=40&md5=3d70c11d1788c11aba3e15e67bb7dd7b;It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected. © 2018 IEEE.;2018;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;1853-1858;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4RG5R55P;conferencePaper;2018;"Viet Tuyen, N.T.; Jeong, S.; Chong, N.Y.";Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction;IEEE International Conference on Intelligent Robots and Systems;NA;NA;10.1109/IROS.2018.8593974;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062987621&doi=10.1109%2fIROS.2018.8593974&partnerID=40&md5=755c3fc2f1c863f79b55e63646138d4d;Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator. © 2018 IEEE.;2018;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;2008-2013;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
W27CVGTJ;journalArticle;2018;"Obaid, M.; Aylett, R.; Barendregt, W.; Basedow, C.; Corrigan, L.J.; Hall, L.; Jones, A.; Kappas, A.; Küster, D.; Paiva, A.; Papadopoulos, F.; Serholt, S.; Castellano, G.";Endowing a robotic tutor with empathic qualities: Design and pilot evaluation;International Journal of Humanoid Robotics;NA;NA;10.1142/S0219843618500251;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058160758&doi=10.1142%2fS0219843618500251&partnerID=40&md5=60f7dbb32b8b7344ac5c0d8be964a7cb;As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions. © 2018 World Scientific Publishing Company.;2018;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;NA;NA;6;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
84PRAKQ9;journalArticle;2018;"Swiderska, A.; Küster, D.";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;Perception;NA;NA;10.1177/0301006618809919;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058656094&doi=10.1177%2f0301006618809919&partnerID=40&md5=2d29a1feddf28df7efb1c2f080d656ba;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain. © The Author(s) 2018.;2018;2021-02-15T22:35:21Z;2021-02-15T22:35:21Z;NA;1139-1152;NA;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
P8C7I9DY;conferencePaper;2018;"James, J.; Watson, C.I.; MacDonald, B.";Artificial Empathy in Social Robots: An analysis of Emotions in Speech;RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2018.8525652;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055010165&doi=10.1109%2fROMAN.2018.8525652&partnerID=40&md5=dc6f59a151e5db0e00c350424b2adb5f;Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;632-637;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2F274BF5;conferencePaper;2018;"Mollahosseini, A.; Abdollahi, H.; Mahoor, M.H.";Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots;RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2018.8525777;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058084838&doi=10.1109%2fROMAN.2018.8525777&partnerID=40&md5=0bd7cd6c5c720a217ec19787cc5218c6;Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;783-789;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LTCWCQVC;conferencePaper;2018;"Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.";Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience;RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2018.8525515;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058099794&doi=10.1109%2fROMAN.2018.8525515&partnerID=40&md5=64fa73971c77b5ebeb7809d94607f32a;Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;275-281;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RI2VN2HN;journalArticle;2018;Weber, A.S.;Emerging medical ethical issues in healthcare and medical robotics;International Journal of Mechanical Engineering and Robotics Research;NA;NA;10.18178/ijmerr.7.6.604-607;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056576175&doi=10.18178%2fijmerr.7.6.604-607&partnerID=40&md5=497839d4cdb779d178e34f97ca54283a;Due to the increasing sophistication and complexity of autonomous machines, Artificial Intelligence, Computerized Decision Support Systems (CDSS), natural language question-answering robots, and social / emotive medical robots, new medical ethics conundrums are arising. Unresolved questions revolve around autonomy, responsibility, empathy, trust, moral agency and the social and economic impacts of medical robots. © 2018 Int. J. Mech. Eng. Rob. Res.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;604-607;NA;6;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FSWK2JR8;journalArticle;2018;"Giannopulu, I.; Terada, K.; Watanabe, T.";Emotional empathy as a mechanism of synchronisation in child-robot interaction;Frontiers in Psychology;NA;NA;10.3389/fpsyg.2018.01852;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055052507&doi=10.3389%2ffpsyg.2018.01852&partnerID=40&md5=4e3455fc4099810d57dbf0e2e66d93bf;Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation. © 2018 Giannopulu, Terada and Watanabe.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;NA;NA;OCT;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8WYB9H3H;conferencePaper;2018;"Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.";Learning Empathy-Driven Emotion Expressions using Affective Modulations;Proceedings of the International Joint Conference on Neural Networks;NA;NA;10.1109/IJCNN.2018.8489158;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056556433&doi=10.1109%2fIJCNN.2018.8489158&partnerID=40&md5=14dfc5df0848f6da4a7837cf8b02c2d7;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;NA;NA;NA;2018-July;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9AH3U5ZY;conferencePaper;2018;"Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.";Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression;2018 15th International Conference on Ubiquitous Robots, UR 2018;NA;NA;10.1109/URAI.2018.8441767;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053513255&doi=10.1109%2fURAI.2018.8441767&partnerID=40&md5=0e071356103385e8abbf327f361ed75a;Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;377-382;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
246RWPT2;conferencePaper;2018;"Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri";Effectiveness of Android-Based Mobile Robots for Children Asperger Syndrome;Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care;NA;NA;10.1109/ICAITI.2018.8686759;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753069&doi=10.1109%2fICAITI.2018.8686759&partnerID=40&md5=af11f585df846db5c051b6434459ed42;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;208-212;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ILP9U7DB;conferencePaper;2018;"Iranzo, R.M.G.; Padilla-Zea, N.; Paderewski-Rodriguez, P.; Gonzalez-Gonzalez, C.S.";Empathy and virtual agents for learning applications in symbiotic systems;IEEE Global Engineering Education Conference, EDUCON;NA;NA;10.1109/EDUCON.2018.8363298;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048111659&doi=10.1109%2fEDUCON.2018.8363298&partnerID=40&md5=62f6bfb9db56637dd5db81cf57ef1d67;Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges. © 2018 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;694-697;NA;NA;2018-April;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GBMTEII5;conferencePaper;2018;"Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.";Design of counseling robot for production by 3D printer;Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017;NA;NA;10.1109/SITIS.2017.20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048855912&doi=10.1109%2fSITIS.2017.20&partnerID=40&md5=56c2a96a7c71f8e67c1dd1dcc7fee57d;Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called 'unazuki' in Japanese, a kind of 'nodding' to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a 'unazuki' or 'dialog promotion nodding' robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such 'unazuki', the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling. © 2017 IEEE.;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;56-62;NA;NA;2018-January;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Q33Q3PIS;conferencePaper;2018;"Wen, J.; Stewart, A.; Billinghurst, M.; Dey, A.; Tossell, C.; Finomore, V.";He who hesitates is lost (..in thoughts over a robot);ACM International Conference Proceeding Series;NA;NA;10.1145/3183654.3183703;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048734329&doi=10.1145%2f3183654.3183703&partnerID=40&md5=b3763171447b67063b193bdef1ec99ee;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams. © 2018 Copyright held by the owner/author(s).;2018;2021-02-15T22:35:22Z;2021-02-15T22:35:22Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TIVTSY6P;conferencePaper;2018;"Anshar, M.; Williams, M.-A.";Evolving artificial pain from fault detection through pattern data analysis;2017 IEEE International Conference on Real-Time Computing and Robotics, RCAR 2017;NA;NA;10.1109/RCAR.2017.8311945;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050694528&doi=10.1109%2fRCAR.2017.8311945&partnerID=40&md5=e13b223e149d6fdfdfed4b5bf7088696;Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment. © 2017 IEEE.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;694-699;NA;NA;2017-July;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FTXN9QDS;conferencePaper;2018;"Lehmann, H.; Broz, F.";Contagious Yawning in Human-Robot Interaction;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3173386.3177063;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045279372&doi=10.1145%2f3173386.3177063&partnerID=40&md5=c34b27a9315cc4b991b432223e771e6a;This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data. © 2018 Authors.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;173-174;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UJSGPNBG;conferencePaper;2018;"Björling, E.A.; Rose, E.; Ren, R.";Teen-Robot Interaction: A Pilot Study of Engagement with a Low-fidelity Prototype;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3173386.3177068;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045253387&doi=10.1145%2f3173386.3177068&partnerID=40&md5=7e37fee6758bc871489fac3d9259145c;Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies. © 2018 Authors.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;69-70;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4TVZ4EFL;conferencePaper;2018;"Kang, D.; Kim, S.; Kwak, S.S.";The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3173386.3177023;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045233579&doi=10.1145%2f3173386.3177023&partnerID=40&md5=ccd02586641d7f3d562f91a4cbdde86f;We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand. © 2018 Authors.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;143-144;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DWUK4I7A;conferencePaper;2018;"Correia, F.; Mascarenhas, S.; Prada, R.; Melo, F.S.; Paiva, A.";Group-based Emotions in Teams of Humans and Robots;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/3171221.3171252;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045153556&doi=10.1145%2f3171221.3171252&partnerID=40&md5=545acc745afe80d9bf6537715a5b6bbf;Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions. © 2018 ACM.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;261-269;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 19</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
84YQT7P4;journalArticle;2018;"Barakova, E.I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.";Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot;Connection Science;NA;NA;10.1080/09540091.2017.1350938;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034210275&doi=10.1080%2f09540091.2017.1350938&partnerID=40&md5=abe1cbc4737c660b91d193a7ede94cf5;In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game–the game with the robot was seen as more challenging and the robot–as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;81-98;NA;1;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7S9DVZEW;journalArticle;2018;"Vallverdú, J.; Nishida, T.; Ohmoto, Y.; Moran, S.; Lázare, S.";Fake empathy and human- robot interaction (HRI): A preliminary study;International Journal of Technology and Human Interaction;NA;NA;10.4018/IJTHI.2018010103;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033380873&doi=10.4018%2fIJTHI.2018010103&partnerID=40&md5=e8c1b39365a7dd4fb4e56730f51ebee7;Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call 'fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different 'humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi- angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment. © Copyright 2018, IGI Global.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;44-59;NA;1;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
69QJFWR2;journalArticle;2018;"Anshar, M.; Williams, M.-A.";Evolving robot empathy towards humans with motor disabilities through artificial pain generation;AIMS Neuroscience;NA;NA;10.3934/NEUROSCIENCE.2018.1.56;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046542640&doi=10.3934%2fNEUROSCIENCE.2018.1.56&partnerID=40&md5=94774a1cfd673260d0b54325f0e577c0;In contact assistive robots, a prolonged physical engagement between robots and humans with motor disabilities due to shoulder injuries, for instance, may at times lead humans to experience pain. In this situation, robots will require sophisticated capabilities, such as the ability to recognize human pain in advance and generate counter-responses as follow up emphatic action. Hence, it is important for robots to acquire an appropriate pain concept that allows them to develop these capabilities. This paper conceptualizes empathy generation through the realization of synthetic pain classes integrated into a robot's self-awareness framework, and the implementation of fault detection on the robot body serves as a primary source of pain activation. Projection of human shoulder motion into the robot arm motion acts as a fusion process, which is used as a medium to gather information for analyses then to generate corresponding synthetic pain and emphatic responses. An experiment is designed to mirror a human peer's shoulder motion into an observer robot. The results demonstrate that the fusion takes place accurately whenever unified internal states are achieved, allowing accurate classification of synthetic pain categories and generation of empathy responses in a timely fashion. Future works will consider a pain activation mechanism development. © 2018 the Author(s).;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;56-73;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XV2NDTWM;conferencePaper;2018;"Rincon, J.A.; Martin, A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.";EmIR: An emotional intelligent robot assistant;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052709722&partnerID=40&md5=ce9bc64a438e015843ae7c9faca4c4c1;The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare centre in the northern area of Portugal. © 2018 CEUR-WS. All rights reserved.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;NA;NA;NA;2166;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KUJ3FR4C;journalArticle;2018;"Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.";Smiles of children with ASD may facilitate helping behaviors to the robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-05204-1_6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5;Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;55-64;NA;NA;11357 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XVNIE98V;journalArticle;2018;"Kwon, O.; Kim, J.; Jin, Y.; Lee, N.";Impact of human-robot interaction on user satisfaction with humanoid-based healthcare;International Journal of Engineering and Technology(UAE);NA;NA;10.14419/ijet.v7i2.12.11038;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911;Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;68-75;NA;2;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EN2HCVLY;journalArticle;2018;"Kohori, T.; Hirayama, S.; Hara, T.; Muramatsu, M.; Naganuma, H.; Yamano, M.; Ichikawa, K.; Matsumoto, H.; Uchiyama, H.";Development and evaluation of an interactive therapy robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-76270-8_6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043505794&doi=10.1007%2f978-3-319-76270-8_6&partnerID=40&md5=9a33e24baf10f8235290981d937942ce;Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes. © Springer International Publishing AG, part of Springer Nature 2018.;2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;66-83;NA;NA;10714 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TM4CKA7V;conferencePaper;2018;Asada, M.;Artificial pain: Empathy, morality, and ethics as a developmental process of consciousness;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059816137&partnerID=40&md5=0c3d169632da3fae45d6ce00852c1fc0;"In this article, I propose a working hypothesis that the nervous system of pain sensation is a key component to shape robots' (artificial systems') conscious minds through the developmental process of empathy, morality, and ethics based on the MNS that promotes the emergence of concept of self (and others). First, the limitation of the current progress of AI focusing on deep learning is pointed out from a viewpoint of the emergence of consciousness. Next, the outline of ideological back-ground on issues of mind in a broad sense is shown. Then, cognitive developmental robotics (CDR) is introduced with two important concepts; physical embodiment and social interaction both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, an issue how robots (artificial systems) could be moral and legal agents is shown. © 2018 for the individual papers by the papers' authors. All rights reserved.";2018;2021-02-15T22:35:23Z;2021-02-15T22:35:23Z;NA;NA;NA;NA;2287;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7I94VC4X;journalArticle;2018;"Sancar, A.E.; Battini Sönmez, E.";A model for an emotional respondent robot;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-319-67934-1_37;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030167102&doi=10.1007%2f978-3-319-67934-1_37&partnerID=40&md5=fa973e11e625a3847ce9b2b2e7082ffc;The aim of this study is to design an emotional regulation model based on facial expressions. It is argued that emotions serve a critical function in intelligent behavior and some researchers posed the questions of whether a robot could be intelligent without emotions. As a result, emotion recognition and adequate reaction are essential requirements for enhancing the quality of human robot interaction. This study proposes a computational model of emotion capable of clustering the perceived facial expression, and using cognitive reappraisal to switch its internal state so as to give a human-like reaction over the time. That is, the agent learns the person’s facial expression by using Self Organizing Map, and gives it a meaning by mapping the perceived expression into its internal state diagram. As a result, the presented model implements empathy with the aim to enhance human-robot communication. © Springer International Publishing AG 2018.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;406-416;NA;NA;678;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CA9FLLSM;journalArticle;2018;"Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.";Towards empathetic human-robot interactions;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-75487-1_14;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;173-193;NA;NA;9624 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VNMN2NNA;journalArticle;2018;"Qureshi, S.; Hagelbäck, J.; Iqbal, S.M.Z.; Javaid, H.; Lindley, C.A.";Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-030-01054-6_25;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;347-363;NA;NA;868;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Q9NH6WWN;journalArticle;2018;"Chen, A.C.-Y.; Lin, Y.-C.";Warm Robot Classroom_Using Wearable Technology as a Gateway to Culturally Responsive Teaching;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-91152-6_19;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050464253&doi=10.1007%2f978-3-319-91152-6_19&partnerID=40&md5=1c19f03d879291cd2cc0f914750ebf1e;[Warm Robot classroom] is related to answer the question of introduce computational thinking teaching aids and course design by studies robots and wearables with social humanity. The discussion is about how to cultivate students with the rational technology thinking and humanity empathy? The research method includes design and research on cultural response teaching curriculum with the composition of product designers and electronic engineers, planning of teaching contents, and solicitation of teaching and learning of cultural responses from more than five kinds of different cultural backgrounds through the a one semester course. Develop the performances from different cultural groups through 3D printing, laser cutting and digital embroidery creations and assess the applicability of course design. This course was held with 64 participants (9 different countries, 5 backgrounds). We describe our experience in designing and organizing a wearable course. We will show that (1) Three interactive modules of difficult levels of soft wearable prototypes. (2) The culturally responsive curriculum. (3) The learning outcome of the teaching implementations with interactive toolkits from the final performance. The result shows that curriculum with different background works together can built students from either side to response to each other. © 2018, Springer International Publishing AG, part of Springer Nature.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;239-253;NA;NA;10925 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4SR5G2GX;journalArticle;2018;Korać, S.T.;Depersonalisation of killing: Towards a 21st century use of force “beyond good and evil?” [Depersonalizacija ubijanja ka upotrebi sile u 21. Veku „s onu stranu dobra i zla?“];Filozofija i Drustvo;NA;NA;10.2298/FID1801049K;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059193212&doi=10.2298%2fFID1801049K&partnerID=40&md5=87fab0df617879e99bff27aab7f6a083;The article analyses how robotisation as the latest advance in military technology can depersonalise the methods of killing in the 21st century by turning enemy soldiers and civilians into mere objects devoid of moral value. The departing assumption is that robotisation of warfare transforms military operations into automated industrial processes with the aim of removing empathy as a redundant ‘cost’. The development of autonomous weapons systems raises a number of sharp ethical controversies related to the projected moral insensitivity of robots regarding the treatment of enemies and civilian population. The futurist vision of war as a foreign policy instrument entirely ‘purified’ of the risk of morally wrong actions is in opposition with the negative effects of the use of drones. The author concludes that the use of lethal robots in combat would eventually remove enemy soldiers and civilians from the realm of ethical reasoning and deprive them of human dignity. Decision to kill in military operations ought to be based on human conscience as the only proper framework of making decisions by reasoning whether an action is right or wrong. © 2018, University of Belgrade - Institute for Philosophy and Social Theory. All rights reserved.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;49-64;NA;1;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
89BFKERS;journalArticle;2018;Baylor, A.L.;Three research directions for affective learning technologies;Proceedings of International Conference of the Learning Sciences, ICLS;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852093&partnerID=40&md5=f752722081155797b31c18bfb8421fc9;"Looking to the future of advanced learning technology research, understanding, supporting and explicitly designing for the role of affect is of great importance. I highlight three emerging areas of research with current research exemplars. First, simulating affect is necessary to enhance human-like relationships with technology; for example, with artificially intelligent virtual agents, or teachable robots as learning companions. Second, sensing and responding to learner affect in immersive learning experiences as well as learning at scale is rapidly evolving; for example, through affective intelligent tutoring systems, or dashboards driven by multimodal analytics. Third, designing technology-based learning experiences that promote, elicit and support affective outcomes requires theory building within the learning sciences; for example, to realize outcomes such as empathy or curiosity and formulate linkages to learning. Finally, I suggest how research in these areas of affective technology afford new opportunities to prepare learners for future learning and work environments. © ISLS.";2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;1843-1846;NA;2018-June;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WQZ3L3SE;conferencePaper;2018;"Vallejo-Jiménez, M.M.; Martínez-Puerta, J.J.; Agudelo, S.B.; Salgado, N.D.";SENA Tecnoacademia Risaralda and Caldas as a collaborative learning scenario in robotics;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062656500&partnerID=40&md5=dffca2434457967c2b9144db0e10a2d5;The Research, Technological Development and Innovation System of SENA (SENNOVA) of Colombia, has the purpose of strengthening the standards of quality and relevance, through programs and projects as Tecnoacademias, defined as a STEM learning scenario, equipped with emerging technologies to develop innovation-oriented skills, through project training, to students of basic and secondary education, in courses such as Mathematics, Physics, Chemistry, Biology, applied sciences such as Robotics, Nanotechnology, Biotechnology and Virtual Technologies. This work presents some of the activities carried out by the apprentices through the Educational Robotics in Tecnoacademia Risaralda and Tecnoacademia Caldas sites, based on Industrial and Mechatronic Design methodologies, using LEGO MINDSTORM EV3 kits and Design Thinking for educators and LEGO, successfully applied in the EducarChile program. It is based on three fundamental pillars, which are empathy, collaboration and experimentation, which are presented in the five (5) phases of the methodology. It should be noted that the tools of innovation and prototyping per se, do not serve much if the team that executes them is not immersed in a culture of tolerance, teamwork, leadership and if there is no feedback and if the capacities are not taken into account and strengths of the work team. All this was achieved through different prototypes of robots of light and robust type originated in a PON scenario (problem, opportunity, needs). © 2018 CEUR-WS. All rights reserved.;2018;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;NA;NA;NA;2312;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TVQSLUAJ;conferencePaper;2017;"Burns, H.D.; Lesseig, K.";Empathy in middle school engineering design process;Proceedings - Frontiers in Education Conference, FIE;NA;NA;10.1109/FIE.2017.8190669;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043250525&doi=10.1109%2fFIE.2017.8190669&partnerID=40&md5=2de94d98be1bbb33936099368e3ff4f4;"This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word ""empathy"" is not used, these problems are defined from an empathetic perspective as ""situations people want to change"" of ""social and global significance."" However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design. © 2017 IEEE.";2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;1-4;NA;NA;2017-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
YQLGH7LN;conferencePaper;2017;"Kurashige, K.; Sakurai, E.; Knauf, R.; Tsuruta, S.; Sakurai, Y.; Damiani, E.";Context respectful counseling agent integrated with robot nodding for dialog promotion;2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017;NA;NA;10.1109/SMC.2017.8122833;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044231442&doi=10.1109%2fSMC.2017.8122833&partnerID=40&md5=9b50118f2dd3ce8a24156a3edb15f411;"Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling. © 2017 IEEE.";2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;1540-1545;NA;NA;2017-January;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EZPFKTCQ;journalArticle;2017;"Borenstein, J.; Arkin, R.C.";Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior;AI and Society;NA;NA;10.1007/s00146-016-0684-1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000443585&doi=10.1007%2fs00146-016-0684-1&partnerID=40&md5=aeb23d28928c11d0e8a8c5616b33c63b;"An under-examined aspect of human–robot interaction that warrants further exploration is whether robots should be permitted to influence a user’s behavior for that person’s own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user’s behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user’s empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be. © 2016, Springer-Verlag London.";2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;499-507;NA;4;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZQC8JFKH;journalArticle;2017;"Chikaraishi, T.; Yoshikawa, Y.; Ogawa, K.; Hirata, O.; Ishiguro, H.";"Creation and staging of android theatre ""Sayonara"" towards developing highly human-like robots";Future Internet;NA;NA;10.3390/fi9040075;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040790411&doi=10.3390%2ffi9040075&partnerID=40&md5=7741ec53279dea95f8e1cde8863ea639;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world. © 2016 by the authors.;2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
G4B52VS5;journalArticle;2017;"Paiva, A.; Leite, I.; Boukricha, H.; Wachsmuth, I.";Empathy in virtual agents and robots: A survey;ACM Transactions on Interactive Intelligent Systems;NA;NA;10.1145/2912150;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030721207&doi=10.1145%2f2912150&partnerID=40&md5=0ee6b019cd9a77afad3da844eab99772;This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user's or another agent's emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent's situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future. Copyright is held by the owner/author(s).;2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;NA;NA;3;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 43</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
45SJLQPX;journalArticle;2017;"Abubshait, A.; Wiese, E.";You look human, but act like a machine: Agent appearance and behavior modulate different aspects of human-robot interaction;Frontiers in Psychology;NA;NA;10.3389/fpsyg.2017.01393;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028087757&doi=10.3389%2ffpsyg.2017.01393&partnerID=40&md5=7c76b89b0bf2a723ace310a3123236ab;Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed. © 2017 Abubshait and Wiese.;2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;NA;NA;AUG;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 31</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DA3ZHCTE;conferencePaper;2017;"Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.";Learning human behavior for emotional body expression in socially assistive robotics;2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2017;NA;NA;10.1109/URAI.2017.7992882;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034217006&doi=10.1109%2fURAI.2017.7992882&partnerID=40&md5=9ad61da9fc07256c0888f6888db1c4a2;Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots. © 2017 IEEE.;2017;2021-02-15T22:35:24Z;2021-02-15T22:35:24Z;NA;45-50;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QJ8KNHCS;journalArticle;2017;"Rouaix, N.; Retru-Chavastel, L.; Rigaud, A.-S.; Monnet, C.; Lenoir, H.; Pino, M.";Affective and engagement issues in the conception and assessment of a robot-assisted psychomotor therapy for persons with dementia;Frontiers in Psychology;NA;NA;10.3389/fpsyg.2017.00950;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021340604&doi=10.3389%2ffpsyg.2017.00950&partnerID=40&md5=76571d1aa765fd440c392484c9fc5bae;"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a ""control software"" for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient- therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction. © 2017 Rouaix, Retru-Chavastel, Rigaud, Monnet, Lenoir and Pino.";2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;NA;NA;JUN;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Z79LTRD2;conferencePaper;2017;"Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.";A laughing-driven pupil response system for inducing empathy;SII 2016 - 2016 IEEE/SICE International Symposium on System Integration;NA;NA;10.1109/SII.2016.7844051;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015395679&doi=10.1109%2fSII.2016.7844051&partnerID=40&md5=79e71dbc5d0d655d939d8f50b2639752;Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy. © 2016 IEEE.;2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;520-525;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
G46Y8JWD;journalArticle;2017;"De Carolis, B.; Ferilli, S.; Palestra, G.";Simulating empathic behavior in a social assistive robot;Multimedia Tools and Applications;NA;NA;10.1007/s11042-016-3797-0;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988691125&doi=10.1007%2fs11042-016-3797-0&partnerID=40&md5=3d3264938f9865faf7b3dd27a9d15393;When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user’s affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot’s affective state and, consequently, the most appropriate empathic behavior. The robot’s empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot. © 2016, Springer Science+Business Media New York.;2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;5073-5094;NA;4;76;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 15</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
24E8HTWC;conferencePaper;2017;"Lewandowska-Tomaszczyk, B.; Wilson, P.A.";Compassion, empathy and sympathy expression features in affective robotics;7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings;NA;NA;10.1109/CogInfoCom.2016.7804526;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2;"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.";2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;65-70;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 10</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
N5T72L6S;journalArticle;2017;"Woo, J.; Botzheim, J.; Kubota, N.";Emotional empathy model for robot partners using recurrent spiking neural network model with Hebbian-LMS learning;Malaysian Journal of Computer Science;NA;NA;10.22452/mjcs.vol30no4.1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036526555&doi=10.22452%2fmjcs.vol30no4.1&partnerID=40&md5=7bf71955acddbdefa5deeff07d6d74dc;"This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply ""Hebbian-LMS"" learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner ""iPhonoid-C"". Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.";2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;258-285;NA;4;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6ZVT72Y7;journalArticle;2017;"Chumkamon, S.; Hayashi, E.";Consciousnes-based emotion and behavior of pet robot with brain-inspired method;Information (Japan);NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1;A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.;2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;615-629;NA;1;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EYVJP9HQ;journalArticle;2017;"Cho, H.-K.; Oh, J.; Lee, K.";A study on the potential roles of a robot peer in socio-emotional development of children;International Journal of Computational Vision and Robotics;NA;NA;10.1504/IJCVR.2017.083447;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b;This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.;2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;335-343;NA;3;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MF9GB4SQ;journalArticle;2017;"Fan, L.; Scheutz, M.; Lohani, M.; McCoy, M.; Stokes, C.";Do we need emotionally intelligent artificial agents? First results of human perceptions of emotional intelligence in humans compared to robots;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-67401-8_15;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029009078&doi=10.1007%2f978-3-319-67401-8_15&partnerID=40&md5=40847ef441d91c4b0c0d33b427b6059c;Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent’s emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them. © Springer International Publishing AG 2017.;2017;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;129-141;NA;NA;10498 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JMB4TW75;conferencePaper;2016;"Ranieri, C.M.; Romero, R.A.F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;Proceedings - 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016;NA;NA;10.1109/LARS-SBR.2016.13;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010416838&doi=10.1109%2fLARS-SBR.2016.13&partnerID=40&md5=48a1a71aed354854f322eb1a82dcc7eb;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness. © 2016 IEEE.;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UGN4QZDJ;conferencePaper;2016;"Sin, Y.M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.-I.; Miyake, Y.";Evaluation of a head motion synchronization system in the communicative process between human and robot;2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan, SICE 2016;NA;NA;10.1109/SICE.2016.7749252;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263059&doi=10.1109%2fSICE.2016.7749252&partnerID=40&md5=ee5466b2a448823dac918c1ff6b6ac0e;An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation. © 2016 The Society of Instrument and Control Engineers - SICE.;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;1514-1519;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
S7K4265H;journalArticle;2016;"Chumkamon, S.; Hayashi, E.; Koike, M.";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;Biologically Inspired Cognitive Architectures;NA;NA;10.1016/j.bica.2016.09.004;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992027508&doi=10.1016%2fj.bica.2016.09.004&partnerID=40&md5=648a687454e6dd807ff6eafa3fbbcddd;"Companion or 'pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross-communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like 'emotion' and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. © 2016 Elsevier B.V. All rights reserved.";2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;51-67;NA;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BVE6UZPM;journalArticle;2016;"Roudposhti, K.K.; Nunes, U.; Dias, J.";Probabilistic social behavior analysis by exploring body motion-based patterns;IEEE Transactions on Pattern Analysis and Machine Intelligence;NA;NA;10.1109/TPAMI.2015.2496209;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978763318&doi=10.1109%2fTPAMI.2015.2496209&partnerID=40&md5=db01d33fa9bc27fd5f8ab2a7bcd42047;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction. © 1979-2012 IEEE.;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;1679-1691;NA;8;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RM66TMES;conferencePaper;2016;"Chumkamon, S.; Masato, K.; Hayashi, E.";Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot;Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015;NA;NA;10.1109/SMC.2015.45;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964478149&doi=10.1109%2fSMC.2015.45&partnerID=40&md5=9f91bfb404d3b6db6083d78cea8a6634;This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA). © 2015 IEEE.;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;185-190;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SI2CKDXA;conferencePaper;2016;Coeckelbergh, M.;Moving machines: Robots, empathy, and the performance of suffering;AISB Annual Convention 2016, AISB 2016;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041917924&partnerID=40&md5=4dcb71c2728f658225bedc448591eef2;NA;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KXP9KLH5;journalArticle;2016;"Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.";Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy;Paladyn;NA;NA;10.1515/pjbr-2016-0005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88;An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.;2016;2021-02-15T22:35:25Z;2021-02-15T22:35:25Z;NA;55-66;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 12</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WR9LZTM9;journalArticle;2016;"Giambattista, A.; Teixeira, L.; Ayanoğlu, H.; Saraiva, M.; Duarte, E.";Expression of emotions by a service robot: A pilot study;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-40406-6_31;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977557359&doi=10.1007%2f978-3-319-40406-6_31&partnerID=40&md5=4e3540b931b764e55a11e0446d99c472;A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot’s facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children. © Springer International Publishing Switzerland 2016.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;328-336;NA;NA;9748;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZIXRVSK9;journalArticle;2016;Musiall, M.;Magical thinking and empathy towards robots;Frontiers in Artificial Intelligence and Applications;NA;NA;10.3233/978-1-61499-708-5-347;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992603376&doi=10.3233%2f978-1-61499-708-5-347&partnerID=40&md5=d0fd98141be39c30e95ee0a8507671b6;"This paper aims to understand why human beings develop empathetic attitudes towards robots. Whilst much research studies this issue from the perspective of the natural sciences, by referring to biological features of the human brain, it is also possible to investigate it from the perspective of the humanities by referring to humans' cultural features. After establishing animation as a necessary condition of empathy towards robots, the presentation delivers a hypothesis that magical thinking - typical for children, members of ""primitive"" societies and individuals with mental disorders - is involved in the empathetic relations with robots. Furthermore, arguments to defend and clarify this hypothesis are presented. © 2016 The authors and IOS Press. All rights reserved.";2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;347-356;NA;NA;290;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BXMP89GH;journalArticle;2016;"Sorbello, R.; Chella, A.; Giardina, M.; Nishio, S.; Ishiguro, H.";An architecture for Telenoid robot as empathic conversational android companion for elderly people;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-319-08338-4_68;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974382&doi=10.1007%2f978-3-319-08338-4_68&partnerID=40&md5=284d20453f0caff779f01dbae2648464;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user. © Springer International Publishing Switzerland 2016.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;939-953;NA;NA;302;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9CSCB3M8;journalArticle;2016;"Bechade, L.; Duplessis, G.D.; Devillers, L.";Empirical study of humor support in social human-robot interaction;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-39862-4_28;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978870310&doi=10.1007%2f978-3-319-39862-4_28&partnerID=40&md5=1ef7ba186fefcb5c0b2d3249f892d26b;As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event’s context. © Springer International Publishing Switzerland 2016.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;305-316;NA;NA;9749;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
C43TSVNB;journalArticle;2016;"Biswas, M.; Murray, J.";The effects of cognitive biases in long-term human-robot interactions: Case studies using three cognitive biases on MARC the humanoid robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-47437-3_15;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992530101&doi=10.1007%2f978-3-319-47437-3_15&partnerID=40&md5=04c0c77ee6491b684750e79ae72cd6c4;The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant’s names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours. © Springer International Publishing AG 2016.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;148-158;NA;NA;9979 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CA5S3ZYB;conferencePaper;2016;"Fung, P.; Dey, A.; Siddique, F.B.; Lin, R.; Yang, Y.; Yan, W.; Yin, R.C.H.";Zara: An empathetic interactive virtual agent;Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994232510&partnerID=40&md5=2f53e4c08a96e5fc3df960ad4e028852;Zara, or 'Zara the Supergirl', is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented humanrobot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015. Copyright © 2016 ISCA.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;1176-1177;NA;NA;08-12-September-2016;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XHBMV458;journalArticle;2016;"Sejima, Y.; Egawa, S.; Sato, Y.; Watanabe, T.";A pupil response system using hemispherical displays for enhancing affective conveyance;Journal of Advanced Mechanical Design, Systems and Manufacturing;NA;NA;10.1299/JAMDSM.2019JAMDSM0032;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078309015&doi=10.1299%2fJAMDSM.2019JAMDSM0032&partnerID=40&md5=29a5562526052c2c6b4b3c50b9ee2dfb;In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker’s affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot’s eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance. © 2019 The Japan Society of Mechanical Engineers.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;NA;NA;4;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
N54MSGWS;conferencePaper;2016;"Fung, P.; Dey, A.; Bin Siddique, F.; Lin, R.; Yang, Y.; Bertero, D.; Yan, W.; Yin, R.C.H.; Wu, C.-S.";Zara: A virtual interactive dialogue system incorporating emotion, sentiment and personality recognition;COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048777533&partnerID=40&md5=fbcd4dcbaee2c6a3edb8e95be195275d;Zara, or 'Zara the Supergirl' is a virtual robot, that can exhibit empathy while interacting with an user, with the aid of its built in facial and emotion recognition, sentiment analysis, and speech module. At the end of the 5-10 minute conversation, Zara can give a personality analysis of the user based on all the user utterances. We have also implemented a real-time emotion recognition, using a CNN model that detects emotion from raw audio without feature extraction, and have achieved an average of 65.7% accuracy on six different emotion classes, which is an impressive 4.5% improvement from the conventional feature based SVM classification. Also, we have described a CNN based sentiment analysis module trained using out-of-domain data, that recognizes sentiment from the speech recognition transcript, which has a 74.8 F-measure when tested on human-machine dialogues. © COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;278-281;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7ZJ6TAYM;journalArticle;2016;"Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.";Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents;Transactions of the Japanese Society for Artificial Intelligence;NA;NA;10.1527/tjsai.C-G31;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a;There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.;2016;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;NA;NA;4;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5LR4896U;conferencePaper;2015;"Darling, K.; Nandy, P.; Breazeal, C.";Empathic concern and the effect of stories in human-robot interaction;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2015.7333675;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954066644&doi=10.1109%2fROMAN.2015.7333675&partnerID=40&md5=cdb1729f65a77b7680f2decb250845e0;People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses. © 2015 IEEE.;2015;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;770-775;NA;NA;2015-November;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 35</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
S2REIJ6R;conferencePaper;2015;Franco, G.A.M.;Evaluation of the emotional answer in HRI on a game situation;Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015;NA;NA;10.1145/2824893.2824897;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979647991&doi=10.1145%2f2824893.2824897&partnerID=40&md5=3c3eddadd8b9eb02473ab17a28a8c9ab;This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.;2015;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZNKZ4WQB;journalArticle;2015;"Suzuki, Y.; Galli, L.; Ikeda, A.; Itakura, S.; Kitazaki, M.";Measuring empathy for human and robot hand pain using electroencephalography;Scientific Reports;NA;NA;10.1038/srep15924;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946601210&doi=10.1038%2fsrep15924&partnerID=40&md5=7480591126ea8768b8ce1b5b5879fca1;This study provides the first physiological evidence of humans € ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.;2015;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 53</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X4PQR5JX;journalArticle;2015;"Han, J.; Jo, M.; Hyun, E.; So, H.-J.";Examining young children’s perception toward augmented reality-infused dramatic play;Educational Technology Research and Development;NA;NA;10.1007/s11423-015-9374-9;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939948308&doi=10.1007%2fs11423-015-9374-9&partnerID=40&md5=8ca770924db1fe1a9950b09569d11ad1;Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children’s satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children’s perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5–6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children’s perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed. © 2015, Association for Educational Communications and Technology.;2015;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;455-474;NA;3;63;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 47</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SVXYXU54;conferencePaper;2015;"Ji, S.H.; You, S.J.; Cho, H.-K.";Design of Emotional Conversations with a Child for a Role Playing Robot;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2701973.2702009;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969278892&doi=10.1145%2f2701973.2702009&partnerID=40&md5=22de8e058c04462574e4504c77cf3ddd;The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot. © 2015 Authors.;2015;2021-02-15T22:35:26Z;2021-02-15T22:35:26Z;NA;73-74;NA;NA;02-05-March-2015;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HCWK6X7V;conferencePaper;2015;"Jeong, S.; Gu, J.; Shin, D.-H.";I am Interested in What You are Saying: Role of Nonverbal Immediacy Cues in Listening;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2701973.2702040;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969131750&doi=10.1145%2f2701973.2702040&partnerID=40&md5=430338bf874134357991c30484c63e40;Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot. © 2015 Authors.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;129-130;NA;NA;02-05-March-2015;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
YVGHPNHK;journalArticle;2015;"Tisseron, S.; Tordo, F.; Baddoura, R.";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0268-5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924301513&doi=10.1007%2fs12369-014-0268-5&partnerID=40&md5=ae9ddda552ec58f57dc89db088c53239;The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. © 2014, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;97-102;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KD8HQZ4B;journalArticle;2015;"Lim, A.; Okuno, H.G.";A Recipe for Empathy: Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0262-y;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924287073&doi=10.1007%2fs12369-014-0262-y&partnerID=40&md5=0b55eb0be5c80bdacedbf176adf6fbd4;Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (“flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence. © 2014, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;35-49;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 16</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LHTJWXST;journalArticle;2015;Asada, M.;Towards Artificial Empathy: How Can Artificial Empathy Follow the Developmental Pathway of Natural Empathy?;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0253-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924289838&doi=10.1007%2fs12369-014-0253-z&partnerID=40&md5=c0449e6915eb39b5a3612055fec7f938;"The design of artificial empathy is one of the most essential issues in social robotics. This is because empathic interactions with ordinary people are needed to introduce robots into our society. Several attempts have been made for specific situations. However, such attempts have provided several limitations; thus, diminishing authenticity. The present article proposes “affective developmental robotics (hereafter, ADR),” which provides more authentic artificial empathy based on the concept of cognitive developmental robotics (hereafter, CDR). First, the evolution and development of empathy as revealed in neuroscience and biobehavioral studies are reviewed, moving from emotional contagion to envy and schadenfreude. These terms are then reconsidered from the ADR/CDR viewpoint, particularly along the developmental trajectory of self-other cognition. Next, a conceptual model of artificial empathy is proposed based on an ADR/CDR viewpoint and discussed with respect to several existing studies. Finally, a general discussion and proposals for addressing future issues are given. © 2014, The Author(s).";2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;19-33;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 35</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ATP9MI44;journalArticle;2015;"Damiano, L.; Dumouchel, P.; Lehmann, H.";Towards Human–Robot Affective Co-evolution Overcoming Oppositions in Constructing Emotions and Empathy;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0258-7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924341694&doi=10.1007%2fs12369-014-0258-7&partnerID=40&md5=80851efee3b5a5866fe3182d7ca5c9b2;This article deals with contemporary research aimed at building emotional and empathic robots, and gives an overview of the field focusing on its main characteristics and ongoing transformations. It interprets the latter as precursors to a paradigmatic transition that could significantly change our social ecologies. This shift consists in abandoning the classical view of emotions as essentially individual states, and developing a relational view of emotions, which, as we argue, can create genuinely new emotional and empathic processes—dynamics of “human–robot” affective coordination supporting the development of mixed (human–robot) ecologies. © 2014, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;7-18;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 19</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8HCLCWW4;journalArticle;2015;"Mirnig, N.; Strasser, E.; Weiss, A.; Kühnlenz, B.; Wollherr, D.; Tscheligi, M.";Can You Read My Face?: A Methodological Variation for Assessing Facial Expressions of Robotic Heads;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0261-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924308183&doi=10.1007%2fs12369-014-0261-z&partnerID=40&md5=c7634d4e7d25e2feda063822ac3b47b8;Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants’ dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach. © 2014, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;63-76;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SSB4S63F;journalArticle;2015;Airenti, G.;The Cognitive Bases of Anthropomorphism: From Relatedness to Empathy;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0263-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924336727&doi=10.1007%2fs12369-014-0263-x&partnerID=40&md5=7771b24f56c2451979b51997da835912;Humans may react very differently with respect to mechanical devices, including robots. They can interact with them with delight or retreat in aversion or fear. According to the famous model of the uncanny valley these opposite reactions depend on the degree of familiarity that different artifacts engender in humans. The aim of my work is trying to find out the cognitive bases of familiarity, analyzing the origin of anthropomorphic projection, namely human disposition to attribute anthropomorphic features - like intentions or feelings—to artifacts. I shall discuss two concepts: relatedness and empathy, and argue that relatedness is the precondition for empathy. The fact that it is possible to attribute anthropomorphic features virtually to any object shows that resemblance is not the point. Anthropomorphism is a kind of relation that humans establish with an artifact, and in order to comprehend this phenomenon we have to focus on the relational aspect. I shall argue that what we call anthropomorphism is an extension to nonhumans of forms of interactions typical of human communication, i.e. the attribution to an artifact of the position of interlocutor in a possible dialogue. It can be shown that attributing to an artifact the position of interlocutor in a dialogue implies dealing with it as if it were endowed of the features characterizing human mind, i.e. mental states and emotions. © 2015, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;117-127;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 21</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SI38TS4V;conferencePaper;2015;"Seo, S.H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J.E.";Poor Thing! Would You Feel Sorry for a Simulated Robot?: A comparison of empathy toward a physical and a simulated robot;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2696454.2696471;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943526431&doi=10.1145%2f2696454.2696471&partnerID=40&md5=5ac18b53dc70b062ef9d8f67cfea37d1;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. © 2015 ACM.";2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;125-132;NA;NA;2015-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 49</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6A36RKRE;conferencePaper;2015;"Yoshida, N.; Nakataniy, Y.; Yonezawa, T.";Breathing expression for intimate communication corresponding to the physical distance and contact between human and robot;EAI International Conference on Bio-inspired Information and Communications Technologies (BICT);NA;NA;10.4108/eai.3-12-2015.2262419;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052166553&doi=10.4108%2feai.3-12-2015.2262419&partnerID=40&md5=9713dbd5e5ed533a7a82dfbe30666dfd;"In this paper, we propose living-being-like breathing expressions concurrent with both aspiration and utterances using a stuffed-Toy robot in order to enable intimate interactions. The focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two. From the factor analysis of the impression for the word ıntimacy"" and the distance between the robot and the participants, it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility. © 2016 ICST.";2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JLFKUUAU;journalArticle;2015;"Fuente, L.A.; Ierardi, H.; Pilling, M.; Crook, N.T.";Influence of upper body pose mirroring in human-robot interaction;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-25554-5_22;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983598081&doi=10.1007%2f978-3-319-25554-5_22&partnerID=40&md5=3f7276e6bca1a0a0ba38bb00b597daee;This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people’s perception of their conversation with it. A set of twelve questions about the participants’ university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;214-223;NA;NA;9388 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Y9MRHLSG;journalArticle;2015;"Garza, A.A.; Lemus Zuñiga, L.G.; del Rosario Baltazar, M.; Marquez, B.Y.; Ramírez, C.L.; Romero, K.";Intelligent social agent for the development of social relations based on primary emotions;Smart Innovation, Systems and Technologies;NA;NA;10.1007/978-3-319-19728-9_28;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947904053&doi=10.1007%2f978-3-319-19728-9_28&partnerID=40&md5=e146418f66b057d4a871dfc2954a655e;This article shows the experimentation with emotions in a scenario with a specific task, where the main goal is to see the behavior of emotions to the task given to them that based on the level of empathy that exists between these emotions, all this work is done within a Social Multi-Agent System, in which it is intended that two or more robots can present a profile of personality and emotion for the search of empathy between them to make a team. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;337-344;NA;NA;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EZJQ3GD6;journalArticle;2015;"Ahn, T.-B.; Kang, E.-S.";Evaluation study of a human-sized bipedal humanoid robot through a public demonstration in a science museum;Journal of Institute of Control, Robotics and Systems;NA;NA;10.5302/J.ICROS.2015.15.0109;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941275810&doi=10.5302%2fJ.ICROS.2015.15.0109&partnerID=40&md5=4fa5bf50debed289c455d163e9699f20;Although human-sized bipedal humanoid robots have been developed as the ideal form of human-friendly robots, studies of humanoid robots from the user perspective and of actual interaction between humanoid robots and the public in daily environments are few. This paper presents a long-term public demonstration that encouraged interaction between a humanoid robot and unspecified individuals. We have collected a significant amount of subjective evaluation data from the public by performing a storytelling demonstration that enhanced people's empathy towards the robot. The evaluation model consists of the robot's human friendliness, which involves its impression on humans, interaction with humans, and imitation of human motions and the robot's human appearance which involves gender, age, height, and body type. This study shows that there is no significant difference in human-friendliness between gender groups (male and female), while there is a significant difference between age groups (children and adults). In human appearance, it appears that there is no significant difference between either gender groups or age groups, except for the case of the robot's height. © ICROS 2015.;2015;2021-02-15T22:35:27Z;2021-02-15T22:35:27Z;NA;849-857;NA;9;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
25XBINKU;conferencePaper;2015;"Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani Sherman, T.";Design and Evaluation of a Peripheral Robotic Conversation Companion;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2696454.2696495;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943575630&doi=10.1145%2f2696454.2696495&partnerID=40&md5=25d296afd2bb48f4924a435a5cdb57c8;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy. © 2015 ACM.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;3-10;NA;NA;2015-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 54</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4SF4WMDK;conferencePaper;2015;Koltick, N.;Autonomous botanist: The poetic potentials of a new robotic species;ACADIA 2015 - Computational Ecologies: Design in the Anthropocene: Proceedings of the 35th Annual Conference of the Association for Computer Aided Design in Architecture;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051989770&partnerID=40&md5=d2e2f91d070c255ab324f046a72147b0;This project begins by asking questions about ethics and empathy towards robots, and contemplates the future of their behavior in ways not informed by pragmatics or economy. What if a robot had a hobby? How do robots make aesthetic decisions? What is a robot’s point of view? It seeks to shift perception of robotic agency and allow the audience to embody the robotic gardeners’ vision, behavior and influence its aesthetics. By amplifying perceptual differences between humans and robots and we allow for both tangible and virtual embodiment experiences from multiple scales and perspectives. This compelling design speculation seeks to deploy a variety of interactive computational techniques, exploring novel forms and behaviors in order to engage deeper philosophical issues surrounding aesthetics, non-human agencies, and the role of the synthetic in the future. © 2015 ACADIA. All rights reserved.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;NA;NA;NA;2015-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VHWTXWR4;journalArticle;2015;"Vallverdú, J.; Casacuberta, D.";Ethical and technical aspects of emotions to create empathy in medical machines;Intelligent Systems, Control and Automation: Science and Engineering;NA;NA;10.1007/978-3-319-08108-3_20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e;This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;341-362;NA;NA;74;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WD3C6KVD;conferencePaper;2015;"Hood, D.; Lemaignan, S.; Dillenbourg, P.";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2696454.2696479;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943550932&doi=10.1145%2f2696454.2696479&partnerID=40&md5=c5d573890e88b608b9382205e80c22f5;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education. © 2015 ACM.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;83-90;NA;NA;2015-March;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 78</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
F77AVV8P;journalArticle;2015;"Pettinati, M.J.; Arkin, R.C.";Towards a robot computational model to preserve dignity in stigmatizing patient-caregiver relationships;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-25554-5_53;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983551906&doi=10.1007%2f978-3-319-25554-5_53&partnerID=40&md5=101e69f850eee5fb87938dd20f24c8b8;Parkinson’s disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patientcaregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;532-542;NA;NA;9388 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
P8IHQXUZ;conferencePaper;2015;"Rasool, Z.; Masuyama, N.; Islam, M.N.; Loo, C.K.";Empathic interaction using the computational emotion model;Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015;NA;NA;10.1109/SSCI.2015.26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964955492&doi=10.1109%2fSSCI.2015.26&partnerID=40&md5=a46376a05176a93e601b99827119b808;This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-Arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors. © 2015 IEEE.;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;109-116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DHJNFCIH;journalArticle;2015;Nijholt, A.;Designing Humor for Playable Cities;Procedia Manufacturing;NA;NA;10.1016/j.promfg.2015.07.358;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009957570&doi=10.1016%2fj.promfg.2015.07.358&partnerID=40&md5=f471888187c5afeb3635554f745fa9c3;Smartness, made possible by intelligent sensors and actuators, is invading our home, office and public environments. This smartness monitors, anticipates and supports our activities, increasing efficiency of our activities. Smartness is usually associated with efficiency, but it also allows environments, virtual humans and social robots to display emotions, empathy and provide environments to introduce and support humorous events. We review examples of playful and humorous street furniture in ‘playable’ cities and projects that allow residents and visitors to interact with objects and environments in playful and humorous ways. We add observations on humor theory, in particular observations that deal with physical, visual and multimodal humor. Our emphasis is on introducing incongruities and on exploring different forms of incongruities in order to introduce humorous situations. Inventories of incongruities are explored. These inventories have been obtained from observing humor in everyday situations, in comedies, in movies, and in TV commercials. Shortcomings of these inventories from the point of view of multimodal and interaction humor are discussed and some preliminary views on additional approaches are provided. © 2015 The Authors;2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;2175-2182;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XF9FGGCH;journalArticle;2015;Santos-Lang, C.C.;Moral ecology approaches to machine ethics;Intelligent Systems, Control and Automation: Science and Engineering;NA;NA;10.1007/978-3-319-08108-3_8;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921383640&doi=10.1007%2f978-3-319-08108-3_8&partnerID=40&md5=a85fa6ea1a4880edfbb476c3505fd3d9;"Wallach and Allen’s seminal book, Moral Machines: Teaching Robots Right from Wrong, categorized theories of machine ethics by the types of algorithms each employs (e.g., top-down vs. bottom-up), ultimately concluding that a hybrid approach would be necessary. Humans are hybrids individually: our brains are wired to adapt our evaluative approach to our circumstances. For example, stressors can inhibit the action of oxytocin in the brain, thus forcing a nurse who usually acts from subjective empathy to defer to objective rules instead. In contrast, ecosystem approaches to ethics promote hybridization across, rather than within, individuals; the nurse being empowered to specialize in personalized care because other workers specialize in standardization, and profitability. Various philosophers have argued, or laid the framework to argue, that such specialization can be advantageous to teams and societies. Rather than mass-produce identical machines to emulate the best individual human, perhaps we should build diverse teams of machines to emulate the best human teams. © Springer International Publishing Switzerland 2015";2015;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;111-127;NA;NA;74;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VKMS65VK;conferencePaper;2014;"Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.";People help robots who help others, not robots who help themselves;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2014.6926262;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937552129&doi=10.1109%2fROMAN.2014.6926262&partnerID=40&md5=752f0cf2f56d804937ab84c1ea24d172;Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot. © 2014 IEEE.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;255-260;NA;NA;2014-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: October;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PF7SC8E4;conferencePaper;2014;"Sejima, Y.; Watanabe, T.; Jindai, M.";Development of an interaction-activated communication model based on a heat conduction equation in voice communication;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2014.6926356;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937538530&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=91ef1fc789e5cfd5dd2329481e79a23e;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication. © 2014 IEEE.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;832-837;NA;NA;2014-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: October;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
G3TYP25J;journalArticle;2014;"Hofree, G.; Ruvolo, P.; Bartlett, M.S.; Winkielman, P.";Bridging the mechanical and the human mind: Spontaneous mimicry of a physically present android;PLoS ONE;NA;NA;10.1371/journal.pone.0099934;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904490592&doi=10.1371%2fjournal.pone.0099934&partnerID=40&md5=160e9e9b43fd8eecd3d04c3cb2e090d0;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users. © 2014 Hofree et al.";2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;NA;NA;7;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 25</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CDDRERIE;journalArticle;2014;"Rosenthal-Von Der Pütten, A.M.; Schulte, F.P.; Eimler, S.C.; Sobieraj, S.; Hoffmann, L.; Maderwald, S.; Brand, M.; Krämer, N.C.";Investigations on empathy towards humans and robots using fMRI;Computers in Human Behavior;NA;NA;10.1016/j.chb.2014.01.004;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893955979&doi=10.1016%2fj.chb.2014.01.004&partnerID=40&md5=28e6e8e0f0617f9322528b0c8ae2a8b6;Although robots are starting to enter into our professional and private lives, little is known about the emotional effects they elicit. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots, we conducted a study that provides further insights into the question of whether humans show emotional reactions towards a robot and whether these reactions differ from those towards a human. To explore emotionality in human-robot interaction we conducted an fMRI study (n = 14). Participants were presented videos showing a human, a robot and an inanimate object, being treated in either an affectionate or in a violent way. Self-reported emotional states and functional imaging data revealed that participants indeed reacted emotionally when seeing the affectionate and violent videos. While no different neural activation patterns emerged for the affectionate interaction towards both, the robot and the human, we found differences in neural activity when comparing only the videos showing abusive behavior indicating that participants experience more emotional distress and show negative empathetic concern for the human in the abuse condition. This was supported by similar findings with regard to participant's self-reported emotional states. © 2014 Elsevier Ltd. All rights reserved.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;201-212;NA;NA;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 58</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3KLHWQGF;journalArticle;2014;"Boucenna, S.; Gaussier, P.; Hafemeister, L.";Development of first social referencing skills: Emotional interaction as a way to regulate robot behavior;IEEE Transactions on Autonomous Mental Development;NA;NA;10.1109/TAMD.2013.2284065;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897900303&doi=10.1109%2fTAMD.2013.2284065&partnerID=40&md5=be7811d799d82165d41f45eb2bf0ebe1;In this paper, we study how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensory-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some 'empathy' or at least 'resonate' with the robot head (low level emotional resonance). Hence, we advocate the idea that social referencing can be bootstrapped from a simple sensory-motor system not dedicated to social interactions. © 2014 IEEE.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;42-55;NA;1;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 16</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KKKYDFEP;conferencePaper;2014;"Chumkamon, S.; Hayashi, E.";ConBe robot: The development of self-perception and expression in face-to-face interaction;2014 Joint 7th International Conference on Soft Computing and Intelligent Systems, SCIS 2014 and 15th International Symposium on Advanced Intelligent Systems, ISIS 2014;NA;NA;10.1109/SCIS-ISIS.2014.7044703;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946531137&doi=10.1109%2fSCIS-ISIS.2014.7044703&partnerID=40&md5=51b3b861908f3facf3b820b97d69b54f;In social robot development of interaction system robot, it is necessary to develop the fundamental function such as the robot perception. Due to the robot should correctly interpret a behavior or mental expression of the human. If the robot has a good emotional insight of the human, it is the advantage for the robot perception. In this paper, we implement the significant technique that take an advantage to the robot such as the human detection, face detection and recognition. Basically, these techniques could further enable the robot capability of intelligent empathy from the expression of human. We intensively study the vision method for facial expression recognition (FER) to understanding the human emotion and interacting by the robot expression in particular case. The robot interaction is based on the interested person that the robot can recognize with their emotional expression. We also experiment the system in term of face-to-face between robot and user with demonstrate using the head robot along with the result, such as the performance of the perception and the behavior expression of the robot. © 2014 IEEE.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;769-775;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5VH9Q6SP;conferencePaper;2014;"Tsuji, Y.; Tsukamoto, A.; Uchida, T.; Hattori, Y.; Nishida, R.; Fukada, C.; Ozeki, M.; Omori, T.; Nagai, T.; Oka, N.";Experimental study of empathy and its behavioral indices in Human-Robot interaction;HAI 2014 - Proceedings of the 2nd International Conference on Human-Agent Interaction;NA;NA;10.1145/2658861.2658933;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914703944&doi=10.1145%2f2658861.2658933&partnerID=40&md5=16221be63a9e817ee01369d52d6d7c36;Similar to relationships between humans, a person desiring to form a good relationship with a robot needs to be able to empathize with it. However, the specific kinds of human-robot interactions that would arouse and enhance empathy for the robot in the user's mind have not yet been clarified. In addition, the human behavioral traits that may be regarded as indices of empathy have not been investigated extensively. In an attempt to address these two issues, a preliminary experiment on empathy in human-robot interaction is conducted. The results suggest that the actions of naming or comforting a robot could contribute to enhancing its user's empathy and that eye fixation could be used as an index of empathy even when the use of a subjective index is inconclusive.;2014;2021-02-15T22:35:28Z;2021-02-15T22:35:28Z;NA;245-248;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8Q9VC3VK;journalArticle;2014;Yamazaki, R.;Conditions of empathy in human-robot interaction;Frontiers in Artificial Intelligence and Applications;NA;NA;10.3233/978-1-61499-480-0-179;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922515215&doi=10.3233%2f978-1-61499-480-0-179&partnerID=40&md5=d468a5cfbde95954321cabda5ce7ab22;The purpose of this paper is to consider the sociality of social robots with the focus on the notion of empathy. Social robots are designed to exploit various biological mechanisms that trigger anthropomorphizing reactions in humans and systems that seem capable of experiencing or feeling are being constructed. A question is whether empathic reactions by humans are justifiable from a conceptual and ethical point of view. I will mainly address the conceptual strand of this question and investigate whether empathy with robots is appropriate or misapplied relative to our current concept of empathy. © 2014 The authors and IOS Press. All rights reserved.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;179-186;NA;NA;273;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
279PGW4T;conferencePaper;2014;"Obaid, M.; Kuchenbrandt, D.; Bartneck, C.";Empathy and yawn contagion: Can we (Humans) catch yawns from robots?;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2559636.2563702;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896926638&doi=10.1145%2f2559636.2563702&partnerID=40&md5=43372d1b56dc6c0a1c12425952a546cc;Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;260-261;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KGSQHUF2;conferencePaper;2014;"Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.";People help robots who help others, not robots who help themselves;IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions;NA;NA;10.1109/ROMAN.2014.6926262;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937566083&doi=10.1109%2fROMAN.2014.6926262&partnerID=40&md5=9fe071102df11945351c6d32dccf993a;Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot. © 2014 IEEE.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;255-260;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VTNQ8HHX;journalArticle;2014;Redstone, J.;Making sense of empathy with social robots;Frontiers in Artificial Intelligence and Applications;NA;NA;10.3233/978-1-61499-480-0-171;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922487652&doi=10.3233%2f978-1-61499-480-0-171&partnerID=40&md5=3b8962d6d462d30230135087952c79a4;Social robots exploit human-like behaviors so that people might form emotional bonds with them. Ostensibly, such bonding is an empathic response on the part of the person toward the robot. However, as philosopher Catrin Misselhorn points out, it's conceptually problematic to say that people empathize with robots, for the social robots of the present arguably don't possess human-like emotions. To address this concern, Misselhorn proposes that empathy with robots is possible owing to a sort of interplay between perception and imagination that she calls 'imaginative perception.' In this paper, I shall make a preliminary sketch of a conceptual framework that, I argue, serves as a clearer, more conceptually straight-forward alternative to imaginative perception. On this framework, empathy with social robots is the result of a kind of perceptual illusion, rather than the result of the imaginative perception of emotion. © 2014 The authors and IOS Press. All rights reserved.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;171-177;NA;NA;273;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
L3BHWD9P;conferencePaper;2014;"Baumgaertner, B.; Weiss, A.";Do emotions matter in the ethics of human-robot interaction? - Artificial empathy and companion robots;AISB 2014 - 50th Annual Convention of the AISB;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907404285&partnerID=40&md5=601ad60390ef3f89eeeb3e60d5ef1d62;In this position statement we shall argue that emotions are not directly relevant in the ethics of human-robot interaction, particularly in the context of robot care-givers and human care-receivers. Our argument is based on (1) current theories of emotion and (2) empirical findings on organizational emotion research in health care.We use a thought experiment to guide the reader through aspects of emotional empathy that support our conclusion. Our general argument is that what matters to care behavior is just the relevant behavior, not the source that drives the behavior. Our reflection will show that emotional deception may not directly impact the care-receiver (as often assumed in HRI) but more relevantly other care personnel.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TZ34PVBB;conferencePaper;2014;"Mok, B.; Yang, S.; Sirkin, D.; Ju, W.";Empathy: Interactions with emotive robotic drawers;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2559636.2563720;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896930170&doi=10.1145%2f2559636.2563720&partnerID=40&md5=4c2bc80edba4918c82e8ba556bcdf4ca;The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - Angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;250-251;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WSMJR8MG;journalArticle;2014;"Gou, M.S.; Vouloutsi, V.; Grechuta, K.; Lallée, S.; Verschure, P.F.M.J.";Empathy in humanoid robots;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-09435-9_50;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905240698&doi=10.1007%2f978-3-319-09435-9_50&partnerID=40&md5=feaef6aa957d395fb24bd3ed5dd63cdd;Humanoid robots should be able to interact with humans in a familiar way since they are going to play a significant role in the future. Thus, it is necessary that Human-Robot Interaction (HRI) is designed in such a way that allows humans to communicate with robots effortlessly and naturally. Emotions play an important role in this interaction since humans feel more predisposed to interact with robots if they are able to create an affective bond with them. In this study, we want to know whether humans are able to empathize with a humanoid robot. Therefore, in the present research, we are going to recreate a Milgram experiment in which we expect participants to empathize with the robot while playing a matching game. Like in Milgram's experiment, they will have to give fake electrical shocks to the robot thinking that they are punishing it. In that way, an empathic state, which we expect to see in our results, may be induced. © 2014 Springer International Publishing.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;423-426;NA;NA;8608 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PFEEPK6I;conferencePaper;2014;"Fraga, L.; Coelho, A.; Branco, P.";Meet the frumbles-A post-digital toy orchestra;ACM International Conference Proceeding Series;NA;NA;10.1145/2663806.2663813;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938392555&doi=10.1145%2f2663806.2663813&partnerID=40&md5=76c17d07ebb1f60cbdedc94bbd5183c6;"""Meet the Frumbles"" is a group of felt robotic characters that talk amongst themselves and interact with the audience. Empathy, cuteness and gags are explored as communicational facilitators and ludic interaction between a felt robot creature's orchestra and its human conductor. Creative coding using computer vision, electronic prototyping and physical actuators was used to implement the autonomous physical existence, sensing and behavior of creatures. Copyright © 2014 ACM.";2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;NA;NA;NA;2014-November;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2QEKFASJ;conferencePaper;2014;"Sejima, Y.; Watanabe, T.; Jindai, M.";Development of an interaction-Activated communication model based on a heat conduction equation in voice communication;IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions;NA;NA;10.1109/ROMAN.2014.6926356;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937573084&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=22e427095e4bdb9f1b57facf7adeb784;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-Activated communication model based on the heat conduction equation in heat-Transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-Activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-Activated communication. © 2014 IEEE.;2014;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;832-837;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BAXSL2Y9;conferencePaper;2013;"Kwak, S.S.; Kim, Y.; Kim, E.; Shin, C.; Cho, K.";What makes people empathize with an emotional robot?: The impact of agency and physical embodiment on human empathy for a robot;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2013.6628441;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889583757&doi=10.1109%2fROMAN.2013.6628441&partnerID=40&md5=10cee47cd33839f55e4ca124f8091bd9;As empathy is important for the emotional interaction between a human and a robot, the design factors which induce human empathy toward robots need to be explored. Human empathy toward a robot can be affected by the presence of a robot. Thus, we focused on the levels of agency and the physical embodiment of a robot, which are influential factors pertaining to social presence, by executing two experiments. In the first experiment, in a 2 (levels of agency: mediated vs. simulated) between-participants experiment, participants interacted with either a mediated robot which delivers the emotional state of a remote user or a simulated robot which expresses its own emotion. Participants empathized more with the mediated robot than with the simulated robot, demonstrating that the proper form of an emotional robot is as a mediator during emotional interaction between people. In the second study, in a 2 (physical embodiment: physically embodied vs. physically disembodied) between-participants experiment design, participants interacted with either a physically embodied robot or a physically disembodied robot. The results showed that participants empathized more with a physically embodied robot than with a physically disembodied robot, indicating the impact of physical embodiment on human empathy. Implications for the design of human-robot interactions are discussed. © 2013 IEEE.;2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;180-185;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 49</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DPPSIY9B;conferencePaper;2013;"Marti, P.; Iacono, I.; Tittarelli, M.; Stienstra, J.";Shaping empathy through perspective taking;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2013.6628403;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889605391&doi=10.1109%2fROMAN.2013.6628403&partnerID=40&md5=c90b77dbc8dda0f686c942f72e051ecd;This paper describes an explorative study to evaluate a dynamic expressive mask associated to a remote robot-view used to control an assistive robot. The mask is generated by a graphical-user-interface platform displayed on a tablet used to control the robot in a smart home environment. The hypothesis of the study is that when robot's behaviour conforms to human social expectations, interactions are more likely to be found enjoyable and meaningful by people. Furthermore the expressivity of the mask is expected to result in empathic interactions with the robot and therefore to sustain rich and meaningful social exchanges. In this study we compared four scenarios of interaction between a robot and a person at home. The scenarios depicted scenes where the robot was asked to execute tasks. Each scenario was showed in two versions: with a static robot-view and with a dynamic, expressive robot-view. The results of a questionnaire administered to 60 persons showed a preference of people to interact with the dynamic expressive mask. Expressivity was a means to stimulate empathic concern and to facilitate perspective taking during the execution of the scenarios. © 2013 IEEE.;2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;751-756;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TIL9C6DU;journalArticle;2013;"Haffey, A.; Press, C.; O'Connell, G.; Chakrabarti, B.";Autistic traits modulate mimicry of social but not nonsocial rewards;Autism Research;NA;NA;10.1002/aur.1323;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890791615&doi=10.1002%2faur.1323&partnerID=40&md5=92c1fa7dd324146ab56c658894e4a084;Autism Spectrum Conditions (ASC) are associated with diminished responsiveness to social stimuli, and especially to social rewards such as smiles. Atypical responsiveness to social rewards, which reinforce socially appropriate behavior in children, can potentially lead to a cascade of deficits in social behavior. Individuals with ASC often show diminished spontaneous mimicry of social stimuli in a natural setting. In the general population, mimicry is modulated both by the reward value and the sociality of the stimulus (i.e., whether the stimulus is perceived to belong to a conspecific or an inanimate object). Since empathy and autistic traits are distributed continuously in the general population, this study aimed to test if and how these traits modulated automatic mimicry of rewarded social and nonsocial stimuli. High and low rewards were associated with human and robot hands using a conditioned learning paradigm. Thirty-six participants from the general population then completed a mimicry task involving performing a prespecified hand movement which was either compatible or incompatible with a hand movement presented to the participant. High autistic traits (measured using the Autism Spectrum Quotient, AQ) predicted lesser mimicry of high-reward than low-reward conditioned human hands, whereas trait empathy showed an opposite pattern of correlations. No such relations were observed for high-reward vs. low-reward conditioned robot hands. These results demonstrate how autistic traits and empathy modulate the effects of reward on mimicry of social compared to nonsocial stimuli. This evidence suggests a potential role for the reward system in underlying the atypical social behavior in individuals with ASC, who constitute the extreme end of the spectrum of autistic traits. © 2013 International Society for Autism Research, Wiley Periodicals, Inc.;2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;614-620;NA;6;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 14</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BAGXIXSX;journalArticle;2013;"Kühnlenz, B.; Sosnowski, S.; Buß, M.; Wollherr, D.; Kühnlenz, K.; Buss, M.";Increasing Helpfulness towards a Robot by Emotional Adaption to the User;International Journal of Social Robotics;NA;NA;10.1007/s12369-013-0182-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886781468&doi=10.1007%2fs12369-013-0182-2&partnerID=40&md5=3841f37f6837c58790a3c7feae6fd93f;This article describes an emotional adaption approach to proactively trigger increased helpfulness towards a robot in task-related human-robot interaction (HRI). Based on social-psychological predictions of human behavior, the approach aims at inducing empathy, paired with a feeling of similarity in human users towards the robot. This is achieved by two differently expressed emotional control variables: by an explicit statement of similarity before task-related interaction, and implicitly expressed by adapting the emotional state of the robot to the mood of the human user, such that the current values of the human mood in the dimensions of pleasure, arousal, and dominance (PAD) are matched. The thereby shifted emotional state of the robot serves as a basis for the generation of task-driven emotional facial- and verbal expressions, employed to induce and sustain high empathy towards the robot throughout the interaction. The approach is evaluated in a user study utilizing an expressive robot head. The effectiveness of the approach is confirmed by significant experimental results. An analysis of the individual components of the approach reveals significant effects of explicit emotional adaption on helpfulness, as well as on the HRI-key concepts anthropomorphism and animacy. © 2013 Springer Science+Business Media Dordrecht.;2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;457-476;NA;4;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 30</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MFQGRHHT;journalArticle;2013;"Moussa, M.B.; Magnenat-Thalmann, N.";Toward socially responsible agents: Integrating attachment and learning in emotional decision-making;Computer Animation and Virtual Worlds;NA;NA;10.1002/cav.1515;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877874878&doi=10.1002%2fcav.1515&partnerID=40&md5=42d30568a9bb3aebd86ac51a9fa1491f;Our goal is to create socially responsible agents, either robots or virtual humans. In this paper, we present an integration of emotions, attachment, and learning in emotional decision-making to achieve this goal. Based on emerging psychological theories, we aim at building human-like emotional decision-making, where emotions play a central role in selecting the next action to be performed by the agent. Here, we present our own approach for emotion appraisal where we use emotional attachment as an important impulse for determining the intensities of emotions. Emotions in their turn are used to calculate the emotional attachment toward the users and for learning to predict future consequences. We report on the results of a simulation evaluation where we assess the influence of emotions, attachment, and learning on decision-making. It is our strong belief that by giving an agent the ability to have emotions and to feel empathy and emotional attachment toward others, we will ultimately give this agent the ability to learn and improve its social behavior skills through interactions with the users and through user feedback. Copyright © 2013 John Wiley & Sons, Ltd.;2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;327-334;NA;3-4;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BBFKB67S;conferencePaper;2013;"Plant, N.; Healey, P.G.T.";Surface Tension;Conference on Human Factors in Computing Systems - Proceedings;NA;NA;10.1145/2468356.2479589;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040727714&doi=10.1145%2f2468356.2479589&partnerID=40&md5=9a87b07b1b9698f79ac1c66418476b1c;"The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?.";2013;2021-02-15T22:35:29Z;2021-02-15T22:35:29Z;NA;2979-2982;NA;NA;2013-April;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GKT23DV2;conferencePaper;2013;"Rosenthal-Von Der Pütten, A.M.; Schulte, F.P.; Eimler, S.C.; Hoffmann, L.; Sobieraj, S.; Maderwald, S.; Krämer, N.C.; Brand, M.";Neural correlates of empathy towards robots;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1109/HRI.2013.6483578;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875695930&doi=10.1109%2fHRI.2013.6483578&partnerID=40&md5=b280b07156fa005c0d3d86ebe820c650;We conducted an fMRI study to investigate emotionality in human-robot interaction. Subjects (N=14) were presented videos showing a human, a robot and an unanimated object, being treated in either an affectionate or a violent way. Violent interaction towards both the robot and the human resulted in similar neural activation patterns in classic limbic structures indicating that both the robot and the human elicit similar emotional reactions. However, differences in neural activity suggest that participants show more negative empathetic concern for the human in a negative situation. © 2013 IEEE.;2013;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;215-216;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 21</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8DNC57VY;conferencePaper;2013;"Jo, D.; Han, J.; Chung, K.; Lee, S.";Empathy between human and robot?;ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1109/HRI.2013.6483546;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875753667&doi=10.1109%2fHRI.2013.6483546&partnerID=40&md5=95cc534f086bc47fdb87cdc2edab4133;This paper aims at finding the answer to the essential question: Can people perceive a robot's presence as having a social existence? We attempt to apply a sociological and psychological approach to understand the influence of robot beings, by observing human emotion and perception changes while subjects watched a funny video clip in the presence of a robot or a human companion, each of which made their own typical laughing sounds. From this experiment, we found that the robot did not affect the human's positive emotions as much as a human companion did, but the robot did discourage negative emotions. However, the subjects were, in general, amused when they were watching the video with the robot. This amusement is similar to the contagious effect of sharing humor with another human being. Our findings suggest that the subjects accepted the robot's presence as a kind of existence empathically. © 2013 IEEE.;2013;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;151-152;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EPK69ADW;journalArticle;2013;"Niculescu, A.; van Dijk, B.; Nijholt, A.; Li, H.; See, S.L.";Making Social Robots More Attractive: The Effects of Voice Pitch, Humor and Empathy;International Journal of Social Robotics;NA;NA;10.1007/s12369-012-0171-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876427330&doi=10.1007%2fs12369-012-0171-x&partnerID=40&md5=e5170bc6f627cbe2b4e6b47229b7ac0e;In this paper we explore how simple auditory/verbal features of the spoken language, such as voice characteristics (pitch) and language cues (empathy/humor expression) influence the quality of interaction with a social robot receptionist. For our experiment two robot characters were created: Olivia, the more extrovert, exuberant, and humorous robot with a higher voice pitch and Cynthia, the more introvert, calmer and more serious robot with a lower voice pitch. Our results showed that the voice pitch seemed to have a strong influence on the way users rated the overall interaction quality, as well as the robot's appeal and overall enjoyment. Further, the humor appeared to improve the users' perception of task enjoyment, robot personality and speaking style while the empathy showed effects on the way users evaluated the robot's receptive behavior and the interaction ease. With our study, we would like to stress in particular the importance of voice pitch in human robot interaction and to encourage further research on this topic. © 2012 Springer Science+Business Media Dordrecht.;2013;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;171-191;NA;2;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 82</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GXWIZIRY;journalArticle;2013;"Leite, I.; Pereira, A.; Mascarenhas, S.; Martinho, C.; Prada, R.; Paiva, A.";The influence of empathy in human-robot relations;International Journal of Human Computer Studies;NA;NA;10.1016/j.ijhcs.2012.09.005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870847748&doi=10.1016%2fj.ijhcs.2012.09.005&partnerID=40&md5=24b444eb789fafcc1eccc1fe602b1bec;The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human-robot interaction. © 2012 Elsevier Ltd. All rights reserved.;2013;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;250-260;NA;3;71;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 91</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
I7GNT6M2;journalArticle;2013;"Urgen, B.A.; Plank, M.; Ishiguro, H.; Poizner, H.; Saygin, A.P.";EEG theta and Mu oscillations during perception of human and robot actions;Frontiers in Neurorobotics;NA;NA;10.3389/fnbot.2013.00019;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899682291&doi=10.3389%2ffnbot.2013.00019&partnerID=40&md5=b4aae2154c5beca9ef9fffd9bde2d77a;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin.;2013;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;NA;NA;NOV;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 34</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9N64EVDF;conferencePaper;2012;"Stienstra, J.; Marti, P.";Squeeze me: Gently please;NordiCHI 2012: Making Sense Through Design - Proceedings of the 7th Nordic Conference on Human-Computer Interaction;NA;NA;10.1145/2399016.2399131;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871548513&doi=10.1145%2f2399016.2399131&partnerID=40&md5=7ea7f0a39509c35dee111044bead8f9d;This paper presents the Squeeze Me, a research-throughdesign case that explores the emergence of empathic behavior between human and machine by sparking an expression-rich relation. The Squeeze Me is a squeezable device used to grab attention from a robot, providing ground for expressive values to be shared. The expressions exerted on the mediating device by the human are mapped to expressive behaviors of the robot in the modality of motion in forthcoming interaction. We propose a doublelayered interaction paradigm in achieving natural and socially acceptable synthesis. Firstly, a direct mapping, inherently exhibiting a natural relationship. Secondly, an amplifying and reductive mapping to construct a personalizing relationship through vivid and lively interactions fed by the intentions of the robot as well as the user. The design case serves to explore consequences of a phenomenological approach on the constitution of empathy in the fields of human and robot interaction. With this work we intend to inspire design engineering to shift from representational and discrete to rich, continuous-sustained and other embodied mechanisms for interaction when targeting empathic behavior to emerge. Copyright © 2012 ACM.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;746-750;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XMM8BFKJ;conferencePaper;2012;"Wallach, W.; Allen, C.";Hard problems: Framing the Chinese room in which a robot takes a moral turing test;AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893196594&partnerID=40&md5=984e7b89899e5cf0d4d527848dc72d3b;Research on approaches for implementing moral decision-making capabilities within AI systems is contributing to a more comprehensive understanding of moral acumen. In addition to being able to reason, consciousness and understanding, a theory of mind, social skills, cooperating with other agents, the ability to solve frame problems, being embodied, empathy, and feeling pleasure and pain may be required for agents to successfully select morally acceptable courses of action within certain domains. The multifaceted nature of moral intelligence complicates both the task of designing artificial moral agents (AMAs) and the challenge of evaluating whether an artificial agent can make safe, legal, and appropriate decisions. Confronted with a somewhat comparable difficulty in determining whether a machine can think, Alan Turing [1] proposed his now famous imitation game. Fifty years later, Colin Allen, Gary Varner, and Jason Zinser [2] suggested a variant of the test: a moral Turing test (MTT). Within some limited domains, reason alone is sufficient for making moral judgments, and moral intelligence may be tested by using the traditional conversational method of posing a question and comparing the AI system's response to that of a human. However, evaluating an artificial agent's ability to accommodate a variety of moral considerations, including some that are difficult to quantify or describe, will necessitate testing it in complex situations. Consider the ability of an artificial agent to deduce the beliefs, desires, and intentions of other agents so that it might work cooperatively with them on a shared task, to distinguish a combatant from a non-combatant during guerrilla warfare, to discern that it is in a morally significant situation, or to discriminate which of many concurrent challenges it should respond to first. These tasks are not easy for humans, and yet we bring resources to bear in tackling such challenges that will be hard to reproduce artificially. Evaluating whether AI systems can manage such tasks sufficiently will either require special variants of the MTT, or they reveal the inadequacy of a MTT for evaluating the moral intelligence of artificial systems.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QWJUGWJT;journalArticle;2012;"Damiano, L.; Dumouchel, P.; Lehmann, H.";Should empathic social robots have interiority?;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-34103-8_27;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868703579&doi=10.1007%2f978-3-642-34103-8_27&partnerID=40&md5=273e4818c6cd8d4ff043f7c125f0658c;"In this article we discuss whether robots need ""interiority"" in order to competently participate in emotional and empathic dynamics with human partners. We draw on original research on emotions, mind, neurophysiological mechanisms of social interaction and HRI to contest the common sense thesis according to which robots without ""interiority"" can only simulate emotions and empathy, to the extent that the affective (emotional and empathic) relationships between them and humans would not be authentic. The main thesis of our article is that empathic social robots do not need ""interiority"", but the ability of dynamical coordination with their social partners and the surrounding environment(s), since this ability (and not ""interiority"") is at the basis of human cognitive and affective (emotional and empathic) activity. © 2012 Springer-Verlag.";2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;268-277;NA;NA;7621 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VBUMQVMH;journalArticle;2012;"Lim, A.; Okuno, H.G.";Using speech data to recognize emotion in human gait;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-34014-7_5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867628984&doi=10.1007%2f978-3-642-34014-7_5&partnerID=40&md5=7ab30baab585123d34f2f79cae6da69f;Robots that can recognize emotions can improve humans' mental health by providing empathy and social communication. Emotion recognition by robots is challenging because unlike in human-computer environments, facial information is not always available. Instead, our method proposes using speech and gait analysis to recognize human emotion. Previous research suggests that the dynamics of emotional human speech also underlie emotional gait (walking). We investigate the possibility of combining these two modalities via perceptually common parameters: Speed, Intensity, irRegularity, and Extent (SIRE). We map low-level features to this 4D cross-modal emotion space and train a Gaussian Mixture Model using independent samples from both voice and gait. Our results show that a single, modality-mixed trained model can perform emotion recognition for both modalities. Most interestingly, recognition of emotion in gait using a model trained uniquely on speech data gives comparable results to a model trained on gait data alone, providing evidence for a common underlying model for emotion across modalities. © 2012 Springer-Verlag.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;52-64;NA;NA;7559 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6EL76M4M;conferencePaper;2012;"Gonsior, B.; Buß, M.; Sosnowski, S.; Wollherr, D.; Kuhnlenz, K.; Buss, M.";Towards transferability of theories on prosocial behavior from Social Psychology to HRI;Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO;NA;NA;10.1109/ARSO.2012.6213407;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863676143&doi=10.1109%2fARSO.2012.6213407&partnerID=40&md5=e83b24886eae05fe86baff1e203e9ffd;This paper describes the transfer of theories on prosocial behavior from Social Psychology to human-robot interaction (HRI) in terms of helpfulness shown by humans towards a robot. Theoretical foundations are given, and relevant influence factors for prosocial behavior are defined. The paper provides an overview on how these factors can be transferred to HRI and are implemented in two experimental settings. In a first experiment, situational empathy towards a robot is increased. In a second experiment, similarity is induced by means of emotional adaption to the mood of the user. Results show that helpfulness towards a robot can be increased by this approach, thus, re-evaluating the transferability of theories from Social Psychology to HRI. © 2012 IEEE.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;101-103;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RZ4Z3MQD;journalArticle;2012;"Mori, M.; MacDorman, K.F.; Kageki, N.";The uncanny valley;IEEE Robotics and Automation Magazine;NA;NA;10.1109/MRA.2012.2192811;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862286533&doi=10.1109%2fMRA.2012.2192811&partnerID=40&md5=8a553f5c078346018240a4c24a66346e;"Recently, the concept of the uncanny valley has rapidly attracted interest in robotics and other scientific circles as well as in popular culture. According to Masahiro Mori, a robotics professor at the Tokyo Institute of Technology, who first researched on this subject, a person's response to a humanlike robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance. This descent into eeriness is known as the uncanny valley. As healthy persons, we are represented at the second peak (moving). Then when we die, we are unable to move; the body goes cold, and the face becomes pale. Therefore, our death can be regarded as a movement from the second peak (moving) to the bottom of the uncanny valley (still). Researchers should begin to build an accurate map of the uncanny valley so that through robotics research they can begin to understand what makes them human.";2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;98-100;NA;2;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 776</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
W5C5JS63;journalArticle;2012;Glaskin, K.;Empathy and the robot: A neuroanthropological analysis;Annals of Anthropological Practice;NA;NA;10.1111/j.2153-9588.2012.01093.x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866548084&doi=10.1111%2fj.2153-9588.2012.01093.x&partnerID=40&md5=59405e41826fbe02a20a7f7938bacf29;Roboticists developing socially interactive robots seek to design them in such a way that humans will readily anthropomorphize them. For this anthropomorphizing to occur, robots need to display emotion-like responses to elicit empathy from the person, so as to enable social interaction. This article focuses on roboticists' efforts to create emotion-like responses in humanoid robots. In particular, I investigate the extent to which the cultural dimensions of emotion and empathy are factored into these endeavors. Recent research suggests that mirror neurons or other brain structures may have a role to play in empathy and imitation. Notwithstanding this, the effect of sociocultural experience in shaping appropriate empathic responses and expectations is also crucial. More broadly, this article highlights how we are literally anthropomorphizing technology, even as the complexity of technology and the role it plays in our lives grows. Both the actual design process and the understanding of how technology shapes our daily lives are core applied dimensions of this work, from carrying out the research to capturing the critical implications of these technological innovations. © 2012 by the American Anthropological Association.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;68-87;NA;1;36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ASZI9PM6;conferencePaper;2012;"Leite, I.; Castellano, G.; Pereira, A.; Martinho, C.; Paiva, A.";Modelling empathic behaviour in a robotic game companion for children: An ethnographic study in real-world settings;HRI'12 - Proceedings of the 7th Annual ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;10.1145/2157689.2157811;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859967043&doi=10.1145%2f2157689.2157811&partnerID=40&md5=b23b27299cb277eaa16dabb494d6a6df;The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with. © 2012 ACM.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;367-374;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 62</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FEMLUSHV;journalArticle;2012;"Leite, I.; Pereira, A.; Castellano, G.; Mascarenhas, S.; Martinho, C.; Paiva, A.";Modelling empathy in social robotic companions;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-28509-7_14;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857580365&doi=10.1007%2f978-3-642-28509-7_14&partnerID=40&md5=b66eeaac8dbba75981f970bfbce5eb6b;Empathy can be broadly defined as the ability to understand and respond appropriately to the affective states of others. In this paper, we present a scenario where a social robot acts as a chess companion for children, and describe our current efforts towards endowing such robot with empathic capabilities. A multimodal framework for modeling some of the user's affective states that combines visual and task-related features is presented. Using this model of the user, we personalise the learning environment by adapting the robot's empathic responses to the particular preferences of the child who is interacting with the robot. We also describe a preliminary study conducted in this scenario. © 2012 Springer-Verlag.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;135-147;NA;NA;7138 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 40</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
IQN8Y2B4;journalArticle;2012;"Beck, A.; Stevens, B.; Bard, K.A.; Cañamero, L.";Emotional body language displayed by artificial agents;ACM Transactions on Interactive Intelligent Systems;NA;NA;10.1145/2133366.2133368;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983513884&doi=10.1145%2f2133366.2133368&partnerID=40&md5=81b4e97a2648aa1e21e58e61ae07a3ee;Complex and natural social interaction between artificial agents (computer-generated or robotic) and humans necessitates the display of rich emotions in order to be believable, socially relevant, and accepted, and to generate the natural emotional responses that humans show in the context of social interaction, such as engagement or empathy. Whereas some robots use faces to display (simplified) emotional expressions, for other robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve naturalness. This research investigates the creation of an affect space for the generation of emotional body language to be displayed by humanoid robots. To do so, three experiments investigating how emotional body language displayed by agents is interpreted were conducted. The first experiment compared the interpretation of emotional body language displayed by humans and agents. The results showed that emotional body language displayed by an agent or a human is interpreted in a similar way in terms of recognition. Following these results, emotional key poses were extracted from an actor's performances and implemented in a Nao robot. The interpretation of these key poses was validated in a second study where it was found that participants were better than chance at interpreting the key poses displayed. Finally, an affect space was generated by blending key poses and validated in a third study. Overall, these experiments confirmed that body language is an appropriate medium for robots to display emotions and suggest that an affect space for body expressions can be used to improve the expressiveness of humanoid robots. © 2012 ACM.;2012;2021-02-15T22:35:30Z;2021-02-15T22:35:30Z;NA;NA;NA;1;2;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 43</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QN6B9WU5;conferencePaper;2011;"Mazzei, D.; Lazzeri, N.; Billeci, L.; Igliozzi, R.; Mancini, A.; Ahluwalia, A.; Muratori, F.; De Rossi, D.";Development and evaluation of a social robot platform for therapy in autism;Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS;NA;NA;10.1109/IEMBS.2011.6091119;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863580441&doi=10.1109%2fIEMBS.2011.6091119&partnerID=40&md5=ef2cf1468c54887befa6d75b94330654;People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred affective state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training. © 2011 IEEE.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;4515-4518;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 28</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LTZULK5M;journalArticle;2011;"Pereira, A.; Leite, I.; Mascarenhas, S.; Martinho, C.; Paiva, A.";Using empathy to improve human-robot relationships;Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST;NA;NA;10.1007/978-3-642-19385-9_17;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885883906&doi=10.1007%2f978-3-642-19385-9_17&partnerID=40&md5=9619e98158ace82186d35585fcfef530;For robots to become our personal companions in the future, they need to know how to socially interact with us. One defining characteristic of human social behaviour is empathy. In this paper, we present a robot that acts as a social companion expressing different kinds of empathic behaviours through its facial expressions and utterances. The robot comments the moves of two subjects playing a chess game against each other, being empathic to one of them and neutral towards the other. The results of a pilot study suggest that users to whom the robot was empathic perceived the robot more as a friend. © ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering 2011.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;130-138;NA;NA;59 LNICST;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 30</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JBRE45I3;journalArticle;2011;"Syrdal, D.S.; Nomura, T.; Hirai, H.; Dautenhahn, K.";Examining the Frankenstein Syndrome: An open-ended cross-cultural survey;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-25504-5_13;https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155166431&doi=10.1007%2f978-3-642-25504-5_13&partnerID=40&md5=eed0d3a7848398bcdea4116602779f7f;This paper reports findings from an open-ended survey on attitudes towards humanoid robots collected from samples in the United Kingdom and Japan. 335 participants were asked how they felt about humanoid robots becoming widespread in society and what tasks they wanted humanoid robots to perform. While the UK sample was overall less negative towards humanoid robots than their Japanese counterparts, the UK sample did not want robots to perform tasks that required capabilities deemed as human qualities, such as empathy, caring, or independent decision making. © 2011 Springer-Verlag.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;125-134;NA;NA;7072 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 16</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VY7XT443;journalArticle;2011;"Bickmore, T.; Pfeifer, L.; Schulman, D.";Relational agents improve engagement and learning in science museum visitors;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-23974-8_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053188794&doi=10.1007%2f978-3-642-23974-8_7&partnerID=40&md5=a953ddc287a525d045d246ae2d972cfe;"A virtual museum guide agent that uses human relationship-building behaviors to engage museum visitors is described. The agent, named ""Tinker"", appears in the form of a human-sized anthropomorphic robot, and uses nonverbal conversational behavior, empathy, social dialogue, reciprocal self-disclosure and other relational behavior to establish social bonds with users. Tinker can describe exhibits in the museum, give directions, and discuss technical aspects of her own implementation. Results from an experiment involving 1,607 visitors indicate that the use of relational behavior leads to significantly greater engagement by museum visitors, measured by session length, number of sessions, and self-reported attitude, as well as learning gains, as measured by a knowledge test, compared to the same agent that did not use relational behavior. Implications for museum exhibits and intelligent tutoring systems are discussed. © 2011 Springer-Verlag.";2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;55-67;NA;NA;6895 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 39</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GYZ4LGR9;conferencePaper;2011;"Gonsior, B.; Sosnowski, S.; Mayer, C.; Blume, J.; Radig, B.; Wollherr, D.; Kuhnlenz, K.";Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2011.6005294;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053019859&doi=10.1109%2fROMAN.2011.6005294&partnerID=40&md5=5d5d3a8ce9853510d7f865baff145c8d;"In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application ""Akinator"" serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode. © 2011 IEEE.";2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;350-356;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 46</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2SATBG27;journalArticle;2011;Mushiaki, S.;Chapitre 5. Neuroscience and nanotechnologies in Japan ? Beyond the hope and hype of converging technologies;Journal International de Bioethique;NA;NA;10.3917/jib.221.0089;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155163375&doi=10.3917%2fjib.221.0089&partnerID=40&md5=c140a86972e32e4a780e7683f64c662f;Nanotechnologies are often said to be «converging» with other technologies like biotechnology, information technology, and cognitive science. And so-called «NBIC convergence» is thought to enable «enhancement» of human performance. First, I classify various kinds of enhancement. Second, I focus on the «cybernetic enhancement,» to which nanotechnologies are supposed to contribute, and analyze the connection and integration of humans with machines, which could lead to the cyborgization of human beings. Third, I examine the portrayal of robot/cyborg technology in Japanese popular media, point out the tendency to empathy or ensoulment concerning robots/cyborgs, and raise the question of «ethical issues of ethical enhancement.» Fourth, I compare nanotechnologies with neurotechnology and criticize the hype of «converging technologies.» Copyright 2011 ESKA. All rights reserved.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;89-97;NA;1-2;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3MDHTW9G;journalArticle;2011;Leite, I.;Using adaptive empathic responses to improve long-term interaction with social robots;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-22362-4_48;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960289713&doi=10.1007%2f978-3-642-22362-4_48&partnerID=40&md5=334d2ce9b0459548ad46fa184320ec4d;The goal of this research is to investigate the effects of empathy and adaptive behaviour in long-term interaction between social robots and users. To address this issue, we propose an action selection mechanism that will allow a social robot to chose adaptive empathic responses, in the attempt to keep users engaged over several interactions. © 2011 Springer-Verlag.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;446-449;NA;NA;6787 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RXW35QMY;journalArticle;2011;"Angulo, C.; Comas, J.; Pardo, D.";Aibo JukeBox - A robot dance interactive experience;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-21498-1_76;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957949420&doi=10.1007%2f978-3-642-21498-1_76&partnerID=40&md5=b0253c42d996edbaa78a9649c1237e40;This paper presents a human-robot interaction system based on the Aibo platform. This robot is both, complex and empathetic enough to generate a high level of interest from the user. The complete system is an interactive JukeBox intending to generate affective participation, i.e., empathy, from the user towards the robot and its behavior. This application is based on a robotic dance control system that generates movements adequate to the music rhythm using a stochastic controller. The user can interact with the system selecting or providing the songs to be danced by the robot. The application has been successfully presented in different non-scientific scenarios. © 2011 Springer-Verlag.;2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;605-612;NA;PART 2;6692 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MQ3AX72C;journalArticle;2011;Mushiaki, S.;Neuroscience and nanotechnologies in Japan–beyond the hope and hype of converging technologies.;Journal international de bioéthique = International journal of bioethics;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053313070&partnerID=40&md5=27a265c06fdb7cfa3778a5d44ec1c569;"Nanotechnologies are often said to be ""converging"" with other technologies like biotechnology, information technology, and cognitive science. And so-called ""NBIC convergence"" is thought to enable ""enhancement"" of human performance. First, I classify various kinds of enhancement. Second, I focus on the ""cybernetic enhancement,"" to which nanotechnologies are supposed to contribute, and analyze the connection and integration of humans with machines, which could lead to the cyborgization of human beings. Third, I examine the portrayal of robot/cyborg technology in Japanese popular media, point out the tendency to empathy or ensoulment concerning robots/cyborgs, and raise the question of ""ethical issues of ethical enhancement."" Fourth, I compare nanotechnologies with neurotechnology and criticize the hype of ""converging technologies.""";2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;91-97, 210-211;NA;1;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TRWHV53U;conferencePaper;2011;"Trappl, R.; Krajewski, M.; Ruttkay, Z.; Widrich, V.";Robots as companions: What can we learn from servants and companions in literature, theater, and film?;Procedia Computer Science;NA;NA;10.1016/j.procs.2011.12.029;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856455778&doi=10.1016%2fj.procs.2011.12.029&partnerID=40&md5=f06303ccb8971eb8c816f56957a1e181;"Many researchers are working on developing robots into adequate partners, be it at the working place, be it at home or in leisure activities, or enabling elder persons to lead a self-determined, independent life. While quite some progress has been made in e.g. speech or emotion understanding, processing and expressing, the relations between humans and robots are usually only short-term. In order to build long-term, i.e. social relations, qualities like empathy, trust building, dependability, non-patronizing, and others will be required. But these are just terms and as such no adequate starting points to ""program"" these capacities even more how to avoid the problems and pitfalls in interactions between humans and robots. However, a rich source for doing this is available, unused until now for this purpose: artistic productions, namely literature, theater plays, not to forget operas, and films with their multitude of examples. Poets, writers, dramatists, screen-writers, etc. have studied for centuries the facets of interactions between persons, their dynamics, and the related snags. And since we wish for human-robot relations as master-servant relations - the human obviously being the master - the study of these relations will be prominent. A procedure is proposed, with four consecutive steps, namely Selection, Analysis, Categorization, and Integration. Only if we succeed in developing robots which are seen as servants we will be successful in supporting and helping humans through robots. © Selection and peer-review under responsibility of FET11 conference organizers and published by Elsevier B.V.";2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;96-98;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HMDCP8DV;journalArticle;2011;"Yamashiro, T.; Kawada, K.; Nagamatsu, M.; Yamamoto, T.";"A practice of 'monozukuri' education featuring ""rescue robots production"" in an elementary school";Nihon Kikai Gakkai Ronbunshu, C Hen/Transactions of the Japan Society of Mechanical Engineers, Part C;NA;NA;10.1299/kikaic.77.1465;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863072864&doi=10.1299%2fkikaic.77.1465&partnerID=40&md5=5e1a1697bcc104010d94c4107288ae1a;"The problem of avoidance of science and technology learning is one of the big issues for education in Japan. Part of the problem might arise from the lack of experiences of so-called ""monozukuri"" or engineering design activities at elementary school levels. Hands on class room activities for elementary schools are developed including the followings. 1)Visual contents including robots in the real world, earthquake disasters, and robots engaging in rescue missions, 2)Using the same kind of body frame of the vehicle robot, four different types of prototype cars are prepared, which enable pupils to find the difference of the effect of gear-ratio, 3)Small cardboard parts called ""parts card"" for each component of the robot which enables pupils to develop their design by manipulating and placing the card to the body frame, 4)Mechanical models varying from simple to complex, multi-link structures. The results of the pre-post questionnaire shows that over 70% of pupils have positive feelings to ""monozukuri"" and shows 10% increase. The parts card facilitates design resulting that almost all design requires only minor modification. The image map method is used, the numbers of the concepts are increased by four points and its quality is improved. One of the objectives of this project is to enhance empathy; the ability to relate well to others. We examined the designs of pupils and found that a variety of equipments are added for disaster victims. © 2011 The Japan Society of Mechanical Engineers.";2011;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;1465-1476;NA;776;77;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CRKFDJM5;conferencePaper;2010;"Beck, A.; Hiolle, A.; Mazel, A.; Cañamero, L.";Interpretation of emotional body language displayed by robots;AFFINE'10 - Proceedings of the 3rd ACM Workshop on Affective Interaction in Natural Environments, Co-located with ACM Multimedia 2010;NA;NA;10.1145/1877826.1877837;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650424811&doi=10.1145%2f1877826.1877837&partnerID=40&md5=f082bcdd148bb341f0169829a4168370;"In order for robots to be socially accepted and generate empathy they must display emotions. For robots such as Nao, body language is the best medium available, as they do not have the ability to display facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should greatly improve its acceptance. This research investigates the creation of an ""Affect Space"" [1] for the generation of emotional body language that could be displayed by robots. An Affect Space is generated by ""blending"" (i.e. interpolating between) different emotional expressions to create new ones. An Affect Space for body language based on the Circumplex Model of emotions [2] has been created. The experiment reported in this paper investigated the perception of specific key poses from the Affect Space. The results suggest that this Affect Space for body expressions can be used to improve the expressiveness of humanoid robots. In addition, early results of a pilot study are described. It revealed that the context helps human subjects improve their recognition rate during a human-robot imitation game, and in turn this recognition leads to better outcome of the interactions.";2010;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;37-42;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 39</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2LLLMB92;conferencePaper;2010;"Leite, I.; Pereira, A.; Mascarenhas, S.; Castellano, G.; Martinho, C.; Prada, R.; Paiva, A.";Closing the loop: From affect recognition to empathic interaction;AFFINE'10 - Proceedings of the 3rd ACM Workshop on Affective Interaction in Natural Environments, Co-located with ACM Multimedia 2010;NA;NA;10.1145/1877826.1877839;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650479851&doi=10.1145%2f1877826.1877839&partnerID=40&md5=457610fa47de048d31f4c8807bf630dc;Empathy is a very important capability in human social relationships. If we aim to build artificial companions (agents or robots) capable of establishing long-term relationships with users, they should be able to understand the user's affective state and react accordingly, that is, behave in an empathic manner. Recent advances in affect recognition research show that it is possible to automatically analyse and interpret affective expressions displayed by humans. However, affect recognition in naturalistic environments is still a challenging issue and there are many unanswered questions related to how a virtual agent or a social robot should react to those states, and how that improves the interaction. We have developed a scenario in which a social robot recognises the user's affective state and displays empathic behaviours. In this paper, we present part of the results of a study assessing the influence of the robot's empathic behaviour on the user's understanding of the interaction.;2010;2021-02-15T22:35:31Z;2021-02-15T22:35:31Z;NA;43-47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 15</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AYPGL2J6;journalArticle;2010;"Evers, V.; Winterboer, A.; Pavlin, G.; Groen, F.";The evaluation of empathy, autonomy and touch to inform the design of an environmental monitoring robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-17248-9_30;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649920020&doi=10.1007%2f978-3-642-17248-9_30&partnerID=40&md5=3c87a3b5f3154ef0d5bcffd732bbf9b4;This paper reports the application of results from human- social agent interaction experiments to inform the design of a social robot to monitor levels of pollutive gasses in the air. Next to licensed environmental agents and immobile chemical sensors, mobile technologies such as robotic agents are needed to collect complaints and smell descriptions from humans in urban industrial areas. These robots will interact with members of the public and ensure responsiveness and accuracy of responses. For robots to be accepted as representative environmental monitoring agents and for people to comply to robot instructions in the case of a calamity, social skills will be important. In this paper we will describe the intelligent environment the environmental robot is part of and discuss preliminary work on the effects of robot empathic and touch behaviors on human responses to robots. These and future findings will inform the design of social monitoring robot behaviors in public settings. © 2010 Springer-Verlag.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;285-294;NA;NA;6414 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
97YZGDED;conferencePaper;2010;"Mayer, C.; Sosnowski, S.; Kühnlenz, K.; Radig, B.";Towards robotic facial mimicry: System development and evaluation;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598629;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649811811&doi=10.1109%2fROMAN.2010.5598629&partnerID=40&md5=be1e023f6c26e8fefbef602794622f7f;We introduce a facial mimicry system, which combines facial expression analysis and synthesis on a robot, utilizing the facial action coding system. The activation of action units on a user's face is automatically extracted from a video stream and mapped to the robot, thus mirroring the facial expression. As a novel approach, a user study quantifies the congruence of the initial human facial expression with the robotic facial expression. The evaluation shows that the robotic facial expression is perceived to be close to the human facial expression, from which it is derived. This is a fundamental aspect for a mimicry system, providing a basis for future research on empathy and emotional closed loop control. © 2010 IEEE.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;198-203;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GZS45DS8;conferencePaper;2010;"Beck, A.; Cañamero, L.; Bard, K.A.";Towards an Affect Space for robots to display emotional body language;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598649;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649809554&doi=10.1109%2fROMAN.2010.5598649&partnerID=40&md5=155a713176f4ea9f15710c1cb7a8bf7a;In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex. © 2010 IEEE.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;464-469;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 70</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2VXTEJFS;conferencePaper;2010;"Mazzei, D.; Billeci, L.; Armato, A.; Lazzeri, N.; Cisternino, A.; Pioggia, G.; Igliozzi, R.; Muratori, F.; Ahluwalia, A.; De Rossi, D.";The FACE of autism;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2010.5598683;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649834348&doi=10.1109%2fROMAN.2010.5598683&partnerID=40&md5=a240f42caa411330d0809d58579705bd;People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented. © 2010 IEEE.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;791-796;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 38</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CKMWQ6RA;journalArticle;2010;Coeckelbergh, M.;Artificial companions: Empathy and vulnerability mirroring in human-robot relations;Studies in Ethics, Law, and Technology;NA;NA;10.2202/1941-6008.1126;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951518701&doi=10.2202%2f1941-6008.1126&partnerID=40&md5=291aad81c3578195777069239c232628;"Under what conditions can robots become companions and what are the ethical issues that might arise in human-robot companionship relations? I argue that the possibility and future of robots as companions depends (among other things) on the robot's capacity to be a recipient of human empathy, and that one necessary condition for this to happen is that the robot mirrors human vulnerabilities. For the purpose of these arguments, I make a distinction between empathy-as-cognition and empathy-as-feeling, connecting the latter to the moral sentiment tradition and its concept of ""fellow feeling."" Furthermore, I sympathise with the intuition that vulnerability mirroring raises the ethical issue of deception. However, given the importance of appearance in social relations, problems with the concept of deception, and contemporary technologies that question the artificial-natural distinction, we cannot easily justify the underlying assumptions of the deception objection. If we want to hold on to them, we need convincing answers to these problems. © 2011 Berkeley Electronic Press. All rights reserved.";2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;NA;NA;3;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
77SHG4UF;conferencePaper;2010;Duhaut, D.;A way to put empathy in a Robot;Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866108268&partnerID=40&md5=b7aefa120587dbd4e227a2ab51730e20;A report on the experiments carried out with our robot in the Emotirob project is given in this paper, in which we show how we build emotion and personality in the robot. With children, the results of interaction with the robot are quite satisfactory in a short-term experiment. However, it was noted that during long-term interaction between the children and the robot, the relationship changes as a kind of lassitude sets up. Thus, the question addressed here is, how can we make a robot acceptable for long-term interaction? We propose to explain why empathy is a part of the solution and what the key points are for artificial intelligence to solve this new problem.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;549-554;NA;NA;2;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XIAVPMT4;journalArticle;2010;"Boucenna, S.; Gaussier, P.; Hafemeister, L.; Bard, K.";Autonomous development of social referencing skills;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-15193-4_59;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249265355&doi=10.1007%2f978-3-642-15193-4_59&partnerID=40&md5=14ed2d292c580e3cbfc3fb0f93322108;"In this work, we are interested in understanding how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensori-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some ""empathy"" or at least ""resonate"" with the robot head (low level emotional resonance). Hence we advocate the idea that social referencing can be bootstrapped from a simple sensori-motor system not dedicated to social interactions. © 2010 Springer-Verlag.";2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;628-638;NA;NA;6226 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5J6RVNT6;journalArticle;2010;"Leite, I.; Mascarenhas, S.; Pereira, A.; Martinho, C.; Prada, R.; Paiva, A.";"""Why can't we be friends?"" an empathic game companion for long-term interaction";Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-642-15892-6_32;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049379436&doi=10.1007%2f978-3-642-15892-6_32&partnerID=40&md5=e59385a36b95870356be6a9e75a4c25c;The ability of artificial companions (virtual agents or robots) to establish meaningful relationships with users is still limited. In humans, a key aspect of such ability is empathy, often seen as the basis of social cooperation and pro-social behaviour. In this paper, we present a study where a social robot with empathic capabilities interacts with two users playing a chess game against each other. During the game, the agent behaves in an empathic manner towards one of the players and in a neutral way towards the other. In an experiment conducted with 40 participants, results showed that users to whom the robot was empathic provided higher ratings in terms of companionship. © 2010 Springer-Verlag Berlin Heidelberg.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;315-321;NA;NA;6356 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 22</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DJTWNMIB;conferencePaper;2010;"Cramer, H.; Goddijn, J.; Wielinga, B.; Evers, V.";Effects of (in)accurate empathy and situational valence on attitudes towards robots;5th ACM/IEEE International Conference on Human-Robot Interaction, HRI 2010;NA;NA;10.1145/1734454.1734513;https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951614868&doi=10.1145%2f1734454.1734513&partnerID=40&md5=9f89fcdee313e99eb0b65f9b667e75a2;Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive. © 2010 IEEE.;2010;2021-02-15T22:35:32Z;2021-02-15T22:35:32Z;NA;141-142;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 48</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Q44YH8TT;journalArticle;2021;"Croes, E.A.J.; Antheunis, M.L.";Can we be friends with Mitsuku? A longitudinal study on the process of relationship formation between humans and a social chatbot;Journal of Social and Personal Relationships;NA;NA;10.1177/0265407520959463;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091422686&doi=10.1177%2f0265407520959463&partnerID=40&md5=7a1fafb08fcca7eb9c8e2df2e58c3779;This explorative study investigated (a) whether social attraction, self-disclosure, interaction quality, intimacy, empathy and communicative competence play a role in getting-acquainted interactions between humans and a chatbot, and (b) whether humans can build a relationship with a chatbot. Although human-machine communication research suggests that humans can develop feelings for computers, this does not automatically imply that humans experience feelings of friendship with a chatbot. In this longitudinal study, 118 participants had seven interactions with chatbot Mitsuku over a 3-week period. After each interaction participants filled out a questionnaire. The results showed that the social processes decreased after each interaction and feelings of friendship were low. In line with the ABCDE model of relationship development, the social processes that aid relationship continuation decrease, leading to deterioration of the relationship. Furthermore, a novelty effect was at play after the first interaction, after which the chatbot became predictable and the interactions less enjoyable. © The Author(s) 2020.;2021;2021-02-15T22:35:55Z;2021-02-15T22:35:55Z;NA;279-300;NA;1;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
H86ZEXL9;conferencePaper;2020;"Daher, K.; Casas, J.; Khaled, O.A.; Mugellini, E.";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020;NA;NA;10.1145/3383652.3423864;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096965302&doi=10.1145%2f3383652.3423864&partnerID=40&md5=fe8b298b7d7e4ba7330d713c3261bfca;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12). © 2020 Owner/Author.;2020;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GNLDX3C2;conferencePaper;2020;"Chen, Z.; Lu, Y.; Nieminen, M.P.; Lucero, A.";Creating a chatbot for and with migrants: Chatbot personality drives co-design activities;DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference;NA;NA;10.1145/3357236.3395495;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090504800&doi=10.1145%2f3357236.3395495&partnerID=40&md5=f1462d9b4b9746c6d634685538c4ee2d;Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria. © 2020 Owner/Author.;2020;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;219-230;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TJ3HPI3T;conferencePaper;2020;"Ravi, A.; Yadav, A.K.S.; Chauhan, J.; Dholakia, J.; Jain, N.";Sentemoji: A dataset to generate empathising conversations;ACM International Conference Proceeding Series;NA;NA;10.1145/3371158.3371218;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078411780&doi=10.1145%2f3371158.3371218&partnerID=40&md5=0bc1621a71993b93cf7db57a229cc50e;Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach. © 2020 Association for Computing Machinery.;2020;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;345-346;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZUDGUTPA;journalArticle;2020;"El Kamali, M.; Angelini, L.; Caon, M.; Lalanne, D.; Abou Khaled, O.; Mugellini, E.";An embodied and ubiquitous e-coach for accompanying older adults towards a better lifestyle;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-49065-2_2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088749526&doi=10.1007%2f978-3-030-49065-2_2&partnerID=40&md5=1a62194f602971512a9ca4bd5e312c38;The population of people age 65 or over is increasing especially in Europe [3]. Granting to this target population a longer and healthier life is paramount for the European Community. In the context of the H2020 EU funded project “NESTORE” [11], an embodied and ubiquitous e-coach is being developed seeking to change the lifestyle of seniors in different domains of wellbeing. NESTORE e-coach is known as a personalized embodied and ubiquitous e-coach that plays three essential roles in elderly’s wellbeing: a coach, a friend and a companion. As a coach, NESTORE will give trainings and advice following a wellbeing path that is proposed by experts in wellbeing. As a friend, this e-coach knows and understands the user. As a companion, this e-coach has the ability to detect the user’s emotion and aims at building empathy with the user based by providing support throughout their daily training. The NESTORE e-coach is based on three different intervention medium: a mobile application, a chatbot and an embodied vocal assistant. These interfaces have different forms, different capabilities and different visions. Users can communicate with the NESTORE e-coach through different interfaces exclusively, sequentially, concurrently and synergistically. The interaction can be initiated from the user side to different interfaces and/or from the e-coach side. In this paper, we present the NESTORE’s full vision for building the three essential roles of this e-coach which are: a coach, a companion and a friend for seniors. Furthermore, we explain the NESTORE system design, architecture, capabilities and how the different interfaces of this E-coach contribute to make a multi-modal system. Finally, we conclude our work with the state of this H2020 project. © Springer Nature Switzerland AG 2020.;2020;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;23-35;NA;NA;12183 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DRBDTYPN;conferencePaper;2019;"Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019;NA;NA;10.1109/RITAPP.2019.8932852;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.;2019;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WLHK6GQK;journalArticle;2019;Powell, J.;Trust me, i'm a chatbot: How artificial intelligence in health care fails the turing test;Journal of Medical Internet Research;NA;NA;10.2196/16222;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074230200&doi=10.2196%2f16222&partnerID=40&md5=f07051700ad8b816ddd71e05e867d094;Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. © 2019 John Powell.;2019;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
A2C8PH6B;conferencePaper;2019;"Weisz, J.D.; Jain, M.; Joshi, N.N.; Johnson, J.; Lange, I.";BigBlueBot: Teaching strategies for successful human-agent interactions;International Conference on Intelligent User Interfaces, Proceedings IUI;NA;NA;10.1145/3301275.3302290;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065584647&doi=10.1145%2f3301275.3302290&partnerID=40&md5=f65fcd8c30c030f91d0e8fa4ff25c7f7;Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future. © 2019 Association for Computing Machinery.;2019;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;448-459;NA;NA;Part F147615;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GLYDQYC7;journalArticle;2019;"Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.";A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study;Journal of Medical Internet Research;NA;NA;10.2196/14658;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.;2019;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TVMSCMG7;journalArticle;2018;"Liu, B.; Sundar, S.S.";Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot;Cyberpsychology, Behavior, and Social Networking;NA;NA;10.1089/cyber.2018.0110;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055080779&doi=10.1089%2fcyber.2018.0110&partnerID=40&md5=6111bd02c236f7c8ae5e9e32b516323c;When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N = 158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N = 88) interacted with a real chatbot. We tested the effect of three types of empathic expression - sympathy, cognitive empathy, and affective empathy - on individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed. © Copyright 2018, Mary Ann Liebert, Inc., publishers.;2018;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;625-636;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 37</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5XN6IJW9;conferencePaper;2017;"Xu, A.; Liu, Z.; Guo, Y.; Sinha, V.; Akkiraju, R.";A new chatbot for customer service on social media;Conference on Human Factors in Computing Systems - Proceedings;NA;NA;10.1145/3025453.3025496;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454411&doi=10.1145%2f3025453.3025496&partnerID=40&md5=eb0554245b67f51b2c89e08ecccdd3ec;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric. © 2017 ACM.";2017;2021-02-15T22:35:56Z;2021-02-15T22:35:56Z;NA;3506-3510;NA;NA;2017-May;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 139</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4WKR2JTQ;journalArticle;2021;"Dollmat, K.S.; Abdullah, N.A.";Machine learning in emotional intelligence studies: a survey;Behaviour and Information Technology;NA;NA;10.1080/0144929X.2021.1877356;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099954220&doi=10.1080%2f0144929X.2021.1877356&partnerID=40&md5=b645897ea31110c75104d7291155ee95;Research has proven that having high level of emotional intelligence (EI) can reduce the chance of getting mental illness. EI, and its component, can be improved with training, but currently the process is less flexible and very time-consuming. Machine learning (ML), on the other hand, can analyse huge amount of data to discover useful trends and patterns in shortest time possible. Despite the benefits, ML usage in EI training is scarce. In this paper, we studied 92 journal articles to discover the trend of the ML utilisation in the study of EI and its components. This survey aims to pave way for future studies that could lead to implementation of ML in EI training, and to rope in researchers in psychology and computer science to find possibilities of having a generic ML algorithm for every EI’s components. Our findings show an increasing trend to apply ML on EI components, and Support Vector Machine and Neural Network are the two most popular ML algorithms used in those researches. We also found that social skill and empathy are the least exposed EI components to ML. Finally, we provide recommendations for future research direction of ML in EI domain, and EI in ML. © 2021 Informa UK Limited, trading as Taylor & Francis Group.;2021;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VNNANXVP;journalArticle;2020;"Wu, H.; Feng, C.; Lu, X.; Liu, X.; Liu, Q.";Oxytocin effects on the resting-state mentalizing brain network;Brain Imaging and Behavior;NA;NA;10.1007/s11682-019-00205-5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078296284&doi=10.1007%2fs11682-019-00205-5&partnerID=40&md5=f30603b1709820ae105c35485f9a0096;Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual’s empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;2530-2541;NA;6;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BBBKNTGV;conferencePaper;2020;"Chromik, M.; Lachner, F.; Butz, A.";ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research;ACM International Conference Proceeding Series;NA;NA;10.1145/3419249.3420163;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095825746&doi=10.1145%2f3419249.3420163&partnerID=40&md5=57bb98a9ac0c0565b43777fe83bbcc28;Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML's impact on current UXR activities and practitioners' predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users' emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research. © 2020 ACM.;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
85YTTGUY;journalArticle;2020;"Zwir, I.; Arnedo, J.; Del-Val, C.; Pulkki-Råback, L.; Konte, B.; Yang, S.S.; Romero-Zaliz, R.; Hintsanen, M.; Cloninger, K.M.; Garcia, D.; Svrakic, D.M.; Rozsa, S.; Martinez, M.; Lyytikäinen, L.-P.; Giegling, I.; Kähönen, M.; Hernandez-Cuervo, H.; Seppälä, I.; Raitoharju, E.; de Erausquin, G.A.; Raitakari, O.; Rujescu, D.; Postolache, T.T.; Sung, J.; Keltikangas-Järvinen, L.; Lehtimäki, T.; Cloninger, C.R.";Uncovering the complex genetics of human character;Molecular Psychiatry;NA;NA;10.1038/s41380-018-0263-6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054357876&doi=10.1038%2fs41380-018-0263-6&partnerID=40&md5=cc28474ea2ceb53ab46558d20cfb0cd7;Human personality is 30–60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic–phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory. © 2018, The Author(s).;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;2295-2312;NA;10;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 22</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BTPHMBAB;journalArticle;2020;"Sakamoto, T.; Yamashita, H.; Goto, M.; Iwanaga, J.";Model for relational analysis of posted articles and reactions on restaurant guide sites;Industrial Engineering and Management Systems;NA;NA;10.7232/iems.2020.19.3.669;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093862693&doi=10.7232%2fiems.2020.19.3.669&partnerID=40&md5=fdb2e6a9bbce1d4cf8653879ff665693;Recently, restaurant guide sites providing restaurant information posted by users on the Internet have been widely used as effective tools for consumers. Users, on a restaurant guide site, utilize IDs to post their recommendation articles on restaurants, and these posted articles are a valuable information source for other users. Open users can search for restaurants and read recommendation articles posted by other users. Furthermore, they can react (e.g., “like”) to a recommendation article when they feel it is helpful or they feel like visiting the restaurant. On a target restaurant guide site, each post includes the user ID, restaurant name, recommendation sentences, etc., and the number of reactions is considered to depend on these posted contents. For users who post recommendation articles, the number of reactions to their posts represents the degree of empathy from other users and is an important motivation for posting. Therefore, posting users will benefit from guidelines on how to write good recommendation sentences to increase the number of reactions. Moreover, the number of reactions can be regarded as an important indicator of the activity level of the restaurant guide site from the viewpoint of the service operating company. Therefore, an analytical model developed using historical information such as posts and reactions by users would be useful for determining the relationship between posted contents and the number of reactions. Therefore, this paper proposes a model based on the machine learning approach to analyze the relation between the number of reactions and posted contents. Finally, we demonstrate the analysis based on the proposed model using practical data. © 2020 KIIE;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;669-679;NA;3;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5IUXKTQ3;conferencePaper;2020;"Toxtli, C.; Richmond-Fuller, A.; Savage, S.";Reputation Agent: Prompting Fair Reviews in Gig Markets;The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020;NA;NA;10.1145/3366423.3380199;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589321&doi=10.1145%2f3366423.3380199&partnerID=40&md5=8235c305e0974c8f0c5d3911f16d1058;"Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers. © 2020 ACM.";2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;1228-1240;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6LGNRPLA;journalArticle;2020;"Leonardi, S.; Monti, D.; Rizzo, G.; Morisio, M.";Multilingual transformer-based personality traits estimation;Information (Switzerland);NA;NA;10.3390/info11040179;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085080344&doi=10.3390%2finfo11040179&partnerID=40&md5=590d131e1ea07c10f6d5c564ed07dc18;Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users' information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes Facebook posts from the myPersonality dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback-Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits. © 2020 by the authors.;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;NA;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VIAHXVTW;conferencePaper;2020;"Dixit, R.; Chinnam, R.B.; Singh, H.";Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations;IEEE Aerospace Conference Proceedings;NA;NA;10.1109/AERO47225.2020.9172612;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092594173&doi=10.1109%2fAERO47225.2020.9172612&partnerID=40&md5=0e5e0dbad1bd51bfa0c0a6e225195406;Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once 'trained,' can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to 'techies' from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further. © 2020 IEEE.;2020;2021-02-15T22:36:21Z;2021-02-15T22:36:21Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XP3E5WQQ;journalArticle;2020;"Kumar, M.; Khatri, S.K.; Mohammadian, M.";Breast cancer identification and prognosis with machine learning techniques - An elucidative review;Journal of Interdisciplinary Mathematics;NA;NA;10.1080/09720502.2020.1731963;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084855111&doi=10.1080%2f09720502.2020.1731963&partnerID=40&md5=63f81c27e48424c44143c5d87af974d3;Cancer is the principle wellspring of death around the globe with 2.09 million cases so far in 2018 [1]. Around 627000 deaths accounting to 6.6% are caused because of female breast cancer and it ranks five amongst the list of top causes for deaths, the prime reason being prognosis being favorable in developed countries. The timely empathy of breast cancer further makes the process of prognosis better hence improving the rates of survival, because this will indorse on time treatment which is given clinically to patients. When the classification is done in an accurate way for malignant and benign tumours, it stops the suffering of patients with excessive ailments. The best possible recognizable proof of breast cancer disease and the process of characterizing into benign and malignant groups is that the main concern of a ton of investigation and research. When thrown light on its particular advantages in significant alternatives recognition from the datasets of entangled breast cancer, the generally perceived option is Machine Learning, because of the philosophy of determination in breast cancer to arrange pattern and forecast modelling. This paper will in general, survey machine learning and assessment of this particular paper, WBCD: Wisconsin Breast Cancer Database has been used as the benchmark dataset. © 2020, © 2020 Taru Publications.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;503-521;NA;2;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AP9VEHZU;journalArticle;2020;"Christov-Moore, L.; Reggente, N.; Douglas, P.K.; Feusner, J.D.; Iacoboni, M.";Predicting Empathy From Resting State Brain Connectivity: A Multivariate Approach;Frontiers in Integrative Neuroscience;NA;NA;10.3389/fnint.2020.00003;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081050035&doi=10.3389%2ffnint.2020.00003&partnerID=40&md5=14a6c372c5d3617e327c91f2225d221e;Recent task fMRI studies suggest that individual differences in trait empathy and empathic concern are mediated by patterns of connectivity between self-other resonance and top-down control networks that are stable across task demands. An untested implication of this hypothesis is that these stable patterns of connectivity should be visible even in the absence of empathy tasks. Using machine learning, we demonstrate that patterns of resting state fMRI connectivity (i.e. the degree of synchronous BOLD activity across multiple cortical areas in the absence of explicit task demands) of resonance and control networks predict trait empathic concern (n = 58). Empathic concern was also predicted by connectivity patterns within the somatomotor network. These findings further support the role of resonance-control network interactions and of somatomotor function in our vicariously driven concern for others. Furthermore, a practical implication of these results is that it is possible to assess empathic predispositions in individuals without needing to perform conventional empathy assessments. © Copyright © 2020 Christov-Moore, Reggente, Douglas, Feusner and Iacoboni.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;NA;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5IA4HFJJ;journalArticle;2020;"Haarsma, G.; Davenport, S.; White, D.C.; Ormachea, P.A.; Sheena, E.; Eagleman, D.M.";Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software;Frontiers in Psychology;NA;NA;10.3389/fpsyg.2019.02926;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079140899&doi=10.3389%2ffpsyg.2019.02926&partnerID=40&md5=d66fb33965d78c0e0dfa4f599eabf818;We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver–operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided. © Copyright © 2020 Haarsma, Davenport, White, Ormachea, Sheena and Eagleman.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RI727WS3;journalArticle;2020;"Wei, L.; Wu, G.-R.; Bi, M.; Baeken, C.";Effective connectivity predicts cognitive empathy in cocaine addiction: a spectral dynamic causal modeling study;Brain Imaging and Behavior;NA;NA;10.1007/s11682-020-00354-y;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088566060&doi=10.1007%2fs11682-020-00354-y&partnerID=40&md5=835728f0a909b8384890b1442ede8006;Social cognition plays a crucial role in the development and treatment of cocaine dependence. However, studies investigating social cognition, such as empathy and its underlying neural basis, are lacking. To explore the neural interactions among reward and memory circuits, we applied effective connectivity analysis on resting-state fMRI data collected from cocaine-dependent subjects. The relationship between effective connectivity within these two important circuits and empathy ability - evaluated with the Interpersonal Reactivity Index (IRI) - was assessed by machine learning algorithm using multivariate regression analysis. In accordance with the neurocircuitry disruptions of cocaine addiction, the results showed that cocaine-dependent subjects relative to healthy controls had altered resting state effective connectivity between parts of the memory and reward systems. Furthermore, effective connectivity between the memory and reward system could predict the fantasy empathy (FE) subscale scores in cocaine dependence. Overall, our findings provide further evidence for the neural substrates of social cognition in cocaine-dependent patients. These new insights could be useful for the development of new treatment programs for this substance dependency disorder. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6U35K9L9;journalArticle;2020;"Rehman, F.; Munawar, A.; Iftikhar, A.; Hassan, J.; Samiullah, F.; Gilani, M.B.A.; Qasim, A.; Qasim, N.";Design and development of ai-based mirror neurons agent towards emotion and empathy;International Journal of Advanced Computer Science and Applications;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083223916&partnerID=40&md5=8442281cfab2a9fa3c207ade4eb4b124;Since numerous years, researchers have to outline keen operators to accomplish the Artificial General Intelligence. Each new science revelation is an open challenge to all researchers. More than twenty years prior to a group of researchers discovered exceptional cerebrum cells, called reflect neurons in monkeys. These cells gave off an impression of being actuated both when the monkey accomplished something itself and when the monkey basically watched another monkey do a similar thing. This new discovery opened a new door for a scientist because of Mirror Neurons functionalities that can be huge contribute to cognitive science, neuroscience, impacting on Artificial General Intelligence. Mirror neuron functionality improves the Machine's learning. This research paper develops models for social interaction in which a machine may have the ability to learn the next person emotional state using mirror neurons and show empathy towards emotions. © 2020, Science and Information Organization.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;386-395;NA;3;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BWT5JTE8;journalArticle;2020;"Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;Digital Health;NA;NA;10.1177/2055207620968355;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094669527&doi=10.1177%2f2055207620968355&partnerID=40&md5=5e2909e410f68527e010deb3b1f9b7b3;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues. © The Author(s) 2020.";2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TQ6XMQZM;conferencePaper;2020;"Diederich, S.; Janßen-Müller, M.; Brendel, A.B.; Morana, S.";Emulating empathetic behavior in online service encounters with sentiment-adaptive responses: Insights from an experiment with a conversational agent;40th International Conference on Information Systems, ICIS 2019;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084712323&partnerID=40&md5=3bac47ce26f79d1c1ad3069daa0798f2;Conversational agents currently attract strong interest for technology-based service provision due to increased capabilities driven by advances in machine learning and natural language processing. The interaction via natural language in combination with a human-like design promises service that is always available, fast, and with a consistent quality and at the same time resembles a human service encounter. However, current conversational agents exhibit the same inherent limitation that every interactive technology has, which is a lack of social skills. In this study, we make a first step towards overcoming this limitation by presenting a design approach that combines automatic sentiment analysis with adaptive responses to emulate empathy in a service encounter. By means of an experiment with 112 participants, we evaluate the approach and find empirical support that a CA with sentiment-adaptive responses is perceived as more empathetic, human-like, and socially present and, in particular, yields a higher service encounter satisfaction. © 40th International Conference on Information Systems, ICIS 2019. All rights reserved.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
9ZQQZFQE;journalArticle;2020;"Lima Dantas, D.; Filgueiras, L.V.L.; Brandão, A.A.F.; Machado Domingues, M.C.; Ferreira, M.R.";Detecting IoT Applications Opportunities and Requirements Elicitation: A Design Thinking Based Approach;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-50344-4_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740148&doi=10.1007%2f978-3-030-50344-4_7&partnerID=40&md5=82f5cd968cdecbc941b929dd7ba6216c;IoT development is complex. To reduce this complexity, IoT platforms provide a set of resources and functionalities to enable application development and support its execution. In this work, we present a human-centered approach for requirements elicitation and mapping them to application resources in IoT platforms, using empathy, definition and ideation methods. A previous study by the authors has identified 11 categories of resources provided by 47 IoT platforms to developers in their application layers. From this set, 6 categories were selected for this work: schedulers and triggers, message and notification triggers, big data and analytics, artificial intelligence and machine learning, dashboards, and services. We invited 18 members of 8 projects for a workshop and divided them in 4 teams, according their project areas, which are: Industry 4.0 (6 participants), Environmental Disasters (4 participants), Environmental Management (3 participants) and Pollution (5 participants). We divided the workshop in 3 phases: warm-up, with user journey mapping, requirements identification using “how might we” questions as a trigger and requirements clustering the questions by the 6 selected categories of resources or an extra category named “others” for those which could not be related to any previous category. Our contribution for the IoT application development is an approach for turning easier requirements elicitation using DT techniques, covering the stages of empathise, definition and ideation, with well-available materials and considering the resources present at application layer of IoT platforms. © 2020, Springer Nature Switzerland AG.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;85-100;NA;NA;12203 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
R5L9CKAC;conferencePaper;2020;"Nehra, V.; Nagpal, R.; Sehgal, R.";Collective intelligence: When, where and why;Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering;NA;NA;10.1109/Confluence47617.2020.9058000;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083999561&doi=10.1109%2fConfluence47617.2020.9058000&partnerID=40&md5=dc43e7ffcf6adf8f724ffaf9d79a8e30;The term 'Collective' is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief. © 2020 IEEE.;2020;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;805-810;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WQ6RPE3N;journalArticle;2019;"O’Connell, K.; Brethel-Haurwitz, K.M.; Rhoads, S.A.; Cardinale, E.M.; Vekaria, K.M.; Robertson, E.L.; Walitt, B.; VanMeter, J.W.; Marsh, A.A.";Increased similarity of neural responses to experienced and empathic distress in costly altruism;Scientific Reports;NA;NA;10.1038/s41598-019-47196-3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069733023&doi=10.1038%2fs41598-019-47196-3&partnerID=40&md5=d20042af6e49a051649ad067549d4110;Empathy—affective resonance with others’ sensory or emotional experiences—is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists’ heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize. © 2019, The Author(s).;2019;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;NA;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
C6LKNSSF;conferencePaper;2019;"Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.";Predicting future alleviation of mental illness in social media: An empathy-based social network perspective;Proceedings - 2019 IEEE Intl Conf on Parallel and Distributed Processing with Applications, Big Data and Cloud Computing, Sustainable Computing and Communications, Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019;NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085484201&doi=10.1109%2fISPA-BDCloud-SustainCom-SocialCom48970.2019.00230&partnerID=40&md5=b25cfa36d495be8d70325de2a2fd3932;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed. © 2019 IEEE.;2019;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;1564-1571;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WMEPQB46;journalArticle;2019;"Krohne, L.G.; Wang, Y.; Hinrich, J.L.; Moerup, M.; Chan, R.C.K.; Madsen, K.H.";Classification of social anhedonia using temporal and spatial network features from a social cognition fMRI task;Human Brain Mapping;NA;NA;10.1002/hbm.24751;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070672968&doi=10.1002%2fhbm.24751&partnerID=40&md5=a024b6f27ce7b57e61c0dcaee4172c31;Previous studies have suggested that the degree of social anhedonia reflects the vulnerability for developing schizophrenia. However, only few studies have investigated how functional network changes are related to social anhedonia. The aim of this fMRI study was to classify subjects according to their degree of social anhedonia using supervised machine learning. More specifically, we extracted both spatial and temporal network features during a social cognition task from 70 subjects, and used support vector machines for classification. Since impairment in social cognition is well established in schizophrenia-spectrum disorders, the subjects performed a comic strip task designed to specifically probe theory of mind (ToM) and empathy processing. Features representing both temporal (time series) and network dynamics were extracted using task activation maps, seed region analysis, independent component analysis (ICA), and a newly developed multi-subject archetypal analysis (MSAA), which here aimed to further bridge aspects of both seed region analysis and decomposition by incorporating a spotlight approach.We found significant classification of subjects with elevated levels of social anhedonia when using the times series extracted using MSAA, indicating that temporal dynamics carry important information for classification of social anhedonia. Interestingly, we found that the same time series yielded the highest classification performance in a task classification of the ToM condition. Finally, the spatial network corresponding to that time series included both prefrontal and temporal-parietal regions as well as insula activity, which previously have been related schizotypy and the development of schizophrenia. © 2019 Wiley Periodicals, Inc.;2019;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;4965-4981;NA;17;40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QLKZYWF7;journalArticle;2019;"Drimalla, H.; Landwehr, N.; Hess, U.; Dziobek, I.";From face to face: the contribution of facial mimicry to cognitive and emotional empathy;Cognition and Emotion;NA;NA;10.1080/02699931.2019.1596068;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063194475&doi=10.1080%2f02699931.2019.1596068&partnerID=40&md5=bb539c57b010be437f0ec7ff35e632e7;Despite advances in the conceptualisation of facial mimicry, its role in the processing of social information is a matter of debate. In the present study, we investigated the relationship between mimicry and cognitive and emotional empathy. To assess mimicry, facial electromyography was recorded for 70 participants while they completed the Multifaceted Empathy Test, which presents complex context-embedded emotional expressions. As predicted, inter-individual differences in emotional and cognitive empathy were associated with the level of facial mimicry. For positive emotions, the intensity of the mimicry response scaled with the level of state emotional empathy. Mimicry was stronger for the emotional empathy task compared to the cognitive empathy task. The specific empathy condition could be successfully detected from facial muscle activity at the level of single individuals using machine learning techniques. These results support the view that mimicry occurs depending on the social context as a tool to affiliate and it is involved in cognitive as well as emotional empathy. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;2019;2021-02-15T22:36:22Z;2021-02-15T22:36:22Z;NA;1672-1686;NA;8;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 14</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AHU3FC8X;conferencePaper;2019;"Franzoni, V.; Milani, A.; Biondi, G.; Micheli, F.";A preliminary work on dog emotion recognition;Proceedings - 2019 IEEE/WIC/ACM International Conference on Web Intelligence Workshops, WI 2019 Companion;NA;NA;10.1145/3358695.3361750;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074373338&doi=10.1145%2f3358695.3361750&partnerID=40&md5=28643a3c506d284761d30c4e16a889af;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence. © 2019 Copyright held by the owner/author(s).;2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;91-96;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
A7GE99DS;journalArticle;2019;"Clavelle, J.T.; Sweeney, C.D.; Swartwout, E.; Lefton, C.; Guney, S.";Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition;Journal of Nursing Administration;NA;NA;10.1097/NNA.0000000000000757;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931093&doi=10.1097%2fNNA.0000000000000757&partnerID=40&md5=c67866ef50603649810f548af2d47672;Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented. © Wolters Kluwer Health, Inc. All rights reserved.;2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;303-309;NA;6;49;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PRZRANS8;journalArticle;2019;"Imel, Z.E.; Pace, B.T.; Soma, C.S.; Tanana, M.; Hirsch, T.; Gibson, J.; Georgiou, P.; Narayanan, S.; Atkins, D.C.";Design feasibility of an automated, machine-learning based feedback system for motivational interviewing;Psychotherapy;NA;NA;10.1037/pst0000221;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063985695&doi=10.1037%2fpst0000221&partnerID=40&md5=20d1cfc6e7033bf619a267c74e7e1fa9;Direct observation of psychotherapy and providing performance-based feedback is the gold-standard approach for training psychotherapists. At present, this requires experts and training human coding teams, which is slow, expensive, and labor intensive. Machine learning and speech signal processing technologies provide a way to scale up feedback in psychotherapy. We evaluated an initial proof of concept automated feedback system that generates motivational interviewing quality metrics and provides easy access to other session data (e.g., transcripts). The system automatically provides a report of session-level metrics (e.g., therapist empathy) and therapist behavior codes at the talk-turn level (e.g., reflections). We assessed usability, therapist satisfaction, perceived accuracy, and intentions to adopt. A sample of 21 novice (n = 10) or experienced (n = 11) therapists each completed a 10-min session with a standardized patient. The system received the audio from the session as input and then automatically generated feedback that therapists accessed via a web portal. All participants found the system easy to use and were satisfied with their feedback, 83% found the feedback consistent with their own perceptions of their clinical performance, and 90% reported they were likely to use the feedback in their practice. We discuss the implications of applying new technologies to evaluation of psychotherapy. © 2019 American Psychological Association.;2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;318-328;NA;2;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3ULJAJ4X;journalArticle;2019;"Blease, C.; Kaptchuk, T.J.; Bernstein, M.H.; Mandl, K.D.; Halamka, J.D.; Desroches, C.M.";Artificial intelligence and the future of primary care: exploratory qualitative study of UK general practitioners' views;Journal of Medical Internet Research;NA;NA;10.2196/12802;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063303215&doi=10.2196%2f12802&partnerID=40&md5=41136ee763c24454922fbdbed2e48d68;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPS') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPS' opinions about the likelihood of future technology to fully replace GPS in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPS also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPS believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPS considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPS' views. © 2019 Journal of Medical Internet Research. All rights reserved.";2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;NA;NA;3;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 15</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X998RJMF;conferencePaper;2019;"Salaken, S.M.; Nahavandi, S.; McGinn, C.; Hossny, M.; Kelly, K.; Abobakr, A.; Nahavandi, D.; Iskander, J.";Development of a cloud-based computational framework for an empathetic robot;ACM International Conference Proceeding Series;NA;NA;10.1145/3313991.3314018;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064612068&doi=10.1145%2f3313991.3314018&partnerID=40&md5=63ff43c5b27f0b4f09c443d56e71a480;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator’s voice is presented. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.;2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;102-108;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZFCCS54R;conferencePaper;2019;"Das, A.K.; Ashrafi, A.; Ahmmad, M.";Joint cognition of both human and machine for predicting criminal punishment in judicial system;2019 IEEE 4th International Conference on Computer and Communication Systems, ICCCS 2019;NA;NA;10.1109/CCOMS.2019.8821655;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071115729&doi=10.1109%2fCCOMS.2019.8821655&partnerID=40&md5=c2141b9cb6d314f80753bcccba34ada4;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can’t only perform faster but also predict better than human. But a human has some qualities which can never be gained by a Machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to ‘Women and Children Repression Prevention Act, 2000’. We apply several Machine learning algorithms to make a Machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide Machine for judging a delinquent. © 2019 IEEE.;2019;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;36-40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UF683J9Q;journalArticle;2018;"Inkster, B.; Sarda, S.; Subramanian, V.";An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study;JMIR mHealth and uHealth;NA;NA;10.2196/12106;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f;"Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.";2018;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;NA;NA;11;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 58</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KXP3RPKI;journalArticle;2018;"Vaughn, D.A.; Savjani, R.R.; Cohen, M.S.; Eagleman, D.M.";Empathic Neural Responses Predict Group Allegiance;Frontiers in Human Neuroscience;NA;NA;10.3389/fnhum.2018.00302;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054818270&doi=10.3389%2ffnhum.2018.00302&partnerID=40&md5=b969317edbd81945e006fad82823c283;"Watching another person in pain activates brain areas involved in the sensation of our own pain. Importantly, this neural mirroring is not constant; rather, it is modulated by our beliefs about their intentions, circumstances, and group allegiances. We investigated if the neural empathic response is modulated by minimally-differentiating information (e.g., a simple text label indicating another's religious belief), and if neural activity changes predict ingroups and outgroups across independent paradigms. We found that the empathic response was larger when participants viewed a painful event occurring to a hand labeled with their own religion (ingroup) than to a hand labeled with a different religion (outgroup). Counterintuitively, the magnitude of this bias correlated positively with the magnitude of participants' self-reported empathy. A multivariate classifier, using mean activity in empathy-related brain regions as features, discriminated ingroup from outgroup with 72% accuracy; the classifier's confidence correlated with belief certainty. This classifier generalized successfully to validation experiments in which the ingroup condition was based on an arbitrary group assignment. Empathy networks thus allow for the classification of long-held, newly-modified and arbitrarily-formed ingroups and outgroups. This is the first report of a single machine learning model on neural activation that generalizes to multiple representations of ingroup and outgroup. The current findings may prove useful as an objective diagnostic tool to measure the magnitude of one's group affiliations, and the effectiveness of interventions to reduce ingroup biases. © 2018 Vaughn, Savjani, Cohen and Eagleman.";2018;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;NA;NA;NA;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SU6BWT5P;conferencePaper;2018;"Bogatyreva, A.A.; Sovkov, A.D.; Tikhomirova, S.A.; Vinogradova, A.R.; Samsonovich, A.V.";Virtual pet powered by a socially-emotional BICA;Procedia Computer Science;NA;NA;10.1016/j.procs.2018.11.101;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059446525&doi=10.1016%2fj.procs.2018.11.101&partnerID=40&md5=641bddc567abf82308667be9f87f06ff;Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents. © 2018 The Authors. Published by Elsevier B.V.;2018;2021-02-15T22:36:23Z;2021-02-15T22:36:23Z;NA;564-571;NA;NA;145;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5YFXHVAK;journalArticle;2018;"Qureshi, S.; Hagelbäck, J.; Iqbal, S.M.Z.; Javaid, H.; Lindley, C.A.";Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-030-01054-6_25;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.;2018;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;347-363;NA;NA;868;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X67EMACV;journalArticle;2018;"Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.";Towards empathetic human-robot interactions;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-75487-1_14;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.;2018;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;173-193;NA;NA;9624 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RKD5ZDNY;journalArticle;2018;"Kajiwara, Y.; Kubo, Y.; Kimura, H.";Estimation of evocation of friendship based on similarity of pulse rate variability of users for event-based social networks;Sensors and Materials;NA;NA;10.18494/SAM.2018.1777;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049905275&doi=10.18494%2fSAM.2018.1777&partnerID=40&md5=4bfc723f0e62ef5c77681b965445a2a1;In contrast to traditional social network services (SNSs), event-based social networks determine close friendships (CFs) of users who share experiences and emotions with candidate friends in offline events. However, we could not provide feedback to cyberspace regarding the place, time, and target of a user realizing friendship since there is no technique for conveniently measuring the evocation of friendship during offline events. In this research, we propose a method of estimating the evocation of friendship using the similarity in the pulse rate variabilities (PRVs) of users when empathy is evoked between them. The user can be made aware of friendship estimated automatically through machine learning by wearing a wristwatch-type pulsimeter. CFs are more likely to evoke empathy than superficial friendships (SFs). To demonstrate the usefulness of this method, we conducted an experiment assuming an event where a group of four people are enjoying their time in an amusement park. From the experimental results, we showed that the similarity of the PRVs in CFs is greater than that in SFs when the favorability rating is high and the users like each other. Moreover, we showed that the proposed method estimated the evocation of friendship during the attraction experience with an f-measure of 0.74 at maximum and during an offline event with a mean f-measure of 0.78. The results showed the usefulness and effectiveness of this method. © MYU K.K.;2018;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;1407-1426;NA;7;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
RI8ARM4E;conferencePaper;2018;"Shetty, D.; Xu, J.";"Strategies to address ""Design thinking"" in engineering curriculum";ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE);NA;NA;10.1115/IMECE2018-87816;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060289006&doi=10.1115%2fIMECE2018-87816&partnerID=40&md5=c3c26deda706705f100c7d880ba1b9e2;It is suggested by many scholars that if the goal of engineering education is to produce engineers who can critically design and create, then providing students with early opportunities to engage in creative engineering design is important. While basic design is focused on the development of new products for the individual, working towards a more sustainable world demands greater attention to designing for and with communities. Improving design education and examining design-learning outcomes requires a kind of targeted approach that could match the best practices to personalize student learning. Design is complex and design includes balancing the needs of multiple stakeholders. However, there is a gap in the preparation of design education that will be needed in a challenging environment. This paper reviews the history of design thinking in the engineering curriculum. Design thinking education starts with an understanding of its importance with socioeconomic relevance. Through observation and empathy, mapping the designer uses the listening and learning tools for mapping users unarticulated needs, working in a team environment. The designer takes time to think carefully why a certain project is considered and details which aspects of machine learning application can be applied from functional to complete success for the end users. The availability of powerful virtual reality methodologies, have made it possible to consider the realistic needs and visualize scenarios and to explore the design alternatives with new ideas before full scale resource allocation on new ideas. Mid-to-advanced level courses with experimental assignments require that students apply through experimentation the principles and concepts learned in foundation courses. The basic design tools such as axiomatic thinking, theory of inventive problem solving, design iteration and simulation using hardware-in-the loop are discussed with case studies. Consideration of product sustainability with the thoughts of design for disassembly and disposal has emerged as a major part of design thinking. Senior engineering courses center on cross and interdisciplinary design and capstone experiences so that students experience fully guided practice of device design and problem solving, simulating what they are likely to experience in the world. This paper examines the critical issues of design thinking in a curriculum from observation, empathy mapping, validation of the idea, and improvement of idea by virtual reality and machine learning, optimization of the idea by tools such as axiomatic design, hardware in the loop simulation, and finally examining product sustainability causes. Copyright © 2018 ASME.;2018;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5K3FP8TJ;conferencePaper;2018;"Coman, A.C.; Zara, G.; Nechaev, Y.; Barlacchi, G.; Moschitti, A.";Exploiting deep neural networks for tweet-based emoji prediction;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057887474&partnerID=40&md5=05bb99e39d4261ed76708c15a4c0e94e;For many years now, emojis have been used in social networks and chat services in order to enrich written text with auxiliary graphical content, achieving a higher degree of empathy. In particular, given the wide use of this medium, emojis are now available in such a number and variety that every basic concept and mood is covered by at least one. For this reason, the connection between the emoji and its semantical meaning grows stronger. In this paper, we will be describing the work performed in order to develop a Machine Learning based tool that, given a tweet, predicts the most likely emoji associated with the text. The task resembles the one presented by Barbieri et al., [23], and is placed within the context of the International Workshop on Semantic Evaluation (SemEval) 2018. We designed a baseline with standard Support Vector Machines and another baseline based on fastText, which was provided as part of the Workshop. In addition, we implemented several models based on Neural Networks such as Bidirectional Long Short-Term Memory Recurrent Neural Networks and Convolutional Neural Networks. We found that the latter is the most effective since it outperformed all our models and ranks in the 6th position out of 47 total participants. Our work aims to illustrate the potential of simpler models, which, thanks to the fine-tuning of hyper-parameters, could achieve accuracy comparable to the more complex models of the challenge. © 2018 CEUR-WS. All rights reserved.;2018;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;116-128;NA;NA;2244;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VMJRPCT2;journalArticle;2017;"Alvarez-Fernandez, S.; Brown, H.R.; Zhao, Y.; Raithel, J.A.; Bishop, S.L.; Kern, S.B.; Lord, C.; Petkova, E.; Di Martino, A.";Perceived social support in adults with autism spectrum disorder and attention-deficit/hyperactivity disorder;Autism Research;NA;NA;10.1002/aur.1735;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019558593&doi=10.1002%2faur.1735&partnerID=40&md5=e545d47342863040e107738960f8fe69;"Perceived social support (PSS) has been related to physical and mental well-being in typically developing individuals, but systematic characterizations of PSS in autism spectrum disorder (ASD) are limited. We compared self-report ratings of the multidimensional scale of PSS (MSPSS) among age- and IQ-matched groups of adults (18–58 years) with cognitively high-functioning ASD (N = 41), or attention-deficit/hyperactivity disorder (ADHD; N = 69), and neurotypical controls (NC; N = 69). Accompanying group comparisons, we used machine learning random forest (RF) analyses to explore predictors among a range of psychopathological and socio-emotional variables. Relative to both ADHD and NC, adults with ASD showed lower MSPSS ratings, specifically for the friends subscale (MSPSS-f). Across ASD and ADHD, interindividual differences in autism severity, affective empathy, symptoms of anxiety related to social interactions, hyperactivity/impulsivity, and somatization best predicted MSPSS-f. These relationships did not differ between clinical groups. While group comparisons demonstrated greater impairment in individuals with ASD, analyzing individuals' characteristics revealed cross-diagnoses similarities in regard to their MSPSS-f relationships. This is consistent with the Research Domain Criteria framework, supporting a trans-diagnostic approach as on the path toward “precision medicine.” Autism Res 2017, 10: 866–877. © 2017 International Society for Autism Research, Wiley Periodicals, Inc. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.";2017;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;866-877;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
86MUNPVI;journalArticle;2017;"Shimada, T.; Sakurai, A.";Recognition of empathy seeking questions in one of the largest woman CQA in Japan;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-54472-4_60;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018617990&doi=10.1007%2f978-3-319-54472-4_60&partnerID=40&md5=001e186fe5d53db5baeeab37adfd42ee;Many questions are posted on community websites in the world. Some of these questions are actually asked in order to receive empathy for the feelings of questioners, instead of getting specific answers to the questions asked. However, it is difficult to receive answers for these questions compared with questions that are asked for seeking responses other than for empathy. If such questions that are asked for the purpose of receiving empathy can get responses, it serves as an important factor to increase satisfaction of users. This paper reports on our attempt to improve response rate to the questions by classifying those questions that are asked for seeking empathy and those that are not by using machine learning and showing the questions classified as the ones seeking empathy to the prospective respondents who have been answered to these questions with higher rate. © Springer International Publishing AG 2017.;2017;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;641-650;NA;NA;10191 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TPAS9M8A;conferencePaper;2017;"Ramaswamy, N.; MacDonald, E.";Telepathic product design for water conservation;Proceedings of the International Conference on Engineering Design, ICED;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029740073&partnerID=40&md5=0f5e5840bdf2bc50fe33cc19d5ccde90;"Can a product that reads the user's mind behave more efficiently and eventually train the user to conserve? Here, as a first step to answering this big question, we present a design method for telepathic products applied to the case study of a kitchen faucet. The case study is used to illustrate the different steps of the design method: (A) Build cognitive empathy and define cognitive styles; (B) Define design requirements, articulate variables that will control performance, understand limitations and design physical product; (C) Design the machine learning algorithm, inputs, and outputs; and (D) Integration and refinement. This work-in-progress report highlights the intricacies of applying adaptive machinelearning behavior to physical products performance in the ""real world"" rather than to a website or device such as a smart phone. Interesting findings include that automatic response, typically associated with websites and phones, is not possible with plumbing as water cannot be instantly at the right temperature; and that cognitive styles indeed manifest in dish washing observations, with distinctly different styles in terms of patience, temperature sensitivity, and laziness.";2017;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;169-178;NA;NA;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: DS87-1;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
H3IYMTVL;journalArticle;2016;"López-Gil, J.-M.; Virgili-Gomá, J.; Gil, R.; García, R.";Method for improving EEG based emotion recognition by combining it with synchronized biometric and eye tracking technologies in a non-invasive and low cost way;Frontiers in Computational Neuroscience;NA;NA;10.3389/fncom.2016.00085;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983514538&doi=10.3389%2ffncom.2016.00085&partnerID=40&md5=eccb032d2d09f3fb6cc015458abac70d;Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric, and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving forty-four people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals, and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self-regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods. © 2016 López-Gil, Virgili-Gomá, Gil and García.;2016;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;NA;NA;AUG;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 20</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GI9Q6TSK;conferencePaper;2016;"Kido, T.; Swan, M.";Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51;"Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.";2016;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;362-368;NA;NA;SS-16-01 - 07;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
J2KGZWQ8;journalArticle;2016;"Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.";Machine learning and empathy: The Civil Rights CAPTCHA;Concurrency Computation;NA;NA;10.1002/cpe.3632;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958909683&doi=10.1002%2fcpe.3632&partnerID=40&md5=458756a37cac7783f5c8ceeed964ed3f;Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7% of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are leaking too much information by unexpected ways, given non-evident design flaws. Copyright © 2015 John Wiley & Sons, Ltd.;2016;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;1310-1323;NA;4;28;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EUVAVT38;conferencePaper;2016;"Bertero, D.; Siddique, F.B.; Wu, C.-S.; Wan, Y.; Chan, R.H.Y.; Fung, P.";Real-time speech emotion and sentiment recognition for interactive dialogue systems;EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings;NA;NA;10.18653/v1/d16-1110;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072837881&doi=10.18653%2fv1%2fd16-1110&partnerID=40&md5=cb47e47a58a6fe6643e7e847811cbdc0;In this paper, we describe our approach of enabling an interactive dialogue system to recognize user emotion and sentiment in real-time. These modules allow otherwise conventional dialogue systems to have “empathy” and answer to the user while being aware of their emotion and intent. Emotion recognition from speech previously consists of feature engineering and machine learning where the first stage causes delay in decoding time. We describe a CNN model to extract emotion from raw speech input without feature engineering. This approach even achieves an impressive average of 65.7% accuracy on six emotion categories, a 4.5% improvement when compared to the conventional feature based SVM classification. A separate, CNN-based sentiment analysis module recognizes sentiments from speech recognition results, with 82.5 F-measure on human-machine dialogues when trained with out-of-domain data. © 2016 Association for Computational Linguistics;2016;2021-02-15T22:36:24Z;2021-02-15T22:36:24Z;NA;1042-1047;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 27</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CZ7RMAZG;conferencePaper;2016;"Kawahara, T.; Yamaguchi, T.; Inoue, K.; Takanashi, K.; Ward, N.";Prediction and generation of backchannel form for attentive listening systems;Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH;NA;NA;10.21437/Interspeech.2016-118;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994351223&doi=10.21437%2fInterspeech.2016-118&partnerID=40&md5=0be540a15263f6c99286d45ff0b40cb6;"In human-human dialogue, especially in attentive listening such as counseling, backchannels are important not only for smooth communication but also for establishing rapport. Despite several studies on when to backchannel, most of the current spoken dialogue systems generate the same pattern of backchannels, giving monotonous impressions to users. In this work, we investigate generation of a variety of backchannel forms according to the dialogue context. We first show the feasibility of choosing appropriate backchannel forms based on machine learning, and the synergy of using linguistic and prosodic features. For generation of backchannels, a framework based on a set of binary classifiers is adopted to effectively make a ""not-to-generate"" decision. The proposed model achieved better prediction accuracy than a baseline which always outputs the same backchannel form and another baseline which randomly generates backchannels. Finally, evaluations by human subjects demonstrate that the proposed method generates backchannels as naturally as human choices, giving impressions of understanding and empathy. Copyright © 2016 ISCA.";2016;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;2890-2894;NA;NA;08-12-September-2016;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 15</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KPEEVBDY;journalArticle;2016;"Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.";Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents;Transactions of the Japanese Society for Artificial Intelligence;NA;NA;10.1527/tjsai.C-G31;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a;There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.;2016;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;NA;NA;4;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KJG8UUNI;conferencePaper;2015;"Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.";Real-time sociometrics from audio-visual features for two-person dialogs;International Conference on Digital Signal Processing, DSP;NA;NA;10.1109/ICDSP.2015.7251991;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961315280&doi=10.1109%2fICDSP.2015.7251991&partnerID=40&md5=447bee82a1f60ad7b9676da82921a344;This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus. © 2015 IEEE.;2015;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;823-827;NA;NA;2015-September;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MDU5GFBY;journalArticle;2015;"Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.";A machine learning attack against the civil rights CAPTCHA;Studies in Computational Intelligence;NA;NA;10.1007/978-3-319-10422-5_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921532152&doi=10.1007%2f978-3-319-10422-5_26&partnerID=40&md5=c429dffc0b1e39cc4456d096362e8de0;Human Interactive Proofs (HIPs) are a basic security measure on the Internet to avoid several types of automatic attacks. Recently, a new HIP has been designed to increase security: the Civil Rights CAPTCHA. It employs the empathy capacity of humans to further strengthen the security of a well known OCR CAPTCHA, Securimage. In this paper, we analyse it from a security perspective, pointing out its design flaws. Then, we create a successful side-channel attack, leveraging some well-known machine learning algorithms. © Springer International Publishing Switzerland 2015.;2015;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;239-248;NA;NA;570;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DE3V4NUZ;journalArticle;2014;"Bedi, G.; Cecchi, G.A.; Slezak, D.F.; Carrillo, F.; Sigman, M.; De Wit, H.";A window into the intoxicated mind? Speech as an index of psychoactive drug effects;Neuropsychopharmacology;NA;NA;10.1038/npp.2014.80;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906320793&doi=10.1038%2fnpp.2014.80&partnerID=40&md5=7ed580cdfca01c709a69f11704fd3729;"Abused drugs can profoundly alter mental states in ways that may motivate drug use. These effects are usually assessed with self-report, an approach that is vulnerable to biases. Analyzing speech during intoxication may present a more direct, objective measure, offering a unique 'window' into the mind. Here, we employed computational analyses of speech semantic and topological structure after ±3,4-methylenedioxymethamphetamine (MDMA; 'ecstasy') and methamphetamine in 13 ecstasy users. In 4 sessions, participants completed a 10-min speech task after MDMA (0.75 and 1.5 mg/kg), methamphetamine (20 mg), or placebo. Latent Semantic Analyses identified the semantic proximity between speech content and concepts relevant to drug effects. Graph-based analyses identified topological speech characteristics. Group-level drug effects on semantic distances and topology were assessed. Machine-learning analyses (with leave-one-out cross-validation) assessed whether speech characteristics could predict drug condition in the individual subject. Speech after MDMA (1.5 mg/kg) had greater semantic proximity than placebo to the concepts friend, support, intimacy, and rapport. Speech on MDMA (0.75 mg/kg) had greater proximity to empathy than placebo. Conversely, speech on methamphetamine was further from compassion than placebo. Classifiers discriminated between MDMA (1.5 mg/kg) and placebo with 88% accuracy, and MDMA (1.5 mg/kg) and methamphetamine with 84% accuracy. For the two MDMA doses, the classifier performed at chance. These data suggest that automated semantic speech analyses can capture subtle alterations in mental state, accurately discriminating between drugs. The findings also illustrate the potential for automated speech-based approaches to characterize clinically relevant alterations to mental state, including those occurring in psychiatric illness. © 2014 American College of Neuropsychopharmacology.";2014;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;2340-2348;NA;10;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 46</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
NFH2Z8R9;journalArticle;2011;"Hong, Y.; Chintapalli, S.V.; Bhardwaj, G.; Zhang, Z.; Patterson, R.L.; Van Rossum, D.B.";Adaptive-BLAST: A user-defined platform for the study of proteins;Journal of Integrated OMICS;NA;NA;10.5584/jiomics.v1i1.33;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977578892&doi=10.5584%2fjiomics.v1i1.33&partnerID=40&md5=8a374620bfbb5cb5c870b18fd7ebba80;Profile-based protein-sequence analysis algorithms comprise some of the most powerful and user-friendly methods for exploring protein sequences to determine their structure, function, and/or evolution (1-4). PSI-BLAST (5, 6) and rps-BLAST (7) are two of the most popular profile-based algorithms ( 1,120 references to date), and have exceptional utility in the identification of homology between proteins, particularly for biological scientists who do not specialize in computational approaches. However, when the performance of these algorithms is compared to other methods [e.g. support-vector machine learning (SVM) (8), hidden-Markov models (HMMs) (9)], they often underperform in identifying the aforementioned protein properties (3, 9-11). We have previously demonstrated that the utility of BLAST algorithms can be significantly improved by: (i) adaptations to the profile libraries employed, (ii) adjustments to output formats, and (iii) alterations to BLAST algorithm itself (4, 6, 12-14). We present here Adaptive-BLAST (Ada-BLAST), which provides a simple user-defined platform for measuring and analyzing primary amino acid sequences. Within this platform, we developed a series of local BLAST applications (apps) that take advantage of the speed and sensitivity afforded by BLAST, while allowing for maximal user-definitions and flexible visualization. We tested the efficacy of these apps in control experiments, studying fold-recognition, in which we obtained >90% accuracy in highly divergent sequences (>25% identity). In addition, these same apps were proficient in classifying transmembrane proteins, identifying structural/functional determinants of ion-channels/receptors, and informing structural modeling algorithms. Indeed, these Ada-BLAST informed-structural models were useful in guiding our experimental research on the N-terminus of Transient Receptor Potential ion-channels (TRPs). Taken together, we propose that Ada-BLAST provides a powerful computational tool that is accessible to bench-scientists and computational biologists alike. The codes for Ada-BLAST are publicly available at: http://empathy.rcc.psu.edu/. © 2011, Proteomass Scientific Society. All rights reserved.;2011;2021-02-15T22:36:25Z;2021-02-15T22:36:25Z;NA;88-101;NA;1;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XVV6SDHC;journalArticle;2021;"Kiesow, H.; Spreng, R.N.; Holmes, A.J.; Chakravarty, M.M.; Marquand, A.F.; Yeo, B.T.T.; Bzdok, D.";Deep learning identifies partially overlapping subnetworks in the human social brain;Communications Biology;NA;NA;10.1038/s42003-020-01559-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099382680&doi=10.1038%2fs42003-020-01559-z&partnerID=40&md5=6fa716c14a9bf81828cfd5652c23f05f;"Complex social interplay is a defining property of the human species. In social neuroscience, many experiments have sought to first define and then locate ‘perspective taking’, ‘empathy’, and other psychological concepts to specific brain circuits. Seldom, bottom-up studies were conducted to first identify explanatory patterns of brain variation, which are then related to psychological concepts; perhaps due to a lack of large population datasets. In this spirit, we performed a systematic de-construction of social brain morphology into its elementary building blocks, involving 10,000 UK Biobank participants. We explored coherent representations of structural co-variation at population scale within a recent social brain atlas, by translating autoencoder neural networks from deep learning. The learned subnetworks revealed essential patterns of structural relationships between social brain regions, with the nucleus accumbens, medial prefrontal cortex, and temporoparietal junction embedded at the core. Some of the uncovered subnetworks contributed to predicting examined social traits in general, while other subnetworks helped predict specific facets of social functioning, such as the experience of social isolation. As a consequence of our population-level evidence, spatially overlapping subsystems of the social brain probably relate to interindividual differences in everyday social life. © 2021, The Author(s).";2021;2021-02-15T22:36:59Z;2021-02-15T22:36:59Z;NA;NA;NA;1;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
J39FXJPS;conferencePaper;2020;"Toxtli, C.; Richmond-Fuller, A.; Savage, S.";Reputation Agent: Prompting Fair Reviews in Gig Markets;The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020;NA;NA;10.1145/3366423.3380199;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589321&doi=10.1145%2f3366423.3380199&partnerID=40&md5=8235c305e0974c8f0c5d3911f16d1058;"Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers. © 2020 ACM.";2020;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;1228-1240;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LME39J8D;conferencePaper;2020;"Sedoc, J.; Buechel, S.; Nachmany, Y.; Buffone, A.; Ungar, L.";Learning word ratings for empathy and distress from document-level user responses;LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096597898&partnerID=40&md5=5c3de64d2b5ef62d84ba3bb9cec6e99e;"Despite the excellent performance of black box approaches to modeling sentiment and emotion, lexica (sets of informative words and associated weights) that characterize different emotions are indispensable to the NLP community because they allow for interpretable and robust predictions. Emotion analysis of text is increasing in popularity in NLP; however, manually creating lexica for psychological constructs such as empathy has proven difficult. This paper automatically creates empathy word ratings from document-level ratings. The underlying problem of learning word ratings from higher-level supervision has to date only been addressed in an ad hoc fashion and has not used deep learning methods. We systematically compare a number of approaches to learning word ratings from higher-level supervision against a Mixed-Level Feed Forward Network (MLFFN), which we find performs best, and use the MLFFN to create the first-ever empathy lexicon. We then use Signed Spectral Clustering to gain insights into the resulting words. The empathy and distress lexica are publicly available at: http://www.wwbp.org/lexica.html. © European Language Resources Association (ELRA), licensed under CC-BY-NC";2020;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;1664-1673;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QAKH3KVR;conferencePaper;2019;"Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.";Predicting future alleviation of mental illness in social media: An empathy-based social network perspective;Proceedings - 2019 IEEE Intl Conf on Parallel and Distributed Processing with Applications, Big Data and Cloud Computing, Sustainable Computing and Communications, Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019;NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085484201&doi=10.1109%2fISPA-BDCloud-SustainCom-SocialCom48970.2019.00230&partnerID=40&md5=b25cfa36d495be8d70325de2a2fd3932;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed. © 2019 IEEE.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;1564-1571;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
A4C83YRV;conferencePaper;2019;"Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019;NA;NA;10.1109/RITAPP.2019.8932852;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VDH7SRU8;journalArticle;2019;"Sena, J.R.; Cabatuan, M.";Deep learning-based facial expression recognition and analysis for filipino gamers;International Journal of Recent Technology and Engineering;NA;NA;10.35940/ijrte.B1027.078219;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286;This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;1822-1827;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZLA2XAGL;conferencePaper;2019;"Barbieri, F.; Guizzo, E.; Lucchesi, F.; Maffei, G.; Del Prado Martín, F.M.; Weyde, T.";Towards a multimodal time-based empathy prediction system;Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019;NA;NA;10.1109/FG.2019.8756532;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070472384&doi=10.1109%2fFG.2019.8756532&partnerID=40&md5=68ba6051cdf7332258f7450ae3a6e899;We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community. © 2019 IEEE.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HFW6AR7X;journalArticle;2019;"Piumatti, G.; Abbiati, M.; Baroffio, A.; Gerbase, M.W.";Associations between motivational factors for studying medicine, learning approaches and empathy among medical school candidates;Advances in Health Sciences Education;NA;NA;10.1007/s10459-018-9866-6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056658658&doi=10.1007%2fs10459-018-9866-6&partnerID=40&md5=03617490c381649c560fcd1583bafa25;Previous research highlighted associations between students’ motivation for medical studies and their learning approaches on the one hand and empathy on the other. Internal motivational factors for studying medicine (e.g., care for patients, save lives) coupled with a deep approach to learning have been positively related to empathy in contrast to external motivational factors (e.g., future earning potential, prestige) and surface learning. However, assessments of these assumptions among medical school candidates are scarce. This study examined the relationship between different motivational factors and empathy among students enrolled in a selection year in medicine by testing the mediating role of learning approaches. A sample of 572 candidates for medical studies answered a self-reported questionnaire half way through their selection year. Measures included internal and external motivational factors for studying medicine, deep and surface learning approaches and empathy. Path-analysis tested the mediation effects of deep and surface approaches to learning on the relationship of internal and external motivational factors with empathy. The deep learning approach partially mediated the significant positive association between internal motivational factors and empathy, while the surface learning approach fully mediated the significant negative association between external motivational factors and empathy. These results suggest that learning approaches could be a pathway by which internal and external motives for studying medicine are related to empathy among medical school candidates. Pedagogical strategies and educational environments accounting for individual differences in motivation and learning may contribute to training students to become professional and caring doctors in the future. © 2018, Springer Nature B.V.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;287-300;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KKML78KE;journalArticle;2019;"Sanal, M.G.; Paul, K.; Kumar, S.; Ganguly, N.K.";Artificial intelligence and deep learning: The future of medicine and medical practice;Journal of Association of Physicians of India;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067569100&partnerID=40&md5=cc6799f54fa56c639d845a3e9b5806d1;Artificial Intelligence (AI) and access to “Big Data” together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (“wiki”) with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition. © 2019, Journal of Association of Physicians of India. All rights reserved.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;71-73;NA;May;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TI4TB5KF;conferencePaper;2019;"Self, B.P.; Widmann, J.";Access for all: Promoting universal design thinking in a rehabilitation engineering course;Proceedings of the 8th Research in Engineering Education Symposium, REES 2019 - Making Connections;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071475285&partnerID=40&md5=6a52fd874b773b65de7b8084345f0ba4;Service learning is a high impact practice that can greatly increase motivation and promote deep learning. We have developed a project-based Rehabilitation Engineering course that included both Biomedical Engineering and Mechanical Engineering students. Projects were supplied by local non-profit community partners (for example Special Olympics), and focused on developing products for people with mobility impairments. In addition to the projects, student assignments included reflection prompts, four hours of community service (two of which had to involve direct contact with people of different abilities), and a sensory deprivation experience to develop empathy. Qualitative evaluation of student responses showed that students were able to develop some aspects of design empathy and understood the importance of accessibility and universal design. Copyright © 2019 Brian Self and Jim Widmann.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;369-377;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ZEXMTGXJ;journalArticle;2019;Griffiths, D.B.;When David met Michel;Religious Studies and Theology;NA;NA;10.1558/RSTH.38299;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071428686&doi=10.1558%2fRSTH.38299&partnerID=40&md5=8aff8e71418d01a4196fb32b0f3976e8;"I entered the Department of Religious Studies in Vancouver in the Fall of 1974. Michel was a year or two advanced and the first person to befriend me and ""show me the robes."" He is a unique individual with generosity of Geist or empathy, and deep analytical skills, wide interests, lucid thinking. His books and many students are evidence of this. It has been a deep joy to be his friend through the years. He has always helped me with intellectual projects and been attentive to personal issues, and all this without a touch of pedantry or arrogance. In addition to his deep learning in Religious Studies and related topics, he has a gift for empathic listening, and a singular capacity to think on his feet and lecture with amazing lucidity. © Equinox Publishing Ltd. 2019.";2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;223-225;NA;1-2;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
EB36HPFV;journalArticle;2019;"Matsuyama, Y.; Asahi, Y.";High Sensitivity Layer Feature Analysis in Food Market;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-22649-7_19;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335;It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.;2019;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;232-243;NA;NA;11570 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KP9F7FRY;conferencePaper;2018;"Marda, M.; Economou, D.; Bouki, V.";Enhancing deeper learning using empathy and creativity in serious games role-play simulations;Proceedings of the European Conference on Games-based Learning;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058967153&partnerID=40&md5=756601e3f4f9ed506dd13d9e12ecdbfa;There is a shift in education towards adopting pedagogical approaches that nurture deeper learning. Educators recognise that effective and active approaches to teaching are more closely associated with deeper learning. These active approaches aim to develop higher order skills, encouraging learners’ critical thinking and decision-making as well as enhancing their capacity to be agile, flexible and adaptable. Among those active approaches stand serious games, which are powerful learning environments that are seen as an emergent and engaging new way of experiment situations and construct knowledge. Serious games, in the form of role-play simulations, are scenario-based games that are used to simulate real life situations. Although serious games and simulations have been widely used in serving educational purposes, there is little evidence on their use in achieving deeper learning. In addition, there is lack of guidelines or a framework for designing serious games to support learners achieve deep learning. This paper proposes a theoretical framework, based on Bloom’s educational model for Mastery Learning, which illustrates the design of instructional process adapted for serious games using empathy and creativity as an approach of designing serious games for achieving deeper learning. It describes an approach of evaluating this framework by designing a serious game focusing on raising awareness about domestic violence and abuse. © 2018, Dechema e.V. All rights reserved.;2018;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;785-791;NA;NA;2018-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
I6UE4TSP;conferencePaper;2018;Asada, M.;Artificial pain: Empathy, morality, and ethics as a developmental process of consciousness;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059816137&partnerID=40&md5=0c3d169632da3fae45d6ce00852c1fc0;"In this article, I propose a working hypothesis that the nervous system of pain sensation is a key component to shape robots' (artificial systems') conscious minds through the developmental process of empathy, morality, and ethics based on the MNS that promotes the emergence of concept of self (and others). First, the limitation of the current progress of AI focusing on deep learning is pointed out from a viewpoint of the emergence of consciousness. Next, the outline of ideological back-ground on issues of mind in a broad sense is shown. Then, cognitive developmental robotics (CDR) is introduced with two important concepts; physical embodiment and social interaction both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, an issue how robots (artificial systems) could be moral and legal agents is shown. © 2018 for the individual papers by the papers' authors. All rights reserved.";2018;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;NA;NA;NA;2287;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
THAHT5MD;journalArticle;2018;"Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.";Towards empathetic human-robot interactions;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-75487-1_14;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.;2018;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;173-193;NA;NA;9624 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HS8J5MBX;conferencePaper;2017;"Xu, A.; Liu, Z.; Guo, Y.; Sinha, V.; Akkiraju, R.";A new chatbot for customer service on social media;Conference on Human Factors in Computing Systems - Proceedings;NA;NA;10.1145/3025453.3025496;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454411&doi=10.1145%2f3025453.3025496&partnerID=40&md5=eb0554245b67f51b2c89e08ecccdd3ec;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric. © 2017 ACM.";2017;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;3506-3510;NA;NA;2017-May;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 139</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WT2LJ33Z;journalArticle;2017;Chan, Z.C.Y.;Poetry writing and artistic ability in problem-based learning;International Journal on Disability and Human Development;NA;NA;10.1515/ijdhd-2016-0003;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb;Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.;2017;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;37-44;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
5SP7CYYV;journalArticle;2016;"Wiśniewska, M.; Grudowski, P.";High-quality academic teachers in business school. The case of The University of Gdańsk, Poland;Total Quality Management and Business Excellence;NA;NA;10.1080/14783363.2015.1064766;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936966560&doi=10.1080%2f14783363.2015.1064766&partnerID=40&md5=0db7256a03085c4e979fe572a2f1f6ea;The Bologna process, the increasing number of higher education institutions, the mass education and the demographic problems make the quality of education and quality of the academic teachers a subject of wide public debate and concern. The aim of the paper is to identify the most preferred characteristics of a teacher working at a business school. The research problem was: What should a high-quality business school academic teacher be like? During the research, a six-stage qualitative survey design was proposed, and a letter questionnaire was applied as a free writing instrument and sent to second-year bachelor students of the Faculty of Management at The University of Gdańsk, Poland. To identify the most preferred characteristics, a content analysis and Pareto analysis were used. As a result, 32 characteristics were proposed and grouped into 5 categories, namely tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Based on this, several proposals and recommendations for the future were specified. The results obtained help not only to understand the needs of students, but also to prepare the most desired teaching environment in which deep learning outcomes are made possible for future managers in the context of modern economy. © 2015 Taylor & Francis.;2016;2021-02-15T22:37:00Z;2021-02-15T22:37:00Z;NA;1158-1170;NA;9-10;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DLCRDVB8;conferencePaper;2016;"Gibson, J.; Can, D.; Xiao, B.; Imel, Z.E.; Atkins, D.C.; Georgiou, P.; Narayanan, S.";A deep learning approach to modeling empathy in addiction counseling;Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH;NA;NA;10.21437/Interspeech.2016-554;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994381542&doi=10.21437%2fInterspeech.2016-554&partnerID=40&md5=597e1b16131430e9c506dd9c234d9232;Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics. Copyright © 2016 ISCA.;2016;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;1447-1451;NA;NA;08-12-September-2016;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XTDWT5D8;conferencePaper;2016;"Kido, T.; Swan, M.";Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing;AAAI Spring Symposium - Technical Report;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51;"Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.";2016;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;362-368;NA;NA;SS-16-01 - 07;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2XSLDMKQ;journalArticle;2016;"Abbiati, M.; Baroffio, A.; Gerbase, M.W.";Personal profile of medical students selected through a knowledge-based exam only: Are we missing suitable students?;Medical Education Online;NA;NA;10.3402/meo.v21.29705;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007079343&doi=10.3402%2fmeo.v21.29705&partnerID=40&md5=f9afdbc35a30596a7a5ca8f19aee8413;Introduction: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. Methods: Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. Results: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. Conclusion: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile. © 2016 Milena Abbiati et al.;2016;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;NA;NA;1;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
82UWUSWI;conferencePaper;2013;"Watkins Jr., D.W.; Paterson, K.G.; Barkdoll, B.D.";Educating engineers through international community engagement - What's it worth?;World Environmental and Water Resources Congress 2013: Showcasing the Future - Proceedings of the 2013 Congress;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887500608&partnerID=40&md5=a68db8ae1d9c1adcacd1e4db2970f879;International experiences have been promoted to better prepare students for the global and rapidly changing society in which we live, to help them realize the impacts of engineering solutions, and to help them develop a deeper empathy for their project stakeholders, often those living in developing countries. If the international experience incorporates serving others through a project of need, it is commonly believed that the students learn on a much deeper level than through the conventional learning approach of classroom lectures, homework problems, and tests. At Michigan Technological University, international community engagement (ICE) programs founded in engineering include an international senior (capstone) design program, a student chapter of Engineers Without Borders-USA, two Peace Corps Master's International programs, community-based participatory research programs, several social enterprises, an international sustainable development certificate, and many supportive classes. More than 500 students have participated in one or more of these programs in the last 15 years, and the vast majority of those surveyed have reported greater satisfaction with their education and a deeper learning experience compared to traditional on-campus learning. A more rigorous assessment program has more recently been adopted, permitting the examination of institutional, program, and student learning outcomes, among others. © 2013 American Society of Civil Engineers.;2013;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;2155-2162;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2PYAKTFK;conferencePaper;2013;"Buckingham Shum, S.; De Laat, M.; De Liddo, A.; Ferguson, R.; Kirschner, P.; Ravenscroft, A.; Sándor, Á.; Whitelock, D.";DCLA13: 1st International Workshop on Discourse-Centric Learning Analytics;ACM International Conference Proceeding Series;NA;NA;10.1145/2460296.2460357;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876484083&doi=10.1145%2f2460296.2460357&partnerID=40&md5=225eb84853168d852fc5766484f3ba1d;This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field. © 2013 Authors.;2013;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;282;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BGVZ3GJD;journalArticle;2012;"Shepherd, R.-M.; Pinder, J.";Reflective practice in addiction studies: Promoting deeper learning and de-stigmatising myths about addictions;Reflective Practice;NA;NA;10.1080/14623943.2012.659098;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863634090&doi=10.1080%2f14623943.2012.659098&partnerID=40&md5=015be0861ef77435a99d1fa7016ceb34;The following study was an exploratory journey to examine reflective practice amongst students taking the undergraduate paper 'Communities and Addiction'. This paper has been an elective paper within the Health Sciences for third year students at the University of Auckland for three years. The students were instructed to reflect on two assignments after they had written each one. The first assignment focused on addiction models and the second assignment focused on social marketing as a public health approach to potentially addictive behaviour (e.g. substance abuse, gambling, and eating disorders). The findings from the first assignment suggested that students developed (or enhanced) empathy towards sufferers of addiction. The findings from both of the assignments revealed that many of the students were developing reflective skills, though often this was at quite a basic level. These findings suggested that more guidance and feedback is needed to aid students in the reflective journey. © 2012 Copyright Taylor and Francis Group, LLC.;2012;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;541-550;NA;4;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UDX9EQQM;journalArticle;2011;"Nordstrom, K.; Korpelainen, P.";Creativity and inspiration for problem solving in engineering education;Teaching in Higher Education;NA;NA;10.1080/13562517.2011.560379;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957795995&doi=10.1080%2f13562517.2011.560379&partnerID=40&md5=94f753d604514090fc63ad97df5e76f9;Problem solving is a critical skill for engineering students and essential to development of creativity and innovativeness. Essential to such learning is an ease of communication and allowing students to address the issues at hand via the terminology, attitudes, humor and empathy, which is inherent to their frame of mind as novices, without the attempt to have to be the expert. Deep learning of scientific fact can be facilitated by using non-conventional tools for teaching, learning and presentation such as drama, video, posters, model making and other similar means. It may be time to break free of the PowerPoint tradition to generate successful approaches for establishing student engagement and maintaining such engagement. © 2011 Taylor & Francis.;2011;2021-02-15T22:37:01Z;2021-02-15T22:37:01Z;NA;439-450;NA;4;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 27</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WEDKTWNF;journalArticle;2020;"Rueda, J.; Lara, F.";Virtual Reality and Empathy Enhancement: Ethical Aspects;Frontiers in Robotics and AI;NA;NA;10.3389/frobt.2020.506984;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096676765&doi=10.3389%2ffrobt.2020.506984&partnerID=40&md5=4b19807309d5e5fc09617f353c543157;The history of humankind is full of examples that indicate a constant desire to make human beings more moral. Nowadays, technological breakthroughs might have a significant impact on our moral character and abilities. This is the case of Virtual Reality (VR) technologies. The aim of this paper is to consider the ethical aspects of the use of VR in enhancing empathy. First, we will offer an introduction to VR, explaining its fundamental features, devices and concepts. Then, we will approach the characterization of VR as an “empathy machine,” showing why this medium has aroused so much interest and why, nevertheless, we do not believe it is the ideal way to enhance empathy. As an alternative, we will consider fostering empathy-related abilities through virtual embodiment in avatars. In the conclusion, however, we will examine some of the serious concerns related to the ethical relevance of empathy and will defend the philosophical case for a reason-guided empathy, also suggesting specific guidelines for possible future developments of empathy enhancement projects through VR embodied experiences. © Copyright © 2020 Rueda and Lara.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AEDL2Y4D;journalArticle;2020;"Patané, I.; Lelgouarch, A.; Banakou, D.; Verdelet, G.; Desoche, C.; Koun, E.; Salemme, R.; Slater, M.; Farnè, A.";Exploring the Effect of Cooperation in Reducing Implicit Racial Bias and Its Relationship With Dispositional Empathy and Political Attitudes;Frontiers in Psychology;NA;NA;10.3389/fpsyg.2020.510787;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095935756&doi=10.3389%2ffpsyg.2020.510787&partnerID=40&md5=792c83d8c15eb412507f81480740cbdb;Previous research using immersive virtual reality (VR) has shown that after a short period of embodiment by White people in a Black virtual body, their implicit racial bias against Black people diminishes. Here we tested the effects of some socio-cognitive variables that could contribute to enhancing or reducing the implicit racial bias. The first aim of the study was to assess the beneficial effects of cooperation within a VR scenario, the second aim was to provide preliminary testing of the hypothesis that empathy and political attitudes could contribute to implicit bias about race, while the third aim was to explore the relationship between political attitudes and empathy. We had (Caucasian) participants embodied in a Black virtual body and engaged either in a cooperative (Coop group) or in a non-cooperative (Neutral group) activity with a confederate experimenter embodying another Black avatar. Before and after VR, we measured participants’ implicit racial bias by means of Implicit Association Test (IAT) and their perceived closeness toward the confederate experimenter. Before VR we also assessed participants’ political attitudes and empathy traits. Results revealed that, as compared to the Neutral group, the Coop group showed lower IAT scores after the social interaction. Interestingly, in the Neutral but not the Coop group the perceived closeness toward the confederate experimenter was associated with the initial racial bias: the more the participants reduced their distance, the more they reduced their IAT score. Moreover, reported traits of empathy and political attitudes significantly explained the variance observed in the initial implicit bias, with perspective-taking, empathic concern, and personal distress being significant predictors of the IAT scores. Finally, there was a relationship between political attitudes and empathy: the more participants considered themselves as left-wing voters, the higher their perspective-taking and empathic concern scores. We discuss these findings within the neuroscientific and social cognition field and encourage scholars from different domains to further explore whether and under which conditions a given manipulation for reducing racial bias could be efficiently transposed in VR. © Copyright © 2020 Patané, Lelgouarch, Banakou, Verdelet, Desoche, Koun, Salemme, Slater and Farnè.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
V8STG25R;conferencePaper;2020;"Cinieri, S.; Kapralos, B.; Uribe-Quevedo, A.; Lamberti, F.";Eye Tracking and Speech Driven Human-Avatar Emotion-Based Communication;2020 IEEE 8th International Conference on Serious Games and Applications for Health, SeGAH 2020;NA;NA;10.1109/SeGAH49190.2020.9201874;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092743436&doi=10.1109%2fSeGAH49190.2020.9201874&partnerID=40&md5=69a18548064c1ffc5d460cba2c56c51d;Feelings, emotions, and empathy play an important role in many daily activities including verbal and non-verbal communication. Their automatic recognition and interpretation is important in a variety of applications requiring communication skills that are difficult to reproduce in computer-simulated environments, including those involving human-avatar interactions. Our recent work has begun investigating the development of intelligent avatars capable of detecting user (human) emotions to allow for realistic human-avatar interactions within medical-based virtual simulations and serious games. In this paper, we present a system that couples eye tracking and dialogue interpretation to allow for intelligent and realistic human-avatar communication. Although formal testing is required, preliminary results are promising, showing the potential of the system. © 2020 IEEE.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LQP46NP2;journalArticle;2020;"Küster, D.; Swiderska, A.";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;International Journal of Psychology;NA;NA;10.1002/ijop.12715;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090926311&doi=10.1002%2fijop.12715&partnerID=40&md5=93cd342d1b06662a239ccc999e6dde9d;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation. © 2020 The Authors. International Journal of Psychology published by John Wiley & Sons Ltd on behalf of International Union of Psychological Science.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HBQMYKXG;conferencePaper;2020;"Guarese, R.; De Jesus Oliveira, V.; Calepso, A.; Valer, R.; Iquiapaza, Y.; Nedel, L.; MacIel, A.";E-mpathy and the phantom limb sensation: A multisensory experience for embodiment of amputation;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818321&partnerID=40&md5=9987bba9a555676ea0699ec2b68a35dd;In the context of promoting empathy among people without disabilities, we propose an application to allow users to experience having an amputated arm. By providing both visual and haptic feedback, our application offers a multisensory experience to enhance the sense of embodiment. The user of our application should still feel their real limb attached to their bodies, and yet see their virtual avatar and interact with the virtual environment as an amputee. A simple task of handling and positioning objects in a table is proposed for users to experience the difficulties of having a missing arm. Additionally, experiment participants are asked to answer a self-presence questionnaire regarding their embodiment of the virtual avatar. Copyright © 2020 for this paper by its authors.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;13-16;NA;NA;2618;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VIHX4SCT;conferencePaper;2020;"Luca, A.I.; Podina, I.R.";The influence of moral factors on bullying behaviors in adolescence: Theoretical considerations and proposal for a vr intervention to promote perspective-taking skills;eLearning and Software for Education Conference;NA;NA;10.12753/2066-026X-20-005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096480125&doi=10.12753%2f2066-026X-20-005&partnerID=40&md5=25daff84e3f0c87d7fb3307f68449e84;"In the last decade, bullying and cyberbullying has known a rapid growth with worrisome consequences in regards to adolescent mental health. In the process of understanding the factors that influence bullying behaviours, researchers turned towards investigating moral factors, such as moral emotions, especially disgust and anger, and particularly a process called” moral disengagement” (MD; [22]). Moral disengagement is thought to contribute to the reason why some individuals, although they express disgust and anger in response to bullying behaviors, do not intervene in such situations. The objective of this research is to propose a VR based intervention aimed at increasing prosocial behaviour by improving perspective taking-skills and empathy concern. In the current paper, we suggest an interactive training simulation program where adolescent volunteers will take their own perspective or the perspective of the avatar in virtual reality, being instructed to try and understand its mental states. The situations encountered in VR are meant to trigger feelings of disgust, anger or elevation, the latter being an emotion elicited by witnessing acts of moral goodness. By increasing the propensity to take the perspective of the avatar, we aim to decrease the process of moral disengagement, especially in bullying and cyberbullying situations and increase prosocial behavior in adolescents. © 2020, National Defence University - Carol I Printing House. All rights reserved.";2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;415-476;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XQDPCCJQ;journalArticle;2020;"Dorn, A.W.; Dawson, P.F.";Simulating Peace Operations: New Digital Possibilities for Training and Public Education;Simulation and Gaming;NA;NA;10.1177/1046878120968605;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095452183&doi=10.1177%2f1046878120968605&partnerID=40&md5=fa1122832b21ccc429123ceace2be44d;Background and Motivation.: A plethora of warfighting games exist commercially, but there is a lack of digital games that deal with peace processes. Furthermore, none simulate actual peacekeeping. The United Nations currently deploys about 100,000 peacekeepers to some of the world’s most dangerous zones, where peacekeepers save lives, alleviate suffering, and help create conditions for peace. The United Nations and national militaries lack peacekeeping simulations to help train their soldiers. Additionally, the public needs to learn more about the way peacekeeping works. Thus, peacekeeping simulation and gaming are worth exploring, especially in the rapidly evolving digital space, which offers new avenues and benefits. Methods.: We review the meager literature on the subject and observe that there are few digital games to directly draw from. We build on previous work that argued the need for such development, but we now assess important design principles and parameters. We draw upon peacekeeping tabletop exercises that are already well developed. Results.: We conclude that excellent scenarios and simulation technologies exist that could be combined quite easily for effective peacekeeping training and public education. We find key materials and scenarios in exercises of the United Nations and of the Pearson Peacekeeping Centre. Highlighted areas for future digital design are the inclusion of non-military avatars, emphasis on soft skills development (especially empathy), and realistically complex links between actions and consequences. Conclusion.: While describing some UN exploration at a proof-of-concept stage, we suggest that both the United Nations and the gaming industry should explore the idea further to achieve synergies between institutional and entertainment applications. The growing capacity of digital technology allows significant innovation, yielding results that could be useful, ethical, enjoyable, and potentially profitable. © 2020 SAGE Publications.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
FU6GEA5V;journalArticle;2020;"Pribbenow, C.M.; Caldwell, K.E.H.; Dantzler, D.D.; Brown, Jr., P.; Carnes, M.";Decreasing Racial Bias Through A Facilitated Game and Workshop: The Case of Fair Play;Simulation and Gaming;NA;NA;10.1177/1046878120983384;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098243099&doi=10.1177%2f1046878120983384&partnerID=40&md5=d34a04335f4fc627541d343be8135d8e;Introduction. Fair Play is an avatar-based role-playing video game in which Jamal Davis, a Black graduate student at a research university, navigates implicit forms of racial bias to reach the win-state of earning his PhD and becoming a professor. Fair Play was designed to educate players on the existence of racial bias in science, technology, engineering, mathematics, and medicine (STEMM) fields in an experiential way and to encourage perspective-taking. Research has found that taking the perspective of another can induce empathy, which improves the empathizer’s attitudes towards individuals and groups. Paired with a facilitated workshop, Fair Play was also designed to teach bias concepts to increase participants’ bias literacy. Intervention. Research on workshops to reduce gender bias suggests that it increased awareness of personal bias, the motivation and self-efficacy to practice bias-reducing strategies, and a more welcoming department climate and the hiring of more women faculty three years after the intervention. Capitalizing on these findings, a 3-hour workshop was developed to reduce race-based bias against Black/African Americans in STEMM using Fair Play. Conclusions. The facilitation of the workshops and Fair Play requires particular competencies due to its topic (racial bias) and player’s skepticism about the reality of the bias incidents. Our data suggest that participants who identify as a person of color are more likely to believe that bias exists compared to White players, which can lead to a discussion about how the incidents in the game were designed and scripted. The facilitator also needs to be versed in a number of intentional design choices, such as Jamal not having voiceover and his success. Finally, this paper describes the Facilitator Game, which was developed as a complement to the game and allows a facilitator to jump to bias incidents quickly while debriefing and discussing the game to further participant learning. © 2020 SAGE Publications.;2020;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
NM2S3UX5;journalArticle;2019;"Wilde, P.; Evans, A.";Empathy at play: Embodying posthuman subjectivities in gaming;Convergence;NA;NA;10.1177/1354856517709987;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070362093&doi=10.1177%2f1354856517709987&partnerID=40&md5=aab7a0ce8378b091e336a622000c3483;In this article, we address the need for a posthuman account of the relationship between the avatar and player. We draw on a particular line of posthumanist theory associated closely with the work of Karen Barad, Rosi Braidotti and N. Katherine Hayles that suggests a constantly permeable, fluid and extended subjectivity, displacing the boundaries between human and other. In doing so, we propose a posthuman concept of empathy in gameplay, and we apply this concept to data from the first author’s 18-month ethnographic field notes of gameplay in the MMORPG World of Warcraft. Exploring these data through our analysis of posthuman empathy, we demonstrate the entanglement of avatar–player, machine–human relationship. We show how empathy allows us to understand this relationship as constantly negotiated and in process, producing visceral reactions in the intra-connected avatar–player subject as well as moments of co-produced in-game action that require ‘affective matching’ between subjective and embodied experiences. We argue that this account of the avatar–player relationship extends research in game culture, providing a horizontal, non-hierarchical discussion of its most necessary interaction. © The Author(s) 2017.;2019;2021-02-15T22:37:38Z;2021-02-15T22:37:38Z;NA;791-806;NA;5-6;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2JRV5QBC;journalArticle;2019;"Agopyan, H.; Griffet, J.; Poirier, T.; Bredin, J.";Modification of knee flexion during walking with use of a real-time personalized avatar;Heliyon;NA;NA;10.1016/j.heliyon.2019.e02797;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074684962&doi=10.1016%2fj.heliyon.2019.e02797&partnerID=40&md5=7dafd73a008abab427e577e1f020b1af;Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed. © 2019 The Author(s);2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;11;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PHBLVMN4;conferencePaper;2019;"Roth, D.; Bloch, C.; Schmitt, J.; Frischlich, L.; Latoschik, M.E.; Bente, G.";Perceived Authenticity, Empathy, and Pro-social Intentions evoked through Avatar-mediated Self-disclosures;ACM International Conference Proceeding Series;NA;NA;10.1145/3340764.3340797;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072795574&doi=10.1145%2f3340764.3340797&partnerID=40&md5=4d0f505abddc6a24356b7791c9830f61;Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one’s avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.;2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;21-30;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TNRWKG6S;conferencePaper;2019;"Degraen, D.; Kosmalla, F.; Krüger, A.";Overgrown: Supporting plant growth with an endoskeleton for ambient notifications;Conference on Human Factors in Computing Systems - Proceedings;NA;NA;10.1145/3290607.3312833;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067302392&doi=10.1145%2f3290607.3312833&partnerID=40&md5=737e704d963e985c7fe9415be110f795;Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments. © 2019 Copyright held by the owner/author(s).;2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UDTH7SCM;journalArticle;2019;"Küster, D.; Krumhuber, E.G.; Hess, U.";You are What You Wear: Unless You Moved—Effects of Attire and Posture on Person Perception;Journal of Nonverbal Behavior;NA;NA;10.1007/s10919-018-0286-3;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055966865&doi=10.1007%2fs10919-018-0286-3&partnerID=40&md5=dfd97f867726dfa1ea0958eb2409c58f;While first impressions are often based on appearance cues, little is known about how these interact with information from other channels. The present research aimed to investigate the impact of occupational stereotypes, evoked by attire, as well as posture on person perception. For this, computer animation was used to create avatars with different types of attire (nurse, military, casual) and posture (open, closed). In Study 1 (N = 164), participants attributed significantly more empathy to avatars wearing a nurse versus a military uniform or casual outfit. When adding posture as an additional cue, Study 2 (N = 312) showed that ratings of empathy and dominance were affected by both attire and posture. This effect was replicated in Study 3 (N = 163) for female avatars, in the sense that open postures in nurses increased empathy ratings and decreased dominance ratings, which both in turn led to greater perceived competence. By contrast, for male avatars, posture did not affect attributions of competence directly. Rather, attire predicted perceived dominance directly, as well as through perceived empathy. The present findings suggest that both posture, and occupational information evoked by attire, are used to infer personal characteristics. However, the strength of each cue may vary with the gender of the target. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.;2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;23-38;NA;1;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
NRI6W2FS;conferencePaper;2019;"Takano, M.; Tsunoda, T.";Self-disclosure of bullying experiences and social support in avatar communication: Analysis of verbal and nonverbal communications;Proceedings of the 13th International Conference on Web and Social Media, ICWSM 2019;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070376669&partnerID=40&md5=c4980b3e2f1fec8b0a980aab67deb0fa;Avatar communication through the Internet has great potential to be an appropriate environment for self-disclosure and social support. Anonymity and ease of access drive self-disclosure of even the most serious problems. Rich nonverbal communication, co-presence, and real-time interaction increase emotional closeness. However, there has not been much research with regard to examining social support in avatar communication. In this paper, we aim to facilitate self-disclosure and social support for bullied people through avatar communication. For this purpose, we analyzed verbal and nonverbal communication about bullying experiences through an avatar communication service. We demonstrate that people who emotionally disclosed their bullying experiences received better social support. In addition, people who provided social support used emotional expressions to convey emotional empathy. These were observed in conversations with a few acquaintances in closed spaces. Our findings reveal areas where we can improve upon the design of avatar communication spaces for effective social support. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;473-481;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MJRIFE5J;journalArticle;2019;"Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.";A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study;Journal of Medical Internet Research;NA;NA;10.2196/14658;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.;2019;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SPACCNFV;journalArticle;2018;"Swiderska, A.; Küster, D.";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;Perception;NA;NA;10.1177/0301006618809919;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058656094&doi=10.1177%2f0301006618809919&partnerID=40&md5=2d29a1feddf28df7efb1c2f080d656ba;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain. © The Author(s) 2018.;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;1139-1152;NA;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
KNWZ3GLI;journalArticle;2018;"Hamilton-Giachritsis, C.; Banakou, D.; Garcia Quiroga, M.; Giachritsis, C.; Slater, M.";Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment;Scientific Reports;NA;NA;10.1038/s41598-018-21036-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042078955&doi=10.1038%2fs41598-018-21036-2&partnerID=40&md5=fb96ebbd43cee03a0b332b62bfa1347d;The ability to perspective-take (cognitive awareness of another's state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a 'mother avatar', which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children. © 2018 The Author(s).;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 10</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
REP27BNE;journalArticle;2018;"Joyal, C.C.; Neveu, S.-M.; Boukhalfi, T.; Jackson, P.L.; Renaud, P.";Suppression of sensorimotor alpha power associated with pain expressed by an avatar: A preliminary EEG study;Frontiers in Human Neuroscience;NA;NA;10.3389/fnhum.2018.00273;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054880498&doi=10.3389%2ffnhum.2018.00273&partnerID=40&md5=fc408903253633371b024fcb0042b21e;"Several studies using functional magnetic resonance imaging (fMRI) showed that empathic capabilities are associated with the activation (and deactivation) of relatively specific neural circuits. A growing number of electroencephalography studies also suggest that it might be useful to assess empathy. The main goal of this study was to use quantitative electroencephalography (qEEG) to test whether observation of pain expressed by an avatar (virtual reality) induces a suppression of alpha waves over sensorimotor cortical areas, as it is observed with human stimuli. Not only was it the case, but also the magnitude of alpha suppression was correlated with perspective-taking capacity of participants. Both empathy levels and magnitude of sensorimotor alpha suppression (SAS) were significantly higher in women than men. Interestingly, a significant interaction emerged between levels of individual empathy and specificity of experimental instructions, where SAS in participants with good perspective-taking was higher during passive observation of the distressed avatar, while the opposite was true during an active (trying to understand) condition. These results suggest that: (1) synthetic characters are able to elicit SAS; (2) SAS is indeed associated with perspective-taking capacities; (3) Persons with poorer perspective-taking capacities can show significant SAS when proper instructions are provided. Therefore, qEEG represents a low-cost objective approach to measure perspective-taking abilities. © 2018 Joyal, Neveu, Boukhalfi, Jackson and Renaud.";2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;NA;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3TLVVUT9;conferencePaper;2018;"Raffe, W.L.; Garcia, J.A.";Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly;2018 IEEE 6th International Conference on Serious Games and Applications for Health, SeGAH 2018;NA;NA;10.1109/SeGAH.2018.8401371;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050191845&doi=10.1109%2fSeGAH.2018.8401371&partnerID=40&md5=131e80406d278219c3234b216c481603;This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations. © 2018 IEEE.;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;1-7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
U952IPXK;journalArticle;2018;"Bernard, F.; Lemée, J.-M.; Aubin, G.; Ter Minassian, A.; Menei, P.";Using a Virtual Reality Social Network During Awake Craniotomy to Map Social Cognition: Prospective Trial;Journal of medical Internet research;NA;NA;10.2196/10332;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053566924&doi=10.2196%2f10332&partnerID=40&md5=11f551d8d5e0a5da719d0fabbdaa2a5b;"BACKGROUND: In awake craniotomy, it is possible to temporarily inactivate regions of the brain using direct electrical stimulation, while the patient performs neuropsychological tasks. If the patient shows decreased performance in a given task, the neurosurgeon will not remove these regions, so as to maintain all brain functions. OBJECTIVE: The objective of our study was to describe our experience of using a virtual reality (VR) social network during awake craniotomy and discuss its future applications for perioperative mapping of nonverbal language, empathy, and theory of mind. METHODS: This was a single-center, prospective, unblinded trial. During wound closure, different VR experiences with a VR headset were proposed to the patient. This project sought to explore interactions with the neuropsychologist's avatar in virtual locations using a VR social network as an available experience. RESULTS: Three patients experienced VR. Despite some limitations due to patient positioning during the operation and the limitation of nonverbal cues inherent to the app, the neuropsychologist, as an avatar, could communicate with the patient and explore gesture communication while wearing a VR headset. CONCLUSIONS: With some improvements, VR social networks can be used in the near future to map social cognition during awake craniotomy. TRIAL REGISTRATION: ClinicalTrials.gov NCT03010943; https://clinicaltrials.gov/ct2/show/NCT03010943 (Archived at WebCite at http://www.webcitation.org/70CYDil0P). ©Florian Bernard, Jean-Michel Lemée, Ghislaine Aubin, Aram Ter Minassian, Philippe Menei. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 26.06.2018.";2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;e10332;NA;6;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
63UHEUNA;journalArticle;2018;"Johnson, E.; Hervás, R.; Gutiérrez López de la Franca, C.; Mondéjar, T.; Ochoa, S.F.; Favela, J.";Assessing empathy and managing emotions through interactions with an affective avatar;Health Informatics Journal;NA;NA;10.1177/1460458216661864;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046768759&doi=10.1177%2f1460458216661864&partnerID=40&md5=7d10b56caf5c71b81ef6a0d346406804;Assistive technologies can improve the quality of life of people diagnosed with different forms of social communication disorders. We report on the design and evaluation of an affective avatar aimed at engaging the user in a social interaction with the purpose of assisting in communication therapies. A human–avatar taxonomy is proposed to assist the design of affective avatars aimed at addressing social communication disorder. The avatar was evaluated with 30 subjects to assess how effectively it conveys the desired emotion and elicits empathy from the user. Results provide evidence that users become used to the avatar after a number of interactions, and they perceive the defined behavior as being logical. The users’ interactions with the avatar entail affective reactions, including the mimic emotions that users felt, and establish a preliminary ground truth about prototypic empathic interactions with avatars that is being used to train learning algorithms to support social communication disorder evaluation. © 2016, © The Author(s) 2016.;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;182-193;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 12</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AUGEUDUE;journalArticle;2018;"Felnhofer, A.; Kafka, J.X.; Hlavacs, H.; Beutl, L.; Kryspin-Exner, I.; Kothgassner, O.D.";Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents;Computers in Human Behavior;NA;NA;10.1016/j.chb.2017.11.031;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037057403&doi=10.1016%2fj.chb.2017.11.031&partnerID=40&md5=c6ba24850a8392df3ff56ebe5b4f75bd;Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the Media Equation Concept (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses. © 2017 Elsevier Ltd;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;399-406;NA;NA;80;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 12</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3WF6W9YN;conferencePaper;2018;"Kowatsch, T.; Nißen, M.; Rüegger, D.; Stieger, M.; Flückiger, C.; Allemand, M.; Von Wangenheim, F.";The impact of interpersonal closeness cues in text-based healthcare chatbots on attachment bond and the desire to continue interacting: An experimental design;26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052961056&partnerID=40&md5=ea614d0bfe759b29a1dc7f99a9de87b3;Working alliance describes an important relationship quality between health professionals and patients and is robustly linked to treatment success. However, due to limited resources of health professionals, working alliance cannot always be promoted just-in-time in a ubiquitous fashion. To address this scalability problem, we investigate the direct effect of interpersonal closeness cues of text-based healthcare chatbots (THCBs) on attachment bond from the working alliance construct and the indirect effect on the desire to continue interacting with THCBs. The underlying research model and hypotheses are informed by counselling psychology and research on conversational agents. In order to investigate the hypothesized effects, we first develop a THCB codebook with 12 design dimensions on interpersonal closeness cues that are categorized into visual cues (i.e. avatar), verbal cues (i.e. greetings, address, jargon, T-V-distinction), quasi-nonverbal cues (i.e. emoticons) and relational cues (i.e. small talk, self-disclosure, empathy, humor, meta-relational talk and continuity). In a second step, four distinct THCB designs are developed along the continuum of interpersonal closeness (i.e. institutional-like, expert-like, peer-like and myself-like THCBs) and a corresponding study design for an interactive THCB-based online experiment is presented to test our hypotheses. We conclude this work-in-progress by outlining our future work. © 26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018. All Rights Reserved.;2018;2021-02-15T22:37:39Z;2021-02-15T22:37:39Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
YURJ6A3U;journalArticle;2017;"Ferguson, C.J.; Donnellan, M.B.";Are Associations Between “Sexist” Video Games and Decreased Empathy Toward Women Robust? A Reanalysis of Gabbiadini et al. 2016;Journal of Youth and Adolescence;NA;NA;10.1007/s10964-017-0700-x;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021122350&doi=10.1007%2fs10964-017-0700-x&partnerID=40&md5=603ebd5a0a8567a347e39875ef17c332;"Gabbiadini, A., Riva, P., Andrighetto, L., Volpato, C., &amp; Bushman, B, (PloS ONE, 2016) provided evidence for a connection between “sexist” video games and decreased empathy toward girls using an experimental paradigm. These claims are based on a moderated mediation model. They reported a three-way interaction between game condition, gender, and avatar identification when predicting masculine ideology in their original study. Masculine ideology was associated, in turn, with decreased empathy. However, there were no main experimental effects for video game condition on empathy. The current analysis considers the strength of the evidence for claims made in the original study on a sample of 153 adolescents (Mage = 16.812, SD = 1.241; 44.2% male). We confirmed that there was little evidence for an overall effect of game condition on empathy toward girls or women. We tested the robustness of the original reported moderated mediation models against other, theoretically derived alternatives, and found that effects differed based on how variables were measured (using alternatives in their public data file) and the statistical model used. The experimental groups differed significantly and substantially in terms of age suggesting that there might have been issues with the procedures used to randomly assign participants to conditions. These results highlight the need for preregistration of experimental protocols in video game research and raise some concerns about how moderated mediation models are used to support causal inferences. These results call into question whether use of “sexist” video games is a causal factor in the development of reduced empathy toward girls and women among adolescents. © 2017, Springer Science+Business Media New York.";2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;2446-2459;NA;12;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
AVG72GEI;conferencePaper;2017;Murphy, D.;Building a hybrid virtual agent for testing user empathy and arousal in response to avatar (micro-)expressions;Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST;NA;NA;10.1145/3139131.3141217;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038598502&doi=10.1145%2f3139131.3141217&partnerID=40&md5=c1d14dd71b245eeb29f6de44b13ffa26;This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR. © 2017 Copyright held by the owner/author(s).;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;NA;NA;NA;Part F131944;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QNFZS64P;conferencePaper;2017;"Lin, C.; Faas, T.; Dombrowski, L.; Brady, E.";Beyond cute: Exploring user types and design opportunities of virtual reality pet games;Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST;NA;NA;10.1145/3139131.3139132;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038583884&doi=10.1145%2f3139131.3139132&partnerID=40&md5=f83b808eee343e0466b0933a733a4d62;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, little is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games. © 2017 Copyright is held by the owner/author(s).;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;NA;NA;NA;Part F131944;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4WDCESBS;conferencePaper;2017;"Vieira, S.; Maritan, T.; Santos, A.; Aschoff, M.; Costa, R.; Veríssimo, V.";A study on the use of multiple avatars in 3D sign language dictionaries;WebMedia 2017 - Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web;NA;NA;10.1145/3126858.3126865;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035022193&doi=10.1145%2f3126858.3126865&partnerID=40&md5=dc3f278f2adca9d4a8b9a0f54aad8165;Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors. © 2017 ACM.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;325-332;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
DVVA9FVF;journalArticle;2017;Chin, G.P.W.-H.;Observed bodies and tool selves: kinaesthetic empathy and the videogame avatar;Digital Creativity;NA;NA;10.1080/14626268.2017.1348363;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025148899&doi=10.1080%2f14626268.2017.1348363&partnerID=40&md5=c7661dcdf2925cb93633714b0755ded6;This paper examines the field of Kinaesthetic Empathy and how it is studied in dance and film then interrogates whether this framework can be applied to the videogame avatar. I study the avatar as textually signifying, as an observed body, and as a prosthetic tool-limb using the works of Merleau-Ponty and Heidegger as theoretical support and Ian Bogost’s procedural style of videogame reading. I perform close readings of videogame-texts Metal Gear Solid 3 and Mirror’s Edge demonstrating how the former enacts a traditional kinaesthetic empathy in the same way as in dance or film and the latter complicates this observer/performer relation. My paper concludes that, though a player/reader may experience a kinaesthetic empathy that resembles the filmic mode of observer/performer kinaesthetic empathy, the videogame form engenders a deeper tool-based empathy, which is altogether different from traditional conceptions of kinaesthetic empathy. © 2017 Informa UK Limited, trading as Taylor & Francis Group.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;206-223;NA;3;28;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XVLMEXAX;journalArticle;2017;"van Rijn, B.; Cooper, M.; Jackson, A.; Wild, C.";Avatar-based therapy within prison settings: pilot evaluation;British Journal of Guidance and Counselling;NA;NA;10.1080/03069885.2015.1068273;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937883419&doi=10.1080%2f03069885.2015.1068273&partnerID=40&md5=eea27491822516edfa435a9ecda8e06b;The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n = 4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population. © 2015 Informa UK Limited, trading as Taylor & Francis Group.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;268-283;NA;3;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 9</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7S9YX9BE;conferencePaper;2017;"Tong, X.; Ulas, S.; Jin, W.; Gromala, D.; Shaw, C.";The design and evaluation of a body-sensing video game to foster empathy towards chronic pain patients;ACM International Conference Proceeding Series;NA;NA;10.1145/3154862.3154869;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055989941&doi=10.1145%2f3154862.3154869&partnerID=40&md5=5e5c7a5c80904cdcb2071e511384877a;"Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations. © 2017 Association for Computing Machinery.";2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;244-250;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7SYH2Q34;journalArticle;2017;Jarvis, L.;The Ethics of Mislocalized Selfhood: Proprioceptive drifting towards the virtual other;Performance Research;NA;NA;10.1080/13528165.2017.1348587;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029772572&doi=10.1080%2f13528165.2017.1348587&partnerID=40&md5=c0fc49b30428a3e8f4e132804abaebbd;In Psychology, ‘proprioceptive drift’ is a term that originates from the rubber hand illusion paradigm to describe the ‘relative displacement of the perceived location of one’s own hand toward the location of the rubber hand’ (Wold et al, 2014). Correspondingly, drift measurements in science are used as a means of rating the intensity of a body-ownership illusion via which a participant in a controlled experiment perceives that an extracorporeal appendage, or virtual whole-body avatar is incorporated as part of one’s own body schema. In this research article, I will examine an applied performance by BeAnotherLab utilising the anti-disciplinary collective’s The Machine to Be Another as part of Good Chance’s Encampment project–this telepresence system produces a VR body illusion intended to increase empathy and reduce proximity between an immersant’s real body and that of a volunteer refugee counterpart. When scientifically-tested body illusions cross a paradigmatic boundary to be framed as immersive art, what are the ethical implications? Furthermore, are these kinds of virtual proprioceptive transactions across different kinds of social and political boundaries symptomatic of radical empathic acts, or a capitalistic desire for the acquisition of another’s experiences by virtual means? This article examines illusory bodily inhabitation through a Levinasian critical lens to consider the ethics of deterritorializing the immersant’s gaze and referring their sense of touch elsewhere to produce ‘narrative immersion’. © 2017 Informa UK Limited, trading as Taylor & Francis Group.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;30-37;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
LY6ERAUB;journalArticle;2017;"Conway, J.R.; Lee, D.; Ojaghi, M.; Catmur, C.; Bird, G.";Submentalizing or mentalizing in a level 1 perspective-taking task: A cloak and goggles test;Journal of Experimental Psychology: Human Perception and Performance;NA;NA;10.1037/xhp0000319;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001065631&doi=10.1037%2fxhp0000319&partnerID=40&md5=4574eab974dd54505c02084899d36262;It has been proposed that humans possess an automatic system to represent mental states ('implicit mentalizing'). The existence of an implicit mentalizing system has generated considerable debate however, centered on the ability of various experimental paradigms to demonstrate unambiguously such mentalizing. Evidence for implicit mentalizing has previously been provided by the 'dot perspective task,' where participants are slower to verify the number of dots they can see when an avatar can see a different number of dots. However, recent evidence challenged a mentalizing interpretation of this effect by showing it was unaltered when the avatar was replaced with an inanimate arrow stimulus. Here we present an extension of the dot perspective task using an invisibility cloaking device to render the dots invisible on certain trials. This paradigm is capable of providing unambiguous evidence of automatic mentalizing, but no such evidence was found. Two further well-powered experiments used opaque and transparent goggles to manipulate visibility but found no evidence of automatic mentalizing, nor of individual differences in empathy or perspective-taking predicting performance, contradicting previous studies using the same design. The results cast doubt on the existence of an implicit mentalizing system, suggesting that previous effects were due to domain-general processes. © 2016 The Author(s).;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;454-465;NA;3;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 31</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XZKKC2ST;conferencePaper;2017;"Hervas, R.; Johnson, E.; Franca, C.G.L.D.L.; Bravo, J.; Mondejar, T.";A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars;Proceedings - 2016 15th International Conference on Ubiquitous Computing and Communications and 2016 8th International Symposium on Cyberspace and Security, IUCC-CSS 2016;NA;NA;10.1109/IUCC-CSS.2016.021;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015234516&doi=10.1109%2fIUCC-CSS.2016.021&partnerID=40&md5=fdd98a86252b4919bd70a2d0688561f0;Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability. © 2016 IEEE.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;93-100;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
NGCP8FME;journalArticle;2017;"Johnson, E.; Hervás, R.; Gutiérrez-López-Franca, C.; Mondéjar, T.; Bravo, J.";Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar;Mobile Information Systems;NA;NA;10.1155/2017/7932529;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021665183&doi=10.1155%2f2017%2f7932529&partnerID=40&md5=56f1d3d19d1da916c8444885ffcfd4a1;In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues. © 2017 Esperanza Johnson et al.;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;NA;NA;NA;2017;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SHUNPDXM;conferencePaper;2017;Gabriel, S.;Teaching human rights with video games?;Proceedings of the 11th European Conference on Games Based Learning, ECGBL 2017;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036477671&partnerID=40&md5=e512018f6f44da07a412436d7d2a07c4;Serious games which deal with human rights topics have been on the rise for the last 15 years. Digital games show some unique properties that make them valuable for inducing social change. Some of the game elements that can be used to integrate values are as follows: Narration, which is one of the elements that is most obvious to players and is part of most of today's digital games, is a proper way of presenting human rights topics and can also include ideological messages. However, there are also other ways of creating empathy for certain groups as the example of Ayitii - The Cost of Life shows: If players feel responsible for the game characters, games can make players think about the topic presented. Being able to take meaningful decisions which influence the player's avatar, other non-playable characters, the narration or the game-world is a property of many recent games. Thus, ethical decisions are included in games and put players into the shoes of those who are oppressed or put in other situations where there is no easy way of deciding if something is right or wrong. Finally, the article also discusses if these serious games can affect players' real lives and change their way of thinking and attitudes. The serious game This War of Mine shows that some players think about their decisions and the topic of the game even after having stopped playing. However, there are also restrictions to transferring game contents into players' lives and induce social change. Quite often it is not enough just to play the game, teaching which must take place in a non-game context, is needed to make players aware of human rights (violations).;2017;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;191-196;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8L8LQKUS;conferencePaper;2016;"Hughes, D.E.; Vasquez, E.; Nicsinger, E.";Improving perspective taking and empathy in children with autism spectrum disorder;2016 IEEE International Conference on Serious Games and Applications for Health, SeGAH 2016;NA;NA;10.1109/SeGAH.2016.7586232;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994711788&doi=10.1109%2fSeGAH.2016.7586232&partnerID=40&md5=bb23946086eb29ab2bf182f27c885055;This paper discusses the design, implementation, and evaluation of a serious game intended to reinforce applied behavior analysis (ABA) techniques used with children with autism spectrum disorder (ASD) by providing a low cost and easily accessible supplement to traditional methods. The goal is develop a safe environment for social exploration and learning that boosts the child's confidence while providing calming mechanisms. Games increase children's motivation and thus increase the rate of learning in computer mediated environments. Furthermore, children with ASD are able to understand basic emotions and facial expressions in avatars more easily than in real-world interactions. © 2016 IEEE.;2016;2021-02-15T22:37:40Z;2021-02-15T22:37:40Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
P9C3MEKK;conferencePaper;2016;"Ishii, Y.; Watanabe, T.; Sejima, Y.";Development of an embodied avatar system using avatar-Shadow's color expressions with an interaction-activated communication model;HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction;NA;NA;10.1145/2974804.2980487;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994531607&doi=10.1145%2f2974804.2980487&partnerID=40&md5=fa666452f49b11f978504b10566a6478;In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color. Copyright © 2016 ACM.;2016;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;337-340;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
MHA57L4U;journalArticle;2016;"Mattan, B.D.; Rotshtein, P.; Quinn, K.A.";Empathy and visual perspective-taking performance;Cognitive Neuroscience;NA;NA;10.1080/17588928.2015.1085372;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953718172&doi=10.1080%2f17588928.2015.1085372&partnerID=40&md5=527ce22966ad81cb1010584fee7295be;This study examined the extent to which visual perspective-taking performance is modulated by trait-level empathy. Participants completed a third-person visual perspective-taking task in which they judged the perspectives of two simultaneously presented avatars, designated “Self” and “Other.” Depending on the trial, these avatars either held the same view (i.e., congruent) or a different view (i.e., incongruent). Analyses focused on the relationship between empathy and two perspective-taking phenomena: Selection between competing perspectives (i.e., perspective-congruence effects) and prioritization of the Self avatar’s perspective. Empathy was related to improved overall performance on this task and a reduced cost of selecting between conflicting perspectives (i.e., smaller perspective-congruence effects). This effect was asymmetric, with empathy (i.e., empathic concern) levels predicting reduced interference from a conflicting perspective, especially when adopting the Self (vs. Other) avatar’s perspective. Taken together, these results highlight the importance of the self–other distinction and mental flexibility components of empathy. © 2016 Taylor & Francis.;2016;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;170-181;NA;1-4;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 14</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
94KLMBT3;conferencePaper;2016;"Marcu, G.; Dowshen, N.; Saha, S.; Sarreal, R.R.; Andalibi, N.";TreatYoSelf: Empathy-driven behavioral intervention for marginalized youth living with HIV;PervasiveHealth: Pervasive Computing Technologies for Healthcare;NA;NA;10.4108/eai.16-5-2016.2263336;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046951092&doi=10.4108%2feai.16-5-2016.2263336&partnerID=40&md5=9c69c52491175e22e9a5c12cd82ac0f2;"Behavioral intervention technologies are well suited to addressing health behavior such as medication adherence, but only if successfully integrated into a user's daily life. Little is known about how to design such technologies to be adoptable, adaptable, useful, and feasible in everyday life. We report on the design process for TreatYoSelf, a smartphone application designed to improve medication adherence among youth living with HIV through reminders and positive reinforcement. Using participatory design, our aim was to understand factors related to adoption and acceptance of behavioral intervention technology as part of daily life. Two challenges of living with HIV led to an empathy-driven approach in our design process: (1) HIV is a stigmatized condition, which (2) disproportionately affects the marginalized populations of young African American men who have sex with men and transgender women. We discuss five empathy-driven design strategies: positive and nonjudgmental tone; minimal, avatar-based gamification; motivational and corny messages; nondisclosure through neutral signifiers; and social support through camaraderie. Our approach enabled us to identify and work through factors, often related to stigma and marginalization, which would lead to rejection of TreatYoSelf use in daily life. © 2016 EAI.";2016;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;NA;NA;NA;2016-May;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 11</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3BLFMG24;journalArticle;2016;"Tordo, F.; Binkley, C.";Auto-empathy or the others-in-oneself's evolution: Definition and clinic of virtual [L'auto-empathie, ou le devenir de l'autrui-en-soi: Définition et clinique du virtuel];Evolution Psychiatrique;NA;NA;10.1016/j.evopsy.2014.02.002;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900883323&doi=10.1016%2fj.evopsy.2014.02.002&partnerID=40&md5=2772d143d98da8ff9a47bdfb519c12da;"Objectives: The authors propose to explore a psychic phenomenon, the ""auto-empathy"", as implemented in the context of digital spaces and particularly in the situation of the player who embodies an avatar (a pixel figure) in a video game. Method: From the perspective of a theoretical opening both phenomenological and psychoanalytic, auto-empathy is the process in which, taking the position of the ""other-in-oneself"", we represent our subjective world - or the all states of our subjectivity (actions, emotions, thoughts) - by an empathic relationship with ourselves. The auto-empathy relationship is a process of distancing, and symbolic appropriation, in which we are divided into halves, implementing our innate ability to be both subject and object for ourselves. Results: The mediatization of auto-empathy in digital worlds can put ourselves instead of a figure that represents us - our avatar - so that our empathy is turned towards ourselves indirectly. This second time of empathy for a virtual figure of the self, called ""mediatized auto-empathy"" or ""virtual auto-empathy"", would contribute thirdly to the development of empathy for oneself. Finally, the development of empathy for others would be supported in a fourth time, by the attention the players are paying to each other in network games. Discussion: These four hypotheses, illustrated by clinical cases, open an interrogation concerning the frame of the psychoanalytical work. In the adolescent, the work of virtualisation, which consists in the creative anticipation of its subjective possibilities, seems regularly impeded. The mental duplicity is no longer in a position to operate a symbolizing distance between the real self and the virtual self, between the subjective self and the subjectivising self. The other-in-oneself is ineffective in proposing to the adolescent an empathic dialogue with oneself. Consequently, the autorepresentation flirts with the seizure, in particular in the subjective states of breaks. Nevertheless, the digital spaces could be indirect media of appropriation of subjective experiences for the teenager. Conclusion: Our reflections led us to think of auto-empathy as the realization of the other-in-oneself which allows us to represent our own subjective world. The auto-empathy mediatized by an avatar can thus be described as a representation by empathy of our subjective part that contains this character. From then on, the space of the video game appears as a space of subjectivation. © 2014 Elsevier Masson SAS.";2016;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;293-308;NA;2;81;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
CWRKXUAU;conferencePaper;2016;Jestice, R.;Walking in someone's virtual shoes: Virtual worlds as a tool for developing empathy;AMCIS 2016: Surfing the IT Innovation Wave - 22nd Americas Conference on Information Systems;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987668886&partnerID=40&md5=fcf90cdfb9ac4debe4a88d5a5f25d8ff;Empathy is an important skill for leaders. It is proposed that virtual worlds can be used effectively as a tool in developing empathy, especially perspective taking. This emerging stream of research explores the use of virtual worlds and avatar manipulation as a means to evoke perspective taking in leadership students. It is proposed that due to the Proteus Effect, virtual world users will change their behavior in a role-play based on their avatar's appearance. Further, it is proposed that this change in behaviors will lead to more insight into the perspectives of different others in a similar real world situation.;2016;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
45SBXCCH;journalArticle;2015;"Pablos, S.M.; García-Bermejo, J.G.; Zalama Casanova, E.; López, J.";Dynamic facial emotion recognition oriented to HCI applications;Interacting with Computers;NA;NA;10.1093/iwc/iwt057;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928327868&doi=10.1093%2fiwc%2fiwt057&partnerID=40&md5=1830d1e522ce7a76abd9ccd267476889;As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176-192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human-computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response. © 2013 The Author. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.;2015;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;99-119;NA;2;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 8</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8STZDDA2;conferencePaper;2015;"Andersen, J.S.; Schoenau-Fog, H.";Using role-taking and behavioral mimicking in games to increase awareness on the bystander effect;ACADEMICMINDTREK 2015 - Proceedings of the 19th International Academic Mindtrek Conference;NA;NA;10.1145/2818187.2818290;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962875863&doi=10.1145%2f2818187.2818290&partnerID=40&md5=9bb92260b998ec261abfbb7a1ee9ae11;This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.;2015;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;69-72;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TVQG7XF2;journalArticle;2015;"Sulpizio, V.; Committeri, G.; Metta, E.; Lambrey, S.; Berthoz, A.; Galati, G.";Visuospatial transformations and personality: evidence of a relationship between visuospatial perspective taking and self-reported emotional empathy;Experimental Brain Research;NA;NA;10.1007/s00221-015-4280-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930869966&doi=10.1007%2fs00221-015-4280-2&partnerID=40&md5=a758a2763261e0854cd1aabac0e34968;In the visuospatial domain, perspective taking is the ability to imagine how a visual scene appears from an external observer’s viewpoint, and can be studied by asking subjects to encode object locations in a visual scene where another individual is present and then detecting their displacement when seeing the scene from the other’s viewpoint. In the current study, we explored the relationship between visuospatial perspective taking and self-report measures of the cognitive and emotional components of empathy in young adults. To this aim, we employed a priming paradigm, in which the presence of an avatar allowed to anticipate the next perceived perspective on the visual scene. We found that the emotional dimension of empathy was positively correlated with the behavioral advantage provided by the presence of the avatar, relative to unprimed perspective changes. These data suggest a link between the tendency to vicariously experience the others’ emotions and the ability to perform self–other spatial transformations. © 2015, Springer-Verlag Berlin Heidelberg.;2015;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;2091-2102;NA;7;233;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2U7C6CEK;journalArticle;2015;"Jackson, P.L.; Michon, P.-E.; Geslin, E.; Carignan, M.; Beaudoin, D.";EEVEE: The Empathy-Enhancing Virtual Evolving Environment;Frontiers in Human Neuroscience;NA;NA;10.3389/fnhum.2015.00112;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933673349&doi=10.3389%2ffnhum.2015.00112&partnerID=40&md5=c41939d6689a9860f5a08ac3f7ec4c58;"Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar’s behavior to the observer’s neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar’s face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders. © 2015 Jackson, Michon, Geslin, Carignan and Beaudoin.";2015;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;NA;NA;MAR;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 14</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BBJRPXJF;journalArticle;2015;"Tisseron, S.; Tordo, F.; Baddoura, R.";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;International Journal of Social Robotics;NA;NA;10.1007/s12369-014-0268-5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924301513&doi=10.1007%2fs12369-014-0268-5&partnerID=40&md5=ae9ddda552ec58f57dc89db088c53239;The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. © 2014, Springer Science+Business Media Dordrecht.;2015;2021-02-15T22:37:41Z;2021-02-15T22:37:41Z;NA;97-102;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BBBHY7BP;journalArticle;2015;"Patel, H.; MacDorman, K.F.";Sending an avatar to do a human’s job: Compliance with authority persists despite the uncanny valley;Presence: Teleoperators and Virtual Environments;NA;NA;10.1162/PRES_a_00212;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929302303&doi=10.1162%2fPRES_a_00212&partnerID=40&md5=19d56358034d04dcd1491d273a47bb96;Just as physical appearance affects social influence in human communication, it may also affect the processing of advice conveyed through avatars, computer-animated characters, and other human-like interfaces. Although the most persuasive computer interfaces are often the most human-like, they have been predicted to incur the greatest risk of falling into the uncanny valley, the loss of empathy attributed to characters that appear eerily human. Previous studies compared interfaces on the left side of the uncanny valley, namely, those with low human likeness. To examine interfaces with higher human realism, a between-groups factorial experiment was conducted through the internet with 426 midwestern U.S. undergraduates. This experiment presented a hypothetical ethical dilemma followed by the advice of an authority figure. The authority was manipulated in three ways: depiction (digitally recorded or computer animated), motion quality (smooth or jerky), and advice (disclose or refrain from disclosing sensitive information). Of these, only the advice changed opinion about the ethical dilemma, even though the animated depiction was significantly eerier than the human depiction. These results indicate that compliance with an authority persists even when using an uncannily realistic computeranimated double. © 2015 by the Massachusetts Institute of Technology.;2015;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;1-23;NA;1;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 7</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
WHPBJSLG;conferencePaper;2014;"Sejima, Y.; Watanabe, T.; Jindai, M.";Development of an interaction-activated communication model based on a heat conduction equation in voice communication;Proceedings - IEEE International Workshop on Robot and Human Interactive Communication;NA;NA;10.1109/ROMAN.2014.6926356;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937538530&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=91ef1fc789e5cfd5dd2329481e79a23e;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication. © 2014 IEEE.;2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;832-837;NA;NA;2014-October;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: October;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
TCR63WRQ;journalArticle;2014;Kumar, A.;Satyamev Jayate: Return of the star as a sacrificial figure;South Asia: Journal of South Asia Studies;NA;NA;10.1080/00856401.2014.906087;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903305515&doi=10.1080%2f00856401.2014.906087&partnerID=40&md5=8eeb748d4113326360347c7abe847f12;This paper attempts to make sense of Satyamev Jayate, a popular Indian television show hosted by film star Aamir Khan, in terms of its politics, Khan's stardom and the attempt to reframe the social on television. Grappling with the broad contours of the cultural economy of justice on national television in India, I suggest that the star descends upon television as an avatar promising empathy to a variety of victims of social injustice. In so doing, Khan converts crime news into emotional truths. The show has not only generated public debate, it also invites the public to return to a performative innocence. As television becomes the site of articulating moral authority, ritual participation and demanding social change, the political is re-assembled through Khan's stardom. The paper also enquires how and why the show compels narrative ingenuity towards what Aditya Nigam calls the implosion of the political-the erasure of the public from the street and its re-inscription in the studio. Equally notable here is the role film-stardom plays in rendering moral authority through the trope of the sacrificial. © 2014 South Asian Studies Association of Australia.;2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;239-254;NA;2;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
GSQ3FE3C;conferencePaper;2014;"Sejima, Y.; Watanabe, T.; Jindai, M.";Development of an interaction-Activated communication model based on a heat conduction equation in voice communication;IEEE RO-MAN 2014 - 23rd IEEE International Symposium on Robot and Human Interactive Communication: Human-Robot Co-Existence: Adaptive Interfaces and Systems for Daily Life, Therapy, Assistance and Socially Engaging Interactions;NA;NA;10.1109/ROMAN.2014.6926356;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937573084&doi=10.1109%2fROMAN.2014.6926356&partnerID=40&md5=22e427095e4bdb9f1b57facf7adeb784;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-Activated communication model based on the heat conduction equation in heat-Transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-Activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-Activated communication. © 2014 IEEE.;2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;832-837;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
P55TKQWR;journalArticle;2014;"Turkay, S.; Kinzer, C.K.";The effects of avatar: Based customization on player identification;International Journal of Gaming and Computer-Mediated Simulations;NA;NA;10.4018/ijgcms.2014010101;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919481767&doi=10.4018%2fijgcms.2014010101&partnerID=40&md5=d1f48e10de40db92e9957d08a1cd57b9;Games allow players to perceive themselves in alternate ways in imagined worlds. Player identification is one of the outcomes of gameplay experiences in these worlds and has been shown to affect enjoyment and reduce self-discrepancy. Avatar-based customization has potential to impact player identification by shaping the relationship between the player and the character. This mixed method study aims to fill the gap in the identification literature by examining the effects of avatar-based customization on players' identification with and empathy towards their characters in a massively multiplayer online game, Lord of the Rings Online (LotRO). Participants (N = 66) played LotRO either in customization or in no-customization groups for about ten hours in four sessions over two weeks in a controlled lab setting. Data were collected through interviews, surveys and observations. Results showed both time and avatar-based customization positively impacted players' identification with their avatars. Self-Determination Theory is used to interpret results. Copyright © 2014, IGI Global.;2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;1-25;NA;1;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 22</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
T9PR6H5G;journalArticle;2014;"Thirioux, B.; Tandonnet, L.; Jaafari, N.; Berthoz, A.";Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia: A behavioural pilot-study using virtual reality technology;Brain and Cognition;NA;NA;10.1016/j.bandc.2014.06.006;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903940796&doi=10.1016%2fj.bandc.2014.06.006&partnerID=40&md5=d4a126273acdb3f6ce72c9bec2fd96f5;"Behavioural and neuroimaging data have recently pointed out that empathy (feeling into someone else) is associated with mental imagery and transformation related to one's and other's visuo-spatial perspectives. Impairments of both empathic and visuo-spatial abilities have been observed in patients with schizophrenia. Especially, it has been suggested that schizophrenics are altered in spontaneously simulating another individual's first-person experience. However, there is so far only little evidence regarding the relationship between deficits in empathy and disturbances in spontaneous heterocentered coding in schizophrenia. In the present pilot-study, we tested with schizophrenic patients our behavioural paradigm that enables to measure from the bodily postures and movements whether individuals in ecologically more valid conditions are interacting with another individual by using egocentered - as in sympathy (feeling with someone else) - or heterocentered - as in empathy - visuo-spatial mechanisms. For that, ten patients and ten controls, standing and moving, interacted with a virtual tightrope walker, displayed life-sized, standing and moving as well. We show that patients with higher negative symptoms had, in most cases, deficits in spontaneously using heterocentered visuo-spatial mechanisms and employed preferentially an egocentered referencing to interact with the avatar. In contrast, preserved spontaneous heterocentered visuo-spatial strategies were not linked to a prevailing negative or positive symptomatology. Our data suggest that the severity of the negative symptoms in schizophrenia relates with disturbances of spontaneous (""on-line"") empathic processing in association with lower scoring self-reported trait cognitive empathy. © 2014 Elsevier Inc.";2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;87-99;NA;NA;90;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 10</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VFJMYHEZ;journalArticle;2014;"Menzel, N.; Willson, L.H.; Doolen, J.";Effectiveness of a poverty simulation in second life®: Changing nursing student attitudes toward poor people;International Journal of Nursing Education Scholarship;NA;NA;10.1515/ijnes-2013-0076;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908608559&doi=10.1515%2fijnes-2013-0076&partnerID=40&md5=aa24ee301d7d65e4fc5c62935bf510cc;Social justice is a fundamental value of the nursing profession, challenging educators to instill this professional value when caring for the poor. This randomized controlled trial examined whether an interactive virtual poverty simulation created in Second Life® would improve nursing students' empathy with and attributions for people living in poverty, compared to a self-study module. We created a multi-user virtual environment populated with families and individual avatars that represented the demographics contributing to poverty and vulnerability. Participants (N = 51 baccalaureate nursing students) were randomly assigned to either Intervention or Control groups and completed the modified Attitudes toward Poverty Scale pre- and post-intervention. The 2.5-hour simulation was delivered three times over a 1-year period to students in successive community health nursing classes. The investigators conducted post-simulation debriefings following a script. While participants in the virtual poverty simulation developed significantly more favorable attitudes on five questions than the Control group, the total scores did not differ significantly. Whereas students readily learned how to navigate inside Second Life®, faculty facilitators required periodic coaching and guidance to be competent. While poverty simulations, whether virtual or face-to-face, have some ability to transform nursing student attitudes, faculty must incorporate social justice concepts throughout the curriculum to produce lasting change. © 2014, Walter de Gruyter GmbH. All rights reserved.;2014;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;NA;NA;1;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 31</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Y5MRXAJB;conferencePaper;2013;"Plant, N.; Healey, P.G.T.";Surface Tension;Conference on Human Factors in Computing Systems - Proceedings;NA;NA;10.1145/2468356.2479589;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040727714&doi=10.1145%2f2468356.2479589&partnerID=40&md5=9a87b07b1b9698f79ac1c66418476b1c;"The human body has a privileged place in explanations of how emotions are communicated. Tangible human bodies, it is hoped, can provide a conceptual and empirical bridge sufficient to convey intangible human experiences; a hope shared by technologies such as avatars and embodied robots. Surface tension explores this idea by testing the boundary between the embodied and disembodied expression of pain. The installation uses motion-capture data of people describing personal experiences of pain. Their original gestural movements are extracted and translated into mechanical gesticulations that stretch and trace forms onto the surface of a canvas; mapping the twists, turns, contractions and accelerations of fingers and hands articulating an experience of pain. We manipulate the parameters of the original motions to ask in what ways can a disembodied translation of a human description of pain evoke recognition or empathy in the viewer?.";2013;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;2979-2982;NA;NA;2013-April;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
8C99KSHR;journalArticle;2013;Sieg, K.;Wii are family: Performing Race in Neo-liberal Europe;Theatre Research International;NA;NA;10.1017/S030788331200096X;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878179286&doi=10.1017%2fS030788331200096X&partnerID=40&md5=2eb54b155cd8b567b6d69b17270600be;This article examines the flash mob dance Glow by the Afro-Norwegian duo Madcon, which was performed at the Eurovision Song Contest in Oslo, Norway, in 2010. The dance was modelled on the format of popular Wii dance games, and coordinated black and white dancers, families, mass publics and prerecorded and live footage in order to choreograph European 'unity in diversity'. The use of black dancers as avatars urging dancing crowds towards greater kinaesthetic sensitivity raises the questions of how race is figured in neo-liberal visions of cosmopolitan Europe, and what role gaming technology plays in facilitating cross-racial empathy and ethical responsiveness at a time when solidarity is fraying as a consequence of fiscal crises and austerity measures. Finally, the article considers Afro-European academic, activist and artistic practices as alternatives to neo-liberal regimes of race. © 2013 International Federation for Theatre Research.;2013;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;20-33;NA;1;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 3</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
BRGPEDAP;journalArticle;2013;"Bouchard, S.; Bernier, F.; Boivin, E.; Dumoulin, S.; Laforest, M.; Guitard, T.; Robillard, G.; Monthuy-Blanc, J.; Renaud, P.";Empathy toward virtual humans depicting a known or unknown person expressing pain;Cyberpsychology, Behavior, and Social Networking;NA;NA;10.1089/cyber.2012.1571;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872559512&doi=10.1089%2fcyber.2012.1571&partnerID=40&md5=842f525f29c1000eca7ba5c4b9140ddd;This study is about pain expressed by virtual humans and empathy in users immersed in virtual reality. It focuses on whether people feel more empathy toward the pain of a virtual human when the virtual human is a realistic representation of a known individual, as opposed to an unknown person, and if social presence is related to users' empathy toward a virtual human's pain. The 42 participants were immersed in virtual reality using a large immersive cube with images retro projected on all six faces (CAVE-Like system) where they can interact in real time with virtual characters. The first immersion (baseline/control) was with a virtual animal, followed by immersions involving discussions with a known virtual human (i.e., the avatar of a person they were familiar with) or an unknown virtual human. During the verbal exchanges in virtual reality, the virtual humans expressed acute and very strong pain. The pain reactions were identical in terms of facial expressions, and verbal and nonverbal behaviors. The Conditions by Time interactions in the repeated measures analyses of variance revealed that participants were empathic toward both virtual humans, yet more empathic toward the known virtual human. Multivariate regression analyses revealed that participants' feeling of social presence - impression that the known virtual character is really there, with them - was a significant predictor of empathy. © Mary Ann Liebert, Inc.;2013;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;61-71;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 29</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7E9JNJEI;journalArticle;2012;"Chen, G.-D.; Lee, J.-H.; Wang, C.-Y.; Chao, P.-Y.; Li, L.-Y.; Lee, T.-Y.";An empathic avatar in a computer-aided learning program to encourage and persuade learners;Educational Technology and Society;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871544623&partnerID=40&md5=abcec5093589166e553e4712fd8692f0;"Animated pedagogical agents with characteristics such as facial expressions, gestures, and human emotions, under an interactive user interface are attractive to students and have high potential to promote students' learning. This study proposes a convenient method to add an embodied empathic avatar into a computer-aided learning program; learners express their emotions by mouse-clicking while reading, and the avatar motivates them accordingly. This study designs empathic responses for avatars to encourage and persuade learners to make greater reading effort. This experiment examines emotional recognition, empathy transformation, and the effect of virtual human encouragement and persuasion. Subjects identify facial expressions of the avatar, especially those expressing positive facial emotions. Compared to the contrast group, the empathic avatar increases learners' willingness to continue reading and complete exercises. © International Forum of Educational Technology & Society (IFETS).";2012;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;62-72;NA;2;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 25</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
IRFDZ97R;conferencePaper;2012;"Karanian, B.A.; Eskandari, M.; Aggarwal, A.; Pincheira, F.; Krauthamer, R.R.; Kress, G.";Open process for entrepreneuring team collaboration: Parallels from an academic research team to the start up they studied;ASEE Annual Conference and Exposition, Conference Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029108723&partnerID=40&md5=d2304a42bf841bae627ab8aa9e09b813;"Increasingly, student entrepreneurial ventures begin as emotional connections, artistic experiences, and expectations for delivering on research teams. This paper explores student team progress and responses to roadblocks while helping a maturing Silicon Valley start-up IMVU consider the role of avatars, creative expression and social interaction in the virtual world. Our goal was to seek a deep understanding of why users choose to spend their time and money to take part in the online community IMVU all the while creating a productive entrepreneurial team atmosphere. This paper explores the unique dynamics of the research team during the evolving investigation and delivery phase, all the while simultaneously examining the underlying emotions and motives of participants in one virtual community. We start with the belief that every new research team is like a start-up company and there are commonalities or differences between the student academic research environment and the company's organizational culture. Our collaborative research team includes members from areas of engineering, design, psychology, and communication. In this paper, we intend to correlate the factors that make the design team effective, utilize the findings to guide new student teams, and facilitate progress across the stages of the project. Two factors set the stage for insights on entrepreneuring: 1) evolving research team dynamics, and 2) the need-finding interactions with users both inside and outside the industry environment studied (IMVU). Surprising discoveries include a strong gender imbalance in the community as well as users reporting that online ""was basically real life."" A palette of stories abstractly parallels the student design team to the start-up they studied. Concepts include: self motivated, ambiguity readiness level, passion, and empathy. The team leader knowingly discussed using an open-process approach. Members noted a considerable lack of reluctance to prototype methods and team presentations; they also reported a deliberate lack of specific planning that they believe contributed to an entertaining and productive team ambiance. The full experiment offers stunning stories and compelling implications for creating effective design interventions in team-based engineering and design classes as well as for those pursuing the stories of compassion, empathy, and transformation in entrepreneuring. © 2012 American Society for Engineering Education.";2012;2021-02-15T22:37:42Z;2021-02-15T22:37:42Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
G4373CAG;conferencePaper;2011;"Cheong, W.L.; Jung, Y.; Theng, Y.-L.";Avatar: A virtual face for the elderly;Proceedings of VRCAI 2011: ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications to Industry;NA;NA;10.1145/2087756.2087850;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856420993&doi=10.1145%2f2087756.2087850&partnerID=40&md5=1916f7bd55a0b5287eb6d86efa07d939;Studies in the field of human-computer interaction have demonstrated a significant impact of avatars and virtual environments on users' interaction experiences and behaviors. However, most of these studies are focused on the young users. With an aging population and more virtual environments built for the elderly, it is important to investigate the types of avatars elderly users prefer and hence provide them with a richer interaction experience through the use of avatars as virtual representations of themselves. In our exploratory study, 24 seniors aged 55 years and above evaluated 20 custom-created avatars. Results showed that the elderly participants were unable to identify with the avatars. However, the results showed a strong trust towards child avatars and an attraction towards animal and object avatars, which indicates a different form of identification or empathy. The paper concludes with discussion of avatar design for the elderly users. © 2011 ACM.;2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;491-498;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
X45FVRM9;journalArticle;2011;"Guadagno, R.E.; Swinth, K.R.; Blascovich, J.";Social evaluations of embodied agents and avatars;Computers in Human Behavior;NA;NA;10.1016/j.chb.2011.07.017;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052786398&doi=10.1016%2fj.chb.2011.07.017&partnerID=40&md5=52e853ef8a284bb0887a3e85bc716b0d;"The purpose of this study was to examine social evaluations (i.e.; perceptions of empathy and positivity) following peoples' interactions with digital human representations. Female research participants engaged in a 3-min interaction while immersed in a 3-D immersive virtual environment with a ""peer counselor."" Participants were led to believe that the peer counselor was either an embodied agent (i.e.; computer algorithm) or an avatar (i.e.; another person). During the interaction, the peer counselor either smiled or not. As predicted, a digitally-rendered smile was found to affect participants' social evaluations. However, these effects were moderated by participants' beliefs about their interaction partner. Specifically, smiles enhanced social evaluations of embodied agents but degraded them for avatars. Although these results are consistent with other findings concerning the communicative realism of embodied agents and avatars they uniquely demonstrate that people's beliefs alone, rather than actual differences in virtual representations, can impact social evaluations. © 2011 Elsevier Ltd. All rights reserved.";2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;2380-2385;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 38</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
JME3KRWZ;journalArticle;2011;Jin, S.A.;My avatar behaves well and this feels right: Ideal and ought selves in video gaming;Social Behavior and Personality;NA;NA;10.2224/sbp.2011.39.9.1175;https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053987515&doi=10.2224%2fsbp.2011.39.9.1175&partnerID=40&md5=7b29b274723a8275cc2f3d2f34c20ac6;Prosocial and violent games were investigated in relation to empathy with avatars and amount of postgame donation. Participants who played a prosocial game demonstrated greater empathy, while those who played a violent game said they would donate a greater amount of money. Flow was found to be a function of the 3-way interaction between game type, self-perception, and regulatory focus. Higgins's (1987) regulatory focus and self-discrepancy (1997) theories are used to explain the underlying theoretical mechanisms behind these results. © Society for Personality Research.;2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;1175-1182;NA;9;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 12</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
N6BYK9RS;journalArticle;2011;Taylor, L.D.;Avatars and emotional engagement in asynchronous online communication;Cyberpsychology, Behavior, and Social Networking;NA;NA;10.1089/cyber.2010.0083;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79954618670&doi=10.1089%2fcyber.2010.0083&partnerID=40&md5=d37170855b520268ab7aae81c8286a05;The notion that an avatar can elicit a sense of emotional involvement or connection on the part of a user in asynchronous online communication was explored through a pair of content analyses of a popular online question-and-answer bulletin board. In the first study, questions accompanied by an avatar not only received more answers than questions without an avatar, but the answers were more likely to be characterized by expressions of empathy. In the second study, a preference for answering questions accompanied by an avatar was found to be associated with interpersonal, altruistic motives for answering questions. Results are discussed in terms of presence and alternative explanations, as well as practical implications. © Copyright 2010, Mary Ann Liebert, Inc.;2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;207-212;NA;4;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 19</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
PVNPCF85;conferencePaper;2011;"Kress, G.; Getz-Kikuchi, R.; Price, T.; Karanian, B.; Nass, C.";Designing for social participation in the virtual universe;ASEE Annual Conference and Exposition, Conference Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029027110&partnerID=40&md5=1e06cdd5854e6e819c535957b7109374;"Increasingly, our emotional connections, artistic experiences and playful escapes are migrating to the virtual world. Virtual environments and online communities are growing and becoming more commonplace in society; for many, they are already a primary means of social interaction. This experiment is a preliminary investigation into the underlying emotional motivation behind participants in the IMVU virtual universe. We seek a deep understanding of why these users choose to spend their time and money to take part in creating this online community. Our collaborative research team includes members from the areas of engineering, design, psychology and communication. Our need-finding interactions with users both inside and out of the IMVU environment have given us insight into the role of avatars, creative expression and social interaction in the virtual world. We assess how users manipulate their social identity and exercise their influence to achieve personal fulfillment online. The full experiment offers compelling implications for creating effective design interventions in team-based engineering and design classes, particularly those involving distributed collaboration, as well as for those pursuing compassion, empathy and social change by design. © 2011 American Society for Engineering Education.";2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
ARGNVVZY;conferencePaper;2011;"Szczesna, A.; Grudzinski, T.; Grudzinski, J.";Settings goals in psychology serious game for preschool children;Proceedings of the European Conference on Games-based Learning;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862487569&partnerID=40&md5=b715e8e0d0b4f3b2b1d58ef29f134efa;The term serious game is generally used for an application that is developed using a computer game technology and game design principles but is used for non-entertainment purposes. We can say that these applications are entertaining games with non-entertainment goals. The idea is that games could be used for more serious purposes such as education, simulating real world phenomenon and relations in the world, increasing life quality through health, rehabilitation and therapy applications or raising interest in the problems in our global world. This paper focuses on psychology serious games. Generally, in psychology games users are represented by their avatar and can interact with the world and other game characters. Like in storytelling or bibliotherapy, the story itself has a therapeutic component so much as it evokes identification, empathy, resistance, opposition and disclosure of many confusing emotions. This goal oriented gaming can be used in goal oriented therapy methods. The game is played according to a scenario where the user can observe and react to different situations. This acts as a powerful tool for helping users understand and reflect on their own behavior and gives them the opportunity to learn from this virtual experience. The next stage is testing the user's new abilities with new situations by applying different games goals. The innovative use of computer in the form of psychotherapeutic games may enhance patient cooperation. This can also help to attract and sustain the interest especially in children. This paper describes the main features of serious games used in psychology based on the prototype of the game Mission - Master Your Fear. This is a serious game based on a specialist scenario founded on bibliotherapy with some therapeutic goals. It deals with issues and problems of preschool children. The result is an interesting and absorbing game for children which may help them solve some problems.;2011;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;567-572;NA;NA;2011-January;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SF4JHSC4;journalArticle;2010;Tordo, F.;Desire of intersubjectivity in the video game: Between virtual auto-empathy and real interpersonal relations [Désir d'intersubjectivité dans les jeux vidéo: Entre auto-empathie virtuelle et relations interpersonnelles réelles];Psychotropes;NA;NA;10.3917/psyt.163.0179;https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951938920&doi=10.3917%2fpsyt.163.0179&partnerID=40&md5=c80ca5831e247cd3eed6c49450204800;Abstract: While it is routinely said that the body disappears in the video game for the sole benefit of sensory stimulations, the avatar, on the contrary, appears as a vehicle of action which engages the player's own corporeity. This action-motricity, which simulates the system of representation of action, is engaged in a process of virtual auto-empathy through corporal sensations felt by the player. A real intersubjective traffic between the characters-players is added, in the persistent worlds, where the virtual other is an already-existing. The dependent or excessive player would be the one to whom the intersubjective desire no longer succeed in going towards another player, preferring sensori-motor interactions, in a progressive indifferentiation of types of virtual objects.;2010;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;179-191;NA;3-4;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
D7ZJA949;conferencePaper;2010;"Van Looy, J.; Courtois, C.; De Vocht, M.";Player identification in online games: Validation of a scale for measuring identification in MMORPGs;ACM International Conference Proceeding Series;NA;NA;10.1145/1823818.1823832;https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249285281&doi=10.1145%2f1823818.1823832&partnerID=40&md5=cf2581b9b9b6c40e31605f68c8d4b973;In this paper, we present a Player Identification (PI) scale for measuring identification in MMORPGs. Three main dimensions were derived from the literature (1) Avatar (character) Identification, (2) Group (guild) Identification and (3) Game (community) Identification whereby Avatar Identification is a second-order factor consisting of (1a) Perceived Similarity, (1b) Wishful Identification and (1c) Embodied Presence. Based on the results of a cross-sectional survey of 544 World of Warcraft players the measurement instrument's proposed factorial structure was confirmed. Subsequently, the constructs were successfully tested both for convergent and discriminant validity. Finally, evidence for nomological validity was gathered by testing ten theoretically rooted hypotheses regarding the effects of Player Identification. The results showed that Avatar Identification positively predicts Empathy, Proteus effect and the motivations role-play, customization and escapism. Group Identification predicts socializing and relationship, and Game Identification predicts advancement, mechanics and escapism. © 2010 ACM.;2010;2021-02-15T22:37:43Z;2021-02-15T22:37:43Z;NA;126-134;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 16</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
B4QH6SKB;journalArticle;2020;Gramantieri, R.;Alexithymic personality in Philip K. Dick’s Do androids dream of electric sheep?;Neohelicon;NA;NA;10.1007/s11059-020-00544-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745112&doi=10.1007%2fs11059-020-00544-z&partnerID=40&md5=d7ae68506033a119722c578a57aa02bd;"The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients’ comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novel Do androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commenting Do androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick. © 2020, Akadémiai Kiadó, Budapest, Hungary.";2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;673-683;NA;2;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
VAEZK4JJ;journalArticle;2020;"Sarkadi; Casmana, A.R.; Cahyana, U.; Paristiowati, M.";The Application of Mobile Learning for University Students in the Pancasila Education Modul in Developing Character of Students' Empathy;Universal Journal of Educational Research;NA;NA;10.13189/ujer.2020.080905;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090322563&doi=10.13189%2fujer.2020.080905&partnerID=40&md5=6b590515ca55be0e70b759af8a00a634;The main purpose of this study is to improve students’ empathy attitudes in Pancasila education courses using applications in mobile phones. It is a tool application or media that is used by educators to be able to transfer knowledge to their students. This is used to be able to increase the interaction and learning motivation of students, so they can obtain maximum learning resources. The name of the application is Pancasila Mobile learning, and it is available on Playstore for Android users and web-based page. Meanwhile, the empathy characters need to be developed by the school to be able to grow in students. As such, this study focuses on growing empathy by using mobile learning applications. The research method used is quantitative. The data collection technique used was an online questionnaire, which was filled by 119 students at universities in Jakarta. They are students who have already or are studying Pancasila in college. The results of this study indicate that the use of mobile learning applications in learning Pancasila in the classroom can increase empathy attitudes towards students. They can carry out positive activities, and feel pleasure and comfort when using mobile learning applications in the learning process. Thus, the use of mobile learning needs to be continuously developed by educators both in universities and schools. Copyright ©2020 by authors, all rights reserved.;2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;3825-3833;NA;9;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
2ZZTSIZL;journalArticle;2020;"de Kervenoael, R.; Hasan, R.; Schwob, A.; Goh, E.";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;Tourism Management;NA;NA;10.1016/j.tourman.2019.104042;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075628508&doi=10.1016%2fj.tourman.2019.104042&partnerID=40&md5=f56ef158af2d44659553121590311519;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies. © 2019 Elsevier Ltd;2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 18</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
4EMJDEU3;journalArticle;2020;"Bae, B.-C.; Kim, H.-J.";A cooperative storytelling card game for conflict resolution and empathy;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-030-50164-8_27;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088745007&doi=10.1007%2f978-3-030-50164-8_27&partnerID=40&md5=fcbbebb6f3c1f3a09c94bdbf6d0e5ece;In this paper we present a prototype for a cooperative storytelling card game focusing on the resolution of conflict and empathy in a narrative. The story-making process in the proposed prototype design is based on Maslow’s hierarchy of needs, and consists of five types of story cards(characters, setting, objects/actions, goals, and emotions) as its story elements. We have developed and tested a prototype game using Unity3D game engine on an Android platform with two play modes - single-player and multi-player. In the multi-player mode, three players can play together: each player is assigned the role of an initiator, a conflictor and a mediator in wireless network environments. Our ultimate goal is to encourage players to empathize with other players by letting them create and resolve (or mediate) emotional conflicts through the process of perspective-taking in a collaborative storytelling game. © Springer Nature Switzerland AG 2020.;2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;375-384;NA;NA;12211 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
7QVM78JY;journalArticle;2020;Księżopolska, I.;Can Androids Write Science Fiction? Ian McEwan’s Machines like Me;Critique - Studies in Contemporary Fiction;NA;NA;10.1080/00111619.2020.1851165;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096586219&doi=10.1080%2f00111619.2020.1851165&partnerID=40&md5=f654e96e86eeb1f62ef29028328451ef;McEwan’s novel Machines Like Me was met with lukewarm reviews and open hostility of the sci-fi genre adherents. It seemed to have appropriated some of the key issues of the genre discourse–the question of what constitutes humanity, of the possibility of coexistence between humans and AI, of the problems of morality and consent. It also made use of time-honored devices of alternative history without treating it too seriously. Instead, the characters are enmeshed in personal problems and conundrums of science and politics, justice and empathy–and love. McEwan’s commentary on the novel in various interviews only aggravated the critics who were all too ready to conclude that Machines Like Me offered little originality. This essay will demonstrate that the text is carefully layered as if to protect its own novelty hidden beneath rather conventional love triangle plot, ponderous political commentary, and genre-specific topicality. It will be an effort to understand the complex relation between the writer and conventions which come into play in his novel, and it will proceed to read the text against the authorial comments, finding suppressed hints that invite an interpretation of the text as narrated by its android hero rather than human subject. © 2020 Taylor & Francis Group, LLC.;2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
T3SVBIB7;journalArticle;2020;"Sulistiadi, W.; Nurhidayah, S.; Asyary, Al";Evaluating the management information system of integrated medical emergency care in batang regency, Indonesia;International journal of online and biomedical engineering;NA;NA;10.3991/ijoe.v16i07.14725;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089019653&doi=10.3991%2fijoe.v16i07.14725&partnerID=40&md5=30a783d732c6318be26f5be2d426c911;An emergency can happen anywhere and anytime, especially in developing countries with a high potential for emergencies, such as Eastern European countries as well as Indonesia. This study aimed to find out the quality of PSC 119 Si Slamet as a prehospital emergency service innovation. The data collection in this study was carried out in a location, namely, Batang Regency, Indonesia, in May-June 2018. The qualitative data collection methods used in this study are in-depth interviews and document reviews. This study was using Service Quality (Servqual) questionnaire. The results show that PSC 119 Si Slamet provides easy access to emergency services to the community 24 hours a day and 7 days a week by simply calling 119 numbers, sending messages via SMS and WhatsApp, or using the Android-based application, with a maximum response time target of 10 minutes. Batang is one of the regencies (rural area) in Central Java province, located on the main coastline, with a hilly geographic condition with many derivatives, climbs, and sharp curves, which is one of the causes of the high number of traffic accidents in the area. This emergency care information systems, with Android-based application, was aimed at improving the quality of services in the health sector, especially emergency services. This service is of good quality as seen from the tangible, reliability, responsiveness, assurance, and empathy dimensions. However, in the implementation, the socialization aspect is not the best to some people. The recommendation given was the need to increase the PSC 119 socialization of Si Slamet not only regionally but also internationally to be massive, especially in developing countries. © 2020 Kassel University Press GmbH.;2020;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;75-85;NA;7;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
57DBHV9H;conferencePaper;2019;"Anurrasyid, A.; Sumitra, I.D.";Elementary School Learning Media Application Based on Android with Customer Satisfaction Index Method;IOP Conference Series: Materials Science and Engineering;NA;NA;10.1088/1757-899X/662/2/022017;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075879846&doi=10.1088%2f1757-899X%2f662%2f2%2f022017&partnerID=40&md5=7074184abbf3181463f02f03011d2907;The objective of this research is to understand customer satisfaction, which is an assessment of a product or service that aims to improve the quality and service of a product or services. In this study the measurement method used is the Customer Satisfaction Index (CSI) method. This method is used to determine how much the level of user satisfaction with learning media applications. The result shows that the calculation of the level of customer satisfaction based on Tangibles, Reliability, Responsiveness, Assurance, and Empathy. The percentage value obtained is based on these five attributes using the Likert Scale, which is a scale of 1-5. Based on the results of the research conducted, the satisfaction of use in the application shows the criteria of satisfaction. This calculation is useful to find out the quality of this learning application. By knowing the value of satisfaction, it can be concluded that this application can help the learning process of children, however this application still not forgetting some suggestions from respondents to evaluate and improve the application to be even better. © Published under licence by IOP Publishing Ltd.;2019;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;NA;NA;NA;662;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Issue: 2;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HZDA87VN;journalArticle;2018;"Shukla, S.; Sharma, P.";Emotions and Media Multitasking Behaviour among Indian College Students;Journal of Creative Communications;NA;NA;10.1177/0973258618790794;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053427916&doi=10.1177%2f0973258618790794&partnerID=40&md5=aa44bb6595f8efc8632f378247c70b8e;Media multitasking, a simultaneous consumption of two or more media, is a ubiquitous and popular behaviour among the youth. One of the reasons for its increasing growth is the structural/market-level factors (known as media factors). Although India is a growing technology hub, there have been limited efforts to identify the media multitasking behaviour among the youth in this country. Thus, this study attempts to analyse the prevalence of media multitasking behaviour among the Indian college students and its relationship with their emotions through two methods: self-report and an android-based application known as ‘Affective Media Landscape Survey’ (AMLS). Previous studies have reported that continuous interaction with media diminishes face-to-face interaction, reduces empathy and increases the tendency to live in the virtual world. This raises the concern for emotional differences in everyday life, if any, between the high and low groups of media multitaskers. So the second objective of the study is to understand the emotional profile of the users that varies among media multitasking index. To achieve these objectives, the same two methods, the ‘self-report’ that involves questionnaires and AMLS (an android-based app to study the frequency of media multitasking behaviour and the emotions of the users) have been employed. The study gives an insight into the emerging behavioural patterns and hence is helpful for designing communities to cater to the growing needs of the young media users. © 2018 Mudra Institute of Communications, Ahmedabad, India.;2018;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;197-211;NA;3;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6D8SADTT;conferencePaper;2018;Brueckner, S.;Empathy amulet: A wearable to connect with strangers;Proceedings - International Symposium on Wearable Computers, ISWC;NA;NA;10.1145/3267242.3267301;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056848773&doi=10.1145%2f3267242.3267301&partnerID=40&md5=348865050bbc443fed58ea7b8b213996;The Empathy Amulet is a wearable interpretation of Philip K. Dick’s empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both hap-tically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today’s world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson’s theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4]. Copyright © 2018 ACM.;2018;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;248-253;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
Z59QC259;conferencePaper;2018;"Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri";Effectiveness of Android-Based Mobile Robots for Children Asperger Syndrome;Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care;NA;NA;10.1109/ICAITI.2018.8686759;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753069&doi=10.1109%2fICAITI.2018.8686759&partnerID=40&md5=af11f585df846db5c051b6434459ed42;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially. © 2018 IEEE.;2018;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;208-212;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
T8CTZ2XD;journalArticle;2018;"Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.";Towards empathetic human-robot interactions;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;NA;10.1007/978-3-319-75487-1_14;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.;2018;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;173-193;NA;NA;9624 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
SJQK5Y67;journalArticle;2017;"Chikaraishi, T.; Yoshikawa, Y.; Ogawa, K.; Hirata, O.; Ishiguro, H.";"Creation and staging of android theatre ""Sayonara"" towards developing highly human-like robots";Future Internet;NA;NA;10.3390/fi9040075;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040790411&doi=10.3390%2ffi9040075&partnerID=40&md5=7741ec53279dea95f8e1cde8863ea639;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world. © 2016 by the authors.;2017;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QPU9QRNQ;journalArticle;2017;Lawrence, D.;More human than human;Cambridge Quarterly of Healthcare Ethics;NA;NA;10.1017/S0963180116001158;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019997561&doi=10.1017%2fS0963180116001158&partnerID=40&md5=e3142c138b00fcf2ae2397005a02231c;"Within the literature surrounding nonhuman animals on the one hand and cognitively disabled humans on the other, there is much discussion of where beings that do not satisfy the criteria for personhood fit in our moral deliberations. In the future, we may face a different but related problem: That we might create (or cause the creation of) beings that not only satisfy but exceed these criteria. The question becomes whether these are minimal criteria, or hierarchical, such that those who fulfill them to greater degree should be afforded greater consideration. This article questions the validity and necessity of drawing divisions among beings that satisfy the minimum requirements for personhood; considering how future beings - intelligent androids, synthezoids, even alternate-substrate sentiences - might fit alongside the baseline human. I ask whether these alternate beings ought to be considered different to us, and why this may or may not matter in terms of a notion of human community. The film Blade Runner, concerned in large part with humanity and its key synthezoid antagonist Roy Batty, forms a framing touchstone for my discussion. Batty is stronger, faster, more resilient, and more intelligent than Homo sapiens. His exploits, far beyond the capability of normal humans, are contrasted with his frailty and transient lifespan, his aesthetic appreciation of the sights he has seen, and his burgeoning empathy. Not for nothing does his creator within the mythos term him more human than human. © Cambridge University Press 2017.";2017;2021-02-15T22:37:59Z;2021-02-15T22:37:59Z;NA;476-490;NA;3;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
QGTADHWF;conferencePaper;2016;"Ranieri, C.M.; Romero, R.A.F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;Proceedings - 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016;NA;NA;10.1109/LARS-SBR.2016.13;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010416838&doi=10.1109%2fLARS-SBR.2016.13&partnerID=40&md5=48a1a71aed354854f322eb1a82dcc7eb;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness. © 2016 IEEE.;2016;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 4</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
6BZXGJ3J;journalArticle;2016;"Lawson, L.; Cane, S.";Do conservators dream of electric sheep? Replicas and replication;Studies in Conservation;NA;NA;10.1080/00393630.2016.1181348;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988329847&doi=10.1080%2f00393630.2016.1181348&partnerID=40&md5=10144d954aca38ab318f4ec5ae973e82;"The paper crosses the boundaries between different genres, drawing on key material and emphasising the philosophical challenges around decision-making and values in relation to replication and replicas. In 1968, Philip K. Dick wrote the book Do Androids Dream of Electric Sheep? which became the inspiration for the 1982 film Bladerunner. The book is set in Los Angeles in a post-apocalyptic future where mankind has left Earth, resulting in androids being created to develop new ‘off-world’ colonies. The book and film create a novel and interesting framework to discuss the subject of replicas and replication within contemporary conservation practice. Key themes are decay promoting replication, original versus replica, creating empathy in replication. The debate focuses on the case study of Naum Gabo's Construction in Space (Crystal) of 1937–39; which was the sculpture replicated in the most recent replication project at Tate, completed in July 2015. © 2016, © The International Institute for Conservation of Historic and Artistic Works 2016.";2016;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;109-113;NA;NA;61;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 2</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
E655LYMW;journalArticle;2016;"Sorbello, R.; Chella, A.; Giardina, M.; Nishio, S.; Ishiguro, H.";An architecture for Telenoid robot as empathic conversational android companion for elderly people;Advances in Intelligent Systems and Computing;NA;NA;10.1007/978-3-319-08338-4_68;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974382&doi=10.1007%2f978-3-319-08338-4_68&partnerID=40&md5=284d20453f0caff779f01dbae2648464;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user. © Springer International Publishing Switzerland 2016.;2016;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;939-953;NA;NA;302;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 6</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
3M6C8YWF;journalArticle;2014;"Hofree, G.; Ruvolo, P.; Bartlett, M.S.; Winkielman, P.";Bridging the mechanical and the human mind: Spontaneous mimicry of a physically present android;PLoS ONE;NA;NA;10.1371/journal.pone.0099934;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904490592&doi=10.1371%2fjournal.pone.0099934&partnerID=40&md5=160e9e9b43fd8eecd3d04c3cb2e090d0;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users. © 2014 Hofree et al.";2014;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;NA;NA;7;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 25</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
XN29U9FY;journalArticle;2013;Toth, J.;Do androids eat electric sheep?: Egotism, empathy, and the ethics of eating in the work of Philip K. Dick;LIT Literature Interpretation Theory;NA;NA;10.1080/10436928.2013.754238;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876399832&doi=10.1080%2f10436928.2013.754238&partnerID=40&md5=bc0b2f2e0d0e89b48fbe1f5b48dd00dc;NA;2013;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;65-85;NA;1;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
UJU54EF6;journalArticle;2013;"Urgen, B.A.; Plank, M.; Ishiguro, H.; Poizner, H.; Saygin, A.P.";EEG theta and Mu oscillations during perception of human and robot actions;Frontiers in Neurorobotics;NA;NA;10.3389/fnbot.2013.00019;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899682291&doi=10.3389%2ffnbot.2013.00019&partnerID=40&md5=b4aae2154c5beca9ef9fffd9bde2d77a;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin. © 2013 Urgen, Plank, Ishiguro, Poizner and Saygin.;2013;2021-02-15T22:38:00Z;2021-02-15T22:38:00Z;NA;NA;NA;NOV;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>cited By 34</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Scopus
HKYF75L6;journalArticle;NA;"Bilewicz, Michal; Tempska, Patrycja; Leliwa, Gniewosz; Dowgiallo, Maria; Tanska, Michalina; Urbaniak, Rafal; Wroczynski, Michal";Artificial intelligence against hate: Intervention reducing verbal aggression in the social network environment;Aggressive Behavior;NA;0096-140X;10.1002/ab.21948;NA;This article presents a quasi-experimental intervention study designed to reduce the level of verbal aggression on a social networking service (Reddit). The interventions were based on three psychological mechanisms: induction of a descriptive norm, induction of a prescriptive norm, and empathy induction. Each intervention was generated using a communicating bot. Participants exposed to these interventions were compared with a control group that received no intervention. The bot-generated normative communications (both the ones priming descriptive and the ones priming prescriptive norms), as well as the empathizing intervention, reduced the proportion of verbal aggression posted by Reddit accounts. All three interventions proved effective in reducing verbal violence when compared with the control condition.;NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;Aggressive Behav.;Artificial intelligence against hate;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley WOS:000608715600001;NA;NA;NA;NA;"artificial intelligence; social media; empathy; hate speech; verbal   aggression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IWREVEGH;journalArticle;NA;"Yun, Jin Ho; Lee, Eun-Ju; Kim, Dong Hyun";Behavioral and neural evidence on consumer responses to human doctors and medical artificial intelligence;Psychology & Marketing;NA;0742-6046;10.1002/mar.21445;NA;Will consumers accept artificial intelligence (AI) as a medical care provider? On the basis of evolution theory, we investigate the implicit psychological mechanisms that underlie consumers' interactions with medical AI and a human doctor. In a behavioral investigation (Study 1), consumers expressed a positive intention to use medical AI's healthcare services when it used personalized rather than mechanical conversation. However, neural investigation (Study 2) using functional magnetic resonance imaging revealed that some consumers' implicit attitudes toward medical AI differed from their expressed behavioral intentions. The brain areas linked with implicitly apathetic emotions were activated even when medical AI used a personalized conversation, whereas consumers' brains were activated in areas associated with prosociality when they interacted with a human doctor who used a personalized conversation. On the basis of our neural evidence, consumers perceive an identical personalized conversation differently when it is offered by a medical AI versus a human doctor. These findings have implications for the area of human-AI interactions and medical decision-making and suggest that replacing human doctors with medical AI is still an unrealistic proposition.;NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;Psychol. Mark.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley WOS:000605686100001;NA;NA;NA;NA;"fMRI; artificial intelligence; evolution; pain; robots; empathy; personalization; metaanalysis; algorithms; apathy; consumer neuroscience; dehumanization; medical   decision-making; mind perception; neuroscience; prosocial behavior; prosociality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YBC8PRFM;journalArticle;NA;"Gunkel, David J.; Wales, Jordan Joseph";Debate: what is personhood in the age of AI?;Ai & Society;NA;0951-5666;10.1007/s00146-020-01129-1;NA;"In a friendly interdisciplinary debate, we interrogate from several vantage points the question of ""personhood"" in light of contemporary and near-future forms of social AI. David J. Gunkel approaches the matter from a philosophical and legal standpoint, while Jordan Wales offers reflections theological and psychological. Attending to metaphysical, moral, social, and legal understandings of personhood, we ask about the position of apparently personal artificial intelligences in our society and individual lives. Re-examining the ""person"" and questioning prominent construals of that category, we hope to open new views upon urgent and much-discussed questions that, quite soon, may confront us in our daily lives.";NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;AI Soc.;Debate;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Springer WOS:000604563700002;NA;NA;NA;NA;"Ethics; Artificial intelligence; robots; empathy; Robots; Law; Personhood";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4QASPL3M;journalArticle;2021;Irfan, Farhana;Artificial Intelligence: Help or Hindrance for Family Physicians?;Pakistan Journal of Medical Sciences;NA;1682-024X;10.12669/pjms.37.1.3351;NA;"The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician's new assistant; AI-physician combinations can act like models of 'peaceful co-existence'. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician's diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients' frustration.";2021-02;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;288-291;NA;1;37;NA;Pak. J. Med. Sci.;Artificial Intelligence;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Saddar Publisher: Professional Medical Publications WOS:000605441900053;NA;C:\Users\esben\Zotero\storage\ZWDBVWHL\Irfan - 2021 - Artificial Intelligence Help or Hindrance for Fam.pdf;NA;NA;"Machine learning; Artificial Intelligence; Family Physicians; management";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YZUIDRVS;journalArticle;2021;"Alrassi, James; Katsufrakis, Peter J.; Chandran, Latha";Technology Can Augment, but Not Replace, Critical Human Skills Needed for Patient Care;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000003733;NA;"The practice of medicine is changing rapidly as a consequence of electronic health record adoption, new technologies for patient care, disruptive innovations that breakdown professional hierarchies, and evolving societal norms. Collectively, these have resulted in the modification of the physician's role as the gatekeeper for health care, increased shift-based care, and amplified interprofessional team-based care. Technological innovations present opportunities as well as challenges. Artificial intelligence, which has great potential, has already transformed some tasks, particularly those involving image interpretation. Ubiquitous access to information via the Internet by physicians and patients alike presents benefits as well as drawbacks: patients and providers have ready access to virtually all of human knowledge, but some websites are contaminated with misinformation and many people have difficulty differentiating between solid, evidence-based data and untruths. The role of the future physician will shift as complexity in health care increases and as artificial intelligence and other technologies advance. These technological advances demand new skills of physicians; memory and knowledge accumulation will diminish in importance while information management skills will become more important. In parallel, medical educators must enhance their teaching and assessment of critical human skills (e.g., clear communication, empathy) in the delivery of patient care. The authors emphasize the enduring role of critical human skills in safe and effective patient care even as medical practice is increasingly guided by artificial intelligence and related technology, and they suggest new and longitudinal ways of assessing essential noncognitive skills to meet the demands of the future. The authors envision practical and achievable benefits accruing to patients and providers if practitioners leverage technological advancements to facilitate the development of their critical human skills.";2021-01;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;37-43;NA;1;96;NA;Acad. Med.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Philadelphia Publisher: Lippincott Williams & Wilkins WOS:000603460500032;NA;NA;NA;NA;"evidence-based medicine; information literacy; students; time";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
893WFAWI;journalArticle;NA;"Erden, Yasemin J.; Hummerstone, Harriet; Rainey, Stephen";Automating autism assessment: What AI can bring to the diagnostic process;Journal of Evaluation in Clinical Practice;NA;1356-1294;10.1111/jep.13527;NA;This paper examines the use of artificial intelligence (AI) for the diagnosis of autism spectrum disorder (ASD, hereafter autism). In so doing we examine some problems in existing diagnostic processes and criteria, including issues of bias and interpretation, and on concepts like the 'double empathy problem'. We then consider how novel applications of AI might contribute to these contexts. We're focussed specifically on adult diagnostic procedures as childhood diagnosis is already well covered in the literature.;NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;J. Eval. Clin. Pract.;Automating autism assessment;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley WOS:000599290600001;NA;C:\Users\esben\Zotero\storage\9IQELYR4\Erden et al. - Automating autism assessment What AI can bring to.pdf;NA;NA;"artificial intelligence; autism; diagnosis; adults; artificial-intelligence; differential-diagnosis; spectrum disorder";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VDY7YNX5;journalArticle;2020;"Kocaballi, A. Baki; Ijaz, Kiran; Laranjo, Liliana; Quiroz, Juan C.; Rezazadegan, Dana; Tong, Huong Ly; Willcock, Simon; Berkovsky, Shlomo; Coiera, Enrico";Envisioning an artificial intelligence documentation assistant for future primary care consultations: A co-design study with general practitioners;Journal of the American Medical Informatics Association;NA;1067-5027;10.1093/jamia/ocaa131;NA;Objective: The study sought to understand the potential roles of a future artificial intelligence (AI) documentation assistant in primary care consultations and to identify implications for doctors, patients, healthcare system, and technology design from the perspective of general practitioners. Materials and Methods: Co-design workshops with general practitioners were conducted. The workshops focused on (1) understanding the current consultation context and identifying existing problems, (2) ideating future solutions to these problems, and (3) discussing future roles for Al in primary care. The workshop activities included affinity diagramming, brainwriting, and video prototyping methods. The workshops were audio-recorded and transcribed verbatim. Inductive thematic analysis of the transcripts of conversations was performed. Results: Two researchers facilitated 3 co-design workshops with 16 general practitioners. Three main themes emerged: professional autonomy, human-AI collaboration, and new models of care. Major implications identified within these themes included (1) concerns with medico-legal aspects arising from constant recording and accessibility of full consultation records, (2) future consultations taking place out of the exam rooms in a distributed system involving empowered patients, (3) human conversation and empathy remaining the core tasks of doctors in any future AI-enabled consultations, and (4) questioning the current focus of AI initiatives on improved efficiency as opposed to patient care. Conclusions: AI documentation assistants will likely to be integral to the future primary care consultations. However, these technologies will still need to be supervised by a human until strong evidence for reliable autonomous performance is available. Therefore, different human-AI collaboration models will need to be designed and evaluated to ensure patient safety, quality of care, doctor safety, and doctor autonomy.;2020-11;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;1695-1704;NA;11;27;NA;J. Am. Med. Inf. Assoc.;Envisioning an artificial intelligence documentation assistant for future primary care consultations;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Oxford Publisher: Oxford Univ Press WOS:000594986600008;NA;C:\Users\esben\Zotero\storage\Z29MHI9J\Kocaballi et al. - 2020 - Envisioning an artificial intelligence documentati.pdf;NA;NA;"artificial intelligence; health; aim; classification; doctor-patient communication; general practitioners; medical informatics; perceptions; primary health care; qualitative study; triple";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TKHNELLL;journalArticle;2020;"Van, Nguyen Thi Thanh; Vrana, Vasiliki; Duy, Nguyen Thien; Minh, Doan Xuan Huy; Dzung, Pham Tien; Mondal, Subhra R.; Das, Subhankar";The Role of Human-Machine Interactive Devices for Post-COVID-19 Innovative Sustainable Tourism in Ho Chi Minh City, Vietnam;Sustainability;NA;NA;10.3390/su12229523;NA;In this research article, we aim to study the proposed role of human-machine interactive (HMI) technologies, including both artificial intelligence (AI) and virtual reality (VR)-enabled applications, for the post-COVID-19 revival of the already depleted tourism industry in Vietnam's major tourist destination and business hub of Ho Chi Minh City. The researchers aim to gather practical knowledge regarding tourists' intentions for such service enhancements, which may drive the sector to adopt a better conclusive growth pattern in post-COVID-19 times. In this study, we attempt to focus on travelers who look for paramount safety with the assurance of empathetic, personalized care in post-COVID-19 times. In the current study, the authors employ structural equation modeling to evaluate the intentions of tourists both structurally and empirically for destination tourism with data collected from tourists with previous exposure to various kinds of these devices. The study shows that human-machine interactive devices are integrating AI and VR and have a significant effect on overall service quality, leading to tourist satisfaction and loyalty. The use of such social interactive gadgets within tourism and mostly in hospitality services requires an organization to make a commitment to futuristic technologies, along with building value by enriching service quality expectations among fearful tourists. This research shows that tourists mainly focus on the use of such HMI devices from the perspective of technology acceptance factors, qualitative value-enhancing service and trustworthy information-sharing mechanisms. The concept of the tour bubble framework is also discussed in detail. The analysis of this discussion gives us a more profound understanding of the novel opportunities which various administrative agencies may benefit from to position these devices better in smart, sustainable destination tourism strategies for the future so that, collectively, service 5.0 with HMI devices can possibly bring back tourism from being disintegrated. Such service applications are the new social innovations leading to sustainable service and a sophisticated experience for all tourists.;2020-11;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;9523;NA;22;12;NA;Sustainability;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Basel Publisher: Mdpi WOS:000594619200001;NA;C:\Users\esben\Zotero\storage\QERHBKY9\Van et al. - 2020 - The Role of Human-Machine Interactive Devices for .pdf;NA;NA;"robots; empathy; 0 and 5; AI and VR devices; covid-19; experience; hospitality; information-technology; perceived value; reality; revival of tourism; robots in tourism; service; service 5; technology acceptance model; tour bubble; tourist interest; user acceptance; Web 4";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HFS6867E;journalArticle;2020;"Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;Digital Health;NA;2055-2076;10.1177/2055207620968355;NA;"Background The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective This study aimed to explore psychiatrists' opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (""comments"") to three open-ended questions in the survey. Results Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that 'man and machine' would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions This study presents timely information on psychiatrists' views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020-10;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;2055207620968355;NA;NA;6;NA;Digit. Health;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: London Publisher: Sage Publications Ltd WOS:000590416300001;NA;C:\Users\esben\Zotero\storage\DVB5SLYK\Blease et al. - 2020 - Artificial intelligence and the future of psychiat.pdf;NA;NA;"anxiety; big data; Artificial intelligence; decision-making; depression; mental health; attitudes; future; opinions; psychiatry; qualitative research; technology; metaanalysis; framework; machine   learning; mental-health interventions; symptoms";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HNDFLYMK;journalArticle;2020;"Jenking, Julian; van der Poel, Sheryl; Kruessel, Jan; Bosch, Ernesto; Nelson, Scott M.; Pinborg, Anja; Yao, Mylene M. W.";Empathetic application of machine learning may address appropriate utilization of ART;Reproductive Biomedicine Online;NA;1472-6483;10.1016/jrbmo.2020.07.005.1472-6483;NA;"The value of artificial intelligence to benefit infertile patients is a subject of debate. This paper presents the experience of one aspect of artificial intelligence, machine learning, coupled with patient empathy to improve utilization of assisted reproductive technology (ART), which is an important aspect of care that is under-recognized. Although ART provides very effective options for infertile patients to build families, patients often discontinue ART when further treatment is likely to be beneficial and most of these patients do not achieve pregnancy without medical aid. Use of ART is only in part dependent on financial considerations; stress and other factors play a major role, as shown by high discontinuation rates despite reimbursement. This commentary discusses challenges and strategies to providing personalized ART prognostics based on machine learning, and presents a case study where appropriate use of such prognostics in ART centres is associated with a trend towards increased ART utilization.";2020-10;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;573-577;NA;4;41;NA;Reprod. Biomed. Online;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Oxford Publisher: Elsevier Sci Ltd WOS:000576601400002;NA;NA;NA;NA;"Artificial intelligence; ART utilization; IVF drop-outs; live birth; Machine   learning; Patient empathy; Prognostication; reproductive medicine";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EQ946ZWH;journalArticle;2020;"Sumitani, Mizuho; Osumi, Michihiro; Abe, Hiroaki; Azuma, Kenji; Tsuchida, Rikuhei; Sumitani, Masahiko";A Robot Has a Mind of Its Own Because We Intuitively Share It;Applied Sciences-Basel;NA;NA;10.3390/app10186531;NA;People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we 'share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent).;2020-09;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;6531;NA;18;10;NA;Appl. Sci.-Basel;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Basel Publisher: Mdpi WOS:000582015200001;NA;C:\Users\esben\Zotero\storage\65FZLPSP\Sumitani et al. - 2020 - A Robot Has a Mind of Its Own Because We Intuitive.pdf;NA;NA;"pain; empathy; facial expressions; affective mind; facial expression; others; robot (virtual agent)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IRK4JWUC;journalArticle;2020;"Ivkov, Milan; Blesic, Ivana; Dudic, Branislav; Bartakova, Gabriela Pajtinkova; Dudic, Zdenka";Are Future Professionals Willing to Implement Service Robots? Attitudes of Hospitality and Tourism Students towards Service Robotization;Electronics;NA;NA;10.3390/electronics9091442;NA;This paper aims to examine attitudes of hospitality and tourism students, as future professionals, towards willingness to implement service robots. The study proposes a new theoretical conceptual model that includes new constructs and items, differentiating it from the others. The model was formed based on the extensive literature review and the interview with an eight-member focus group (hotel managers and academic researchers). Data collection was performed in two stages, pilot research based on 82 respondents and the main study, with the final number of respondents being 236. The initial results of the exploratory factor analysis were further tested using the confirmatory factor analysis. After the exclusion of several items due to low factor loadings and in order to improve model validity, analyses further suggested a nine-dimensional solution with 45 items. The study findings reveal a positive relationship between seven constructs and students' willingness to implement service robots, with the expected business outcome being the most influencing one. On the other hand, positive relation was not found for empathy and social influence constructs. Theoretical contributions and practical implications are discussed in the paper. In conclusion, study limitations and future research suggestions are provided.;2020-09;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;1442;NA;9;9;NA;Electronics;Are Future Professionals Willing to Implement Service Robots?;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Basel Publisher: Mdpi WOS:000581269900001;NA;C:\Users\esben\Zotero\storage\3ADJAAIL\Ivkov et al. - 2020 - Are Future Professionals Willing to Implement Serv.pdf;NA;NA;"decision-making; model; behavior; students; artificial-intelligence; hospitality; information-technology; user acceptance; adoption; challenges; consumers; extension; service robots; tourism; willingness to implement service robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9LHNFZ9G;journalArticle;2020;"Chiang, Ai-Hsuan; Trimi, Silvana";Impacts of service robots on service quality;Service Business;NA;1862-8516;10.1007/s11628-020-00423-8;NA;With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers' top priorities for robots' service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots' responsiveness, but this construct was found to be a low priority.;2020-09;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;439-459;NA;3;14;NA;Serv. Bus.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Heidelberg Publisher: Springer Heidelberg WOS:000557116400001;NA;C:\Users\esben\Zotero\storage\2KBI6UJG\Chiang and Trimi - 2020 - Impacts of service robots on service quality.pdf;NA;NA;"evolution; Artificial intelligence; model; future; capabilities; determinants; diversity; firm; Importance-performance analysis; intelligence; performance; satisfaction; Service quality; Service robot; topsis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6U4AU3AH;journalArticle;2020;Novak, Thomas P.;A Generalized Framework for Moral Dilemmas Involving Autonomous Vehicles: A Commentary on Gill;Journal of Consumer Research;NA;0093-5301;10.1093/jcr/ucaa024;NA;By using scenarios based on moral dilemmas, Gill (2020) found that when consumers are riding in an autonomous vehicle (AV), they are more willing to harm a pedestrian than when they, themselves, are driving a regular car. By taking a first-person perspective, in contrast to most prior research that has taken a third-person perspective, the problem is framed in a personal way that allows identification of a mechanism of responsibility attribution. In this commentary, a generalized framework is developed in which we can locate the work of Gill (2020), as well as prior research that uses moral dilemmas, to understand how consumers believe that AVs should respond when faced with competing life-and-death alternatives. The framework shows the distinct positions that research to date has adopted, points out gaps in research, and suggests a family of four research agendas that can be pursued going forward, driven in large part by the perspective taken to the moral dilemma. Research employing these different perspectives, including the unresearched problem of taking the perspective of the object, holds promise for using moral dilemmas for enabling our understanding of consumer experience and consumer-object relationships with AVs.;2020-08;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;292-300;NA;2;47;NA;J. Consum. Res.;A Generalized Framework for Moral Dilemmas Involving Autonomous Vehicles;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Cary Publisher: Oxford Univ Press Inc WOS:000579083400008;NA;NA;NA;NA;"artificial intelligence; self; empathy; consumer; consumer-object relationships; internet; life; moral dilemmas; object experience; perspective-taking; things; trolley; trolley problem";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5KB562QX;journalArticle;2020;"Labash, Aqeel; Aru, Jaan; Matiisen, Tambet; Tampuu, Ardi; Vicente, Raul";Perspective Taking in Deep Reinforcement Learning Agents;Frontiers in Computational Neuroscience;NA;NA;10.3389/fncom.2020.00069;NA;Perspective taking is the ability to take into account what the other agent knows. This skill is not unique to humans as it is also displayed by other animals like chimpanzees. It is an essential ability for social interactions, including efficient cooperation, competition, and communication. Here we present our progress toward building artificial agents with such abilities. We implemented a perspective taking task inspired by experiments done with chimpanzees. We show that agents controlled by artificial neural networks can learn via reinforcement learning to pass simple tests that require some aspects of perspective taking capabilities. We studied whether this ability is more readily learned by agents with information encoded in allocentric or egocentric form for both their visual perception and motor actions. We believe that, in the long run, building artificial agents with perspective taking ability can help us develop artificial intelligence that is more human-like and easier to communicate with.;2020-07-23;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;69;NA;NA;14;NA;Front. Comput. Neurosci.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Lausanne Publisher: Frontiers Media Sa WOS:000560280300001;NA;C:\Users\esben\Zotero\storage\54W6NBWU\Labash et al. - 2020 - Perspective Taking in Deep Reinforcement Learning .pdf;NA;NA;"artificial intelligence; empathy; deep reinforcement learning; individual-differences; memory; multi-agent; perspective taking; theory of mind";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MEN5WAHB;journalArticle;2020;"Pepito, Joseph Andrew; Ito, Hirokazu; Betriana, Feni; Tanioka, Tetsuya; Locsin, Rozzano C.";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations;Nursing Philosophy;NA;1466-7681;10.1111/nup.12318;NA;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.";2020-10;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;e12318;NA;4;21;NA;Nurs. Philos.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley WOS:000550452400001;NA;NA;NA;NA;"emotion; affective developmental robotics; artificial   intelligence; artificial empathy; care; humanoid nurse robots; intelligent humanoid robots; nursing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RJ558FQ5;journalArticle;NA;Ostherr, Kirsten;Artificial Intelligence and Medical Humanities;Journal of Medical Humanities;NA;1041-3545;10.1007/s10912-020-09636-4;NA;"The use of artificial intelligence in healthcare has led to debates about the role of human clinicians in the increasingly technological contexts of medicine. Some researchers have argued that AI will augment the capacities of physicians and increase their availability to provide empathy and other uniquely human forms of care to their patients. The human vulnerabilities experienced in the healthcare context raise the stakes of new technologies such as AI, and the human dimensions of AI in healthcare have particular significance for research in the humanities. This article explains four key areas of concern relating to AI and the role that medical/health humanities research can play in addressing them: definition and regulation of ""medical"" versus ""health"" data and apps; social determinants of health; narrative medicine; and technological mediation of care. Issues include data privacy and trust, flawed datasets and algorithmic bias, racial discrimination, and the rhetoric of humanism and disability. Through a discussion of potential humanities contributions to these emerging intersections with AI, this article will suggest future scholarly directions for the field.";NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;J. Med. Humanit.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Springer WOS:000547351600001;NA;C:\Users\esben\Zotero\storage\Y39NHGYH\Ostherr - Artificial Intelligence and Medical Humanities.pdf;NA;NA;"big data; Natural language processing; future; Big data; datafication; design; Digital health; disability; era; Health technology; health-care; Narrative medicine; perceived discrimination; race; Social   determinants of health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
B7K9ZN8I;journalArticle;2020;"Goldberg, Simon B.; Flemotomos, Nikolaos; Martinez, Victor R.; Tanana, Michael J.; Kuo, Patty B.; Pace, Brian T.; Villatte, Jennifer L.; Georgiou, Panayiotis G.; Van Epps, Jake; Imel, Zac E.; Narayanan, Shrikanth S.; Atkins, David C.";Machine Learning and Natural Language Processing in Psychotherapy Research: Alliance as Example Use Case;Journal of Counseling Psychology;NA;0022-0167;10.1037/cou0000382;NA;Artificial intelligence generally and machine learning specifically have become deeply woven into the lives and technologies of modern life. Machine learning is dramatically changing scientific research and industry and may also hold promise for addressing limitations encountered in mental health care and psychotherapy. The current paper introduces machine learning and natural language processing as related methodologies that may prove valuable for automating the assessment of meaningful aspects of treatment. Prediction of therapeutic alliance from session recordings is used as a case in point. Recordings from 1,235 sessions of 386 clients seen by 40 therapists at a university counseling center were processed using automatic speech recognition software. Machine learning algorithms learned associations between client ratings of therapeutic alliance exclusively from session linguistic content. Using a portion of the data to train the model, machine learning algorithms modestly predicted alliance ratings from session content in an independent test set (Spearman's rho =15, p <.001). These results highlight the potential to harness natural language processing and machine learning to predict a key psychotherapy process variable that is relatively distal from linguistic content. Six practical suggestions for conducting psychotherapy research using machine learning are presented along with several directions for future research. Questions of dissemination and implementation may be particularly important to explore as machine learning improves in its ability to automate assessment of psychotherapy process and outcome.;2020-07;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;438-448;NA;4;67;NA;J. Couns. Psychol.;Machine Learning and Natural Language Processing in Psychotherapy Research;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Washington Publisher: Amer Psychological Assoc WOS:000546625200003;NA;NA;NA;NA;"machine learning; big data; depression; technology; artificial   intelligence; client; improvement; mental-health; methodology; natural language processing; of-the-art; therapeutic alliance; therapist empathy; validation; working alliance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FEH4Y7Q3;journalArticle;2020;"Polap, Dawid; Kesik, Karolina; Winnicka, Alicja; Wozniak, Marcin";Strengthening the perception of the virtual worlds in a virtual reality environment;Isa Transactions;NA;0019-0578;10.1016/j.isatra.2020.02.023;NA;Virtual reality is becoming more and more improved primarily due to numerous applications and the powers of mobile devices. Using various sensors, precise displays and high computing powers smartphone are becoming devices that make the boost in technology. Now it is necessary to efficiently use various sensors without affecting system operation and improve control abilities for various purposes. Especially in practical applications received by mass users such as games and any kind of experience. In this article, we propose a system that allows to extend the perception of the virtual world by conveying information about the user's movements in reality into the supervised model. The system retrieves data from several sources, quickly analyzes them using artificial intelligence techniques, and returns information to the mobile phone about the activity that is being processed. The concept extends the understanding of today's virtual reality by allowing the user to move and perform simple gestures in a specially designed room. Moreover, we propose multiplayer mode in virtual reality, where players are in different places. The proposed architecture of the system has been tested on simple applications, and the results show high potential for implementations in various apps by achieving almost 90% efficiency in changing player direction in real time and only 7.5% of collision cases. (C) 2020 ISA. Published by Elsevier Ltd. All rights reserved.;2020-07;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;397-406;NA;NA;102;NA;ISA Trans.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Elsevier Science Inc WOS:000540721100033;NA;NA;NA;NA;"Virtual reality; Image processing; empathy; Convolutional neural network; game; Mobile games; Player behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
APU6LLTT;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots;Tourism Management;NA;0261-5177;10.1016/j.tourman.2019.104042;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;104042;NA;NA;78;NA;Tourism Manage.;Leveraging human-robot interaction in hospitality services;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Oxford Publisher: Elsevier Sci Ltd WOS:000514750800008;NA;NA;NA;NA;"Artificial intelligence; gender; engagement; Human-robot interaction; Hospitality services; Intention to use robots; Social robots; future; health; perceptions; experience; reality; technology acceptance model; tourism; satisfaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EAA6YDQW;journalArticle;NA;Andreotta, Adam J.;The hard problem of AI rights;Ai & Society;NA;0951-5666;10.1007/s00146-020-00997-x;NA;In the past few years, the subject of AI rights-the thesis that AIs, robots, and other artefacts (hereafter, simply 'AIs') ought to be included in the sphere of moral concern-has started to receive serious attention from scholars. In this paper, I argue that the AI rights research program is beset by an epistemic problem that threatens to impede its progress-namely, a lack of a solution to the 'Hard Problem' of consciousness: the problem of explaining why certain brain states give rise to experience. To motivate this claim, I consider three ways in which to ground AI rights-namely: superintelligence, empathy, and a capacity for consciousness. I argue that appeals to superintelligence and empathy are problematic, and that consciousness should be our central focus, as in the case of animal rights. However, I also argue that AI rights is disanalogous from animal rights in an important respect: animal rights can proceed without a solution to the 'Hard Problem' of consciousness. Not so with AI rights, I argue. There we cannot make the same kinds of assumptions that we do about animal consciousness, since we still do not understand why brain states give rise to conscious mental states in humans.;NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;AI Soc.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Springer WOS:000536422900003;NA;C:\Users\esben\Zotero\storage\FTCTTH4Z\Andreotta - The hard problem of AI rights.pdf;NA;NA;"Ethics; Artificial intelligence; AI rights; Animals rights; The 'hard   problem' of consciousness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ULSJDYV5;journalArticle;2020;Wenk, H.;Communication in the age of artificial intelligence;Gefasschirurgie;NA;0948-7034;10.1007/s00772-020-00644-1;NA;Communication is essential in vascular medicine. Medicine without communication is unthinkable. The computerization of medical devices and the increasing application of artificial intelligence adds new aspects to communication between humans and humans, machines and machines as well as between humans and machines. Against the background of formalization of communication, empathy when dealing with patients, physicians and other professional groups in medicine is necessary in order to guarantee and optimize the success of treatment.;2020-09;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;339-344;NA;5;25;NA;Gefasschirurgie;NA;NA;NA;NA;NA;NA;NA;German;NA;NA;NA;NA;Web of Science;NA;Place: Heidelberg Publisher: Springer Heidelberg WOS:000532090700002;NA;NA;NA;NA;"Machine learning; Empathy; Computer; Physician-Patient-Relations; Vascular medicine";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
H9W49T7A;journalArticle;NA;Johnson, James;Delegating strategic decision-making to machines: Dr. Strangelove Redux?;Journal of Strategic Studies;NA;0140-2390;10.1080/01402390.2020.1759038;NA;Will the use of artificial intelligence (AI) in strategic decision-making be stabilizing or destabilizing? What are the risks and trade-offs of pre-delegating military force (or automating escalation) to machines? How might non-nuclear state and non-state actors leverage AI to put pressure on nuclear states? This article analyzes the impact of strategic stability of the use of AI in the strategic decision-making process, in particular, the risks and trade-offs of pre-delegating military force (or automating escalation) to machines. It argues that AI-enabled decision support tools, by substituting the role of human critical thinking, empathy, creativity, and intuition in the strategic decision-making process, will be fundamentally destabilizing if defense planners come to view AI's 'support' function as a panacea for the cognitive fallibilities and human analysis and decision-making. The article also considers the nefarious use of AI-enhanced fake news, deepfakes, bots, and other forms of social media by non-state actors and state proxy actors, which might cause states to exaggerate a threat from ambiguous or manipulated information, increasing instability.;NA;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;J. Strateg. Stud.;Delegating strategic decision-making to machines;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Abingdon Publisher: Routledge Journals, Taylor & Francis Ltd WOS:000532600800001;NA;NA;NA;NA;"Artificial intelligence; artificial-intelligence; -China relations; command; deterrence policy; emerging technology; nuclear security; s; stability; strategic stability; u";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
F9IH99NU;journalArticle;2020;"Liao, Jing; Hansen, Preben; Chai, Chunlei";A framework of artificial intelligence augmented design support;Human-Computer Interaction;NA;0737-0024;10.1080/07370024.2020.1733576;NA;"Recent advances in Artificial Intelligence raise interest in its participation in design activity, which is commonly considered to be complex and human-dominated. In this work, we aim to examine AI roles in early design stages. The human ideation components and design tools related to AI are discussed in a framework of AI-augmented design support. The framework develops a hierarchy of design cognition (basis), approaches and principles. The cognitive models are constructed in an empirical study of 30 designers (26 for analysis, 4 for pilot study) by concurrent Think-Aloud protocol and behavior analysis. The process of producing new design ideas is explained by a transparent analysis of designers' language and behaviors. Three strategies to organize cognitive activities in design ideation are summarized: develop structured consideration, relate to a scenario, and stick-to designing. These strategies suggest AI could act as (1) representation creation, (2) empathy trigger and (3) engagement, in principles of ""knowledge-driven"" and ""decompose-and-integrate"". The design support with AI provides new perspectives on computer-based design tools that limit to well-defined design variables. The framework is built on a generic notion of design activity and ""mimic"" human design rationales, expected to benefit research of domain-independent computational design supports and cognitive supports.";2020-11-01;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;511-544;NA;5-6;35;NA;Hum.-Comput. Interact.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Philadelphia Publisher: Taylor & Francis Inc WOS:000532117600001;NA;NA;NA;NA;"evolution; empathy; design supports; Human computer interaction theory; artificial   intelligence; analogy; creative design; engineering design; fixation; knowledge representation; stimuli; tools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X4L5EAZ3;journalArticle;2020;Schmetkamp, Susanne;Understanding AI - Can and Should we Empathize with Robots?;Review of Philosophy and Psychology;NA;1878-5158;10.1007/s13164-020-00473-x;NA;Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding.;2020-12;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;881-897;NA;4;11;NA;Rev. Philos. Psychol.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Dordrecht Publisher: Springer WOS:000529458800001;NA;NA;NA;NA;"perception; Ethics; Artificial intelligence; Empathy; Fictional characters; Humanoid robots; hypothesis; Interaction; Perspective-taking";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
G46GZE3V;journalArticle;2020;Kerasidou, Angeliki;Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare;Bulletin of the World Health Organization;NA;0042-9686;10.2471/BLT.19.237198;NA;Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote.;2020-04;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;245-250;NA;4;98;NA;Bull. World Health Organ.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Geneva 27 Publisher: World Health Organization WOS:000523183600017;NA;C:\Users\esben\Zotero\storage\UZEQFCYW\Kerasidou - 2020 - Artificial intelligence and the ongoing need for e.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8PNZCQGE;journalArticle;2020;Nadin, Mihai;Aiming AI at a moving target: health (or disease);Ai & Society;NA;0951-5666;10.1007/s00146-020-00943-x;NA;"Justified by spectacular achievements facilitated through applied deep learning methodology (based on neural networks), the ""Everything is possible"" view dominates this new hour in the ""boom and bust"" curve of AI performance. The optimistic view collides head on with the ""It is not possible""-ascertainments often originating in a skewed understanding of both AI and medicine. The meaning of the conflicting views can be assessed only by addressing the nature of medicine. Specifically: Which part of medicine, if any, can and should be entrusted to AI-now or at some moment in the future? AI or not, medicine should incorporate the anticipation perspective in providing care.";2020-12;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;841-849;NA;4;35;NA;AI Soc.;Aiming AI at a moving target;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Springer WOS:000562497900001;NA;NA;NA;NA;"Data; Artificial intelligence; empathy; Anticipation; Deep medicine; Meaning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GQ7KZZ23;journalArticle;2020;"Rehman, Faisal; Munawar, Adeel; Iftikhar, Aqsa; Hassan, Jawad; Samiullah, Fouzia; Gilani, Muhammad Basit Ali; Qasim, Awais; Qasim, Neelam";Design and Development of AI-based Mirror Neurons Agent towards Emotion and Empathy;International Journal of Advanced Computer Science and Applications;NA;2158-107X;NA;NA;Since numerous years, researchers have to outline keen operators to accomplish the Artificial General Intelligence. Each new science revelation is an open challenge to all researchers. More than twenty years prior to a group of researchers discovered exceptional cerebrum cells, called reflect neurons in monkeys. These cells gave off an impression of being actuated both when the monkey accomplished something itself and when the monkey basically watched another monkey do a similar thing. This new discovery opened a new door for a scientist because of Mirror Neurons functionalities that can be huge contribute to cognitive science, neuroscience, impacting on Artificial General Intelligence. Mirror neuron functionality improves the Machine's learning. This research paper develops models for social interaction in which a machine may have the ability to learn the next person emotional state using mirror neurons and show empathy towards emotions.;2020-03;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;386-395;NA;3;11;NA;Int. J. Adv. Comput. Sci. Appl.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: West Yorkshire Publisher: Science & Information Sai Organization Ltd WOS:000524029200049;NA;NA;NA;NA;"perception; artificial intelligence; machine learning; emotions; pain; empathy; experience; imitation; Mirror neurons functionalities; system";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7T967FDS;journalArticle;2020;"Srivastava, Tripti K.; Waghmare, Lalitbhushan";Implications of Artificial Intelligence (Al) on Dynamics of Medical Education and Care: A Perspective ocr;Journal of Clinical and Diagnostic Research;NA;2249-782X;10.7860/JCDR/2020/4329.3.13565;NA;"Artificial Intelligence (Al) applies to the development of systems endowed with the intellectual processes characteristic of humans. The Al era is likely to profoundly impact present system of Health care. Large data storing, processing and its interpretation through Electronic Medical records (EMRs) indicate great potential benefit to health services. Devices are likely to outperform humans, more so cognitively; and coming to terms with this fact require physicians to brace themselves to practice in a technologically enhanced environment. In near future, Al is likely to take a central place in health care with everything revolving round its mechanics. The era of Al envisages new roles of a physician and health professionals should realise the importance of being efficient in interacting with these machines in an efficient manner. Patient psychology and empathy shall take a central place in patient care and budding doctors should be braced with such relevant competencies. Accordingly, Al needs to find a suitable place within the curriculum of medical education that deals with technology, interactive learning environments and managing Al systems. It is also imperative that medical teachers realise the potential of Al on health care and are suitably equipped to train these emerging concepts to future doctors.";2020-03;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;3;14;NA;J. Clin. Diagn. Res.;Implications of Artificial Intelligence (Al) on Dynamics of Medical Education and Care;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Delhi Publisher: Premchand Shantidevi Research Foundation WOS:000520094700038;NA;NA;NA;NA;"computer; Electronic medical records; Health care; System";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8NDUN6FD;book;2020;"Nehra, Vanshika; Nagpal, Renuka; Sehgal, Rajni";Collective Intelligence: When, Where and Why;NA;978-1-72812-791-0;NA;NA;NA;"The term ""Collective"" is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms intact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.";2020;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;NA;Collective Intelligence;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;Pages: 805-810 Publication Title: Proceedings of the Confluence 2020: 10th International Conference on Cloud Computing, Data Science & Engineering WOS:000571173300140;NA;NA;NA;NA;"Artificial Intelligence; Collective Intelligence; Swami Intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5LX45BHQ;journalArticle;2020;Banerjee, Soumya;A Framework for Designing Compassionate and Ethical Artificial Intelligence and Artificial Consciousness;Interdisciplinary Description of Complex Systems;NA;1334-4684;10.7906/indecs.18.2.2;NA;Intelligence and consciousness have fascinated humanity for a long time and we have long sought to replicate this in machines. In this work, we show some design principles for a compassionate and conscious artificial intelligence. We present a computational framework for engineering intelligence, empathy, and consciousness in machines. We hope that this framework will allow us to better understand consciousness and design machines that are conscious and empathetic. Our hope is that this will also shift the discussion from fear of artificial intelligence towards designing machines that embed our cherished values. Consciousness, intelligence, and empathy would be worthy design goals that can be engineered in machines.;2020;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;85-95;NA;2;18;NA;Interdiscip. Descr. Complex Syst.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Patent Number: A Place: Sesvete Publisher: Croatian Interdisciplinary Soc WOS:000534556600002;NA;C:\Users\esben\Zotero\storage\WJRWTNT3\Banerjee - 2020 - A Framework for Designing Compassionate and Ethica.pdf;NA;NA;"artificial intelligence; empathy; artificial consciousness; engineering   intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IG6EZJSP;journalArticle;2020;Davis, Anthony E.;The Future of Law Firms (and Lawyers) in the Age of Artificial Intelligence;Revista Direito Gv;NA;1808-2432;10.1590/2317-6172201945;NA;"This article explores the future for lawyers and law firms in the light of the changes that Artificial Intelligence (""AI"") is already bringing to the universe of legal services. Part I briefly describes some of the ways AI is already in use in ordinary life - from facial recognition, through medical diagnosis to translation services. Part II describes how AI is transforming what it means to provide legal services in six primary areas: litigation review; expertise automation; legal research; contract analytics; contract and litigation document generation; and predictive analytics. Part III explores who are the providers of these AI driven legal services - often non-lawyer legal service providers - and how these providers are replacing at least some of what clients have traditionally sought from lawyers. Part III also discusses the implications of all these changes both for the future role of lawyers individually, and in particular what services will clients still need lawyers to perform: judgment, empathy, creativity and adaptability. In turn, this Part examines what will these changes mean for the size, shape, composition and economic model of law firms, as well as the implications of these changes for legal education and lawyer training. Part IV identifies the principal legal, ethical, regulatory and risk management issues raised by the use of AI in the provision of legal services. Finally, in Part V the article considers who will be the likely providers of AI based services other than law firms: legal publishers, major accounting firms and venture capital funded businesses.";2020;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;e1945;NA;1;16;NA;Rev. Direito GV;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Sao Paulo Sp Publisher: Fundacao Getulio Vargas, Escola Direito WOS:000527400100007;NA;C:\Users\esben\Zotero\storage\V8GJ94ID\Davis - 2020 - The Future of Law Firms (and Lawyers) in the Age o.pdf;NA;NA;"Artificial Intelligence (AI); Future of Legal Services; Law   Firms; Lawyers; Legal Service Providers";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FTTIXKRU;journalArticle;2020;"Lizeta, Bakola N.; Drigas, Athanasios S.";Technological Development Process of Emotional Intelligence as a Therapeutic Recovery Implement in Children with ADHD and ASD Comorbidity;International Journal of Online and Biomedical Engineering;NA;NA;10.3991/ijoe.v16i03.12877;NA;The perception, empathy, expression and regulation of emotion have been recognized as the determining factors to everyday communication and psychosocial adaptation in children. Deficits in them can cause emotional and social problems and affect everyday life. This paper aims at investigating by reviewing the current clinical and empirical knowledge of psychoemotional and social development as much as emotional intelligence in children diagnosed with Attention Deficit Hyperactivity Disorder (ADHD) and Autism Spectrum Disorder (ASD) coexistence looking into the emotion recognition deficits as well as processing, reciprocity and emotional expression deficits noticing and characterizing these children mostly. Moreover they are considering and being studied the technical means and the ways that they could help in the development and growing of social skills and emotional intelligence. The results proclaimed that the therapeutic contribution of Information and Communication Technologies (ICTs) can be determinant.;2020;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;75-85;NA;3;16;NA;Int. J. Online Biomed. Eng.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Wien Publisher: Int Assoc Online Engineering WOS:000521269500005;NA;C:\Users\esben\Zotero\storage\ZWG87ED7\Lizeta and Drigas - 2020 - Technological Development Process of Emotional Int.pdf;NA;NA;"artificial intelligence; robots; autism; ADHD and ASD comorbidity; attention deficit/hyperactivity disorder; emotional and social   development; Emotional intelligence; social interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y3H3PDLG;journalArticle;2020;"Vaucheret Paz, E.; Martino, M.; Hyland, M.; Corletto, M.; Puga, C.; Peralta, M.; Deltetto, N.; Kuhlmann, T.; Cavalie, D.; Leist, M.; Duarte, B.; Lascombes, I.";Sentiment Analysis in Children with Neurodevelopmental Disorders in an Ingroup/Outgroup Setting;Journal of Autism and Developmental Disorders;NA;0162-3257;10.1007/s10803-019-04242-3;NA;"People punish transgressors with different intensity depending if they are members of their group or not. We explore this in a cross-sectional analytical study with paired samples in children with developmental disorders who watched two videos and expressed their opinion. In Video-1, a football-player from the participant's country scores a goal with his hand. In Video-2, a player from another country does the same against the country of the participant. Each subject watched the two videos and their answers were compared. The autism spectrum disorder (ASD) group showed negative feelings in Video 1 (M = -.1; CI 95% -.51 to .31); and in Video 2 (M = -.43; CI 95%.77 to -.09; t(8) = 1.64, p = .13), but the attention deficit hyperactivity disorder, learning disabilities, intellectual disability groups showed positive opinion in Video-1 and negative in Video-2. This suggests that children with ASD respect rules regardless of whether those who break them belong or not to their own group, possibly due to lower degrees of empathy.";2020-01;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;162-170;NA;1;50;NA;J. Autism Dev. Disord.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Springer/Plenum Publishers WOS:000519271900001;NA;NA;NA;NA;"evolution; Empathy; empathy; 3rd-party punishment; altruism; Artificial   intelligence; costly punishment; favoritism; Morality; Neurodevelopmental disorders; scale; Social norms; Third-party punishment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7E3SRT4T;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;Artificial Intelligence in Medicine;NA;0933-3657;10.1016/j.artmed.2019.101753;NA;Background: Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective: To characterize the global psychiatrist community's opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design: Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures: We measured opinions about the likelihood that AI/ML tools would be able to fully replace - not just assist - the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist's perceptions about whether benefits of AI/ML would outweigh the risks. Results: Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions: Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020-01;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;101753;NA;NA;102;NA;Artif. Intell. Med.;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Amsterdam Publisher: Elsevier WOS:000514254100025;NA;C:\Users\esben\Zotero\storage\B8C9UYY9\Doraiswamy et al. - 2020 - Artificial intelligence and the future of psychiat.pdf;NA;NA;"Deep learning; Empathy; Autonomous agents; Mental health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Z358WDUH;journalArticle;2019;Bhalla, Navneet;The 3S Process: A Framework for Teaching AI Strategy in Business Education;Technology Innovation Management Review;NA;1927-0321;10.22215/timreview/1290;NA;"A gap has emerged in teaching artificial intelligence (AI) in business education, where a style of curriculum based on strategy is missing. This article presents a new framework, the 3S Process, as a method for teaching leaders how to strategically adopt AI within their organizations. At a high-level, the 3S Process consists of three stages (Story, Strategy, and Solution), which are described in detail in the article. Stage 1: Story in the process is inspired by the Harvard Case Method to provide context for a problem. Stage 2: Strategy uses Design Thinking to produce candidate solutions. The substage of Empathy in Design Thinking plays a crucial role to reduce bias in designing AI. Virtualization technology is a tool for students to experience hands-on learning in prototype development. Stage 3: Solution is where students advocate for their conceptual AI solution in the context of the case study. AI is a type of complex system; therefore, students should consider feedback loops and the potential for unintended biases to enter a deployed solution. The presentation of the 3S Process in this article is conceptual. Further empirical studies, including evaluations of the 3S Process in classroom settings, will be considered in the future.";2019-12;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;36-42;NA;12;9;NA;Technol. Innov. Manag. Rev.;The 3S Process;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Ottawa Publisher: Carleton Univ Graphic Services WOS:000505058600005;NA;NA;NA;NA;"Artificial Intelligence; 3S Process; Business Education; Design   Thinking; Harvard Case Method";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BHTLQUFU;journalArticle;2019;"Bridge, Pete; Bridge, Robert";Artificial Intelligence in Radiotherapy: A Philosophical Perspective;Journal of Medical Imaging and Radiation Sciences;NA;1939-8654;10.1016/j.jmir.2019.09.003;NA;The increasing uptake of machine learning solutions for segmentation and planning leaves no doubt that artificial intelligence (AI) will soon be providing input into a range of radiotherapy procedures. Although this promises to deliver increased speed and accuracy, the future role of AI in relation to radiotherapy should be thought through carefully. There is currently a gap between published developments and widespread adoption, which provides some space to prepare the workforce and to consider the implications on practice. It is rare to find philosophical input into a medical journal, but the advent of AI makes this perspective increasingly important. Philosophical insight can help explore the potential impact of AI, in particular, on human creativity and oversight. Without this perspective, we run the risk of focusing solely on the immediate logistical impact on patients and departments. This commentary identifies three key aspects of radiotherapy that the authors feel would suffer most under AI control: creativity, innovation, and patient safety, which all demand uniquely human attributes. The article also provides insight from a philosophical perspective with regard to human consciousness, ethics, and empathy. Philosophically we should, perhaps, retain ethical concerns about the widening role of AI in radiotherapy beyond simple quantitative interpretation and image processing. As developments continue, we have time to determine how our roles will evolve and to establish a framework for ensuring appropriate human input into patient care. Most importantly, we must start to embed a philosophical approach to adoption of AI technology from the outset if we are to prepare ourselves for the challenge that lies ahead.;2019-12;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;S27-S31;NA;4;50;NA;J. Med. Imaging Radiat. Sci.;Artificial Intelligence in Radiotherapy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Elsevier Science Inc WOS:000502586400007;NA;C:\Users\esben\Zotero\storage\PRHFIW58\Bridge and Bridge - 2019 - Artificial Intelligence in Radiotherapy A Philoso.pdf;NA;NA;"Artificial intelligence; head; philosophy; radiotherapy; variability";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X7IBUA95;journalArticle;2019;"Lee, Yeonjoo; Ha, Miyeon; Kwon, Sujeong; Shim, Yealin; Kim, Jinwoo";Egoistic and altruistic motivation: How to induce users' willingness to help for imperfect AI;Computers in Human Behavior;NA;0747-5632;10.1016/j.chb.2019.06.009;NA;Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users' voluntary engagement in the loop with an imperfect AI.;2019-12;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;180-196;NA;NA;101;NA;Comput. Hum. Behav.;Egoistic and altruistic motivation;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Oxford Publisher: Pergamon-Elsevier Science Ltd WOS:000489190700020;NA;NA;NA;NA;"emotion; model; automation; empathy; trust; AI (Artificial Intelligence); Explainable AI; Food image recognition; Human in the loop (HITL); Trust; experience; machines; markets; responses; Willingness to   help";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RJDAINJY;journalArticle;2019;"Shorey, Shefaly; Ang, Emily; Yap, John; Ng, Esperanza Debby; Lau, Siew Tiang; Chui, Chee Kong";A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education: Development Study;Journal of Medical Internet Research;NA;1438-8871;10.2196/14658;NA;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019-10-29;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;e14658;NA;10;21;NA;J. Med. Internet Res.;A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Toronto Publisher: Jmir Publications, Inc WOS:000493441600001;NA;NA;NA;NA;"artificial intelligence; learning; communication; virtual reality; technology; students; health-care; benefits; interventions; module; nursing education; patient; patients";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JAC72UHF;journalArticle;2019;Powell, John;Trust Me, I'm a Chatbot: How Artificial Intelligence in Health Care Fails the Turing Test;Journal of Medical Internet Research;NA;1438-8871;10.2196/16222;NA;Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game.;2019-10-28;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;e16222;NA;10;21;NA;J. Med. Internet Res.;Trust Me, I'm a Chatbot;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Toronto Publisher: Jmir Publications, Inc WOS:000492839500001;NA;NA;NA;NA;"artificial intelligence; machine learning; information; conversational agents; chatbots; medical informatics; digital   health; ehealth";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PUXN27MZ;journalArticle;2019;Bristol, R. Curtis;An Essay on Narrative, Reality, and Imagination;Psychoanalytic Inquiry;NA;0735-1690;10.1080/07351690.2019.1659025;NA;"Narrative is a verbal account, a story of related events which can be factual, fictional or both. Life experience and imagination are as essential to narrative as narrative is to mankind. The phylogenic perspective of literature suggests an inborn capacity for empathy, intelligence and inventiveness, whereas the ontological example is variable. Western knowledge, politics and ethics have evolved from their narrative of Greek myth, epic and drama, the few medieval writers, singularly by the Elizabethan theater, importantly the Arthurian legend and romance stories, English and Russian novels, and uniquely the American short story. This heritage progressively demarcated such life themes as the hero, maiden and adversary; love, hate and indifference; loyalty, deception and betrayal; desire, achievement and loss. These characterizations of self and other remain relevant to the contemporary novel, cinema/TV, and theater, as well as the news, commentary, and real life. Conversely, postmodern assumptions challenge that individual subjectivity determines what is real, valid or authentic, consequently the relativism of traditional, institutional and historical precedents of the truth. Further, the computer, gaming, smart device, and artificial intelligence have changed the content and function of customary narrative. Nonetheless, narrative ? real and imagined, ancient and new ? retains the meaning of a story about connected events which variously transcends the boundaries of difference.";2019-10-03;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;476-484;NA;7;39;NA;Psychoanal. Inq.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Abingdon Publisher: Routledge Journals, Taylor & Francis Ltd WOS:000492525400002;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YA6NKJVE;journalArticle;2019;Wartman, Steven A.;The Empirical Challenge of 21st-Century Medical Education;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000002866;NA;Medical education is at a crossroads. Facing challenges wrought by science and technology as well as societal change, the curriculum is increasingly out of synch with new needs in teaching content and medical practice. The path to significant curricular reform is difficult because of a variety of factors, including deeply entrenched values, the natural resistance to change, and the accreditation process. Indeed, even the very definition of what it means to be a professional is changing with profound implications for the future role of the physician and the sacrosanct doctor-patient relationship. In this Invited Commentary, the author enumerates challenges facing medical education in the current era. To address these challenges, the author recommends specific curricular emphases for 21st-century medical education: knowledge capture and curation, collaboration with and management of artificial intelligence applications, a deep understanding of probabilistic reasoning, and the cultivation of empathy and compassion in accordance with ethical standards. Given these needs, it is imperative that schools act today to undertake significant curricular reform and, in so doing, strive to make the hard changes necessary to produce optimal practitioners in a rapidly transforming 21st century. The author provides first steps an institution can take to begin to address these challenges.;2019-10;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;1412-1415;NA;10;94;NA;Acad. Med.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Philadelphia Publisher: Lippincott Williams & Wilkins WOS:000509244700007;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VQBWZZXI;journalArticle;2019;"Gong, Chao; Lin, Fuhong; Zhou, Xianwei; Lu, Xing";Amygdala-Inspired Affective Computing: to Realize Personalized Intracranial Emotions with Accurately Observed External Emotions;China Communications;NA;1673-5447;NA;NA;Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected.;2019-08;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;115-129;NA;8;16;NA;China Commun.;Amygdala-Inspired Affective Computing;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Beijing Publisher: China Inst Communications WOS:000482003900011;NA;NA;NA;NA;"emotion recognition; affective computing; external emotions; intracranial emotions; personalized machines";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6IEH447Y;journalArticle;2019;Cotino Hueso, Lorenzo;Ethics in Design for the Development of an Artificial Intelligence, Trustworthy Robotics and Big Data and Their Utility for the Law;Revista Catalana De Dret Public;NA;1885-5709;10.2436/rcdp.i58.2019.3303;NA;"The study deals with the ethics of artificial intelligence (AI). Firstly, we explain the proclamation of the ethics and its necessity in the different international reference documents, although the analysis is focused on the actions carried out in the European Union. It is precisely in the EU where there is a special commitment to developing an ethics for a trustworthy AI in design and made in Europe, to position itself in front of United States and especially China, two countries that don't pay much attention to the issue. Firstly, we describe the content of ethics of AI and its essential principles from the point of view of the dignity and rights; second, we describe the main five principles contained in the international declarations. Third, we include other basic principles which arise from the demands of empathy with humans. From a somewhat sceptical perspective, we argue the potential utilities of ethics of AI for the law: it is considered to be an especially preventive instrument and that an ethical governance of AI can be developed, following the examples of policies and frameworks on public ethics and institutional integrity. The phases to be followed are described in this regard. We explain in detail the opportunity and the basic content of codes of conduct and committees and other control systems. Finally, we make an appeal for the design of algorithms that serve as guardians of regulatory compliance and the ethics of AI.";2019-06;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;29-48;NA;58;NA;NA;Rev. Catalana Dret Public;NA;NA;NA;NA;NA;NA;NA;Spanish;NA;NA;NA;NA;Web of Science;NA;Place: Barcelona Publisher: Escola Adm Publica Catalunya WOS:000472010900003;NA;C:\Users\esben\Zotero\storage\7X8AGIUU\Cotino Hueso - 2019 - Ethics in Design for the Development of an Artific.pdf;NA;NA;"artificial intelligence; ethics in design; European Union; fundamental rights; robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SL24NJ4W;journalArticle;2019;"Clavelle, Joanne T.; Sweeney, Cynthia D.; Swartwout, Ellen; Lefton, Cindy; Guney, Senem";Leveraging Technology to Sustain Extraordinary Care A Qualitative Analysis of Meaningful Nurse Recognition;Journal of Nursing Administration;NA;0002-0443;10.1097/NNA.0000000000000757;NA;OBJECTIVE: Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND: Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing andmachine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS: Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS: The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS: AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented.;2019-06;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;303-309;NA;6;49;NA;J. Nurs. Adm.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Philadelphia Publisher: Lippincott Williams & Wilkins WOS:000470749100006;NA;NA;NA;NA;satisfaction;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
M3H6WTX2;journalArticle;2019;Masters, Ken;Artificial intelligence in medical education;Medical Teacher;NA;0142-159X;10.1080/0142159X.2019.1595557;NA;Artificial intelligence (AI) is a growing phenomenon, and will soon facilitate wide-scale changes in many professions, including medical education. In order for medical educators to be properly prepared for AI, they will need to have at least a fundamental knowledge of AI in relation to learning and teaching, and the extent to which it will impact on medical education. This Guide begins by introducing the broad concepts of AI by using fairly well-known examples to illustrate AI's implications within the context of education. It then considers the impact of AI on medicine and the implications of this impact for educators trying to educate future doctors. Drawing on these strands, it then identifies AI's direct impact on the methodology and content of medical education, in an attempt to prepare medical educators for the changing demands and opportunities that are about to face them because of AI.;2019-09-02;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;976-980;NA;9;41;NA;Med. Teach.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Abingdon Publisher: Taylor & Francis Ltd WOS:000470504500001;NA;NA;NA;NA;"empathy; diagnosis; students";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VKFFUW2R;journalArticle;2019;"Blease, Charlotte; Kaptchuk, Ted J.; Bernstein, Michael H.; Mandl, Kenneth D.; Halamka, John D.; DesRoches, Catherine M.";Artificial Intelligence and the Future of Primary Care: Exploratory Qualitative Study of UK General Practitioners' Views;Journal of Medical Internet Research;NA;1438-8871;10.2196/12802;NA;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPs') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPs' opinions about the likelihood of future technology to fully replace GPs in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPs also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPs believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPs considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPs' views.";2019-03-20;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;e12802;NA;3;21;NA;J. Med. Internet Res.;Artificial Intelligence and the Future of Primary Care;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Toronto Publisher: Jmir Publications, Inc WOS:000462278400001;NA;C:\Users\esben\Zotero\storage\VW7TNH7A\Blease et al. - 2019 - Artificial Intelligence and the Future of Primary .pdf;NA;NA;"artificial intelligence; big data; attitudes; future; opinions; qualitative research; technology; health; machine   learning; general practice; primary care";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ITUXJ3YI;journalArticle;2019;"Akl, Selim G.; Salay, Nancy";Artificial Intelligence A Promising Future?;Queens Quarterly;NA;0033-6041;NA;NA;"Is a computer capable, like a human, of experiencing emotions (empathy, jealousy, fear)? Can a computer, through cunning, imitate the expression of such emotions for ""personal"" gain? Allowing for all this to be possible, it would follow necessarily that the computer must not only be self-conscious but also have awareness and understanding of the human mind, in order to know its interlocutors' expectations and anticipate their response. Perhaps the real question is beyond ""Can a computer think?"" One may ask: ""Can a computer be as manipulative, as deceptive, as duplicitous - or as charming, as honest, and as kind as a human can be?""";2019;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;6-19;NA;1;126;NA;Queens Q.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Kingston Publisher: Queens Quarterly WOS:000463847500002;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
98C4WVAV;book;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;NA;978-1-4503-6690-8;NA;NA;NA;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (Al), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic Al agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;NA;EmotoTent;NA;NA;NA;NA;Assoc Computing Machinery;New York;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1145/3311927.3326596 Pages: 755-760 Publication Title: Proceedings of Acm Interaction Design and Children (idc 2019) WOS:000559055100103;NA;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; robotic agents; mind-body   interaction; tangible user-interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9BLB7RSN;book;2019;Shvo, Maayan;Towards Empathetic Planning and Plan Recognition;NA;978-1-4503-6324-2;NA;NA;NA;Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants.;2019;2021-02-11T01:55:23Z;2021-02-11T01:55:23Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Assoc Computing Machinery;New York;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1145/3306618.3314307 Pages: 525-526 Publication Title: Aies '19: Proceedings of the 2019 Aaai/Acm Conference on Ai, Ethics, and Society WOS:000556121100074;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
M6XF2BTG;bookSection;2019;"Gutierrez y Restrepo, Emmanuelle; Baldassarre, Martin; Boticario, Jesus G.";Accessibility, Biases and Ethics in Chatbots and Intelligent Agents for Education;Edulearn19: 11th International Conference on Education and New Learning Technologies;978-84-09-12031-4;NA;NA;NA;The use of chatbots is increasingly common in universities around the world to support both educational and administrative tasks. There is also a growing awareness of the importance of inclusive education and, as a consequence, the need to comply with accessibility requirements regarding web contents and web interface (WCAG). These requirements are also supported by specific laws in most countries. But such awareness does not yet reach the interfaces of conversational agents or chatbots that are being developed. Within the framework of the European project ACACIA, co-funded by the Erasmus+ program of the European Union, Artemisa, a chatbot has been created dedicated to fight against sexual harassment and search for volunteers to promote the acceptance of diversity and tolerance, has been created using a platform that facilitates the generation and management of this type of artificial intelligences. But to what extent Artemisa is an accessible chatbot or not? Is it ethically acceptable to make use of a tool that is intended to support inclusiveness but presents accessibility barriers to some users? What is the current state in terms of accessibility compliance of chatbots that work on social networks? This article seeks to answer this and other questions related to accessibility in Chatbots, conversational agents and virtual assistant's. Based on the answer to these questions it follows that there is a need for training in interculturalism and web accessibility to combat the biases that present such entities, which are endowed with artificial intelligence and, unfortunately, in some cases causing serious damage to some people.;2019;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;8824-8833;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Iated-Int Assoc Technology Education & Development;Valenica;English;NA;NA;NA;NA;Web of Science;NA;ISSN: 2340-1117 WOS:000553304903063;NA;NA;NA;NA;"artificial intelligence; ethics; empathy; Conversational agents; accessibility; biases; Chatbot";"Chova, L. G.; Martinez, A. L.; Torres, I. C.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8S79F4VN;book;2019;"Das, Amit Kumar; Ashrafi, Aziza; Ahmmad, Muktadir";Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System;NA;978-1-72811-322-7;NA;NA;NA;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to 'Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.;2019;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;Pages: 36-40 Publication Title: 2019 Ieee 4th International Conference on Computer and Communication Systems (icccs 2019) WOS:000539154300008;NA;NA;NA;NA;"Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5BID4AV7;bookSection;2019;Chiu, K. C.;Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation;2019 Ieee International Conference on Industrial Engineering and Engineering Management (ieem);978-1-72813-804-6;NA;NA;NA;This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence.;2019;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;1516-1520;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;ISSN: 2157-3611 WOS:000541902500302;NA;NA;NA;NA;"Artificial Intelligence; consumer-oriented technology; Dream Consultation; Knowledge Management; Semantic   Analytics; stress; Text Mining";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FURBD9DK;book;2019;"Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco";A Preliminary Work on Dog Emotion Recognition;NA;978-1-4503-6988-6;NA;NA;NA;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.;2019;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Assoc Computing Machinery;New York;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1145/3358695.3361750 Pages: 91-96 Publication Title: 2019 Ieee/Wic/Acm International Conference on Web Intelligence Workshops (wi 2019 Companion) WOS:000518627400014;NA;NA;NA;NA;"Affective Computing; Emotion Recognition; Neural Networks; Transfer Learning; Artificial   Intelligence";"Barnaghi, P.; Gottlob, G.; Katsaros, D.; Manolopoulos, Y.; Pandey, R.; Tzouramanis, T.; Vakali, A.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3IA45IYS;journalArticle;2019;Ponce Sole, Juli;Artificial Intelligence, Administrative Law and Mankind Reservation: Algorithms and Due Technological Process;Revista General De Derecho Administrativo;NA;1696-9650;NA;NA;After analyzing the situation in Spain, it suggests some regulatory improvements in accordance to international ideas and regulations. The study recommends a reservation for human intervention in the case of discretionary powers due to the need of human empathy for their proper exercise. It includes some measures against opacity of algorithms to guarantee the right to good administration and specially its expressions as a right to understand public decisions.;2019-01;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;421176;NA;50;NA;NA;Rev. Gen. Derecho Adm.;Artificial Intelligence, Administrative Law and Mankind Reservation;NA;NA;NA;NA;NA;NA;Spanish;NA;NA;NA;NA;Web of Science;NA;Place: Madrid Publisher: Iustel WOS:000460613300011;NA;NA;NA;NA;"artificial intelligence; administrative   procedure; discrecionality; Enlightment; good administration; mankind reservation; right to understand";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5D7BBPKG;journalArticle;2018;"Inkster, Becky; Sarda, Shubhankar; Subramanian, Vinod";An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study;Jmir Mhealth and Uhealth;NA;2291-5222;10.2196/12106;NA;"Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods.";2018-11;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;e12106;NA;11;6;NA;JMIR mHealth uHealth;An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Toronto Publisher: Jmir Publications, Inc WOS:000451080100001;NA;C:\Users\esben\Zotero\storage\A2T23INZ\Inkster et al. - 2018 - An Empathy-Driven, Conversational Artificial Intel.pdf;NA;NA;"resilience; artificial intelligence; emotions; depression; psychotherapy; empathy; conversational agents; mental health; anxiety disorders; chatbots; coping skills; depressive symptoms; efficacy; guided-self-help; health; individual participant data; metaanalysis; mHealth; primary-care; psychological; randomized controlled-trials";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JBI7G2GY;journalArticle;2018;"Yalcin, Ozge Nilay; DiPaola, Steve";A computational model of empathy for interactive agents;Biologically Inspired Cognitive Architectures;NA;2212-683X;10.1016/j.bica.2018.07.010;NA;Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018-10;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;20-25;NA;NA;26;NA;Biol. Inspired Cogn. Archit.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Amsterdam Publisher: Elsevier Science Bv WOS:000453493800002;NA;NA;NA;NA;"emotion; Empathy; Affective computing; Conversational agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Z9LXHL6B;journalArticle;2018;Johnston, S. Claiborne;Anticipating and Training the Physician of the Future: The Importance of Caring in an Age of Artificial Intelligence;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000002175;NA;Artificial intelligence and other forms of information technology are only just beginning to change the practice of medicine. The pace of change is expected to accelerate as tools improve and as demands for analyzing a rapidly growing body of knowledge and array of data increase. The medical students of today will practice in a world where information technology is sophisticated and omnipresent. In this world, the tasks of memorization and analysis will be less important to them as practicing physicians. On the other hand, the nonanalytical, humanistic aspects of medicinemost importantly, the art of caringwill remain a critical function of the physician, and facility with improving systems of care will be required. Communication, empathy, shared decision making, leadership, team building, and creativity are all skills that will continue to gain importance for physicians. These skills should be further prioritized in medical school curricula to produce an even more effective physician for the future.;2018-08;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;1105-1106;NA;8;93;NA;Acad. Med.;Anticipating and Training the Physician of the Future;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Philadelphia Publisher: Lippincott Williams & Wilkins WOS:000439699000014;NA;NA;NA;NA;classification;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
W9H4P52S;journalArticle;2018;Kouzov, Orlin;Art, Social and Culture Education Supported by Artificial Intelligence Tools;Digital Presentation and Preservation of Cultural and Scientific Heritage;NA;1314-4006;NA;NA;The use of tools, based on AI, will become a regular practice in education due to the dynamic social development. The role of the artificial intelligence in social sciences, arts and culture is key to the achievement of emotional empathy of people in view of the future symbiosis of man and machine.;2018;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;111-119;NA;NA;8;NA;Digit. Present. Preserv. Cult. Sci. Herit.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Sofia Publisher: Inst Mathematics & Informatics, Bulgarian Acad Sciences WOS:000458563100010;NA;NA;NA;NA;"artificial intelligence; critical thinking; educational transformation; knowledge economy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QK8PHPPH;journalArticle;2018;"Toole, J. Tory; Kurian, P.; Craddock, T. J. A.";Coherent Energy Transfer and the Potential Implications for Consciousness;Journal of Cognitive Science;NA;1598-2327;NA;NA;"The argument that biological systems are too ""warm and wet"" to support quantum effects is becoming increasingly antiquated as research in the field of quantum biology progresses. In fact, not only is it becoming apparent that quantum processes may regularly take place in biological systems, but these processes may underlie the mechanisms of consciousness and propel our models of conceptualizing the human brain into the next era of scientific understanding. The phenomena of consciousness have allured scientists and philosophers for thousands of years, while a precise technical understanding has remained elusive. If possible, developing this understanding will likely be one of humanity's greatest achievements. Knowing the fundamental processes that create conscious experience has far-reaching implications, from the potential birth of true artificial intelligence to a better understanding of mental health disorder etiologies and treatments. One major challenge in the mental health professions, and, ultimately, in empathy of any kind, is being able to see from and appreciate another person's unique, subjective experience. Discoveries in the field of consciousness could help bridge this gap.";2018;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;115-124;NA;2;19;NA;J. Cogn. Sci.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Seoul Publisher: Seoul Natl Univ, Inst Cognitive Science WOS:000438352700003;NA;NA;NA;NA;"Consciousness; Coherent energy transfer; microtubules; Quantum biology; quantum coherence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
H9KAKVFD;journalArticle;2017;Moritz, Juergen;Augmented humanity;Technoetic Arts;NA;1477-965X;10.1386/tear.15.3.341_1;NA;Augmented Reality (AR) is commonly defined as a digital layer of information viewed on top of the physical world through a smartphone, tablet or eyewear. Increasingly, this understanding of AR is shifting to a dynamic framework of 'smart things', including wearable technology, sensors and artificial intelligence (AI), with the ability to intercede in key moments and to deliver contextual and meaningful experiences. The things that come into context are the logical next steps in an evolutionary development towards computers that are better able to show empathy in relation to people: even more human oriented, anticipative and ubiquitous. Thus, this outsourcing of meaning to empathic technologies points to one of the fundamental questions concerning the relation of human and technology the nature of the trust that users place in technology.;2017-12;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;341-352;NA;3;15;NA;Technoetic Arts;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Bristol Publisher: Intellect Ltd WOS:000427327900010;NA;NA;NA;NA;"trust; Augmented Reality; empathic technologies; Foucault; quantified   self; self-care; smart technologies; technologies of the self";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
W73GFA8T;journalArticle;2017;Stocker, Reto;Current and future challenges in critical care medicine;Therapeutische Umschau;NA;0040-5930;10.1024/0040-5930/a000879;NA;Actual and future challenges in critical care medicine among others include changes in the demographic structure of Western societies leading to a growing number of aged and very old patients to be treated in the intensive care unit. Although age per se is not a good predictor for ICU survival it frequently comes along with several comorbidities influencing not only ICU but also one to five year survival as well as quality of life compared to a matched non-post-ICU population. Therefore, risk stratification among others seeking for signs of frailty in addition to the development of instruments in order to estimate the post-ICU quality of life are important in order to perform a sound risk-benefit analysis. For patients at risk scheduled for a major intervention pre-interventional interdisciplinary case analysis and discussion including patient and next of kin is warranted. Moreover, aged patients are at risk for under and overtreatment why clear written strategies adapted to the individual case have to be established. With regard to the development of more and more advanced treatment options in patients who finally cannot be cured a change of paradigm concerning palliative care is urgently needed. In these situations palliative care should not be seen as treatment option in the last days only but as accompanying support as soon as it is recognized that cure is not possible. This allows the patient to discuss and establish an advanced care planning together with the care givers. Major challenges in the very near future result from advances in personalized medicine (including genetic analysis) and from digital transformations of our societies. Both are closely connected and will change modern medicine within the next 15 years entirely. Expert systems with artificial intelligence and robots will support but also confront health care professionals with their limitations and hopefully remind them that medicine is not only science but also art and that the digital world at least for a while cannot provide clinical judgment, empathy and humanity as good as human beings.;2017-07;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;25-31;NA;2;74;NA;Ther. Umsch.;NA;NA;NA;NA;NA;NA;NA;German;NA;NA;NA;NA;Web of Science;NA;Place: Bern 9 Publisher: Verlag Hans Huber WOS:000419755900006;NA;NA;NA;NA;"frailty; mortality; multicenter; prevalence; units";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NG6J6CW2;journalArticle;2017;Lawrence, David;More Human than Human;Cambridge Quarterly of Healthcare Ethics;NA;0963-1801;10.1017/S0963180116001158;NA;"Within the literature surrounding nonhuman animals on the one hand and cognitively disabled humans on the other, there is much discussion of where beings that do not satisfy the criteria for personhood fit in our moral deliberations. In the future, we may face a different but related problem: that we might create (or cause the creation of) beings that not only satisfy but exceed these criteria. The question becomes whether these are minimal criteria, or hierarchical, such that those who fulfill them to greater degree should be afforded greater consideration. This article questions the validity and necessity of drawing divisions among beings that satisfy the minimum requirements for personhood; considering how future beings-intelligent androids, synthezoids, even alternate-substrate sentiences-might fit alongside the ""baseline"" human. I ask whether these alternate beings ought to be considered different to us, and why this may or may not matter in terms of a notion of ""human community."" The film Blade Runner, concerned in large part with humanity and its key synthezoid antagonist Roy Batty, forms a framing touchstone for my discussion. Batty is stronger, faster, more resilient, and more intelligent than Homo sapiens. His exploits, far beyond the capability of normal humans, are contrasted with his frailty and transient lifespan, his aesthetic appreciation of the sights he has seen, and his burgeoning empathy. Not for nothing does his creator within the mythos term him ""more human than human.""";2017-07;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;476-490;NA;3;26;NA;Camb. Q. Healthc. Ethics;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: New York Publisher: Cambridge Univ Press WOS:000402285700015;NA;NA;NA;NA;"artificial intelligence; enhancement; humanity; novel beings; personhood; posthuman";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BXAFKL8G;journalArticle;2017;"Smith, Glenn W.; Leymarie, Frederic Fol";The Machine as Artist: An Introduction;Arts;NA;2076-0752;10.3390/arts6020005;NA;With the understanding that art and technology are continuing to experience an historic and rapidly intensifying rapprochementbut with the understanding as well that accounts thereof have tended to be constrained by scientific/engineering rigor on the one hand, or have tended to swing to the opposite extremeit is the goal of this special issue of Arts to provide an opportunity for artists, humanists, scientists, and engineers to consider this development from the broader perspective which it deserves, while at the same time retaining a focus on what must surely be the emerging core of our subject: the state of the art in mechatronics and computation is such that we can now begin to speak comfortably of the machine as artistand we can begin to hope, as well, that an aesthetic sensitivity on the part of the machine might help lead to a friendlier and more sensitive machine intelligence in general.;2017-06;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;5;NA;2;6;NA;Arts;The Machine as Artist;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Basel Publisher: Mdpi WOS:000404631700002;NA;C:\Users\esben\Zotero\storage\T4KL65KP\Smith and Leymarie - 2017 - The Machine as Artist An Introduction.pdf;NA;NA;"artificial intelligence; empathy; technology; aesthetics; art; embodiment; science";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JNM4E9PH;journalArticle;2017;"Balan, K.; Mohanram, Sudha; Karpagam, M.";A Modified Neural Network Relaying for High Efficiency Biomedical Power Transformer Protection;Research Journal of Biotechnology;NA;2278-4535;NA;NA;The main element in a power system is the power transformer. A transformer set-up forms the central element in transmitting and distributing power. There is heavy transmission loss if the power system is defective. The transformers should be protected from internal faults and magnetic inrush currents. The power demands for a biomedical research center or hospital are higher and need to be consistent for the working of all biomedical equipments used. This paper proposes transient detection techniques using Wavelet transform (WT). The advantage of WT is that, it can represent current and voltage signals. Empathy of transients is very fast and precise so this work tends to elaborate on a new wavelet method to classify the inrush currents from power system disturbances. The classification problems in Artificial Intelligence (AI) are solved using neural networks. The neural networks derive its inspiration from neurons present in human body. The performance of NN is assessed based on the design of the hidden layers and by evaluating the weights that connect the nodes. There are no modifications made to the design of the hidden layers as the weight calculated is more important than the hidden structure. An optimum solution can be obtained by calculating the weights of NN by decreasing the function cost or error. This work aims to propose a modified neural network. The neural networks are trained using Firefly Algorithm (FA). Since this protocol is a simple and an efficient metaheuristic optimization technique which draws inspiration from fireflies which tend to move towards brighter light. The experimental results prove the computational efficiency of training process using firefly optimization technique.;2017-01;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;215-224;NA;NA;12;NA;Res. J. Biotechnol.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Indore Publisher: Research Journal Biotechnology WOS:000418956400031;NA;NA;NA;NA;"Artificial Neural Network (ANN); firefly algorithm; Firefly Algorithm (FA); Power Transformer Protection; Wavelet   Transform (WT)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X2WYKJNC;journalArticle;2017;"Schubert, Emery; Canazza, Sergio; De Poli, Giovanni; Roda, Antonio";Algorithms can Mimic Human Piano Performance: The Deep Blues of Music;Journal of New Music Research;NA;0929-8215;10.1080/09298215.2016.1264976;NA;Can a computer play a music score, e.g. via a Disklavier, in a way that cannot be distinguished from a human performance of the same music? One hundred and seventy-two participants with a wide range of music playing backgrounds rated sound recordings of 7 performances of piano music by Kuhlau, one played by a human, and six generated by algorithms, including a mechanical' and an unmusical' rendering. Participants rated the extent to which each performance was by a human and explained their answers. The mechanical performance had the lowest mean rating, but the human performance was rated as statistically identical to the other stimuli. There were no differences between ratings made by classical piano experts and lay listeners, but despite this, the musicians were more confident with their ratings. Qualitative analysis revealed five broad themes that contribute to judging whether a piece appears to be human. The themes were labelled (in descending order of frequency) intuitive, expressive, imperfections, halo (global preference) and empathy. This paper presents new evidence systematically demonstrating that algorithm generated performances of piano music can be indistinguishable from human performances, suggesting some parallels with the 1990s victory of the Deep Blue computer of the world champion (human) chess player.;2017;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;175-186;NA;2;46;NA;J. New Music Res.;Algorithms can Mimic Human Piano Performance;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Abingdon Publisher: Routledge Journals, Taylor & Francis Ltd WOS:000401528700005;NA;NA;NA;NA;"artificial intelligence; automated piano performance; expert-novice; expressiveness; models; music competitions; music judgement; musical Turing test";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
H5Q52MIE;bookSection;2017;"Gutierrez y Restrepo, Emmanuelle; Boticario, Jesus G.";Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future;2017 International Conference on Engineering, Technology and Innovation (ice/Itmc);978-1-5386-0774-9;NA;NA;NA;This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society.;2017;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;1552-1558;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;ISSN: 2334-315X WOS:000464318300207;NA;NA;NA;NA;"Artificial Intelligence; Empathy; Accessibility; Afective   computing; Diversity";"JardimGoncalves, R.; Mendonca, J. P.; Pallot, M.; Zarli, A.; Martins, J.; Marques, M.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
595KYRQC;bookSection;2017;"Maia, Denise A.; Maia, Rodrigo Filev";Pedagogical Robotics as a Tool to Workers Development to Industry 4.0;9th International Conference on Education and New Learning Technologies (edulearn17);978-84-697-3777-4;NA;NA;NA;The forth industrial revolution is changing the way that all businesses, governments, and consumers interact with the physical world and the production system. This new revolution brings new paradigms that is breaking the way men work, and, consequently, changes in their training will also be necessary due to differences in knowledge and skills needed to meet new job demands. A fundamental characteristic of this new mode of production is multidisciplinary teams with a high level of technical knowledge and the ability to face several aspects of the production system, from production line up to customer interaction and integration with business and corporative systems. Besides, due to the velocity of transformations, the new employees must be able to learn and change quickly. Furthermore, such workers must develop intrinsically human characteristics like empathy, personal relationship and technical skills that machines won't be able to do, since all other activities would be done by machines with artificial intelligence and advanced robotics. This paper proposes the use of pedagogical robotics in order to develop multidisciplinary ability and development of interpersonal relationships, creativity and critical thinking to the future employees. It is discussed active learning methodology and the features of educational robotics that could be applied in order to develop the abilities to attend these new job demands.;2017;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;2283-2285;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Iated-Int Assoc Technology Education & Development;Valenica;English;NA;NA;NA;NA;Web of Science;NA;ISSN: 2340-1117 WOS:000491356002058;NA;NA;NA;NA;"active learning; Industry 4.0; pedagogical robotics";"Chova, L. G.; Martinez, A. L.; Torres, I. C.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YHYZJU7M;bookSection;2017;"Fan, Lisa; Scheutz, Matthias; Lohani, Monika; Mccoy, Marissa; Stokes, Charlene";Do We Need Emotionally Intelligent Artificial Agents? First Results of Human Perceptions of Emotional Intelligence in Humans Compared to Robots;Intelligent Virtual Agents, Iva 2017;978-3-319-67401-8 978-3-319-67400-1;NA;NA;NA;Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent's emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them.;2017;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;129-141;NA;NA;10498;NA;NA;Do We Need Emotionally Intelligent Artificial Agents?;NA;NA;NA;NA;Springer International Publishing Ag;Cham;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1007/978-3-319-67401-8_15 ISSN: 0302-9743 WOS:000455400000015;NA;NA;NA;NA;"automation; emotional intelligence; trust; Human-robot interaction; performance; climate; empathetic robot; workplace";"Beskow, J.; Peters, C.; Castellano, G.; OSullivan, C.; Leite, I.; Kopp, S.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IEZX6897;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Masato, Koike";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;Biologically Inspired Cognitive Architectures;NA;2212-683X;10.1016/j.bica.2016.09.004;NA;"Companion or 'pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like 'emotion' and based on emotional intelligence (El) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. (C) 2016 Elsevier B.V. All rights reserved.";2016-10;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;51-67;NA;NA;18;NA;Biol. Inspired Cogn. Archit.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Amsterdam Publisher: Elsevier Science Bv WOS:000390513600006;NA;NA;NA;NA;"brain; network; Behavior; Human-robot interaction; experience; facial expression; Emotional intelligence; models; Companion robot; Consciousness based   architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XQRHIQU2;journalArticle;2016;"Javier Hernandez-Castro, Carlos; Barrero, David F.; R-Moreno, Maria D.";Machine learning and empathy: the Civil Rights CAPTCHA;Concurrency and Computation-Practice & Experience;NA;1532-0626;10.1002/cpe.3632;NA;Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7% of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are leaking too much information by unexpected ways, given non-evident design flaws. Copyright (c) 2015 John Wiley & Sons, Ltd.;2016-03-25;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;1310-1323;NA;4;28;NA;Concurr. Comput.-Pract. Exp.;Machine learning and empathy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley WOS:000370646300026;NA;NA;NA;NA;"artificial intelligence; machine learning; captcha; hip; WordNet";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
47KZR2Z5;book;2016;"Liu, Xin; London, Kati";TAI: A Tangible Al Interface to Enhance Human-Artificial Intelligence (AI) Communication Beyond the Screen;NA;978-1-4503-4031-1;NA;NA;NA;Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-Al communication experience.;2016;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;TAI;NA;NA;NA;NA;Assoc Computing Machinery;New York;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1145/2901790.2901896 Pages: 281-285 Publication Title: Dis 2016: Proceedings of the 2016 Acm Conference on Designing Interactive Systems WOS:000390478300030;NA;NA;NA;NA;"Affective Communication; robot; Shape-changing interface; Social Agent; Tangible interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
V3UABN89;bookSection;2016;"Millward, Frank; Keens, Heather";The Visceral Voice Breath and the Politics of Vocalization;Design, User Experience, and Usability: Novel User Experiences, Pt II;978-3-319-40355-7 978-3-319-40354-0;NA;NA;NA;There are many factors that influence the sound of a 'visceral' or emotive affect vocalization. This discussion develops ideas about how we hear and understand emotive content in the human and the synthetic voice, particularly in relation to affect utterances and nonverbal and paralinguistic vocal gestures. This is important for areas of affective computing and for developing human computer interactive voice processes. Focus is given to how the breath or vocal energy and the affordance of sound, along with socio-political and cultural factors have impact on interactive vocalizations and what that implies for the development of the artificial emotionally intelligent voice of the future.;2016;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;57-66;NA;NA;9747;NA;NA;NA;NA;NA;NA;NA;Springer Int Publishing Ag;Cham;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1007/978-3-319-40355-7_6 ISSN: 0302-9743 WOS:000389470000006;NA;NA;NA;NA;"emotions; model; speech; Affect utterance; Artificial emotional intelligence; challenge; consciousness; Interactive; neurobiological naturalism; neuroontology; Paralinguistic; scientific reduction; Synthetic voice; Visceral; Voice; Voice   qualities; Voice empathy";Marcus, A.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5DWMGCGM;journalArticle;2015;Herzfeld, Noreen;Empathetic Computers: The Problem of Confusing Persons and Things;Dialog-a Journal of Theology;NA;0012-2033;10.1111/dial.12152;NA;"As computers become both more intelligent and ubiquitous we increasingly rely on them for forms of companionship. We are relational beings, instinctively drawn to those who relate back to us, an instinct that is rooted in our creation in the image of a triune, and thus relational, God. Relationships with computers, which necessarily displace relationships with other humans, have so far been shown to be dissatisfying. This dissatisfaction arises because a computer cannot be truly empathetic. It cannot feel emotion due to its lack of a body; it can only simulate emotion. This makes relationship with a computer similar to relationship with a sociopath and can isolate us from both others and our true selves.";2015-03;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;34-39;NA;1;54;NA;Dialog;Empathetic Computers;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Hoboken Publisher: Wiley-Blackwell WOS:000351452100009;NA;NA;NA;NA;"artificial intelligence; empathy; computers; imago Dei; Karl Barth; sociopathology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WUPS2XS7;journalArticle;2015;"Rossi, Pier Giuseppe; Fedeli, Laura";Empathy, Education and AI;International Journal of Social Robotics;NA;1875-4791;10.1007/s12369-014-0272-9;NA;The concept of empathy has multiple meanings. In the present paper we present an experiment in which the relationship between empathy and spatial perspective Berthoz and Jorland (L'Empathie, 2004) acquires a significant role in the process of structural coupling Maturana and Varela (The tree of knowledge: the biological roots of human understanding, 1992) and Damiano (UnitA in dialogo. Un nuovo stile per la conoscenza, 2009). The concept of empathy in education is at the basis of the relation between teacher and students and between teaching and learning. Thus the concepts of co-activity Vinatier and Numa-Bocage (Revue fran double dagger aise de p,dagogie, 158:85-101, 2007) and of structural coupling have analogies with empathy and can provide operational indications. The research question is the following: is it possible to detect the presence of a structural coupling and of empathic processes in a class of students and their teachers through the mediation of a conceptual space created by an automated AI system? The present contribution analyses the use of an AI plug-in developed within the European project I-TUTOR. In the experiment the artefact plays the role of mediator between the teacher and the students and lets their different perspectives be compared. The artefact does not engage in dialogue with the student in a one-to-one relationship, but it is a vertex of the student-artefact-teacher triangle. The artefact, an automated space, fosters a comparison between the perspective of the student and that of the teacher in relation to the dominant teaching object of the course. The paper describes the findings of the experiment run with two groups of students and proposes some changes to be worked into the plug-in to foster further empathic processes.;2015-02;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;103-109;NA;1;7;NA;Int. J. Soc. Robot.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Dordrecht Publisher: Springer WOS:000351108400011;NA;NA;NA;NA;"Education; Artificial intelligence; Empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3AM7DGVQ;book;2015;"Headleand, Christopher J.; Jackson, James; Priday, Lee; Teahan, William; Ap Cenydd, Llyr";Does the Perceived Identity of Non-Player Characters Change how We Interact with Them?;NA;978-1-4673-9403-1;NA;NA;NA;Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it.;2015;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1109/CW.2015.35 Pages: 145-152 Publication Title: 2015 International Conference on Cyberworlds (cw) WOS:000380483300024;NA;NA;NA;NA;"behavior; embodiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BHLKYIV8;bookSection;2015;"Ceschi, Andrea; Scalco, Andrea; Dickert, Stephan; Sartori, Riccardo";Compassion and Prosocial Behavior. Is it Possible to Simulate them Virtually?;Trends in Practical Applications of Agents, Multi-Agent Systems and Sustainability: The Paams Collection;978-3-319-19629-9 978-3-319-19628-2;NA;NA;NA;"In the field of artificial intelligence, a question dealing with computer and cognitive science is arising and becoming more and more crucial: Can we design agents so sophisticated that they are capable of mimicking emotional behaviors in general as well as specific emotions like compassion or empathy? Despite the production of different computational models, their integration with cognitive and psychological theories remains a central problem. Reasons are both methodological and theoretical. Primarily, it is difficult to quantify the impact of such factors as individual differences, inclinations and personality traits. In addition, Agent-Based Models (ABMs) often use linear dynamics, even in describing emotions, without considering the basis of psychophysics. Bearing in mind this and focusing on compassion as a particular emotion, the paper aims to present a ""Decalogue"" for those interested in designing agents capable of mimicking human emotional behaviors. In the paper, compassion will be translated as prosocial behavior.";2015;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;207-214;NA;NA;372;NA;NA;NA;NA;NA;NA;NA;Springer-Verlag Berlin;Berlin;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1007/978-3-319-19629-9_23 ISSN: 2194-5357 WOS:000380446400023;NA;NA;NA;NA;"Psychophysics; Compassion; altruism; Emotional behaviors; Prosocial Behavior";"Bajo, J.; Hernandez, J. Z.; Mathieu, P.; Campbell, A.; FernandezCaballero, A.; Moreno, M. N.; Julian, V.; AlonsoBetanzos, A.; JimenezLopez, M. D.; Botti, V.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4TNUUWF6;bookSection;2015;"Gil, Pablo; Rossi, Claudio; Coral, William";Biophilic Evolutionary Buildings that Restore the Experience of Animality in the City;Biomimetic and Biohybrid Systems, Living Machines 2015;978-3-319-22979-9 978-3-319-22978-2;NA;NA;NA;In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible - or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa, cade that learns optimal configurations according to the perception of aggressiveness and calmness.;2015;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;465-472;NA;NA;9222;NA;NA;NA;NA;NA;NA;NA;Springer-Verlag Berlin;Berlin;English;NA;NA;NA;NA;Web of Science;NA;DOI: 10.1007/978-3-319-22979-9_47 ISSN: 0302-9743 WOS:000364183200047;NA;NA;NA;NA;"Biomimicry; Biophilia; Embodied   evolution; Evolutionary robotics; Intelligent buildings; Wellbeing";"Wilson, S. P.; Verschure, Pfmj; Mura, A.; Prescott, T. J.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VS3CHMSZ;journalArticle;2014;"Potapov, Alexey; Rodionov, Sergey";Universal empathy and ethical bias for artificial general intelligence;Journal of Experimental & Theoretical Artificial Intelligence;NA;0952-813X;10.1080/0952813X.2014.895112;NA;Rational agents are usually built to maximise rewards. However, artificial general intelligence (AGI) agents can find undesirable ways of maximising any prior reward function. Therefore, value learning is crucial for safe AGI. We assume that generalised states of the world are valuable - not rewards themselves, and propose an extension of AIXI, in which rewards are used only to bootstrap hierarchical value learning. The modified AIXI agent is considered in the multi-agent environment, where other agents can be either humans or other 'mature' agents, the values of which should be revealed and adopted by the 'infant' AGI agent. Ageneral framework for designing such empathic agent with ethical bias is proposed as an extension of the universal intelligence model as well. Moreover, we perform experiments in the simple Markov environment, which demonstrate feasibility of our approach to value learning in safe AGI.;2014;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;405-416;NA;3;26;NA;J. Exp. Theor. Artif. Intell.;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Web of Science;NA;Place: Abingdon Publisher: Taylor & Francis Ltd WOS:000338009300008;NA;C:\Users\esben\Zotero\storage\B7SS47H8\Potapov and Rodionov - 2014 - Universal empathy and ethical bias for artificial .pdf;NA;NA;"empathy; multi-agent environment; representations; safe AGI; aixi";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XT2V4Z7B;book;2014;"Majot, Andrew M.; Yampolskiy, Roman V.";AI Safety Engineering Through Introduction of Self-Reference Into Felicific Calculus via Artificial Pain and Pleasure;NA;978-1-4799-4992-2;NA;NA;NA;"In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of ""moral mathematics"" felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed.";2014;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Ieee;New York;English;NA;NA;NA;NA;Web of Science;NA;Publication Title: 2014 Ieee International Symposium on Ethics in Science, Technology and Engineering WOS:000356362200026;NA;NA;NA;NA;"robot; Concept Learning; Intelligent Agents; Machine Learning; Perceptual Reasoning; Philosophical   Foundations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
B885QLXX;bookSection;2011;"Correa da Silva, Flavio Soares; Bressane Neto, Ary Fagundes";Affective Agents for Empathic Interactions;Entertainment Computing - Icec 2011;978-3-642-24499-5;NA;NA;NA;In the present work we develop an experimental setting to evaluate the influence of affect - more precisely, of simulated coherent fluctuations in mood and emotional states - in the construction of empathy in synthetic characters for interactive digital entertainment. Our goal is to evaluate whether the impression of interacting with human-like agents can be more relevant than purely utilitarian metrics for user preferences to interact with systems in certain situations. We have built affective agents to play computer games against human users, and assessed empirically the extent to which users consider more engaging to play against the affective agents than to play against agents that are easy to beat.;2011;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;161-172;NA;NA;6972;NA;NA;NA;NA;NA;NA;NA;Springer-Verlag Berlin;Berlin;English;NA;NA;NA;NA;Web of Science;NA;ISSN: 0302-9743 WOS:000306728900018;NA;NA;NA;NA;"emotion; Affective Computing; Artificial Intelligence; Intelligent Agents; Digital Entertainment";"Anacleto, J.; Fels, S.; Graham, N.; Kaparalos, B.; ElNasr, M. S.; Stanley, K.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EXVNM83Y;book;2011;"Champion, Erik M.; Dekker, Andrew";INDIRECT BIOFED ARCHITECTURE Strategies to best utilise biofeedback tools and interaction metaphors within digital architectural environments;NA;978-988-19026-2-7;NA;NA;NA;This paper explains potential benefits of indirect biofeedback used within interactive virtual environments, and reflects on an earlier study that allowed for the dynamic modification of a virtual environment's graphic shaders, music and artificial intelligence (of Non Playing Characters) based on the biofeedback of the player. It then examines both the potential and the issues in applying biofeedback (already effective for games) to digital architectural environments, and suggests potential uses such as personalization, object creation, atmospheric augmentation, filtering, and tracking.;2011;2021-02-11T01:55:38Z;2021-02-11T01:55:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Caadria-Assoc Computer-Aided Architectural Design Research Asia;Hong Kong;English;NA;NA;NA;NA;Web of Science;NA;Pages: 241-250 Publication Title: Proceedings of the 16th International Conference on Computer-Aided Architectural Design Research in Asia (caadria 2011): Circuit Bending, Breaking and Mending WOS:000351503300024;NA;NA;NA;NA;"sensors; biofeedback; empathy theory; Virtual worlds";"Herr, C. M.; Gu, N.; Roudavski, S.; Schnabel, M. A.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6H5AGJN2;journalArticle;NA;"Yun, Jin Ho; Lee, Eun-Ju; Kim, Dong Hyun";Behavioral and neural evidence on consumer responses to human doctors and medical artificial intelligence;PSYCHOLOGY & MARKETING;NA;0742-6046;10.1002/mar.21445;NA;Will consumers accept artificial intelligence (AI) as a medical care provider? On the basis of evolution theory, we investigate the implicit psychological mechanisms that underlie consumers' interactions with medical AI and a human doctor. In a behavioral investigation (Study 1), consumers expressed a positive intention to use medical AI's healthcare services when it used personalized rather than mechanical conversation. However, neural investigation (Study 2) using functional magnetic resonance imaging revealed that some consumers' implicit attitudes toward medical AI differed from their expressed behavioral intentions. The brain areas linked with implicitly apathetic emotions were activated even when medical AI used a personalized conversation, whereas consumers' brains were activated in areas associated with prosociality when they interacted with a human doctor who used a personalized conversation. On the basis of our neural evidence, consumers perceive an identical personalized conversation differently when it is offered by a medical AI versus a human doctor. These findings have implications for the area of human-AI interactions and medical decision-making and suggest that replacing human doctors with medical AI is still an unrealistic proposition.;NA;2021-02-11T03:48:10Z;2021-02-11T03:48:10Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article; Early Access";NA;NA;NA;NA;"fMRI; artificial intelligence; personalization; apathy; consumer neuroscience; prosociality; medical decision-making";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WL7VTLHK;journalArticle;NA;"Gunkel, David J.; Wales, Jordan Joseph";Debate: what is personhood in the age of AI?;AI & SOCIETY;NA;0951-5666;10.1007/s00146-020-01129-1;NA;In a friendly interdisciplinary debate, we interrogate from several vantage points the question of “personhood” in light of contemporary and near-future forms of social AI. David J. Gunkel approaches the matter from a philosophical and legal standpoint, while Jordan Wales offers reflections theological and psychological. Attending to metaphysical, moral, social, and legal understandings of personhood, we ask about the position of apparently personal artificial intelligences in our society and individual lives. Re-examining the “person” and questioning prominent construals of that category, we hope to open new views upon urgent and much-discussed questions that, quite soon, may confront us in our daily lives.;NA;2021-02-11T03:48:10Z;2021-02-11T03:48:10Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Ethics; Artificial intelligence; Robots; Law; Personhood";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IBY7YQN9;journalArticle;NA;"Ho, Jeffrey C. F.; Ng, Ryan";Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion;BEHAVIOUR & INFORMATION TECHNOLOGY;NA;0144-929X;10.1080/0144929X.2020.1864018;NA;This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters - NPCs in a prosocial VR game - influences players' in-game empathy towards NPCs and game immersion. Participants first experienced either a robot's perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants' game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players' weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed.;NA;2021-02-11T03:48:10Z;2021-02-11T03:48:10Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article; Early Access";NA;NA;NA;NA;"empathy; virtual reality; digital games; Perspective taking; prosocial games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EN3BIVAV;journalArticle;2020;"Ionta, Silvio; Costantini, Marcello; Ferretti, Antonio; Galati, Gaspare; Romani, Gian Luca; Aglioti, Salvatore M.";Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain;CORTEX;NA;0010-9452;10.1016/j.cortex.2020.09.028;NA;Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by lowand high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively. (C) 2020 The Author(s). Published by Elsevier Ltd.;2020-12;2021-02-11T03:48:10Z;2021-02-11T03:48:10Z;NA;295-308;NA;NA;133;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE Publisher: ELSEVIER MASSON, CORP OFF Type: Article;NA;NA;NA;NA;"fMRI; Empathy; Pain; Affective; Sensorimotor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HKF5CINN;journalArticle;2020;"Sueur, Cedric; Forin-Wiart, Marie-Amelie; Pele, Marie";Are They Really Trying to Save Their Buddy? The Anthropomorphism of Animal Epimeletic Behaviours;ANIMALS;NA;2076-2615;10.3390/ani10122323;NA;Simple Summary Anthropomorphism, defined as attributing human traits to animals and other entities, seems to have appeared during evolution to improve an individual's understanding of other species (or indeed the world in general). Yet anthropomorphism can have beneficial or harmful consequences especially for animals, and there seems to be little interest in monitoring the potential danger of this approach. Few studies have focused on the factors affecting how we attribute intentions or beliefs to animals, and more quantitative studies are needed to identify how and why humans attribute mental states and cognitive abilities to other animals. In this study, participants answer questions about three videos in which an individual (a sparrow, an elephant and a macaque, respectively) displayed behaviours towards an inanimate conspecific that suddenly regained consciousness at the end of the footage. A fourth video showed a robot dog being kicked by an engineer to demonstrate its stability. These questions were designed to measure how far participants attribute humanlike intentions, beliefs or mental states to non-human animals and robots. Men and older participants are less likely to attribute humanlike mental states to animals. Similarly, people who work with animals or have at least one pet at home demonstrated less naive anthropomorphism. Conversely, we found that members of animal protection associations showed more biophilia (affinity for other living organisms), attributed more intentions and mental states to animals and were further from biological reality (current scientific knowledge of each species) than non-members. Understanding the potential usefulness of these factors can lead to better relationships with animals and encourage human-robot interactions. Anthropomorphism is a natural tendency in humans, but it is also influenced by many characteristics of the observer (the human) and the observed entity (here, the animal species). This study asked participants to complete an online questionnaire about three videos showing epimeletic behaviours in three animal species. In the videos, an individual (a sparrow, an elephant and a macaque, respectively) displayed behaviours towards an inanimate conspecific that suddenly regained consciousness at the end of the footage. A fourth video showed a robot dog being kicked by an engineer to demonstrate its stability. Each video was followed by a series of questions designed to evaluate the degree of anthropomorphism of participants, from mentaphobia (no attribution of intentions and beliefs, whatever the animal species) to full anthropomorphism (full attribution of intentions and beliefs by animals, to the same extent as in humans) and to measure how far the participants had correctly assessed each situation in terms of biological reality (current scientific knowledge of each species). There is a negative correlation (about 61%) between the mental states attributed to animals by humans and the real capability of animals. The heterogeneity of responses proved that humans display different forms of anthropomorphism, from rejecting all emotional or intentional states in animals to considering animals to show the same intentions as humans. However, the scores participants attributed to animals differed according to the species shown in the video and to human socio-demographic characteristics. Understanding the potential usefulness of these factors can lead to better relationships with animals and encourage a positive view of human-robot interactions. Indeed, reflective or critical anthropomorphism can increase our humanity.;2020-12;2021-02-11T03:48:10Z;2021-02-11T03:48:10Z;NA;NA;NA;12;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; robot; animal ethics; birds; cognitive biases; comparative thanatology; elephants; mentaphobia; primates";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6MNWYLZ9;journalArticle;2020;"Konijn, Elly A.; Hoorn, Johan F.";Differential Facial Articulacy in Robots and Humans Elicit Different Levels of Responsiveness, Empathy, and Projected Feelings;ROBOTICS;NA;NA;10.3390/robotics9040092;NA;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot's face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot's face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) x 2 (treatment: affectionate vs. maltreated). Participants (N = 265; M-age = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of `because I feel, I believe it's real,' despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of `it is just a robot' fades into the background and appears not relevant anymore.";2020-12;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; social robots; facial expression; experiment; human-robot communication; user response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BT4B3H84;journalArticle;NA;"Salminen, Joni; Jung, Soon-gyo; Kamel, Ahmed Mohamed Sayed; Santos, Joao M.; Jansen, Bernard J.";Using artificially generated pictures in customer-facing systems: an evaluation study with data-driven personas;BEHAVIOUR & INFORMATION TECHNOLOGY;NA;0144-929X;10.1080/0144929X.2020.1838610;NA;We conduct two studies to evaluate the suitability of artificially generated facial pictures for use in a customer-facing system using data-driven personas. STUDY 1 investigates the quality of a sample of 1,000 artificially generated facial pictures. Obtaining 6,812 crowd judgments, we find that 90% of the images are rated medium quality or better. STUDY 2 examines the application of artificially generated facial pictures in data-driven personas using an experimental setting where the high-quality pictures are implemented in persona profiles. Based on 496 participants using 4 persona treatments (2 x 2 research design), findings of Bayesian analysis show that using the artificial pictures in persona profiles did not decrease the scores for Authenticity, Clarity, Empathy, and Willingness to Use of the data-driven personas.;NA;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article; Early Access";NA;NA;NA;NA;"human factors; user behaviour; artificially generated facial pictures; computer interaction; Evaluation; human&#8211";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QBL9F5BM;journalArticle;2020;"Bagheri, Elahe; Esteban, Pablo G.; Cao, Hoang-Long; De Beir, Albert; Lefeber, Dirk; Vanderborght, Bram";An Autonomous Cognitive Empathy Model Responsive to Users' Facial Emotion Expressions;ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS;NA;2160-6455;10.1145/3341198;NA;Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.;2020-11;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;3, SI;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"Empathy; social robots; human robot interaction; adaptive interaction; facial emotion detection; non-verbal behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7BE7FBC9;journalArticle;2020;"Van, Nguyen Thi Thanh; Vrana, Vasiliki; Duy, Nguyen Thien; Minh, Doan Xuan Huy; Dzung, Pham Tien; Mondal, Subhra R.; Das, Subhankar";The Role of Human-Machine Interactive Devices for Post-COVID-19 Innovative Sustainable Tourism in Ho Chi Minh City, Vietnam;SUSTAINABILITY;NA;NA;10.3390/su12229523;NA;In this research article, we aim to study the proposed role of human-machine interactive (HMI) technologies, including both artificial intelligence (AI) and virtual reality (VR)-enabled applications, for the post-COVID-19 revival of the already depleted tourism industry in Vietnam's major tourist destination and business hub of Ho Chi Minh City. The researchers aim to gather practical knowledge regarding tourists' intentions for such service enhancements, which may drive the sector to adopt a better conclusive growth pattern in post-COVID-19 times. In this study, we attempt to focus on travelers who look for paramount safety with the assurance of empathetic, personalized care in post-COVID-19 times. In the current study, the authors employ structural equation modeling to evaluate the intentions of tourists both structurally and empirically for destination tourism with data collected from tourists with previous exposure to various kinds of these devices. The study shows that human-machine interactive devices are integrating AI and VR and have a significant effect on overall service quality, leading to tourist satisfaction and loyalty. The use of such social interactive gadgets within tourism and mostly in hospitality services requires an organization to make a commitment to futuristic technologies, along with building value by enriching service quality expectations among fearful tourists. This research shows that tourists mainly focus on the use of such HMI devices from the perspective of technology acceptance factors, qualitative value-enhancing service and trustworthy information-sharing mechanisms. The concept of the tour bubble framework is also discussed in detail. The analysis of this discussion gives us a more profound understanding of the novel opportunities which various administrative agencies may benefit from to position these devices better in smart, sustainable destination tourism strategies for the future so that, collectively, service 5.0 with HMI devices can possibly bring back tourism from being disintegrated. Such service applications are the new social innovations leading to sustainable service and a sophisticated experience for all tourists.;2020-11;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;22;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"COVID-19; 0 and 5; AI and VR devices; revival of tourism; robots in tourism; service 5; tour bubble; tourist interest; Web 4";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XIMQTXZP;journalArticle;2020;"Giannopulu, Irini; Etournaud, Aude; Terada, Kazunori; Velonaki, Mari; Watanabe, Tomio";Ordered interpersonal synchronisation in ASD children via robots;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-020-74438-6;NA;Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020-10-15;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY Publisher: NATURE RESEARCH Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MWIP9PRH;journalArticle;NA;"Maggi, Gianpaolo; Dell'Aquila, Elena; Cucciniello, Ilenia; Rossi, Silvia";“Don't Get Distracted!”: The Role of Social Robots' Interaction Style on Users' Cognitive Performance, Acceptance, and Non-Compliant Behavior;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00702-4;NA;Social robots are developed to provide companionship and assistance in the daily life of the children, older, and disable people but also have great potential as educational technology by facilitating learning. In these application areas, a social robot can take the role of a coach by training and assisting individuals also in cognitive tasks. Since a robot's interaction style affects users' trust and acceptance, customizing its behavior to the proposed tasks could, potentially, have an impact on the users' performance. To investigate these phenomena, we enrolled sixty volunteers and endowed a social robot with afriendlyand anauthoritarianinteraction style. The aim was to explore whether and how the robot's interaction style could enhance users' cognitive performance during a psychometric evaluation. The results showed that theauthoritarianinteraction style seems to be more appropriate to improve the performance when the tasks require high cognitive demands. These differences in cognitive performance between the groups did not depend on users' intrinsic characteristics, such as gender and personality traits. Nevertheless, in theauthoritariancondition, participants' cognitive performance was related to their trust and the acceptance of the technology. Finally, we found that users' non-compliant behavior was not related to their personality traits. This finding indirectly supports the role of the robot's interaction style in influencing the compliance behavior of the users.;NA;2021-02-11T03:48:11Z;2021-02-11T03:48:11Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Social robots; Cognitive performance; Non-verbal features; Robot's behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RNIM5EDZ;journalArticle;NA;"Bagheri, Elahe; Roesler, Oliver; Cao, Hoang-Long; Vanderborght, Bram";A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00683-4;NA;Robots that express human's social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better.;NA;2021-02-11T03:48:12Z;2021-02-11T03:48:12Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Personality; Reinforcement learning; Empathy; Human-robot interaction; Social robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WI3JFD7N;journalArticle;NA;"Kuester, Dennis; Swiderska, Aleksandra";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;INTERNATIONAL JOURNAL OF PSYCHOLOGY;NA;0020-7594;10.1002/ijop.12715;NA;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.;NA;2021-02-11T03:48:12Z;2021-02-11T03:48:12Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND Publisher: JOHN WILEY & SONS LTD Type: Article; Early Access";NA;NA;NA;NA;"Robots; Benevolent intentions; Dehumanisation; Mind perception; Moral typecasting theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QAA3MHI7;journalArticle;NA;"James, Jesin; Balamurali, B. T.; Watson, Catherine I.; MacDonald, Bruce";Empathetic Speech Synthesis and Testing for Healthcare Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00691-4;NA;One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot's voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people's acceptance of social robots.;NA;2021-02-11T03:48:12Z;2021-02-11T03:48:12Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Social robots; Artificial empathy; Emotional speech synthesis; Healthcare; Prosody modelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
V63NVBQY;journalArticle;2020;"Sumitani, Mizuho; Osumi, Michihiro; Abe, Hiroaki; Azuma, Kenji; Tsuchida, Rikuhei; Sumitani, Masahiko";A Robot Has a Mind of Its Own Because We Intuitively Share It;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app10186531;NA;People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we `share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent).;2020-09;2021-02-11T03:48:12Z;2021-02-11T03:48:12Z;NA;NA;NA;18;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"pain; empathy; affective mind; facial expression; robot (virtual agent)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IM3KLLK5;journalArticle;2020;"Ivkov, Milan; Blesic, Ivana; Dudic, Branislav; Bartakova, Gabriela Pajtinkova; Dudic, Zdenka";Are Future Professionals Willing to Implement Service Robots? Attitudes of Hospitality and Tourism Students towards Service Robotization;ELECTRONICS;NA;NA;10.3390/electronics9091442;NA;This paper aims to examine attitudes of hospitality and tourism students, as future professionals, towards willingness to implement service robots. The study proposes a new theoretical conceptual model that includes new constructs and items, differentiating it from the others. The model was formed based on the extensive literature review and the interview with an eight-member focus group (hotel managers and academic researchers). Data collection was performed in two stages, pilot research based on 82 respondents and the main study, with the final number of respondents being 236. The initial results of the exploratory factor analysis were further tested using the confirmatory factor analysis. After the exclusion of several items due to low factor loadings and in order to improve model validity, analyses further suggested a nine-dimensional solution with 45 items. The study findings reveal a positive relationship between seven constructs and students' willingness to implement service robots, with the expected business outcome being the most influencing one. On the other hand, positive relation was not found for empathy and social influence constructs. Theoretical contributions and practical implications are discussed in the paper. In conclusion, study limitations and future research suggestions are provided.;2020-09;2021-02-11T03:48:12Z;2021-02-11T03:48:12Z;NA;NA;NA;9;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"students; hospitality; service robots; tourism; willingness to implement service robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
C8XEJXWI;journalArticle;2020;"Chiang, Ai-Hsuan; Trimi, Silvana";Impacts of service robots on service quality;SERVICE BUSINESS;NA;1862-8516;10.1007/s11628-020-00423-8;NA;With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers' top priorities for robots' service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots' responsiveness, but this construct was found to be a low priority.;2020-09;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;439-459;NA;3;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY Publisher: SPRINGER HEIDELBERG Type: Article;NA;NA;NA;NA;"Artificial intelligence; Importance-performance analysis; Service quality; Service robot; TOPSIS";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RNPKP359;journalArticle;2020;"Pepito, Joseph Andrew; Ito, Hirokazu; Betriana, Feni; Tanioka, Tetsuya; Locsin, Rozzano C.";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations;NURSING PHILOSOPHY;NA;1466-7681;10.1111/nup.12318;NA;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.";2020-10;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; affective developmental robotics; artificial empathy; humanoid nurse robots; intelligent humanoid robots; nursing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FHW8T4G9;journalArticle;2020;Gramantieri, Riccardo;Alexithymic personality in Philip K. Dick'sDo androids dream of electric sheep?;NEOHELICON;NA;0324-4652;10.1007/s11059-020-00544-z;NA;"The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients' comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novelDo androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commentingDo androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick.";2020-12;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;673-683;NA;2, SI;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Schizophrenia; Affective disorders; Alexithymia; Dick; Do androids dream of electric sheep?; Philip K";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
J8V5TIPK;journalArticle;2020;"Rossi, Silvia; Conti, Daniela; Garramone, Federica; Santangelo, Gabriella; Staffa, Mariacarla; Varrasi, Simone; Di Nuovo, Alessandro";The Role of Personality Factors and Empathy in the Acceptance and Performance of a Social Robot for Psychometric Evaluations;ROBOTICS;NA;NA;10.3390/robotics9020039;NA;Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the “openness to experience”, on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests.;2020-06;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;NA;NA;2;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; human friendly cognitive robotics; personality factors; psychometric evaluation; social assistive robots; technology acceptance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EH88MVLV;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots;TOURISM MANAGEMENT;NA;0261-5177;10.1016/j.tourman.2019.104042;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
35NGI4C9;journalArticle;NA;Andreotta, Adam J.;The hard problem of AI rights;AI & SOCIETY;NA;0951-5666;10.1007/s00146-020-00997-x;NA;In the past few years, the subject of AI rights-the thesis that AIs, robots, and other artefacts (hereafter, simply `AIs') ought to be included in the sphere of moral concern-has started to receive serious attention from scholars. In this paper, I argue that the AI rights research program is beset by an epistemic problem that threatens to impede its progress-namely, a lack of a solution to the `Hard Problem' of consciousness: the problem of explaining why certain brain states give rise to experience. To motivate this claim, I consider three ways in which to ground AI rights-namely: superintelligence, empathy, and a capacity for consciousness. I argue that appeals to superintelligence and empathy are problematic, and that consciousness should be our central focus, as in the case of animal rights. However, I also argue that AI rights is disanalogous from animal rights in an important respect: animal rights can proceed without a solution to the `Hard Problem' of consciousness. Not so with AI rights, I argue. There we cannot make the same kinds of assumptions that we do about animal consciousness, since we still do not understand why brain states give rise to conscious mental states in humans.;NA;2021-02-11T03:48:13Z;2021-02-11T03:48:13Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Ethics; Artificial intelligence; AI rights; Animals rights; The `hard problem' of consciousness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EXS6NVU8;journalArticle;2020;Schmetkamp, Susanne;Understanding AI - Can and Should we Empathize with Robots?;REVIEW OF PHILOSOPHY AND PSYCHOLOGY;NA;1878-5158;10.1007/s13164-020-00473-x;NA;Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding.;2020-12;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;881-897;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Ethics; Artificial intelligence; Empathy; Fictional characters; Humanoid robots; Interaction; Perspective-taking";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QZX43764;journalArticle;2020;"Trost, Margaret J.; Chrysilla, Grace; Gold, Jeffrey I.; Mataric, Maja";Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children;PAIN RESEARCH & MANAGEMENT;NA;1203-6765;10.1155/2020/7935215;NA;"Objectives. Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods. We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot's empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with . Results. Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions. Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management.";2020-04-09;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;NA;NA;NA;2020;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND Publisher: HINDAWI LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
I8GFTK9A;journalArticle;2020;"Yalcin, Ozge Nilay; DiRaola, Steve";Modeling empathy: building a link between affective and cognitive processes;ARTIFICIAL IN℡LIGENCE REVIEW;NA;0269-2821;10.1007/s10462-019-09753-0;NA;Computational modeling of empathy has recently become an increasingly popular way of studying human relations. It provides a way to increase our understanding of the link between affective and cognitive processes and enhance our interaction with artificial agents. However, the variety of fields contributing to empathy research has resulted in isolated approaches to modeling empathy, and this has led to various definitions of empathy and an absence of common ground regarding underlying empathic processes. Although this diversity may be useful in that it allows for an in-depth examination of various processes linked to empathy, it also may not yet provide a coherent theoretical picture of empathy. We argue that a clear theoretical positioning is required for collective progress. The aim of this article is, therefore, to call for a holistic and multilayered view of a model of empathy, taken from the rich background research from various disciplines. To achieve this, we present a comprehensive background on the theoretical foundations, followed by the working definitions, components, and models of empathy that are proposed by various fields. Following this introduction, we provide a detailed review of the existing techniques used in AI research to model empathy in interactive agents, focusing on the strengths and weaknesses of each approach. We conclude with a discussion of future directions in this emerging field.;2020-04;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;2983-3006;NA;4;53;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Artificial agents; Cognitive modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3885MY5W;journalArticle;NA;"Law, Theresa; Chita-Tegmark, Meia; Scheutz, Matthias";The Interplay Between Emotional Intelligence, Trust, and Gender in Human-Robot Interaction A Vignette-Based Study;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00624-1;NA;"As robots begin to enter roles in which they work closely with human teammates or peers, it is critical to understand how people trust them based on how they interpret the robot's behavior. In this paper we investigated the interplay between trust in a robot and people's perceptions of the robot's emotional intelligence. We used a vignette-based method to explore the following questions: (1) Do subjects perceive differences in robot EI, and is their trust in the robot influenced by differences in the robot's reliability and capability? (2) Does a robot's EI influence how much it is trusted and conversely does a robot's capability and reliability influence how emotionally intelligent it is perceived to be? (3) Do people trust male and female robots differently when the robots exhibit different levels of EI or different levels of capability and reliability, and do gender stereotypical expectations related to EI transfer to trust?; (4) Does focusing on the robot's EI increase one's trust in the robot? (5) Is the interplay between trust, EI and gender the same for different levels of evoked social presence and human-likeness (i.e., when the interaction is presented in different modalities, text or spoken dialogue when the robot's voice is actually heard)? We found that trust in the robot was influenced by the level of the robot's EI (p < .001) and that gender stereotypical expectations related to EI were transferred to trust (p = .006), but gender effects on trust disappeared when only capability and reliability (robot's trustworthiness) were manipulated but not the robot's EI (p = .103). Surprisingly, we found that people trusted the robot more when the interaction was presented in text format (p = .024), going against our hypothesis that spoken dialogue would evoke more social presence and thus bolster EI perception and instill more trust. We suggest that this effect might be due to people's expectations of a more expressive and human-like voice. Finally, we also found that people's trust ratings in the robot were higher when they were made to notice and think about the robot's EI, by answering EI questionnaires prior to trust questionnaires (p = .022). We discuss the implications of our findings for robot design and HRI research.";NA;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Human-robot interaction; Trust; Emotional intelligence; Gender";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
29L97SLA;journalArticle;2020;McBride, Neil;Robot Enhanced Therapy for Autistic Children: An Ethical Analysis;IEEE TECHNOLOGY AND SOCIETY MAGAZINE;NA;0278-0097;10.1109/MTS.2020.2967493;NA;The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in IEEE Technology and Society Magazine, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions.;2020-03;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;51-60;NA;1;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Medical treatment; Ethics; Robot sensing systems; Autism; Pediatrics; Social implications of technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
I5Q6CPJD;journalArticle;2020;"Bjorling, Elin A.; Thomas, Kyle; Rose, Emma J.; Cakmak, Maya";Exploring Teens as Robot Operators, Users and Witnesses in the Wild;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.00005;NA;As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.;2020-02-21;2021-02-11T03:48:14Z;2021-02-11T03:48:14Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; social robots; mental health; adolescence; human-centered design; participatory; Wizard of Oz";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RQNB7KKK;conferencePaper;2020;"Mitsuno, Seiya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.;2020;2021-02-11T03:48:15Z;2021-02-11T03:48:15Z;NA;653-658;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JGXC3KPC;conferencePaper;2020;"Ye, Sean; Feigh, Karen; Howard, Ayanna";Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.;2020;2021-02-11T03:48:15Z;2021-02-11T03:48:15Z;NA;1186-1189;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9LYT3QCN;conferencePaper;2020;"Perusquia-Hernandez, Monica; Balda, Marisabel Cuberos; Jauregui, David Antonio Gomez; Paez-Granados, Diego; Dollack, Felix; Salazar, Jose Victorio";Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self-tracking results might cause the opposite effect. Subtle self-tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.;2020;2021-02-11T03:48:15Z;2021-02-11T03:48:15Z;NA;1328-1333;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;"embodiment; empathy and intersubjectivity; haptic feedback; human-machine interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2GZ2A446;conferencePaper;2020;"Garcia Corretjer, Marialejandra; Ros, Raquel; Martin, Fernando; Miralles, David";The Maze of Realizing Empathy with Social Robots;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.;2020;2021-02-11T03:48:16Z;2021-02-11T03:48:16Z;NA;1334-1339;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HVGQSXBS;journalArticle;2020;"Marquez-Sanchez, Sergio; Mora-Simon, Sara; Herrera-Santos, Jorge; Olga Roncero, Ana; Corchado, Juan M.";Intelligent Dolls and robots for the treatment of elderly people with dementia;ADCAIJ-ADVANCES IN DISTRIBUTED COMPUTING AND ARTIFICIAL IN℡LIGENCE JOURNAL;NA;2255-2863;10.14201/ADCAIJ20209199112;NA;Dolls and robots are effective and beneficial non-pharmacological therapies applied in different clinical settings. Doll therapy (DT), principally based on Bowlby's attachment theory, uses an empathy or lifelike baby doll to awaken caring behaviors in patients. Robot therapies (RT) involve care robots that have a friendly attitude and appearance. They evoke different verbal, motor and emotional reactions in patients. Both DT and RT are person-centred therapies that provide patients with a realistic experience with the aim of improving their wellbeing. These therapies can be used in people suffering from different neurological, psychological and mental health disorders, such as Alzheimer's Disease, autism spectrum disorder, stress or depression. In this paper, the characteristics of both therapies, their benefits and the possibilities for innovation in the therapeutic field are presented.;2020;2021-02-11T03:48:16Z;2021-02-11T03:48:16Z;NA;99-112;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: APARTADO DE CORREOS 325, SALAMANCA, 00000, SPAIN Publisher: EDICIONES UNIV SALAMANCA Type: Article;NA;NA;NA;NA;"Doll Therapy; Innovative therapy; Non-pharmacological therapy; Robot Therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CK4GK5PF;journalArticle;2020;Riabov, Oleg;THE RED MACHINE: THE DEHUMANIZATION OF THE COMMUNIST ENEMY IN AMERICAN COLD WAR CINEMA;QUAESTIO ROSSICA;NA;2311-911X;10.15826/qr.2020.2.479;NA;"This article deals with the US Cold War cinematographic construction of the Soviet enemy. The researcher focuses on the means of dehumanising the communist enemy, external and internal, by equating it to a machine. The author applies Nick Haslam's dual model of dehumanization (2006), according to which dehumanization is visible in two main forms: animalistic, by associating members of the out-group with animals, and mechanistic, by associating them with a soulless machine. The materials used consist of US films from the “Long Fifties”, in which Hollywood, equating the enemy to machines, developed three plots: the robotic existence of individuals in a totalitarian society; the transformation of Americans into zombies by communists by means of Soviet science; and the body snatching of Americans by an alien mind, an allegory of a future communist occupation of the USA. The article demonstrates that dehumanization was implemented by directly labeling the representatives of the communist world as robots and by attributing to them a lack of emotions, consciousness, will, individuality, initiative, warmth, love, friendship, creative abilities, and even the ability to smile. Such an image of the enemy implied a moral exclusion, treating them as an inanimate object unworthy of empathy, including in the event of their destruction. The author points out that the use of mechanistic dehumanization was very effective. Essentialization of the differences between “us” and “them” occurred: the symbolic border between them is presented as a boundary between living and nonliving. The image of mortal danger was created: the “Red Machine” is strong and merciless, it cannot be moved to pity, and so it is permissible to destroy it. This image contributed to the legitimation of power: the political opponents of the authorities are represented as internal enemies who are anxious to turn Americans into obedient executors of someone else's will and to deprive them of humanity. At the same time, the machine also has weaknesses, and it is possible to defeat it: since it is devoid of human creativity, it is clearly inferior to the free human spirit embodied in America.";2020;2021-02-11T03:48:16Z;2021-02-11T03:48:16Z;NA;536-550;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PROSPEKT LENINA 51, EKATERINBURG, 620083, RUSSIA Publisher: URAL FEDERAL UNIV Type: Article;NA;NA;NA;NA;"dehumanization; Cold War; image of Russia; image of the enemy; propaganda; US cinema";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y94FID7M;conferencePaper;2020;"Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vazquez, Marynel";Prompting Prosocial Human Interventions in Response to Robot Mistreatment;PROCEEDINGS OF THE 2020 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI `20);978-1-4503-6746-2;NA;10.1145/3319502.3374781;NA;Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.;2020;2021-02-11T03:48:16Z;2021-02-11T03:48:16Z;NA;211-220;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; SIGAI; IEEE Robot & Automat Soc; ACM Digital Lib; FN Robot; ARM; Cambridge Consultants; Furhat Robot; Halodi; Toyota Res Inst; Cambridge Univ Press; EXG Wear; Frontiers Robot & AI; Honda Res Inst; IDLab; MDPI Robot; MIT Press Europe; Promobot; Semio ISSN: 2167-2121 Type: Proceedings Paper";<p>ACM/IEEE International Conference on Human-Robot Interaction (HRI), Cambridge, ENGLAND, MAR 23-26, 2020</p>;NA;NA;NA;"Human-robot interaction; prosocial behavior; robot abuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FYTFSHK5;journalArticle;2020;"Sejima, Yoshihiro; Maeda, Ryosuke; Sato, Yoichiro; Watanabe, Tomio";A video communication system with a virtual pupil CG superimposed on the partner's pupil;JOURNAL OF ADVANCED MECHANICAL DESIGN SYSTEMS AND MANUFACTURING;NA;1881-3054;10.1299/jamdsm.2020jamdsm0091;NA;Pupil response plays an important role in expression of talker's affect in an embodied interaction and communication. Focusing on the pupil response in human voice communication, we analyzed the pupil response during utterance, and demonstrated that the pupil enlarges and contracts in synchronization with the burst-pause (ON-OFF) of the utterance. In addition, it was confirmed that the pupil response is effective for enhancing affective conveyance by using the developed system in which an interactive CG character generates the pupil response based on the synchronization with the burst-pause of utterance. In this study, we developed a video communication system with a virtual pupil CG superimposed on the partner's pupil for enhancing affective conveyance. This system generates a virtual pupil response in synchronization with the talker's burst-pause of utterance. We performed a communication experiment under the condition that the virtual pupil CG is generated by being synchronized with the talker's burst-pause of utterance. The effectiveness of the system was demonstrated by means of sensory evaluations of 12 pairs of participants in the video communication.;2020;2021-02-11T03:48:17Z;2021-02-11T03:48:17Z;NA;NA;NA;6;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: SHINANOMACHI-RENGAKAN BLDG., SHINANOMACHI 35, SHINJUKU-KU, TOKYO, 160-0016, JAPAN Publisher: JAPAN SOC MECHANICAL ENGINEERS Type: Article;NA;NA;NA;NA;"Empathy; Human interface; Human-robot interaction design; Kansei and affective engineering; Media representation; Pupil response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CK68SP9I;journalArticle;2020;"Rafique, Memoona; Hassan, Muhammad Awais; Jaleel, Abdul; Khalid, Hina; Bano, Gulshan";A Computation Model for Learning Programming and Emotional Intelligence;IEEE ACCESS;NA;2169-3536;10.1109/ACCESS.2020.3015533;NA;Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.;2020;2021-02-11T03:48:17Z;2021-02-11T03:48:17Z;NA;149616-149629;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Computational modeling; Education; Robots; Emotional intelligence; basic programming; Programming profession; robots based learning; screen-free interface; Sequential analysis; Tools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E3ZXWFIS;journalArticle;2020;"Lizeta, Bakola N.; Drigas, Athanasios S.";Technological Development Process of Emotional Intelligence as a Therapeutic Recovery Implement in Children with ADHD and ASD Comorbidity;INTERNATIONAL JOURNAL OF ONLINE AND BIOMEDICAL ENGINEERING;NA;NA;10.3991/ijoe.v16i03.12877;NA;The perception, empathy, expression and regulation of emotion have been recognized as the determining factors to everyday communication and psychosocial adaptation in children. Deficits in them can cause emotional and social problems and affect everyday life. This paper aims at investigating by reviewing the current clinical and empirical knowledge of psychoemotional and social development as much as emotional intelligence in children diagnosed with Attention Deficit Hyperactivity Disorder (ADHD) and Autism Spectrum Disorder (ASD) coexistence looking into the emotion recognition deficits as well as processing, reciprocity and emotional expression deficits noticing and characterizing these children mostly. Moreover they are considering and being studied the technical means and the ways that they could help in the development and growing of social skills and emotional intelligence. The results proclaimed that the therapeutic contribution of Information and Communication Technologies (ICTs) can be determinant.;2020;2021-02-11T03:48:17Z;2021-02-11T03:48:17Z;NA;75-85;NA;3;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: KIRCHENGASSE 10-200, WIEN, A-1070, AUSTRIA Publisher: INT ASSOC ONLINE ENGINEERING Type: Article;NA;NA;NA;NA;"artificial intelligence; robots; ADHD and ASD comorbidity; Emotional intelligence; social interaction; emotional and social development";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2QBT33G3;journalArticle;2020;"So, Wing-Chee; Cheng, Chun-Ho; Lam, Wan-Yi; Huang, Ying; Ng, Ka-Ching; Tung, Hiu-Ching; Wong, Wing";A Robot-Based Play-Drama Intervention May Improve the Joint Attention and Functional Play Behaviors of Chinese-Speaking Preschoolers with Autism Spectrum Disorder: A Pilot Study;JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS;NA;0162-3257;10.1007/s10803-019-04270-z;NA;Children with autism spectrum disorder (ASD) have deficits in joint attention and play behaviors. We examined whether a robot-based play-drama intervention would promote these skills. Chinese-speaking preschool children were randomly assigned to an intervention group (N = 12) and a waitlist control group (N = 11). Children in the intervention group watched three robot dramas and engaged in role-plays with both robots and human experimenters over the course of 9 weeks. There were significant improvements in joint attention initiations and functional play behaviors in the intervention group. Parents of this group of children also reported less severe social impairments. It was therefore concluded that a robot-based play-drama intervention can enhance the joint attention and play behaviors of children with ASD.;2020-02;2021-02-11T03:48:17Z;2021-02-11T03:48:17Z;NA;467-481;NA;2;50;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER/PLENUM PUBLISHERS Type: Article;NA;NA;NA;NA;"Social robots; Autism; Early childhood; Functional play; Intervention; Joint attention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8XNBQ578;journalArticle;2019;"Carlson, Zachary; Lemmon, Louise; Higgins, MacCallister; Frank, David; Shahrezaie, Roya Salek; Feil-Seifer, David";Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-019-00599-8;NA;"Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable.";2019-12;2021-02-11T03:48:18Z;2021-02-11T03:48:18Z;NA;727-739;NA;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Perception; Human-robot interaction; Human-robot cooperation; Mistreatment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A3EN4ZXX;journalArticle;2019;"Johanson, Deborah L.; Ahn, Ho Seok; MacDonald, Bruce A.; Ahn, Byeong Kyu; Lim, JongYoon; Hwang, Euijun; Sutherland, Craig J.; Broadbent, Elizabeth";The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction: Randomized Controlled Trial;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/13667;NA;Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings.;2019-10-04;2021-02-11T03:48:18Z;2021-02-11T03:48:18Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"engagement; social interaction; robotics; health care robotics; social intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QXK55PE5;journalArticle;2019;"Bloch, Carola; Vogeley, Kai; Georgescu, Alexandra L.; Falter-Wagner, Christine M.";INTRApersonal Synchrony as Constituent of INTERpersonal Synchrony and Its Relevance for Autism Spectrum Disorder;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2019.00073;NA;INTERpersonal synchrony leads to increased empathy, rapport and understanding, enabling successful human-human interactions and reciprocal bonding. Research shows that individuals with Autism Spectrum Disorder (ASD) exhibit difficulties to INTERpersonally synchronize but underlying causes are yet unknown. In order to successfully synchronize with others, INTRApersonal synchronization of communicative signals appears to be a necessary prerequisite. We understand INTRApersonal synchrony as an implicit factor of INTERpersonal synchrony and therefore hypothesize that atypicalities of INTRApersonal synchrony may add to INTERpersonal synchrony problems in ASD and their interaction partners. In this perspective article, we first review evidence for INTERpersonal dissynchrony in ASD, with respect to different approaches and assessment methods. Second, we draft a theoretical conceptualization of INTRApersonal dissynchrony in ASD based on a temporal model of human interaction. We will outline literature indicating INTRApersonal dissynchrony in ASD, therefore highlighting findings of atypical timing functions and findings from clinical and behavioral studies that indicate peculiar motion patterns and communicative signal production in ASD. Third, we hypothesize that findings from these domains suggest an assessment and investigation of temporal parameters of social behavior in individuals with ASD. We will further propose specific goals of empirical approaches on INTRApersonal dissynchrony. Finally we present implications of research on INTRApersonal timing in ASD for diagnostic and therapeutic purposes, what in our opinion warrants the increase of research efforts in this domain.;2019-08-20;2021-02-11T03:48:18Z;2021-02-11T03:48:18Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"human-human interaction; non-verbal behavior; autism spectrum disorder; INTERpersonal synchrony; INTRApersonal synchrony; timing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8YQLHPMD;journalArticle;2019;"Vanman, Eric J.; Kappas, Arvid";“Danger, Will Robinson!” The challenges of social robots for intergroup relations;SOCIAL AND PERSONALITY PSYCHOLOGY COMPASS;NA;1751-9004;10.1111/spc3.12489;NA;Society's increasing reliance on robots in everyday life provides exciting opportunities for social psychologists to work with engineers in the nascent field of social robotics. In contrast to industrial robots that, for example, may be used on an assembly line, social robots are designed specifically to interact with humans and/or other robots. People tend to perceive social robots as autonomous and capable of having a mind. As such, they are also more likely to be subject to social categorization by humans. As social robots become more human like, people may also feel greater empathy for them and treat robots more like (human) ingroup members. On the other hand, as they become more human like, robots also challenge our human distinctiveness, threaten our identity, and elicit suspicion about their ability to deceive us with their human-like qualities. We review relevant research to explore this apparent paradox, particularly from an intergroup relations perspective. We discuss these findings and propose three research questions that we believe social psychologists are ideally suited to address.;2019-08;2021-02-11T03:48:18Z;2021-02-11T03:48:18Z;NA;NA;NA;8;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UJLRAWK8;journalArticle;2019;"Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farne, A.; Dominey, P. F.; Pavani, F.";Embodiment into a robot increases its acceptability;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-019-46528-7;NA;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects' head movements. As a result, participants saw themselves as a robot. When participant' and robot's head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots' humanoid's appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019-07-12;2021-02-11T03:48:19Z;2021-02-11T03:48:19Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JMS2JHYJ;journalArticle;2019;"Rincon, Jaime A.; Costa, Angelo; Novais, Paulo; Julian, Vicente; Carrascosa, Carlos";A new emotional robot assistant that facilitates human interaction and persuasion;KNOWLEDGE AND INFORMATION SYSTEMS;NA;0219-1377;10.1007/s10115-018-1231-9;NA;The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare center in the northern area of Portugal.;2019-07;2021-02-11T03:48:19Z;2021-02-11T03:48:19Z;NA;363-383;NA;1;60;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND Publisher: SPRINGER LONDON LTD Type: Article;NA;NA;NA;NA;"Social robots; Ambient assisted living; Emotional models";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WH4BSWNR;journalArticle;2019;"Fava, Fabricio; Soares, Camila Mangueira; Carvalhais, Miguel";Playful design, empathy and the nonhuman turn;TECHNOETIC ARTS;NA;1477-965X;10.1386/tear_00012_1;NA;In the context of interspecies play involving humans, we find limitations when it comes to understanding most species. One reason for this may be the fact that we tend to anthropomorphize the other to be able to empathize with it. In light of this, how can we infer communication signs of other species so we are able to connect with the nonhuman world? We look for answers to this question by adopting a phenomenological approach that allows us to decentre from the anthropocentric perspective. We highlight animal studies, especially those that extend to them the notion of play, and the studies on interspecies playful interaction conducted in the context of animal- computer interaction. In addition, we propose considering empathy as an interspecies dialogical bridge with nonhumans. Finally, we argue about an expansion of the field of interaction design as an approach to the connection with the nonhuman world.;2019-06;2021-02-11T03:48:19Z;2021-02-11T03:48:19Z;NA;141-154;NA;1-2;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE MILL, PARNALL RD, BRISTOL, BS16 3JG, ENGLAND Publisher: IN℡LECT LTD Type: Article;NA;NA;NA;NA;"empathy; interaction design; interspecies; nonhuman turn; play; playful design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8ESUZYW6;journalArticle;2019;"Perula-Martinez, Raul; Castro-Gonzalez, Alvaro; Malfaz, Maria; Alonso-Martin, Fernando; Salichs, Miguel A.";Bioinspired decision-making for a socially interactive robot;COGNITIVE SYSTEMS RESEARCH;NA;1389-0417;10.1016/j.cogsys.2018.10.028;NA;Nowadays, robots and humans coexist in real settings where robots need to interact autonomously making their own decisions. Many applications require that robots adapt their behavior to different users and remember each user's preferences to engage them in the interaction. To this end, we propose a decision making system for social robots that drives their actions taking into account the user and the robot's state. This system is based on bio-inspired concepts, such as motivations, drives and wellbeing, that facilitate the rise of natural behaviors to ease the acceptance of the robot by the users. The system has been designed to promote the human-robot interaction by using drives and motivations related with social aspects, such as the users' satisfaction or the need of social interaction. Furthermore, the changes of state produced by the users' exogenous actions have been modeled as transitional states that are considered when the next robot's action has to be selected. Our system has been evaluated considering two different user profiles. In the proposed system, user's preferences are considered and alter the homeostatic process that controls the decision making system. As a result, using reinforcement learning algorithms and considering the robot's wellbeing as the reward function, the social robot Mini has learned from scratch two different policies of action, one for each user, that fit the users' preferences. The robot learned behaviors that maximize its wellbeing as well as keep the users engaged in the interactions. (C) 2018 Elsevier B.V. All rights reserved.;2019-05;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;287-301;NA;NA;54;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Human-robot interaction; Artificial motivations; Autonomous robots; Decision making system; Learning behaviors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
V8UKWS3C;journalArticle;2019;"Cross, Emily S.; Riddoch, Katie A.; Pratts, Jaydan; Titone, Simon; Chaudhury, Bishakha; Hortensius, Ruud";A neurocognitive investigation of the impact of socializing with a robot on empathy for pain;PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES;NA;0962-8436;10.1098/rstb.2018.0034;NA;To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue `From social brains to social robots: applying neurocognitive insights to human-robot interaction'.;2019-04-29;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;NA;NA;1771;374;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND Publisher: ROYAL SOC Type: Article;NA;NA;NA;NA;"fMRI; social cognition; empathy; human-robot interaction; social robotics; experience-dependent plasticity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UEHXMLDC;journalArticle;2019;"Alves-Oliveira, Patricia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION;NA;NA;10.1145/3300188;NA;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NTDZATZI;conferencePaper;2019;"Qureshi, Shahnawaz; Hagelback, Johan; Iqbal, Syed Muhammad Zeeshan; Javaid, Hamad; Lindley, Craig A.";Evaluation of Classifiers for Emotion Detection While Performing Physical and Visual Tasks: Tower of Hanoi and IAPS;IN℡LIGENT SYSTEMS AND APPLICATIONS, VOL 1;978-3-030-01054-6 978-3-030-01053-9;NA;10.1007/978-3-030-01054-6_25;NA;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT.;2019;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;347-363;NA;NA;868;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>Intelligent Systems Conference (IntelliSys), London, ENGLAND, SEP 06-07, 2018</p>;NA;NA;NA;"Electroencephalography (EEG); Artificial Neural Networks (ANN); Bayesian Network (BNT); Cognitive psychology; Human Computer Interaction (HCI); K-Nearest Neighbor (KNN); Regression Tree (RT); Support Vector Machine (SVM); Tower of Hanoi (ToH)";Arai, K and Kapoor, S and Bhatia, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EHLGL284;conferencePaper;2019;"Esfandbod, Alireza; Rokhi, Zeynab; Taheri, Alireza; Alemi, Minoo; Meghdari, Ali";Human-Robot Interaction based on Facial Expression Imitation;2019 7TH INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM 2019);978-1-72816-604-9;NA;NA;NA;Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database, which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants' viewpoints on the imitation capability of the robot of 4.1 out of 5.;2019;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;69-73;NA;NA;NA;NA;NA;NA;RSI International Conference on Robotics and Mechatronics ICRoM;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Iran ISSN: 2377-679X Type: Proceedings Paper";<p>7th International Conference on Robotics and Mechatronics (ICRoM), Sharif Univ Technol, Tehran, IRAN, NOV 20-21, 2019</p>;NA;NA;NA;"Human Robot Interaction; Social Robots; Facial Expression Recognition; Convolutional Neural Network; Imitation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
C3UF9LJK;conferencePaper;2019;"Kampman, Onno; Bin Siddique, Farhad; Yang, Yang; Fung, Pascale";Adapting a Virtual Agent to User Personality;ADVANCED SOCIAL INTERACTION WITH AGENTS;978-3-319-92108-2 978-3-319-92107-5;NA;10.1007/978-3-319-92108-2_13;NA;We propose to adapt a virtual agent called `Zara the Supergirl' to user personality. User personality is deducted through two models, one based on raw audio and the other based on speech transcription text. Both models show good performance, with an average F-score of 69.6 for personality perception from audio, and an average F-score of 71.0 for recognition from text. Both models deploy a Convolutional Neural Network. Through a Human-Agent Interaction study we find correlations between user personality and preferred agent personality. The study suggests that especially the Openness user personality trait correlates with a stronger preference for agents with more gentle personality. People also sense more empathy and enjoy better conversations when agents adapt their personalities.;2019;2021-02-11T03:48:20Z;2021-02-11T03:48:20Z;NA;111-118;NA;NA;510;NA;NA;NA;Lecture Notes in Electrical Engineering;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1876-1100 Type: Proceedings Paper;<p>8th International Workshop on Spoken Dialogue Systems (IWSDS), Farmington, PA, JUN 06-09, 2017</p>;NA;NA;NA;"Adaptive virtual agents; Empathetic robots; Personality recognition";Eskenazi, M and Devillers, L and Mariani, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QCGX2ZFB;conferencePaper;2019;"Sripian, Peeraya; Kurono, Yuya; Yoshida, Reiji; Sugaya, Midori";Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals;2019 28TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72812-622-7;NA;NA;NA;Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 1944-9445 Type: Proceedings Paper;<p>28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), New Delhi, INDIA, OCT 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZJG2VIQU;conferencePaper;2019;"Carranza, Karmelo Antonio Lazaro R.; Manalili, Joshua; Bugtai, Nilo T.; Baldovino, Renann G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7TH INTERNATIONAL CONFERENCE ON ROBOT IN℡LIGENCE TECHNOLOGY AND APPLICATIONS (RITA);978-1-72813-118-4;NA;NA;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computat Intelligence Soc; MIR MSREP; Smilegate; WCG; Inst Control Robot & Syst; Daejeon Int Marketing Enterprise; Korea Tourism Org Type: Proceedings Paper";<p>7th International Conference on Robot Intelligence Technology and Applications (RiTA), KAIST, Daejeon, SOUTH KOREA, NOV 01-03, 2019</p>;NA;NA;NA;"deep learning; affective computing; emotionally aware technology; facial expression detection; scripted chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VTQCD4E9;conferencePaper;2019;"Barros, Pablo; Churamani, Nikhil; Lim, Angelica; Wermter, Stefan";The OMG-Empathy Dataset: Evaluating the Impact of Affective Behavior in Storytelling;2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND IN℡LIGENT INTERACTION (ACII);978-1-72813-888-6;NA;NA;NA;Processing human affective behavior is important for developing intelligent agents that interact with humans in complex interaction scenarios. A large number of current approaches that address this problem focus on classifying emotion expressions by grouping them into known categories. Such strategies neglect, among other aspects, the impact of the affective responses from an individual on their interaction partner thus ignoring how people empathize towards each other. This is also reflected in the datasets used to train models for affective processing tasks. Most of the recent datasets, in particular, the ones which capture natural interactions (”in-the-wild” datasets), are designed, collected, and annotated based on the recognition of displayed affective reactions, ignoring how these displayed or expressed emotions are perceived. In this paper, we propose a novel dataset composed of dyadic interactions designed, collected and annotated with a focus on measuring the affective impact that eight different stories have on the listener. Each video of the dataset contains around 5 minutes of interaction where a speaker tells a story to a listener. After each interaction, the listener annotated, using a valence scale, how the story impacted their affective state, reflecting how they empathized with the speaker as well as the story. We also propose different evaluation protocols and a baseline that encourages participation in the advancement of the field of artificial empathy and emotion contagion.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;NA;NA;NA;NA;NA;NA;NA;International Conference on Affective Computing and Intelligent Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2156-8103 Type: Proceedings Paper;<p>8th International Conference on Affective Computing and Intelligent Interaction (ACII), Cambridge, ENGLAND, SEP 03-06, 2019</p>;NA;NA;NA;"Empathy; Affective Behaviour; Dyadic Interactions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SXM3GVEG;conferencePaper;2019;"Costantini, Stefania; De Gasperis, Giovanni; Migliarini, Patrizio";Multi-agent System Engineering for Emphatic Human-Robot Interaction;2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL IN℡LIGENCE AND KNOWLEDGE ENGINEERING (AIKE);978-1-72811-488-0;NA;10.1109/AIKE.2019.00015;NA;Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;36-42;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE COMPUTER SOC;10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc Type: Proceedings Paper";<p>2nd IEEE International Conference on Artificial Intelligence and Knowledge Engineering (AIKE), Cagliari, ITALY, JUN 03-05, 2019</p>;NA;NA;NA;"perception; emotions; communication; empathy; affect; human robot interaction; logic";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BZQKK4CQ;conferencePaper;2019;"Mallol-Ragolta, Adria; Schmitt, Maximilian; Baird, Alice; Cummins, Nicholas; Schuller, Bjoern";Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual ( OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient ( CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;721-725;NA;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YBGMHTKM;conferencePaper;2019;"Peterson, Jordan; Cohen, Chase; Harrison, Paige; Novak, Jonathan; Tossell, Chad; Phillips, Elizabeth";Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming;2019 SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS);978-1-72810-998-5;NA;NA;NA;The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;170-175;NA;NA;NA;NA;NA;NA;IEEE Systems and Information Engineering Design Symposium;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2639-7439 Type: Proceedings Paper;<p>Systems and Information Engineering Design Symposium (SIEDS), Univ Virginia, Charlottesville, VA, APR 26, 2019</p>;NA;NA;NA;"Human-robot interaction; Human-machine teaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
N9TI662R;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019);978-1-4503-6287-0;NA;10.1145/3313991.3314018;NA;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;102-108;NA;NA;NA;NA;NA;NA;International Conference on Computer and Automation Engineering;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2154-4352 Type: Proceedings Paper;<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ET8IXWIK;journalArticle;2019;"Sejima, Yoshihiro; Egawa, Shoichi; Sato, Yoichiro; Watanabe, Tomio";A pupil response system using hemispherical displays for enhancing affective conveyance;JOURNAL OF ADVANCED MECHANICAL DESIGN SYSTEMS AND MANUFACTURING;NA;1881-3054;10.1299/jamdsm.2019jamdsm0032;NA;In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker's affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot's eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance.;2019;2021-02-11T03:48:21Z;2021-02-11T03:48:21Z;NA;NA;NA;2;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: SHINANOMACHI-RENGAKAN BLDG., SHINANOMACHI 35, SHINJUKU-KU, TOKYO, 160-0016, JAPAN Publisher: JAPAN SOC MECHANICAL ENGINEERS Type: Article;NA;NA;NA;NA;"Empathy; Human interface; Human-robot interaction design; Kansei and affective engineering; Media representation; Pupil response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JCQD6KM3;conferencePaper;2019;Vertesi, Janet;Seeing Like a Rover: Team Work and Human-robot Relations;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.;2019;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;152;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"Teamwork; Human-Robot Interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y6S8F7CN;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodriguez, Veronica";Good Robot Design or Machiavellian? An in-the-wild robot leveraging minimal knowledge of passersby's culture;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people ( changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;382-391;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GA9AIZDP;conferencePaper;2019;"Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amelie; Lefort, Mathieu; Hassas, Salima";The RoPE Scale: a Measure of How Empathic a Robot is Perceived;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.;2019;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;656-657;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"Psychometrics; Human-Robot Interaction; Perceived Empathy; Social Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KCCR3QKX;conferencePaper;2019;"Daly, Joseph E.; Bremner, Paul; Leonards, Ute";Robots in Need: Acquiring Assistance with Emotion;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;There will always be occasions where robots require assistance from humans. Understanding what motivates people to help a robot, and what effect this interaction has on an individual will be essential in successfully integrating robots into our society. Emotions are important in motivating prosocial behavior between people, and therefore may also play a large role in human-robot interaction. This research explores the role of emotion in motivating people to help a robot and some of the ethical issues that arise as a result, with the ultimate aim of developing suitable methods for robots to interact with humans to acquire assistance.;2019;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;706-708;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"emotion; empathy; human-robot interaction; prosocial behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Q4FZHLGC;journalArticle;2019;"Xefteris, Stefanos; Palaigeorgiou, George";Mixing Educational Robotics, Tangibles and Mixed Reality Environments for the Interdisciplinary Learning of Geography and History;INTERNATIONAL JOURNAL OF ENGINEERING PEDAGOGY;NA;2192-4880;10.3991/ijep.v9i2.9950;NA;In the present study we present a mixed reality learning environment that aims to become a creative, joyful and efficient interdisciplinary canvas for learning about history and geography and for concurrently fostering computational thinking. The environment makes use of embodied affordances and educational robotics and consists of two parts: an augmented 3D-tangible model of southern Europe with finger-based interaction and a second floor-based augmented robotics track depicting European landmarks, where students are asked to perform tasks with Mindstorms EV3 robots. The game scenario describes a treasure hunt around Europe and students swap between finger-based and robotics-based interactive surfaces in two pairs. We evaluated our intervention with pre-service teachers in six groups of three or four who played with the environment for approximately 45 minutes each. Data collection was performed through pre- and post-knowledge test, attitude questionnaire and a semi-formal group interview. The answers showed that the mixed reality environment improved motivation, engagement and enhanced their orientation around Europe's geophysical features. The robotics aspect consolidated further their computational thinking skills while being highly exciting. The proposed approach was closer to the preservice teacher's expectations and interactive experiences, exploited embodied learning opportunities and gamified the learning process.;2019;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;78-94;NA;2;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: DIAGONALE 10, D-34127 KASSEL, GERMANY Publisher: KASSEL UNIV PRESS GMBH Type: Article;NA;NA;NA;NA;"educational robotics; geography learning; history learning; Mixed reality; tangible interfaces";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KVKN8CFD;journalArticle;2018;"Obaid, Mohammad; Aylett, Ruth; Barendregt, Wolmet; Basedow, Christina; Corrigan, Lee J.; Hall, Lynne; Jones, Aidan; Kappas, Arvid; Kuester, Dennis; Paiva, Ana; Papadopoulos, Fotios; Serholt, Sofia; Castellano, Ginevra";Endowing a Robotic Tutor with Empathic Qualities: Design and Pilot Evaluation;INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS;NA;0219-8436;10.1142/S0219843618500251;NA;As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions.;2018-12;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;NA;NA;6;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type: Article;NA;NA;NA;NA;"children; education; empathy; Robot; tutor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5AKUM7QG;journalArticle;2018;"Swiderska, Aleksandra; Kuester, Dennis";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;PERCEPTION;NA;0301-0066;10.1177/0301006618809919;NA;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.;2018-12;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;1139-1152;NA;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"pain; robots; empathy; mind perception; anthropomorphism; harm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7M7C2PGR;journalArticle;2018;"Bigman, Yochanan E.; Gray, Kurt";People are averse to machines making moral decisions;COGNITION;NA;0010-0277;10.1016/j.cognition.2018.08.003;NA;Do people want autonomous machines making moral decisions? Nine studies suggest that that the answer is `no'-in part because machines lack a complete mind. Studies 1-6 find that people are averse to machines making morally-relevant driving, legal, medical, and military decisions, and that this aversion is mediated by the perception that machines can neither fully think nor feel. Studies 5-6 find that this aversion exists even when moral decisions have positive outcomes. Studies 7-9 briefly investigate three potential routes to increasing the acceptability of machine moral decision-making: limiting the machine to an advisory role (Study 7), increasing machines' perceived experience (Study 8), and increasing machines' perceived expertise (Study 9). Although some of these routes show promise, the aversion to machine moral decision-making is difficult to eliminate. This aversion may prove challenging for the integration of autonomous technology in moral domains including medicine, the law, the military, and self-driving vehicles.;2018-12;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;21-34;NA;NA;181;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Robots; Morality; Mind perception; Autonomous machines; Moral agency; Skynet";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FCCU74GB;journalArticle;2018;Holbrook, Colin;Cues of Violent Intergroup Conflict Diminish Perceptions of Robotic Personhood;ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS;NA;2160-6455;10.1145/3181674;NA;"Convergent lines of evidence indicate that anthropomorphic robots are represented using neurocognitive mechanisms typically employed in social reasoning about other people. Relatedly, a growing literature documents that contexts of threat can exacerbate coalitional biases in social perceptions. Integrating these research programs, the present studies test whether cues of violent intergroup conflict modulate perceptions of the intelligence, emotional experience, or overall personhood of robots. In Studies 1 and 2, participants evaluated a large, bipedal all-terrain robot; in Study 3, participants evaluated a small, social robot with humanlike facial and vocal characteristics. Across all studies, cues of violent conflict caused significant decreases in perceived robotic personhood, and these shifts were mediated by parallel reductions in emotional connection with the robot (with no significant effects of threat on attributions of intelligence/skill). In addition, in Study 2, participants in the conflict condition estimated the large bipedal robot to be less effective in military combat, and this difference was mediated by the reduction in perceived robotic personhood. These results are discussed as they motivate future investigation into the links among threat, coalitional bias and human-robot interaction.";2018-11;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;NA;NA;4;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"Theory of Mind; empathy; human-robot interaction; group prejudice; Threat detection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UN574PJ7;journalArticle;2018;"Puetten, Astrid M. Rosenthal-von der; Kraemer, Nicole C.; Herrmann, Jonathan";The Effects of Humanlike and Robot-Specific Affective Nonverbal Behavior on Perception, Emotion, and Behavior;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-018-0466-7;NA;"Research demonstrated that humans are able to interpret humanlike (affective) nonverbal behavior (HNB) in artificial entities (e.g. Beck et al., in: Proceedings of the 19th IEEE international symposium on robot and human interactive communication, IEEE Press, Piscataway, 2010. 10.1109/ROMAN.2010.5598649; Bente et al. in J Nonverbal Behav 25: 151-166, 2001; Mumm and Mutlu, in: Proceedings of the 6th international conference on human-robot interaction, HRI. ACM Press, New York, 2011. 10.1145/1957656.1957786). However, some robots lack the possibility to produce HNB. Using robot-specific nonverbal behavior (RNB) such as different eye colors to convey emotional meaning might be a fruitful mechanism to enhance HRI experiences, but it is unclear whether RNB is as effective as HNB. We present a review on affective nonverbal behaviors in robots and an experimental study. We experimentally tested the influence of HNB and RNB (colored LEDs) on users' perception of the robot (e.g. likeability, animacy), their emotional experience, and self-disclosure. In a between-subjects design, users interacted with either (a) a robot displaying no nonverbal behavior, (b) a robot displaying affective RNB, (c) a robot displaying affective HNB or (d) a robot displaying affective HNB and RNB. Results show that HNB, but not RNB, has a significant effect on the perceived animacy of the robot, participants' emotional state, and self-disclosure. However, RNB still slightly influenced participants' perception, emotion, and behavior: Planned contrasts revealed having any type of nonverbal behavior significantly increased perceived animacy, positive affect, and self-disclosure. Moreover, observed linear trends indicate that the effects increased with the addition of nonverbal behaviors (control< RNB< HNB). In combination, our results suggest that HNB is more effective in transporting the robot's communicative message than RNB.";2018-11;2021-02-11T03:48:22Z;2021-02-11T03:48:22Z;NA;569-582;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Affective nonverbal behavior; Emotional state; Experimental study; Humanoid robot; Self-disclosure";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5N9HHW2S;journalArticle;2018;"Giannopulu, Irini; Terada, Kazunori; Watanabe, Tomio";Emotional Empathy as a Mechanism of Synchronisation in Child-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2018.01852;NA;Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation.;2018-10-16;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"child; emotional empathy; heart rate; interactor robot; synchronisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MJC64FYY;journalArticle;2018;"Liu, Bingjie; Sundar, S. Shyam";Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot;CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING;NA;2152-2715;10.1089/cyber.2018.0110;NA;When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N=158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N=88) interacted with a real chatbot. We tested the effect of three types of empathic expressionsympathy, cognitive empathy, and affective empathyon individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed.;2018-10;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;625-636;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA Publisher: MARY ANN LIEBERT, INC Type: Article;NA;NA;NA;NA;"empathy; human-robot interaction; CASA; sympathy; uncanny valley";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6TXI7ENA;journalArticle;2018;"Clinton, Michael; Madi, Murielle; Doumit, Myrna; Ezzeddine, Sawsan; Rizk, Ursula";“My Greatest Fear Is Becoming a Robot”: The Paradox of Transitioning to Nursing Practice in Lebanon;SAGE OPEN;NA;2158-2440;10.1177/2158244018782565;NA;We investigated the challenges final-year nursing students (FYNSs) and first-year registered nurses (FYRNs) face as they transition to nursing practice in Lebanon. Our purpose was to understand the challenges of transition from the perspective of FYNS and FYRNs. We conducted focus group discussions with FYNSs and FYRNs recruited from four leading universities. Thematic analysis identified an unexpected paradox that has implications for quality of nursing care and retention of graduates. While humanoids are marketed to communicate empathically with patients, FYNSs in Lebanon struggle to resist becoming robots.;2018-06-18;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;NA;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"education; empathy; technology; nursing; robotics; assistive; coping; trends";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UVHRV3YM;journalArticle;2018;Coeckelbergh, Mark;Why Care About Robots? Empathy, Moral Standing, and the Language of Suffering;KAIROS-JOURNAL OF PHILOSOPHY & SCIENCE;NA;1647-659X;10.2478/kjps-2018-0007;NA;This paper tries to understand the phenomenon that humans are able to empathize with robots and the intuition that there might be something wrong with “abusing” robots by discussing the question regarding the moral standing of robots. After a review of some relevant work in empirical psychology and a discussion of the ethics of empathizing with robots, a philosophical argument concerning the moral standing of robots is made that questions distant and uncritical moral reasoning about entities' properties and that recommends first trying to understand the issue by means of philosophical and artistic work that shows how ethics is always relational and historical, and that highlights the importance of language and appearance in moral reasoning and moral psychology. It is concluded that attention to relationality and to verbal and non-verbal languages of suffering is key to understand the phenomenon under investigation, and that in robot ethics we need less certainty and more caution and patience when it comes to thinking about moral standing.;2018-06;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;141-158;NA;1;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: DE GRUYTER POLAND SP Z O O, BOGUMILA ZUGA 32A STR, 01-811 WARSAW, POLAND Publisher: SCIENDO Type: Article;NA;NA;NA;NA;"robots; empathy; language; phenomenology; art; hermeneutics; moral standing; relations; Wittgenstein";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JNPXQWLG;journalArticle;2018;"Menne, Isabelle M.; Schwab, Frank";Faces of Emotion: Investigating Emotional Facial Expressions Towards a Robot;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-017-0447-2;NA;Emotions have always been an intriguing topic in everyday life as well as in science. As robots are starting to move from industry halls to our private homes, emotions have become a vital theme for the field of human-robot interaction. Since Darwin, research suggests facial expressions are associated with emotions. Facial expressions could provide an ideal tool for a natural, social human-robot interaction. Despite a growing body of research on the implementation of emotions in robots (mostly based on facial expressions), systematic research on users' emotions and facial expressions towards robots remains largely neglected (cf. Arkin and Moshkina in Calvo R, D'Mello S, Gratch J, Kappas A (eds) The Oxford handbook of affective computing. Oxford University Press, New York, pp 483-493, 2015 on challenges in effective testing in affective human-robot interaction). We experimentally investigated the multilevel phenomenon of emotions by using a multi-method approach. Since self-reports of emotions are prone to biases such as social desirability, we supplemented it by an objective behavioral measurement. By using the Facial Action Coding System we analyzed the facial expressions of 62 participants who watched the entertainment robot dinosaur Pleo either in a friendly interaction or being tortured. Participants differed in the type and frequency of Action Units displayed as well as in their self-reported feelings depending on the type of treatment they had watched (friendly or torture). In line with a previous study by Rosenthal-von der Putten et al. (Int J Soc Robot 5(1):17-34, 2013. https://doi.org/10.1007/s12369-012-0173-8), participants reported feeling more positive after the friendly video and more negative after the torture video. In the torture condition, participants furthermore showed a wide range of different Action Units primarily associated with negative emotions. For example, the Action Unit 4 (”Brow Lowerer”) that is common in negative emotions such as anger and sadness was displayed more frequently in the torture condition than in the friendly condition. The Action Unit 12 (”Lip Corner Puller”) however, an Action Unit commonly associated with joy, was present in both conditions and thus not necessarily predictive of positive emotions. The findings indicate the importance for a thorough investigation of the variables of emotional facial expressions. In investigating the Action Units participants display due to an emotional situation, we aim to provide information on spontaneous facial expressions towards a robot that could also serve as guidance for automatic approaches.;2018-04;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;199-209;NA;2, SI;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Emotion; Empathy; Human-robot interaction; Emotional response; Facial Action Coding System; Facial expression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GAE6NBWJ;conferencePaper;2018;"Kuehnlenz, Barbara; Busse, Fabian; Foertsch, Pascal; Wolf, Maximilian; Kuehnlenz, Kolja";Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.;2018;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;275-281;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2ILQUJFY;conferencePaper;2018;"James, Jesin; Watson, Catherine Inez; MacDonald, Bruce";Artificial Empathy in Social Robots: An analysis of Emotions in Speech;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.;2018;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;632-637;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E55EJUNI;conferencePaper;2018;"Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H.";Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.;2018;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;783-789;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
N7ITEFVP;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor";He who hesitates is lost (...in thoughts over a robot);PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18);978-1-4503-5420-2;NA;10.1145/3183654.3183703;NA;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.;2018;2021-02-11T03:48:23Z;2021-02-11T03:48:23Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Amer Psychol Assoc Type: Proceedings Paper;<p>Technology, Mind, and Society Conference (TechMindSociety), Washington, DC, APR 05-07, 2018</p>;NA;NA;NA;"Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SJQJTMDE;conferencePaper;2018;"Tan, Xiang Zhi; Vazquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron";Inducing Bystander Interventions During Robot Abuse with Social Mechanisms;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171247;NA;We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant's performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;169-177;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"robots; empathy; Human-robot interaction; abuse; bullying; peer intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ICYTARDF;conferencePaper;2018;"Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana";Group-based Emotions in Teams of Humans and Robots;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171252;NA;Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;261-269;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"emotion; trust; group effects; Human-robot teamwork; identification; inter-group interactions; self-categorisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5WWD8P4B;conferencePaper;2018;"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea";Counseling Robot Implementation and Evaluation;2018 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC);978-1-5386-6650-0;NA;10.1109/SMC.2018.00297;NA;A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called “unazuki” in Japanese, a kind of nodding to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared according several subjective feelings by the evaluation subjects.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;1716-1722;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Sci Council Japan ISSN: 1062-922X Type: Proceedings Paper";"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE Syst Man &amp; Cybernet Soc, Miyazaki, JAPAN, OCT 07-10, 2018</p>";NA;NA;NA;"Robot; Counseling; Dialog Promotion; Nodding; unazuki";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IMJHW7EZ;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Tossell, Chad";Band of Brothers and Bolts: Caring About Your Robot Teammate;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;1853-1858;NA;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3MCBYNI2;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;2008-2013;NA;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KSCFXDBM;conferencePaper;2018;"Sancar, Ayse E.; Sonmez, Elena Battini";A Model for an Emotional Respondent Robot;ADVANCES IN SIGNAL PROCESSING AND IN℡LIGENT RECOGNITION SYSTEMS;978-3-319-67934-1 978-3-319-67933-4;NA;10.1007/978-3-319-67934-1_37;NA;The aim of this study is to design an emotional regulation model based on facial expressions. It is argued that emotions serve a critical function in intelligent behavior and some researchers posed the questions of whether a robot could be intelligent without emotions. As a result, emotion recognition and adequate reaction are essential requirements for enhancing the quality of human robot interaction. This study proposes a computational model of emotion capable of clustering the perceived facial expression, and using cognitive reappraisal to switch its internal state so as to give a human-like reaction over the time. That is, the agent learns the person's facial expression by using Self Organizing Map, and gives it a meaning by mapping the perceived expression into its internal state diagram. As a result, the presented model implements empathy with the aim to enhance human-robot communication.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;406-416;NA;NA;678;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Liverpool John Moores Univ ISSN: 2194-5357 Type: Proceedings Paper;<p>3rd International Symposium on Signal Processing and Intelligent Recognition Systems (SIRS), Manipal Univ, Manipal Inst Technol, Manipal, INDIA, SEP 13-16, 2017</p>;NA;NA;NA;NA;Thampi, SM and Krishnan, S and Corchado Rodriguez, JM and Das, S and Wozniak, M and Al-Jumeily, D;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JLV6RIYN;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression;2018 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS (UR);978-1-5386-6334-9;NA;NA;NA;Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;377-382;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>15th International Conference on Ubiquitous Robots (UR), Honolulu, HI, JUN 26-30, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SMQY89SV;conferencePaper;2018;"Gil Iranzo, Rosa M.; Padilla-Zea, Natalia; Paderewski-Rodriguez, Patricia; Gonzalez-Gonzalez, Carina S.";Empathy and Virtual Agents for Learning Applications in Symbiotic Systems;PROCEEDINGS OF 2018 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE (EDUCON) - EMERGING TRENDS AND CHALLENGES OF ENGINEERING EDUCATION;978-1-5386-2957-4;NA;NA;NA;Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges.;2018;2021-02-11T03:48:24Z;2021-02-11T03:48:24Z;NA;694-697;NA;NA;NA;NA;NA;NA;IEEE Global Engineering Education Conference;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Coplaca; Fuentealta; Soc Desarrollo Ayuntamiento Tenerife; Grupo Visual Canarias; MathWorks; Cypress; Pentec Blackboard; UNIR iTED ISSN: 2165-9567 Type: Proceedings Paper";<p>IEEE Global Engineering Education Conference (EDUCON) - Emerging Trends and Challenges of Engineering Education, Santa Cruz de Tenerife, SPAIN, APR 17-20, 2018</p>;NA;NA;NA;"ethics; empathy; robot; bot; symbiotic agents; transparency";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GAP9JVSV;conferencePaper;2018;"Kohori, Tomoko; Hirayama, Shiho; Hara, Takenori; Muramatsu, Michiko; Naganuma, Hiroyuki; Yamano, Masayuki; Ichikawa, Kazuko; Matsumoto, Hiroko; Uchiyama, Hiroko";Development and Evaluation of an Interactive Therapy Robot;ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY, ACE 2017;978-3-319-76270-8 978-3-319-76269-2;NA;10.1007/978-3-319-76270-8_6;NA;Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;66-83;NA;NA;10714;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Multimodal Technologies & Interact Journal ISSN: 0302-9743 Type: Proceedings Paper;<p>14th International Conference on Advances in Computer Entertainment Technology (ACE), London, ENGLAND, DEC 14-16, 2017</p>;NA;NA;NA;"Healing elements Therapeutic robots designed to communicate with humans; Therapeutic effect";Cheok, AD and Inami, M and Romao, T;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
24HQRX9S;journalArticle;2018;"Anshar, Muh; Williams, Mary-Anne";Evolving robot empathy towards humans with motor disabilities through artificial pain generation;AIMS NEUROSCIENCE;NA;2373-8006;10.3934/Neuroscience.2018.1.56;NA;In contact assistive robots, a prolonged physical engagement between robots and humans with motor disabilities due to shoulder injuries, for instance, may at times lead humans to experience pain. In this situation, robots will require sophisticated capabilities, such as the ability to recognize human pain in advance and generate counter-responses as follow up emphatic action. Hence, it is important for robots to acquire an appropriate pain concept that allows them to develop these capabilities. This paper conceptualizes empathy generation through the realization of synthetic pain classes integrated into a robot's self-awareness framework, and the implementation of fault detection on the robot body serves as a primary source of pain activation. Projection of human shoulder motion into the robot arm motion acts as a fusion process, which is used as a medium to gather information for analyses then to generate corresponding synthetic pain and emphatic responses. An experiment is designed to mirror a human peer's shoulder motion into an observer robot. The results demonstrate that the fusion takes place accurately whenever unified internal states are achieved, allowing accurate classification of synthetic pain categories and generation of empathy responses in a timely fashion. Future works will consider a pain activation mechanism development.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;56-73;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 2604, SPRINGFIELD, MO 65801-2604 USA Publisher: AMER INST MATHEMATICAL SCIENCES-AIMS Type: Article;NA;NA;NA;NA;"assistive robots; cognitive; empathic reaction; joint position; shoulder motion; synthetic pain";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7ZLDN4SC;journalArticle;2018;Korac, Srdan T.;DEPERSONALISATION OF KILLING Towards A 21st Century Use Of Force “Beyond Good And Evil?”;PHILOSOPHY AND SOCIETY-FILOZOFIJA I DRUSTVO;NA;0353-5738;10.2298/FID1801049K;NA;The article analyses how robotisation as the latest advance in military technology can depersonalise the methods of killing in the 21st century by turning enemy soldiers and civilians into mere objects devoid of moral value. The departing assumption is that robotisation of warfare transforms military operations into automated industrial processes with the aim of removing empathy as a redundant `cost'. The development of autonomous weapons systems raises a number of sharp ethical controversies related to the projected moral insensitivity of robots regarding the treatment of enemies and civilian population. The futurist vision of war as a foreign policy instrument entirely `purified' of the risk of morally wrong actions is in opposition with the negative effects of the use of drones. The author concludes that the use of lethal robots in combat would eventually remove enemy soldiers and civilians from the realm of ethical reasoning and deprive them of human dignity. Decision to kill in military operations ought to be based on human conscience as the only proper framework of making decisions by reasoning whether an action is right or wrong.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;49-64;NA;1;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: KRALJICE NATALIJE 45, BELGRADE, 11000, SERBIA Publisher: UNIV BELGRADE, INST PHILOSOPHY & SOCIAL THEORY Type: Article;NA;NA;NA;NA;"autonomous weapons systems; depersonalisation; drones; ethics of war; international relations; lethal robots; military interventions; warfare";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9LG4W63N;journalArticle;2018;"Barakova, E. I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.";Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot;CONNECTION SCIENCE;NA;0954-0091;10.1080/09540091.2017.1350938;NA;In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game - the game with the robot was seen as more challenging and the robot - as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;81-98;NA;1, SI;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"combining social and game strategy; Economic game strategies for robots; engagement robot/computer; long-term relations with robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
J7K4M83M;conferencePaper;2018;"Churamani, Nikhil; Banos, Pablo; Strahl, Erik; Wermter, Stefan";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6014-6;NA;NA;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2161-4393 Type: Proceedings Paper;<p>International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, BRAZIL, JUL 08-13, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VXE8UD3V;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-02-11T03:48:25Z;2021-02-11T03:48:25Z;NA;173-193;NA;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BPN826A2;conferencePaper;2018;"Chen, Aqua Chuan-Yu; Lin, Yu-Cheng";Warm Robot Classroom_Using Wearable Technology as a Gateway to Culturally Responsive Teaching;LEARNING AND COLLABORATION TECHNOLOGIES: LEARNING AND TEACHING, LCT 2018, PT II;978-3-319-91152-6 978-3-319-91151-9;NA;10.1007/978-3-319-91152-6_19;NA;[Warm Robot classroom] is related to answer the question of introduce computational thinking teaching aids and course design by studies robots and wearables with social humanity. The discussion is about how to cultivate students with the rational technology thinking and humanity empathy? The research method includes design and research on cultural response teaching curriculum with the composition of product designers and electronic engineers, planning of teaching contents, and solicitation of teaching and learning of cultural responses from more than five kinds of different cultural backgrounds through the a one semester course. Develop the performances from different cultural groups through 3D printing, laser cutting and digital embroidery creations and assess the applicability of course design. This course was held with 64 participants (9 different countries, 5 backgrounds). We describe our experience in designing and organizing a wearable course. We will show that (1) Three interactive modules of difficult levels of soft wearable prototypes. (2) The culturally responsive curriculum. (3) The learning outcome of the teaching implementations with interactive toolkits from the final performance. The result shows that curriculum with different background works together can built students from either side to response to each other.;2018;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;239-253;NA;NA;10925;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>5th International Conference on Learning and Collaboration Technologies (LCT) Held as Part of 20th International Conference on Human-Computer Interaction (HCI International), Las Vegas, NV, JUL 15-20, 2018</p>;NA;NA;NA;"Cultural issues in learning with collaboration technologies; Interactive design; Smart textiles; Wearable technology";Zaphiris, P and Ioannou, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
N6V7UL7E;conferencePaper;2018;"Bogatyreva, Anastasia A.; Sovkov, Andrei D.; Tikhomirova, Svetlana A.; Vinogradova, Anna R.; Samsonovich, Alexei V.";Virtual pet powered by a socially-emotional BICA;POSTPROCEEDINGS OF THE 9TH ANNUAL INTERNATIONAL CONFERENCE ON BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES (BICA 2018);NA;NA;10.1016/j.procs.2018.11.101;NA;Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents. (C) 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the scientific committee of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures.;2018;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;564-571;NA;NA;145;NA;NA;NA;Procedia Computer Science;NA;NA;NA;ELSEVIER;Radarweg 29, PO Box 211, AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Biologically Inspied Cognit Architectures Soc; GoodAI; Whole Brain Architecture Initiat; Czech Tech Univ ISSN: 1877-0509 Type: Proceedings Paper";<p>9th Annual International Conference of the Biologically-Inspired-Cognitive-Architectures-Society (BICA) held as part of the Joint Multi-Conference on Human-Level Artificial Intelligence (HLAI), Czech Tech Univ, Prague, CZECH REPUBLIC, AUG 22-24, 2018</p>;NA;NA;NA;"emotional intelligence; virtual character; cognitive architecture; reinforcement learning; semantic space";Samsonovich, AV and Lebiere, CJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4RA968LQ;journalArticle;2018;"Vallverdu, Jordi; Nishida, Toyoaki; Ohmoto, Yoshisama; Moran, Stuart; Lazare, Sarah";Fake Empathy and Human-Robot Interaction (HRI): A Preliminary Study;INTERNATIONAL JOURNAL OF TECHNOLOGY AND HUMAN INTERACTION;NA;1548-3908;10.4018/IJTHI.2018010103;NA;Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call `fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different `humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi-angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment.;2018-03;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;44-59;NA;1;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type: Article;NA;NA;NA;NA;"Emotions; Empathy; Robots; Human-Robot Interaction; Fake; HRI; WOZ";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TL32XQW4;journalArticle;2017;"Chikaraishi, Takenobu; Yoshikawa, Yuichiro; Ogawa, Kohei; Hirata, Oriza; Ishiguro, Hiroshi";Creation and Staging of Android Theatre “Sayonara” towards Developing Highly Human-Like Robots;FUTURE INTERNET;NA;1999-5903;10.3390/fi9040075;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017-12;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI AG Type: Article;NA;NA;NA;NA;"social robots; android theatre; contemporary colloquial theatre theory; robot theatre";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MBHUXLNA;journalArticle;2017;"Borenstein, Jason; Arkin, Ronald C.";Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior;AI & SOCIETY;NA;0951-5666;10.1007/s00146-016-0684-1;NA;"An under-examined aspect of human-robot interaction that warrants further exploration is whether robots should be permitted to influence a user's behavior for that person's own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user's behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user's empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be.";2017-11;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;499-507;NA;4;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Charity; Companion robots; Design ethics; Nudges; Robot ethics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
D6VSPKAX;journalArticle;2017;"Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke";Empathy in Virtual Agents and Robots: A Survey;ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS;NA;2160-6455;10.1145/2912150;NA;This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user's or another agent's emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent's situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.;2017-10;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;NA;NA;3;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"virtual agents; empathy; affective computing; human-computer interaction; human-robot interaction; social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PXGPE2MN;journalArticle;2017;"Abubshait, Abdulaziz; Wiese, Eva";You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.01393;NA;Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed.;2017-08-23;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"intentionality; social cognition; human-robot interaction; social robotics; mind perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YP2GKQ54;journalArticle;2017;"Leite, Iolanda; McCoy, Marissa; Lohani, Monika; Ullman, Daniel; Salomons, Nicole; Stokes, Charlene; Rivers, Susan; Scassellati, Brian";Narratives with Robots: The Impact of Interaction Context and Individual Differences on Story Recall and Emotional Understanding;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2017.00029;NA;Role-play scenarios have been considered a successful learning space for children to develop their social and emotional abilities. In this paper, we investigate whether socially assistive robots in role-playing settings are as effective with small groups of children as they are with a single child and whether individual factors such as gender, grade level (first vs. second), perception of the robots (peer vs. adult), and empathy level (low vs. high) play a role in these two interaction contexts. We conducted a three-week repeated exposure experiment where 40 children interacted with socially assistive robotic characters that acted out interactive stories around words that contribute to expanding children's emotional vocabulary. Our results showed that although participants who interacted alone with the robots recalled the stories better than participants in the group condition, no significant differences were found in children's emotional interpretation of the narratives. With regard to individual differences, we found that a single child setting appeared more appropriate to first graders than a group setting, empathy level is an important predictor for emotional understanding of the narratives, and children's performance varies depending on their perception of the robots (peer vs. adult) in the two conditions.;2017-07-12;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;1-14;NA;NA;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"emotional intelligence; socially assistive robotics; individual differences; multiparty interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A4BEL4DX;journalArticle;2017;"Rouaix, Natacha; Retru-Chavastel, Laure; Rigaud, Anne-Sophie; Monnet, Clotilde; Lenoir, Hermine; Pino, Maribel";Affective and Engagement Issues in the Conception and Assessment of a Robot-Assisted Psychomotor Therapy for Persons with Dementia;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.00950;NA;"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a “control software” for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient-therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction.";2017-06-30;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"engagement; social robots; control software; dementia; geriatrics; psychomotor therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MYJ4RAQ6;journalArticle;2017;"Slomian, Justine; Emonts, Patrick; Vigneron, Lara; Acconcia, Alessandro; Reginster, Jean-Yves; Oumourgh, Mina; Bruyere, Olivier";Meeting the Needs of Mothers During the Postpartum Period: Using Co-Creation Workshops to Find Technological Solutions;JMIR RESEARCH PROTOCOLS;NA;1929-0748;10.2196/resprot.6831;NA;Background: The postnatal period is associated with many new needs for mothers. Objective: The aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth. Methods: Two co-creation workshops were undertaken with parents and professionals. The aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth. The aim of the second workshop was to create solutions in response to the criteria selected during the first workshop. Results: Parents and health professionals want solutions that include empathy (ie, to help fight against the feelings of abnormality and loneliness), that help mothers in daily life, that are personalized and adapted to different situations, that are educational, and that assures some continuity in their contact with health professionals. In practice, we found that parents and professionals think the solution should be accessible to everyone and available at all times. To address these criteria, technology experts proposed different solutions, such as a forum dedicated to the postpartum period that is supervised by professionals, a centralized website, a system of videoconferencing, an online exchange group, a “gift voucher” system, a virtual reality app, or a companion robot. Conclusions: The human component seems to be very important during the postnatal period. Nevertheless, technology could be a great ally in helping mothers during the postpartum period. Technology can help reliably inform parents and may also give them the right tools to find supportive people. However, these technologies should be tested in clinical trials.;2017-05;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;NA;NA;5;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"co-creating workshop; co-creation; mothers' needs; postpartum needs; technological solutions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LK7HXVPA;journalArticle;2017;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe";Simulating empathic behavior in a social assistive robot;MULTIMEDIA TOOLS AND APPLICATIONS;NA;1380-7501;10.1007/s11042-016-3797-0;NA;When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user's affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot's affective state and, consequently, the most appropriate empathic behavior. The robot's empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.;2017-02;2021-02-11T03:48:26Z;2021-02-11T03:48:26Z;NA;5073-5094;NA;4;76;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Social assistive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
W7N4SRK8;conferencePaper;2017;"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto";Design of Counseling Robot for production by 3D printer;2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS);978-1-5386-4283-2;NA;10.1109/SITIS.2017.20;NA;Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;56-62;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Comp Soc; Malaviya Natl Inst Technol; Univ Bourgogne; Univ Milan; Univ Bourgogne, Lab Electronique Image Informatique Res Grp; Natl Res Ctr Italy, Inst High Performance Comp & Networking; Govt Rajasthan, Dept Sci & Technol; IEEE Comp Soc, Special Interest Grp Semant Multimedia Management; ACM Special Interest Grp Appl Comp, French Chapter; IFIP; ACM Type: Proceedings Paper";<p>13th International Conference on Signal-Image Technology and Internet-Based Systems (SITIS), Jaipur, INDIA, DEC 04-07, 2017</p>;NA;NA;NA;"Robot; Counseling; Dialog Promotion; Nodding; unazuki";Yetongnon, K and Dipanda, A and Chbeir, R and Gallo, L and Nain, N;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TLMNJBX5;conferencePaper;2017;"Anshar, Muh; Williams, Mary-Anne";Evolving Artificial Pain from Fault Detection through Pattern Data Analysis;2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR);978-1-5386-2035-9;NA;NA;NA;Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;694-699;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Inst Elect & Elect Engineers; Inst Elect & Elect Engineers Robot & Automat Soc; Harbin Inst Technol; Beijing Inst Technol; Univ Nevada; Univ Electro Commun Tokyo; Chinese Univ Hong Kong; Chinese Acad Sci Type: Proceedings Paper";<p>IEEE International Conference on Real-time Computing and Robotics (RCAR), Okinawa, JAPAN, JUL 14-18, 2017</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
L64KS94U;conferencePaper;2017;"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damian, Ernesto";Context Respectful Counseling Agent integrated with Robot nodding for Dialog Promotion;2017 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC);978-1-5386-1645-1;NA;NA;NA;Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;1540-1545;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 1062-922X Type: Proceedings Paper;<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), Banff, CANADA, OCT 05-08, 2017</p>;NA;NA;NA;"Robot; Counseling; Dialog Promotion; Nodding; unazuki";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XKVBIELM;conferencePaper;2017;"Burns, Henriette D.; Lesseig, Kristin";Empathy in Middle School Engineering Design Process;2017 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE);978-1-5090-5920-1;NA;NA;NA;This work-in-progress studies empathy in middle school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;NA;NA;NA;NA;NA;NA;NA;Frontiers in Education Conference;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE ASEE; IEEE Comp Soc; Indian ISSN: 0190-5848 Type: Proceedings Paper";<p>IEEE Frontiers in Education Conference (FIE), Indianapolis, IN, OCT 18-21, 2017</p>;NA;NA;NA;"empathy; design process; after-school science club; engineering; middle school";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Z9RX6MAQ;conferencePaper;2017;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Learning Human Behavior for Emotional Body Expression in Socially Assistive Robotics;2017 14TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT IN℡LIGENCE (URAI);978-1-5090-3056-9;NA;NA;NA;Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;45-50;NA;NA;NA;NA;NA;NA;International Conference on Ubiquitous Robots and Ambient Intelligence;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: KROS; IEEE; IEEE Robot and Automat Soc; RSJ; JEJU CVB; KOFST; ROBOTIS; SAMSUNG; GIRLS ROBOT; YUJIN ROBOT; NAVER LABS; KIST; WINDOWMATE; HYUNDAI ROTEM; MINDS LAB; WALKBOT; SRRC; NEUROMEKA; YM NAEUL TECH ISSN: 2325-033X Type: Proceedings Paper";<p>14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI), Jeju, SOUTH KOREA, JUN 28-JUL 01, 2017</p>;NA;NA;NA;"human-robot interaction; clustering; emotional body expression; imitation learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GDGWTIE9;journalArticle;2017;"Woo, Jinseok; Botzheim, Janos; Kubota, Naoyuki";EMOTIONAL EMPATHY MODEL FOR ROBOT PARTNERS USING RECURRENT SPIKING NEURAL NETWORK MODEL WITH HEBBIAN-LMS LEARNING;MALAYSIAN JOURNAL OF COMPUTER SCIENCE;NA;0127-9084;NA;NA;This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply “Hebbian-LMS” learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner “iPhonoid-C”. Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;258-285;NA;4;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA Publisher: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH Type: Article;NA;NA;NA;NA;"Conversation System; Emotional Empathy Model; Hebbian-LMS Learning; Recurrent Spiking Neural Network; Robot Partner";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ALCIAIBJ;conferencePaper;2017;"Scholten, Mark R.; Kelders, Saskia M.; van Gemert-Pijnen, Julia E. W. C.";A Scoped Review of the Potential for Supportive Virtual Coaches as Adjuncts to Self-guided Web-Based Interventions;PERSUASIVE TECHNOLOGY: DEVELOPMENT AND IMPLEMENTATION OF PERSONALIZED TECHNOLOGIES TO CHANGE ATTITUDES AND BEHAVIORS, PERSUASIVE 2017;978-3-319-55134-0 978-3-319-55133-3;NA;10.1007/978-3-319-55134-0_4;NA;This study aimed to explore supportive capabilities of VAs with the potential benefit in mind that users of self-guided eHealth interventions could be better supported. Spontaneous empathy and the explicitly expressed intention of non-responsive VAs to deliver user support is likely capable to engage and motivate users. Responsive VAs have even larger potential. However, they are more costly to realize and have a higher risk of failure. Effective user frustration detection and mitigation by Responsive VAs has been empirically demonstrated, but so far within artificial contexts. Altogether it makes sense to further explore the option to add VAs as adjuncts to self-guided eHealth interventions a potential remedy to low adherence.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;43-54;NA;NA;10171;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Exxellence Labbs; ConnectedCare; Coolminds ISSN: 0302-9743 Type: Proceedings Paper";"<p>12th International Conference on Persuasive Technologies (PERSUASIVE), Univ Twente, Persuas Hlth Technol Lab, Cte eHealth &amp; Wellbeing Res, Amsterdam, NETHERLANDS, APR 04-06, 2017</p>";NA;NA;NA;"Persuasive technology; Virtual agent; ehealth; Embodied conversational agent; Virtual human";DeVries, PW and OinasKukkonen, H and Siemons, L and BeerlageDeJong, N and VanGemertPijnen, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
S76YTYZX;conferencePaper;2017;"Fan, Lisa; Scheutz, Matthias; Lohani, Monika; Mccoy, Marissa; Stokes, Charlene";Do We Need Emotionally Intelligent Artificial Agents? First Results of Human Perceptions of Emotional Intelligence in Humans Compared to Robots;IN℡LIGENT VIRTUAL AGENTS, IVA 2017;978-3-319-67401-8 978-3-319-67400-1;NA;10.1007/978-3-319-67401-8_15;NA;Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent's emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;129-141;NA;NA;10498;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: KTH Royal Inst Technol ISSN: 0302-9743 Type: Proceedings Paper;"<p>17th International Conference on Intelligent Virtual Agents (IVA), Swedish Natl Museum Sci &amp; Technol, Stockholm, SWEDEN, AUG 27-30, 2017</p>";NA;NA;NA;"emotional intelligence; Human-robot interaction; empathetic robot";Beskow, J and Peters, C and Castellano, G and OSullivan, C and Leite, I and Kopp, S;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MVVPUT2U;conferencePaper;2017;"Moosaei, Maryam; Das, Sumit K.; Popa, Dan O.; Riek, Laurel D.";Using Facially Expressive Robots to Calibrate Clinical Pain Perception;PROCEEDINGS OF THE 2017 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'17);978-1-4503-4336-7;NA;10.1145/2909824.3020216;NA;In this paper, we introduce a novel application of social robotics in healthcare: high fidelity, facially expressive, robotic patient simulators (RPSs), and explore their usage within a clinical experimental context. Current commercially-available RPSs, the most commonly used humanoid robots worldwide, are substantially limited in their usability and fidelity due to the fact that they lack one of the most important clinical interaction and diagnostic tools: an expressive face. Using autonomous facial synthesis techniques, we synthesized pain both on a humanoid robot and comparable virtual avatar. We conducted an experiment with 51 clinicians and 51 laypersons (n = 102), to explore differences in pain perception across the two groups, and also to explore the effects of embodiment (robot or avatar) on pain perception. Our results suggest that clinicians have lower overall accuracy in detecting synthesized pain in comparison to lay participants. We also found that all participants are overall less accurate detecting pain from a humanoid robot in comparison to a comparable virtual avatar, lending support to other recent findings in the HRI community. This research ultimately reveals new insights into the use of RPSs as a training tool for calibrating clinicians' pain detection skills.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;32-41;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; AAAI; HFES ISSN: 2167-2121 Type: Proceedings Paper";<p>12th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Vienna, AUSTRIA, MAR 06-09, 2017</p>;NA;NA;NA;"emotion; affective communication; social robots; facial expressions; humanoid robots; human robot interaction; health informatics; medical technologies; non-verbal communication; patient simulation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GP89Q5Y6;conferencePaper;2017;"Yoshida, Naoto; Yonezawa, Tomoko";Physiological Expression of Robots Enhancing Users' Emotion in Direct and Indirect Communication;PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17);978-1-4503-5113-3;NA;10.1145/3125739.3132609;NA;One of the important factors in medical and nursing care recently has been arousing the emotions of patients. Many types of communication robots and pet robots have been developed as communication partners for patients. The user's emotions are stimulated during direct communication with the robot, although there is less chance that the robot will approach the user in other situations such as watching TV and listening to music without disturbing him or her. The user feels that the robot is troublesome during the user's other tasks. The purpose of this research is to elevate the user's emotional experience through emotional expression by physiological expressions of a partner robot in the user's daily life. Ambient but emotional expressions of physiological phenomena are perceived by touch, even when the user is concentrating on other tasks. First, we focused on breathing, heartbeat and body temperature as the physiological phenomena. From the results of the evaluations of the robot's heartbeat and body temperature, along with our previous results for the breathing, each expression has arousal and pleasure axes of the robot's situation. In this paper, we focus on the joint attention of the robot and user to an emotional photograph, and we verified whether the strength of the user's own emotional response to the content was changed by the physiological expressions of the robot while they looked at photographs together. The results suggest that the physiological expression of the robot would make the common emotional experience of users the user's own emotion in the experience more excited and more relaxed.;2017;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;505-509;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Assoc Comp Machinery Type: Proceedings Paper;<p>5th International Conference on Human Agent Interaction (HAI), Excellence Ctr Cognit Interact Technol, Bielefeld, GERMANY, OCT 17-20, 2017</p>;NA;NA;NA;"empathy; emotional expressions; enhancing users' emotion; Physiological phenomena; stuffed-toy robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GSMSCHHQ;journalArticle;2016;"Balkenius, Christian; Canamero, Lola; Parnamets, Philip; Johansson, Birger; Butz, Martin V.; Olsson, Andreas";Outline of a sensory-motor perspective on intrinsically moral agents;ADAPTIVE BEHAVIOR;NA;1059-7123;10.1177/1059712316667203;NA;We propose that moral behaviour of artificial agents could (and should) be intrinsically grounded in their own sensory-motor experiences. Such an ability depends critically on seven types of competencies. First, intrinsic morality should be grounded in the internal values of the robot arising from its physiology and embodiment. Second, the moral principles of robots should develop through their interactions with the environment and with other agents. Third, we claim that the dynamics of moral (or social) emotions closely follows that of other non-social emotions used in valuation and decision making. Fourth, we explain how moral emotions can be learned from the observation of others. Fifth, we argue that to assess social interaction, a robot should be able to learn about and understand responsibility and causation. Sixth, we explain how mechanisms that can learn the consequences of actions are necessary for a robot to make moral decisions. Seventh, we describe how the moral evaluation mechanisms outlined can be extended to situations where a robot should understand the goals of others. Finally, we argue that these competencies lay the foundation for robots that can feel guilt, shame and pride, that have compassion and that know how to assign responsibility and blame.;2016-10;2021-02-11T03:48:27Z;2021-02-11T03:48:27Z;NA;306-319;NA;5;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"empathy; Autonomous robots; embodied emotions; embodied interaction; intrinsic morality; sensory-motor grounding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Q24RK4IT;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Masato, Koike";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES;NA;2212-683X;10.1016/j.bica.2016.09.004;NA;"Companion or `pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like `emotion' and based on emotional intelligence (El) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. (C) 2016 Elsevier B.V. All rights reserved.";2016-10;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;51-67;NA;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Behavior; Human-robot interaction; Emotional intelligence; Companion robot; Consciousness based architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HXUWZNQC;journalArticle;2016;"Baraglia, Jimmy; Nagai, Yukie; Asada, Minoru";Emergence of Altruistic Behavior Through the Minimization of Prediction Error;IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS;NA;2379-8920;10.1109/TCDS.2016.2562121;NA;The emergence of altruistic behavior in infants fosters their social development and supports their involvement in our society. Altruistic tendencies, intended to benefit others with no apparent rewards, are also very useful for social robots that are designed to be used in our households. Yet, to make robots capable of learning how to help others as infants do, it is important to understand the mechanisms and motives responsible for the development of altruistic behavior. Further, understanding the mechanisms behind the early development of pro-social behavior would be a great contribution to the field of developmental psychology. To these ends, we hypothesize that infants from 14 months of age help others to minimize the differences between predicted actions and observations, that is, to minimize prediction errors. To evaluate our hypothesis, we created a computational model based on psychological studies and implemented it in real and simulated robots. Our system first acquires its own sensory-motor representation by interacting with its environment. Then, using its experience, the system recognizes and predicts others' actions and uses this prediction to estimate a prediction error. Our experiments demonstrated that our robots could spontaneously generate helping behaviors by being motivated by the minimization of prediction errors.;2016-09;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;141-151;NA;3;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"prediction error; Altruistic behavior; cognitive developmental robotics; helping behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XXN9WMKL;journalArticle;2016;"Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge";Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns;IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE IN℡LIGENCE;NA;0162-8828;10.1109/TPAMI.2015.2496209;NA;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading). The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.;2016-08;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;1679-1691;NA;8, SI;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA Publisher: IEEE COMPUTER SOC Type: Article;NA;NA;NA;NA;"Bayesian approach; frequency domain; human movement analysis; social role; Social signal processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LHHUL6TL;journalArticle;2016;"Hoenen, Matthias; Luebke, Katrin T.; Pause, Bettina M.";Non-anthropomorphic robots as social entities on a neurophysiological level;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2015.12.034;NA;The mirror-neuron-system (MNS) is involved in the perception of actions of humans and anthropomorphic robots. The current study investigates whether social interaction with a non-anthropomorphic robot is sufficient for a response of the MNS. Fifty-seven participants observed movements of a vacuum cleaning robot before and after it was handled by its owner. The robot was either humanized, being treated aggressively (n = 30), or it was treated as an object (n = 27). Electroencephalographic mu-activity is used as an index of MNS activity, because both are inversely correlated. Activity within the 8-13 Hz band was measured at central (mu activity) and occipital (alpha-activity) electrodes. Further, the level of aggressiveness displayed by the robot's owner, and the participants' compassion were rated on visual analog scales. Mu-activity showed medium-sized correlations with rated aggressiveness and compassion: The more aggressive the action towards the robot was perceived (r = -.379, p = .004), and the more compassion was felt for the robot (r = -.339, p = .010), the less pronounced mu-activity was at electrode C3 in response to the robot's movement. Thus social interaction with a non-anthropomorphic robot might establish the robot as a social entity and is sufficient to activate the human MNS. (C) 2015 Elsevier Ltd. All rights reserved.;2016-04;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;182-186;NA;NA;57;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Electroencephalography; Anthropomorphism; Human robot interaction; Mirror neuron system; Mu-activity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WJ8SCVEI;conferencePaper;2016;"Fung, Pascale; Dey, Anik; Bin Siddique, Farhad; Lin, Ruixi; Yang, Yang; Yan, Wan; Yin, Ricky Chan Ho";Zara: An Empathetic Interactive Virtual Agent;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;NA;NA;Zara, or `Zara the Supergirl', is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented human robot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;1176-1177;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"emotion recognition; human-computer interaction; speech recognition; empathy module";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6JTGGB5I;journalArticle;2016;"Matsuda, Goh; Hiraki, Kazuo; Ishiguro, Hiroshi";EEG-Based Mu Rhythm Suppression to Measure the Effects of Appearance and Motion on Perceived Human Likeness of a Robot;JOURNAL OF HUMAN-ROBOT INTERACTION;NA;2163-0364;10.5898/JHRI.5.1.Matsuda;NA;We performed two electroencephalogram (EEG) experiments to examine how humanoid robot appearance and motion affect human subjects' perception of the robots. Mu rhythm suppression of EEG, which is considered to reflect mirror neuron system (MNS) activation, was regarded as a neurological indicator of perceived human likeness. Video clips depicting upper-body actions performed by three agents (human, android, and mechanical robot) were presented in experiment 1. In experiment 2, point-light motion (PLM) stimuli generated from experiment 1 stimuli were presented. The results of experiment 1 revealed that only the human and android actions evoked significant mu suppression. No PLM stimulus elicited significant mu suppression in experiment 2. These findings suggest that an overall human-like form is necessary to activate the MNS.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;68-81;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNAL HUMAN-ROBOT INTERACTION, STANFORD, CA 00000 USA Publisher: JOURNAL HUMAN-ROBOT INTERACTION Type: Article;NA;NA;NA;NA;"EEG; humanoid robot; android; mirror neuron; mu suppression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A923UM4G;conferencePaper;2016;"Egawa, Shoichi; Sejima, Yoshihiro; Sato, Yoichiro; Watanabe, Tomio";A Laughing-driven Pupil Response System for Inducing Empathy;2016 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII);978-1-5090-3329-4;NA;NA;NA;Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;520-525;NA;NA;NA;NA;NA;NA;IEEE/SICE International Symposium on System Integration;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; SICE; SICE Syst Integrat Div; IEEE Robot & Automat Soc; IEEE ind Elect Soc; Hokkaido Univ, Grad Sch Informat Sci & Technol ISSN: 2474-2317 Type: Proceedings Paper";<p>IEEE/SICE International Symposium on System Integration (SII), Sapporo, JAPAN, DEC 13-15, 2016</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
URK63NS9;conferencePaper;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji";Social Expression of Pet Robot Based on Artificial Consciousness and Biologically Inspired Online Topological Method;PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON ARTIFICIAL LIFE AND ROBOTICS (ICAROB 2016);978-4-9908350-1-9;NA;NA;NA;The social robot becomes important to the future world of pervasive computing, where the robot currently facilitates our life. The social behavior and natural action of the robot is one of the most needed function for emerging future realistic human-like robot. Our paper proposes the artificial topological consciousness based on a pet robot using the artificial neurotransmitter and motivation. Since, the significant is cross-creature communication to friendly companionship. This system focuses on three points. The first, the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can socially perform its expression to human using biologically inspired topological on-line method for encouragement or being delighted by its own emotion and the human expression. We believe the artificial consciousness based on complexity level and the robot social expression enhance the user affinity by the experiment.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;204-207;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ALIFE ROBOTICS CO, LTD;HIG HANDADAI, OITA, 870-1112, JAPAN;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ALife Robot Corp Ltd; Int Conf Artificial Life & Robot, Int Steering Comm; IEEE Fukuoka Sect; IEEE Robot & Automat Soc; Chinese Assoc Artificial Intelligence Type: Proceedings Paper";<p>International Conference on Artificial Life and Robotics (ICAROB), Okinawa, JAPAN, JAN 29-31, 2016</p>;NA;NA;NA;"Consciousness-Based Architecture; Cross-Creature Communication; EQ";Jia, Y and Ito, T and Lee, JJ and Sugisaka, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JNMBEKXW;journalArticle;2016;"Nomura, Tatsuya; Kanda, Takayuki; Kidokoro, Hiroyoshi; Suehiro, Yoshitaka; Yamada, Sachie";Why do children abuse robots?;INTERACTION STUDIES;NA;1572-0373;10.1075/is.17.3.02nom;NA;We found that children sometimes abused a social robot placed in a shopping mall hallway. They verbally abused the robot, repeatedly obstructed its path, and sometimes even kicked and punched the robot. To investigate the reasons for the abuse, we conducted a field study in which we interviewed visiting children who exhibited serious abusive behaviors, including physical contact. We analyzed interview contents to determine whether the children perceived the robot as human-like, why they abused it, and whether they thought that the robot would suffer from their abusive behavior. We obtained valid interviews from 23 children (age range, 5-9 years old) over 13 days of observations. We found that 1) the majority of the children engaged in abuse because they were curious about the robot's reactions or enjoyed abusing it and considered it human-like, and 2) about half of them believed the robot was capable of perceiving their abusive behaviors.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;348-370;NA;3;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS Publisher: JOHN BENJAMINS PUBLISHING CO Type: Article;NA;NA;NA;NA;"children; abusive behavior; Communication robot; semi-structured interview";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7L8LKJAP;conferencePaper;2016;"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile";Emotion Recognition Using Facial Expression Images for a Robotic Companion;ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2016;978-3-319-44188-7 978-3-319-44187-0;NA;10.1007/978-3-319-44188-7_6;NA;Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5%. These experiments serve as benchmark for our current research project in the area of social robotics.;2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;79-93;NA;NA;629;NA;NA;NA;Communications in Computer and Information Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1865-0929 Type: Proceedings Paper;<p>17th International Conference on Engineering Applications of Neural Networks (EANN), Robert Gordon Univ, Aberdeen, SCOTLAND, SEP 02-05, 2016</p>;NA;NA;NA;"Neural networks; Social robots; Emotion recognition; Gabor filter; Image classification; Support Vector Machine";Jayne, C and Iliadis, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3TMXUIKH;conferencePaper;2016;"Lewandowska-Tomaszczyk, Barbara; Wilson, Paul A.";Compassion, empathy and sympathy expression features in affective robotics;2016 7TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM);978-1-5090-2645-6;NA;NA;NA;"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive VALENCE and more of a desire to act than Polish wspolczucie. Polish empatia is also characterised by a more negative VALENCE than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative VALENCE in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the COMPASSION model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents.";2016;2021-02-11T03:48:28Z;2021-02-11T03:48:28Z;NA;65-70;NA;NA;NA;NA;NA;NA;International Conference on Cognitive Infocommunications;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 2375-1312 Type: Proceedings Paper;<p>7th IEEE International Conference on Cognitive Infocommunications (CogInfoCom), Wroclaw, POLAND, OCT 16-18, 2016</p>;NA;NA;NA;"emotions; empathy; expressiveness; action tendencies; affective robotics; British English; cognitive corpus linguistics; compassion; empatia; false negative; false positive; GRID; online sorting; Polish; responsiveness; sympathy; sympatia; VALENCE; wspolczucie";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MRNC9VBM;conferencePaper;2016;"Sin, Yap Miao Robin; Liang, Qiao; Tani, Koyu; Ogawa, Ken-ichiro; Miyake, Yoshihiro";Evaluation of a Head Motion Synchronization System in the Communicative Process Between Human and Robot;2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE);978-4-907764-50-0;NA;NA;NA;An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;1514-1519;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE), Tsukuba, JAPAN, SEP 20-23, 2016</p>;NA;NA;NA;"human-robot interaction; Head motion synchronization; mutual entrainment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TPBWKJ8A;journalArticle;2016;"Lee, Hawon; You, Sujeong; Ji, Sanghoon; Cho, Hye-Kyung";Perspective taking encourages cleaning task performance: a child-robot interaction;INTERNATIONAL JOURNAL OF KNOWLEDGE AND LEARNING;NA;1741-1009;10.1504/IJKL.2016.079760;NA;This paper presents a robot-mediated learning environment for children, exploring the possibility of motivating children to focus on a socially appropriate, but unappealing task. To examine the effect quantitatively, we incorporated the task of cleaning up toy blocks. Performance was measured by the number of blocks children cleaned up. We compared results in three different cases: without the robot, with the robot programmed to take children's perspective in a moderate way, and with the robot programmed to take children's perspective in a strong or repeated way. The findings were very interesting. Perspective taking in both cases increased children's intimacy with the robot and enhanced cleaning performance. However, we found that strong stimuli generated a lower level of intimacy but a higher cleaning performance than moderate stimuli. On the basis of these findings, we propose potential applications of robot-mediated learning for young children.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;204-219;NA;2-3, SI;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND Publisher: INDERSCIENCE ENTERPRISES LTD Type: Article;NA;NA;NA;NA;"perspective taking; child-robot interactions; intimacy; robot learning; robot-mediated learning; role-playing robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
35DX8HV2;conferencePaper;2016;"Ranieri, Caetano M.; Romero, Roseli A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016;978-1-5090-3656-1;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Brazilian Comp Soc; Centro Estudos Sistemas Avancados Recife; Centro Informatica UFPE; ROBOLIURE; VIRTUS IMPAVIDA; Inst Inovacao; Robolivre; CAPES; Inst SENAI Inovacao; Conselho Nacl Desenvolvimento Cientifico Tecnologico; Fundacao Amparo Ciencia Tecnologia Estado Pernambuco; IEEE Robot & Automat Soc Chapter Brazil; IEEE Latin Amer Robot Council Type: Proceedings Paper";<p>13th Latin American Robotics Symposium / 4th Brazilian Robotics Symposium (LARS/SBR), Recife, BRAZIL, OCT 08-12, 2016</p>;NA;NA;NA;NA;Cavalcante, SV and Tonidandel, F;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TXW855GE;conferencePaper;2016;"Liu, Xin; London, Kati";TAI: A Tangible Al Interface to Enhance Human-Artificial Intelligence (AI) Communication Beyond the Screen;DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS;978-1-4503-4031-1;NA;10.1145/2901790.2901896;NA;Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-Al communication experience.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;281-285;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; ACM SIGCHI Type: Proceedings Paper";<p>11th ACM SIGCHI Conference on Designing Interactive Systems (DIS), Qeensland Univ Technol, Brisbane, AUSTRALIA, JUN 04-08, 2016</p>;NA;NA;NA;"Affective Communication; Shape-changing interface; Social Agent; Tangible interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ATGDJTHU;conferencePaper;2016;Coeckelbergh, Mark;Is It Wrong to Kick a Robot? Towards a Relational and Critical Robot Ethics and Beyond;WHAT SOCIAL ROBOTS CAN AND SHOULD DO;978-1-61499-708-5 978-1-61499-707-8;NA;10.3233/978-1-61499-708-5-7;NA;NA;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;7-8;NA;NA;290;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Aarhus Univ, Sch Culture & Soc, Res Unit Robophilosophy; Res Network Transdisciplinary Studies Social Robot; Danish Res Council Humanities ISSN: 0922-6389 Type: Proceedings Paper";<p>Conference on Robot Philosophy / TRANSOR Conference on What Social Robots Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016</p>;NA;NA;NA;"empathy; human-robot relations; moral status; normative ethics; relational epistemology; robot ethics";Seibt, J and Norskov, M and Andersen, SS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6BCUEP9U;conferencePaper;2016;Musial, Maciej;Magical Thinking and Empathy Towards Robots;WHAT SOCIAL ROBOTS CAN AND SHOULD DO;978-1-61499-708-5 978-1-61499-707-8;NA;10.3233/978-1-61499-708-5-347;NA;This paper aims to understand why human beings develop empathetic attitudes towards robots. Whilst much research studies this issue from the perspective of the natural sciences, by referring to biological features of the human brain, it is also possible to investigate it from the perspective of the humanities by referring to humans' cultural features. After establishing animation as a necessary condition of empathy towards robots, the presentation delivers a hypothesis that magical thinking - typical for children, members of “primitive” societies and individuals with mental disorders - is involved in the empathetic relations with robots. Furthermore, arguments to defend and clarify this hypothesis are presented.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;347-356;NA;NA;290;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Aarhus Univ, Sch Culture & Soc, Res Unit Robophilosophy; Res Network Transdisciplinary Studies Social Robot; Danish Res Council Humanities ISSN: 0922-6389 Type: Proceedings Paper";<p>Conference on Robophilosophy / TRANSOR Conference on What Social Robots Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016</p>;NA;NA;NA;"robots; empathy; animation; magical thinking";Seibt, J and Norskov, M and Andersen, SS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8N6ZR9XH;conferencePaper;2016;"Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Oliveira, Patricia Alves; Ribeiro, Tiago; Barendrege, Wolmet; Serholt, Sofia; Kappas, Arvid";Map Reading with an Empathic Robot Tutor;ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16);978-1-4673-8369-1;NA;NA;NA;In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;567;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; HFES; AAAI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>11th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Christchurch, NEW ZEALAND, MAR 07-10, 2016</p>;NA;NA;NA;"empathy; robot-child interaction; robotic tutor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WDWUW379;conferencePaper;2016;Wilson, Jason R.;Robot Assistance in Medication Management Tasks;ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16);978-1-4673-8369-1;NA;NA;NA;NA;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;643-644;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; HFES; AAAI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>11th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Christchurch, NEW ZEALAND, MAR 07-10, 2016</p>;NA;NA;NA;"decision-making; empathy; assistive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VTKQMBBR;conferencePaper;2016;"Bechade, Lucile; Duplessis, Guillaume Dubuisson; Devillers, Laurence";Empirical Study of Humor Support in Social Human-Robot Interaction;DISTRIBUTED, AMBIENT AND PERVASIVE INTERACTIONS, (DAPI 2016);978-3-319-39862-4 978-3-319-39861-7;NA;10.1007/978-3-319-39862-4_28;NA;As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event's context.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;305-316;NA;NA;9749;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>4th International Conference on Distributed, Ambient and Pervasive Interactions (DAPI) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;NA;Streitz, N and Markopoulos, P;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WR7PHQQU;conferencePaper;2016;"Biswas, Mriganka; Murray, John";The Effects of Cognitive Biases in Long-Term Human-Robot Interactions: Case Studies Using Three Cognitive Biases on MARC the Humanoid Robot;SOCIAL ROBOTICS, (ICSR 2016);978-3-319-47437-3 978-3-319-47436-6;NA;10.1007/978-3-319-47437-3_15;NA;The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant's names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours.;2016;2021-02-11T03:48:29Z;2021-02-11T03:48:29Z;NA;148-158;NA;NA;9979;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper";<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>;NA;NA;NA;"Human-robot interaction; Cognitive bias in robot; Human-robot long-term interactions; Imperfect robot";Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2QYYCWJX;conferencePaper;2016;"Giambattista, Angela; Teixeira, Luis; Ayanoglu, Hande; Saraiva, Magda; Duarte, Emilia";Expression of Emotions by a Service Robot: A Pilot Study;DESIGN, USER EXPERIENCE, AND USABILITY: TECHNOLOGICAL CONTEXTS, PT III;978-3-319-40406-6 978-3-319-40405-9;NA;10.1007/978-3-319-40406-6_31;NA;A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot's facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children.;2016;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;328-336;NA;NA;9748;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>5th International Conference on Design, User Experience, and Usability (DUXU) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;"Service robot; Human robot interaction; Healthcare; Emotional design; User experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
62PF5W3L;conferencePaper;2016;"Radu, Iulian; Antle, Alissa N.";All Creatures Great and Small: Becoming Other Organisms through the EmbodySuit;PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016);NA;NA;10.1145/2930674.2955209;NA;"The EmbodySuit augmented human system allows students to experience life from the perspectives of different organisms, by virtually and physically becoming birds, spiders, ants and even bacteria. Inspired by current advances in nanorobotics, Star Trek's holodeck and the Magic school bus, Embodysuit makes learning embodied and experiential. The student becomes a real organism, part of a real, natural ecosystem. The student's senses are adapted to those of the organism, and the student's actions map to the actions of an organism-sized robot inside a real environment. Our system is based on our projection of advances that will occur in the next 35 years in augmented reality, cybernetics and micro robotics. By about 2050 EmbodySuit type systems will be feasible to prototype, enabling us to address key research questions in classroom scientific inquiry; experiential and embodied learning; technology development; and design for 3D embodied cyber-systems.";2016;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;751-755;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: British Broadcasting Corp, Res & Dev Grp; ACM Type: Proceedings Paper";<p>15th International ACM Conference on Interaction Design and Children (IDC), Univ Cent Lancashire, Child Comp Interact, Media City, ENGLAND, JUN 21-24, 2016</p>;NA;NA;NA;"children; experiential learning; education; design; Augmented reality; cyborgs; embodied empathy; nanorobots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WBUNVIH3;conferencePaper;2016;"Sorbello, Rosario; Chella, Antonio; Giardina, Marcello; Nishio, Shuichi; Ishiguro, Hiroshi";An Architecture for Telenoid Robot as Empathic Conversational Android Companion for Elderly People;IN℡LIGENT AUTONOMOUS SYSTEMS 13;978-3-319-08338-4 978-3-319-08337-7;NA;10.1007/978-3-319-08338-4_68;NA;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic human-android interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user.;2016;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;939-953;NA;NA;302;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Univ Padova ISSN: 2194-5357 Type: Proceedings Paper;<p>13th International Conference on Intelligent Autonomous Systems (IAS), Centro Congressi Padova, Padova, ITALY, JUL 15-18, 2014</p>;NA;NA;NA;"Humanoid robot; Humanoid robot interaction; Life support empathic robot; Telenoid";Menegatti, E and Michael, N and Berns, K and Yamaguchi, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PK3C8PNI;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS;978-1-4503-4239-1;NA;10.5555/2936924.2937061;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating `memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;931-939;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Fdn Autonomous Agents & Multiagent Syst; Natl Sci Fdn; Artificial Intelligence Journal; Springer; Unicen; Sumitomo Elect; Living Analyt Res Ctr; Panasonic R & D Ctr Singapore; Assoc Comp Machinery Special Interest Grp Artificial Intelligence; Assoc Comp Machinery Type: Proceedings Paper";<p>15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Singapore, SINGAPORE, MAY 09-10, 2016</p>;NA;NA;NA;"Memory; Empathy; Human-Robot Interaction; Human-Agent Interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DID8SQ7H;journalArticle;2015;"Suzuki, Yutaka; Galli, Lisa; Ikeda, Ayaka; Itakura, Shoji; Kitazaki, Michiteru";Measuring empathy for human and robot hand pain using electroencephalography;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/srep15924;NA;This study provides the first physiological evidence of humans' ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.;2015-11-03;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GKVKCQ77;journalArticle;2015;"Han, Jeonghye; Jo, Miheon; Hyun, Eunja; So, Hyo-jeong";Examining young children's perception toward augmented reality-infused dramatic play;ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT;NA;1042-1629;10.1007/s11423-015-9374-9;NA;Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children's satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children's perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5-6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children's perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed.;2015-06;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;455-474;NA;3;63;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Augmented reality; Dramatic play; Educational robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AD25GHKB;journalArticle;2015;"Damiano, Luisa; Dumouchel, Paul; Lehmann, Hagen";Towards Human-Robot Affective Co-evolution Overcoming Oppositions in Constructing Emotions and Empathy;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0258-7;NA;This article deals with contemporary research aimed at building emotional and empathic robots, and gives an overview of the field focusing on its main characteristics and ongoing transformations. It interprets the latter as precursors to a paradigmatic transition that could significantly change our social ecologies. This shift consists in abandoning the classical view of emotions as essentially individual states, and developing a relational view of emotions, which, as we argue, can create genuinely new emotional and empathic processes-dynamics of “human-robot” affective coordination supporting the development of mixed (human-robot) ecologies.;2015-02;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;7-18;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-Robot Interaction; Affective coordination; Affective robotics; Artificial emotions and empathy; Naked vs. embodied mind; Synthetic methodology/Synthetic approach";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
F3IJC335;journalArticle;2015;"Mirnig, Nicole; Strasser, Ewald; Weiss, Astrid; Kuehnlenz, Barbara; Wollherr, Dirk; Tscheligi, Manfred";Can You Read My Face? A Methodological Variation for Assessing Facial Expressions of Robotic Heads;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0261-z;NA;Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants' dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach.;2015-02;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;63-76;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Facial expressions; Robot emotions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JQR6UETJ;journalArticle;2015;"Tisseron, Serge; Tordo, Frederic; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0268-5;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015-02;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;97-102;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Psychology; Human-robot interaction; Auto-empathy; Direct empathy; Empathy with robots; Intersubjective empathy; Reciprocal empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AE22QHT2;journalArticle;2015;Stephan, Achim;Empathy for Artificial Agents;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0260-0;NA;The paper has three goals. First, it introduces into different notions of empathy and related capacities such as emotional contagion, affective empathy, cognitive empathy, and sympathy. Second, it presents a case in point of an intelligent tutoring system, Affective AutoTutor, whose affect-sensitive behavior seems to further and enhance the outcome of its interactions with its students. Affective AutoTutor appears to behave empathically within a well defined learning environment. Third, attention is directed towards the requirements to be met by artificial empathizers to be judged as empathizers tout court by their social interactants, even when acting in unspecified social situations. To be a convincing empathizer, the artificial agent would not only need to grasp the emotional states of its interaction partners and understand their situation with respect to an adequate world model, but also communicate its own affective states. Eventually, an artificial empathizer should be ready to react appropriately to its interaction partner's reciprocal empathy.;2015-02;2021-02-11T03:48:30Z;2021-02-11T03:48:30Z;NA;111-116;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Affective AutoTutor; Affective empathy; Artificial agent; Cognitive empathy; Empathic behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LZZHFJNL;journalArticle;2015;Airenti, Gabriella;The Cognitive Bases of Anthropomorphism: From Relatedness to Empathy;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0263-x;NA;Humans may react very differently with respect to mechanical devices, including robots. They can interact with them with delight or retreat in aversion or fear. According to the famous model of the uncanny valley these opposite reactions depend on the degree of familiarity that different artifacts engender in humans. The aim of my work is trying to find out the cognitive bases of familiarity, analyzing the origin of anthropomorphic projection, namely human disposition to attribute anthropomorphic features - like intentions or feelings-to artifacts. I shall discuss two concepts: relatedness and empathy, and argue that relatedness is the precondition for empathy. The fact that it is possible to attribute anthropomorphic features virtually to any object shows that resemblance is not the point. Anthropomorphism is a kind of relation that humans establish with an artifact, and in order to comprehend this phenomenon we have to focus on the relational aspect. I shall argue that what we call anthropomorphism is an extension to nonhumans of forms of interactions typical of human communication, i.e. the attribution to an artifact of the position of interlocutor in a possible dialogue. It can be shown that attributing to an artifact the position of interlocutor in a dialogue implies dealing with it as if it were endowed of the features characterizing human mind, i.e. mental states and emotions.;2015-02;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;117-127;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Communication; Empathy; Theory of mind; Anthropomorphism; Relatedness";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
R4YRVGML;journalArticle;2015;Pare, Zaven;The Art of Being Together with Robots: A Conversation with Professor Hiroshi Ishiguro;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0264-9;NA;The content of this article is primarily a transcription of two events: A demo of a video-conference with the Geminoid HI-2 at Osaka University (Systems Innovation Department in the Graduate School of Engineering), and a conversation about Geminoids with Professor Hiroshi Ishiguro at ATR (Advanced Telecommunication Research Institute International-Kyoto). As Professor Ishiguro says during the conversation, his quest “is harmony between humans and robots”. By creating and manipulating androids (human-like appearance robot), the roboticist reveals and highlights the assembly, disassembly and reconfigurations of human representation and human presence.;2015-02;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;129-136;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Telepresence; Familiarity; Geminoid; Human likeness; Sympathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TGMH8QF7;journalArticle;2015;Asada, Minoru;Towards Artificial Empathy How Can Artificial Empathy Follow the Developmental Pathway of Natural Empathy?;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0253-z;NA;"The design of artificial empathy is one of the most essential issues in social robotics. This is because empathic interactions with ordinary people are needed to introduce robots into our society. Several attempts have been made for specific situations. However, such attempts have provided several limitations; thus, diminishing authenticity. The present article proposes “affective developmental robotics (hereafter, ADR),” which provides more authentic artificial empathy based on the concept of cognitive developmental robotics (hereafter, CDR). First, the evolution and development of empathy as revealed in neuroscience and biobehavioral studies are reviewed, moving from emotional contagion to envy and schadenfreude. These terms are then reconsidered from the ADR/CDR viewpoint, particularly along the developmental trajectory of self-other cognition. Next, a conceptual model of artificial empathy is proposed based on an ADR/CDR viewpoint and discussed with respect to several existing studies. Finally, a general discussion and proposals for addressing future issues are given.";2015-02;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;19-33;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Artificial empathy; Affective developmental robotics; Self/other cognition";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QQRA5N8U;journalArticle;2015;"Lim, Angelica; Okuno, Hiroshi G.";A Recipe for Empathy Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0262-y;NA;Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (”flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence.;2015-02;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;35-49;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Developmental robotics; Emotional contagion based on SIRE model; MEI robot; Robot empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4C2TGTKH;conferencePaper;2015;Nijholt, Anton;Designing humor for playable cities;6TH INTERNATIONAL CONFERENCE ON APPLIED HUMAN FACTORS AND ERGONOMICS (AHFE 2015) AND THE AFFILIATED CONFERENCES, AHFE 2015;NA;NA;10.1016/j.promfg.2015.07.358;NA;Smartness, made possible by intelligent sensors and actuators, is invading our home, office and public environments. This smartness monitors, anticipates and supports our activities, increasing efficiency of our activities. Smartness is usually associated with efficiency, but it also allows environments, virtual humans and social robots to display emotions, empathy and provide environments to introduce and support humorous events. We review examples of playful and humorous street furniture in `playable' cities and projects that allow residents and visitors to interact with objects and environments in playful and humorous ways. We add observations on humor theory, in particular observations that deal with physical, visual and multimodal humor. Our emphasis is on introducing incongruities and on exploring different forms of incongruities in order to introduce humorous situations. Inventories of incongruities are explored. These inventories have been obtained from observing humor in everyday situations, in comedies, in movies, and in TV commercials. Shortcomings of these inventories from the point of view of multimodal and interaction humor are discussed and some preliminary views on additional approaches are provided. (C) 2015 The Authors. Published by Elsevier B.V.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;2175-2182;NA;NA;3;NA;NA;NA;Procedia Manufacturing;NA;NA;NA;ELSEVIER SCIENCE BV;SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 2351-9789 Type: Proceedings Paper;<p>6th International Conference on Applied Human Factors and Ergonomics (AHFE), Las Vegas, NV, JUL 26-30, 2015</p>;NA;NA;NA;"Human-computer interaction; Computational humor; Incongruities; Playable cities";Ahram, T and Karwowski, W and Schmorrow, D;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JBXFITJI;conferencePaper;2015;Koltick, Nicole;AUTONOMOUS BOTANIST: THE POETIC POTENTIALS OF A NEW ROBOTIC SPECIES;COMPUTATIONAL ECOLOGIES: DESIGN IN THE ANTHROPOCENE;978-0-692-53726-8;NA;NA;NA;This project begins by asking questions about ethics and empathy towards robots, and contemplates the future of their behavior in ways not informed by pragmatics or economy. What if a robot had a hobby? How do robots make aesthetic decisions? What is a robot's point of view? It seeks to shift perception of robotic agency and allow the audience to embody the robotic gardeners' vision, behavior and influence its aesthetics. By amplifying perceptual differences between humans and robots and we allow for both tangible and virtual embodiment experiences from multiple scales and perspectives. This compelling design speculation seeks to deploy a variety of interactive computational techniques, exploring novel forms and behaviors in order to engage deeper philosophical issues surrounding aesthetics, non-human agencies, and the role of the synthetic in the future.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;332-340;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTER AIDED DESIGN ARCHITECTURE-ACADIA;2325 3 ST, SUITE 229, SAN FRANCISCO, CA 94107 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: AUTODESK; BHDP; V RAY; WOODS BAGOT; Bentley; FLUX; VECTORWORKS; HKS LINE; Core StudioThornton Tomasetti; Oasys; Auto DesSys Inc; DAAP; Formlabs; VIMtrek; Rhinoceros; Proving Ground; Assoc Robots Architecture; TAFT Res Ctr; Delft Univ Technol; Univ Cincinnati Type: Proceedings Paper";<p>35th Annual Conference of the Association-for-Computer-Aided-Design-in-Architecture, Cincinnati, OH, OCT 19-25, 2015</p>;NA;NA;NA;NA;Combs, L and Perry, C;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8MFWL6YJ;conferencePaper;2015;"Chumkamon, Sakmongkon; Masato, Koike; Hayashi, Eiji";Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot;2015 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2015): BIG DATA ANALYTICS FOR HUMAN-CENTRIC SYSTEMS;978-1-4799-8696-5;NA;10.1109/SMC.2015.45;NA;This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;185-190;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE COMPUTER SOC;10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; IEEE Syst Man & Cybernet Soc; Hong Kong Polytechn Univ; K C Wong Fdn ISSN: 1062-922X Type: Proceedings Paper";<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), City Univ Hong Kong, Hong Kong, PEOPLES R CHINA, OCT 09-12, 2015</p>;NA;NA;NA;"CBA; Facial Expression Recognition; Human-Robot Interactio; Social Robot; component";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BGLUNF8H;conferencePaper;2015;"Dimitrova, Maya; Wagatsuma, Hiroaki; Tripathi, Gyanendra Nath; Ai, Guangyi";Adaptive and Intuitive Interactions with Socially-Competent Pedagogical Assistant Robots;2015 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY BASED HIGHER EDUCATION AND TRAINING (ITHET);978-1-4799-1756-3;NA;NA;NA;The paper presents a novel framework for including social competence in pedagogical assistant robots based on recent social neuroscience investigations. An educational model describing the interplay of social interaction and social observation in typical children and children with autistic spectrum conditions (ASC) is proposed. The behavioral results of a study of human gaze movements while viewing a robot tutor are briefly presented. The implications for design of adaptive and intuitive robotic tutoring systems as pedagogical assistants for typical children and children with special educational needs are discussed.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;NA;NA;NA;NA;NA;NA;NA;International Conference on Information Technology Based Higher Education and Training;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: EAEEIE; IEEE; IGIP; ICS; UNINOVA; UNESCO; FCT ISSN: 2380-1603 Type: Proceedings Paper";<p>International Conference on Information Technology Based Higher Education and Training (ITHET), Lisbon, PORTUGAL, JUN 11-13, 2015</p>;NA;NA;NA;"social neuroscience; autistic spectrum conditions; pedagogical assistant robots; robot tutoring; social competence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QW5IF7SI;conferencePaper;2015;"Rasool, Zeeshan; Masuyama, Naoki; Islam, Md. Nazrul; Loo, Chu Kiong";Empathic Interaction using the Computational Emotion Model;2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL IN℡LIGENCE (IEEE SSCI);978-1-4799-7560-0;NA;10.1109/SSCI.2015.26;NA;"This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model; whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.";2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;109-116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computational Intelligence Soc; IEEE BigData Type: Proceedings Paper";<p>IEEE Symposium Series Computational Intelligence, Cape Town, SOUTH AFRICA, DEC 07-10, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FYAZNFYL;conferencePaper;2015;"Darling, Kate; Nandy, Palash; Breazeal, Cynthia";Empathic concern and the effect of stories in human-robot interaction;2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-4673-6704-2;NA;NA;NA;People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;770-775;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper";<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E48I97J3;conferencePaper;2015;Wilson, Jason R.;Towards an Affective Robot Capable of Being a Long-Term Companion;2015 INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND IN℡LIGENT INTERACTION (ACII);978-1-4799-9953-8;NA;NA;NA;While it has been well established that affect influences judgments and decision-making, few computational models of the phenomenon exist. The work I have done and propose focuses on the role of affect in complex decision-making or judgment tasks where a pure utilitarian approach does not reflect human behavior. It is especially challenging to develop models that can predict choices made by an individual. However, as we approach having companion robots that have long-term relationships with a user, it becomes increasingly vital for the robot to be sensitive to the affect of the human and to behave in a manner that is consistent with the expectations of the user and society. The models and underlying robot architecture I describe here bring us closer to robots being accepted in our homes.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;754-759;NA;NA;NA;NA;NA;NA;International Conference on Affective Computing and Intelligent Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: AAAC ISSN: 2156-8103 Type: Proceedings Paper;<p>6th AAAC Affective Computing and Intelligent Interaction International Conference (ACII), Xian, PEOPLES R CHINA, SEP 21-24, 2015</p>;NA;NA;NA;"decision-making; human-robot interaction; affect; computational models";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E26AG2VF;conferencePaper;2015;"Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani-Sherman, Tal";Design and Evaluation of a Peripheral Robotic Conversation Companion;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696495;NA;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.;2015;2021-02-11T03:48:31Z;2021-02-11T03:48:31Z;NA;3-10;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"Empathy; Human-robot interaction; Ambient kinetic tangibles; Behavior change; Design; Robotic companions; Smartphone robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
36AIE6ST;conferencePaper;2015;"Hood, Deanna; Lemaignan, Severin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696479;NA;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced bene fits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;83-90;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
F9DG5VXB;conferencePaper;2015;"Fuente, Luis A.; Ierardi, Hannah; Pilling, Michael; Crook, Nigel T.";Influence of Upper Body Pose Mirroring in Human-Robot Interaction;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_22;NA;This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people's perception of their conversation with it. A set of twelve questions about the participants' university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;214-223;NA;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;"Empathy; Anthropomorphism; Body-pose mirroring; Rapport";Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
H7LL3IEE;conferencePaper;2015;"Pettinati, Michael J.; Arkin, Ronald C.";Towards a Robot Computational Model to Preserve Dignity in Stigmatizing Patient-Caregiver Relationships;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_53;NA;Parkinson's disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patient-caregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;532-542;NA;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;NA;Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9ASX8YJH;journalArticle;2015;"Drigas, Athanasios S.; Papoutsi, Chara";ICTs for Assessment and Intervention on Cultivation of Empathy;INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING;NA;1863-0383;10.3991/ijet.v10i5.4731;NA;Empathy can be defined as the ability to perceive and understand others' emotional states. Neuropsychological evidence has shown that humans empathize with each other to different degrees depending on factors such as their mood, personality, and social relationships. ICTs with the features that offered are a very important tool for the detection, the development and the cultivation of empathy in children and adults in various fields and in different ways.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;10-15;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: DIAGONALE 10, D-34127 KASSEL, GERMANY Publisher: KASSEL UNIV PRESS GMBH Type: Article;NA;NA;NA;NA;"Health; Empathy; Robots; Games; Autism; Bullying; Empathic Agents; ICTs; Neural Mechanisms; Social Networks; Virtual Environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
L2T738MA;conferencePaper;2015;"Alanis Garza, Arnulfo; Lemus Zuniga, Lenin G.; del Rosario Baltazar, Maria; Yail Marquez, Bogart; Lino Ramirez, Carlos; Romero, Karina";Intelligent Social Agent for the Development of Social Relations Based on Primary Emotions;AGENT AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS;978-3-319-19728-9;NA;10.1007/978-3-319-19728-9_28;NA;This article shows the experimentation with emotions in a scenario with a specific task, where the main goal is to see the behavior of emotions to the task given to them that based on the level of empathy that exists between these emotions, all this work is done within a Social Multi-Agent System, in which it is intended that two or more robots can present a profile of personality and emotion for the search of empathy between them to make a team.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;337-344;NA;NA;38;NA;NA;NA;Smart Innovation Systems and Technologies;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: KES Int Innovat Knowledge Based & Intelligent Engn Syst; Univ Zagreb, Fac Elect Engn & Comp ISSN: 2190-3018 Type: Proceedings Paper";<p>9th KES International Conference on Agent and Multi-Agent Systems -Technologies and Applications (KES-AMSTA), Sorrento, ITALY, JUN 17-19, 2015</p>;NA;NA;NA;NA;Jezic, G and Howlett, RJ and Jain, LC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E2VMTKL6;conferencePaper;2015;"Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.";Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696471;NA;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.";2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;125-132;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"empathy; Human-robot interaction; robot embodiment; simulated interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7EQDIWQ5;conferencePaper;2015;"Deshmukh, Amol; Jones, Aidan; Janarthanam, Srinivasan; Hastie, Helen; Ribeiro, Tiago; Aylett, Ruth; Paiva, Ana; Castellano, Ginevra";An Empathic Robotic Tutor in a Map Application;PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15);978-1-4503-3413-6;NA;NA;NA;In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;1923-1924;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IFAAMAS; NSF; Artificial Intelligence; ACM SIGAI; ARGELA; Microsoft Res; Fundamentals Collect Adapt Sysgt; Japan Soc Software Sci & Technol; Teknoparkistanbul; Acm In Cooperat Type: Proceedings Paper";<p>14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Istanbul, TURKEY, MAY 04-08, 2015</p>;NA;NA;NA;"Empathy; Human-robot interaction; Robotic Tutors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U33H47I9;conferencePaper;2015;"Gemeinboeck, Petra; Saunders, Rob";Movement Matters: How a Robot Becomes Body;PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'17);978-1-4503-5209-3;NA;10.1145/3077981.3078035;NA;This paper explores movement and its capacity for meaning-making and eliciting affect in human-robot interaction. Bringing together creative robotics, dance and machine learning, our research project develops a novel relational approach that harnesses dancers' movement expertise to design a non-anthropomorphic robot, its potential to move and capacity to learn. The project challenges the common assumption that robots need to appear human or animal-like to enable people to form connections with them. Our performative body-mapping (PBM) approach, in contrast, embraces the difference of machinic embodiment and places movement and its connection-making, knowledge-generating potential at the center of our social encounters. The paper discusses the first stage of the project, in which we collaborated with dancers to study how movement propels the becoming-body of a robot, and outlines our embodied approach to machine learning, grounded in the robot's performative capacity.;2015;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>4th International Conference on Movement and Computing (MOCO), Univ London, London, ENGLAND, 2017</p>;NA;NA;NA;"machine learning; social robotics; Dance; kinesthetic empathy; movement; non-anthropomorphic robots";Niehaus, K;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PRSLCB9J;journalArticle;2014;"Leite, Iolanda; Castellano, Ginevra; Pereira, Andre; Martinho, Carlos; Paiva, Ana";Empathic Robots for Long-term Interaction;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0227-1;NA;As a great number of robotic products are entering people's lives, the question of how can they behave in order to sustain long-term interactions with users becomes increasingly more relevant. In this paper, we present an empathic model for social robots that aim to interact with children for extended periods of time. The application of this model to a scenario where a social robot plays chess with children is described. To evaluate the proposed model, we conducted a long-term study in an elementary school and measured children's perception of social presence, engagement and social support.;2014-08;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;329-341;NA;3, SI;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Long-term interaction; Social presence Engagement; Social support";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4UEKEUV4;journalArticle;2014;"Hofree, Galit; Ruvolo, Paul; Bartlett, Marian Stewart; Winkielman, Piotr";Bridging the Mechanical and the Human Mind: Spontaneous Mimicry of a Physically Present Android;PLOS ONE;NA;1932-6203;10.1371/journal.pone.0099934;NA;The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android “humanlike.” These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.;2014-07-18;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;NA;NA;7;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA Publisher: PUBLIC LIBRARY SCIENCE Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NNFL2PQX;journalArticle;2014;"Rosenthal-von der Puetten, Astrid M.; Schulte, Frank P.; Eimler, Sabrina C.; Sobieraj, Sabrina; Hoffmann, Laura; Maderwald, Stefan; Brand, Matthias; Kraemer, Nicole C.";Investigations on empathy towards humans and robots using fMRI;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2014.01.004;NA;Although robots are starting to enter into our professional and private lives, little is known about the emotional effects they elicit. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots, we conducted a study that provides further insights into the question of whether humans show emotional reactions towards a robot and whether these reactions differ from those towards a human. To explore emotionality in human-robot interaction we conducted an fMRI study (n = 14). Participants were presented videos showing a human, a robot and an inanimate object, being treated in either an affectionate or in a violent way. Self-reported emotional states and functional imaging data revealed that participants indeed reacted emotionally when seeing the affectionate and violent videos. While no different neural activation patterns emerged for the affectionate interaction towards both, the robot and the human, we found differences in neural activity when comparing only the videos showing abusive behavior indicating that participants experience more emotional distress and show negative empathetic concern for the human in the abuse condition. This was supported by similar findings with regard to participant's self-reported emotional states. (C) 2014 Elsevier Ltd. All rights reserved.;2014-04;2021-02-11T03:48:32Z;2021-02-11T03:48:32Z;NA;201-212;NA;NA;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Functional magnetic resonance imaging; Empathy; Human-robot interaction; Experimental study; Psychophysiological measures";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7ADVGD5D;journalArticle;2014;"Boucenna, Sofiane; Gaussier, Philippe; Hafemeister, Laurence";Development of First Social Referencing Skills: Emotional Interaction as a Way to Regulate Robot Behavior;IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT;NA;1943-0604;10.1109/TAMD.2013.2284065;NA;In this paper, we study how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensory-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some “empathy” or at least “resonate” with the robot head (low level emotional resonance). Hence, we advocate the idea that social referencing can be bootstrapped from a simple sensory-motor system not dedicated to social interactions.;2014-03;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;42-55;NA;1;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Emotion; human-robot interaction; social referencing; sensory-motor architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZQGEXLI8;conferencePaper;2014;"Vitale, Jonathan; Williams, Mary-Anne; Johnston, Benjamin";Socially Impaired Robots: Human Social Disorders and Robots' Socio-Emotional Intelligence;SOCIAL ROBOTICS;978-3-319-11973-1 978-3-319-11972-4;NA;NA;NA;Social robots need intelligence in order to safely coexist and interact with humans. Robots without functional abilities in understanding others and unable to empathise might be a societal risk and they may lead to a society of socially impaired robots. In this work we provide a survey of three relevant human social disorders, namely autism, psychopathy and schizophrenia, as a means to gain a better understanding of social robots' future capability requirements. We provide evidence supporting the idea that social robots will require a combination of emotional intelligence and social intelligence, namely socio-emotional intelligence. We argue that a robot with a simple socio-emotional process requires a simulation-driven model of intelligence. Finally, we provide some critical guidelines for designing future socio-emotional robots.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;350-359;NA;NA;8755;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Journal Artificial Intelligence; Aldebaran Robot; Assoc Advancement Artificial Intelligence; Robohub; Stanford Ctr Legal Informat (CodeX) ISSN: 0302-9743 Type: Proceedings Paper";"<p>6th International Conference on Social Robotics (ICSR), Univ Technol,Ctr Quantum Computat &amp; Intelligent Syst, Sydney, AUSTRALIA, OCT 27-29, 2014</p>";NA;NA;NA;"empathy; social robots; autism; theory of mind; psychopathy; schizophrenia; simulation theory; socio-emotional intelligence";Beetz, M and Johnston, B and Williams, MA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NER8DSYP;conferencePaper;2014;"Hayes, Bradley; Ullman, Daniel; Alexander, Emma; Bank, Caroline; Scassellati, Brian";People Help Robots Who Help Others, Not Robots Who Help Themselves;2014 23RD IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN);978-1-4799-6765-0;NA;NA;NA;Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;255-260;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; IEEE Syst, Man & Cybernet Soc ISSN: 1944-9445 Type: Proceedings Paper";<p>23rd IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Heriot Watt Univ, Edinburgh, SCOTLAND, AUG 25-29, 2014</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
I9PTYTY5;conferencePaper;2014;"Sejima, Yoshihiro; Watanabe, Tomio; Jindai, Mitsuru";Development of an Interaction-activated Communication Model Based on a Heat Conduction Equation in Voice Communication;2014 23RD IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN);978-1-4799-6765-0;NA;NA;NA;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;832-837;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; IEEE Syst, Man & Cybernet Soc ISSN: 1944-9445 Type: Proceedings Paper";<p>23rd IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Heriot Watt Univ, Edinburgh, SCOTLAND, AUG 25-29, 2014</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GY4XJ8WC;conferencePaper;2014;"Majot, Andrew M.; Yampolskiy, Roman V.";AI Safety Engineering Through Introduction of Self-Reference Into Felicific Calculus via Artificial Pain and Pleasure;2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING;978-1-4799-4992-2;NA;NA;NA;In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of “moral mathematics” felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE Type: Proceedings Paper;<p>IEEE International Symposium on Ethics in Science, Technology and Engineering, Chicago, IL, MAY 23-24, 2014</p>;NA;NA;NA;"Concept Learning; Intelligent Agents; Machine Learning; Perceptual Reasoning; Philosophical Foundations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VLYMQ3NM;conferencePaper;2014;"Chumkamon, Sakmongkon; Eiji, Hayashi";ConBe Robot: The Development of Self-Perception and Expression in Face-to-Face Interaction;2014 JOINT 7TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING AND IN℡LIGENT SYSTEMS (SCIS) AND 15TH INTERNATIONAL SYMPOSIUM ON ADVANCED IN℡LIGENT SYSTEMS (ISIS);978-1-4799-5955-6;NA;NA;NA;In social robot development of interaction system robot, it is necessary to develop the fundamental function such as the robot perception. Due to the robot should correctly interpret a behavior or mental expression of the human. If the robot has a good emotional insight of the human, it is the advantage for the robot perception. In this paper, we implement the significant technique that take an advantage to the robot such as the human detection, face detection and recognition. Basically, these techniques could further enable the robot capability of intelligent empathy from the expression of human. We intensively study the vision method for facial expression recognition (FER) to understanding the human emotion and interacting by the robot expression in particular case. The robot interaction is based on the interested person that the robot can recognize with their emotional expression. We also experiment the system in term of face-to-face between robot and user with demonstrate using the head robot along with the result, such as the performance of the perception and the behavior expression of the robot.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;769-775;NA;NA;NA;NA;NA;NA;Joint International Conference on Soft Computing and Intelligent Systems SCIS and International Symposium on Advanced Intelligent Systems ISIS;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Japan Soc Fuzzy Theory & Intelligent informat; Korean Inst Intelligent Syst; Int Fuzzy Syst Assoc; N Amer Fuzzy Informat Proc Soc; IEEE Syst, Man, & Cybernet Soc; IEEE Computat Intelligence Soc; World Federat Soft Comp; IEEE SMC Japan Chapter ISSN: 2377-6870 Type: Proceedings Paper";<p>Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS), Kitakyushu, JAPAN, DEC 03-06, 2014</p>;NA;NA;NA;"social robot; human-robot interaction; facial expression recognition";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DNA4QUJ4;conferencePaper;2014;"Costa, Sandra; Soares, Filomena; Pereira, Ana Paula; Santos, Cristina; Hiolle, Antoine";A Pilot Study using Imitation and Storytelling Scenarios as Activities for Labelling Emotions by Children with Autism using a Humanoid Robot;FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014);978-1-4799-7540-2;NA;NA;NA;In this paper we present a child-robot interaction pilot study, focusing on recognizing and labelling emotions displayed by a humanoid robot. ZECA (Zeno Engaging Children with Autism) has a special skin covering its face which allows the display of facial expressions representing five emotions: joy, sadness, fear, anger, and surprise. These facial expressions were used in two different game scenarios, involving imitation and storytelling activities. The goal of these scenarios is to help the child acquire knowledge about different emotions and to improve their skill in recognizing them. The results show that these scenarios are appropriate for the goal established for this study, and positive behaviours concerning non-verbal communication were observed. This exploratory study demonstrated the possible positive outcomes this child-robot interaction can produce and highlighted the issues regarding data collection and their analysis that will inform future studies.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;299-304;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE Type: Proceedings Paper;<p>4th Joint IEEE International Conferences on Development and Learning and Epigenetic Robotics (IEEE ICDL-Epirob), Genoa, ITALY, OCT 13-16, 2014</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2R8DYVMY;conferencePaper;2014;"Mok, Brian; Yang, Stephen; Sirkin, David; Ju, Wendy";Empathy: Interactions with Emotive Robotic Drawers;HRI'14: PROCEEDINGS OF THE 2014 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-2658-2;NA;10.1145/2559636.2563720;NA;The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;250-251;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; ACM SIGAI; IEEE Robotics & Automation; HFES; AAAI; ACM; IEEE ISSN: 2167-2121 Type: Proceedings Paper";<p>9th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Bielefeld, GERMANY, MAR 03-06, 2014</p>;NA;NA;NA;"Human Robot Interactions; Interaction Design; Interactive Furniture; Video Prototyping; Wizard of Oz Experiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YGQTKN9D;conferencePaper;2014;"Obaid, Mohammad; Kuchenbrandt, Dieta; Bartneck, Christoph";Empathy and Yawn Contagion: Can we (Humans) Catch Yawns from Robots?;HRI'14: PROCEEDINGS OF THE 2014 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-2658-2;NA;10.1145/2559636.2563702;NA;Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;260-261;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; ACM SIGAI; IEEE Robotics & Automation; HFES; AAAI; ACM; IEEE ISSN: 2167-2121 Type: Proceedings Paper";<p>9th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Bielefeld, GERMANY, MAR 03-06, 2014</p>;NA;NA;NA;"Empathy; Humanoid; Robot; Yawn";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JLAJ2T5U;conferencePaper;2014;Redstone, Josh;Making Sense of Empathy with Social Robots;SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS;978-1-61499-480-0 978-1-61499-479-4;NA;10.3233/978-1-61499-480-0-171;NA;Social robots exploit human-like behaviors so that people might form emotional bonds with them. Ostensibly, such bonding is an empathic response on the part of the person toward the robot. However, as philosopher Catrin Misselhorn points out, it's conceptually problematic to say that people empathize with robots, for the social robots of the present arguably don't possess human-like emotions. To address this concern, Misselhorn proposes that empathy with robots is possible owing to a sort of interplay between perception and imagination that she calls “imaginative perception.” In this paper, I shall make a preliminary sketch of a conceptual framework that, I argue, serves as a clearer, more conceptually straight-forward alternative to imaginative perception. On this framework, empathy with social robots is the result of a kind of perceptual illusion, rather than the result of the imaginative perception of emotion.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;171-177;NA;NA;273;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 0922-6389 Type: Proceedings Paper;<p>Conference on Robo-Philosophy - Sociable Robotics and the Future of Social Relations, Aarhus, DENMARK, AUG 20-23, 2014</p>;NA;NA;NA;"emotion; empathy; sympathy; uncanny valley; imaginative perception";Seibt, J and Hakli, R and Norskov, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
T2EF3ZEN;conferencePaper;2014;Yamazaki, Ryuji;Conditions of Empathy in Human-Robot Interaction;SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS;978-1-61499-480-0 978-1-61499-479-4;NA;10.3233/978-1-61499-480-0-179;NA;The purpose of this paper is to consider the sociality of social robots with the focus on the notion of empathy. Social robots are designed to exploit various biological mechanisms that trigger anthropomorphizing reactions in humans and systems that seem capable of experiencing or feeling are being constructed. A question is whether empathic reactions by humans are justifiable from a conceptual and ethical point of view. I will mainly address the conceptual strand of this question and investigate whether empathy with robots is appropriate or misapplied relative to our current concept of empathy.;2014;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;179-186;NA;NA;273;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 0922-6389 Type: Proceedings Paper;<p>Conference on Robo-Philosophy - Sociable Robotics and the Future of Social Relations, Aarhus, DENMARK, AUG 20-23, 2014</p>;NA;NA;NA;"emotion; empathy; embodiment; android; alteration; openness; subjectivity";Seibt, J and Hakli, R and Norskov, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E36IUEKP;journalArticle;2013;"Haffey, Anthony; Press, Clare; O'Connell, Garret; Chakrabarti, Bhismadev";Autistic Traits Modulate Mimicry of Social but not Nonsocial Rewards;AUTISM RESEARCH;NA;1939-3792;10.1002/aur.1323;NA;Autism Spectrum Conditions (ASC) are associated with diminished responsiveness to social stimuli, and especially to social rewards such as smiles. Atypical responsiveness to social rewards, which reinforce socially appropriate behavior in children, can potentially lead to a cascade of deficits in social behavior. Individuals with ASC often show diminished spontaneous mimicry of social stimuli in a natural setting. In the general population, mimicry is modulated both by the reward value and the sociality of the stimulus (i.e., whether the stimulus is perceived to belong to a conspecific or an inanimate object). Since empathy and autistic traits are distributed continuously in the general population, this study aimed to test if and how these traits modulated automatic mimicry of rewarded social and nonsocial stimuli. High and low rewards were associated with human and robot hands using a conditioned learning paradigm. Thirty-six participants from the general population then completed a mimicry task involving performing a prespecified hand movement which was either compatible or incompatible with a hand movement presented to the participant. High autistic traits (measured using the Autism Spectrum Quotient, AQ) predicted lesser mimicry of high-reward than low-reward conditioned human hands, whereas trait empathy showed an opposite pattern of correlations. No such relations were observed for high-reward vs. low-reward conditioned robot hands. These results demonstrate how autistic traits and empathy modulate the effects of reward on mimicry of social compared to nonsocial stimuli. This evidence suggests a potential role for the reward system in underlying the atypical social behavior in individuals with ASC, who constitute the extreme end of the spectrum of autistic traits. Autism Res 2013, 6: 614-620. (c) 2013 International Society for Autism Research, Wiley Periodicals, Inc.;2013-12;2021-02-11T03:48:33Z;2021-02-11T03:48:33Z;NA;614-620;NA;6;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"empathy; autism; imitation; mimicry; nonsocial; reward; social";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BHCWQV4L;journalArticle;2013;"Kuehnlenz, Barbara; Sosnowski, Stefan; Buss, Malte; Wollherr, Dirk; Kuehnlenz, Kolja; Buss, Martin";Increasing Helpfulness towards a Robot by Emotional Adaption to the User;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-013-0182-2;NA;This article describes an emotional adaption approach to proactively trigger increased helpfulness towards a robot in task-related human-robot interaction (HRI). Based on social-psychological predictions of human behavior, the approach aims at inducing empathy, paired with a feeling of similarity in human users towards the robot. This is achieved by two differently expressed emotional control variables: by an explicit statement of similarity before task-related interaction, and implicitly expressed by adapting the emotional state of the robot to the mood of the human user, such that the current values of the human mood in the dimensions of pleasure, arousal, and dominance (PAD) are matched. The thereby shifted emotional state of the robot serves as a basis for the generation of task-driven emotional facial-and verbal expressions, employed to induce and sustain high empathy towards the robot throughout the interaction. The approach is evaluated in a user study utilizing an expressive robot head. The effectiveness of the approach is confirmed by significant experimental results. An analysis of the individual components of the approach reveals significant effects of explicit emotional adaption on helpfulness, as well as on the HRI-key concepts anthropomorphism and animacy.;2013-11;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;457-476;NA;4;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Emotions; Empathy; Anthropomorphism; Adaption; Animacy; Helpfulness; Prosocial behavior; Similarity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IHVYIFAY;journalArticle;2013;"Ben Moussa, Maher; Magnenat-Thalmann, Nadia";Toward socially responsible agents: integrating attachment and learning in emotional decision-making;COMPUTER ANIMATION AND VIRTUAL WORLDS;NA;1546-4261;10.1002/cav.1515;NA;Our goal is to create socially responsible agents, either robots or virtual humans. In this paper, we present an integration of emotions, attachment, and learning in emotional decision-making to achieve this goal. Based on emerging psychological theories, we aim at building human-like emotional decision-making, where emotions play a central role in selecting the next action to be performed by the agent. Here, we present our own approach for emotion appraisal where we use emotional attachment as an important impulse for determining the intensities of emotions. Emotions in their turn are used to calculate the emotional attachment toward the users and for learning to predict future consequences. We report on the results of a simulation evaluation where we assess the influence of emotions, attachment, and learning on decision-making. It is our strong belief that by giving an agent the ability to have emotions and to feel empathy and emotional attachment toward others, we will ultimately give this agent the ability to learn and improve its social behavior skills through interactions with the users and through user feedback. Copyright (c) 2013 John Wiley & Sons, Ltd.;2013-08;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;327-334;NA;3-4;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY-BLACKWELL Type: Article;NA;NA;NA;NA;"robots; affective computing; emotional decision-making; interaction; virtual humans";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NGMSAW2P;journalArticle;2013;"Niculescu, Andreea; van Dijk, Betsy; Nijholt, Anton; Li, Haizhou; See, Swee Lan";Making Social Robots More Attractive: The Effects of Voice Pitch, Humor and Empathy;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-012-0171-x;NA;In this paper we explore how simple auditory/verbal features of the spoken language, such as voice characteristics (pitch) and language cues (empathy/humor expression) influence the quality of interaction with a social robot receptionist. For our experiment two robot characters were created: Olivia, the more extrovert, exuberant, and humorous robot with a higher voice pitch and Cynthia, the more introvert, calmer and more serious robot with a lower voice pitch. Our results showed that the voice pitch seemed to have a strong influence on the way users rated the overall interaction quality, as well as the robot's appeal and overall enjoyment. Further, the humor appeared to improve the users' perception of task enjoyment, robot personality and speaking style while the empathy showed effects on the way users evaluated the robot's receptive behavior and the interaction ease. With our study, we would like to stress in particular the importance of voice pitch in human robot interaction and to encourage further research on this topic.;2013-04;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;171-191;NA;2;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Social robots; Humor; Quantitative evaluation; User studies; Voice pitch";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6TRCE3L3;journalArticle;2013;"Leite, Iolanda; Martinho, Carlos; Paiva, Ana";Social Robots for Long-Term Interaction: A Survey;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-013-0178-y;NA;As the field of HRI evolves, it is important to understand how users interact with robots over long periods. This paper reviews the current research on long-term interaction between users and social robots. We describe the main features of these robots and highlight the main findings of the existing long-term studies. We also present a set of directions for future research and discuss some open issues that should be addressed in this field.;2013-04;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;291-308;NA;2;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Long-term interaction; Longitudinal studies";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VAIDHTE8;journalArticle;2013;"Leite, Iolanda; Pereira, Andre; Mascarenhas, Samuel; Martinho, Carlos; Prada, Rui; Paiva, Ana";The influence of empathy in human-robot relations;INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES;NA;1071-5819;10.1016/j.ijhcs.2012.09.005;NA;The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human robot interaction. (C) 2012 Elsevier Ltd. All rights reserved.;2013-03;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;250-260;NA;3;71;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND Publisher: ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Empathy; Social robots; Affective interactions; Artificial companions; Friendship";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CDELH2W4;conferencePaper;2013;"Rughinis, Razvan; Rughinis, Cosima";Robots and the European Public Imagination: Eurobarometer Survey Results and Methodological Issues;2013 3RD INTERNATIONAL CONFERENCE ON SOCIAL SCIENCES AND SOCIETY (ICSSS 2013), PT 1;978-1-61275-061-3;NA;NA;NA;We analyze the Eurobarometer 77.1 / 2012 survey data on robots, and we identify three attitudinal clusters of respondents: 1) people who adopt an anthropomorphic approach, accepting robots for high-and low-empathy tasks, 2) people who have an instrumental orientation, accepting robots only for low-empathy tasks, and 3) respondents who are generally aversive towards robots. Young people, students, the higher educated, and men are more often found in the first two categories than in the third. The third attitudinal cluster is more skeptical when evaluating robots, while the first two clusters do not differ in their assessments, being equally appreciative. We evaluate critically the relevance of such survey-based classification for real-life decision situations, especially when people's answers about robots are not based on actual experiences of interaction with robots. Still, investigating the cultural construct of `robot' in present-day public imagination and uncovering its variability is potentially useful for technological designers, marketers, and policy-makers.;2013;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;230-235;NA;NA;32;NA;NA;NA;Advances in Education Research;NA;NA;NA;INFORMATION ENGINEERING RESEARCH INST, USA;100 CONTINENTAL DR, NEWARK, DE 19713 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Informat Engn Res Inst ISSN: 2160-1070 Type: Proceedings Paper;<p>3rd International Conference on Social Sciences and Society (ICSSS), SOUTH KOREA, DEC 27-28, 2013</p>;NA;NA;NA;"Survey research; Robots; Public imagination";Lee, G;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YHXSSE75;conferencePaper;2013;"Deshmukh, Amol; Castellano, Ginevra; Kappas, Arvid; Barendregt, Wolmet; Nabais, Fernando; Paiva, Ana; Ribeiro, Tiago; Leite, Iolanda; Aylett, Ruth";Towards Empathic Artificial Tutors;PROCEEDINGS OF THE 8TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI 2013);978-1-4673-3055-8 978-1-4673-3099-2;NA;NA;NA;In this paper we discuss how the EMOTE project will design, develop and evaluate a new generation of artificial embodied tutors that have perceptive capabilities to engage in empathic interactions with learners in a shared physical space.;2013;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;113+;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; IEEE Robot & Automat (RA); AAAI; Human Factors & Ergonom Soc (HFES); ACM SIGCHI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>8th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Tokyo, JAPAN, MAR 03-06, 2013</p>;NA;NA;NA;"Empathy; Human-robot interaction; Robotic Tutors";Kuzuoka, H and Evers, V and Imai, M and Forlizzi, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
62ZK9NR7;conferencePaper;2013;"Jo, Doori; Han, Jooyun; Chung, Kyungmi; Lee, Sukhan";Empathy between Human and Robot?;PROCEEDINGS OF THE 8TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI 2013);978-1-4673-3055-8 978-1-4673-3099-2;NA;NA;NA;This paper aims at finding the answer to the essential question: Can people perceive a robot's presence as having a social existence? We attempt to apply a sociological and psychological approach to understand the influence of robot beings, by observing human emotion and perception changes while subjects watched a funny video clip in the presence of a robot or a human companion, each of which made their own typical laughing sounds. From this experiment, we found that the robot did not affect the human's positive emotions as much as a human companion did, but the robot did discourage negative emotions. However, the subjects were, in general, amused when they were watching the video with the robot. This amusement is similar to the contagious effect of sharing humor with another human being. Our findings suggest that the subjects accepted the robot's presence as a kind of existence empathically.;2013;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;151+;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; IEEE Robot & Automat (RA); AAAI; Human Factors & Ergonom Soc (HFES); ACM SIGCHI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>8th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Tokyo, JAPAN, MAR 03-06, 2013</p>;NA;NA;NA;"social robot; empathy; robot companion; human robot interaction; emotional contagion; presence";Kuzuoka, H and Evers, V and Imai, M and Forlizzi, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X5RADI3H;conferencePaper;2013;"Rosenthal-von der Puetten, Astrid M.; Schulte, Frank P.; Eimler, Sabrina C.; Hoffmann, Laura; Sobieraj, Sabrina; Maderwald, Stefan; Kraemer, Nicole C.; Brand, Matthias";Neural Correlates of Empathy Towards Robots;PROCEEDINGS OF THE 8TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI 2013);978-1-4673-3055-8;NA;NA;NA;We conducted an fMRI study to investigate emotionality in human-robot interaction. Subjects (N=14) were presented videos showing a human, a robot and an unanimated object, being treated in either an affectionate or a violent way. Violent interaction towards both the robot and the human resulted in similar neural activation patterns in classic limbic structures indicating that both the robot and the human elicit similar emotional reactions. However, differences in neural activity suggest that participants show more negative empathetic concern for the human in a negative situation.;2013;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;215-216;NA;NA;NA;NA;NA;NA;ACMIEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; IEEE Robot & Automat (RA); AAAI; Human Factors & Ergonom Soc (HFES); ACM SIGCHI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>8th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Tokyo, JAPAN, MAR 03-06, 2013</p>;NA;NA;NA;"empathy; human-robot interaction; experimental study; functional magnetic resonance imaging";Kuzuoka, H and Evers, V and Imai, M and Forlizzi, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GI8GMH8F;conferencePaper;2013;"Lebec, Olivier; Ben Ghezala, Mohamed Walid; Leynart, Violaine; Laffont, Isabelle; Fattal, Charles; Devilliers, Laurence; Chastagnol, Clement; Martin, Jean-Claude; Mezouar, Youcef; Korrapatti, Hermanth; Dupourque, Vincent; Leroux, Christophe";High level functions for the intuitive use of an assistive robot;2013 IEEE 13TH INTERNATIONAL CONFERENCE ON REHABILITATION ROBOTICS (ICORR);978-1-4673-6024-1 978-1-4673-6022-7;NA;NA;NA;This document presents the research project ARMEN (Assistive Robotics to Maintain Elderly People in a Natural environment), aimed at the development of a user friendly robot with advanced functions for assistance to elderly or disabled persons at home. Focus is given to the robot SAM (Smart Autonomous Majordomo) and its new features of navigation, manipulation, object recognition, and knowledge representation developed for the intuitive supervision of the robot. The results of the technical evaluations show the value and potential of these functions for practical applications. The paper also documents the details of the clinical evaluations carried out with elderly and disabled persons in a therapeutic setting to validate the project.;2013;2021-02-11T03:48:34Z;2021-02-11T03:48:34Z;NA;NA;NA;NA;NA;NA;NA;NA;International Conference on Rehabilitation Robotics ICORR;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; EMB; IEEE Robot & Automat Soc; Ctr Sensorimotor Neural Engn NSF Engn Res Ctr ISSN: 1945-7898 Type: Proceedings Paper";<p>13th IEEE International Conference on Rehabilitation Robotics (ICORR), Univ Washington Campus, Seattle, WA, JUN 24-26, 2013</p>;NA;NA;NA;"object recognition; assistive robotics; elderly and disabled people; empathy emotion understanding; evaluation protocol; intuitive HMI; mobile manipulation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2P4ULJTI;journalArticle;2013;"Urgen, Burcu A.; Plank, Markus; Ishiguro, Hiroshi; Poizner, Howard; Saygin, Ayse P.";EEG theta and Mu oscillations during perception of human and robot actions;FRONTIERS IN NEUROROBOTICS;NA;1662-5218;10.3389/fnbot.2013.00019;NA;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other.;2013;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"EEG; social robotics; action perception; mirror neuron system; mu rhythm; theta rhythm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DUK3XGEZ;journalArticle;2013;"Rosenthal-von der Puetten, Astrid M.; Kraemer, Nicole C.; Hoffmann, Laura; Sobieraj, Sabrina; Eimler, Sabrina C.";An Experimental Study on Emotional Reactions Towards a Robot;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-012-0173-8;NA;"Although robots are starting to enter into our professional and private lives, little is known about the emotional effects which robots elicit. However, insights into this topic are an important prerequisite when discussing, for example, ethical issues regarding the question of what role we (want to) allow robots to play in our lives. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots and anecdotal evidence of emotional attachments to robots (e. g. Klamer and BenAllouch in Trappl R. (ed.), Proceedings of EMCSR 2010, Vienna, 2010; Klamer and BenAllouch in Proceedings of the 27th International Conference on Human Factors in Computing Systems (CHI-2010), Atlanta, GA. ACM, New York, 2010; Kramer et al. in Appl. Artif. Intell. 25(6): 474-502, 2011), we conducted a study that provides further insights into the question of whether humans show emotional reactions towards Ugobe's Pleo, which is shown in different situations. We used a 2 x 2 design with one between-subjects factor “prior interaction with the robot” (never seen the robot before vs. 10-minute interaction with the robot) and a within-subject factor “type of video” (friendly interaction video vs. torture video). Following a multi-method approach, we assessed participants' physiological arousal and self-reported emotions as well as their general evaluation of the videos and the robot. In line with our hypotheses, participants showed increased physiological arousal during the reception of the torture video as compared to the normal video. They also reported fewer positive and more negative feelings after the torture video and expressed empathic concern for the robot. It appears that the acquaintance with the robot does not play a role, as “prior interaction with the robot” showed no effect.";2013-01;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;17-34;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Human-robot interaction; Experimental study; Emotional response; Psychophysiological measures";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4KSJMG5Z;conferencePaper;2013;"Marti, Patrizia; Stienstra, Jelle T.";Engaging through her eyes Embodying the perspective of a robot companion;PROCEEDINGS OF THE EIGHTEENTH INTERNATIONAL SYMPOSIUM ON ARTIFICIAL LIFE AND ROBOTICS (AROB 18TH `13);978-4-9902880-7-5;NA;NA;NA;In response to a change in the use of computers and interactive technologies, traditional Human-Computer Interaction concepts of usability, efficiency and productivity have progressively been enriched with other concepts such as curiosity, empathy, playfulness and affection [1]. Korhonen et al. [2] state that the acceptance of a product depends not only on its utilitarian properties but also on non-utilitarian ones including playfulness. However, even if there seems to be near consensus on the importance of designing interactive systems beyond rational and functional requirements, the way in which this can be achieved is still an open research issue. In this paper we describe our design approach to develop an embodied and playful mobile interface to control a robot companion in a smart home environment. A major challenge of the research is to engage an older person in rich, empathic and playful interaction with a robot to encourage a prolonged, subtle, and stimulating effect beyond the initial encounter [3]. This challenge is explored through the design of innovative concepts of playful interaction embodying the perspective of the robot companion.;2013;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;5-8;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ALIFE ROBOTICS CO, LTD;3661-8 OAZA, SHIMOHANDA, OITA 870-1112, JAPAN;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Symposium Artificial Life & Robot, Int Org Comm; Soc Instrument & Control Engineers; Robot Soc Japan; Inst Elect Engineers Japan; Inst Syst Control & Informat Engineers; Inst Elect Informat & Commun Engineers; IEEE Japan Council, IEEE Robot & Automat Soc, Japan Chapter; Japan Robot Assoc; Inst Control Robot & Syst; Chinese Assoc Artificial Intelligence Type: Proceedings Paper";<p>18th International Symposium on Artificial Life and Robotics (AROB), Daejeon, SOUTH KOREA, JAN 30-FEB 01, 2013</p>;NA;NA;NA;"embodied interaction; graphical user interface; playful interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FVKV87H9;journalArticle;2012;"Morita, Tomoyo; Slaughter, Virginia; Katayama, Nobuko; Kitazaki, Michiteru; Kakigi, Ryusuke; Itakura, Shoji";Infant and adult perceptions of possible and impossible body movements: An eye-tracking study;JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY;NA;0022-0965;10.1016/j.jecp.2012.07.003;NA;This study investigated how infants perceive and interpret human body movement. We recorded the eye movements and pupil sizes of 9- and 12-month-old infants and of adults (N = 14 per group) as they observed animation clips of biomechanically possible and impossible arm movements performed by a human and by a humanoid robot. Both 12-month-old infants and adults spent more time looking at the elbows during impossible compared with possible arm movements, irrespective of the appearance of the actor. These results suggest that by 12 months of age, infants recognize biomechanical constraints on how arms move, and they extend this knowledge to humanoid robots. Adults exhibited more pupil dilation in response to the human's impossible arm movements compared with the possible ones, but 9- and 12-month-old infants showed no differential pupil dilation to the same actions. This finding suggests that the processing of human body movements might still be immature in 12-month-olds, as they did not show an emotional response to biomechanically impossible body movements. We discuss these findings in relation to the hypothesis that perception of others' body movements relies upon the infant's own sensorimotor experience. (C) 2012 Elsevier Inc. All rights reserved.;2012-11;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;401-414;NA;3;113;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA Publisher: ACADEMIC PRESS INC ELSEVIER SCIENCE Type: Article;NA;NA;NA;NA;"Robot; Biomechanical constraints; Body movement; Eye-tracking; Infant cognition; Pupil size";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RUGMN86V;conferencePaper;2012;"Dimitrova, Maya; Vegt, Niko; Barakova, Emilia";Designing a System of Interactive Robots for Training Collaborative Skills to Autistic Children;2012 15TH INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL);978-1-4673-2427-4;NA;10.1109/ICL.2012.6402179;NA;Using robots to reward and stimulate children doing tasks together can be helpful in improving their social skills. Robots implemented 3 types of behavior scenarios - imitate, enhance and counteract - in a collaborative game of teaching robots perform movements shown by hand gestures. The paper presents a novel account of ASD symptoms based on the interplay of empathic concern and empathic accuracy in different personalities with and without cognitive deficits. Performance of autistic children was compared with two age groups of typically developing children - under and above the age of 7. The study confirmed the limited resource hypothesis - cognitive and motivational - bringing about the observed phenomena in situations of limited attention resources and performance under distraction. The robotic framework for educating children has shown potential for developing of various complex cognitive and social skills and has substantial developmental impact.;2012;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>15th International Conference on Interactive Collaborative Learning (ICL), Villach, AUSTRIA, SEP 26-28, 2012</p>;NA;NA;NA;"robots; empathy; autism; behavioral training with multiagent system of robots; collaboration through immitation games; design of interactive robot scenarios; learning robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7BH4DYF9;conferencePaper;2012;"Gonsior, Barbara; Buss, Malte; Sosnowski, Stefan; Wollherr, Dirk; Kuehnlenz, Kolja; Buss, Martin";Towards Transferability of Theories on Prosocial Behavior from Social Psychology to HRI;2012 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO);978-1-4673-0482-5 978-1-4673-0481-8;NA;NA;NA;This paper describes the transfer of theories on prosocial behavior from Social Psychology to human-robot interaction (HRI) in terms of helpfulness shown by humans towards a robot. Theoretical foundations are given, and relevant influence factors for prosocial behavior are defined. The paper provides an overview on how these factors can be transferred to HRI and are implemented in two experimental settings. In a first experiment, situational empathy towards a robot is increased. In a second experiment, similarity is induced by means of emotional adaption to the mood of the user. Results show that helpfulness towards a robot can be increased by this approach, thus, re-evaluating the transferability of theories from Social Psychology to HRI.;2012;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;101-103;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot & Automat Soc; Aldebaran Robot; Sensodrive; Cluster Excellence Cognit Tech Syst; TUM, Inst Adv Study Type: Proceedings Paper";<p>IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO), Tech Univ Munchen, Munich, GERMANY, MAY 21-23, 2012</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2W2ELGV5;conferencePaper;2012;"Leite, Iolanda; Castellano, Ginevra; Pereira, Andre; Martinho, Carlos; Paiva, Ana";Modelling Empathic Behaviour in a Robotic Game Companion for Children: an Ethnographic Study in Real-World Settings;HRI'12: PROCEEDINGS OF THE SEVENTH ANNUAL ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-1063-5;NA;NA;NA;The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. How-ever, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the childrens affective states. The findings suggest that the robots empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with.;2012;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;367-374;NA;NA;NA;NA;NA;NA;ACMIEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGART; HFES; AAAI; IEEE Robot & Automat ISSN: 2167-2121 Type: Proceedings Paper";<p>7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Boston, MA, MAR 05-08, 2012</p>;NA;NA;NA;"Empathy; Social Robots; Affect Recognition; Children";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SU4GCH9Y;conferencePaper;2011;Leite, Iolanda;Using Adaptive Empathic Responses to Improve Long-Term Interaction with Social Robots;USER MODELING, ADAPTATION, AND PERSONALIZATION;978-3-642-22361-7;NA;NA;NA;The goal of this research is to investigate the effects of empathy and adaptive behaviour in long-term interaction between social robots and users. To address this issue, we propose an action selection mechanism that will allow a social robot to chose adaptive empathic responses, in the attempt to keep users engaged over several interactions.;2011;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;446-449;NA;NA;6787;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: User Modeling Inc; ACM SIGART, SIGCHI & SIGIR; Chen Family Fdn; Microsoft Res; US Natl Sci Fdn; Springer; Telefon Espana; Univ Girona ISSN: 0302-9743 Type: Proceedings Paper";<p>19th International Conference on User Modeling, Adaptation and Personalization (UMAP 2011), Girona, SPAIN, JUL 11-15, 2011</p>;NA;NA;NA;"empathy; social robots; adaptive feedback; affective user modeling";Konstan, JA and Conejo, R and Marzo, JL and Oliver, N;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
65RYMWU6;conferencePaper;2011;"Pereira, Andre; Leite, Iolanda; Masearenhas, Samuel; Martinho, Carlos; Paiva, Ana";Using Empathy to Improve Human-Robot Relationships;HUMAN-ROBOT PERSONAL RELATIONSHIPS;978-3-642-19384-2;NA;NA;NA;For robots to become our personal companions in the future, they need to know how to socially interact with us. One defining characteristic of human social behaviour is empathy. In this paper, we present a robot that acts as a social companion expressing different kinds of empathic behaviours through its facial expressions and utterances. The robot comments the moves of two subjects playing a chess game against each other, being empathic to one of them and neutral towards the other. The results of a pilot study suggest that users to whom the robot was empathic perceived the robot more as a friend.;2011;2021-02-11T03:48:35Z;2021-02-11T03:48:35Z;NA;130+;NA;NA;59;NA;NA;NA;Lecture Notes of the Institute for Computer Sciences Social Informatics and Telecommunications Engineering;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 1867-8211 Type: Proceedings Paper;<p>3rd International Conference on Human-Robot Personal Relationships, Leiden, NETHERLANDS, JUN 23-24, 2010</p>;NA;NA;NA;"empathy; human-robot interaction; companionship";Lamers, MH and Verbeek, FJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
39PV5JFF;conferencePaper;2011;"Mazzei, Daniele; Lazzeri, Nicole; Billeci, Lucia; Igliozzi, Roberta; Mancini, Alice; Ahluwalia, Arti; Muratori, Filippo; De Rossi, Danilo";Development and evaluation of a social robot platform for therapy in autism;2011 ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY (EMBC);978-1-4244-4122-8;NA;NA;NA;People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred “affective” state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training.;2011;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;4515-4518;NA;NA;NA;NA;NA;NA;IEEE Engineering in Medicine and Biology Society Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Engn Med & Biol Soc (EMBS) ISSN: 1557-170X Type: Proceedings Paper";<p>33rd Annual International Conference of the IEEE Engineering-in-Medicine-and-Biology-Society (EMBS), Boston, MA, AUG 30-SEP 03, 2011</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U5AUCHPF;conferencePaper;2011;"Angulo, Cecilio; Comas, Joan; Pardo, Diego";Aibo JukeBox - A Robot Dance Interactive Experience;ADVANCES IN COMPUTATIONAL IN℡LIGENCE, IWANN 2011, PT II;978-3-642-21498-1;NA;NA;NA;This paper presents a human-robot interaction system based on the Aibo platform. This robot is both, complex and empathetic enough to generate a high level of interest from the user. The complete system is an interactive JukeBox intending to generate affective participation, i.e., empathy, from the user towards the robot and its behavior. This application is based on a robotic dance control system that generates movements adequate to the music rhythm using a stochastic controller. The user can interact with the system selecting or providing the songs to be danced by the robot. The application has been successfully presented in different non-scientific scenarios.;2011;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;605-612;NA;NA;6692;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Malaga; Univ Granada; Univ Politecnica Catalunya ISSN: 0302-9743 Type: Proceedings Paper";<p>11th International Work-Conference on Artificial Neural Networks (IWANN), Torremolinos, SPAIN, JUN 08-10, 2011</p>;NA;NA;NA;"Human Robot Interaction; dancing robots; interactive environment";Cabestany, J and Rojas, I and Joya, G;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QQUJ3B3N;conferencePaper;2011;"Trappl, Robert; Krajewski, Markus; Ruttkay, Zsofia; Widrich, Virgil";Robots as Companions: What can we Learn from Servants and Companions in Literature, Theater, and Film?;PROCEEDINGS OF THE 2ND EUROPEAN FUTURE TECHNOLOGIES CONFERENCE AND EXHIBITION 2011 (FET 11);NA;NA;10.1016/j.procs.2011.12.029;NA;Many researchers are working on developing robots into adequate partners, be it at the working place, be it at home or in leisure activities, or enabling elder persons to lead a self-determined, independent life. While quite some progress has been made in e. g. speech or emotion understanding, processing and expressing, the relations between humans and robots are usually only short-term. In order to build long-term, i.e. social relations, qualities like empathy, trust building, dependability, non-patronizing, and others will be required. But these are just terms and as such no adequate starting points to “program” these capacities even more how to avoid the problems and pitfalls in interactions between humans and robots. However, a rich source for doing this is available, unused until now for this purpose: artistic productions, namely literature, theater plays, not to forget operas, and films with their multitude of examples. Poets, writers, dramatists, screen-writers, etc. have studied for centuries the facets of interactions between persons, their dynamics, and the related snags. And since we wish for human-robot relations as master-servant relations - the human obviously being the master - the study of these relations will be prominent. A procedure is proposed, with four consecutive steps, namely Selection, Analysis, Categorization, and Integration. Only if we succeed in developing robots which are seen as servants we will be successful in supporting and helping humans through robots. (C) Selection and peer-review under responsibility of FET11 conference organizers and published by Elsevier B. V.;2011;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;96-98;NA;NA;7;NA;NA;NA;Procedia Computer Science;NA;NA;NA;ELSEVIER SCIENCE BV;SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: European Commiss Future & Emerging Technol (FET); European Res Consortium Informat & Mathemat (ERCIM); Hungarian Acad Sci; Hungarian Presidency European Un ISSN: 1877-0509 Type: Proceedings Paper";<p>2nd European Future Technologies Conference and Exhibition (FET), Budapest, HUNGARY, MAY 04-06, 2011</p>;NA;NA;NA;"robots; companions; film; literature; servants; theater";Giacobino, E and Pfeifer, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
72YP9R2E;journalArticle;2010;"Looije, Rosemarijn; Neerincx, Mark A.; Cnossen, Fokie";Persuasive robotic assistant for health self-management of older adults: Design and evaluation of social behaviors;INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES;NA;1071-5819;10.1016/j.ijhcs.2009.08.007;NA;"Daily health self-management, such as the harmonization of food, exercise and medication, is a major problem for a large group of older adults with obesity or diabetics Computer-based personal assistance can help to behave healthy by persuading and guiding older adults For effective persuasion, the assistant should express social behaviors (e g, turn taking, emotional expressions) to be trustworthy and show empathy From the motivational interviewing method and synthetic assistants' literature, we derived a set of social behaviors, and implemented a subset in a physical character, a virtual character and a text interface The first behavior type concerns conversing with high-level dialogue (semantics, intentions), which could be implemented in all 3 assistants The other behavior types could only be implemented in the characters: showing natural cues (e g, gaze, posture), expressing emotions (e g, compassionate face), and accommodating social conversations (e.g, turn taking). In an experiment, 24 older adults (45-65) interacted with the text interface and one of the characters, conform a “one-week diabetics scenario” They experienced the virtual and physical character as more empathic and trustworthy than the text-based assistant, and expressed more conversational behavior with the characters However, it seems that the preference of interacting with the character or the text interface was influenced by the conscientiousness of the participant; more conscientious people liked the text interface better Older adults responded more negative to the characters that lacked the social behaviors than to the text interface Some differences between the virtual and physical character probably occurred due to the specific constraints of the physical character (C) 2009 Elsevier Ltd All rights reserved";2010-06;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;386-397;NA;6, SI;68;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND Publisher: ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Human-robot interaction; Health-care; Persuasive computing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SVXNG8IQ;journalArticle;2010;"Riek, Laurel D.; Paul, Philip C.; Robinson, Peter";When my robot smiles at me Enabling human-robot rapport via real-time head gesture mimicry;JOURNAL ON MULTIMODAL USER INTERFACES;NA;1783-7677;10.1007/s12193-009-0028-2;NA;People use imitation to encourage each other during conversation. We have conducted an experiment to investigate how imitation by a robot affect people's perceptions of their conversation with it. The robot operated in one of three ways: full head gesture mimicking, partial head gesture mimicking (nodding), and non-mimicking (blinking). Participants rated how satisfied they were with the interaction. We hypothesized that participants in the full head gesture condition will rate their interaction the most positively, followed by the partial and non-mimicking conditions. We also performed gesture analysis to see if any differences existed between groups, and did find that men made significantly more gestures than women while interacting with the robot. Finally, we interviewed participants to try to ascertain additional insight into their feelings of rapport with the robot, which revealed a number of valuable insights.;2010-03;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;99-108;NA;1-2, SI;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Human-robot interaction; Social robotics; Facial expressions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CW238QXJ;conferencePaper;2010;"Mayer, Christoph; Sosnowski, Stefan; Kuehnlenz, Kolja; Radig, Bernd";Towards robotic facial mimicry: system development and evaluation;2010 IEEE RO-MAN;978-1-4244-7990-0;NA;NA;NA;We introduce a facial mimicry system, which combines facial expression analysis and synthesis on a robot, utilizing the facial action coding system. The activation of action units on a user's face is automatically extracted from a video stream and mapped to the robot, thus mirroring the facial expression. As a novel approach, a user study quantifies the congruence of the initial human facial expression with the robotic facial expression. The evaluation shows that the robotic facial expression is perceived to be close to the human facial expression, from which it is derived. This is a fundamental aspect for a mimicry system, providing a basis for future research on empathy and emotional closed loop control.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;198-203;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Scuola Super SantAnna, CEIICP Inst; IEEE Inst Elect Soc (IES); IEEE Robot & Automat Soc (RA); IEEE Syst Man & Cybernet Soc (IEEE SMC); Robot Soc Japan (RSJ); EU SKILLS Integrated Project; IEEE Robot & Automat Soc, Italian Chapter (I-RAS); Korea Robot Soc (KROS); Movimento Italiano Modellist Simulazione (MIMOS); Soc Italiana Docenti Ricercatori Automat; Guger Technol (G.Tec); Aldebaran Robot Type: Proceedings Paper";<p>19th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Viareggio, ITALY, SEP 13-15, 2010</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LRZVDY9Y;conferencePaper;2010;"Beck, Aryel; Canamero, Lola; Bard, Kim A.";Towards an Affect Space for Robots to Display Emotional Body Language;2010 IEEE RO-MAN;978-1-4244-7990-0;NA;NA;NA;In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;464-469;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Scuola Super SantAnna, CEIICP Inst; IEEE Inst Elect Soc (IES); IEEE Robot & Automat Soc (RA); IEEE Syst Man & Cybernet Soc (IEEE SMC); Robot Soc Japan (RSJ); EU SKILLS Integrated Project; IEEE Robot & Automat Soc, Italian Chapter (I-RAS); Korea Robot Soc (KROS); Movimento Italiano Modellist Simulazione (MIMOS); Soc Italiana Docenti Ricercatori Automat; Guger Technol (G.Tec); Aldebaran Robot Type: Proceedings Paper";<p>19th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Viareggio, ITALY, SEP 13-15, 2010</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DRGARX6S;conferencePaper;2010;"Mazzei, Daniele; Billeci, Lucia; Armato, Antonino; Lazzeri, Nicole; Cisternino, Antonio; Pioggia, Giovanni; Igliozzi, Roberta; Muratori, Filippo; Ahluwalia, Arti; De Rossi, Danilo";The FACE of Autism;2010 IEEE RO-MAN;978-1-4244-7990-0;NA;NA;NA;People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;791-796;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Scuola Super SantAnna, CEIICP Inst; IEEE Inst Elect Soc (IES); IEEE Robot & Automat Soc (RA); IEEE Syst Man & Cybernet Soc (IEEE SMC); Robot Soc Japan (RSJ); EU SKILLS Integrated Project; IEEE Robot & Automat Soc, Italian Chapter (I-RAS); Korea Robot Soc (KROS); Movimento Italiano Modellist Simulazione (MIMOS); Soc Italiana Docenti Ricercatori Automat; Guger Technol (G.Tec); Aldebaran Robot Type: Proceedings Paper";<p>19th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Viareggio, ITALY, SEP 13-15, 2010</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6ZTFRH57;journalArticle;2010;Cleland, Kathy;Mixed reality interaction: audience responses to robots and virtual characters;DIGITAL CREATIVITY;NA;1462-6268;10.1080/14626261003654608;NA;This article explores the way audiences respond to screen-based (virtual) and embodied (robotic) entities in the mixed reality terrain of the gallery space. While it would seem that physical three-dimensional objects in a gallery space, especially self-moving objects such as robots, have a distinct advantage in the reality stakes over screen images, the author suggests that there is no hard and fast distinction between how audiences respond to robotic entities and to screen-based virtual characters. It is the ability of an artwork to respond to and `dialogue' with its audienceto `look back' and `talk back'that is the key factor in making it an engaging and believable social partner. Artists discussed include Mari Velonaki, Stelarc, Ruairi Glynn, Karolina Sobecka and Golan Levin.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;30-38;NA;1;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"phenomenology; virtual reality; robotics; art; avatars; audience interaction; audience response; media art; mirror neurons; mixed reality; new media art; virtual worlds";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VD6BMMWG;conferencePaper;2010;"Boucenna, Sofiane; Gaussier, Philippe; Hafemeister, Laurence; Bard, Kim A.";Autonomous Development of Social Referencing Skills;FROM ANIMALS TO ANIMATS 11;978-3-642-15192-7;NA;NA;NA;In this work, we are interested in understanding how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensori-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some “empathy” or at least “resonate” with the robot head (low level emotional resonance). Hence we advocate the idea that social referencing can be bootstrapped from a simple sensori-motor system not dedicated to social interactions.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;628+;NA;NA;6226;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Pierre & Marie Curie; Inst Syst Intelligent & Robot; CNRS; Univ So Denmark; ISAB; Museum Natl Hist Naturelle; Polytech; Lect Notes Artificial Intelligence; GDR Robot; CLOS LUCE; Robosoft; Cyberbotics; GOSTAI; ICEA; AAI Canada Inc; EUCOGII; THALES; Brain Vis Syst ISSN: 0302-9743 Type: Proceedings Paper";"<p>11th International Conference on Simulation of Adaptive Behavior, Univ Pierre &amp; Marie Curie, Paris, FRANCE, AUG 25-28, 2010</p>";NA;NA;NA;NA;Doncieux, S and Girard, B and Guillot, A and Hallam, J and Meyer, JA and Mouret, JB;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YW54XST4;conferencePaper;2010;"Camurri, Antonio; Varni, Giovanna; Volpe, Gualtiero";Towards Analysis of Expressive Gesture in Groups of Users: Computational Models of Expressive Social Interaction;GESTURE IN EMBODIED COMMUNICATION AND HUMAN-COMPUTER INTERACTION;978-3-642-12552-2;NA;NA;NA;In this paper we present a survey of our research on analysis of expressive gesture and how it is evolving towards the analysis of expressive social interaction in groups of users. Social interaction and its expressive implications (e.g., emotional contagion, empathy) is an extremely relevant component for analysis of expressive gesture, since it provides significant information on the context expressive gestures are performed in. However, most of the current systems analyze expressive gestures according to basic emotion categories or simple dimensional approaches. Moreover, almost all of them are intended for a single user, whereas social interaction is often neglected. After briefly recalling our pioneering studies on collaborative robot-human interaction, this paper presents two steps in the direction of novel computational models and techniques for measuring social interaction: (i) the interactive installation Mappe per Affetti Erranti for active listening to sound and music content, and (ii) the techniques we developed for explicitly measuring synchronization within a group of users. We conclude with the research challenges we will face in the near future.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;122-133;NA;NA;5934;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>8th International Gesture Workshop, Bielefeld Univ, Ctr Interdisciplinary Res, Bielefeld, GERMANY, FEB 25-27, 2009</p>;NA;NA;NA;"analysis of social interaction in small groups; expressive gesture analysis and processing; multimodal interactive systems";Kopp, S and Wachsmuth, I;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
45LZ6TRK;conferencePaper;2010;"Leite, Iolanda; Mascarenhas, Samuel; Pereira, Andre; Martinho, Carlos; Prada, Rui; Paiva, Ana";“Why Can't We Be Friends?” An Empathic Game Companion for Long-Term Interaction;IN℡LIGENT VIRTUAL AGENTS, IVA 2010;978-3-642-15891-9;NA;NA;NA;The ability of artificial companions (virtual agents or robots) to establish meaningful relationships with users is still limited. In humans, a key aspect of such ability is empathy, often seen as the basis of social cooperation and pro-social behaviour. In this paper, we present a study where a social robot with empathic capabilities interacts with two users playing a chess game against each other. During the game, the agent behaves in an empathic manner towards one of the players and in a neutral way towards the other. In an experiment conducted with 40 participants, results showed that users to whom the robot was empathic provided higher ratings in terms of companionship.;2010;2021-02-11T03:48:36Z;2021-02-11T03:48:36Z;NA;315-321;NA;NA;6356;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Univ Penn, SIG Ctr Comp Graph ISSN: 0302-9743 Type: Proceedings Paper;<p>10th International Conference on Intelligent Virtual Agents (IVA), Philadelphia, PA, SEP 20-22, 2010</p>;NA;NA;NA;"empathy; companionship; affective interaction; friendship";Allbeck, J and Badler, N and Bickmore, T and Pelachaud, C and Safonova, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
T5GGD7E7;conferencePaper;2010;"Cramer, Henriette; Goddijn, Jorrit; Wielinga, Bob; Evers, Vanessa";Effects of (In)Accurate Empathy and Situational Valence on Attitudes towards Robots;PROCEEDINGS OF THE 5TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI 2010);978-1-4244-4893-7;NA;10.1145/1734454.1734513;NA;Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.;2010;2021-02-11T03:48:37Z;2021-02-11T03:48:37Z;NA;141-142;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat; AAAI; Human Factors & Ergon Soc; IEEE Syst, Man, & Cybernet Soc; Robot Lab ISSN: 2167-2121 Type: Proceedings Paper";<p>5th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Jst Erato Asada Project, Osaka, JAPAN, MAR 02-05, 2010</p>;NA;NA;NA;"empathy; human-robot interaction; social robots; emotional valence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MPVIFHUY;conferencePaper;2010;"Evers, Vanessa; Winterboer, Andi; Pavlin, Gregor; Groen, Frans";The Evaluation of Empathy, Autonomy and Touch to Inform the Design of an Environmental Monitoring Robot;SOCIAL ROBOTICS, ICSR 2010;978-3-642-17247-2;NA;NA;NA;This paper reports the application of results from human-social agent interaction experiments to inform the design of a social robot to monitor levels of pollutive gasses in the air. Next to licensed environmental agents and immobile chemical sensors, mobile technologies such as robotic agents are needed to collect complaints and smell descriptions from humans in urban industrial areas. These robots will interact with members of the public and ensure responsiveness and accuracy of responses. For robots to be accepted as representative environmental monitoring agents and for people to comply to robot instructions in the case of a calamity, social skills will be important. In this paper we will describe the intelligent environment the environmental robot is part of and discuss preliminary work on the effects of robot empathic and touch behaviors on human responses to robots. These and future findings will inform the design of social monitoring robot behaviors in public settings.;2010;2021-02-11T03:48:37Z;2021-02-11T03:48:37Z;NA;285-294;NA;NA;6414;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Natl Univ Singapore, Interact Digital Media Inst (IDMI), Social Robot Lab (SRL); A STAR, Inst Infocomm Res (I2R), Human Language Technol Dept; Servo Dynam Private Ltd; Aldebaran Robot ISSN: 0302-9743 Type: Proceedings Paper";<p>2nd International Conference on Social Robotics (ICSR), Singapore, SINGAPORE, NOV 23-24, 2010</p>;NA;NA;NA;"Social robots; Human Robot Interaction; Environmental Monitoring; Robot Social Behaviors";Ge, SS and Li, H and Cabibihan, JJ and Tan, YK;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KTVTMN4X;journalArticle;2021;"Croes, Emmelyn A. J.; Antheunis, Marjolijn L.";Can we be friends with Mitsuku? A longitudinal study on the process of relationship formation between humans and a social chatbot;JOURNAL OF SOCIAL AND PERSONAL RELATIONSHIPS;NA;0265-4075;10.1177/0265407520959463;NA;This explorative study investigated (a) whether social attraction, self-disclosure, interaction quality, intimacy, empathy and communicative competence play a role in getting-acquainted interactions between humans and a chatbot, and (b) whether humans can build a relationship with a chatbot. Although human-machine communication research suggests that humans can develop feelings for computers, this does not automatically imply that humans experience feelings of friendship with a chatbot. In this longitudinal study, 118 participants had seven interactions with chatbot Mitsuku over a 3-week period. After each interaction participants filled out a questionnaire. The results showed that the social processes decreased after each interaction and feelings of friendship were low. In line with the ABCDE model of relationship development, the social processes that aid relationship continuation decrease, leading to deterioration of the relationship. Furthermore, a novelty effect was at play after the first interaction, after which the chatbot became predictable and the interactions less enjoyable.;2021-01;2021-02-11T04:00:00Z;2021-02-11T04:00:09Z;NA;279-300;NA;1;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"Chatbot; friendship; human-machine communication; relationship formation; self-disclosure; social attraction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
377QVF4K;journalArticle;2020;"de Gennaro, Mauro; Krumhuber, Eva G.; Lucas, Gale";Effectiveness of an Empathic Chatbot in Combating Adverse Effects of Social Exclusion on Mood;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2019.03061;NA;From past research it is well known that social exclusion has detrimental consequences for mental health. To deal with these adverse effects, socially excluded individuals frequently turn to other humans for emotional support. While chatbots can elicit social and emotional responses on the part of the human interlocutor, their effectiveness in the context of social exclusion has not been investigated. In the present study, we examined whether an empathic chatbot can serve as a buffer against the adverse effects of social ostracism. After experiencing exclusion on social media, participants were randomly assigned to either talk with an empathetic chatbot about it (e.g., “I'm sorry that this happened to you”) or a control condition where their responses were merely acknowledged (e.g., “Thank you for your feedback”). Replicating previous research, results revealed that experiences of social exclusion dampened the mood of participants. Interacting with an empathetic chatbot, however, appeared to have a mitigating impact. In particular, participants in the chatbot intervention condition reported higher mood than those in the control condition. Theoretical, methodological, and practical implications, as well as directions for future research are discussed.;2020-01-23;2021-02-11T04:00:00Z;2021-02-11T04:00:09Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; virtual human; chatbot; mood; social exclusion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
W72PPH9W;journalArticle;2019;"Shorey, Shefaly; Ang, Emily; Yap, John; Ng, Esperanza Debby; Lau, Siew Tiang; Chui, Chee Kong";A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education: Development Study;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/14658;NA;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019-10-29;2021-02-11T04:00:01Z;2021-02-11T04:00:09Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"artificial intelligence; learning; communication; virtual reality; technology; nursing education; patients";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HF6II8GH;journalArticle;2019;Powell, John;Trust Me, I'm a Chatbot: How Artificial Intelligence in Health Care Fails the Turing Test;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/16222;NA;Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game.;2019-10-28;2021-02-11T04:00:01Z;2021-02-11T04:00:09Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; conversational agents; chatbots; medical informatics; ehealth; digital health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WRW5UTC5;conferencePaper;2019;"Gutierrez y Restrepo, Emmanuelle; Baldassarre, Martin; Boticario, Jesus G.";ACCESSIBILITY, BIASES AND ETHICS IN CHATBOTS AND IN℡LIGENT AGENTS FOR EDUCATION;EDULEARN19: 11TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-12031-4;NA;NA;NA;The use of chatbots is increasingly common in universities around the world to support both educational and administrative tasks. There is also a growing awareness of the importance of inclusive education and, as a consequence, the need to comply with accessibility requirements regarding web contents and web interface (WCAG). These requirements are also supported by specific laws in most countries. But such awareness does not yet reach the interfaces of conversational agents or chatbots that are being developed. Within the framework of the European project ACACIA, co-funded by the Erasmus+ program of the European Union, Artemisa, a chatbot has been created dedicated to fight against sexual harassment and search for volunteers to promote the acceptance of diversity and tolerance, has been created using a platform that facilitates the generation and management of this type of artificial intelligences. But to what extent Artemisa is an accessible chatbot or not? Is it ethically acceptable to make use of a tool that is intended to support inclusiveness but presents accessibility barriers to some users? What is the current state in terms of accessibility compliance of chatbots that work on social networks? This article seeks to answer this and other questions related to accessibility in Chatbots, conversational agents and virtual assistant's. Based on the answer to these questions it follows that there is a need for training in interculturalism and web accessibility to combat the biases that present such entities, which are endowed with artificial intelligence and, unfortunately, in some cases causing serious damage to some people.;2019;2021-02-11T04:00:01Z;2021-02-11T04:00:09Z;NA;8824-8833;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>11th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 01-03, 2019</p>;NA;NA;NA;"artificial intelligence; ethics; empathy; Conversational agents; accessibility; biases; Chatbot";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XAPYW95I;conferencePaper;2019;"Carranza, Karmelo Antonio Lazaro R.; Manalili, Joshua; Bugtai, Nilo T.; Baldovino, Renann G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7TH INTERNATIONAL CONFERENCE ON ROBOT IN℡LIGENCE TECHNOLOGY AND APPLICATIONS (RITA);978-1-72813-118-4;NA;NA;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019;2021-02-11T04:00:01Z;2021-02-11T04:00:09Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computat Intelligence Soc; MIR MSREP; Smilegate; WCG; Inst Control Robot & Syst; Daejeon Int Marketing Enterprise; Korea Tourism Org Type: Proceedings Paper";<p>7th International Conference on Robot Intelligence Technology and Applications (RiTA), KAIST, Daejeon, SOUTH KOREA, NOV 01-03, 2019</p>;NA;NA;NA;"deep learning; affective computing; emotionally aware technology; facial expression detection; scripted chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
222N9ZL8;conferencePaper;2019;"Chin, Hyojin; Yi, Mun Yong";Should an Agent Be Ignoring It? A Study of Verbal Abuse Types and Conversational Agents' Response Styles;CHI EA `19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS;978-1-4503-5971-9;NA;10.1145/3290607.3312826;NA;Verbal abuse is a hostile form of communication ill-intended to harm the other person. With a plethora of AI solutions around, the other person being targeted may be a conversational agent. In this study, involving 3 verbal abuse types (Insult, Threat, Swearing) and 3 response styles (Avoidance, Empathy, Counterattacking), we examine whether a conversational agent's response style under varying abuse types influences those emotions found to mitigate people's aggressive behaviors. Sixty-four participants, assigned to one of the abuse type conditions, interacted with the three conversational agents in turn and reported their feelings about guiltiness, anger, and shame after each session. Our study results show that, regardless of the abuse type, the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathetic agent than the other two agents. Our study findings have direct implications for the design of conversational agents.;2019;2021-02-11T04:00:02Z;2021-02-11T04:00:09Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>CHI Conference on Human Factors in Computing Systems (CHI), Glasgow, SCOTLAND, MAY 04-09, 2019</p>;NA;NA;NA;"Chatbot; Agent Abuse; Agent Response Style; Conversational Agent; Conversational AI; Verbal Abuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QZZFRUKK;conferencePaper;2019;"Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid";BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions;PROCEEDINGS OF IUI 2019;978-1-4503-6272-6;NA;10.1145/3301275.3302290;NA;Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.;2019;2021-02-11T04:00:02Z;2021-02-11T04:00:09Z;NA;448-459;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Assoc Comp Machinery Type: Proceedings Paper;<p>24th ACM International Conference on Intelligent User Interfaces (IUI), Los Angeles, CA, MAR 16-20, 2019</p>;NA;NA;NA;"Mechanical Turk; conversational agents; Explainable AI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KUDLUJMJ;journalArticle;2018;"Liu, Bingjie; Sundar, S. Shyam";Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot;CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING;NA;2152-2715;10.1089/cyber.2018.0110;NA;When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N=158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N=88) interacted with a real chatbot. We tested the effect of three types of empathic expressionsympathy, cognitive empathy, and affective empathyon individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed.;2018-10;2021-02-11T04:00:02Z;2021-02-11T04:00:09Z;NA;625-636;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA Publisher: MARY ANN LIEBERT, INC Type: Article;NA;NA;NA;NA;"empathy; human-robot interaction; CASA; sympathy; uncanny valley";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BLXFILFS;conferencePaper;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17);978-1-4503-4655-9;NA;10.1145/3025453.3025496;NA;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-02-11T04:00:02Z;2021-02-11T04:00:09Z;NA;3506-3510;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>ACM SIGCHI Conference on Human Factors in Computing Systems (CHI), Denver, CO, MAY 06-11, 2017</p>;NA;NA;NA;"social media; deep learning; Chatbot; customer service";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XEHCQ2T4;journalArticle;2021;Irfan, Farhana;Artificial Intelligence: Help or Hindrance for Family Physicians?;PAKISTAN JOURNAL OF MEDICAL SCIENCES;NA;1682-024X;10.12669/pjms.37.1.3351;NA;"The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician's new assistant; AI-physician combinations can act like models of `peaceful co-existence'. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician's diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients' frustration.";2021-02;2021-02-11T04:02:13Z;2021-02-11T04:02:13Z;NA;288-291;NA;1;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PANORAMA CENTRE, RM 522, 5TH FLOOR, BLDG 2, RAJA GHAZANFAR ALI RD, PO BOX 8766, SADDAR, KARACHI 00000, PAKISTAN Publisher: PROFESSIONAL MEDICAL PUBLICATIONS Type: Article;NA;NA;NA;NA;"Machine learning; Artificial Intelligence; Family Physicians";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VU33H5CY;journalArticle;2020;"Wu, Haiyan; Feng, Chunliang; Lu, Xiaping; Liu, Xun; Liu, Quanying";Oxytocin effects on the resting-state mentalizing brain network;BRAIN IMAGING AND BEHAVIOR;NA;1931-7557;10.1007/s11682-019-00205-5;NA;Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual's empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing.;2020-12;2021-02-11T04:02:13Z;2021-02-11T04:02:13Z;NA;2530-2541;NA;6;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"fMRI; Functional connectivity; Mentalizing network; Oxytocin; Temporoparietal junction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VLE8PF9W;journalArticle;2020;"Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;DIGITAL HEALTH;NA;2055-2076;10.1177/2055207620968355;NA;"Background The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective This study aimed to explore psychiatrists' opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (”comments”) to three open-ended questions in the survey. Results Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that `man and machine' would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions This study presents timely information on psychiatrists' views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020-10;2021-02-11T04:02:13Z;2021-02-11T04:02:13Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"machine learning; Artificial intelligence; mental health; attitudes; future; opinions; psychiatry; qualitative research; technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GBRTA2JT;journalArticle;2020;"Nebli, Ahmed; Rekik, Islem";Gender differences in cortical morphological networks;BRAIN IMAGING AND BEHAVIOR;NA;1931-7557;10.1007/s11682-019-00123-6;NA;Cortical morphological networks (CMN), where each network models the relationship in morphology between different cortical brain regions quantified using a specific measurement (e.g., cortical thickness), have not been investigated with respect to gender differences in the human brain. Cortical processes are expected to involve complex interactions between different brain regions, univariate methods thus might overlook informative gender markers. Hence, by leveraging machine learning techniques with the potential to highlight multivariate interacting effects, we found that the most discriminative CMN connections between males and females were derived from the left hemisphere using the mean sulcal depth as measurement. However, for both left and right hemispheres, the first most discriminative morphological connection revealed across all cortical attributes involved (entorhinal cortex <-> caudal anterior cingulate cortex) and (entorhinal cortex <-> transverse temporal cortex) respectively, which gives us new insights into behavioral gender differences from an omics perspective and might explain why males and females learn differently.;2020-10;2021-02-11T04:02:13Z;2021-02-11T04:02:13Z;NA;1831-1839;NA;5;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Gender differences; Brain connectivity; Cortical morphological networks; Cortical morphology; Feature selection; Sulcal depth; T1-weighted MRI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BHS74H79;journalArticle;2020;"Jenking, Julian; van der Poel, Sheryl; Kruessel, Jan; Bosch, Ernesto; Nelson, Scott M.; Pinborg, Anja; Yao, Mylene M. W.";Empathetic application of machine learning may address appropriate utilization of ART;REPRODUCTIVE BIOMEDICINE ONLINE;NA;1472-6483;10.1016/jrbmo.2020.07.005.1472-6483;NA;"The value of artificial intelligence to benefit infertile patients is a subject of debate. This paper presents the experience of one aspect of artificial intelligence, machine learning, coupled with patient empathy to improve utilization of assisted reproductive technology (ART), which is an important aspect of care that is under-recognized. Although ART provides very effective options for infertile patients to build families, patients often discontinue ART when further treatment is likely to be beneficial and most of these patients do not achieve pregnancy without medical aid. Use of ART is only in part dependent on financial considerations; stress and other factors play a major role, as shown by high discontinuation rates despite reimbursement. This commentary discusses challenges and strategies to providing personalized ART prognostics based on machine learning, and presents a case study where appropriate use of such prognostics in ART centres is associated with a trend towards increased ART utilization.";2020-10;2021-02-11T04:02:13Z;2021-02-11T04:02:13Z;NA;573-577;NA;4;41;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Editorial Material;NA;NA;NA;NA;"Machine learning; Artificial intelligence; ART utilization; IVF drop-outs; Patient empathy; Prognostication";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CT3P78VN;journalArticle;2020;"Zwir, Igor; Arnedo, Javier; Del-Val, Coral; Pulkki-Raback, Laura; Konte, Bettina; Yang, Sarah S.; Romero-Zaliz, Rocio; Hintsanen, Mirka; Cloninger, Kevin M.; Garcia, Danilo; Svrakic, Dragan M.; Rozsa, Sandor; Martinez, Maribel; Lyytikainen, Leo-Pekka; Giegling, Ina; Kahonen, Mika; Hernandez-Cuervo, Helena; Seppala, Ilkka; Raitoharju, Emma; de Erausquin, Gabriel A.; Raitakari, Olli; Rujescu, Dan; Postolache, Teodor T.; Sung, Joohon; Keltikangas-Jarvinen, Liisa; Lehtimaki, Terho; Cloninger, C. Robert";Uncovering the complex genetics of human character;MOLECULAR PSYCHIATRY;NA;1359-4184;10.1038/s41380-018-0263-6;NA;Human personality is 30-60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic-phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory.;2020-10;2021-02-11T04:02:14Z;2021-02-11T04:02:14Z;NA;2295-2312;NA;10;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND Publisher: SPRINGERNATURE Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NQSHFAWC;journalArticle;2020;"Sakamoto, Teppei; Yamashita, Haruka; Goto, Masayuki; Iwanaga, Jiro";Model for Relational Analysis of Posted Articles and Reactions on Restaurant Guide Sites;INDUSTRIAL ENGINEERING AND MANAGEMENT SYSTEMS;NA;1598-7248;10.7232/iems.2020.19.3.669;NA;Recently, restaurant guide sites providing restaurant information posted by users on the Internet have been widely used as effective tools for consumers. Users, on a restaurant guide site, utilize IDs to post their recommendation articles on restaurants, and these posted articles are a valuable information source for other users. Open users can search for restaurants and read recommendation articles posted by other users. Furthermore, they can react (e.g., “like”) to a recommendation article when they feel it is helpful or they feel like visiting the restaurant. On a target restaurant guide site, each post includes the user ID, restaurant name, recommendation sentences, etc., and the number of reactions is considered to depend on these posted contents. For users who post recommendation articles, the number of reactions to their posts represents the degree of empathy from other users and is an important motivation for posting. Therefore, posting users will benefit from guidelines on how to write good recommendation sentences to increase the number of reactions. Moreover, the number of reactions can be regarded as an important indicator of the activity level of the restaurant guide site from the viewpoint of the service operating company. Therefore, an analytical model developed using historical information such as posts and reactions by users would be useful for determining the relationship between posted contents and the number of reactions. Therefore, this paper proposes a model based on the machine learning approach to analyze the relation between the number of reactions and posted contents. Finally, we demonstrate the analysis based on the proposed model using practical data.;2020-09;2021-02-11T04:02:14Z;2021-02-11T04:02:14Z;NA;669-679;NA;3;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VICTORIA BLDG RM 509, 705-1 YEOKSAM-DONG, KANGNAM-GU, SEOUL, 135-080, SOUTH KOREA Publisher: KOREAN INST INDUSTRIAL ENGINEERS Type: Article;NA;NA;NA;NA;"Machine Learning; Natural Language Processing; Business Analytics; Restaurant Guide";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ALNFNMFJ;journalArticle;2020;"Usta, Mirac Baris; Karabekiroglu, Koray";Computational analysis of affective facial behavior in children with the specific learning disorder;ANADOLU PSIKIYATRI DERGISI-ANATOLIAN JOURNAL OF PSYCHIATRY;NA;1302-6631;10.5455/apd.82969;NA;"Objective: Clinical characterization of facial behavior is getting more critical in psychiatric disorders; however, there are no objective measures of these expressions. Our study aims to investigate to affective facial behaviors in specific learning disorder (SLD), collect objective facial behavior information to help decision making, and examine the discrimination ability of these behaviors in SLD and healthy controls (HC). Methods: SLD and HC group watched three, 5-minute scenes from cartoon videos and between these scenes in 2-minute question session was applied. Openface software for video analysis used three machine learning algorithms and the performance of these algorithms tested on our data using SLD and HC groups as prediction class. ROC curves and AUC had been calculated. Results: Prediction models using three machine learning classifiers had been created independently with tenfold cross-validation. SVM method showed the highest AUC=0.76 with sensitivity 72%, specifity 96%. Conclusion: Computational identification of facial behavior in children a promising beginning for the technologies to aid psychiatrists in the evaluation of learning and other neurodevelopmental disorders. Quantitative assessment of facial expression in neurodevelopmental disorders are both beneficial and informative and in future may be used as an addition to traditional methods of psychiatric examination.";2020-08;2021-02-11T04:02:14Z;2021-02-11T04:02:14Z;NA;429-434;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: CUMHURIYET UNIV TIP FAK PSIKIYATRI ABD, SIVAS, 58140, TURKEY Publisher: CUMHURIYET UNIV TIP FAK PSIKIYATRI ANABILIM DALI Type: Article;NA;NA;NA;NA;"machine learning; facial behavior; specific learning disorder";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CKUZSKAN;journalArticle;NA;"Wei, Luqing; Wu, Guo-Rong; Bi, Minghua; Baeken, Chris";Effective connectivity predicts cognitive empathy in cocaine addiction: a spectral dynamic causal modeling study;BRAIN IMAGING AND BEHAVIOR;NA;1931-7557;10.1007/s11682-020-00354-y;NA;Social cognition plays a crucial role in the development and treatment of cocaine dependence. However, studies investigating social cognition, such as empathy and its underlying neural basis, are lacking. To explore the neural interactions among reward and memory circuits, we applied effective connectivity analysis on resting-state fMRI data collected from cocaine-dependent subjects. The relationship between effective connectivity within these two important circuits and empathy ability - evaluated with the Interpersonal Reactivity Index (IRI) - was assessed by machine learning algorithm using multivariate regression analysis. In accordance with the neurocircuitry disruptions of cocaine addiction, the results showed that cocaine-dependent subjects relative to healthy controls had altered resting state effective connectivity between parts of the memory and reward systems. Furthermore, effective connectivity between the memory and reward system could predict the fantasy empathy (FE) subscale scores in cocaine dependence. Overall, our findings provide further evidence for the neural substrates of social cognition in cocaine-dependent patients. These new insights could be useful for the development of new treatment programs for this substance dependency disorder.;NA;2021-02-11T04:02:14Z;2021-02-11T04:02:14Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"social cognition; cocaine dependence; effective connectivity; fantasy empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FW9RS9UR;journalArticle;2020;"Goldberg, Simon B.; Flemotomos, Nikolaos; Martinez, Victor R.; Tanana, Michael J.; Kuo, Patty B.; Pace, Brian T.; Villatte, Jennifer L.; Georgiou, Panayiotis G.; Van Epps, Jake; Imel, Zac E.; Narayanan, Shrikanth S.; Atkins, David C.";Machine Learning and Natural Language Processing in Psychotherapy Research: Alliance as Example Use Case;JOURNAL OF COUNSELING PSYCHOLOGY;NA;0022-0167;10.1037/cou0000382;NA;Artificial intelligence generally and machine learning specifically have become deeply woven into the lives and technologies of modern life. Machine learning is dramatically changing scientific research and industry and may also hold promise for addressing limitations encountered in mental health care and psychotherapy. The current paper introduces machine learning and natural language processing as related methodologies that may prove valuable for automating the assessment of meaningful aspects of treatment. Prediction of therapeutic alliance from session recordings is used as a case in point. Recordings from 1,235 sessions of 386 clients seen by 40 therapists at a university counseling center were processed using automatic speech recognition software. Machine learning algorithms learned associations between client ratings of therapeutic alliance exclusively from session linguistic content. Using a portion of the data to train the model, machine learning algorithms modestly predicted alliance ratings from session content in an independent test set (Spearman's rho =15, p <.001). These results highlight the potential to harness natural language processing and machine learning to predict a key psychotherapy process variable that is relatively distal from linguistic content. Six practical suggestions for conducting psychotherapy research using machine learning are presented along with several directions for future research. Questions of dissemination and implementation may be particularly important to explore as machine learning improves in its ability to automate assessment of psychotherapy process and outcome.;2020-07;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;438-448;NA;4, SI;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA Publisher: AMER PSYCHOLOGICAL ASSOC Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; methodology; natural language processing; therapeutic alliance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A8C9M668;journalArticle;2020;Wenk, H.;Communication in the age of artificial intelligence;GEFASSCHIRURGIE;NA;0948-7034;10.1007/s00772-020-00644-1;NA;Communication is essential in vascular medicine. Medicine without communication is unthinkable. The computerization of medical devices and the increasing application of artificial intelligence adds new aspects to communication between humans and humans, machines and machines as well as between humans and machines. Against the background of formalization of communication, empathy when dealing with patients, physicians and other professional groups in medicine is necessary in order to guarantee and optimize the success of treatment.;2020-09;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;339-344;NA;5, SI;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;German;NA;NA;NA;NA;NA;NA;Place: TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY Publisher: SPRINGER HEIDELBERG Type: Article;NA;NA;NA;NA;"Machine learning; Empathy; Computer; Physician-Patient-Relations; Vascular medicine";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TI4E9JFL;journalArticle;NA;"Bagirathan, Anandhi; Selvaraj, Jerritta; Gurusamy, Anusuya; Das, Himangshu";Recognition of positive and negative valence states in children with autism spectrum disorder (ASD) using discrete wavelet transform (DWT) analysis of electrocardiogram signals (ECG);JOURNAL OF AMBIENT IN℡LIGENCE AND HUMANIZED COMPUTING;NA;1868-5137;10.1007/s12652-020-01985-1;NA;Children with autism spectrum disorder (ASD) are deficit in communication, social skills, empathy, emotional responsiveness and have significant behavioral pattern. They have difficulty in understanding other feelings and their own emotions. This leads to the sudden emotional outburst and aggressive behavior in these children. Parents, caretakers and doctors find it very difficult to prevent such extreme behaviors. Learning the positive and negative valence leads in determining the early indications before the onset of emotional outbursts in children with ASD. The present study measures the psycho physiological electrocardiogram (ECG) signal from the typically developed (TD) children and children with ASD in the age group of 5-11 years. Personalized protocol was developed for every child with ASD to induce positive and negative valence and ECG data was collected using wearable Shimmer ECG device. The heart rate variability (HRV) and the QRS amplitude were derived from ECG signal using Pan-Tompkins algorithm and eleven features were extracted using DWT (db2, db4 and db8) mother wavelet. The significant features of ECG, HRV and QRS amplitude were classified using the K nearest neighbor (KNN), support vector machine (SVM) and ensemble classifier. Ensemble and KNN classifier achieved maximum accuracy of 81% and 76.2% for children with ASD and Ensemble and SVM classifiers obtained maximum accuracy of 87.4% and 83.8% for TD children using HRV data.;NA;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY Publisher: SPRINGER HEIDELBERG Type: Article; Early Access";NA;NA;NA;NA;"Autism spectrum disorder (ASD); Heart rate variability (HRV); K nearest neighbor (KNN); Pan-Tompkins algorithm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SEP5TTP3;journalArticle;2020;"Leonardi, Simone; Monti, Diego; Rizzo, Giuseppe; Morisio, Maurizio";Multilingual Transformer-Based Personality Traits Estimation;INFORMATION;NA;NA;10.3390/info11040179;NA;Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users' information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes Facebook posts from the myPersonality dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback-Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits.;2020-04;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;NA;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"deep learning; affective computing; natural language processing; Big 5; multilingual embeddings; personality dimensions; sentence embeddings";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ARBG5SFM;journalArticle;2020;"Joda, Tim; Bornstein, Michael M.; Jung, Ronald E.; Ferrari, Marco; Waltimo, Tuomas; Zitzmann, Nicola U.";Recent Trends and Future Direction of Dental Research in the Digital Era;INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH;NA;NA;10.3390/ijerph17061987;NA;The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.;2020-03-02;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;NA;NA;6;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Letter;NA;NA;NA;NA;"artificial intelligence (AI); digital transformation; machine learning (ML); patient-centered outcomes; personalized dental medicine; rapid prototyping; tele-health; augmented and virtual reality (AR; VR)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QJNWSHDF;journalArticle;2020;"Rehman, Faisal; Munawar, Adeel; Iftikhar, Aqsa; Hassan, Jawad; Samiullah, Fouzia; Gilani, Muhammad Basit Ali; Qasim, Awais; Qasim, Neelam";Design and Development of AI-based Mirror Neurons Agent towards Emotion and Empathy;INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS;NA;2158-107X;NA;NA;Since numerous years, researchers have to outline keen operators to accomplish the Artificial General Intelligence. Each new science revelation is an open challenge to all researchers. More than twenty years prior to a group of researchers discovered exceptional cerebrum cells, called reflect neurons in monkeys. These cells gave off an impression of being actuated both when the monkey accomplished something itself and when the monkey basically watched another monkey do a similar thing. This new discovery opened a new door for a scientist because of Mirror Neurons functionalities that can be huge contribute to cognitive science, neuroscience, impacting on Artificial General Intelligence. Mirror neuron functionality improves the Machine's learning. This research paper develops models for social interaction in which a machine may have the ability to learn the next person emotional state using mirror neurons and show empathy towards emotions.;2020-03;2021-02-11T04:02:15Z;2021-02-11T04:02:15Z;NA;386-395;NA;3;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND Publisher: SCIENCE & INFORMATION SAI ORGANIZATION LTD Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; emotions; empathy; Mirror neurons functionalities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XT5XQG2Z;journalArticle;2020;"Srivastava, Tripti K.; Waghmare, Lalitbhushan";Implications of Artificial Intelligence (Al) on Dynamics of Medical Education and Care: A Perspective ocr;JOURNAL OF CLINICAL AND DIAGNOSTIC RESEARCH;NA;2249-782X;10.7860/JCDR/2020/4329.3.13565;NA;"Artificial Intelligence (Al) applies to the development of systems endowed with the intellectual processes characteristic of humans. The Al era is likely to profoundly impact present system of Health care. Large data storing, processing and its interpretation through Electronic Medical records (EMRs) indicate great potential benefit to health services. Devices are likely to outperform humans, more so cognitively; and coming to terms with this fact require physicians to brace themselves to practice in a technologically enhanced environment. In near future, Al is likely to take a central place in health care with everything revolving round its mechanics. The era of Al envisages new roles of a physician and health professionals should realise the importance of being efficient in interacting with these machines in an efficient manner. Patient psychology and empathy shall take a central place in patient care and budding doctors should be braced with such relevant competencies. Accordingly, Al needs to find a suitable place within the curriculum of medical education that deals with technology, interactive learning environments and managing Al systems. It is also imperative that medical teachers realise the potential of Al on health care and are suitably equipped to train these emerging concepts to future doctors.";2020-03;2021-02-11T04:02:16Z;2021-02-11T04:02:16Z;NA;NA;NA;3;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 71 JAIN COLONY, VEER NAGAR, DELHI, 110 007, INDIA Publisher: PREMCHAND SHANTIDEVI RESEARCH FOUNDATION Type: Editorial Material;NA;NA;NA;NA;"Electronic medical records; Health care; System";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KJLIVPB7;journalArticle;2020;"Christov-Moore, Leonardo; Reggente, Nicco; Douglas, Pamela K.; Feusner, Jamie D.; Iacoboni, Marco";Predicting Empathy From Resting State Brain Connectivity: A Multivariate Approach;FRONTIERS IN INTEGRATIVE NEUROSCIENCE;NA;1662-5145;10.3389/fnint.2020.00003;NA;Recent task fMRI studies suggest that individual differences in trait empathy and empathic concern are mediated by patterns of connectivity between self-other resonance and top-down control networks that are stable across task demands. An untested implication of this hypothesis is that these stable patterns of connectivity should be visible even in the absence of empathy tasks. Using machine learning, we demonstrate that patterns of resting state fMRI connectivity (i.e. the degree of synchronous BOLD activity across multiple cortical areas in the absence of explicit task demands) of resonance and control networks predict trait empathic concern (n = 58). Empathic concern was also predicted by connectivity patterns within the somatomotor network. These findings further support the role of resonance-control network interactions and of somatomotor function in our vicariously driven concern for others. Furthermore, a practical implication of these results is that it is possible to assess empathic predispositions in individuals without needing to perform conventional empathy assessments.;2020-02-14;2021-02-11T04:02:16Z;2021-02-11T04:02:16Z;NA;NA;NA;NA;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"fMRI; resting state; machine learning; connectivity; empathy; empathic concern; experience sharing; mirroring";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YIITV7IZ;journalArticle;2020;"Haarsma, Gabe; Davenport, Sasha; White, Devonte C.; Ormachea, Pablo A.; Sheena, Erin; Eagleman, David M.";Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2019.02926;NA;We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver-operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided.;2020-01-24;2021-02-11T04:02:16Z;2021-02-11T04:02:16Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"machine learning; neurocognitive; neurolaw; predictive validity; risk assessment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
25UTR682;conferencePaper;2020;"Nehra, Vanshika; Nagpal, Renuka; Sehgal, Rajni";Collective Intelligence: When, Where and Why;PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING;978-1-72812-791-0;NA;NA;NA;The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms intact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.;2020;2021-02-11T04:02:16Z;2021-02-11T04:02:16Z;NA;805-810;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn Type: Proceedings Paper";<p>10th International Conference on Cloud Computing, Data Science and Engineering (Confluence), Amity Univ, Noida, INDIA, JAN 29-31, 2020</p>;NA;NA;NA;"Artificial Intelligence; Collective Intelligence; Swami Intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
424MDIPM;journalArticle;2020;"Kumar, Mohan; Khatri, Sunil Kumar; Mohammadian, Masoud";Breast cancer identification and prognosis with machine learning techniques - An elucidative review;JOURNAL OF INTERDISCIPLINARY MATHEMATICS;NA;0972-0502;10.1080/09720502.2020.1731963;NA;Cancer is the principle wellspring of death around the globe with 2.09 million cases so far in 2018 [1]. Around 627000 deaths accounting to 6.6% are caused because of female breast cancer and it ranks five amongst the list of top causes for deaths, the prime reason being prognosis being favorable in developed countries. The timely empathy of breast cancer further makes the process of prognosis better hence improving the rates of survival, because this will indorse on time treatment which is given clinically to patients. When the classification is done in an accurate way for malignant and benign tumours, it stops the suffering of patients with excessive ailments. The best possible recognizable proof of breast cancer disease and the process of characterizing into benign and malignant groups is that the main concern of a ton of investigation and research. When thrown light on its particular advantages in significant alternatives recognition from the datasets of entangled breast cancer, the generally perceived option is Machine Learning, because of the philosophy of determination in breast cancer to arrange pattern and forecast modelling. This paper will in general, survey machine learning `and assessment of this particular paper, WBCD: Wisconsin Breast Cancer Database has been used as the benchmark dataset.;2020;2021-02-11T04:02:17Z;2021-02-11T04:02:17Z;NA;503-521;NA;2, SI;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: G-159, PUSHKAR ENCLAVE, PASHCHIM VIHAR, NEW DELHI, 110 063, INDIA Publisher: TARU PUBLICATIONS Type: Review;NA;NA;NA;NA;"Machine learning; ANN; Breast cancer; DT; k-NN; SVM; WBCD";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8J77VMSR;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;ARTIFICIAL IN℡LIGENCE IN MEDICINE;NA;0933-3657;10.1016/j.artmed.2019.101753;NA;Background: Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective: To characterize the global psychiatrist community's opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design: Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures: We measured opinions about the likelihood that AI/ML tools would be able to fully replace - not just assist - the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist's perceptions about whether benefits of AI/ML would outweigh the risks. Results: Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions: Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020-01;2021-02-11T04:02:17Z;2021-02-11T04:02:17Z;NA;NA;NA;NA;102;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS Publisher: ELSEVIER Type: Article;NA;NA;NA;NA;"Deep learning; Empathy; Autonomous agents; Mental health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KU6X58B8;journalArticle;2019;"Bridge, Pete; Bridge, Robert";Artificial Intelligence in Radiotherapy: A Philosophical Perspective;JOURNAL OF MEDICAL IMAGING AND RADIATION SCIENCES;NA;1939-8654;10.1016/j.jmir.2019.09.003;NA;The increasing uptake of machine learning solutions for segmentation and planning leaves no doubt that artificial intelligence (AI) will soon be providing input into a range of radiotherapy procedures. Although this promises to deliver increased speed and accuracy, the future role of AI in relation to radiotherapy should be thought through carefully. There is currently a gap between published developments and widespread adoption, which provides some space to prepare the workforce and to consider the implications on practice. It is rare to find philosophical input into a medical journal, but the advent of AI makes this perspective increasingly important. Philosophical insight can help explore the potential impact of AI, in particular, on human creativity and oversight. Without this perspective, we run the risk of focusing solely on the immediate logistical impact on patients and departments. This commentary identifies three key aspects of radiotherapy that the authors feel would suffer most under AI control: creativity, innovation, and patient safety, which all demand uniquely human attributes. The article also provides insight from a philosophical perspective with regard to human consciousness, ethics, and empathy. Philosophically we should, perhaps, retain ethical concerns about the widening role of AI in radiotherapy beyond simple quantitative interpretation and image processing. As developments continue, we have time to determine how our roles will evolve and to establish a framework for ensuring appropriate human input into patient care. Most importantly, we must start to embed a philosophical approach to adoption of AI technology from the outset if we are to prepare ourselves for the challenge that lies ahead.;2019-12;2021-02-11T04:02:17Z;2021-02-11T04:02:17Z;NA;S27-S31;NA;4, 2;50;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA Publisher: ELSEVIER SCIENCE INC Type: Editorial Material;NA;NA;NA;NA;"Artificial intelligence; philosophy; radiotherapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TNWCN5PV;journalArticle;2019;"Speer, Sebastian P. H.; Boksem, Maarten A. S.";Decoding fairness motivations from multivariate brain activity patterns;SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE;NA;1749-5016;10.1093/scan/nsz097;NA;A preference for fairness may originate from prosocial or strategic motivations: we may wish to improve others' well-being or avoid the repercussions of selfish behavior. Here, we used functional magnetic resonance imaging to identify neural patterns that dissociate these two motivations. Participants played both the ultimatum and dictator game (UG-DG) as proposers. Because responders can reject the offer in the UG, but not the DG, offers and neural patterns between the games should differ for strategic players but not prosocial players. Using multivariate pattern analysis, we found that the decoding accuracy of neural patterns associated with UG and DG decisions correlated significantly with differences in offers between games in regions associated with theory of mind (ToM), such as the temporoparietal junction, and cognitive control, such as the dorsolateral prefrontal cortex and inferior frontal cortex. We conclude that individual differences in prosocial behavior may be driven by variations in the degree to which self-control and ToM processes are engaged during decision-making such that the extent to which these processes are engaged is indicative of either selfish or prosocial motivations.;2019-11;2021-02-11T04:02:17Z;2021-02-11T04:02:17Z;NA;1197-1207;NA;11;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article;NA;NA;NA;NA;"fMRI; machine learning; cognitive control; prosocial behavior; theory of mind";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DRF4EJFI;journalArticle;2019;Powell, John;Trust Me, I'm a Chatbot: How Artificial Intelligence in Health Care Fails the Turing Test;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/16222;NA;Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game.;2019-10-28;2021-02-11T04:02:17Z;2021-02-11T04:02:17Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; conversational agents; chatbots; medical informatics; ehealth; digital health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UWAPD4KW;journalArticle;2019;"Krohne, Laerke Gebser; Wang, Yi; Hinrich, Jesper L.; Moerup, Morten; Chan, Raymond C. K.; Madsen, Kristoffer H.";Classification of social anhedonia using temporal and spatial network features from a social cognition fMRI task;HUMAN BRAIN MAPPING;NA;1065-9471;10.1002/hbm.24751;NA;Previous studies have suggested that the degree of social anhedonia reflects the vulnerability for developing schizophrenia. However, only few studies have investigated how functional network changes are related to social anhedonia. The aim of this fMRI study was to classify subjects according to their degree of social anhedonia using supervised machine learning. More specifically, we extracted both spatial and temporal network features during a social cognition task from 70 subjects, and used support vector machines for classification. Since impairment in social cognition is well established in schizophrenia-spectrum disorders, the subjects performed a comic strip task designed to specifically probe theory of mind (ToM) and empathy processing. Features representing both temporal (time series) and network dynamics were extracted using task activation maps, seed region analysis, independent component analysis (ICA), and a newly developed multi-subject archetypal analysis (MSAA), which here aimed to further bridge aspects of both seed region analysis and decomposition by incorporating a spotlight approach.We found significant classification of subjects with elevated levels of social anhedonia when using the times series extracted using MSAA, indicating that temporal dynamics carry important information for classification of social anhedonia. Interestingly, we found that the same time series yielded the highest classification performance in a task classification of the ToM condition. Finally, the spatial network corresponding to that time series included both prefrontal and temporal-parietal regions as well as insula activity, which previously have been related schizotypy and the development of schizophrenia.;2019-12-01;2021-02-11T04:02:18Z;2021-02-11T04:02:18Z;NA;4965-4981;NA;17;40;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"archetypical analysis; decomposition; functional connectivity; social anhedonia; support vector classification";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QX7V2QH4;journalArticle;2019;"O'Connell, Katherine; Brethel-Haurwitz, Kristin M.; Rhoads, Shawn A.; Cardinale, Elise M.; Vekaria, Kruti M.; Robertson, Emily L.; Walitt, Brian; VanMeter, John W.; Marsh, Abigail A.";Increased similarity of neural responses to experienced and empathic distress in costly altruism;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-019-47196-3;NA;Empathy-affective resonance with others' sensory or emotional experiences-is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists' heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize.;2019-07-24;2021-02-11T04:02:18Z;2021-02-11T04:02:18Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XYJAZJQK;journalArticle;2019;"Clavelle, Joanne T.; Sweeney, Cynthia D.; Swartwout, Ellen; Lefton, Cindy; Guney, Senem";Leveraging Technology to Sustain Extraordinary Care A Qualitative Analysis of Meaningful Nurse Recognition;JOURNAL OF NURSING ADMINISTRATION;NA;0002-0443;10.1097/NNA.0000000000000757;NA;OBJECTIVE: Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND: Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing andmachine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS: Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS: The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS: AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented.;2019-06;2021-02-11T04:02:18Z;2021-02-11T04:02:18Z;NA;303-309;NA;6;49;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA Publisher: LIPPINCOTT WILLIAMS & WILKINS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
37PDQZTW;journalArticle;2019;"Imel, Zac E.; Pace, Brian T.; Soma, Christina S.; Tanana, Michael; Hirsch, Tad; Gibson, James; Georgiou, Panayiotis; Narayanan, Shrikanth; Atkins, David C.";Design Feasibility of an Automated, Machine-Learning Based Feedback System for Motivational Interviewing;PSYCHOTHERAPY;NA;0033-3204;10.1037/pst0000221;NA;Direct observation of psychotherapy and providing performance-based feedback is the gold-standard approach for training psychotherapists. At present, this requires experts and training human coding teams, which is slow, expensive, and labor intensive. Machine learning and speech signal processing technologies provide a way to scale up feedback in psychotherapy. We evaluated an initial proof of concept automated feedback system that generates motivational interviewing quality metrics and provides easy access to other session data (e.g.. transcripts). The system automatically provides a report of session-level metrics (e.g., therapist empathy) and therapist behavior codes at the talk-turn level (e.g., reflections). We assessed usability, therapist satisfaction, perceived accuracy, and intentions to adopt. A sample of 21 novice (n = 10) or experienced (n = 11) therapists each completed a 10-min session with a standardized patient. The system received the audio from the session as input and then automatically generated feedback that therapists accessed via a web portal. All participants found the system easy to use and were satisfied with their feedback, 83% found the feedback consistent with their own perceptions of their clinical performance, and 90% reported they were likely to use the feedback in their practice. We discuss the implications of applying new technologies to evaluation of psychotherapy.;2019-06;2021-02-11T04:02:18Z;2021-02-11T04:02:18Z;NA;318-328;NA;2;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1390 SOUTH DIXIE HIGHWAY, STE 2222, CORAL GABLES, FL 33146-2946 USA Publisher: AMER PSYCHOLOGICAL ASSOC, DIV PSYCHOTHERAPY Type: Article;NA;NA;NA;NA;"machine learning; feedback; adherence; dissemination; motivational interviewing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TXTVCLJZ;journalArticle;2019;"Gomez, Javier; Jaccheri, Letizia; Maragoudakis, Manolis; Sharma, Kshitij";Digital storytelling for good with Tappetina game;ENTERTAINMENT COMPUTING;NA;1875-9521;10.1016/j.entcom.2019.100297;NA;Context: Storytelling is an important asset in today's society. Digital platforms for storytelling can facilitate collaborative development of stories. The storytelling process, if properly facilitated, can lead to the creation of stories that improve the relations between the players. Moreover, stories convey important information about the players and their interaction. Extended knowledge and better tools are needed about how to facilitate storytelling for good and analysis to exploit the power of the generated data. Research question: How to facilitate Digital Storytelling for good? Method: The investigation is based on a case study approach in which participants have been engaged in the creation of stories. The study is based on empirical data collection and analysis: from the stories recorded, we extract the storytelling features and performance. We have provided qualitative (Domain Expert) and quantitative (Machine Learning) analysis of the stories. In total, 58 users played the game in 15 sessions. Results and conclusions: The main result is a framework for analysing digital stories. The analysis gives an indication of which game building blocks lead to stories for good. Future work will include a redesign of the game and its building blocks which lead to stories for good and further analyses.;2019-05;2021-02-11T04:02:19Z;2021-02-11T04:02:19Z;NA;NA;NA;NA;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Machine Learning; Data analysis; Digital storytelling; Games for Good";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CA87ZAGD;journalArticle;2019;"Drimalla, Hanna; Landwehr, Niels; Hess, Ursula; Dziobek, Isabel";From face to face: the contribution of facial mimicry to cognitive and emotional empathy;COGNITION & EMOTION;NA;0269-9931;10.1080/02699931.2019.1596068;NA;Despite advances in the conceptualisation of facial mimicry, its role in the processing of social information is a matter of debate. In the present study, we investigated the relationship between mimicry and cognitive and emotional empathy. To assess mimicry, facial electromyography was recorded for 70 participants while they completed the Multifaceted Empathy Test, which presents complex context-embedded emotional expressions. As predicted, inter-individual differences in emotional and cognitive empathy were associated with the level of facial mimicry. For positive emotions, the intensity of the mimicry response scaled with the level of state emotional empathy. Mimicry was stronger for the emotional empathy task compared to the cognitive empathy task. The specific empathy condition could be successfully detected from facial muscle activity at the level of single individuals using machine learning techniques. These results support the view that mimicry occurs depending on the social context as a tool to affiliate and it is involved in cognitive as well as emotional empathy.;2019-11-17;2021-02-11T04:02:19Z;2021-02-11T04:02:19Z;NA;1672-1686;NA;8;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"empathy; cognitive; complex emotions; emotional; Facial mimicry";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9HKN8M7I;journalArticle;2019;"Blease, Charlotte; Kaptchuk, Ted J.; Bernstein, Michael H.; Mandl, Kenneth D.; Halamka, John D.; DesRoches, Catherine M.";Artificial Intelligence and the Future of Primary Care: Exploratory Qualitative Study of UK General Practitioners' Views;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/12802;NA;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPs') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPs' opinions about the likelihood of future technology to fully replace GPs in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (”comments”) to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPs also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPs believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPs considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPs' views.";2019-03-20;2021-02-11T04:02:19Z;2021-02-11T04:02:19Z;NA;NA;NA;3;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; attitudes; future; opinions; qualitative research; technology; general practice; primary care";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7K4MP8FL;conferencePaper;2019;"Qureshi, Shahnawaz; Hagelback, Johan; Iqbal, Syed Muhammad Zeeshan; Javaid, Hamad; Lindley, Craig A.";Evaluation of Classifiers for Emotion Detection While Performing Physical and Visual Tasks: Tower of Hanoi and IAPS;IN℡LIGENT SYSTEMS AND APPLICATIONS, VOL 1;978-3-030-01054-6 978-3-030-01053-9;NA;10.1007/978-3-030-01054-6_25;NA;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT.;2019;2021-02-11T04:02:19Z;2021-02-11T04:02:19Z;NA;347-363;NA;NA;868;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>Intelligent Systems Conference (IntelliSys), London, ENGLAND, SEP 06-07, 2018</p>;NA;NA;NA;"Electroencephalography (EEG); Artificial Neural Networks (ANN); Bayesian Network (BNT); Cognitive psychology; Human Computer Interaction (HCI); K-Nearest Neighbor (KNN); Regression Tree (RT); Support Vector Machine (SVM); Tower of Hanoi (ToH)";Arai, K and Kapoor, S and Bhatia, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
L9PVLF9L;conferencePaper;2019;"Das, Amit Kumar; Ashrafi, Aziza; Ahmmad, Muktadir";Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System;2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019);978-1-72811-322-7;NA;NA;NA;Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.;2019;2021-02-11T04:02:20Z;2021-02-11T04:02:20Z;NA;36-40;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE Type: Proceedings Paper;<p>4th IEEE International Conference on Computer and Communication Systems (ICCCS), Singapore, SINGAPORE, FEB 23-25, 2019</p>;NA;NA;NA;"Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
R9YS4THB;conferencePaper;2019;"Tavabi, Leili; Stefanov, Kalin; Gilani, Setareh Nasihati; Traum, David; Soleymani, Mohammad";Multimodal Learning for Identifying Opportunities for Empathetic Responses;ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION;978-1-4503-6860-5;NA;10.1145/3340555.3353750;NA;Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users' emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard -of-Oz setting, using the wizard's empathetic responses and annotations collected on Amazon Mechanical Turk as ground -truth labels. Our model outperforms a textbased baseline achieving Fl -score of 0.71 on a classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.;2019;2021-02-11T04:02:20Z;2021-02-11T04:02:20Z;NA;95-104;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; Assoc Comp Machinery; Openstream; Alibaba Grp; Microsoft; Baidu; Sensetime; Tencent YouTu Lab; AISpeech Type: Proceedings Paper";<p>21st ACM International Conference on Multimodal Interaction (ICMI), Suzhou, PEOPLES R CHINA, OCT 14-18, 2019</p>;NA;NA;NA;"machine learning; empathy; human behavior; multimodal sentiment; virtual human";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U4QQGR2H;conferencePaper;2019;"Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco";A Preliminary Work on Dog Emotion Recognition;2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB IN℡LIGENCE WORKSHOPS (WI 2019 COMPANION);978-1-4503-6988-6;NA;10.1145/3358695.3361750;NA;Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.;2019;2021-02-11T04:02:20Z;2021-02-11T04:02:20Z;NA;91-96;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; WIC; Assoc Comp Machinery; Aristotle Univ Thessaloniki; Open Univ Cyprus Type: Proceedings Paper";<p>19th IEEE/WIC/ACM International Conference on Web Intelligence (WI), Thessaloniki, GREECE, OCT 13-17, 2019</p>;NA;NA;NA;"Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning";Barnaghi, P and Gottlob, G and Katsaros, D and Manolopoulos, Y and Pandey, R and Tzouramanis, T and Vakali, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
79EX3ZFR;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019);978-1-4503-6287-0;NA;10.1145/3313991.3314018;NA;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-02-11T04:02:20Z;2021-02-11T04:02:20Z;NA;102-108;NA;NA;NA;NA;NA;NA;International Conference on Computer and Automation Engineering;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2154-4352 Type: Proceedings Paper;<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YKEVILQT;conferencePaper;2019;"Sood, Ashima; Bhatia, Rekha";Baron-Cohen Model Based Personality Classification Using Ensemble Learning;DATA SCIENCE AND BIG DATA ANALYTICS;978-981-10-7641-1 978-981-10-7640-4;NA;10.1007/978-981-10-7641-1_5;NA;These days intelligence is not the only factor for judging the personality of a human being. Rather, emotional quotient (EQ) as well as systemizing quotient (SQ) has a major role to play for classifying a human's personality in many areas. Using these quotients, we can foresee one's personality in the society. The broad classification of personality on the basis of EQ and SQ score has been well researched using machine learning techniques with varying degree of accuracy. In the present researchwork, the performance of different classification techniques have been enhanced using ensemble learning in which various combination of classification models with different permutations has been done. Ensemble learning technique increases the accuracy in most of the cases in the present work.;2019;2021-02-11T04:02:21Z;2021-02-11T04:02:21Z;NA;57-65;NA;NA;16;NA;NA;NA;Lecture Notes on Data Engineering and Communications Technologies;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Assoc Comp Machinery ISSN: 2367-4512 Type: Proceedings Paper;<p>ACM Women in Research (ACM-WIR) Conference, Sri Aurobindo Inst Technol, Indore, INDIA, JAN 05-06, 2018</p>;NA;NA;NA;"Machine learning; Classification; Baron-Cohen; Emotional quotient; Ensemble modeling; Systemizing quotient";Mishra, DK and Yang, XS and Unal, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ULBB6B72;conferencePaper;2019;"Shetty, Devdas; Xu, Jiajun";STRATEGIES TO ADDRESS “DESIGN THINKING” IN ENGINEERING CURRICULUM;PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2018, VOL 5;978-0-7918-5206-4;NA;NA;NA;It is suggested by many scholars that if the goal of engineering education is to produce engineers who can critically design and create, then providing students with early opportunities to engage in creative engineering design is important. While basic design is focused on the development of new products for the individual, working towards a more sustainable world demands greater attention to designing for and with communities. Improving design education and examining design-learning outcomes requires a kind of targeted approach that could match the best practices to personalize student learning. Design is complex and design includes balancing the needs of multiple stakeholders. However, there is a gap in the preparation of design education that will be needed in a challenging environment. This paper reviews the history of design thinking in the engineering curriculum. Design thinking education starts with an understanding of its importance with socioeconomic relevance. Through observation and empathy, mapping the designer uses the listening and learning tools for mapping users unarticulated needs, working in a team environment. The designer takes time to think carefully why a certain project is considered and details which aspects of machine learning application can be applied from functional to complete success for the end users. The availability of powerful virtual reality methodologies, have made it possible to consider the realistic needs and visualize scenarios and to explore the design alternatives with new ideas before full scale resource allocation on new ideas. Mid-to-advanced level courses with experimental assignments require that students apply through experimentation the principles and concepts learned in foundation courses. The basic design tools such as axiomatic thinking, theory of inventive problem solving, design iteration and simulation using hardware-in-the loop are discussed with case studies. Consideration of product sustainability with the thoughts of design for disassembly and disposal has emerged as a major part of design thinking. Senior engineering courses center on cross and interdisciplinary design and capstone experiences so that students experience fully guided practice of device design and problem solving, simulating what they are likely to experience in the world. This paper examines the critical issues of design thinking in a curriculum from observation, empathy mapping, validation of the idea, and improvement of idea by virtual reality and machine learning, optimization of the idea by tools such as axiomatic design, hardware in the loop simulation, and finally examining product sustainability causes.;2019;2021-02-11T04:02:21Z;2021-02-11T04:02:21Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;AMER SOC MECHANICAL ENGINEERS;THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Amer Soc Mech Engineers Type: Proceedings Paper;<p>ASMEInternational Mechanical Engineering Congress and Exposition (IMECE2018), Pittsburgh, PA, NOV 09-15, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6P44I9PG;journalArticle;2018;Olivier, Bert;Media, technology and the question about human benumbedness;TYDSKRIF VIR GEESTESWETENSKAPPE;NA;0041-4751;10.17159/2224-7912/2018/v58n4-1a2;NA;It is no exaggeration to claim that we live in a time that is dominated by the media as part of the more encompassing hegemony of technology What is less widely known, and understood, is that peoples lives are to a very large extent “mediated” by away of living that is pervasively technology-oriented - in other words, where earlier ages experienced the social and natural reality without some or other technical device interposed between themselves and the world, the vast majority of people today relate to the world around them by means of such technical devices. Moreover, the latter are not “innocent” or neutral, but predispose their users to specific kinds of experiences, as well as to the widespread belief that society can be technically controlled A brief discussion is devoted to Gil Germain's contention, that in the current technologically oriented dispensation humans have forgotten what it means to be “desiring” beings, and that the social ideal of technological control has reduced human “desire” - the character of being “open” to the world - to mere, technically satisfiable “need”. Under such circumstances technology mediates human experience of the world The very fact that the American president can (and does), frequently cause an uproar in American society and beyond by means of timely and untimely “tweets” - that is, by using the social internet site, Twitter - is symptomatic of this state of affairs, as well as of the fact that we live in the era of what Manuel Castells calls the “network society”. According to Castells this novel societal configuration has been made possible by the technological revolution stretching back to the invention of the radio, which led to the advent of television and multi-media, and culminated in the development of the internet. Significantly, this global technological revolution has fundamentally altered the experience of time and space, with the consequence that the traditional experience of space as “place”, and time as sequential, has made way for the newly dominant modes of spatial and temporal experience, namely as “the space of flows” and “timeless time”. The reconstruction of Castells `s conception of the structural dynamics of contemporary, society in broad terms, as fundamentally technologically generated, sets the scene for the more specifically focused discussion that follows, beginning with Sherry Turkle's analysis of the effects of technology on human behaviour. What Turkle's recent work brings to light is that, although many people aspire to the status of (what is known as) “digital natives”, this does not come without a significant cost, namely a certain deterioration in affective and intellectual functioning. Despite her initial optimism about the gains of electronic technology, particularly the internet, in the social domain, her more recent work has therefore shifted to a distinctly critical approach to the relationship between people (particularly children) and technology. Not only has the use of smartphones and electronic tablets given rise to the phenomenon of being “alone together” with one's device, and concomitantly, to keeping people at arm's length in social reality (with to-be-expected negative consequences for one k ability and willingness to negotiate complex human relationships), but the attachment of particularly young children to their smartphones has had the demonstrable effect of eroding their capacity for empathy with others, as well as more generally their ability to communicate with their peers in concrete social space. Furthermore, “ doing things” on the internet has given people the wrong impression regarding the overcoming of political problems, which often require concrete social interaction and painstaking negotiation - something that people sometimes learn anew with a shock, when their “internet activism” comes to nothing. Another critical theorist concerning technology, Bernard Stiegler, radicalises Turkle k thinking by offering a critique of technology as being, on the one hand, a source of enslavement and of the “stupidification” of people, while simultaneously being a means of “critical intenstfication”. In this respect, he argues, technology is a pharmakon - poison and cure at the same time. This means that technical devices such as smartphones inculcate an over-dependence on them in users, simultaneously - as external memory-machines - robbing them of their capacity for memory and thinking. After all, the ability to manipulate a technical device cannot be equated with critical thinking, nor can the storing of information on a smartphone or a computer be regarded as being synonymous with exercising ones own memory. On the other hand, however, Stiegler recognises the capacity of technical devices to give one access to archives of information, as well as to technically mediated experiences of the world that was not previously possible, and urges users to use technology for critical intellectual purposes, instead of being only at the receiving end of information regarding marketing and purchasing opportunities, disseminated via technical devices by capitalist agencies. He draws attention to the fact that schools have become the veritable battlegrounds where these agencies vie with teachers for the attention of students, in the process interfering with the development of their critical intellectual ability for the sake of capturing their attention for purposes of marketing. The paper concludes with a brief elaboration on some ways in which Stiegler's and Turkle's dire diagnoses may be countered with practices that give reason for hope.;2018-12;2021-02-11T04:02:21Z;2021-02-11T04:02:21Z;NA;634-649;NA;4, 1;58;NA;NA;NA;NA;NA;NA;NA;NA;NA;Afrikaans;NA;NA;NA;NA;NA;NA;Place: P. O. BOX 538, PRETORIA, 00000, SOUTH AFRICA Publisher: SUID-AFRIKAANSE AKAD VIR WETENSKAP EN KUNS, SEKRETARIS Type: Article;NA;NA;NA;NA;"media; technology; Castells; mediation; Stiegler; Turkle";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
26E2E85Y;journalArticle;2018;"Inkster, Becky; Sarda, Shubhankar; Subramanian, Vinod";An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study;JMIR MHEALTH AND UHEALTH;NA;2291-5222;10.2196/12106;NA;"Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods.";2018-11;2021-02-11T04:02:22Z;2021-02-11T04:02:22Z;NA;NA;NA;11;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"resilience; artificial intelligence; emotions; depression; empathy; conversational agents; mental health; chatbots; coping skills; mHealth; psychological";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9VPCAEQP;journalArticle;2018;"Feng, Chunliang; Yuan, Jie; Geng, Haiyang; Gu, Ruolei; Zhou, Hui; Wu, Xia; Luo, Yuejia";Individualized prediction of trait narcissism from whole-brain resting-state functional connectivity;HUMAN BRAIN MAPPING;NA;1065-9471;10.1002/hbm.24205;NA;Narcissism is one of the most fundamental personality traits in which individuals in general population exhibit a large heterogeneity. Despite a surge of interest in examining behavioral characteristics of narcissism in the past decades, the neurobiological substrates underlying narcissism remain poorly understood. Here, we addressed this issue by applying a machine learning approach to decode trait narcissism from whole-brain resting-state functional connectivity (RSFC). Resting-state functional MRI (fMRI) data were acquired for a large sample comprising 155 healthy adults, each of whom was assessed for trait narcissism. Using a linear prediction model, we examined the relationship between whole-brain RSFC and trait narcissism. We demonstrated that the machine-learning model was able to decode individual trait narcissism from RSFC across multiple neural systems, including functional connectivity between and within limbic and prefrontal systems as well as their connectivity with other networks. Key nodes that contributed to the prediction model included the amygdala, prefrontal and anterior cingulate regions that have been linked to trait narcissism. These findings remained robust using different validation procedures. Our findings thus demonstrate that RSFC among multiple neural systems predicts trait narcissism at the individual level.;2018-09;2021-02-11T04:02:22Z;2021-02-11T04:02:22Z;NA;3701-3712;NA;9;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"connectome-based predictive modeling; cross validation; narcissism; resting-state functional connectivity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
C2YP5UCY;journalArticle;2018;"Melo, Francisco S.; Mascarenhas, Samuel; Paiva, Ana";A Tutorial on Machine Learning for Interactive Pedagogical Systems;INTERNATIONAL JOURNAL OF SERIOUS GAMES;NA;2384-8766;10.17083/ijsg.v5i3.256;NA;This paper provides a short introduction to the field of machine learning for interactive pedagogical systems. Departing from different examples encountered in interactive pedagogical systems-such as intelligent tutoring systems or serious games-we go over several representative families of methods in machine learning, introducing key concepts in this field. We discuss common challenges in machine learning and how current methods address such challenges. Conversely, by anchoring our presentation on actual interactive pedagogical systems, highlight how machine learning can benefit the development of such systems.;2018-09;2021-02-11T04:02:22Z;2021-02-11T04:02:22Z;NA;79-112;NA;3;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: IST INT COMUNICAZIONI, VILLA PIAGGIO, GENOA, 16125, ITALY Publisher: SERIOUS GAMES SOC Type: Article;NA;NA;NA;NA;"Machine Learning; Interactive Pedagogical Systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
P4U5EWD7;journalArticle;2018;"Vaughn, Don A.; Savjani, Ricky R.; Cohen, Mark S.; Eagleman, David M.";Empathic Neural Responses Predict Group Allegiance;FRONTIERS IN HUMAN NEUROSCIENCE;NA;1662-5161;10.3389/fnhum.2018.00302;NA;"Watching another person in pain activates brain areas involved in the sensation of our own pain. Importantly, this neural mirroring is not constant; rather, it is modulated by our beliefs about their intentions, circumstances, and group allegiances. We investigated if the neural empathic response is modulated by minimally-differentiating information (e.g., a simple text label indicating another's religious belief), and if neural activity changes predict ingroups and outgroups across independent paradigms. We found that the empathic response was larger when participants viewed a painful event occurring to a hand labeled with their own religion (ingroup) than to a hand labeled with a different religion (outgroup). Counterintuitively, the magnitude of this bias correlated positively with the magnitude of participants' self-reported empathy. A multivariate classifier, using mean activity in empathy-related brain regions as features, discriminated ingroup from outgroup with 72% accuracy; the classifier's confidence correlated with belief certainty. This classifier generalized successfully to validation experiments in which the ingroup condition was based on an arbitrary group assignment. Empathy networks thus allow for the classification of long-held, newly-modified and arbitrarily-formed ingroups and outgroups. This is the first report of a single machine learning model on neural activation that generalizes to multiple representations of ingroup and outgroup. The current findings may prove useful as an objective diagnostic tool to measure the magnitude of one's group affiliations, and the effectiveness of interventions to reduce ingroup biases.";2018-07-31;2021-02-11T04:02:22Z;2021-02-11T04:02:22Z;NA;NA;NA;NA;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"machine learning; social neuroscience; pain; empathy; affect; ingroup; mind reading; religion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JE8IMRLP;conferencePaper;2018;"Yasuda, Kazuhiro; Saichi, Kenta; Iwata, Hiroyasu";Design and initial validity study of perception-empathy biofeedback system for gait training in older adults;2018 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC);978-1-5386-6650-0;NA;10.1109/SMC.2018.00265;NA;"Maintaining gait performance is important as a strategy for health promotion and fall prevention in older adults. In the present study, we introduced a haptic-based biofeedback (BF) system designed to augment foot pressure information with a wearable vibrotactile BF device attached to the pelvis. This device provided information regarding an older adult's foot pressure pattern to the person (trainee) and coach (trainer) to refine the interpersonal feedback. In this project, a feasibility laboratory study was first conducted to clarify the validity of the BF system (i.e., kinematic changes and cognitive burden of the device). Our preliminary study showed that the system had potential to modify the kinematic pattern in some older adults, but not walking speed (comprehensive evaluation of walking). Moreover, it is likely that the device required, to some extent, a cognitive burden for specific older people; thus, this aspect may have interfered with the usability of the BF in the initial practice phase. These results provided essential preliminary knowledge for designing a successful BF system and future trial with BF devices.";2018;2021-02-11T04:02:23Z;2021-02-11T04:02:23Z;NA;1530-1534;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Sci Council Japan ISSN: 1062-922X Type: Proceedings Paper";"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE Syst Man &amp; Cybernet Soc, Miyazaki, JAPAN, OCT 07-10, 2018</p>";NA;NA;NA;"motor learning; biofeedback; gait; human-machine interface; interpersonal feedback; older";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9X3MLUYN;conferencePaper;2018;"D'Errico, Francesca; Paciello, Marinella; Amadei, Matteo";`Behind our words': psychological paths underlying the un/supportive stance toward immigrants in social media.;2018 IEEE 5TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA);978-1-5386-5090-5;NA;10.1109/DSAA.2018.00084;NA;The present work is aimed at exploring the psychological paths underlying supportive and unsupportive social media stances toward immigrants. This investigation is based on a particular case of supportive communication on immigration promoted on line by a public figure (Morandi, a famous Italian singer). The used methodology integrated methods from data science and psychology, and it was based on a machine learning approach combined with a psycho-lexical analysis of online discussions. Results showed that from the words used by social media commenters can be extracted peculiar psychological processes behind supportive and unsupportive stance toward immigrant hosting. In particular, words were qualitatively grouped by defining the underlying value dimension, cognitive, emotional and also attributional processes for both supportive and unsupportive commenters. Thus this study allowed to find fine grained socio-psychological shades by overcoming the simple polarized online stances detection.;2018;2021-02-11T04:02:23Z;2021-02-11T04:02:23Z;NA;649-656;NA;NA;NA;NA;NA;NA;Proceedings of the International Conference on Data Science and Advanced Analytics;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM SIGKDD; Amer Stat Assoc; European Assoc Data Sci; IEEE Computat Intelligence Soc; ISI Fdn; NYU Stern Fubon Ctr; SoBigData; crowdAI; Intesa Sanpaolo ISSN: 2472-1573 Type: Proceedings Paper";<p>5th IEEE International Conference on Data Science and Advanced Analytics (IEEE DSAA), Turin, ITALY, OCT 01-04, 2018</p>;NA;NA;NA;"emotions; immigrants; online discussions; prosocial stance; values";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3D8QRNTG;journalArticle;2018;"Kiehl, Kent A.; Anderson, Nathaniel E.; Aharoni, Eyal; Maurer, J. Michael; Harenski, Keith A.; Rao, Vikram; Claus, Eric D.; Harenski, Carla; Koenigs, Mike; Decety, Jean; Kosson, David; Wager, Tor D.; Calhoun, Vince D.; Steele, Vaughn R.";Age of gray matters: Neuroprediction of recidivism;NEUROIMAGE-CLINICAL;NA;2213-1582;10.1016/j.nicl.2018.05.036;NA;"Age is one of the best predictors of antisocial behavior. Risk models of recidivism often combine chronological age with demographic, social and psychological features to aid in judicial decision-making. Here we use independent component analyses (ICA) and machine learning techniques to demonstrate the utility of using brain-based measures of cerebral aging to predict recidivism. First, we developed a brain-age model that predicts chronological age based on structural MRI data from incarcerated males (n = 1332). We then test the model's ability to predict recidivism in a new sample of offenders with longitudinal outcome data (n = 93). Consistent with hypotheses, inclusion of brain-age measures of the inferior frontal cortex and anterior-medial temporal lobes (i.e., amygdala) improved prediction models when compared with models using chronological age; and models that combined psychological, behavioral, and neuroimaging measures provided the most robust prediction of recidivism. These results verify the utility of brain measures in predicting future behavior, and suggest that brain-based data may more precisely account for important variation when compared with traditional proxy measures such as chronological age. This work also identifies new brain systems that contribute to recidivism which has clinical implications for treatment development.";2018;2021-02-11T04:02:23Z;2021-02-11T04:02:23Z;NA;813-823;NA;NA;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Age; Antisocial; MRI; Neuroprediction; Recidivism";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FKGLAKTQ;journalArticle;2018;"Kajiwara, Yusuke; Kubo, Yuki; Kimura, Haruhiko";Estimation of Evocation of Friendship Based on Similarity of Pulse Rate Variability of Users for Event-based Social Networks;SENSORS AND MATERIALS;NA;0914-4935;10.18494/SAM.2018.1777;NA;In contrast to traditional social network services (SNSs), event-based social networks determine close friendships (CFs) of users who share experiences and emotions with candidate friends in offline events. However, we could not provide feedback to cyberspace regarding the place, time, and target of a user realizing friendship since there is no technique for conveniently measuring the evocation of friendship during offline events. In this research, we propose a method of estimating the evocation of friendship using the similarity in the pulse rate variabilities (PRVs) of users when empathy is evoked between them. The user can be made aware of friendship estimated automatically through machine learning by wearing a wristwatch-type pulsimeter. CFs are more likely to evoke empathy than superficial friendships (SFs). To demonstrate the usefulness of this method, we conducted an experiment assuming an event where a group of four people are enjoying their time in an amusement park. From the experimental results, we showed that the similarity of the PRVs in CFs is greater than that in SFs when the favorability rating is high and the users like each other. Moreover, we showed that the proposed method estimated the evocation of friendship during the attraction experience with anf-measure of 0.74 at maximum and during an offline event with a mean f-measure of 0.78. The results showed the usefulness and effectiveness of this method.;2018;2021-02-11T04:02:24Z;2021-02-11T04:02:24Z;NA;1407-1426;NA;7;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1-23-3-303 SENDAGI, TOKYO, 113-0022, JAPAN Publisher: MYU, SCIENTIFIC PUBLISHING DIVISION Type: Article;NA;NA;NA;NA;"machine learning; friendship; favorability; similarity of pulse rate variability of users";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
B227UPI9;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-02-11T04:02:24Z;2021-02-11T04:02:24Z;NA;173-193;NA;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y9VCEKRT;conferencePaper;2018;"Bogatyreva, Anastasia A.; Sovkov, Andrei D.; Tikhomirova, Svetlana A.; Vinogradova, Anna R.; Samsonovich, Alexei V.";Virtual pet powered by a socially-emotional BICA;POSTPROCEEDINGS OF THE 9TH ANNUAL INTERNATIONAL CONFERENCE ON BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES (BICA 2018);NA;NA;10.1016/j.procs.2018.11.101;NA;Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents. (C) 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the scientific committee of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures.;2018;2021-02-11T04:02:24Z;2021-02-11T04:02:24Z;NA;564-571;NA;NA;145;NA;NA;NA;Procedia Computer Science;NA;NA;NA;ELSEVIER;Radarweg 29, PO Box 211, AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Biologically Inspied Cognit Architectures Soc; GoodAI; Whole Brain Architecture Initiat; Czech Tech Univ ISSN: 1877-0509 Type: Proceedings Paper";<p>9th Annual International Conference of the Biologically-Inspired-Cognitive-Architectures-Society (BICA) held as part of the Joint Multi-Conference on Human-Level Artificial Intelligence (HLAI), Czech Tech Univ, Prague, CZECH REPUBLIC, AUG 22-24, 2018</p>;NA;NA;NA;"emotional intelligence; virtual character; cognitive architecture; reinforcement learning; semantic space";Samsonovich, AV and Lebiere, CJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
G22HTCHQ;journalArticle;2017;"Plaeschke, Rachel N.; Cieslik, Edna C.; Mueller, Veronika I.; Hoffstaedter, Felix; Plachti, Anna; Varikuti, Deepthi P.; Goosses, Mareike; Latz, Anne; Caspers, Svenja; Jockwitz, Christiane; Moebus, Susanne; Gruber, Oliver; Eickhoff, Claudia R.; Reetz, Kathrin; Heller, Julia; Suedmeyer, Martin; Mathys, Christian; Caspers, Julian; Grefkes, Christian; Kalenscher, Tobias; Langner, Robert; Eickhoff, Simon B.";On the Integrity of Functional Brain Networks in Schizophrenia, Parkinson's Disease, and Advanced Age: Evidence from Connectivity-Based Single-Subject Classification;HUMAN BRAIN MAPPING;NA;1065-9471;10.1002/hbm.23763;NA;Previous whole-brain functional connectivity studies achieved successful classifications of patients and healthy controls but only offered limited specificity as to affected brain systems. Here, we examined whether the connectivity patterns of functional systems affected in schizophrenia (SCZ), Parkinson's disease (PD), or normal aging equally translate into high classification accuracies for these conditions. We compared classification performance between pre-defined networks for each group and, for any given network, between groups. Separate support vector machine classifications of 86 SCZ patients, 80 PD patients, and 95 older adults relative to their matched healthy/young controls, respectively, were performed on functional connectivity in 12 task-based, meta-analytically defined networks using 25 replications of a nested 10-fold cross-validation scheme. Classification performance of the various networks clearly differed between conditions, as those networks that best classified one disease were usually non-informative for the other. For SCZ, but not PD, emotion-processing, empathy, and cognitive action control networks distinguished patients most accurately from controls. For PD, but not SCZ, networks subserving autobiographical or semantic memory, motor execution, and theory-of-mind cognition yielded the best classifications. In contrast, young-old classification was excellent based on all networks and outperformed both clinical classifications. Our pattern-classification approach captured associations between clinical and developmental conditions and functional network integrity with a higher level of specificity than did previous whole-brain analyses. Taken together, our results support resting-state connectivity as a marker of functional dysregulation in specific networks known to be affected by SCZ and PD, while suggesting that aging affects network integrity in a more global way. (C) 2017 Wiley Periodicals, Inc.;2017-12;2021-02-11T04:02:25Z;2021-02-11T04:02:25Z;NA;5845-5858;NA;12;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"machine learning; schizophrenia; functional connectivity; brain networks; normal aging; Parkinson's disease; resting-state fMRI; support vector machine";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
P4JSGQQX;journalArticle;2017;"Alvarez-Fernandez, Sonia; Brown, Hallie R.; Zhao, Yihong; Raithel, Jessica A.; Bishop, Somer L.; Kern, Sarah B.; Lord, Catherine; Petkova, Eva; Di Martino, Adriana";Perceived Social Support in Adults with Autism Spectrum Disorder and Attention-Deficit/Hyperactivity Disorder;AUTISM RESEARCH;NA;1939-3792;10.1002/aur.1735;NA;"Perceived social support (PSS) has been related to physical and mental well-being in typically developing individuals, but systematic characterizations of PSS in autism spectrum disorder (ASD) are limited. We compared self-report ratings of the multidimensional scale of PSS (MSPSS) among age-and IQ-matched groups of adults (18-58 years) with cognitively high-functioning ASD (N=41), or attention-deficit/hyperactivity disorder (ADHD; N=69), and neurotypical controls (NC; N=69). Accompanying group comparisons, we used machine learning random forest (RF) analyses to explore predictors among a range of psychopathological and socio-emotional variables. Relative to both ADHD and NC, adults with ASD showed lower MSPSS ratings, specifically for the friends subscale (MSPSS-f). Across ASD and ADHD, interindividual differences in autism severity, affective empathy, symptoms of anxiety related to social interactions, hyperactivity/impulsivity, and somatization best predicted MSPSS-f. These relationships did not differ between clinical groups. While group comparisons demonstrated greater impairment in individuals with ASD, analyzing individuals' characteristics revealed cross-diagnoses similarities in regard to their MSPSS-f relationships. This is consistent with the Research Domain Criteria framework, supporting a trans-diagnostic approach as on the path toward “precision medicine.” (C) 2017 International Society for Autism Research, Wiley Periodicals, Inc.";2017-05;2021-02-11T04:02:25Z;2021-02-11T04:02:25Z;NA;866-877;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"social cognition; adults; autism spectrum disorder; attention-deficit/hyperactivity disorder; perceived social support";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
N6V5EULP;journalArticle;2017;"Kahler, Christopher W.; Lechner, William J.; MacGlashan, James; Wray, Tyler B.; Littman, Michael L.";Initial Progress Toward Development of a Voice-Based Computer-Delivered Motivational Intervention for Heavy Drinking College Students: An Experimental Study;JMIR MENTAL HEALTH;NA;2368-7959;10.2196/mental.7571;NA;Background: Computer-delivered interventions have been shown to be effective in reducing alcohol consumption in heavy drinking college students. However, these computer-delivered interventions rely on mouse, keyboard, or touchscreen responses for interactions between the users and the computer-delivered intervention. The principles of motivational interviewing suggest that in-person interventions may be effective, in part, because they encourage individuals to think through and speak aloud their motivations for changing a health behavior, which current computer-delivered interventions do not allow. Objective: The objective of this study was to take the initial steps toward development of a voice-based computer-delivered intervention that can ask open-ended questions and respond appropriately to users' verbal responses, more closely mirroring a human-delivered motivational intervention. Methods: We developed (1) a voice-based computer-delivered intervention that was run by a human controller and that allowed participants to speak their responses to scripted prompts delivered by speech generation software and (2) a text-based computer-delivered intervention that relied on the mouse, keyboard, and computer screen for all interactions. We randomized 60 heavy drinking college students to interact with the voice-based computer-delivered intervention and 30 to interact with the text-based computer-delivered intervention and compared their ratings of the systems as well as their motivation to change drinking and their drinking behavior at 1-month follow-up. Results: Participants reported that the voice-based computer-delivered intervention engaged positively with them in the session and delivered content in a manner consistent with motivational interviewing principles. At 1-month follow-up, participants in the voice-based computer-delivered intervention condition reported significant decreases in quantity, frequency, and problems associated with drinking, and increased perceived importance of changing drinking behaviors. In comparison to the text-based computer-delivered intervention condition, those assigned to voice-based computer-delivered intervention reported significantly fewer alcohol-related problems at the 1-month follow-up (incident rate ratio 0.60, 95% CI 0.44-0.83, P=.002). The conditions did not differ significantly on perceived importance of changing drinking or on measures of drinking quantity and frequency of heavy drinking. Conclusions: Results indicate that it is feasible to construct a series of open-ended questions and a bank of responses and follow-up prompts that can be used in a future fully automated voice-based computer-delivered intervention that may mirror more closely human-delivered motivational interventions to reduce drinking. Such efforts will require using advanced speech recognition capabilities and machine-learning approaches to train a program to mirror the decisions made by human controllers in the voice-based computer-delivered intervention used in this study. In addition, future studies should examine enhancements that can increase the perceived warmth and empathy of voice-based computer-delivered intervention, possibly through greater personalization, improvements in the speech generation software, and embodying the computer-delivered intervention in a physical form.;2017-06;2021-02-11T04:02:25Z;2021-02-11T04:02:25Z;NA;NA;NA;2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"alcohol intervention; Computer-delivered intervention; heavy drinking; voice-based systems";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QQJDF865;conferencePaper;2017;"Shimada, Tatsuro; Sakurai, Akito";Recognition of Empathy Seeking Questions in One of the Largest Woman CQA in Japan;IN℡LIGENT INFORMATION AND DATABASE SYSTEMS, ACIIDS 2017, PT I;978-3-319-54472-4;NA;10.1007/978-3-319-54472-4_60;NA;Many questions are posted on community websites in the world. Some of these questions are actually asked in order to receive empathy for the feelings of questioners, instead of getting specific answers to the questions asked. However, it is difficult to receive answers for these questions compared with questions that are asked for seeking responses other than for empathy. If such questions that are asked for the purpose of receiving empathy can get responses, it serves as an important factor to increase satisfaction of users. This paper reports on our attempt to improve response rate to the questions by classifying those questions that are asked for seeking empathy and those that are not by using machine learning and showing the questions classified as the ones seeking empathy to the prospective respondents who have been answered to these questions with higher rate.;2017;2021-02-11T04:02:25Z;2021-02-11T04:02:25Z;NA;641-650;NA;NA;10191;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Japan Adv Inst Sci & Technol; Wroclaw Univ Sci & Technol; IEEE SMC Tech Comm Computat Collect Intelligence; Quang Binh Univ; Yeungnam Univ; Bina Nusantara Univ; Univ Teknologi Malaysia; Univ Newcastle ISSN: 0302-9743 Type: Proceedings Paper";<p>9th Asian Conference on Intelligent Information and Database Systems (ACIIDS), Kanazawa, JAPAN, APR 03-05, 2017</p>;NA;NA;NA;"Machine learning; NLP; Community; CQA";Nguyen, NT and Tojo, S and Nguyen, LM and Trawinski, B;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
N6LFGN65;conferencePaper;2017;"Maia, Denise A.; Maia, Rodrigo Filev";PEDAGOGICAL ROBOTICS AS A TOOL TO WORKERS DEVELOPMENT TO INDUSTRY 4.0;9TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES (EDULEARN17);978-84-697-3777-4;NA;NA;NA;The forth industrial revolution is changing the way that all businesses, governments, and consumers interact with the physical world and the production system. This new revolution brings new paradigms that is breaking the way men work, and, consequently, changes in their training will also be necessary due to differences in knowledge and skills needed to meet new job demands. A fundamental characteristic of this new mode of production is multidisciplinary teams with a high level of technical knowledge and the ability to face several aspects of the production system, from production line up to customer interaction and integration with business and corporative systems. Besides, due to the velocity of transformations, the new employees must be able to learn and change quickly. Furthermore, such workers must develop intrinsically human characteristics like empathy, personal relationship and technical skills that machines won't be able to do, since all other activities would be done by machines with artificial intelligence and advanced robotics. This paper proposes the use of pedagogical robotics in order to develop multidisciplinary ability and development of interpersonal relationships, creativity and critical thinking to the future employees. It is discussed active learning methodology and the features of educational robotics that could be applied in order to develop the abilities to attend these new job demands.;2017;2021-02-11T04:02:26Z;2021-02-11T04:02:26Z;NA;2283-2285;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>9th International Conference on Education and New Learning Technologies (EDULEARN), Barcelona, SPAIN, JUL 03-05, 2017</p>;NA;NA;NA;"active learning; Industry 4.0; pedagogical robotics";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DKGC6XKA;conferencePaper;2017;"Ramaswamy, Naren; MacDonald, Erin";℡EPATHIC PRODUCT DESIGN FOR WATER CONSERVATION;DS87-1 PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON ENGINEERING DESIGN (ICED 17), VOL 1: RESOURCE SENSITIVE DESIGN, DESIGN RESEARCH APPLICATIONS AND CASE STUDIES;978-1-904670-89-6;NA;NA;NA;"Can a product that reads the user's mind behave more efficiently and eventually train the user to conserve? Here, as a first step to answering this big question, we present a design method for telepathic products applied to the case study of a kitchen faucet. The case study is used to illustrate the different steps of the design method: (A) Build cognitive empathy and define cognitive styles; (B) Define design requirements, articulate variables that will control performance, understand limitations and design physical product; (C) Design the machine learning algorithm, inputs, and outputs; and (D) Integration and refinement. This work-in-progress report highlights the intricacies of applying adaptive machine-learning behavior to physical products performance in the “real world” rather than to a website or device such as a smart phone. Interesting findings include that automatic response, typically associated with websites and phones, is not possible with plumbing as water cannot be instantly at the right temperature; and that cognitive styles indeed manifest in dish washing observations, with distinctly different styles in terms of patience, temperature sensitivity, and laziness.";2017;2021-02-11T04:02:26Z;2021-02-11T04:02:26Z;NA;169-178;NA;NA;NA;NA;NA;NA;International Conference on Engineering Design;NA;NA;NA;DESIGN SOC;109 DUNDEE DRIVE, GLASGOW, G52 3HL, SCOTLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ British Columbia, Dept Mech Engn; Design Soc; Univ British Columbia; Tech Univ Denmark; McGill Univ; Clemson Univ; Ryerson Univ; Univ Studiorum Zagrabiensis ISSN: 2220-4334 Type: Proceedings Paper";<p>21st International Conference on Engineering Design (ICED), Vancouver, CANADA, AUG 21-25, 2017</p>;NA;NA;NA;"Case study; Design methods; Ecodesign; Human behaviour in design; User centred design";Maier, A and Skec, S and Kim, H and Kokkolaras, M and Oehmen, J and Fadel, G and Salustri, F and VanDerLoos, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7BUIYNNX;journalArticle;2016;"Haladjian, Harry Haroutioun; Montemayor, Carlos";Artificial consciousness and the consciousness-attention dissociation;CONSCIOUSNESS AND COGNITION;NA;1053-8100;10.1016/j.concog.2016.08.011;NA;Artificial Intelligence is at a turning point, with a substantial increase in projects aiming to implement sophisticated forms of human intelligence in machines. This research attempts to model specific forms of intelligence through brute-force search heuristics and also reproduce features of human perception and cognition, including emotions. Such goals have implications for artificial consciousness, with some arguing that it will be achievable once we overcome short-term engineering challenges. We believe, however, that phenomenal consciousness cannot be implemented in machines. This becomes clear when considering emotions and examining the dissociation between consciousness and attention in humans. While we may be able to program ethical behavior based on rules and machine learning, we will never be able to reproduce emotions or empathy by programming such control systems these will be merely simulations. Arguments in favor of this claim include considerations about evolution, the neuropsychological aspects of emotions, and the dissociation between attention and consciousness found in humans. Ultimately, we are far from achieving artificial consciousness. (C) 2016 Elsevier Inc. All rights reserved.;2016-10;2021-02-11T04:02:27Z;2021-02-11T04:02:27Z;NA;210-225;NA;NA;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA Publisher: ACADEMIC PRESS INC ELSEVIER SCIENCE Type: Review;NA;NA;NA;NA;"Consciousness; Emotions; Artificial intelligence; Empathy; Artificial consciousness; Phenomenology; Visual attention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5EES2ZFJ;journalArticle;2016;"Lopez-Gil, Juan-Miguel; Virgili-Goma, Jordi; Gil, Rosa; Garcia, Roberto";Method for Improving EEG Based Emotion Recognition by Combining It with Synchronized Biometric and Eye Tracking Technologies in a Non-invasive and Low Cost Way;FRONTIERS IN COMPUTATIONAL NEUROSCIENCE;NA;1662-5188;10.3389/fncom.2016.00085;NA;Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric, and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving forty-four people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals, and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self-regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods.;2016-08-19;2021-02-11T04:02:27Z;2021-02-11T04:02:27Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"EEG; emotions; empathy; biometric information; eye tracking";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WM7RNMMG;journalArticle;2016;"Xiao, Bo; Imel, Zac E.; Georgiou, Panayiotis; Atkins, David C.; Narayanan, Shrikanth S.";Computational Analysis and Simulation of Empathic Behaviors: a Survey of Empathy Modeling with Behavioral Signal Processing Framework;CURRENT PSYCHIATRY REPORTS;NA;1523-3812;10.1007/s11920-016-0682-5;NA;Empathy is an important psychological process that facilitates human communication and interaction. Enhancement of empathy has profound significance in a range of applications. In this paper, we review emerging directions of research on computational analysis of empathy expression and perception as well as empathic interactions, including their simulation. We summarize the work on empathic expression analysis by the targeted signal modalities (e.g., text, audio, and facial expressions). We categorize empathy simulation studies into theory- based emotion space modeling or application- driven user and context modeling. We summarize challenges in computational study of empathy including conceptual framing and understanding of empathy, data availability, appropriate use and validation of machine learning techniques, and behavior signal processing. Finally, we propose a unified view of empathy computation and offer a series of open problems for future research.;2016-05;2021-02-11T04:02:27Z;2021-02-11T04:02:27Z;NA;NA;NA;5;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Review;NA;NA;NA;NA;"Computational modeling; Empathy; Analysis; Behavioral signal processing; Simulation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TMMIUICE;journalArticle;2016;"Javier Hernandez-Castro, Carlos; Barrero, David F.; R-Moreno, Maria D.";Machine learning and empathy: the Civil Rights CAPTCHA;CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE;NA;1532-0626;10.1002/cpe.3632;NA;Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7% of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are leaking too much information by unexpected ways, given non-evident design flaws. Copyright (c) 2015 John Wiley & Sons, Ltd.;2016-03-25;2021-02-11T04:02:27Z;2021-02-11T04:02:27Z;NA;1310-1323;NA;4, SI;28;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; machine learning; WordNet; CAPTCHA; HIP";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GHJMFSPF;conferencePaper;2016;"Hervas, Ramon; Johnson, Esperanza; Gutierrez Lopez de la Franca, Carlos; Bravo, Jose; Mondejar, Tania";A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars;2016 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING AND COMMUNICATIONS AND 2016 INTERNATIONAL SYMPOSIUM ON CYBERSPACE AND SECURITY (IUCC-CSS);978-1-5090-5566-1;NA;10.1109/IUCC-CSS.2016.20;NA;Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability.;2016;2021-02-11T04:02:28Z;2021-02-11T04:02:28Z;NA;93-100;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Carlos III Madrid; Univ Granada Type: Proceedings Paper";<p>15th International Conference on Ubiquitous Computing and Communications (IUCC) / 8th International Symposium on Cyberspace and Security (CSS), Granada, SPAIN, DEC 14-16, 2016</p>;NA;NA;NA;"Affective Computing; Machine Learning; Cognitive Health; Human-Avatar Interaction; Social Communication Disorders";GarciaBlas, J and Carretero, J and Ray, I and Jin, Q and Georgalas, N;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8Y996SGC;journalArticle;2016;"Bairaktarova, Diana; Bernstein, William Z.; Reid, Tahira; Ramani, Karthik";Beyond Surface Knowledge: An Exploration of How Empathic Design Techniques Enhances Engineers Understanding of Users' Needs;INTERNATIONAL JOURNAL OF ENGINEERING EDUCATION;NA;0949-149X;NA;NA;This study explores the role of empathic design techniques on solving design problems in a developing world context. In our study, over 100 graduate students were asked to individually conceptualize and design an extremely affordable washing machine to be used in developing countries. All participating students, many of whom had significant industry experience, were enrolled in a graduate-level product design course. This course is as much about design thinking and learning as it is about design innovation, creativity and doing design. The design of an artifact is addressed from a multidisciplinary perspective that includes determination through inspiration, ideation, and implementation using a design thinking framework. Student submissions were categorized based on (1) design methods such as concept generation, product definition, prototyping and design verification, and (2) student demographic information. The application of the design methods on the project influenced the further development of class-based exercises that infuse empathy into design. The study presented here also provides a framework for engaging distance-learning students within hands-on empathic-design exercises. The results show that techniques such as interviews of focus groups and immersive practices help students to better understand user needs in developing world contexts, leading to more feasible design solutions. Visual thinking was also linked as an effective means to engage students in empathic design without the use of physical materials.;2016;2021-02-11T04:02:28Z;2021-02-11T04:02:28Z;NA;111-122;NA;1, A;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: IJEE , ROSSMORE,, DURRUS, BANTRY, COUNTY CORK 00000, IRELAND Publisher: TEMPUS PUBLICATIONS Type: Article;NA;NA;NA;NA;"engineering education; distance learning; empathic design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LD4UXEUX;journalArticle;2016;de Zulueta, Paquita C.;Developing compassionate leadership in health care: an integrative review;JOURNAL OF HEALTHCARE LEADERSHIP;NA;1179-3201;10.2147/JHL.S93724;NA;"Compassionate health care is universally valued as a social and moral good to be upheld and sustained. Leadership is considered pivotal for enabling the development and preservation of compassionate health care organizations. Strategies for developing compassionate health care leadership in the complex, fast-moving world of today will require a paradigm shift from the prevalent dehumanizing model of the organization as machine to one of the organizations as a living complex adaptive system. It will also require the abandonment of individualistic, heroic models of leadership to one of shared, distributive, and adaptive leadership. “Command and control” leadership, accompanied by stifling regulation, rigid prescriptions, coercive punishments, and/or extrinsic rewards, infuses fear into the system with consequent disempowerment and disunity within the workforce, and the attrition of innovation and compassion. It must be eschewed. Instead, leadership should be developed throughout the organization with collective holistic learning strategies combined with high levels of staff support and engagement. Culture and leadership are interdependent and synergistic; their codevelopment needs to be grounded in a sophisticated, scientifically based account of human nature held within a coherent philosophical framework reflected by modern organizational and leadership theories. Developing leadership for compassionate care requires acknowledging and making provision for the difficulties and challenges of working in an anxiety-laden context. This means providing appropriate training and well-being programs, sustaining high levels of trust and mutually supportive interpersonal connections, and fostering the sharing of knowledge, skills, and workload across silos. It requires enabling people to experiment without fear of reprisal, to reflect on their work, and to view errors as opportunities for learning and improvement. Tasks and relational care need to be integrated into a coherent unity, creating space for real dialog between patients, clinicians, and managers, so that together they can cocreate ways to flourish in the context of illness and dying.";2016;2021-02-11T04:02:28Z;2021-02-11T04:02:28Z;NA;1-10;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND Publisher: DOVE MEDICAL PRESS LTD Type: Review;NA;NA;NA;NA;"resilience; culture; compassion; adaptive; complexity; servant leadership";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AURUJ44L;conferencePaper;2016;"Kawahara, Tatsuya; Yamaguchi, Takashi; Inoue, Koji; Takanashi, Katsuya; Ward, Nigel";Prediction and Generation of Backchannel Form for Attentive Listening Systems;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;10.21437/Interspeech.2016-118;NA;In human-human dialogue, especially in attentive listening such as counseling, backchannels are important not only for smooth communication but also for establishing rapport. Despite several studies on when to backchannel, most of the current spoken dialogue systems generate the same pattern of backchannels, giving monotonous impressions to users. In this work, we investigate generation of a variety of backchannel forms according to the dialogue context. We first show the feasibility of choosing appropriate backchannel forms based on machine learning, and the synergy of using linguistic and prosodic features. For generation of backchannels, a framework based on a set of binary classifiers is adopted to effectively make a “not-to-generate” decision. The proposed model achieved better prediction accuracy than a baseline which always outputs the same backchannel form and another baseline which randomly generates backchannels. Finally, evaluations by human subjects demonstrate that the proposed method generates backchannels as naturally as human choices, giving impressions of understanding and empathy.;2016;2021-02-11T04:02:29Z;2021-02-11T04:02:29Z;NA;2890-2894;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"spoken dialogue systems; attentive listening; backchannel";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GDQ8ZIGU;journalArticle;2015;"Yarkoni, Tal; Ashar, Yoni K.; Wager, Tor D.";Interactions between donor Agreeableness and recipient characteristics in predicting charitable donation and positive social evaluation;PEERJ;NA;2167-8359;10.7717/peerj.1089;NA;Agreeable people are more likely to display prosocial attitudes and helpful behavior in a broad range of situations. Here we show that this tendency interacts with the personal characteristics of interaction partners. In an online study (n = 284), participants were given the opportunity to report attitudes toward and make monetary donations to needy individuals who were described in dynamically generated biographies. Using a machine learning and multilevel modeling framework, we tested three potential explanations for the facilitatory influence of Agreeableness on charitable behavior. We find that Agreeableness preferentially increased donations and prosocial attitudes toward targets normatively rated as being more deserving. Our results advance understanding of person-by-situation interactions in the context of charitable behavior and prosocial attitudes.;2015-08-18;2021-02-11T04:02:29Z;2021-02-11T04:02:29Z;NA;NA;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND Publisher: PEERJ INC Type: Article;NA;NA;NA;NA;"Personality; Charity; Agreeableness; Charitable donation; Social evaluation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UCYYP4UX;journalArticle;2015;"Gesiarz, Filip; Crockett, Molly J.";Goal-directed, habitual and Pavlovian prosocial behavior;FRONTIERS IN BEHAVIORAL NEUROSCIENCE;NA;1662-5153;10.3389/fnbeh.2015.00135;NA;Although prosocial behaviors have been widely studied across disciplines, the mechanisms underlying them are not fully understood. Evidence from psychology, biology and economics suggests that prosocial behaviors can be driven by a variety of seemingly opposing factors: altruism or egoism, intuition or deliberation, inborn instincts or learned dispositions, and utility derived from actions or their outcomes. Here we propose a framework inspired by research on reinforcement learning and decision making that links these processes and explains characteristics of prosocial behaviors in different contexts. More specifically, we suggest that prosocial behaviors inherit features of up to three decision-making systems employed to choose between self- and other-regarding acts: a goal directed system that selects actions based on their predicted consequences, a habitual system that selects actions based on their reinforcement history, and a Pavlovian system that emits reflexive responses based on evolutionarily prescribed priors. This framework, initially described in the field of cognitive neuroscience and machine learning, provides insight into the potential neural circuits and computations shaping prosocial behaviors. Furthermore, it identifies specific conditions in which each of these three systems should dominate and promote other- or self- regarding behavior.;2015-05-27;2021-02-11T04:02:30Z;2021-02-11T04:02:30Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"prosocial behavior; altruism; reinforcement learning; dictator game; model-based; model-free; Pavlovian; warm-glow";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
F8KPGPLC;conferencePaper;2015;"Tahir, Yasir; Chakraborty, Debsubhra; Maszczyk, Tomasz; Dauwels, Shoko; Dauwels, Justin; Thalmann, Nadia; Thalmann, Daniel";Real-Time Sociometrics from Audio-Visual Features for Two-Person Dialogs;2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP);978-1-4799-8058-1;NA;NA;NA;This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.;2015;2021-02-11T04:02:30Z;2021-02-11T04:02:30Z;NA;823-827;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Circuits and Syst Singapore Chapter; Imperial Coll London; IEEE; ROSE; NANYANG TECHNOL UNIV Temasek Labs NTU; parisstandford Type: Proceedings Paper";<p>IEEE International Conference on Digital Signal Processing (DSP), Singapore, SINGAPORE, JUL 21-24, 2015</p>;NA;NA;NA;"machine learning; audiovisual analysis; dialog; real-time; sociometrics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SCXI5677;conferencePaper;2015;"Javier Hernandez-Castro, Carlos; Barrero, David F.; R-Moreno, Maria D.";A Machine Learning Attack against the Civil Rights CAPTCHA;IN℡LIGENT DISTRIBUTED COMPUTING VIII;978-3-319-10421-8;NA;10.1007/978-3-319-10422-5_26;NA;Human Interactive Proofs (HIPs) are a basic security measure on the Internet to avoid several types of automatic attacks. Recently, a new HIP has been designed to increase security: the Civil Rights CAPTCHA. It employs the empathy capacity of humans to further strengthen the security of a well known OCR CAPTCHA, Securimage. In this paper, we analyse it from a security perspective, pointing out its design flaws. Then, we create a successful side-channel attack, leveraging some well-known machine learning algorithms.;2015;2021-02-11T04:02:30Z;2021-02-11T04:02:30Z;NA;239-248;NA;NA;570;NA;NA;NA;Studies in Computational Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Autonoma Madrid, Comp Sci Dept; Univ Craiova, Fac Automat, Comp & Elect, Software Engn Dept ISSN: 1860-949X Type: Proceedings Paper";"<p>8th Symposium on Intelligent Distributed Computing (IDC), Univ Autonoma Madrid, Escuela Politecnica Super, Appl Intelligence &amp; Data, Madrid, SPAIN, SEP 03-05, 2014</p>";NA;NA;NA;NA;Camacho, D and Braubach, L and Venticinque, S and Badica, C;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
M5UUZRMN;conferencePaper;2015;"Gemeinboeck, Petra; Saunders, Rob";Movement Matters: How a Robot Becomes Body;PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'17);978-1-4503-5209-3;NA;10.1145/3077981.3078035;NA;This paper explores movement and its capacity for meaning-making and eliciting affect in human-robot interaction. Bringing together creative robotics, dance and machine learning, our research project develops a novel relational approach that harnesses dancers' movement expertise to design a non-anthropomorphic robot, its potential to move and capacity to learn. The project challenges the common assumption that robots need to appear human or animal-like to enable people to form connections with them. Our performative body-mapping (PBM) approach, in contrast, embraces the difference of machinic embodiment and places movement and its connection-making, knowledge-generating potential at the center of our social encounters. The paper discusses the first stage of the project, in which we collaborated with dancers to study how movement propels the becoming-body of a robot, and outlines our embodied approach to machine learning, grounded in the robot's performative capacity.;2015;2021-02-11T04:02:31Z;2021-02-11T04:02:31Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>4th International Conference on Movement and Computing (MOCO), Univ London, London, ENGLAND, 2017</p>;NA;NA;NA;"machine learning; social robotics; Dance; kinesthetic empathy; movement; non-anthropomorphic robots";Niehaus, K;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VGDMUAYK;journalArticle;2014;"Bedi, Gillinder; Cecchi, Guillermo A.; Slezak, Diego F.; Carrillo, Facundo; Sigman, Mariano; de Wit, Harriet";A Window into the Intoxicated Mind? Speech as an Index of Psychoactive Drug Effects;NEUROPSYCHOPHARMACOLOGY;NA;0893-133X;10.1038/npp.2014.80;NA;"Abused drugs can profoundly alter mental states in ways that may motivate drug use. These effects are usually assessed with self-report, an approach that is vulnerable to biases. Analyzing speech during intoxication may present a more direct, objective measure, offering a unique `window' into the mind. Here, we employed computational analyses of speech semantic and topological structure after +/- 3,4-methylenedioxymethamphetamine (MDMA; `ecstasy') and methamphetamine in 13 ecstasy users. In 4 sessions, participants completed a 10-min speech task after MDMA (0.75 and 1.5 mg/kg), methamphetamine (20 mg), or placebo. Latent Semantic Analyses identified the semantic proximity between speech content and concepts relevant to drug effects. Graph-based analyses identified topological speech characteristics. Group-level drug effects on semantic distances and topology were assessed. Machine-learning analyses (with leave-one-out cross-validation) assessed whether speech characteristics could predict drug condition in the individual subject. Speech after MDMA (1.5 mg/kg) had greater semantic proximity than placebo to the concepts friend, support, intimacy, and rapport. Speech on MDMA (0.75 mg/kg) had greater proximity to empathy than placebo. Conversely, speech on methamphetamine was further from compassion than placebo. Classifiers discriminated between MDMA (1.5 mg/kg) and placebo with 88% accuracy, and MDMA (1.5 mg/kg) and methamphetamine with 84% accuracy. For the two MDMA doses, the classifier performed at chance. These data suggest that automated semantic speech analyses can capture subtle alterations in mental state, accurately discriminating between drugs. The findings also illustrate the potential for automated speech-based approaches to characterize clinically relevant alterations to mental state, including those occurring in psychiatric illness.";2014-09;2021-02-11T04:02:31Z;2021-02-11T04:02:31Z;NA;2340-2348;NA;10;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
K6AAXAP5;conferencePaper;2014;"Majot, Andrew M.; Yampolskiy, Roman V.";AI Safety Engineering Through Introduction of Self-Reference Into Felicific Calculus via Artificial Pain and Pleasure;2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING;978-1-4799-4992-2;NA;NA;NA;In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of “moral mathematics” felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed.;2014;2021-02-11T04:02:32Z;2021-02-11T04:02:32Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE Type: Proceedings Paper;<p>IEEE International Symposium on Ethics in Science, Technology and Engineering, Chicago, IL, MAY 23-24, 2014</p>;NA;NA;NA;"Concept Learning; Intelligent Agents; Machine Learning; Perceptual Reasoning; Philosophical Foundations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7QD5SKBL;journalArticle;2013;"Hasey, Gary Marcel; Kiang, Michael";A Review of Recent Literature Employing Electroencephalographic Techniques to Study the Pathophysiology, Phenomenology, and Treatment Response of Schizophrenia;CURRENT PSYCHIATRY REPORTS;NA;1523-3812;10.1007/s11920-013-0388-x;NA;"Clinical experience and research findings suggest that schizophrenia is a disorder comprised of multiple genetic and neurophysiological subtypes with differential response to treatment. Electroencephalography (EEG) is a non-invasive, inexpensive and useful tool for investigating the neurobiology of schizophrenia and its subtypes. EEG studies elucidate the neurophysiological mechanisms potentially underlying clinical symptomatology. In this review article recent advances in applying EEG to study pathophysiology, phenomenology, and treatment response in schizophrenia are discussed. Investigative strategies employed include: analyzing quantitative EEG (QEEG) spectral power during the resting state and cognitive tasks; applying machine learning methods to identify QEEG indicators of diagnosis and treatment response; and using the event-related brain potential (ERP) technique to characterize the neurocognitive processes underlying clinical symptoms. Studies attempting to validate potential EEG biomarkers of schizophrenia and its symptoms, which could be useful in assessing familial risk and treatment response, are also reviewed.";2013-09;2021-02-11T04:02:32Z;2021-02-11T04:02:32Z;NA;NA;NA;9;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Review;NA;NA;NA;NA;"Electrophysiology; Language; Electroencephalography; Machine learning; Cognition; Psychosis; Schizophrenia; Working memory; Empathy; Biomarkers; Clozapine; Delusions; Disorganized speech; Endophenotypes; Error monitoring; Event-related potentials; QEEG; Resting state; Symptoms; Thought disorder; Treatment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HMQH2UGV;journalArticle;2021;"Kiesow, Hannah; Spreng, R. Nathan; Holmes, Avram J.; Chakravarty, M. Mallar; Marquand, Andre F.; Yeo, B. T. Thomas; Bzdok, Danilo";Deep learning identifies partially overlapping subnetworks in the human social brain;COMMUNICATIONS BIOLOGY;NA;NA;10.1038/s42003-020-01559-z;NA;"Complex social interplay is a defining property of the human species. In social neuroscience, many experiments have sought to first define and then locate `perspective taking', `empathy', and other psychological concepts to specific brain circuits. Seldom, bottom-up studies were conducted to first identify explanatory patterns of brain variation, which are then related to psychological concepts; perhaps due to a lack of large population datasets. In this spirit, we performed a systematic de-construction of social brain morphology into its elementary building blocks, involving similar to 10,000 UK Biobank participants. We explored coherent representations of structural co-variation at population scale within a recent social brain atlas, by translating autoencoder neural networks from deep learning. The learned subnetworks revealed essential patterns of structural relationships between social brain regions, with the nucleus accumbens, medial prefrontal cortex, and temporoparietal junction embedded at the core. Some of the uncovered subnetworks contributed to predicting examined social traits in general, while other subnetworks helped predict specific facets of social functioning, such as the experience of social isolation. As a consequence of our population-level evidence, spatially overlapping subsystems of the social brain probably relate to interindividual differences in everyday social life. Kiesow et al. use deep learning to identify partially overlapping subnetworks in the human social brain at the population level. They also demonstrate that the learned subnetwork representations can be used to predict social traits.";2021-01-14;2021-02-11T04:12:03Z;2021-02-11T04:12:03Z;NA;NA;NA;1;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY Publisher: NATURE RESEARCH Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MJ8IFGSC;journalArticle;2020;"Collard, James; Clarke, Michael";Experiential learning for trainee therapists through a shame attack exercise;COGNITIVE BEHAVIOUR THERAPIST;NA;1754-470X;10.1017/S1754470X20000549;NA;Research on self-practice/self-reflection (SP/SR) programmes in training cognitive behavioural therapy (CBT) have shown promising outcomes over the past decade. To date, the SP/SR framework research has generally focused on entire programmes and has rarely assessed the utility of specific exercises as teaching tools. This study aimed to determine the utility of an exposure intervention known as a shame attack in helping to facilitate CBT training in a clinical psychology programe when delivered in a SP/SR framework. It also sought to examine the potential for the exercise to be used as a form of competency-based assessment. Forty-one student trainees engaged in self-directed shame attack exercises and provided written reflections on their experiences. The reflections were then studied via thematic analysis. The results indicate that the exercise provides an avenue for competency-based assessment of trainee therapists' conceptual knowledge, formulation skills and intervention planning. It also promoted learning outcomes relating to a `deeper' and more nuanced appreciation of CBT theory and practice. The shame attack exercise provided for personal development and the opportunity to experience typical client challenges with engaging in exposure interventions, which have the potential for enhancing empathy and cognitive behavioural skills. Key learning aims To understand the usefulness of a shame attack exercise for training within a SP/SR framework. To examine the potential for using SP/SR as a form of competency-based training. To demonstrate the benefits of experiential learning through SP/SR in training CBT.;2020-11-23;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;NA;NA;NA;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND Publisher: CAMBRIDGE UNIV PRESS Type: Article;NA;NA;NA;NA;"experiential learning; cognitive behavioural therapy training; self-practice self-reflection; shame attack";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KYFHHI86;journalArticle;2020;"Grinberg, Hana; Zahavi, Arnona";Becoming the Little Prince: Autism Within a Psychoanalytic Environment;PSYCHOANALYTIC INQUIRY;NA;0735-1690;10.1080/07351690.2020.1810527;NA;This article will describe a long-term psychoanalysis using a self-psychology approach with a child who was diagnosed with ASD (age 4 at the beginning of the analysis). The analytic process, accompanied by deep empathy for the child's enclosed and different world, relies and builds on the child's own inner resources. Together the therapist and patient creatively learn about each other so that the analyst can join the child's world in his own unique way. The analysis raises questions about the potential of psychoanalysis and the psychoanalyst's role for the autistic patient, who has his own vision of the outside world from within his particular inner world. Can we take his suffering and difference upon ourselves and let him experience belonging and inclusion, thus aiding his developmental process of integrating the fragments of his existence into a living, adaptive, creative person thriving within relationships?;2020-10-02;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;529-535;NA;7, SI;40;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5F73JWE2;journalArticle;2021;"McGowan, Kevin; Christenson, Lea Ann; Muccio, Leah";Collaborative Professional Learning: An Exploration of Empathy in Early Childhood Teacher Education;JOURNAL OF RESEARCH IN CHILDHOOD EDUCATION;NA;0256-8543;10.1080/02568543.2020.1801537;NA;Three early childhood teacher educators from different institutions engaged in a collaborative self-study to explore the role of empathy in preservice teacher professional development. The two-fold purpose of the study was to: 1) develop and refine their practices to build teacher candidates' empathy in their interactions with children, families, and colleagues and 2) reclaim accountability in teacher education by examining their practices in complex ways. They postulate that high-stakes testing, technology, and neoliberal education reforms influence their teacher candidates' abilities and willingness to apply empathy in the classroom. A deeper understanding of how teacher candidates understand and apply empathy provides avenues for teacher educators to navigate the tensions in school reform impacted contexts.;2021-01-02;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;111-121;NA;1;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"empathy; Early childhood; teacher candidates; teacher education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KYYWDII8;journalArticle;NA;"Wedin, Adam; Sandstrom, Stina; Sandstrom, Linda; Forsberg, Angelica";Critical care nurses' experiences of nursing intoxicated patients after abuse of drugs;NURSING IN CRITICAL CARE;NA;1362-1017;10.1111/nicc.12533;NA;"Background Patients intoxicated after abusing illicit drugs constitute a significant proportion of patients cared for in intensive care units. Intensive critical care nurses who nurse accidentally intoxicated patients face complex and demanding situations, and there is a lack of studies regarding this topic. Aims and objectives To illuminate Swedish intensive critical care nurses' experiences of nursing accidentally intoxicated patients after abuse of illicit drugs. Design A qualitative design with an inductive approach was used. Methods Semi-structured interviews were conducted with eight intensive critical care nurses at an intensive care unit in Sweden. Data were analysed using qualitative content analysis. Findings The themes found illuminate intensive critical care nurses' experiences of nursing accidentally intoxicated patients after their abuse of illicit drugs: feeling empathy and a wish to provide dignified care; dreading nursing the patient and feeling a lack of empathy; feeling frustration and questioning the care; lacking knowledge about a complex and challenging situation. Conclusions It is essential to respond to intoxicated patients with empathy and dignity. Intensive critical care nurses should learn how to identify factors that lead to provocation and agitation in order to reduce the occurrence of dangerous situations in intensive care units. Relevance to clinical practice To create a caring environment where the interaction becomes more positive and harmonious, an intensive care nurse needs a deep understanding of what a drug abuse disorder means. Moreover, the ability to see the person behind the abuse and to provide non-judgemental support is required. WHAT IS KNOWN ABOUT THIS TOPICWHAT THIS PAPER CONTRIBUTES Patients intoxicated after abuse of illicit drugs constitute a significant proportion of patients cared for in ICUs worldwide. Intensive critical nurses who nurse accidentally intoxicated patients face complex and demanding situations, and few studies have addressed this topic. It is essential to respond to intoxicated patients who are admitted to the ICU with empathy and dignity, as well as to learn how to identify factors that lead to provocation and agitation in order to reduce the occurrence of dangerous situations. Education is warranted and must be enhanced, including knowledge about drug abuse and training in communication and empathy Nursing should include an understanding of what the disease of drug abuse means and the development of the ability to see the person behind the abuse and to provide non-judgemental support.";NA;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article; Early Access";NA;NA;NA;NA;"nursing; illicit drugs; intensive critical care; intoxicated patients";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7C96QBEA;journalArticle;2020;"Zelenski, Amy B.; Saldivar, Norma; Park, Linda S.; Schoenleber, Vonnie; Osman, Fauzia; Kraemer, Sara";Interprofessional Improv: Using Theater Techniques to Teach Health Professions Students Empathy in Teams;ACADEMIC MEDICINE;NA;1040-2446;10.1097/ACM.0000000000003420;NA;Problem Health professionals need to learn how to relate to one another to ensure high-quality patient care and to create collaborative and supportive teams in the clinical environment. One method for addressing both of these goals is teaching empathy during professional training to foster connection and commonality across differences. The authors describe a pilot improvisational theater (improv) course and present the preliminary outcomes showing its impact on interprofessional empathy. Approach In 2016-2017, the authors piloted a 15-hour course to teach interprofessional empathy to health professions students at the University of Wisconsin-Madison using improv techniques. The authors used a convergent mixed-methods design to evaluate the course's impact on interprofessional empathy. Students enrolled in the course (intervention group, n = 45) and a comparison group (n = 41) completed 2 validated empathy questionnaires (Interpersonal Reactivity Index [IRI], Consultative and Relational Empathy [CARE] measure) and a facial expression recognition task to measure empathy in the pre- and postintervention periods. Differences were examined using paired t tests. Semistructured interviews were conducted with 8 course participants to gain a deeper understanding of the course's effects. Outcomes The intervention group's mean scores on 5 CARE items improved significantly: ease, care, explain, help, and plan. On the IRI, personal distress levels decreased significantly in both the intervention and comparison groups. In the interviews, students who took the class reported a positive impact on their interprofessional relationships and on their ability to think on their feet. They also reported improv influenced other areas of their lives, including patient care and interactions with people outside their work life. Next Steps The authors have continued to offer the course. They aim to conduct a randomized controlled study with medical students and test durability by measuring empathy again 3-6 months following the intervention.;2020-08;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;1210-1214;NA;8;95;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA Publisher: LIPPINCOTT WILLIAMS & WILKINS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
D9LDUR5L;journalArticle;2020;"Labash, Aqeel; Aru, Jaan; Matiisen, Tambet; Tampuu, Ardi; Vicente, Raul";Perspective Taking in Deep Reinforcement Learning Agents;FRONTIERS IN COMPUTATIONAL NEUROSCIENCE;NA;NA;10.3389/fncom.2020.00069;NA;Perspective taking is the ability to take into account what the other agent knows. This skill is not unique to humans as it is also displayed by other animals like chimpanzees. It is an essential ability for social interactions, including efficient cooperation, competition, and communication. Here we present our progress toward building artificial agents with such abilities. We implemented a perspective taking task inspired by experiments done with chimpanzees. We show that agents controlled by artificial neural networks can learn via reinforcement learning to pass simple tests that require some aspects of perspective taking capabilities. We studied whether this ability is more readily learned by agents with information encoded in allocentric or egocentric form for both their visual perception and motor actions. We believe that, in the long run, building artificial agents with perspective taking ability can help us develop artificial intelligence that is more human-like and easier to communicate with.;2020-07-23;2021-02-11T04:12:04Z;2021-02-11T04:12:04Z;NA;NA;NA;NA;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"artificial intelligence; deep reinforcement learning; multi-agent; perspective taking; theory of mind";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5TAYCECF;journalArticle;NA;"Toh, Weimin; Lim, Fei Victor";Using Video Games for Learning: Developing a Metalanguage for Digital Play;GAMES AND CULTURE;NA;1555-4120;10.1177/1555412020921339;NA;With technological advancement, digital play is increasingly popular as digital games appeal to all ages but are particularly attractive to youths and children. It is useful to develop a deeper understanding of digital play and to explore ways in which caregivers can guide young people in their play to recognize and develop different types of learning. This article attempts to address these issues through proposing a metalanguage for digital play. The theoretical orientation adopted in this article is that of social semiotics and critical multiliteracies. Our focus is on harnessing the affordances of digital play for learning by systematizing them into a metalanguage based on social semiotic theory that models the meaning potential of semiotic resources into the representation, engagement, and organization functions. From the metalanguage, the pedagogical implications or a set of principles of using digital play for learning in the classroom context are discussed.;NA;2021-02-11T04:12:05Z;2021-02-11T04:12:05Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article; Early Access";NA;NA;NA;NA;"digital learning; metalanguage; multiliteracies; multimodal digital play; social semiotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
W6BYCQAZ;journalArticle;2020;"Maldonado, Julie; Schuller, Mark";“Imagining a More Just World”: Interview with Julie Maldonado;ANNALS OF ANTHROPOLOGICAL PRACTICE;NA;2153-957X;10.1111/napa.12136;NA;It is difficult to canonize anthropology and anthropological concepts, in part because of the creative tensions within the discipline's contradictions: a desire and deep respect for local knowledge with a global, comparative perspective, what might be called the “anthropological imagination.” Firmly rooted in-and in defense of-an inclusive vision of humanity, an anthropological imagination inspires “radical empathy.” It offers the scaffolding of a coalitional politics that values the specificity of local struggles but also reaffirms and defends humanity. We must identify the humanity in others, and the common humanity in their struggle, while affirming particular identities and challenging differential privilege: an anthropological imagination inspires radical empathy and solidarity, reminding us, in the words of the World Social Forum, that “another world is possible.” How people learn to cultivate this anthropological imagination and bring it in the service of marginalized groups is not generally discussed, and rarely taught. This article aims to bridge this gap. On October 10, 2018, Julie Maldonado, Associate Director for the Livelihoods Knowledge Exchange Network (LiKEN), discussed her new book,Seeking Justice in an Energy Sacrifice Zone: Standing on Vanishing Land in Coastal Louisiana, via video-conference with Mark Schuller's Anthropology and Contemporary World Problems class at Northern Illinois University. This interview offers one perspective of a career focused around advocacy anthropology that aims to reach public audiences and policy- and decision-makers in ways that translates scholarly research into information that is most useful for problem solving and enacting change in response to our climate crisis.;2020-05;2021-02-11T04:12:05Z;2021-02-11T04:12:05Z;NA;6-13;NA;1;44;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN, NJ 07030 USA Publisher: WILEY Type: Editorial Material;NA;NA;NA;NA;"climate change; advocacy anthropology; environmental justice; public anthropology; social justice";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UZSQLSLY;journalArticle;2020;"Leonardi, Simone; Monti, Diego; Rizzo, Giuseppe; Morisio, Maurizio";Multilingual Transformer-Based Personality Traits Estimation;INFORMATION;NA;NA;10.3390/info11040179;NA;Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users' information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes Facebook posts from the myPersonality dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback-Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits.;2020-04;2021-02-11T04:12:05Z;2021-02-11T04:12:05Z;NA;NA;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"deep learning; affective computing; natural language processing; Big 5; multilingual embeddings; personality dimensions; sentence embeddings";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EQPHTIJM;journalArticle;2020;Nadin, Mihai;Aiming AI at a moving target: health (or disease);AI & SOCIETY;NA;0951-5666;10.1007/s00146-020-00943-x;NA;Justified by spectacular achievements facilitated through applied deep learning methodology (based on neural networks), the “Everything is possible” view dominates this new hour in the “boom and bust” curve of AI performance. The optimistic view collides head on with the “It is not possible”-ascertainments often originating in a skewed understanding of both AI and medicine. The meaning of the conflicting views can be assessed only by addressing the nature of medicine. Specifically: Which part of medicine, if any, can and should be entrusted to AI-now or at some moment in the future? AI or not, medicine should incorporate the anticipation perspective in providing care.;2020-12;2021-02-11T04:12:05Z;2021-02-11T04:12:05Z;NA;841-849;NA;4;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Data; Artificial intelligence; Anticipation; Deep medicine; Meaning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7IP9GUUL;journalArticle;2020;Engbers, Ruth A.;Students' perceptions of interventions designed to foster empathy: An integrative review;NURSE EDUCATION TODAY;NA;0260-6917;10.1016/j.nedt.2019.104325;NA;Objective: Empathy is assumed to be an important element of nursing care, and nursing educators are attempting to find ways to effectively foster empathy in their students. The purpose of this review is to gain a deeper grasp of what undergraduate nursing students are learning from interventions educators have designed to cultivate empathy by synthesizing qualitative data. Review methods: Utilizing the review methodology proposed by Whittemore and Knafl, a survey of the CINAHL, Web of Science, PubMed, and PsychINFO databases was undertaken to answer the question: What are undergraduate nursing students' perceptions of interventions designed to foster empathy? Results: A thematic synthesis of the students' perceptions from the 17 articles meeting inclusion criteria revealed five themes: Understanding the other's experience, embodying the other's experience, becoming aware of self, informing the role of the nurse, and learning or transforming. Conclusions: Although additional conceptual work remains to create a coherent, complete, and parsimonious definition of empathy, the results indicate that the students are gaining many of the facets assumed to be part of the concept of empathy through these educational interventions. Immersive simulations that put students in the role of the “other” were particularly impactful, especially if they created a disorienting dilemma followed by guided reflection. These findings can help nursing educators tailor their interventions for their specific intended learning outcomes.;2020-03;2021-02-11T04:12:05Z;2021-02-11T04:12:05Z;NA;NA;NA;NA;86;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNAL PRODUCTION DEPT, ROBERT STEVENSON HOUSE, 1-3 BAXTERS PLACE, LEITH WALK, EDINBURGH EH1 3AF, MIDLOTHIAN, SCOTLAND Publisher: CHURCHILL LIVINGSTONE Type: Review;NA;NA;NA;NA;"Education; Empathy; Simulation; Experiential learning; Qualitative";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XMU5C8UT;conferencePaper;2020;"Davidova, Jelena; Kokina, Irena";Students' Opinion on the Quality Assurance of a Study Process: Case Study at Daugavpils University, Latvia;RURAL ENVIRONMENT, EDUCATION, PERSONALITY. (REEP);978-9984-48-343-6;NA;10.22616/REEP.2020.005;NA;"It is obvious that in recent years the system of higher education quality assurance has undergone several essential changes: a greater emphasis is being laid on the qualification framework, on student-centred learning and study results; also there is a change in the attitude from quality assurance towards the development of the teaching staff One of the characteristics of higher education is the extent the higher education is based on active students' participation in the assessment of the study process. The aim of the study is to explore students' opinions about the process of study quality assurance at the Daugavpils University (further - DU), Latvia. The participants of this study were 60 students from 12 master and doctoral study programs at DU. The analysis of structured interviews with the students made it possible to identify the typical characteristic features of DU internal quality assessment. The research showed that students assess highly lecturers' personal qualities (attitude to their profession, personal interest in students' success, empathy, striving for cooperation) and their professional qualities (knowledge of the subject, didactic and communicative competence, and ability to get the feedback from students as well). To promote the cooperation between the students and the academic staff of DU, it is useful to practice trans-disciplinary out-of-study forms. Summer schools for students studying in master and doctoral programs encourage students to think about the future of civilization, about a sustainable and unsustainable behaviour on a local and global scale, goals of a sustainable development and awareness about them, and also about the role of a qualitative education content and study environment for achieving these goals. The use of international summer schools, academic discussions and creative work-shops contribute to a deeper understanding of the study content, of topicalities in global education and possibilities of synergetic thinking in cooperation between students and lecturers.";2020;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;48-54;NA;NA;NA;NA;NA;NA;Rural Environment Education Personality;NA;NA;NA;LATVIA UNIV LIFE SCIENCES & TECHNOLOGIES;LIELA IELA 2, JELGAVA, LV-3001, LATVIA;English;NA;NA;NA;NA;NA;NA;ISSN: 2255-8071 Issue: 13 Type: Proceedings Paper;<p>13th Annual International Scientific Conference on Rural Environment, Education, Personality (REEP), Latvia Univ Life Sci, Jelgava, LATVIA, 2020</p>;NA;NA;NA;"out-of-study forms in a higher education institution; study process quality assurance";Dislere, V;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FSYW2FSQ;journalArticle;2020;"Doraiswamy, P. Murali; Blease, Charlotte; Bodner, Kaylee";Artificial intelligence and the future of psychiatry: Insights from a global physician survey;ARTIFICIAL IN℡LIGENCE IN MEDICINE;NA;0933-3657;10.1016/j.artmed.2019.101753;NA;Background: Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective: To characterize the global psychiatrist community's opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design: Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures: We measured opinions about the likelihood that AI/ML tools would be able to fully replace - not just assist - the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist's perceptions about whether benefits of AI/ML would outweigh the risks. Results: Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions: Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.;2020-01;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;NA;NA;NA;102;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS Publisher: ELSEVIER Type: Article;NA;NA;NA;NA;"Deep learning; Empathy; Autonomous agents; Mental health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZSSAY5LY;journalArticle;2019;"Du Toit-Brits, Charlene; Blignaut, Henry";Positioning self-directed continuing learning skills in twenty-first century education;TYDSKRIF VIR GEESTESWETENSKAPPE;NA;0041-4751;10.17159/2224-7912/2019/v59n4a4;NA;Education must be recognised as an essential instrument in addressing the challenges within the twenty-first century, but it cannot exist in isolation or independently. Therefore, it is important to pay attention to the demands for education and training in support of the labour markets. The knowledge-oriented nature of work requires that all individuals must be literate, take responsibility for actions (learning) and learn how to think. High demands are set for the personal skills of individuals as they are responsible for their personal development as well as for establishing their quality of life. Individuals, therefore, need more knowledge and insight, a higher consciousness of the self and a greater ability to motivate the self. High demands are made towards the interpersonal skills of individuals, including, amongst others, empathy (orientation to service delivery) and social skills (communication, conflict management, team building skills, cooperation, initiating change). In the opinion of the authors, transformative and holistic continuing or lifelong self-directed learning is vital to addressing the gap between the knowledge and skills which learners acquire at school and the knowledge and skills which are relevant in the labour market and the twenty-first century. We argue, firstly, that transformative and holistic continuing self-directed learning with its purpose and function is essential for human functioning. Secondly, the connection between transformative and holistic continuing self-directed learning and success requires a change in ways of thinking (a mindshift). Thirdly, transformative and holistic continuing self-directed learning results in successful change in the individual learner. The fourth reason which the authors provide is that transformative and holistic continuing self-directed learning is essential to becoming successful in a labour market context. In addition, we believe that transformative and holistic continuing self-directed learning involves action learning, since individuals must learn while they are thinking about issues and working on real problems to implement real solutions. It can be seen as a systematic process that builds on the experiences, knowledge and skills of individuals, while individuals must also be encouraged to question learning content, which can lead to the creation of new knowledge. The information explosion requires the education system to move from a pervasive teacher-directed approach to a more learner-centred approach to prepare school learners for the labour market and the twenty-first century. The authors support the discourse that education institutions must deliver learners who will have a high degree of self-directedness in learning and become transformed lifelong self-directed individuals who do not merely focus on the product (market) but realise the value of the learning process. Education requires a paradigm shift that includes the relevance of alternative teaching-learning strategies and methods like SDL and problem solving in which learners are functionally immersed in deep thinking and occupied with their learning. The above statement is vital to creating citizens who can think independently, creatively solve problems and assume their positions as contributing citizens of the society. According to the authors, (life-long) SDL is of great importance in filling the gap between the knowledge and skills that learners must master at school on the one hand and the knowledge and skills that are relevant for the labour market and society of the twenty-first century on the other. Education in the twenty-first century should, therefore, be recognised as an important tool for dealing with the challenges of the 21st century, but it cannot be used in isolation (Knowles, Holton & Swanson 2015). Thus, this study indicates that it is essential that the skills that the twenty-first century societies and workplaces demand be developed in schools. In addition, the educational needs, general objectives in the Curriculum and Assessment Policy Statement of South Africa (CAPS), the twenty-first century skills and the skills needed for individuals to function amidst the fourth industrial revolution should be combined in an effort to contribute to (lifelong) SDL.;2019-12;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;512-529;NA;4;59;NA;NA;NA;NA;NA;NA;NA;NA;NA;Afrikaans;NA;NA;NA;NA;NA;NA;Place: P. O. BOX 538, PRETORIA, 00000, SOUTH AFRICA Publisher: SUID-AFRIKAANSE AKAD VIR WETENSKAP EN KUNS, SEKRETARIS Type: Article;NA;NA;NA;NA;"learning; 21st century; continuous life-long; education system; learners; self-directed learning; self-directedness; skills; teacher";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CCW2UHYV;journalArticle;2019;Walter, Pierre;Innovations in Teaching Adult Education Living History Museums and Transformative Learning in the University Classroom;ADULT LEARNING;NA;1045-1595;10.1177/1045159519826074;NA;"The difficult times in which we live require innovative, creative, and hopeful pedagogies of adult education. This article describes a nontraditional experiential, “empathy-invoking” approach to the teaching of a graduate course on the theory and research of adult learning. The approach begins with the building of a safe learning community, a familiar “knowledge curriculum,” and a structured syllabus with academic readings, small group discussions, student “theory-topractice” facilitation of learning activities, and an academic mid-term paper. Both the teacher and students design and lead learning activities which elaborate, “unpack,” and critique readings, and develop students' capacity for experiential, emotional, spiritual, arts-based, and bodily learning as well as group process, all the while reinforcing trust, deeper relationships, cooperation, and better knowledge of each others' lives, personalities, capabilities, and identities. The class culminates in creative presentations where learners transform the classroom into “living history museums” representing the sites of adult learning they have investigated in field research. Visitors to living history museums engage in a rich array of informal adult learning; they gain new knowledge, participate in hands-on learning and role playing, and at times even experience transformative learning. In this class, the museum and its learning opportunities come into the classroom, and are created by learners themselves.";2019-08;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;121-127;NA;3;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"adult education pedagogy; adult learning theory; experiential curriculum; holistic learning; living history museums; transformative learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5IU6S9Y5;journalArticle;2019;"Swendiman, Robert A.; Marcaccio, Christina L.; Han, Jason; Hoffman, Daniel I.; Weiner, Timothy M.; Nance, Michael L.; Chou, Carol M.";Attitudes and Habits of Highly Humanistic Surgeons: A Single-Institution, Mixed-Methods Study;ACADEMIC MEDICINE;NA;1040-2446;10.1097/ACM.0000000000002690;NA;Purpose Humanism in medicine is associated with increased patient satisfaction, trust of patients in their doctors, and better outcomes. The authors sought to identify attitudes, habits, and other factors that sustain humanism in academic surgical faculty, and compare these with attributes determined from a previous study of internal medicine faculty. Method A mixed-methods study design at University of Pennsylvania Health System was employed from 2016 to 2018 using a survey instrument and semistructured interviews. Surgical residents nominated faculty who exemplified humanism. In-depth interviews were then conducted with surgeons receiving the most nominations. The interviews were transcribed, and common themes were identified using the grounded theory method. These were compared with findings from a previous internal medicine study. Results Ten faculty described three strongly shared attitudes: humility, responsibility, and a desire to live up to a high standard of professional behavior. Five habits were found important to sustaining these attitudes and their practice: self-reflection, finding deep connections with patients, maintaining personal and professional relationships, “having fun” at work, and paying it forward to surgical trainees. Surgeons also cited the importance of past role models in developing humanistic attitudes and sustaining practice. Responses were compared with previously documented attitudes and habits of humanistic internal medicine faculty at the institution. Conclusions This study identified recurring attitudes and habits that characterize humanistic behaviors in a cohort of academic surgeons. Learning from these exemplary humanistic surgeons may inform the development of future educational programs for residents and faculty in sustaining humanism.;2019-07;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;1027-1032;NA;7;94;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA Publisher: LIPPINCOTT WILLIAMS & WILKINS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ABEXSGL5;journalArticle;2019;"Piumatti, Giovanni; Abbiati, Milena; Baroffio, Anne; Gerbase, Margaret W.";Associations between motivational factors for studying medicine, learning approaches and empathy among medical school candidates;ADVANCES IN HEALTH SCIENCES EDUCATION;NA;1382-4996;10.1007/s10459-018-9866-6;NA;Previous research highlighted associations between students' motivation for medical studies and their learning approaches on the one hand and empathy on the other. Internal motivational factors for studying medicine (e.g., care for patients, save lives) coupled with a deep approach to learning have been positively related to empathy in contrast to external motivational factors (e.g., future earning potential, prestige) and surface learning. However, assessments of these assumptions among medical school candidates are scarce. This study examined the relationship between different motivational factors and empathy among students enrolled in a selection year in medicineby testing the mediating role of learning approaches. A sample of 572 candidates for medical studies answered a self-reported questionnaire half way through their selection year. Measures included internal and external motivational factors for studying medicine, deep and surface learning approaches and empathy. Path-analysis tested the mediation effects of deep and surface approaches to learning on the relationship of internal and external motivational factors with empathy. The deep learning approach partially mediated the significant positive association between internal motivational factors and empathy, while the surface learning approach fully mediated the significant negative association between external motivational factors and empathy. These results suggest that learning approaches could be a pathway by which internal and external motives for studying medicine are related to empathy among medical school candidates. Pedagogical strategies and educational environments accounting for individual differences in motivation and learning may contribute to training students to become professional and caring doctors in the future.;2019-05;2021-02-11T04:12:06Z;2021-02-11T04:12:06Z;NA;287-300;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Learning approaches; Motivational factors; Undergraduate medical students";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
K4ZNXRPN;journalArticle;2019;Roberts, Kelly Morris;An analysis of autobiographical tools in written reflection: implications for teaching critical thinking and goal-setting;REFLECTIVE PRACTICE;NA;1462-3943;10.1080/14623943.2019.1575196;NA;"This paper analyzes the results of an 18month study of a variety of participants involved in written reflection on their learning, both in classes at two universities in the Southern US or in voluntary focus groups. The purpose of the study was to analyze the effects of including autobiographical tools in written reflection. Participants used three tools from the genre of autobiography as they reflected on their learning inside either course content, internship experiences, experiential learning, or goal-setting. Over 500 samples were gathered, offering a large data set for analysis of what kinds of best practice produce quality reflective writing. Through analysis of the data and student surveys and interviews, results show increased attention to critical thinking and metacognition; expressed flexibility, adaptability, and ability to handle ambiguity; and value in connection to others/empathy-building as a result of incorporating autobiographical tools in reflective prompts. The study indicated that reflections using the same autobiographical tool over the course of several sessions seemed to produce deeper levels of reflection and more engagement with the autobiographical tool. Of the three autobiographical tools used in the study, the tool that seemed most helpful to participants was reflection as storytelling that revealed aspects of the self.";2019-03-04;2021-02-11T04:12:07Z;2021-02-11T04:12:07Z;NA;201-217;NA;2;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"experiential learning; critical thinking; Reflection; teacher education; autobiography; goal setting; written reflection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JDIM425C;journalArticle;NA;Walter, Pierre;Innovations in Teaching Adult Education Living History Museums and Transformative Learning in the University Classroom;ADULT LEARNING;NA;1045-1595;10.1177/1045159519826074;NA;"The difficult times in which we live require innovative, creative, and hopeful pedagogies of adult education. This article describes a nontraditional experiential, “empathy-invoking” approach to the teaching of a graduate course on the theory and research of adult learning. The approach begins with the building of a safe learning community, a familiar “knowledge curriculum,” and a structured syllabus with academic readings, small group discussions, student “theory-to-practice” facilitation of learning activities, and an academic mid-term paper. Both the teacher and students design and lead learning activities which elaborate, “unpack,” and critique readings, and develop students' capacity for experiential, emotional, spiritual, arts-based, and bodily learning as well as group process, all the while reinforcing trust, deeper relationships, cooperation, and better knowledge of each others' lives, personalities, capabilities, and identities. The class culminates in creative presentations where learners transform the classroom into “living history museums” representing the sites of adult learning they have investigated in field research. Visitors to living history museums engage in a rich array of informal adult learning; they gain new knowledge, participate in hands-on learning and role playing, and at times even experience transformative learning. In this class, the museum and its learning opportunities come into the classroom, and are created by learners themselves.";NA;2021-02-11T04:12:07Z;2021-02-11T04:12:07Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article; Early Access";NA;NA;NA;NA;"adult education pedagogy; adult learning theory; experiential curriculum; holistic learning; living history museums; transformative learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FICD6447;journalArticle;2019;"Schultze, Steven R.; Mujica, Frances C.; Kleinheksel, A. J.";Demographic and spatial trends in diabetes-related virtual nursing examinations;SOCIAL SCIENCE & MEDICINE;NA;0277-9536;10.1016/j.socscimed.2019.01.002;NA;Diabetes currently affects nearly 30 million Americans, but the distribution of cases is not uniform across all demographics or every state. In the course of their education, nurses learn how to become important conduits for information on diabetes management during their eventual interactions with patients. Exploring the status and trends of diabetes-related knowledge in nursing students is one method to explore the idea that one's community affects how one sees disease. However, they are not yet experts, which places them in a period of transition. This study used data mined from the Shadow Health Digital Clinical Experience (TM) virtual patient exams conducted by nursing students between the years of 2012 and 2015 to find any potential demographic or spatial trends within simulation performance results from nursing students who examined a virtual patient with self-managed diabetes. Findings of the analysis indicated that age and experience affected the way in which an examination was conducted, where older and more experienced nursing students asked 8% fewer examination questions, yet showed 32% more empathy and offered 76% more educational statements than their younger counterparts. Spatial trends were less pronounced, although deeper analysis revealed that students in states closer to the national mean for population rate with diabetes perform better, show more empathy, and offer more educational statements during examinations compared to states well above or well below the national mean. This suggests that targeted information may be preferable to “one-sizefits-all” public health awareness and education programs for diabetes programs used uniformly across the country.;2019-02;2021-02-11T04:12:07Z;2021-02-11T04:12:07Z;NA;225-230;NA;NA;222;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Data mining; Demographics; Diabetes; Nursing students; Spatial analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2PZZIH6Q;conferencePaper;2019;"Trevino Sherk, Julieta; Cobreros Rodriguez, Carlos";RURAL DEMOCRATIC DESIGN: PARTICIPATORY DESIGN AND SERVICE LEARNING STRATEGIES IN SUSTAINABLE DEVELOPMENT TO PROMOTE CIVIC MINDEDNESS IN COMMUNITY DEVELOPMENT;TOWARDS A NEW INNOVATION LANDSCAPE;978-1-912254-05-7;NA;NA;NA;The Natural Lab is a design-build programme at the Architecture, Art and Design School at the Tecnologico de Monterrey in Queretaro, Mexico. Ethnographic research and participatory design methods were part of a collaborative process aimed at empowering students in creating a sustainable community for the residents of Tilaco, Mexico. Student teams discovered the real needs of the community through ethnographic research, and were involved in daily activities of the community, the important events, and the festivities. This built deep empathy with the people with whom students were designing, getting to understand who they are, what they do, what they think and feel. The attitude was about understanding the emotional needs of the users. In conjunction with the ethnographic information determined during the discovery phase, students applied participatory design methods throughout the process, beginning with activities that helped community members create a vision for their development. Students adapted participatory methods to all the phases of the design process, which were implemented through community workshops. These workshops helped to address complexities, empower community, and balance the need to preserve natural/cultural resources. The student and community's work culminated in co-design proposals of high social impact through key strategic actions including the construction of small-scale and environmentally responsible projects.;2019;2021-02-11T04:12:07Z;2021-02-11T04:12:07Z;NA;NA;NA;NA;NA;NA;NA;NA;E&PDE;NA;NA;NA;DESIGN SOC;109 DUNDEE DRIVE, GLASGOW, G52 3HL, SCOTLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Dept Design, Mfg & Engn Management; Design Soc, Design Educ Special Interest Grp; Inst Engn Designers Type: Proceedings Paper";"<p>21st International Conference on Engineering and Product Design Education (E and PDE), Univ Strathclyde Technol &amp; Innovat Ctr, Glasgow, SCOTLAND, SEP 11-13, 2019</p>";NA;NA;NA;"civic mindedness; ethnographic studies; participatory design; rural community development; Service-learning";Bohemia, E and Kovacevic, A and Buck, L and Brisco, R and Evans, D and Grierson, H and Ion, W and Whitfield, RI;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3RBRA72V;conferencePaper;2019;"Mathews, Deepa Mary; Abraham, Sajimon";Social Data Sentiment Analysis of a Multilingual Dataset: A Case Study with Malayalam and English;ADVANCED INFORMATICS FOR COMPUTING RESEARCH, PT I;"978-981-15-0108-1; 978-981-15-0107-4";NA;10.1007/978-981-15-0108-1_8;NA;Opinion Analysis is an articulate methodology that is indivisibly crypt to the sector of Emotional Sciences which concern the individual supposition, emotions or thoughts and thereby identifies the personal deeds. Natural language processing techniques presume that in common most of the user annotations are written in English dialect, but as focus shifts onto processing comments from internet sources such as microblogging services, this becomes progressively harder to guarantee. Conveying the empathy in their own language can be well thought-out as the homey means for expressing the exact opinion and it leads to the generation of multilinguistic societal data. So the challenge is to analyze the formal textual content along with the informal and mixed linguistic nature of social data. This prompts the need of Sentiment Analysis in multilingual dialects. This article surveys the methodologies used for analyzing the sentiment of multilingual data and proposed a model built using Long Short Term Memory approach.;2019;2021-02-11T04:12:07Z;2021-02-11T04:12:07Z;NA;70-78;NA;NA;1075;NA;NA;NA;Communications in Computer and Information Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Comp Soc India, Jaipur Chapter; MRK Inst Engn & Technol; Leafra Res Pvt Ltd ISSN: 1865-0929 Type: Proceedings Paper";<p>3rd International Conference on Advanced Informatics for Computing Research (ICAICR), Shimla, INDIA, JUN 15-16, 2019</p>;NA;NA;NA;"Deep learning; Sentiment analysis; Opinion mining; Long Short Term Memory; Malayalam; Multilingual";Luhach, AK and Jat, DS and Hawari, KBG and Gao, XZ and Lingras, P;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WUV8MXY3;conferencePaper;2019;"Carranza, Karmelo Antonio Lazaro R.; Manalili, Joshua; Bugtai, Nilo T.; Baldovino, Renann G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7TH INTERNATIONAL CONFERENCE ON ROBOT IN℡LIGENCE TECHNOLOGY AND APPLICATIONS (RITA);978-1-72813-118-4;NA;NA;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019;2021-02-11T04:12:08Z;2021-02-11T04:12:08Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computat Intelligence Soc; MIR MSREP; Smilegate; WCG; Inst Control Robot & Syst; Daejeon Int Marketing Enterprise; Korea Tourism Org Type: Proceedings Paper";<p>7th International Conference on Robot Intelligence Technology and Applications (RiTA), KAIST, Daejeon, SOUTH KOREA, NOV 01-03, 2019</p>;NA;NA;NA;"deep learning; affective computing; emotionally aware technology; facial expression detection; scripted chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DPG927ZU;conferencePaper;2019;"Tavabi, Leili; Stefanov, Kalin; Gilani, Setareh Nasihati; Traum, David; Soleymani, Mohammad";Multimodal Learning for Identifying Opportunities for Empathetic Responses;ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION;978-1-4503-6860-5;NA;10.1145/3340555.3353750;NA;Embodied interactive agents possessing emotional intelligence and empathy can create natural and engaging social interactions. Providing appropriate responses by interactive virtual agents requires the ability to perceive users' emotional states. In this paper, we study and analyze behavioral cues that indicate an opportunity to provide an empathetic response. Emotional tone in language in addition to facial expressions are strong indicators of dramatic sentiment in conversation that warrant an empathetic response. To automatically recognize such instances, we develop a multimodal deep neural network for identifying opportunities when the agent should express positive or negative empathetic responses. We train and evaluate our model using audio, video and language from human-agent interactions in a wizard -of-Oz setting, using the wizard's empathetic responses and annotations collected on Amazon Mechanical Turk as ground -truth labels. Our model outperforms a textbased baseline achieving Fl -score of 0.71 on a classification. We further investigate the results and evaluate the capability of such a model to be deployed for real-world human-agent interactions.;2019;2021-02-11T04:12:08Z;2021-02-11T04:12:08Z;NA;95-104;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; Assoc Comp Machinery; Openstream; Alibaba Grp; Microsoft; Baidu; Sensetime; Tencent YouTu Lab; AISpeech Type: Proceedings Paper";<p>21st ACM International Conference on Multimodal Interaction (ICMI), Suzhou, PEOPLES R CHINA, OCT 14-18, 2019</p>;NA;NA;NA;"machine learning; empathy; human behavior; multimodal sentiment; virtual human";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HLI7QWQA;conferencePaper;2019;"Davidova, Jelena; Kokina, Irena";Study environment in the context of hei study quality assurance: case study at Daugavpils University (Latvia);5TH INTERNATIONAL CONFERENCE ON HIGHER EDUCATION ADVANCES (HEAD'19);978-84-9048-661-0;NA;10.4995/HEAd19.2019.9047;NA;In recent years the system of higher education quality assurance has undergone several essential changes: a greater emphasis is being laid on the qualification framework, on student-centered learning and study results, the development of the teaching staff active students' participation in the assessment of the study process. The given study is oriented towards studying students' opinions about the study environment in the context of study quality assurance at Daugavpils University (DU), Latvia. The participants of this study were 60 students from 12 master and doctoral study programs at Daugavpils University. The analysis of structured interviews with the students made it possible to identify the typical characteristic features of HEI study environment as the significant ctireria of DU internal quality assessment. The research showed that students assess highly lecturers' personal qualities (attitude to their profession, personal interest in students' success, empathy, striving for cooperation) and their professional qualities (knowledge of the subject, didactic and communicative competence, and ability to get the feedback from students as well). To promote the cooperation between the students and the academic staff of DU, it is useful to practice trans-disciplinary out-of-study forms, which contribute to a deeper understanding of the study content, of topicalities in global education and possibilities of synergetic thinking in cooperation with students and lecturers.;2019;2021-02-11T04:12:08Z;2021-02-11T04:12:08Z;NA;1305-1312;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;UNIV POLITECNICA VALENCIA;CAMINO VERA S-N, VALENCIA, 46022, SPAIN;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Generalitat Valenciana; Univ Politecnica Valencia; European Social Fund; Fac Administrac Direcc Empresas; Dept Economia Ciencias Sociales; Inst Ciencias Educac; Centro Ingn Economica; Nievina Type: Proceedings Paper";"<p>5th International Conference on Higher Education Advances (HEAd), Univ Politecnica Valencia, Fac Business Adm &amp; Management, Valencia, SPAIN, JUN 25-28, 2019</p>";NA;NA;NA;"higher education institution; quality assurance";Domenech, J and Merello, P and DeLaPoza, E and Blazquez, D and PenaOrtiz, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JALYQN97;journalArticle;2019;"Borges, Marcelo Gulcs; McVittie, Janet";Conversations on Pedagogies of Place and Environment between Brazil and Canada: Contrasting Contexts to Enshroud Content with Empathy;INTERFACES BRASIL-CANADA;NA;1519-0994;NA;NA;Based on pedagogical practices in environmental and science education that privilege the concept of place in all dimensions, we explore in this paper the work and experiences of two teacher educators, one in Brazil and one in Canada, as they visit and learn from one another's places. We wonder about unique places and how such different contexts, with different cultures, histories, and geographies, support researchers and their teacher candidates, guiding them to becoming better teachers within a context for addressing current pressing issues: social and ecological justice. While contrasting our different paths, we reflect and discuss our practices with/on empathy and place education. We discussed the power of bringing teacher education to places (and vice-versa). By contrasting places and their unique ontologies and epistemologies with empathy, we developed deeper understanding of the integral role of place in learning, and better ideas for preparing teachers to teach about their contexts.;2019;2021-02-11T04:12:09Z;2021-02-11T04:12:09Z;NA;12-38;NA;3;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AV VICTOR BARRETO 2288, CANOAS, 92010-000, BRAZIL Publisher: EDITORA UNILASALLE Type: Article;NA;NA;NA;NA;"Canada; Empathy; Brazil; Place; Teacher Education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y3ELMER4;journalArticle;2019;"Rathbone, Adam; Nazar, Hamde; Harburn, Jonathan; Todd, Adam; Husband, Andrew K.";Exploring Undergraduate Pharmacy Student Experiences of Learning Human Anatomy Using Cadaveric Specimens;AMERICAN JOURNAL OF PHARMACEUTICAL EDUCATION;NA;0002-9459;NA;NA;Objective. To gain insights into pharmacy students' experiences in learning human anatomy using qualitative interviews and thematic analysis. Methods. Participants included Master of Pharmacy students at the end of their first year or the beginning of their second year. The study used a transcendental phenomenological design. Data were collected using semi-structured individual interviews that were recorded and transcribed verbatim. Thematic analysis was used to identify structural and textural components of participants' experiences using data management software. Results. Sixteen participants were recruited and interviewed. Students described developing an understanding of anatomy that differed from their previous experiences, focusing on variation in anatomical structures between patients, and developing professional attributes such as empathy and respect. Students described haptic learning that acted as a hook on which to anchor additional learning from textbooks and lectures. Finally, students perceived the experience as valuable to their future careers as caring professionals. Conclusion. The results of this qualitative study demonstrate that the value of teaching anatomy to undergraduate students goes beyond developing a broad knowledge of anatomical structures, but also engages a deeper conceptual appreciation of professionalism, thereby inducting them into a community of professional practice.;2019;2021-02-11T04:12:09Z;2021-02-11T04:12:09Z;NA;1782-1789;NA;8;83;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1426 PRINCE STREET, ALEXANDRIA, VA 22314-2815 USA Publisher: AMER ASSOC COLL PHARMACY Type: Article;NA;NA;NA;NA;"education; anatomy; pharmacy; professionalism; qualitative interviews";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CQN8TLUM;conferencePaper;2019;"Barbieri, Francesco; Guizzo, Eric; Lucchesi, Federico; Maffei, Giovanni; del Prado Martin, Fermin Moscoso; Weyde, Tillman";Towards a Multimodal Time-Based Empathy Prediction System;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community(1);2019;2021-02-11T04:12:09Z;2021-02-11T04:12:09Z;NA;716-720;NA;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FLFI967E;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019);978-1-4503-6287-0;NA;10.1145/3313991.3314018;NA;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-02-11T04:12:10Z;2021-02-11T04:12:10Z;NA;102-108;NA;NA;NA;NA;NA;NA;International Conference on Computer and Automation Engineering;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2154-4352 Type: Proceedings Paper;<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5H7Z36JL;journalArticle;2019;"Donate Campos, Olga; Ferrete Sarria, Carmen";Living History: Possibilities of historical empathy to motivate students and achieve an effective understanding of historical events;DIDACTICA DE LAS CIENCIAS EXPERIMENTALES Y SOCIALES;NA;0214-4379;10.7203/DCES.36.12993;NA;This work investigates the possibilities of historical empathy to motivate students and achieve a learning based on a deep understanding of history, avoiding mnemonic and superficial learning. To this end, historical empathy activities were implemented in secondary classrooms. Their application is analyzed by defining levels of understanding of the historical context and by collecting data on the motivational capacity of these activities.;2019;2021-02-11T04:12:10Z;2021-02-11T04:12:10Z;NA;47-60;NA;36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Spanish;NA;NA;NA;NA;NA;NA;Place: APDO CORREOS, 22045, VALENCIA, 46071, SPAIN Publisher: UNIV VALENCIA, DEPT DIDACTICA CIENCIAS EXPERIMENTALES & SOCIALES Type: Article;NA;NA;NA;NA;"active learning; historical empathy; motivation; secondary school; significant learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
SXUISWLX;journalArticle;2019;Griffiths, David Burke;WHEN DAVID MET MICHEL;RELIGIOUS STUDIES AND THEOLOGY;NA;0829-2922;10.1558/rsth.38299;NA;I entered the Department of Religious Studies in Vancouver in the Fall of 1974. Michel was a year or two advanced and the first person to befriend me and “show me the robes.” He is a unique individual with generosity of Geist or empathy, and deep analytical skills, wide interests, lucid thinking. His books and many students are evidence of this. It has been a deep joy to be his friend through the years. He has always helped me with intellectual projects and been attentive to personal issues, and all this without a touch of pedantry or arrogance. In addition to his deep learning in Religious Studies and related topics, he has a gift for empathic listening, and a singular capacity to think on his feet and lecture with amazing lucidity.;2019;2021-02-11T04:12:10Z;2021-02-11T04:12:10Z;NA;223-225;NA;1-2, SI;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 415, THE WORKSTATION, 15 PATERNOSTER ROW, SHEFFIELD, S1 2BX, ENGLAND Publisher: EQUINOX PUBLISHING LTD Type: Article;NA;NA;NA;NA;"empathy; students; analysis; friend; Geist; joy; University of British Columbia; Vancouver";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HF6294VR;conferencePaper;2019;Vertesi, Janet;Seeing Like a Rover: Team Work and Human-robot Relations;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.;2019;2021-02-11T04:12:10Z;2021-02-11T04:12:10Z;NA;152;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"Teamwork; Human-Robot Interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6KX7F4RJ;journalArticle;2019;Sinclair, Brian Robert;Seeing through the eyes of the other: Student-centric unintended consequences of immersion, collision and expansion;KYBERNETES;NA;0368-492X;10.1108/K-02-2018-0089;NA;Purpose The purpose of this paper is to explore three diverse case studies in higher education that provide learners with innovative, disruptive and potent ways of seeing, thinking and acting. It considers pedagogical structure and phenomenological dimensions over an array of study abroad and immersive learning conditions. This paper illustrates rich and impactful ways that learning can unfold, including the unintended consequences of education that opens eyes, changes perspectives and builds empathy. Methodology This paper deploys a case study method whereby three unique programs for studio education are critically considered/analyzed. The research connects cases and delineates approaches in environmental design, whereby greater understanding and deeper knowledge can be attained. Findings This paper, through study of cases of immersive learning, reveals effective ways in which studio teaching can serve to heighten sensitivity, construct rich self/world views and render visible more profound knowledge. Such knowledge transcends disciplinary boundaries and professional borders - encompassing a fuller spectrum of awareness that includes the social, the cultural and the spiritual. Research limitations/implications This paper investigates studio-based graduate education in Environmental Design, with a particular focus on Architecture/Planning. As such, there are limitations to the applicability of discoveries and revelations. That said, the general model for teaching and learning may have value across disciplines well beyond those examined in the current research. Practical implications In an increasingly complex world, where cultures and values routinely collide, the research presents pedagogical approaches that promise to erode walls, dissolve barriers and counter fragmentation. The case studies illustrate effective ways to heighten learning beyond the ethos of traditional classes and conventional classrooms. Originality/value This paper proffers bold creative models for teaching that defy everyday strategies. It encourages moving students to places/spaces, both concrete and abstract, that challenge their assumptions, test their capabilities and permit exceptional personal/professional growth.;2019;2021-02-11T04:12:11Z;2021-02-11T04:12:11Z;NA;318-332;NA;2, SI;48;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND Publisher: EMERALD GROUP PUBLISHING LTD Type: Article;NA;NA;NA;NA;"Holism; Systems; Education; Design; Culture; Pedagogy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RXVYJ3WX;journalArticle;2018;"Palombi, Laura C.; Fike, Ashley; Chang, Clement; Stratton, Timothy P.; Koh-Knox, Cynthia";How does a drug court experience influence student pharmacists?;CURRENTS IN PHARMACY TEACHING AND LEARNING;NA;1877-1297;10.1016/j.cptl.2018.07.015;NA;"Introduction: Drug court is a highly structured, community-based criminal justice alternative to imprisonment and probation that incorporates chemical dependency treatment for offenders with a substance abuse diagnosis. Drug court provides a unique learning experience for pharmacy students. Methods: Students from Purdue University College of Pharmacy and the University of Minnesota College of Pharmacy participated in drug court and provided written reflections regarding their experiences. Analysis of reflections explored how students' life experiences might be associated with their understanding of substance use disorder, and how the drug court experience might impact students' attitudes regarding substance use disorder as well as professional and personal development. Results: Consensual qualitative analysis of student pharmacist reflections of the drug court experience led to eleven distinct themes: description of the student experience at drug court; past experiences and exposures; past perceptions and judgments; stereotype deconstruction; empathy development; development of impartiality and fair-minded approach; situational appreciation; analytical thinking; role of the pharmacist; metacognition; and science of substance use disorder. Discussion: Colleges of pharmacy wishing to provide students with an opportunity for personal and professional development focused on substance use disorder and recovery should explore experiential learning opportunities in drug court settings. Conclusions: The drug court experience allows student pharmacist learners to gain a deeper personal understanding of substance use disorder while examining their own biases. Students reported that this experience challenges them to rethink notions of “good” and “bad” and reflect on personal preconceived views about substance use disorder and morality.";2018-10;2021-02-11T04:12:11Z;2021-02-11T04:12:11Z;NA;1331-1341;NA;10;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA Publisher: ELSEVIER SCIENCE INC Type: Article;NA;NA;NA;NA;"Bias; Addiction; Consensual qualitative research; Problem-solving courts; Stigma; Substance use disorder";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GJRD7ZT3;journalArticle;2018;Garrett, Frances;Engaged pedagogy through role-play in a Buddhist studies classroom;TEACHING THEOLOGY AND RELIGION;NA;1368-4868;10.1111/teth.12462;NA;The article discusses two versions of a complex role-playing exercise in undergraduate courses on Buddhism. The pedagogical exercise demonstrated how imagination cultivated through creative writing could be used to enhance learning about history, culture, and religion. Students were also challenged to generate an understanding of religious practice that arose from both cognitive and sensory learning. The project showed that by interacting with a form of engaged pedagogy that worked with the imagination, without leaving the classroom students developed a deep care for and active engagement with communities located spatially and temporally far from home. With empathy and critical reflection, they came to see how religious meaning is constructed at a communal level through embodied action and emotional sensibility.;2018-10;2021-02-11T04:12:11Z;2021-02-11T04:12:11Z;NA;336-344;NA;4, SI;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"embodied learning; Buddhist studies; engaged pedagogy; role-playing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
89S9VMWE;journalArticle;2018;van der Walt, Johannes L.;Forgiveness education in schools as a possible measure to prevent future social and emotional pain;TYDSKRIF VIR GEESTESWETENSKAPPE;NA;0041-4751;10.17159/2224-7912/2018/v58n2a9;NA;"It was assumed for purposes of this article that many of the cases of people seeking counselling as a result of social and emotional pain due to social injustice inflicted upon them could have been prevented if they had been taught how to ask for and to extend forgiveness. (This of course does not imply that forgiveness education will remove all such social and emotional pain.) Children need to be taught how to deal with social injustices such as bullying, thereby saving them social and emotional pain later in their lives. Literature abounds with incidents that require forgiveness. The record of incidents underlines the need for incorporating forgiveness education in formal school programs. As far as could be established, forgiveness education has not yet been incorporated anywhere as a formal school subject. However, provision has been made in many education systems for its inclusion in, for instance, Citizenship Education and other formative subjects. In South Africa it could form part of the Life Orientation and Life Skills programs currently taught in schools. The purpose of this article is to provide school educators (teachers) with guidelines for teaching forgiveness education in schools, if (and when) it is incorporated in the formal curriculum. The rationale for including forgiveness education in the formal school curriculum can be explicated in terms of the social space and ethical function theory. Forgiveness and forgiveness education should occur in the social space resulting from the infliction of a social injury upon a person or group. Forgiveness education in turn should occur in the educational space provided by schools and other pedagogical settings. According to the principle of sovereignty in own sphere, schools are unique in that they embody pedagogical and didactical spaces. The school is firstly pedagogically focused upon the guiding, unfolding, nurturing, forming and developing of the learners to prepare them for a future as mature and responsible adults who understand the process of forgiveness. In this process, schools will secondly typically employ the didactical art and skill of teaching how and when to forgive. The theory also encapsulates the notion that the space in which forgiveness education is to occur should be ethical in that it displays and promotes love, patience and empathy, responsible and accountable interaction with the learners and a deeper understanding among learners as a caring community. According to this perspective, the school approaches forgiveness and forgiveness education as part of the moral development of the learners. Against the backdrop outlined above, the following is suggested as a “syllabus” or “subject curriculum” for forgiveness education: The first step of the forgiveness process to be taught is that a person should understand the context in which the apparent injustice has taken place. Children should be able to distinguish between a no-harm situation and one in which genuine injustice has been inflicted. Actions are always context-sensitive. This is the uncovering phase in which the person becomes aware of personal emotions and of the pain brought about by the actions of another. The second step is to gain insight into the function of anger, dissatisfaction and resentment. The forgiveness process begins with anger and resentment. It is important, however, to distinguish between productive, and sinful and senseless anger. Anger is productive if it helps one understand what has occurred, if one remains in charge of the anger, if the anger does not deteriorate into childish self-centredness, does not destroy the other person and if it helps one in choosing to forgive. The injured person should abjure all forms of reactive anger, that is anger that insists on revenge and retribution, and rather opt for transitional anger, i.e. forward-looking anger rooted in thoughts of well-being for both the injured and the injurer, in empathy for both the self and the other. The third step in the forgiveness process is to realise that the injustice or injury is of a permanent nature. The injury will never disappear and will never be forgotten, and therefore has to be dealt with. The fourth step is to realise that forgiveness begins with oneself and not with the injurer. To forgive is not a token of weakness; forgiveness is always granted from a position of strength because it ultimately results in healing of the self and the other. It liberates one from unhappiness and resentment and is an act of mercy to the self. It now becomes important to distinguish between two kinds of forgiveness: conditional and unconditional, and to realise that it is by far better to forgive unconditionally. The fifth step is an active decision to forgive, a step inspired by empathy for the perpetrator. To forgive is not just to forget or to pardon but rather to set the perpetrator and oneself free. An unforgiving attitude deprives one from opportunities of becoming what one could have been, namely a healed person. This is the decision-making phase in the forgiveness process. The sixth step is the workphase. The injured person invokes various cognitive and affective forgiveness strategies. One of the most important tasks in this phase is to reframe the perpetrator, in other words to attempt to view him or her in a more favourable light. Reframing ideally results in greater empathy with the injurer. The seventh step entails viewing forgiveness as a gift. It is only once one has forgiven the other that one is set free completely. The process ends with the outcome phase. The injured person begins reaping benefits from the process in the sense of beginning to grow spiritually after the dissipation of anger and the liberation from feelings of injustice. The way is now paved for a conflict- free future. The previously injured person can now become more pro-social, more morally responsible and develop a stronger sense of belonging. Enmity and alienation are replaced by a sense of peace. Empirical evidence has shown that people and groups who have successfully forgiven tend to display lower stress and anxiety levels, more positive relationships, gain more hope for the future and for life in general, and have a more positive view of the self. This is because they have successfully liberated themselves as well as the injurer from the burden of an unforgiving attitude. Only people who have been instructed in the process of forgiving during their formative years, who have been taught and as a result have learned what it means to forgive even the unforgiveable will be able to comply with the dictum of doing unto others what you would want them do unto you, able to care for their interests as if those interests were your own. Not many people are able to do what one of the mothers of the Gugulethu 7 spontaneously did when she unconditionally forgave one of the murderers of her son during the apartheid era. In doing so, she demonstrated that she had mastered the steps of the forgiveness process outlined above. Most other people require instruction in the forgiveness process to be able to emulate her example.";2018-06;2021-02-11T04:12:11Z;2021-02-11T04:12:11Z;NA;344-360;NA;2;58;NA;NA;NA;NA;NA;NA;NA;NA;NA;Afrikaans;NA;NA;NA;NA;NA;NA;Place: P. O. BOX 538, PRETORIA, 00000, SOUTH AFRICA Publisher: SUID-AFRIKAANSE AKAD VIR WETENSKAP EN KUNS, SEKRETARIS Type: Article;NA;NA;NA;NA;"citizenship education; emotional pain; forgiveness; forgiveness education; life orientation; life skills; school; schooling; social injustice; social pain";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4MC6DSS5;journalArticle;2018;Shaikh, Naaz Jahan;Poetry in Medicine;INDIAN JOURNAL OF SURGERY;NA;0972-2068;10.1007/s12262-017-1697-9;NA;We are all stressed out to read and understand our medical practice which is so vast and seems monotonous. Amidst so much tension, we can still enjoy our profession if we can narrate the sequence in a different style. Poetry is one way of such expression. Poetry is a combination of knowledge and feeling. Just as we have all read Zachary Cope's Surgery in Verse which correlates the disease with its signs in a different way that is poetry, I have tried to use poetry in my medical practice, too. We can understand as well as express better. The whole topic seems so easy once it comes in the form of poetry. Writing in a poetic form requires a thorough knowledge of the subject. Added to this are empathy and sympathy. It needs a deep sense of understanding to feel what the sufferer would feel. Imagination can take us to any part of the world and beyond however minute the structure imagined may be. This is an attempt to present poetry in medical, both while learning and during practice.;2018-06;2021-02-11T04:12:11Z;2021-02-11T04:12:11Z;NA;297;NA;3;80;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA Publisher: SPRINGER INDIA Type: Letter;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
75HUEG54;journalArticle;2018;"Salmon, Angela K.; Gangotena, Maria Victoria; Melliou, Kiriaki";Becoming Globally Competent Citizens: A Learning Journey of Two Classrooms in an Interconnected World;EARLY CHILDHOOD EDUCATION JOURNAL;NA;1082-3301;10.1007/s10643-017-0860-z;NA;Globally competent people are aware of world issues, take perspective, are engaged and know how to communicate to different people. This article portraits a story of two kindergarten classrooms, one in the United States and the other in Greece, both working with culturally diverse children and, in the case of the American classroom, English Language learners. The teachers shared philosophical foundations reflected in their practice and discourse in the classroom as they took a learning journey through Harvard Project Zero's Out of Eden Learn project. Out of Eden Learn serves as a platform to engage children from both settings in exploring their own neighborhoods, investigating contemporary global issues, and reflecting on how they as individuals fit into a broader geographical and historical context. Through meaningful hands-on experiences, the children in these two classrooms gained deep understandings of themselves and their surroundings, made personal connections and developed empathy as they heard stories of children around the world. In their learning journey, the two teachers used thinking routines to help the children slow down and observe the world around them. The experience not only helped the teachers comply with curriculum standards, but also allowed them to keep alive the children's capacity to be curious and promote parental involvement. The children developed a sense of self-understanding and self-identity as a point of reference to develop perspective and understanding of other cultures.;2018-05;2021-02-11T04:12:12Z;2021-02-11T04:12:12Z;NA;301-312;NA;3;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Culture and language; Empathy and resilience; Global competencies; Habits of mind; Slow looking; Thinking routines";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3MIJNW55;journalArticle;2018;"Spataro, Sandra E.; Bloch, Janel";“Can You Repeat That?” Teaching Active Listening in Management Education;JOURNAL OF MANAGEMENT EDUCATION;NA;1052-5629;10.1177/1052562917748696;NA;Listening is a critical communication skill and therefore an essential element of management education. Active listening surpasses passive listening or simple hearing to establish a deeper connection between speaker and listener, as the listener gives the speaker full attention via inquiry, reflection, respect, and empathy. This article offers a method and tools for teaching active listening that can be implemented in online, hybrid, or face-to-face platforms. We begin by reviewing the great demand for listening skills, in light of how little time is spent on listening instruction compared with that on speaking instruction. We then present a set of learning materials and a procedure for using them that includes both pre- and posttests, multimedia learning materials, and exercises that enhance skill development. We follow the learning plan with analyses of both quantitative and qualitative data, showing support for the suggested method. These results fit with our personal experience of consistent success with the method across student levels (graduate and undergraduate) and platforms (online and face-to-face). Finally, we conclude with a discussion of the presentation and some implications for teaching listening in management education.;2018-04;2021-02-11T04:12:12Z;2021-02-11T04:12:12Z;NA;168-198;NA;2;42;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"communication; active listening; blended courses; hybrid; listening pedagogy; management education; online education; self-assessment; television; written exercises";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PVT8SL5N;journalArticle;2018;"Hood, Donna G.; Haskins, Tara L.; Roberson, Sherrie C.";Stepping Into Their Shoes: The Ostomy Experience;JOURNAL OF NURSING EDUCATION;NA;0148-4834;10.3928/01484834-20180322-08;NA;Background: Empathetic patient care and reflective practice are linked to improved patient outcomes. Nurse educators play a key role in facilitating the development of empathy in nursing students. Research reveals an interest in reflective learning using a variety of approaches. Method: Taking cues from the previous literature, “The Ostomy Experience” was developed, implemented, and evaluated qualitatively. The Ostomy Experience included paired learning, simulated ostomy stories, skills application in a laboratory setting, personal experience of an ostomate appliance, and structured reflective journaling throughout the process. Responses were evaluated for emerging themes. Results: Data analysis revealed themes of Encountering Emotions, Becoming Aware, and Impacting Personal Practice. Conclusion: The structured reflective journaling yielded rich student learning data. Responses were evident of self-proclaimed change in attitudes, deeper understanding of the patient experience, and achievement of the learning objectives.;2018-04;2021-02-11T04:12:12Z;2021-02-11T04:12:12Z;NA;233-236;NA;4;57;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 6900 GROVE RD, THOROFARE, NJ 08086 USA Publisher: SLACK INC Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EC57472G;journalArticle;2018;"Gardner, Janet; Emory, Jan";Changing students' perceptions of the homeless: A community service learning experience;NURSE EDUCATION IN PRACTICE;NA;1471-5953;10.1016/j.nepr.2018.01.001;NA;The homeless are an underserved, local vulnerable population that can benefit from a service learning clinical practicum experience for baccalaureate prepared nursing students. Negative attitudes and disrespect among healthcare workers has been identified by the homeless as a barrier to healthcare. A service learning experience with a vulnerable population has been shown to change nursing students' attitudes and beliefs. A large university in a southern city partnered with a community based organization that provided services to the homeless to educate senior nursing students in a service learning experience. The goal of this project was to examine attitudes and perceptions of nursing students toward the homeless population before and after participation in a service learning clinical practicum experience. This case study utilized a pre and post experience questionnaire to collect qualitative data for the purposes of the project. The findings revealed students demonstrated a decrease in fear, an increase in empathy, and a deeper understanding of the advocacy role of nurses for people experiencing homelessness. Nurse educators are challenged to engage students with vulnerable populations to change the attitudes and perceptions for improvement in the overall health of communities served worldwide. Partnerships and service learning experiences can benefit all.;2018-03;2021-02-11T04:12:12Z;2021-02-11T04:12:12Z;NA;133-136;NA;NA;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Homeless; Nursing education; Service learning; Vulnerable populations";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BUIRGCD2;conferencePaper;2018;"Nasir, Md; Baucom, Brian; Narayanan, Shrikanth; Georgiou, Panayiotis";Towards an Unsupervised Entrainment Distance in Conversational Speech using Deep Neural Networks;19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING MARKETS IN MULTILINGUAL SOCIETIES;978-1-5108-7221-9;NA;10.21437/Interspeech.2018-1395;NA;Entrainment is a known adaptation mechanism that causes interaction participants to adapt or synchronize their acoustic characteristics. Understanding how interlocutors tend to adapt to each other's speaking style through entrainment involves measuring a range of acoustic features and comparing those via multiple signal comparison methods. In this work, we present a turn-level distance measure obtained in an unsupervised manner using a Deep Neural Network (DNN) model, which we call Neural Entrainment Distance (NED). This metric establishes a framework that learns an embedding from the population wide entrainment in an unlabeled training corpus. We use the framework for a set of acoustic features and validate the measure experimentally by showing its efficacy in distinguishing real conversations from fake ones created by randomly shuffling speaker turns. Moreover, we show real world evidence of the validity of the proposed measure. We find that high value of NED is associated with high ratings of emotional bond in suicide assessment interviews, which is consistent with prior studies.;2018;2021-02-11T04:12:12Z;2021-02-11T04:12:12Z;NA;3423-3427;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Int Speech Commun Assoc ISSN: 2308-457X Type: Proceedings Paper;<p>19th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2018), Hyderabad, INDIA, AUG 02-SEP 06, 2018</p>;NA;NA;NA;"behavioral analysis; conversational speech; deep neural network; embeddings; entrainment; unsupervised learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
C4344UGQ;journalArticle;2018;"Fowler, Rebecca C.; Katzman, Joanna G.; Comerci, George D., Jr.; Shelley, Brian M.; Duhigg, Daniel; Olivas, Cynthia; Arnold, Thomas; Kalishman, Summers; Monnette, Rebecca; Arora, Sanjeev";Mock ECHO: A Simulation-Based Medical Education Method;TEACHING AND LEARNING IN MEDICINE;NA;1040-1334;10.1080/10401334.2018.1442719;NA;Problem: This study was designed to develop a deeper understanding of the learning and social processes that take place during the simulation-based medical education for practicing providers as part of the Project ECHO (R) model, known as Mock ECHO training. The ECHO model is utilized to expand access to care of common and complex diseases by supporting the education of primary care providers with an interprofessional team of specialists via videoconferencing networks. Intervention: Mock ECHO trainings are conducted through a train the trainer model targeted at leaders replicating the ECHO model at their organizations. Trainers conduct simulated teleECHO clinics while participants gain skills to improve communication and self-efficacy. Context: Three focus groups, conducted between May 2015 and January 2016 with a total of 26 participants, were deductively analyzed to identify common themes related to simulation-based medical education and interdisciplinary education. Principal themes generated from the analysis included (a) the role of empathy in community development, (b) the value of training tools as guides for learning, (c) Mock ECHO design components to optimize learning, (d) the role of interdisciplinary education to build community and improve care delivery, (e) improving care integration through collaboration, and (f) development of soft skills to facilitate learning. Outcome: Mock ECHO trainings offer clinicians the freedom to learn in a noncritical environment while emphasizing real-time multidirectional feedback and encouraging knowledge and skill transfer. Lessons Learned: The success of the ECHO model depends on training interprofessional healthcare providers in behaviors needed to lead a teleECHO clinic and to collaborate in the educational process. While building a community of practice, Mock ECHO provides a safe opportunity for a diverse group of clinician experts to practice learned skills and receive feedback from coparticipants and facilitators.;2018;2021-02-11T04:12:13Z;2021-02-11T04:12:13Z;NA;423-432;NA;4;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"communication skills; curriculum; learning outcomes; mentoring; multiprofessional; phase of education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4LMDWNFN;conferencePaper;2018;"Marda, Mariana; Economou, D.; Bouki, V.";Enhancing Deeper Learning Using Empathy and Creativity in Serious Games Role-Play Simulations;PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON GAMES BASED LEARNING (ECGBL 2018);978-1-912764-00-6;NA;NA;NA;There is a shift in education towards adopting pedagogical approaches that nurture deeper learning. Educators recognise that effective and active approaches to teaching are more closely associated with deeper learning. These active approaches aim to develop higher order skills, encouraging learners' critical thinking and decision-making as well as enhancing their capacity to be agile, flexible and adaptable. Among those active approaches stand serious games, which are powerful learning environments that are seen as an emergent and engaging new way of experiment situations and construct knowledge. Serious games, in the form of role-play simulations, are scenario-based games that are used to simulate real life situations. Although serious games and simulations have been widely used in serving educational purposes, there is little evidence on their use in achieving deeper learning. In addition, there is lack of guidelines or a framework for designing serious games to support learners achieve deep learning. This paper proposes a theoretical framework, based on Bloom's educational model for Mastery Learning, which illustrates the design of instructional process adapted for serious games using empathy and creativity as an approach of designing serious games for achieving deeper learning. It describes an approach of evaluating this framework by designing a serious game focusing on raising awareness about domestic violence and abuse.;2018;2021-02-11T04:12:13Z;2021-02-11T04:12:13Z;NA;785-791;NA;NA;NA;NA;NA;NA;Proceedings of the European Conference on Games-Based Learning;NA;NA;NA;ACAD CONFERENCES LTD;CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2049-0992 Type: Proceedings Paper;<p>12th European Conference on Games Based Learning (ECGBL), SKEMA Business Sch, FRANCE, OCT 04-05, 2018</p>;NA;NA;NA;"empathy; creativity; deeper learning; formative assessment; role-play simulations; serious games";Ciussi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A99743QF;journalArticle;2018;"Alejandra Castaneda, Maira; Maye Guerra, Ananda; Ferro, Roberto";Analysis on the gamification and implementation of Leap Motion Controller in the IED Tecnico industrial de Tocancipa;INTERACTIVE TECHNOLOGY AND SMART EDUCATION;NA;1741-5659;10.1108/ITSE-12-2017-0069;NA;"Purpose This paper aims to show that the use of technological tools such as augmented reality (AR) and its integration in the education system through gamification offers better learning results when compared with traditional education. Design/methodology/approach Through the implementation of the Leap Motion Controller in English classes of the first and third grades at the I.E.D. Tecnico Industrial de Tocancipa, the authors compared the appropriation of topics in groups that received the class in the traditional way and groups that were introduced to the Leap Motion Controller as a pedagogical tool. A statistical and comparative analysis was performed on the results obtained for each group. Findings It was concluded that the use of technological tools has a positive impact in terms of educational performance and learning, giving better results than traditional education; in addition, students showed great empathy with the AR tool. On the other hand, there were limitations to just having a Leap Motion Controller device, which prevented the student experience was even more didactic; based on this, for future research, factors such as the size of the population and the amount of available resources will be taken into account to achieve better results. Originality/value The importance of this paper lies in the little research that has been done in Colombia regarding the introduction of AR and other emerging technologies as pedagogical tools, turning the present findings into a base to go deeper into the field and to prove that it is possible to introduce successfully this type of technology in the education.";2018;2021-02-11T04:12:13Z;2021-02-11T04:12:13Z;NA;155-164;NA;2, SI;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND Publisher: EMERALD GROUP PUBLISHING LTD Type: Article;NA;NA;NA;NA;"Learning; Augmented reality; Leap motion controller; Pedagogical tool";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BBBF9PKE;journalArticle;2018;"Gouthro, Patricia A.; Holloway, Susan M.";Learning to be critically reflective: exploring fiction writing and adult learning;STUDIES IN CONTINUING EDUCATION;NA;0158-037X;10.1080/0158037X.2017.1415875;NA;Many educators in adult, community and higher education contexts are concerned with fostering reflective learning amongst their students. This paper explores the concept of critical reflection and considers how engaging with fiction may be an innovative pedagogical approach to support critical learning opportunities. Drawing upon interviews with fiction writers, ways in which critical reflection may be encouraged in connection to reading and writing fiction are taken up by exploring three different thematic areas that relate to a Habermasian framework of knowledge constitutive approaches to learning. These different areas can be categorised as (a) technical-rational, (b) humanistic and (c) critical or emancipatory. The first of these considers critical reflection as a way to develop technical capacities as a creative writer. The next section takes up a humanistic framework to explore the value of individual and collective learning opportunities to enhance personal growth and critical reflection. The third area of discussion considers a deeper critical or emancipatory framework of learning through critical reflection which may lead to social change. The paper concludes by considering the value of arts-informed adult education approaches, such as those related to fiction writing, to enhance the development of critical reflection amongst adult learners.;2018;2021-02-11T04:12:14Z;2021-02-11T04:12:14Z;NA;133-148;NA;2;40;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"writing; Critical reflection; fiction; imagination";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZAX5WYWU;journalArticle;2018;"Sautner, Kerry; Medina, Gregorio";Using Storytelling to Establish Justice: How Civic Education Can Change Police Community Relations;JOURNAL OF MUSEUM EDUCATION;NA;1059-8650;10.1080/10598650.2018.1454734;NA;"Police trainings at museums have been a small but strong program within the museum field. Programs that provide youth and police the opportunity to engage one another in structured learning environments can enable those participants to share personal experiences, explore negative stereotypes, and discuss mutual perceptions of controversial topics (e.g. police brutality). These programs create a healthy foundation for both groups to address current and potential conflict in effective ways; to discuss the scope and limits of police authority; and to contribute actively toward a deeper understanding of and empathy for one another. Programs that are designed to give police and young people the opportunity to explore the past - historical and personal - provide participants with a richer perspective on societal issues today. This article will examine two programs that use storytelling to establish common ground between students and police.";2018;2021-02-11T04:12:14Z;2021-02-11T04:12:14Z;NA;114-125;NA;2;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"dialogue; students; race; Civic education; museum; police; story-sharing; storytelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LV47NRCP;journalArticle;2018;"Iyer, Radha; Carrington, Suzanne; Mercer, Louise; Selva, Gitta";Critical service-learning: promoting values orientation and enterprise skills in pre-service teacher programmes;ASIA-PACIFIC JOURNAL OF TEACHER EDUCATION;NA;1359-866X;10.1080/1359866X.2016.1210083;NA;Experiential learning pathways within education programmes such as Service-learning are a means to enrich the learning of pre-service teachers. As a pathway, Service-learning provides value-oriented learning focused on inclusion, diversity, and difference. This paper adopts critical social theory to examine how, along with these values, critical Service-learning promotes a deeper comprehension of values such as empathy, civic responsibility, social justice, and equity. Our paper also studies how, along with values, enterprise skills develop when pre-service teachers adopt a self-responsible, decision-making approach to implementing inclusion, social justice, and equity. Fifty-one data sets from interviews, questionnaires, and reflection logs with two groups of students over two semesters were examined to comprehend the unique experiences of students as they navigated through values and enterprise skills. The study concludes by reiterating the value of incorporating nontraditional ways of learning that align with the traditional pedagogical offerings for pre-service teachers.;2018;2021-02-11T04:12:14Z;2021-02-11T04:12:14Z;NA;133-147;NA;2;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"values; teacher education; Enterprise skills; pre-service teacher; service-learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3TN8JCXL;conferencePaper;2018;"Hongwei, Li; Meng, Zhang; Yuanjie, Wang; Xin, Li";A CASE STUDY OF OPEN-LOOP DESIGN THINKING CURRICULUM TO BRING UP MORE INNOVATION OUTCOMES AND FOSTER INNOVATION ABILITY;11TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND INNOVATION (ICERI2018);978-84-09-05948-5;NA;NA;NA;Serving as an important district for education and technology in Xi'an, China, Beilin district accommodates 17 universities in the area, with 30 thousand teaching and research personnel as well as a total enrollment of 173.5 thousand students. Enterprises, universities and governments in Beilin are facing with a widespread challenge in the world. Provided particular educational and industry resources, the challenge is to find a practice which is potentially valuable for teaching corporations to improve innovation products, ideas, organizational outcomes related to innovation and explore more innovation outcomes to support the development of economics. In view of this, redefining new multidisciplinary learning to stay abreast of change is in urgent need. Consequently, “design thinking” has generated significant attention in the innovation press and has been heralded as a novel problem-solving methodology well suited to the often-cited challenges different organizations face in encouraging innovation and growth. This paper deals with a project proposing to gradually change the quality and quantity of innovation outcomes in Beilin. Through the combination of online live design thinking courses provided by an American educational institution together with representatives from public agencies and private organizations, an open-loop design thinking curriculum was designed for what has been named as “ Design Talents “ Program. 12 teachers including 2 instructors from American Alliance for International Education teaching design thinking process, 2 teaching assistants (associate professor in the field of design) from China and 8 representatives with technical skills got involved in the maker practice process, assuring that students can acquire a range of capacities during their training. With ages ranging from 19 to 41, a selected group of totally 68 students and representatives from different majors in 14 universities at Beilin District, Xi'an, participated in the first phase training. The results presented, a total of 14 innovation projects were proposed from the training, 3 of which have been set out to break into the market, and 2 of which gained second prize of start-up competition. According to the investigation and deep interview after the training, not only those efficiency and productivity were realized, but also creative confidence, empathy, communication and collaboration, as well as creative behaviors have been fostered. The open-loop design thinking courses constructed an effective route for fostering innovation ability and bringing out more innovation outcomes.;2018;2021-02-11T04:12:14Z;2021-02-11T04:12:14Z;NA;5435-5440;NA;NA;NA;NA;NA;NA;ICERI Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1095 Type: Proceedings Paper;<p>11th Annual International Conference of Education, Research and Innovation (ICERI), Seville, SPAIN, NOV 12-14, 2018</p>;NA;NA;NA;"Design thinking; Innovation outcomes; Multidisciplinary course";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E6C9MYQN;conferencePaper;2018;"Paredes, S. D.; Rancan, L.; Garcia, C.; Asencio, J. M.; Garutti, I; Huerta, L.; Maranon, G.; Simon, C.; Zueco, J. A.; Vara, E.";QUALITATIVE ANALYSIS OF EXPECTATIONS OF MEDICAL STUDENTS ON THEIR PARTICIPATION IN AN INNOVATION ACTIVITY COMBINING FORMAL DEBATE WITH FLIPPED CLASSROOM;11TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND INNOVATION (ICERI2018);978-84-09-05948-5;NA;NA;NA;The traditional classroom lecture is still commonly used in undergraduate medical education. However, classroom lectures can be considered teacher-centered strategies that are conducive to passive learning on behalf of learners. For this reason, there are calls for a shift in medical education away from the traditional lecture approach and toward other instructional approaches that encourage higher-order thinking and active participation from students. One such approach that has received much attention is the flipped classroom, which allows students to independently learn foundational concepts as required homework, and then use this gained knowledge during class time to engage in critical thinking opportunities and application of knowledge. In the flipped classroom model, learners are first exposed to educational content prior to formal class sessions via readings, videos, or other electronic exercises that have been formally assigned. Given that students have already acquired knowledge through this initial phase, the subsequent classroom time is dedicated to activities that allow students to apply their knowledge to challenging problems in a setting that promotes collaboration with peers and feedback and direction from professors. In addition, using formal debate in higher education appears to be a useful tool to prepare students to face the complexity of issues affecting the modern world and to work with individuals with different viewpoints and backgrounds. In fact, using formal debate in higher education has been associated with improving communication and empathy, critical-thinking ability, literature searching, and application of evidence, teamwork, and self-directed learning. Debates allow students an opportunity not only to identify that there is an issue to resolve, but also to demonstrate a deeper analysis of the issue, including appraisal, critique, and reasoning of the issue for a potential solution. Flipped classroom together with formal debate were proposed to medical students as innovative methodologies to improve communication skills and critical thinking in response to the demand to have future biomedical professionals better trained in these areas. The general aim of the innovation experience was to encourage the active participation of students in the construction of knowledge, as well as to develop didactic strategies for their autonomous learning and to design active processes of acquisition of skills and abilities for their professional performance. Here, we report the expectations of medical students from Complutense University of Madrid on their future participation in the afore-mentioned innovation activity. Participants considered that the experience would help them gain confidence and security when it comes to presenting scientific facts, be fluent when talking in public, and expand their knowledge on some controversial topics. Regarding the negative aspects, some showed concern about being sufficiently prepared to carry out the activity with guaranteed success, taking into account that for a significant part of the students it was the first time that they participated in an innovative activity that combined both flipped learning and formal debate.;2018;2021-02-11T04:12:15Z;2021-02-11T04:12:15Z;NA;6140-6146;NA;NA;NA;NA;NA;NA;ICERI Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1095 Type: Proceedings Paper;<p>11th Annual International Conference of Education, Research and Innovation (ICERI), Seville, SPAIN, NOV 12-14, 2018</p>;NA;NA;NA;"Communication skills; Critical thinking; Flipped classroom; Formal debate; Health Sciences";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Q92QICDV;conferencePaper;2018;Fuller, Rob;Cross-functional Teams That Grok It: The Collective Empathic Understanding of Product Requirements;2018 IEEE 26TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2018);978-1-5386-7418-5;NA;10.1109/RE.2018.00063;NA;Software development has become increasingly software `product' development, without the authoritative `customer' stakeholder role that many requirements engineering processes assume exists in some form. Many progressive software product companies today are empowering cross-functional product teams to own their product to collectively understand the product context, the true product needs, and manage its on-going evolution. Some teams do this better than others and neither established requirements elicitation and validation processes nor conventional team leadership practices explain the reasons for the differences. This research inquires into how cross-functional product teams, as a collective, create and nurture a shared mental model that accurately represents the external product domain and its realities. The research also examines how teams use that collective understanding to shape development plans, internal and external communications, new team member onboarding, etc. The aim of this research is to develop substantive theory that describes how self-directed, cross-functional product development teams take an empathic-based approach to discovering, understanding, and maintaining a deep, collective understanding of the domain and true product needs. This theory will support software product development leaders in creating richer conditions for teams to grok.;2018;2021-02-11T04:12:15Z;2021-02-11T04:12:15Z;NA;466-471;NA;NA;NA;NA;NA;NA;International Requirements Engineering Conference;NA;NA;NA;IEEE COMPUTER SOC;10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; Intel Inc; Tata Consulting Services; Univ Calgary, Schulich Sch Engn; NSF; IEEE Tech Council Software Engn; Reuse Co; Iteratec; Univ Hamburg; Int Requirements Engn Board; Springer ISSN: 2332-6441 Type: Proceedings Paper";"<p>26th IEEE International Requirements Engineering Conference (RE), Banff Ctr Arts &amp; Creativ, Banff, CANADA, AUG 20-24, 2018</p>";NA;NA;NA;"knowledge management; collective sensemaking; complex adaptive systems; design science; empathy-driven development; requirements validation; tacit knowledge; team learning";Ruhe, G and Maalej, W and Amyot, D;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
PG9Q2QAA;conferencePaper;2018;"Churamani, Nikhil; Banos, Pablo; Strahl, Erik; Wermter, Stefan";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6014-6;NA;NA;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018;2021-02-11T04:12:16Z;2021-02-11T04:12:16Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2161-4393 Type: Proceedings Paper;<p>International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, BRAZIL, JUL 08-13, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GCSWD8ZG;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-02-11T04:12:16Z;2021-02-11T04:12:16Z;NA;173-193;NA;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5BE4Q7BQ;conferencePaper;2018;"Loudova, Irena; Novotna, Jana";THE CLASS TEACHER AND THE QUALITY OF PUPILS' LIFE;EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-02709-5;NA;NA;NA;The aim of the paper is to discuss a specific semi-professional group - class teachers and their professional, social and personal competences. We were focusing on the concept of interaction among participants in the educational and learning process. We set the following research questions: In which areas can a class teacher influence the quality of pupils' life? What interventions can a class teacher implement to improve the quality of pupils' life? Who can a class teacher cooperate with in this effort and in which educational processes? A qualitative research approach was chosen for the research study. The data was obtained by a deep semi-structured interview. We focused not on how individuals understand and interpret their experience as a class teacher. The analysis of the interviews shows not only what the class teachers considered to be obvious and commonplace, but also what is very challenging and struggling in their work. Class teacher is involved in a complex network of social relationships. Besides personal identity, it is just social identity, i.e. awareness of belonging to a particular social group, sharing and empathy, which are important for communication and relationships. Symmetrical communication is undoubtedly the necessary condition for effective cooperation. The opportunity to overcome stereotypes and categorizations is being created in joint actions. Teachers take care of continuity, proximity and consistency with both children and parents. They emotionally put more into relationships, and they are more interested in good mutual relations. Teachers often tend to be more sympathetic, emphasizing children's needs and harmonious interaction.;2018;2021-02-11T04:12:16Z;2021-02-11T04:12:16Z;NA;3649-3656;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>;NA;NA;NA;"Class teacher; personal identity; quality of pupils' life; social identity; symmetrical communication";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BW9SNJHH;conferencePaper;2018;"Macianskiene, Nemira; Bijeikiene, Vilma";APPLICATION OF FORMATIVE ASSESSMENT FOR THE ENHANCED FOREIGN LANGUAGE LEARNING;EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-02709-5;NA;NA;NA;"Education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking, problem-solving, global empathy, tolerance, intercultural awareness as well as team-work and collaboration. Formative assessment (FA) has emerged to be one of the efficient tools in the development of the above-mentioned competences and thus a topical issue in today's education. A number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills, student responsibility, active self-regulated learning, viewing learning as a goal rather than an outcome (Anderson, M., 2016; Brookhart, 2009; Chappuis, J., 2016; Fisher & Frey, 2014; [13]). The present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education. It aims at investigating how the application of formative assessment assists in fostering deep learning, student-centered approach, collaborative and tension free environment, active learning in small groups, enhanced dynamic exchange of feedback between teachers and students as well as self-assessment and peer-assessment both in traditional classroom as well as in virtual learning environment. It also explores the impact of formative assessment upon student lifelong learning skill development. Methodologically, the study is based on an opinion survey, reflection and class observation performed with 181 university students and 21 language teachers. The study has revealed that formative assessment adds significant value to the learning and teaching of languages. It settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality, cooperative learning, connection-building among all members of the learning and teaching process including students and teachers. It has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further in-depth research.";2018;2021-02-11T04:12:17Z;2021-02-11T04:12:17Z;NA;10084-10091;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>;NA;NA;NA;"foreign language learning and teaching; Formative assessment; student-centered approach; tertiary education";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3LZSKFAS;journalArticle;2017;"Baltatzis, Vasileios; Bintsi, Kyriaki-Margarita; Apostolidis, Georgios K.; Hadjileontiadis, Leontios J.";Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-017-17562-0;NA;"Bullying is an everlasting phenomenon and the first, yet difficult, step towards the solution is its detection. Conventional approaches for bullying incidence identification include questionnaires, conversations and psychological tests. Here, unlike the conventional approaches, two experiments are proposed that involve visual stimuli with cases of bullying- and non-bullying-related ones, set within a 2D (simple video preview) and a Virtual Reality (VR) (immersive video preview) context. In both experimental settings, brain activity is recorded using high density (HD) (256 channels) electroencephalogram (EEG), and analyzed to identify the bullying stimuli type (bullying/non-bullying) and context (2D/VR). The proposed classification analysis uses a convolutional neural network (CNN), applying deep learning on the oscillatory modes (OCMs) embedded within the raw HD EEG data. The extraction of OCMs from the HD EEG data is achieved with swarm decomposition (SWD), which efficiently accounts for the non-stationarity and noise contamination of the raw HD EEG data. Experimental results from 17 subjects indicate that the new SWD/CNN approach achieves high discrimination accuracy (AUC = 0.987 between bullying/non-bullying stimuli type; AUC = 0.975, between bullying/non-bullying stimuli type and 2D/VR context), paving the way for better understanding of how brain's responses could act as indicators of bullying experience within immersive environments.";2017-12-11;2021-02-11T04:12:17Z;2021-02-11T04:12:17Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LXDGJ6AR;journalArticle;2017;"Tabari, Fariba; Khaghanizade, Morteza; Dehghan-Nayeri, Nahid; Najafi-Mehri, Soheil";Mental Health and Old Age: A Qualitative Study in Iranian Population;JOURNAL OF CLINICAL AND DIAGNOSTIC RESEARCH;NA;2249-782X;10.7860/JCDR/2017/27303.10843;NA;Introduction: Health, which usually declines with age, is one of the determinants of quality of life. Mental health disorder is one of the most common health-threatening problems of older age. Aim: The present qualitative study was conducted with the aim to identify factors that affect the mental health of elderly population. Materials and Methods: This study was a qualitative study with content analysis approach, conducted on the elderly Iranians in Tehran. Purposive sampling method was used to select 15 elderly Iranians. Semi-structured and in-depth interviews were carried out with 15 elderly Iranians in the parks and homes in 2015. To analyze the data, the content of interviews was typed and entered into MAXQDA software. This software was also used to code the data. The interview began with a main question about their experiences of everyday life, and then, exploratory questions to encourage the participants and access to deeper information were required. Results: Two themes of “interaction” and “worthiness”, 5 main categories (communication/relationship, empathy/compassion, entertainment/amusement, support and respect), and 15 subcategories (interpersonal communication, communication with others, communication with God, talking to people, being consulted, being employed, studying and learning, using the media, going to park, family support, social support, social respect, family respect, respect for personal space, and respect for beliefs) were extracted from the data. Conclusion: The results of this study encourage health-care providers to identify the factors that influence the sense of worthiness in elderly by keeping continuous contact with them and taking advantage of the unique opportunity they have to interact with them and influence their belief. By designing educational programs, mental disorders can be prevented, that this population may develop.;2017-11;2021-02-11T04:12:17Z;2021-02-11T04:12:17Z;NA;VC5-VC8;NA;11;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 71 JAIN COLONY, VEER NAGAR, DELHI, 110 007, INDIA Publisher: PREMCHAND SHANTIDEVI RESEARCH FOUNDATION Type: Article;NA;NA;NA;NA;"Content analysis; Elderly; Mental hygiene";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TUVFLPJ7;journalArticle;2017;"Scholten, Mark R.; Kelders, Saskia M.; Van Gemert-Pijnen, Julia E. W. C.";Self-Guided Web-Based Interventions: Scoping Review on User Needs and the Potential of Embodied Conversational Agents to Address Them;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/jmir.7351;NA;Background: Web-based mental health interventions have evolved from innovative prototypes to evidence-based and clinically applied solutions for mental diseases such as depression and anxiety. Open-access, self-guided types of these solutions hold the promise of reaching and treating a large population at a reasonable cost. However, a considerable factor that currently hinders the effectiveness of these self-guided Web-based interventions is the high level of nonadherence. The absence of a human caregiver apparently has a negative effect on user adherence. It is unknown to what extent this human support can be handed over to the technology of the intervention to mitigate this negative effect. Objective: The first objective of this paper was to explore what is known in literature about what support a user needs to stay motivated and engaged in an electronic health (eHealth) intervention that requires repeated use. The second objective was to explore the current potential of embodied conversational agents (ECAs) to provide this support. Methods: This study reviews and interprets the available literature on (1) support within eHealth interventions that require repeated use and (2) the potential of ECAs by means of a scoping review. The rationale for choosing a scoping review is that the subject is broad, diverse, and largely unexplored. Themes for (1) and (2) were proposed based on grounded theory and mapped on each other to find relationships. Results: The results of the first part of this study suggest the presence of user needs that largely remain implicit and unaddressed. These support needs can be categorized as task-related support and emotion-related support. The results of the second part of this study suggest that ECAs are capable of engaging and motivating users of information technology applications in the domains of learning and behavioral change. Longitudinal studies must be conducted to determine under what circumstances ECAs can create and maintain a productive user relationship. Mapping the user needs on the ECAs' capabilities suggests that different kinds of ECAs may provide different solutions for improving the adherence levels. Conclusions: Autonomous ECAs that do not respond to a user's expressed emotion in real time but take on empathic roles may be sufficient to motivate users to some extent. It is unclear whether those types of ECAs are competent enough and create sufficient believability among users to address the user's deeper needs for support and empathy. Responsive ECAs may offer a better solution. However, at present, most of these ECAs have difficulties to assess a user's emotional state in real time during an open dialogue. By conducting future research with relationship theory-based ECAs, the added value of ECAs toward user needs can be better understood.;2017-11;2021-02-11T04:12:18Z;2021-02-11T04:12:18Z;NA;NA;NA;11;19;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Review;NA;NA;NA;NA;"review; eHealth; human computer interaction; adherence; clinical psychology; embodied conversational agent; health behavior; intelligent tutoring system; ITS; Web-based intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IQPDYTB5;journalArticle;2017;"Rouzrokh, Mahsa; Muldoon, Meghan; Torabian, Pooneh; Mair, Heather";The memory-work sessions: Exploring critical pedagogy in tourism;JOURNAL OF HOSPITALITY LEISURE SPORT & TOURISM EDUCATION;NA;1473-8376;10.1016/j.jhlste.2017.08.006;NA;The paper reports on a pedagogical `experiment' undertaken by scholars aiming to critically reflect on tourism and tourism studies. Memory-work, a feminist, qualitative methodology, was chosen because it centres critical tourism inquiry within the context of sharing meaningful, personal experiences. The team met regularly to engage in supportive, critical dialogue about their memories and to spark critical reflections about tourism more broadly. Four substantive themes (embodied remembering, gendered bodies, racialized bodies, and embodying the gaze) were developed from collective analyses of initial discussions. A deeper reflection on the potential of this approach for engendering critical tourism pedagogy was also undertaken to explore its potential as critical tourism pedagogy. Five pedagogical themes (building safe spaces and developing trust, creating empathy, engaging tourism literature in `real life', opening doors for ongoing reflection, and decentring power and knowledge) were identified. The paper concludes with recommendations for adapting this approach to their own tourism teaching and learning endeavours.;2017-11;2021-02-11T04:12:18Z;2021-02-11T04:12:18Z;NA;163-173;NA;B, SI;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Critical tourism pedagogy; Embodiment; Memory-work; Transformational learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ETALU6QD;journalArticle;2017;"Saunders, Mitzi M.; Kowalski, Sonya L.; Weathers, Suzanne";Students' Perceptions of a Poem to Evaluate Learning: A Qualitative Study;JOURNAL OF NURSING EDUCATION;NA;0148-4834;10.3928/01484834-20170918-09;NA;Background: How best to use poetry in nursing education remains uncertain. This study explored students' perceptions of incorporating a poem into a final examination to evaluate learning in an advanced physical assessment course. Method: Qualitative design and method were used to collect and analyze data retrieved from private interviews with seven graduate nursing students. Results: The themes were Being There, Think More, and Feeling Rushed. Students recommended the strategy as a measure of learning because it simulated a real patient encounter and made them think at a deeper level than other traditional approaches used to evaluating learning. Conclusion: Poetry might engage nursing students in thinking critically and compassionately and be closer in touch with real-time nursing care than other traditionally used methods to evaluate nursing practice. More research is needed to validate poetry's best fit in nursing curricula.;2017-10;2021-02-11T04:12:18Z;2021-02-11T04:12:18Z;NA;628-632;NA;10;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 6900 GROVE RD, THOROFARE, NJ 08086 USA Publisher: SLACK INC Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CQD94JEH;journalArticle;2017;"Toivonen, Asta Kristiina; Lindblom-Ylanne, Sari; Louhiala, Pekka; Pyorala, Eeva";Medical students' reflections on emotions concerning breaking bad news;PATIENT EDUCATION AND COUNSELING;NA;0738-3991;10.1016/j.pec.2017.05.036;NA;Objectives: To gain a deeper understanding of fourth year medical students' reflections on emotions in the context of breaking bad news (BBN). Methods: During the years 2010-2012, students reflected on their emotions concerning BBN in a learning assignment at the end of the communications skills course. The students were asked to write a description of how they felt about a BBN case. The reflections were analysed using qualitative content analysis. Results: 351 students agreed to participate in the study. We recognized ten categories in students' reflections namely empathy, insecurity, anxiety, sadness, ambivalence, guilt, hope, frustration, gratefulness and emotional detachment. Most students expressed empathy, but there was a clear tension between feeling empathy and retaining professional distance by emotional detachment. Conclusions: Students experience strong and perplexing emotions during their studies, especially in challenging situations. A deeper understanding of students' emotions is valuable for supporting students' professional development and coping in their work in the future. Practice implications: Medical students need opportunities to reflect on emotional experiences during their education to find strategies for coping with them. Emotions should be actively discussed in studies where the issues of BBN are addressed. Teachers need education in attending emotional issues constructively. (C) 2017 Elsevier B.V. All rights reserved.;2017-10;2021-02-11T04:12:19Z;2021-02-11T04:12:19Z;NA;1903-1909;NA;10;100;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND Publisher: ELSEVIER IRELAND LTD Type: Article;NA;NA;NA;NA;"Emotions; Empathy; Reflection; Content analysis; Breaking bad news; Medical students; Undergraduate medical education";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AJZPVIVW;journalArticle;2017;"Hunukumbure, Agra Dilshani; Smith, Susan F.; Das, Saroj";Holistic feedback approach with video and peer discussion under teacher supervision;BMC MEDICAL EDUCATION;NA;1472-6920;10.1186/s12909-017-1017-x;NA;Background: High quality feedback is vital to learning in medical education but many students and teachers have expressed dissatisfaction on current feedback practices. Lack of teachers' insight into students' feedback requirements may be a key, which might be addressed by giving control to the students with student led feedback practices. The conceptual framework was built on three dimensions of learning theory by Illeris and Vygotsky's zone of proximal development and scaffolding. We introduced a feedback session with self-reflection and peer feedback in the form of open discussion on video-recorded student performances under teacher's guidance. The aims of this qualitative study were to explore students' perception on this holistic feedback approach and to investigate ways of maximising effective feedback and learning. Methods: Semi-structured interviews were used to gather data which were evaluated using a thematic analytical approach. The participants were third year medical students of Imperial College London on clinical placements at Hillingdon Hospital. Results: Video based self-reflection helped some students to identify mistakes in communication and technical skills of which they were unaware prior to the session. Those who were new to video feedback found their expected self-image different to that of their actual image on video, leading to some distress. However many also identified that mistakes were not unique to themselves through peer videos and learnt from both model performances and from each other's mistakes. Balancing honest feedback with empathy was a challenge for many during peer discussion. The teacher played a vital role in making the session a success by providing guidance and a supportive environment. Conclusions: This study has demonstrated many potential benefits of this holistic feedback approach with video based self-reflection and peer discussion with students engaging at a deeper cognitive level than the standard descriptive feedback.;2017-09-29;2021-02-11T04:12:19Z;2021-02-11T04:12:19Z;NA;NA;NA;NA;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND Publisher: BIOMED CENTRAL LTD Type: Article;NA;NA;NA;NA;"Feedback; Holistic; Peer discussion; Self-reflection; Teacher guidance; Undergraduate; Video";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XK7EGFLK;journalArticle;2017;"Corr, M.; Roulston, G.; King, N.; Dornan, T.; Blease, C.; Gormley, G. J.";Living with “melanoma' ... for a day: a phenomenological analysis of medical students' simulated experiences;BRITISH JOURNAL OF DERMATOLOGY;NA;0007-0963;10.1111/bjd.15402;NA;"Background Despite the rising incidence of melanoma, medical students have progressively fewer opportunities to encounter patients with this important condition. Curricula tend to attach the greatest value to intellectual forms of learning. However, compared with intellectual learning, experiential learning affords students deep insights about a condition. Doctors who experience ill health are more empathic towards patients. However, opportunities to learn about cancer experientially are limited. Temporary transfer tattoos can simulate the ill health associated with melanoma. We reasoned that if doctors who have been sick are more empathic temporarily `having' melanoma might have a similar effect. Objectives To explore the impact of wearing a melanoma tattoo on medical students' understanding of patienthood and attitudes towards patients with melanoma. Methods Ten fourth-year medical students were recruited to a simulation. They wore a melanoma tattoo for 24h and listened to a patient's account of receiving their diagnosis. Data were captured using audio diaries and face-to-face interviews, transcribed and analysed phenomenologically using the template analysis method. Results There were four themes: (i) melanoma simulation: opening up new experiences; (ii) drawing upon past experiences; (iii) a transformative introduction to patienthood; (iv) doctors in the making: seeing cancer patients in a new light. Conclusions By means of a novel simulation, medical students were introduced to lived experiences of having a melanoma. Such an inexpensive simulation can prompt students to reflect critically on the empathetic care of such patients in the future.";2017-09;2021-02-11T04:12:19Z;2021-02-11T04:12:19Z;NA;771-778;NA;3;177;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NF4JJP5J;journalArticle;2017;Windahl, Charlotta;Market sense-making in design practice: exploring curiosity, creativity and courage;JOURNAL OF MARKETING MANAGEMENT;NA;0267-257X;10.1080/0267257X.2016.1272306;NA;"This paper introduces the three interrelated design catalysts of curiosity, creativity and courage, and explores how they actuate market sense-making activities in design practice. Drawing on the interplay between action and meaning dimensions in design practice and service-marketing theory, it specifically investigates when desirability, rather than feasibility or viability, is the locus of innovation activities. Thus, the following three aspects of market sense-making in design practice are identified: (a) curiosity catalyses empathy and the deep understanding of markets, which are seen as socially constructed of individual (value-in-use) and connected (value-in-context) experiences; (b) creativity catalyses logical leaps' with regard to understanding the opportunities for creating future markets; and (c) courage catalyses learning through iterations, which reduce cognitive bias with regard to market assumptions, thereby reducing cognitive bias in both curiosity- and creativity-driven activities.";2017-03;2021-02-11T04:12:19Z;2021-02-11T04:12:19Z;NA;280-291;NA;3-4;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Editorial Material;NA;NA;NA;NA;"creativity; courage; curiosity; Design practice; market innovation; SDL; service theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FES2FHSH;conferencePaper;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17);978-1-4503-4655-9;NA;10.1145/3025453.3025496;NA;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-02-11T04:12:20Z;2021-02-11T04:12:20Z;NA;3506-3510;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>ACM SIGCHI Conference on Human Factors in Computing Systems (CHI), Denver, CO, MAY 06-11, 2017</p>;NA;NA;NA;"social media; deep learning; Chatbot; customer service";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CLD5GVRI;conferencePaper;2017;"Lee, Chien-Sing; Wong, K. Daniel";An Entrepreneurial Narrative Media-Model Framework to Knowledge Building and Open Co-Design for Smart Cities;2017 COMPUTING CONFERENCE;978-1-5090-5443-5;NA;NA;NA;"Addressing wicked design problems which require eclectic methodologies, it is important to investigate how to create better links between theory and practice and therefore develop greater appreciation for disciplinary concepts and methodologies; develop deeper understanding of design, design thinking, object-orientation and agile methodology and how these can complement each other in systems design and development. This study situates learning within the IEEE Smart Cities context, and Garud et. al's entrepreneurial narrative framework scoped within Gaynor's 21st century skillsets for technology, engineering management and society. The focus is on the systems and human factors aspects of computing, scaffolded by the SDLC, design thinking's empathy/agile methodology's user stories to improve understanding of information systems, and development of opportunities.";2017;2021-02-11T04:12:20Z;2021-02-11T04:12:20Z;NA;1169-1175;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Sci & Information Org; IEEE; Nat Res Type: Proceedings Paper";<p>Computing Conference, United Kingdon, London, ENGLAND, JUL 18-20, 2017</p>;NA;NA;NA;"entrepreneurial; knowledge building; media model; open co-design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8GXS9R52;journalArticle;2017;"Davies, Philip H. J.; Gustafson, Kristian";Weighing the evidence: the BCISS Iraq HUMINT Analytic Matrix Exercise;IN℡LIGENCE AND NATIONAL SECURITY;NA;0268-4527;10.1080/02684527.2017.1328860;NA;This article examines the Brunel Iraq HUMINT Matrix exercise. The purpose of this approach to intelligence pedagogy is to get participants to think through and work out analytic methods, issues, and potential solutions from first principles and for themselves. Our strategy is to try and fuse training and education learning outcomes, so that students emerge with a technical competence in analytic methods, underpinned by a deeper understanding of the foundations and internal logic shaping those methods. The Iraq Matrix exercise seeks to unpack and examine the nuts and bolts of source evaluation, and to test alternative hypotheses with particular attention to the relationship between the quality of various sources and, the weight of judgements they can or cannot sustain. The ultimate goal is to encourage what is currently fashionably referred to as `reflexive practice', whereby the practitioner reflects critically and self-critically upon how their task works and how they do it, then uses those insights to improve their workplace performance. But not all of our teaching is directed towards practitioners. For those whose aims are scholarly and academic, the aim is to give observers a more visceral understanding of the challenges of the intelligence task they intended to study. Here the intended reflexive practice goal is to encourage an empathy with the workaday challenges facing those in the business of intelligence analysis, and to discourage the observer's temptation to make facile and simplistic judgements about processes or events.;2017;2021-02-11T04:12:21Z;2021-02-11T04:12:21Z;NA;905-919;NA;7, SI;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XMQI34B2;journalArticle;2017;Verjee, Mohamud A.;REFLECTING ON THE HUMANITIES, RELATED TO EXPERIENCES OF ILLNESS, WITH A CREATIVE EXPLORATION OF METAPHORIC SPACES;PSYCHIATRIA DANUBINA;NA;0353-5053;NA;NA;Every patient has a story to tell, and every experienced physician has a bank of stories to recall. A patient's visit is not chance but a search for a cure, amelioration of state, advice, guidance, a prescription, or for seeking reassurance, comfort, and in some circumstances, permission to “be well”. From the simplest tale to the most complex, narratives abound. Sometimes, the most intimate information shared with the physician confidante, go dark and deep, with a yearning to “tell all” after a period of suppression. Successful communication and rapport also depends on the carer's response, the degree of concentration, listening skills, body language, eye contact engagement, the patient relationship and empathy. How do we as physicians cope with emotion on both sides when it comes to listening to a narrated story, keeping matters in perspective, recognizing the effects of depression, grieving, anger, forgiveness, or the strength of the patient to be able to face their demons when cowardly acts of abuse have been committed. The professionalism of doctors should always be at the highest level, but individuals vary in their responses. A price may be paid with arising stress, unsolved patient problems, an increase in new ones, and the general challenge of coping. Time may not be the only enemy with modern day medical practice. Does narrative medicine have a place in reducing this dissonance, and will learning to share stories, as well as being a good listener, limit adverse outcomes?;2017;2021-02-11T04:12:21Z;2021-02-11T04:12:21Z;NA;S556-S558;NA;3;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VLASKA 69, HR-10000 ZAGREB, CROATIA Publisher: MEDICINSKA NAKLADA Type: Article; Proceedings Paper";<p>6th Biennial Cambridge International Conference on Mental Health, Univ Cambridge, Clare Coll, Cambridge, ENGLAND, SEP 20-22, 2017</p>;NA;NA;NA;"communication; empathy; body language; professionalism; carer's response; concentration; doctors; eye contact engagement; listening skills; narrative medicine; rapport; the patient relationship";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UXY7S6YK;conferencePaper;2017;Kristanti, Fransisca;Developing Competence, Conscience, and Compassion through Reflective Pedagogy;PROCEEDINGS OF THE FIFTH INTERNATIONAL SEMINAR ON ENGLISH LANGUAGE AND TEACHING (ISELT 2017);978-94-6252-391-3;NA;NA;NA;This paper outlines how Reflective Pedagogy contributes to the development of students' holistic learning by developing their competence, conscience, and compassion in Speaking class. The application of Reflective Pedagogy, which sets out a learning cycle from context understanding to evaluation, and the employment of student-focused topics allow a more holistic learning process to take place. Giving students more opportunity to experience a full cycle of learning from planning to performance results in a deeper level of learning. Furthermore, trusting students with the responsibility in the conduct of their learning course, provided with appropriate approach and structured monitoring, leads to a more thorough development. Utilizing self-evaluation and peer-evaluation rubrics is a way to sharpen the students' cognitive awareness, whereas self-reflection and peer-feedback forms enable them to develop their conscience by exercising their empathy towards themselves and others as well as to reinforce their compassion by accepting and giving assistance to their peers. Furthermore, a recorded speech performance enables students to reflect and evaluate themselves and become essential to raise the students' awareness of their strengths and needs. This collaboration allows them to develop their competence, conscience, and compassion in their own pace.;2017;2021-02-11T04:12:21Z;2021-02-11T04:12:21Z;NA;121-125;NA;NA;110;NA;NA;NA;Advances in Social Science Education and Humanities Research;NA;NA;NA;ATLANTIS PRESS;29 AVENUE LAVMIERE, PARIS, 75019, FRANCE;English;NA;NA;NA;NA;NA;NA;ISSN: 2352-5398 Type: Proceedings Paper;"<p>5th International Seminar on English Language and Teaching (ISELT), Univ Negeri Padang, Fac Languages &amp; Arts, English Dept, Padang., INDONESIA, MAY 09-10, 2017</p>";NA;NA;NA;"compassion; competence; conscience; Reflective pedagogy";Rozimela, Y and Fatimah, S and Amri, Z and Anwar, D and Refnaldi and Ardi, H and Arianto, MA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TCYDH8AA;journalArticle;2017;[Anonymous];ASCH 2017 Annual Conference Plenary Session Abstracts;AMERICAN JOURNAL OF CLINICAL HYPNOSIS;NA;0002-9157;10.1080/00029157.2017.1282739;NA;Attunement can be considered the deepest level of rapport, a foundation of empathy. We will learn how to attune to affect, behavior, cognition, attitude, perception, and relationship patterns-even how to attune to the precociousness associations that drives behavior. A precursor to every intervention, attunement will be described from the perspective of hypnosis, psychotherapy, and social psychology. Clinical applications will be demonstrated and discussed.;2017;2021-02-11T04:12:22Z;2021-02-11T04:12:22Z;NA;445-447;NA;4;59;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4HIP3XI6;journalArticle;2017;"Wadsworth, Pamela; Colorafi, Karen; Shearer, Nelma";Using Narratives to Enhance Nursing Practice and Leadership: What Makes a Good Nurse?;TEACHING AND LEARNING IN NURSING;NA;1557-3087;10.1016/j.teln.2016.08.001;NA;"Storytelling is an ancient practice that has functioned to maintain history, deepen empathy and understanding, and empower groups and individuals. Unfortunately, nurses are not encouraged to share their stories of contributions to patient care. In this article, 3 nurses share stories about learning to be good nurses, even while going against long-held nursing ideals. The authors argue that narratives can lead to a deeper understanding of nursing as a practice and discipline. The authors also contend that narratives facilitate the empowerment in nurses and patients using narratives; nurses recognize their power and facilitate their patients' recognition of power. (C) 2017 Organization for Associate Degree Nursing. Published by Elsevier Inc. All rights reserved.";2017-01;2021-02-11T04:12:22Z;2021-02-11T04:12:22Z;NA;28-31;NA;1;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA Publisher: ELSEVIER SCIENCE INC Type: Article;NA;NA;NA;NA;"Empowerment; Good nurse; Group oppression; Leadership; Narratives";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2PL4UAH5;journalArticle;2017;Su, Ying-Fen;The Way of Empathy in Moderation: Philosophical Dimension of “Expressing Passions”;UNIVERSITAS-MONTHLY REVIEW OF PHILOSOPHY AND CULTURE;NA;1015-8383;NA;NA;"With the affirmation that “passions” is the nature of man; however, if the passions are not expressed appropriately, they can also be harmful to man as well. How to express passions appropriately is an issue worthy of discussion. This essay begins with the discussion and the analysis on why a person can be disturbed and hurt by passions when expressing them. Firstly, the essay is to clarify the word root of “passion”, including the relations among nature, passion, and desire as well as the principle of expressing passions by enumerating “what one dislikes/” and “refraining from doing it unto others/” as examples. Secondly, the essay is to talk about “the way of empathy in moderation” when expressing passions, a way which includes sincerity (be loyal to oneself) and faithfulness (be compassionate to others). Thirdly, the essay proposes the importance of “habit” in expressing passions: “knowing” and “thinking” is indispensible to one's acquisition of “habit” in learning “the way of empathy in moderation”; one has to “assimilate oneself into nature” and cultivates the habit of expressing “the way of empathy in moderation”. Finally, this essay is to affirm the viewpoint presented in “Nature Emerges from Life” in the Guodian Chu Slips, “One must temper passion with reason before expressing or receiving it, and then it should be seasoned with ritual.” This viewpoint provides us with a model of “passion to be stressed and to be well expressed” and with a humanistic value on the humanistic way of “passion deep and ritual clear”.";2017-01;2021-02-11T04:12:22Z;2021-02-11T04:12:22Z;NA;71-86;NA;1;44;NA;NA;NA;NA;NA;NA;NA;NA;NA;Chinese;NA;NA;NA;NA;NA;NA;Place: 106 NO 96 LE-LI RD, DA AN DISTRICT, TAIPEI, 10668, TAIWAN Publisher: UNIVERSITAS Type: Article;NA;NA;NA;NA;"Expressing Passions; Faithfulness (Be Compassionate to Others); Habit; Sincerity (Be Loyal to Oneself); The Way of Empathy in Moderation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
H3XAUMMQ;journalArticle;2016;"Kelley, Tanya M.; Johnston, Erik W.";Immersive Policy Learning: An Interactive Course Experiment;JOURNAL OF PUBLIC AFFAIRS EDUCATION;NA;1523-6803;10.1080/15236803.2016.12002232;NA;An in-course experiment provided undergraduate public policy students with tangible experience in dealing with unfair, discriminatory, intrusive, and arbitrary policies and practices similar to those that legally exist in government. Students were subjected to in-course policies that gave preferential status and enhanced opportunities to some classmates while others were punished or handicapped. Each of the seemingly arbitrary conditions has parallels in U.S. legal, economic, and social systems. The experiment was designed to enhance student learning through an immersion in a simulated policy environment and to offer a personalized experience of dealing with unjust and arbitrary policies. Experimental and control group responses were analyzed with a grounded research approach. The authors found that the immersive environment led to deeper knowledge of the policy situation and an understanding of how to get involved in a policy area to effect change. This study illustrates potential applications for active learning, simulated empathy, and student empowerment.;2016;2021-02-11T04:12:22Z;2021-02-11T04:12:22Z;NA;125-140;NA;1;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1029 VERMONT AVE, NW, STE 1100, WASHINGTON, DC 20005 USA Publisher: NATL ASSOC SCHOOLS PUBLIC AFFAIRS & ADM-NASPAA Type: Article;NA;NA;NA;NA;"learning environment; participatory experiment; Policy learning; student empowerment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3ZQNVUCF;journalArticle;2016;"Bartal, Inbal Ben-Ami; Shan, Haozhe; Molasky, Nora M. R.; Murray, Teresa M.; Williams, Jasper Z.; Decety, Jean; Mason, Peggy";Anxiolytic Treatment Impairs Helping Behavior in Rats;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2016.00850;NA;"Despite decades of research with humans, the biological mechanisms that motivate an individual to help others remain poorly understood. In order to investigate the roots of pro-sociality in mammals, we established the helping behavior test, a paradigm in which rats are faced with a conspecific trapped in a restrainer that can only be opened from the outside. Over the course of repeated test sessions, rats exposed to a trapped cagemate learn to open the door to the restrainer, thereby helping the trapped rat to escape (Ben-Ami Bartal et al., 2011). The discovery of this natural behavior provides a unique opportunity to probe the motivation of rodent helping behavior, leading to a deeper understanding of biological influences on human pro-sociality. To determine if an affective response motivates door-opening, rats receiving midazolam, a benzodiazepine anxiolytic, were tested in the helping behavior test. Midazolam-treated rats showed less helping behavior than saline-treated rats or rats receiving no injection. Yet, midazolam-treated rats opened a restrainer containing chocolate, highlighting the socially specific effects of the anxiolytic. To determine if midazolam interferes with helping through a sympatholytic effect, the peripherally restricted beta-adrenergic receptor antagonist nadolol was administered; nadolol did not interfere with helping. The corticosterone response of rats exposed to a trapped cagemate was measured and compared to the rats' subsequent helping behavior. Rats with the greatest corticosterone responses showed the least helping behavior and those with the smallest responses showed the most consistent helping at the shortest latency. These results are discussed in terms of their implications for the interaction between stress and pro-social behavior. Finally, we observed that door-opening appeared to be reinforcing. A novel analytical tool was designed to interrogate the pattern of door-opening for signs that a rat's behavior on one session influenced his behavior on the next session. Results suggest that helping a trapped rat has a greater motivational value than does chocolate. In sum, this series of experiments clearly demonstrates the fundamental role of affect in motivating pro-social behavior in rodents and the need for a helper to resonate with the affect of a victim.";2016-06-08;2021-02-11T04:12:23Z;2021-02-11T04:12:23Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; altruism; emotional contagion; helping; midazolam; rodent";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DPPYBZ62;journalArticle;2016;"Lee, Winona K.; Harris, Chessa C. D.; Mortensen, Kawika A.; Long, Linsey M.; Sugimoto-Matsuda, Jeanelle";Enhancing student perspectives of humanism in medicine: reflections from the Kalaupapa service learning project;BMC MEDICAL EDUCATION;NA;1472-6920;10.1186/s12909-016-0664-7;NA;Background: Service learning is endorsed by the Liaison Committee on Medical Education (LCME) as an integral part of U.S. medical school curricula for future physicians. Service learning has been shown to help physicians in training rediscover the altruistic reasons for pursuing medicine and has the potential to enhance students' perspectives of humanism in medicine. The Kalaupapa service learning project is a unique collaboration between disadvantaged post-baccalaureate students with an underserved rural community. This study was conducted to determine whether the Kalaupapa service learning curricula enhanced student perspectives of humanism in medicine at an early stage of their medical training. Method: Program participants between 2008 and 2014 (n = 41) completed written reflections following the conclusion of the service learning project. Four prompts guided student responses. Reflections were thematically analyzed. Once all essays were read, team members compared their findings to condense or expand themes and assess levels of agreement. Results: Emerging themes of resilience and unity were prominent throughout the student reflections. Students expressed respect and empathy for the patients' struggles and strengths, as well as those of their peers. The experience also reinforced students' commitment to service, particularly to populations in rural and underserved communities. Students also gained a deeper understanding of the patient experience and also of themselves as future physicians. Conclusion: To identify and address underserved and rural patients' health care needs, training programs must prepare an altruistic health care workforce that embraces the humanistic element of medicine. The Kalaupapa service learning project is a potential curricular model that can be used to enhance students' awareness and perspectives of humanism in medicine.;2016-05-09;2021-02-11T04:12:23Z;2021-02-11T04:12:23Z;NA;NA;NA;NA;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND Publisher: BIOMED CENTRAL LTD Type: Article;NA;NA;NA;NA;"Diversity; Service-learning; Healthcare workforce; Humanism; Native Hawaiian";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JTAKPLGT;journalArticle;2016;"Tseng, Fen-Yu; Shieh, Jeng-Yi; Kao, Tze-Wah; Wu, Chau-Chung; Chu, Tzong-Shinn; Chen, Yen-Yuan";Developing and Evaluating Medical Humanities Problem-Based Learning Classes Facilitated by the Teaching Assistants Majored in the Liberal Arts A Longitudinal Crossover Study;MEDICINE;NA;0025-7974;10.1097/MD.0000000000002765;NA;"Although medical humanities courses taught by teachers from nonmedical backgrounds are not unusual now, few studies have compared the outcome of medical humanities courses facilitated by physicians to that by teaching assistants majored in the liberal arts. The objectives of this study were to (1) analyze the satisfaction of medical students with medical humanities problem-based learning (PBL) classes facilitated by nonmedical teaching assistants (TAF) majored in the liberal arts, and those facilitated by the attending physicians (APF) and (2) examine the satisfaction of medical students with clinical medicine-related and clinical medicine-unrelated medical humanities PBL classes. A total of 123 medical students, randomly assigned to 16 groups, participated in this study. There were 16 classes in the course: 8 of them were TAF classes; and the others were APF classes. Each week, each group rotated from 1 subject of the 16 subjects of PBL to another subject. All of the 16 groups went through all the 16 subjects in the 2013 spring semester. We examined the medical students' satisfaction with each class, based on a rating score collected after each class was completed, using a scale from 0 (the lowest satisfaction) to 100 (the highest satisfaction). We also conducted multivariate linear regression analysis to examine the association between the independent variables and the students' satisfaction. Medical students were more satisfied with the TAF (91.35 +/- 7.75) medical humanities PBL classes than APF (90.40 +/- 8.42) medical humanities PBL classes (P = 0.01). Moreover, medical students were more satisfied with the clinical medicine-unrelated topics (92.00 +/- 7.10) than the clinical medicine-related topics (90.36 +/- 7.99) in the medical humanities PBL course (P = 0.01). This medical humanities PBL course, including nonmedical subjects and topics, and nonmedical teaching assistants from the liberal arts as class facilitators, was satisfactory. This pedagogical approach of student-centered, nonmedical topics, nonmedical facilitators, and small groups, which is associated with a deep approach to learning medical humanities, should be highly encouraged.";2016-02;2021-02-11T04:12:23Z;2021-02-11T04:12:23Z;NA;1-6;NA;6;95;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA Publisher: LIPPINCOTT WILLIAMS & WILKINS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TME5S73I;journalArticle;2016;"Koban, Leonie; Wager, Tor D.";Beyond Conformity: Social Influences on Pain Reports and Physiology;EMOTION;NA;1528-3542;10.1037/emo0000087;NA;"Social information can profoundly influence behavior, but its effects are often explained in terms of “conformity,” implying effects on decision-making and communication rather than deeper sensory modulation. We examined whether information about other people's pain reports affected both participants' pain experience and skin conductance responses (SCR) during pain. Sixty volunteers experienced painful heat stimulation preceded by 2 kinds of informational cues: (a) nonreinforced social information indicating low or high pain ratings from previous participants; and (b) reinforced conditioned stimuli (CSlow, Cs-high). Both high-pain social information and CShigh cues enhanced pain and SCRs relative to their respective controls, with particularly robust effects of social information. Effects of both manipulations on both pain and SCRs were mediated by trial-by-trial pain expectancies. These results demonstrate strong social influences on pain and autonomic responses, and suggest that expectations from multiple sources can influence pain physiology independent of reinforcement.";2016-02;2021-02-11T04:12:24Z;2021-02-11T04:12:24Z;NA;24-32;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA Publisher: AMER PSYCHOLOGICAL ASSOC Type: Article;NA;NA;NA;NA;"learning; heat pain; personality; placebo; social influence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RSHDDI3R;conferencePaper;2016;"Gibson, James; Can, Dogan; Xiao, Bo; Imel, Zac E.; Atkins, David C.; Georgiou, Panayiotis; Narayanan, Shrikanth";A Deep Learning Approach to Modeling Empathy in Addiction Counseling;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;10.21437/Interspeech.2016-554;NA;Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics.;2016;2021-02-11T04:12:24Z;2021-02-11T04:12:24Z;NA;1447-1451;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"behavioral signal processing; motivational interviews; recurrent neural networks; word embedding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AT66AS6Q;journalArticle;2016;"Wisniewska, Malgorzata; Grudowski, Piotr";High-quality academic teachers in business school. The case of The University of Gdansk, Poland;TOTAL QUALITY MANAGEMENT & BUSINESS EXCELLENCE;NA;1478-3363;10.1080/14783363.2015.1064766;NA;The Bologna process, the increasing number of higher education institutions, the mass education and the demographic problems make the quality of education and quality of the academic teachers a subject of wide public debate and concern. The aim of the paper is to identify the most preferred characteristics of a teacher working at a business school. The research problem was: What should a high-quality business school academic teacher be like? During the research, a six-stage qualitative survey design was proposed, and a letter questionnaire was applied as a free writing instrument and sent to second-year bachelor students of the Faculty of Management at The University of Gdansk, Poland. To identify the most preferred characteristics, a content analysis and Pareto analysis were used. As a result, 32 characteristics were proposed and grouped into 5 categories, namely tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Based on this, several proposals and recommendations for the future were specified. The results obtained help not only to understand the needs of students, but also to prepare the most desired teaching environment in which deep learning outcomes are made possible for future managers in the context of modern economy.;2016;2021-02-11T04:12:25Z;2021-02-11T04:12:25Z;NA;1158-1170;NA;9-10;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"management education; academic teacher; business school; quality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XR8FC6TN;journalArticle;2016;"Palagi, Elisabetta; Cordoni, Giada; Demuru, Elisa; Bekoff, Marc";Fair play and its connection with social tolerance, reciprocity and the ethology of peace;BEHAVIOUR;NA;0005-7959;10.1163/1568539X-00003336;NA;The concept of peace, with its corollary of behaviours, strategies and social implications, is commonly believed as a uniquely human feature. Through a comparative approach, we show how social play In animals may have paved the way for the emergence of peace. By playing fairly, human and nonhuman animals learn to manage their social dynamics in a more relaxed and tolerant way that results in a more effective management of conflicts. We show that play promotes tolerance, cooperation, fairness and reciprocity, which are essential elements of the so-called positive peace. This kind of peace is reached through an evolving process in which individuals continually modify social relationships to attain peaceful coexistence. In conclusion, we assume that the concept of peace has deep biological roots that constitute the basis for more sophisticated cultural constructions.;2016;2021-02-11T04:12:25Z;2021-02-11T04:12:25Z;NA;1195-1216;NA;9-11, SI;153;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS Publisher: BRILL ACADEMIC PUBLISHERS Type: Review;NA;NA;NA;NA;"despotic species; egalitarian species; playful expression; positive peace; pre-school children";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4WGB46A6;conferencePaper;2016;"Leem, Soo Yeon; Lee, Sang Won";INTERDISCIPLINARY DESIGN EDUCATION BASED ON COLLABORATION BETWEEN ARTS AND ENGINEERING SCHOOLS;INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2015, VOL 3;978-0-7918-5710-6;NA;NA;NA;In this paper, the new graduate course, referred to as “Creation and Innovation”, for interdisciplinary design and innovation is introduced based on the collaboration between arts and engineering. In this course, students having various backgrounds in arts and engineering schools participates and forms several interdisciplinary teams for project-based learning. The systematic methods such as Design Thinking Process and Strategic Foresight and Innovation have been combinatorially adopted for this course. Those methods are human-centered approaches, which allow deep understanding on users' needs and wants by being empathized with users and their environments. This empathy activity can enable the students to actively consider users' various aspects, which has been of much significance in the current interdisciplinary design education. It is also shown that the collaboration among the team members with the backgrounds of arts and engineering can be effective to generate more creative and innovative ideas by combining their holistic and analytic views.;2016;2021-02-11T04:12:25Z;2021-02-11T04:12:25Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;AMER SOC MECHANICAL ENGINEERS;THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ASME, Design Engn Div; ASME, Comp & Informat Engn Div Type: Proceedings Paper";<p>ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, Boston, MA, AUG 02-05, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WCZW85S5;journalArticle;2016;"Abbiati, Milena; Baroffio, Anne; Gerbase, Margaret W.";Personal profile of medical students selected through a knowledge-based exam only: are we missing suitable students?;MEDICAL EDUCATION ONLINE;NA;1087-2981;10.3402/meo.v21.29705;NA;Introduction: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. Methods: Students applying for medical school (N = 311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. Results: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p = 0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. Conclusion: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile.;2016;2021-02-11T04:12:26Z;2021-02-11T04:12:26Z;NA;NA;NA;NA;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"assessment; medical students; personal characteristics; profile; selection; undergraduate";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZPWE8PT7;journalArticle;2016;Domen, Ronald E.;The Pathologist as Poet;ACADEMIC PATHOLOGY;NA;2374-2895;10.1177/2374289516659078;NA;The role of the humanities (eg, philosophy, bioethics, literature, music, theater, religion, anthropology) in medical education has been argued long and hard for decades. It is argued that the study of subjects included in the humanities can enhance critical thinking skills, foster a deeper level of learning and understanding, and help to enhance one's level of compassion, empathy, and moral/ethical reasoning. It is the author's contention that writing and reading poetry (as an example of a personal pursuit in the humanities) can help achieve these goals not only in our contact with patients but also in our contact with other humans and cultures in the world at large.;2016-12;2021-02-11T04:12:26Z;2021-02-11T04:12:26Z;NA;NA;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"ethics; literature; professionalism; bioethics; humanities; medical education; medical humanities; poetry";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QJC7HA2D;journalArticle;2015;"Park, Jiyeon; Jeon, Dongryul";Correlation of Students' Brain Types to their Conceptions of Learning Science and Approaches to Learning Science;EURASIA JOURNAL OF MATHEMATICS SCIENCE AND TECHNOLOGY EDUCATION;NA;1305-8215;NA;NA;The systemizing and empathizing brain type represent two contrasted students' characteristics. The present study investigated differences in the conceptions and approaches to learning science between the systemizing and empathizing brain type students. The instruments are questionnaires on the systematizing and empathizing, questionnaires on the conceptions of learning science and questionnaires on the approaches to learning science. The data showed that the conception of learning science as taking tests was negatively correlated with the systemizing but not correlated with the empathizing. However, the conception of learning science as increasing knowledge and understanding was more positively correlated with the empathizing. The deep motive and strategy were more positively related with the systemizing than the empathizing, while the latter was more negatively correlated with the surface strategy. Our study suggests that while students with high systemizing are more motivated to learn science the ability to empathize is also important for successful science study.;2015-10;2021-02-11T04:12:26Z;2021-02-11T04:12:26Z;NA;1141-1149;NA;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GAZI UNIV, GAZI EGTIM FAKULTESI, K BLOK 210, TEKNIKOKULLAR, ANKARA, 06500, TURKEY Publisher: EURASIA Type: Article;NA;NA;NA;NA;"approaches to learning science; conceptions of learning science; empathizing brain type; systemizing brain type";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6225NMZW;journalArticle;2015;Wickramasekera, Ian E., II;Mysteries of Hypnosis and the Self Are Revealed by the Psychology and Neuroscience of Empathy;AMERICAN JOURNAL OF CLINICAL HYPNOSIS;NA;0002-9157;10.1080/00029157.2014.978495;NA;"This article reviews a growing body of research and theory in hypnosis and neuroscience that supports the empathic involvement theory (EIT) of hypnosis (Wickramasekera II, 2001; Wickramasekera II & Szlyk, 2003; Wickramasekera II, 2007c). The EIT is a unified transpersonal theory of hypnosis and the self, which weaves together empathic elements of Dzogchen, neodissociative, neuroscience, psychoanalytic, sociocognitive, and other theories by proposing that hypnotic phenomena are inherently characterized by their deep involvement with processes of empathy and the self. The EIT proposes that the experience of hypnosis is embodied in a system of neural networks in the brain that utilizes empathy-related processes, adaptive resonance between perceptual input and top-down expectancies, and connectionist learning algorithms to (a) empathically enact the affect, cognition, body language, response expectancies, social roles, sensations, etc. that are presented to them during hypnosis in accordance with socio-cognitive theories of hypnosis; (b) engage in a convergent psychophysiological relationship with another person in accordance with psychoanalytic, Ericksonian, and polyvagal/social engagement system theories; (c) alter the empathic self/other (theory of mind) coding of phenomenological experiences during hypnosis in accordance with aspects of the neo-dissociative and socio-cognitive traditions; and (d) develop an experiential understanding of the illusion of self that may lead, in some people, to its transcendence in accordance with Bon-Buddhist, Dzogchen, and transpersonal scholars. A unified definition of hypnosis is proposed based on findings in the empathic neuroscience of hypnosis as well as a working model of the neuromatrix of the self.";2015-07-03;2021-02-11T04:12:27Z;2021-02-11T04:12:27Z;NA;330-348;NA;3, SI;57;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"self; empathy; neuroscience; consciousness; Dzogchen; hypnosis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FEJ53MEV;journalArticle;2015;Mizell, Karen;PHILOSOPHY FOR CHILDREN, COMMUNITY OF INQUIRY, AND HUMAN RIGHTS EDUCATION;CHILDHOOD AND PHILOSOPHY;NA;2525-5061;NA;NA;The Community of Inquiry (COI) is a unique discourse model that brings adults and children together in collaborative discussions of philosophical and ethical topics. The model deepens children's higher order cognitive skills as they address complex dilemmas. This paper examines the potential for COI to deepen children's moral and intellectual understanding through recursive discourse that encourages them to transcend traditional and cultural limitations, confront their own moral predispositions, and increase inter-cultural understanding. As children become familiar with normative values couched in ethical dialogue, they are immersed in ideals of reciprocity and empathy in ways that transcend narrow self-interest. The technique plays upon children's freedom of thought and freedom of conscience as they learn to express their views and to listen to the perspectives of others. COI is a functional practice enhancing a deep and practical education of character. Such dialogues can become effective vehicles for introducing children to discussions of human dignity and rights that also challenge traditional power relationships between adults and children. The uncritical assumption underlying such power differentials often contests the de facto rights and dignity of children. COI is a valuable tool for human rights education as it encourages children's sensitivity to the rights and dignities of others and, simultaneously, honors children's own rights and dignities as participating citizens in the global community.;2015-12;2021-02-11T04:12:27Z;2021-02-11T04:12:27Z;NA;319-328;NA;22;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: NEFI-CENTER PHILOSOPHICAL & CHILDHOOD STUDIES, RIO DE JANEIRO, 00000, BRAZIL Publisher: STATE UNIV RIO DE JANEIRO Type: Article;NA;NA;NA;NA;"Community of Inquiry; Ethnocentrism; Human Rights Education; Inter-cultural Education; Philosophy for Children";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FWP84CHM;journalArticle;2015;Hopkinson, Clare;Using poetry in a critically reflexive action research co-inquiry with nurses;ACTION RESEARCH;NA;1476-7503;10.1177/1476750314565943;NA;There are few reports of healthcare action research using collaborative or co-operative inquiry (co-inquiry) while research featuring poetry is also rare. This paper presents a cycle from a critically reflexive action research co-inquiry that explored the tensions and possibilities of nurses' reflecting during care-giving where poems emerged as data. These poems were inspired by reflections, observations, co-inquirers' stories and interviews. They formed part of a first-, second- and third-person co-inquiry. Applying Bourdieu's concepts of doxa, habitus and field to the poems revealed cultural aspects of nursing practice. The poems resonated with nurses' experiences producing deeper conversations and powerful reflexive co-inquiries about practice. The poems evoked suppressed emotions and empathy. I argue poems derived from practice are embodied knowledge and thus have a legitimate place in healthcare action research. Practice-based poems could be valuable for other practice-orientated professions in producing practice learning and change.;2015-03;2021-02-11T04:12:27Z;2021-02-11T04:12:27Z;NA;30-47;NA;1, SI;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"emotions; co-inquiry; collaborative action research; embodied knowledge; emotional labour; habitus and field; Poetry; reflexive";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y34SC9XN;journalArticle;2015;"Koopman, Eva Maria (Emy); Hakemulder, Frank";Effects of Literature on Empathy and Self-Reflection: A Theoretical-Empirical Framework;JOURNAL OF LITERARY THEORY;NA;1862-5290;10.1515/jlt-2015-0005;NA;"Various scholars have made claims about literature's potential to evoke empathy and self-reflection, which would eventually lead to more pro-social behavior. But is it indeed the case that a seemingly idle pass-time activity like literary reading can do all that? And if so, how can we explain such an influence? Would the effects be particular to unique literary text qualities or to other aspects that literary texts share with other genres (e.g., narrativity)? Empirical research is necessary to answer these questions. This article presents an overview of empirical studies investigating the relationship between reading and empathy, and reading and self-reflection. We reveal those questions in the research that are not addressed as of yet, and synthesize the available approaches to literary effects. Based on theory as well as empirical work, a multi-factor model of literary reading is constructed. With regard to reading and empathy, the metaphor of the moral laboratory (cf. Hakemulder 2000) comes close to a concise summary of the research and theory. Being absorbed in a narrative can stimulate empathic imagination. Readers go along with the author/narrator in a (fictional) thought-experiment, imagining how it would be to be in the shoes of a particular character, with certain motives, under certain circumstances, meeting with certain events. That would explain why narrativity can result in a broadening of readers' consciousness, in particular so that it encompasses fellow human beings. Fictionality might stimulate readers to consider the narrative they read as a thought experiment, creating distance between them and the events, allowing them to experiment more freely with taking the position of a character different from themselves, also in moral respects. Literary features, like gaps and ambiguous characterization, may stimulate readers to make more mental inferences, thus training their theory of mind. However, apart from literature possibly being able to train basic cognitive ability, we have little indication for the importance of literary imagination over narrative or fictional imagination. Regarding self-reflection, while there is no convincing evidence that literary texts are generally more thought-provoking than non-literary texts (either narrative or expository), there is tentative indication for a relation between reading literary texts and self-reflection. However, as was the case for the studies on empathy, there is a lack of systematic comparisons between literary narratives and non-literary narratives. There are some suggestions regarding the processes that can lead to self-reflection. Empirical and theoretical work indicates that the combination of experiencing narrative and aesthetic emotions tends to trigger self-reflection. Personal and reading experience may influence narrative and aesthetic emotions. By proposing a multi-factor model of literary reading, we hope to give an impulse to current reader response research, which too often conflates narrativity, fictionality and literariness. The multi-factor model of literary reading contains (our simplified versions of) two theoretical positions within the field of reader response studies on underlying processes that lead to empathy and reflection: the idea of reading literature as a form of role-taking proposed by Oatley (e.g., 1994; 1999) and the idea of defamiliarization through deviating textual and narrative features proposed by Miall and Kuiken (1994; 1999). We argue that these positions are in fact complementary. While the role-taking concept seems most adequate to explain empathic responses, the defamiliarization concept seems most adequate in explaining reflective responses. The discussion of these two theoretical explanations leads to the construction of a theoretical framework (and model) that offers useful suggestions which texts could be considered to have which effects on empathy and reflection. In our multi-factor model of literary reading, an important addition to the previously mentioned theories is the concept “stillness”. We borrow this term from the Canadian author Yann Martel (2009), who suggests reading certain literary texts will help to stimulate self-contemplation (and appreciation for art), moments that are especially valuable in times that life seems to be racing by, and we are enveloped by work and a multitude of other activities. Other literary authors have proposed similar ideas. Stillness is related to, or overlaps with the more commonly used term “aesthetic distance”, an attitude of detachment, allowing for contemplation to take place (cf. Cupchik 2001). Stillness, we propose, allows a space in which slow thinking (Kahneman 2011) can take place. Stillness is not reflection itself, but a precondition for reflection. In our model, stillness is an empty space or time that is created as a result of reading processes: the slowing down of readers' perceptions of the fictional world, caused by defamiliarization. Our multi-factor model suggests that while role-taking can take place for all types of narratives, literary and fictional narratives may evoke the type of aesthetic distance (stillness) that leads to a suspension of judgment, adding to a stronger experience of role-taking and narrative empathy. In a time when the biggest bestsellers are about crime and erotic sadomasochism, the idea that reading literature can make us better human beings may seem farfetched. However, ever since Aristotle's Poetics (1987; orig. around 335 BCE), authors, critics, and academics have made claims concerning the ethical potential of narrative drama and poetic language (e.g., Althusser 1983; Booth 1988; Boyd 2009; Bronzwaer 1986; De Botton 1997; Habermas 1983; Hunt 2007; Nussbaum 1995; 1997; 2001; 2010; Pinker 2011; Sontag 2007; Van Peer 1995). The general claims are that reading literature may enhance self-knowledge, make people more aware of the plights of those suffering, and more willing to take action to help them. In recent years, the philosopher Martha Nussbaum has defended the ethical power of literature most ardently. Reading literature, she says, triggers a type of imagination that is “an essential ingredient of an ethical stance that asks us to concern ourselves with the good of other people whose lives are distant from our own” (1995, xvi). Through this “literary imagination”, readers learn to put themselves in the place of people they could not have known that intimately in any other way, thus deepening their understanding and compassion. As Nussbaum (2001, 2) further argues, literary texts can lead to the sort of “self-examination” that is crucial to ethical decision-making. Often this is reflection on the self, in relation to others. Knowing how we might respond to certain situations might help us understand how others would feel as well (cf. Johnson's 1993 conception of “moral imagination”, and extensive use of the term elsewhere, e.g., Beran 1998; Guroian 1996; Hutchison 2004). These are just a few of the reasons why empathy and self-reflection make an interesting couple to focus on when studying the effects of reading literary texts. To various scholars, the claims about the relevance of this duo and their relation with literary imagination are far-reaching rather than farfetched. Hunt (2007), for instance, proposes that fiction has contributed to a mindset that enabled people to think up a concept like human rights. Novels such as Rousseau's Julie (1761) and Richardson's Pamela (1740) stimulated readers, she says, to empathize across borders of class, sex, and nation. “As a consequence”, Hunt claims, “they came to see others - people they did not know personally - as like them, as having the same kinds of inner emotions. Without this learning process, `equality' could have no deep meaning and in particular no political consequence” (ibid., 40). She illustrates her statements with examples of responses of contemporary readers. Pinker (2011) takes this line of argument even further, suggesting that the spectacular increase in availability and consumption of narratives in our history might have caused an increase in empathic ability and, subsequently, a decline in violence. The relevance of literature's effect on self-reflection is maybe less self-evident, but that does not make the claims less sweeping. Among others, Althusser (1980), Habermas (1983), and Bronzwaer (1986) have argued that literature's polyvalence can lead us to reflect on our own norms, values, and prejudices, and that this would ultimately benefit society. Indeed, awareness of self and others may be key to our happiness, social success (Cooper/Sawaf 2003; Goleman 1995), and even productivity (Ibarra/Barbulescu 2010, see Bal/Veltkamp 2013). But is it indeed the case that a seemingly idle pass-time activity like literary reading can do all that? And if so, how can we explain such an influence? Would the effects be particular to unique literary text qualities or to other aspects that literary texts share with other genres (e.g., narrativity)? The purpose of this article is to construct a model for such effects of literary narratives. It will reveal those questions in the research that are not addressed as of yet, and will synthesize the available approaches to literary effects. In our attempt to construct an explanatory model for literary imagination, we first evaluate the empirical indications that reading literature affects empathy in its various forms (Section 2.1). We will see that it remains unclear how such effects come about, but that recent studies help us to make some significant progress in understanding the workings of literary imagination (Section 2.2). In Section 3 we will do the same for reflection. Finally, we will synthesize our findings in our explanatory model in Section 4. We will make use of earlier overviews (Hake-mulder 2000; Keen 2007; Kimmel 1970; Klemenz-Belgardt 1981; Mar/Oatley/ Djikic/Mullin 2011), adding other and more recent empirical work that will help us to build a synthetic framework for future research. Yet, before all this, we need to define the key terms (Section 1).";2015-03;2021-02-11T04:12:27Z;2021-02-11T04:12:27Z;NA;79-111;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY Publisher: WALTER DE GRUYTER GMBH Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3IS6A9EG;journalArticle;2015;Cook-Sather, Alison;Dialogue Across Differences of Position, Perspective, and Identity: Reflective Practice in/on a Student-Faculty Pedagogical Partnership Program;TEACHERS COLLEGE RECORD;NA;0161-4681;NA;NA;Background: Inspired by various conceptualizations of both cultural diversity and cross-role partnership, this discussion challenges the assumption that holds sway in many people's minds: Differences primarily divide us. The context for this argument is a program that pairs undergraduate students and faculty members in semester-long partnerships to explore and revise pedagogical practices. Purpose: The purpose of this article is to explore how dialogue across differences supported by a student-faculty partnership program can inspire greater openness to and appreciation of differences. The focus is on fostering deeper connection and empathy across student and faculty positions, perspectives, and cultural identities. Research Design: Through systematically documented reflective practice, I draw on audio-recorded conversations, mid-and end-of-semester feedback, and follow-up interviews with student and faculty participants in the program, as well as on my own reflective notes and less formal communication with participants, to identify the ways in which these faculty and students conceptualize differences as resources for learning. Findings: Through supporting the demanding work of communicating and collaborating across differences, this program makes it normative for differences to exist and for people in relationships to benefit from them. The student-faculty partnerships evoke deliberate consideration of differences in position, perspective, and identity within collaborative work, which, in turn, generate ongoing critical reflection with the promise of changing higher educational practices. Conclusions/Recommendations: Higher education needs to create more opportunities for students and faculty to engage in dialogue across various kinds of difference. Suggestions are offered for how to create structures and support within which faculty and students can forge new perspectives that allow them to draw on differences as a uniting rather than a dividing force.;2015-02;2021-02-11T04:12:28Z;2021-02-11T04:12:28Z;NA;NA;NA;2;117;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 525 W 120TH ST, NEW YORK, NY 10027 USA Publisher: TEACHERS COLL OF COLUMBIA UNIV Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ARM9M77X;conferencePaper;2015;"Ene, Ionel; Barna, Iuliana";Religious Education and Teachers' Role in Students' Formation towards Social Integration;6TH INTERNATIONAL CONFERENCE EDU WORLD 2014: EDUCATION FACING CONTEMPORARY WORLD ISSUES;NA;NA;10.1016/j.sbspro.2015.02.081;NA;Religious education is a demanding area of pedagogical education, as there is no universal method to systematically insert religious principles in the children's education. The theory and methodology of the curriculum, instruction and evaluation require certain skills from teachers, such as: a great interest in the adequacy of the training process to the needs of each individual, the ability to adjust to different situations, a holistic assessment of the students performance, the involvement of the students in the learning process, etc. These skills are equally indispensable for the teacher of Religion, who must have greater sensitivity and empathy, and also deep religious convictions, reflected in their behaviour and in their way of relating with the student. (C) 2015 The Authors. Published by Elsevier Ltd.;2015;2021-02-11T04:12:28Z;2021-02-11T04:12:28Z;NA;30-35;NA;NA;180;NA;NA;NA;Procedia Social and Behavioral Sciences;NA;NA;NA;ELSEVIER SCIENCE BV;SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 1877-0428 Type: Proceedings Paper;<p>6th International Conference Edu World 2014 Education Facing Contemporary World Issues, Pitesti, ROMANIA, NOV 07-09, 2014</p>;NA;NA;NA;"methods; competences; religious education; social phenomenon";Soare, E and Langa, C;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
927HWL4G;journalArticle;2015;"Walshaw, Margaret; Duncan, Wayne";Hermeneutics as a methodological resource for understanding empathy in on-line learning environments;INTERNATIONAL JOURNAL OF RESEARCH & METHOD IN EDUCATION;NA;1743-727X;10.1080/1743727X.2014.914166;NA;Hermeneutics is both a philosophical tradition and a methodological resource. In this qualitative study, hermeneutics provided, simultaneously, a framework and a methodology for understanding empathy in synchronous multimedia conferencing. As a framework for the design of the study, hermeneutics supported the overriding objective to understand the human phenomenon of empathy and students' and teachers' experiences of this phenomenon. As a methodological resource, hermeneutics pointed to an approach to data collection and analysis that would allow us to honour and remain faithful to participants' stories of their experiences of empathy in on-line educational environments. In this article, we provide an explanation of the iterative approach used to interpret empathy within classroom environments devoid of face-to-face interactions. Those approaches offered increasingly deeper understandings of the ways in which people are able to perceive how others feel in on-line environments.;2015;2021-02-11T04:12:29Z;2021-02-11T04:12:29Z;NA;304-319;NA;3, SI;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"empathy; hermeneutics; on-line environments";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
A8XGQXFZ;journalArticle;2015;Stinson, Madonna;Speaking up about oracy: the contribution of drama pedagogy to enhanced oral communication;ENGLISH TEACHING-PRACTICE AND CRITIQUE;NA;1175-8708;10.1108/ETPC-07-2015-0055;NA;Purpose - The purpose of this paper is to consider the growing interest in oracy and to propose the pedagogy of process drama as an ideal model for the dialogic classroom. Design/methodology/approach - This paper takes the form of an explanatory case study where the author draws on a successful drama/oracy project in a primary school in Brisbane, Australia, to illustrate the connections between Alexander's five indicators of a dialogic classroom and the process drama in which the students participated. Findings - The application of this process drama as pedagogy for the teaching and learning of oracy has contributed positively to students' oral communication skills and intercultural awareness. In addition, parents provide positive feedback about student engagement in school and developing self-confidence because “they have something to say”. Research limitations/implications - There was no formal pre-post test for the oral communication skills on this study, instead the researchers developed a draft “oracy” checklist which deserves further interrogation and development. Practical implications - There are implications for the use of process drama as a means of creating and sustaining the dialogic classroom. Teacher professional development would be required to assist the planning and delivery of dramas that allow for the deep and complex learning evidenced in this study. Social implications - This is an ideal vehicle for assisting in the development of empathy, collaboration, emotional intelligence and intercultural understanding. Originality/value - This is an example of an extremely high-quality curriculum plan and implementation. The importance of engaging in implicit and explicit instruction of oral communication for the twenty-first century should not be underestimated. The process drama allows oral language to be foregrounded, with additional learning opportunities from a range of other learning areas, brought together in a coherent and complex model of practice.;2015;2021-02-11T04:12:29Z;2021-02-11T04:12:29Z;NA;303-313;NA;3, SI;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND Publisher: EMERALD GROUP PUBLISHING LTD Type: Article;NA;NA;NA;NA;"Pedagogy; Dialogic classroom; English language arts; English teaching; Oracy; Oral language pedagogy; Process drama; Speaking and listening";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8W6DTKE3;journalArticle;2015;"Hurst, Samia A.; Baroffio, Anne; Ummel, Marinette; Burn, Carine Layat";Helping medical students to acquire a deeper understanding of truth-telling;MEDICAL EDUCATION ONLINE;NA;1087-2981;10.3402/meo.v20.28133;NA;Problem: Truth-telling is an important component of respect for patients' self-determination, but in the context of breaking bad news, it is also a distressing and difficult task. Intervention: We investigated the long-term influence of a simulated patient-based teaching intervention, integrating learning objectives in communication skills and ethics into students' attitudes and concerns regarding truth-telling. We followed two cohorts of medical students from the preclinical third year to their clinical rotations (fifth year). Open-ended responses were analysed to explore medical students' reported difficulties in breaking bad news. Context: This intervention was implemented during the last preclinical year of a problem-based medical curriculum, in collaboration between the doctor-patient communication and ethics programs. Outcome: Over time, concerns such as empathy and truthfulness shifted from a personal to a relational focus. Whereas `truthfulness' was a concern for the content of the message, `truth-telling' included concerns on how information was communicated and how realistically it was received. Truth-telling required empathy, adaptation to the patient, and appropriate management of emotions, both for the patient's welfare and for a realistic understanding of the situation. Lessons learned: Our study confirms that an intervention confronting students with a realistic situation succeeds in making them more aware of the real issues of truth-telling. Medical students deepened their reflection over time, acquiring a deeper understanding of the relational dimension of values such as truth-telling, and honing their view of empathy.;2015;2021-02-11T04:12:29Z;2021-02-11T04:12:29Z;NA;NA;NA;NA;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: RIPVAGEN 7, JARFALLA, SE-175 64, SWEDEN Publisher: CO-ACTION PUBLISHING Type: Article;NA;NA;NA;NA;"communication skills; clinical education; ethics and humanities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LIT9KRSI;journalArticle;2014;"McDonald, Paul; Tang, Yi-Yuan";Neuroscientific Insights Into Management Development: Theoretical Propositions and Practical Implications;GROUP & ORGANIZATION MANAGEMENT;NA;1059-6011;10.1177/1059601114550712;NA;Research from the interdisciplinary field of social cognitive neuroscience provides insights as to how managers learn and develop, resulting in theoretical propositions and practical implications. Third-generation management development is applied as a conceptual framework for the organization and presentation of relevant evidence from the neuroscience literature. Neuroscience offers potential to theoretically advance our understanding of management development as well as practically enhance managerial capacity to (a) reflect with a deeper sense of self-awareness, (b) analyze with greater balance across hard and soft data, (c) position organizations within broader perspectives, (d) collaborate interpersonally by establishing relationships that engender egalitarianism and trust, and (e) enact change in a nonlinear manner. Ten propositions are developed linking neurological processes to management development. Practical implications are suggested as well as research considerations for future integration between neuroscience and management development.;2014-10;2021-02-11T04:12:30Z;2021-02-11T04:12:30Z;NA;475-503;NA;5;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Review;NA;NA;NA;NA;"ambidextrous learning; management development; social cognitive neuroscience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KGK9B2PX;journalArticle;2014;"Thomas, Joyce; McDonagh, Deana; Canning, Lisa";Developing the Arts Entrepreneur: The `Learning Cloud';DESIGN JOURNAL;NA;1460-6925;10.2752/175630614X13982745783046;NA;To help people address and (re)solve problems and seize opportunities, we need the vision and leadership that emerge from a deeper connection between creativity and empathy. There is emerging acknowledgement in higher education that a significant training gap exists in the teaching of entrepreneurship and leadership skill sets for `creatives'. An educational paradigm shift is needed to ensure that creatives can maximize their intellectual capital and are empowered to fully contribute to the economic, social and cultural growth of communities. This paper discusses the development of the arts entrepreneur using a new model of teaching and learning that places creativity and empathy at the core of learning. By helping creatives build their uniqueness into creative enterprises, we enable them to impact their communities and regional economies with creativity, entrepreneurship and sustainable values.;2014-09;2021-02-11T04:12:30Z;2021-02-11T04:12:30Z;NA;425-443;NA;3, SI;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 50 BEDFORD SQ, LONDON, WC1B 3DP, ENGLAND Publisher: BLOOMSBURY PUBLISHING PLC Type: Article;NA;NA;NA;NA;"creativity; arts; economic growth; entrepreneurialism; learning cloud";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7GHIRTHM;journalArticle;2014;"Stone, Teresa E.; Levett-Jones, Tracy";A comparison of three types of stimulus material in undergraduate mental health nursing education;NURSE EDUCATION TODAY;NA;0260-6917;10.1016/j.nedt.2013.07.014;NA;"Aims and objectives: The paper discusses an innovative educational approach that compared the use of different textual forms as stimulus materials in the teaching of an introductory mental health course. Background: Practitioners in many disciplines, including nursing, appreciate the value of narratives in making sense of experiences, challenging assumptions and enhancing learning: they enable exploration of reality from different perspectives and create an emotional resonance. Narratives help nursing students to uncover embedded meanings, values and beliefs; they can include written texts, illustrated texts or picture books. Participants: 180 students enrolled in an elective undergraduate nursing course. Method: This project afforded students the choice of critically analysing (a) a chapter from one of two autobiographies, (b) an illustrated text, or (c) an illustration from a picture book. Each text was a narrative account from a personal or carer's perspective of the experience of mental illness. Their written submissions were then analysed by means of a qualitative descriptive approach. Results: In analysis of the autobiographies students tended to paraphrase the authors' words and summarise their experiences. Those choosing the illustrated text were able to link the images and text, and provide a deeper and more insightful level of interpretation, albeit influenced by the author's personal account and expressed emotions; however, those analysing a picture book illustration demonstrated a surprising level of critical and creative thinking, and their interpretations were empathetic, insightful and thoughtful. Conclusion: The use of picture books, although not a common approach in nursing education, appears to engage students, challenge them to think more deeply, and stimulate their imagination. (C) 2013 Elsevier Ltd. All rights reserved.";2014-04;2021-02-11T04:12:30Z;2021-02-11T04:12:30Z;NA;586-591;NA;4;34;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNAL PRODUCTION DEPT, ROBERT STEVENSON HOUSE, 1-3 BAXTERS PLACE, LEITH WALK, EDINBURGH EH1 3AF, MIDLOTHIAN, SCOTLAND Publisher: CHURCHILL LIVINGSTONE Type: Article;NA;NA;NA;NA;"Education; Empathy; Mental health; Nursing student; Picture books; Therapeutic engagement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
AMDJNKC3;conferencePaper;2014;"Wisniewska, Malgorzata; Grudowski, Piotr";THE HIGH QUALITY BUSINESS SCHOOL ACADEMIC TEACHER OF THE 21ST CENTURY - POLISH STUDENTS' PERSPECTIVE;NEW CHALLENGES OF ECONOMIC AND BUSINESS DEVELOPMENT - 2014;978-9984-45-836-6;NA;NA;NA;The literature shows that the success and competence of future managers depend on the quality of their academic teachers. Moreover high quality study requires high quality lecturing/teaching that creates an environment in which deep learning outcomes are made possible for students. The aim was to identify the characteristics of the academic teacher working at business schools, according to the expectations of Polish students from a 21st century perspective. A qualitative survey design was used in the form of a letter questionnaire. 144 second-year bachelor students of Gdansk University from the Faculty of Management were asked to list a maximum of five, most preferred characteristics, and to comment their answers. Finally, 109 students participated in the study, and 471 characteristics were proposed, analyzed and put into five categories, like: tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Content analysis and Pareto-Lorenzo analysis was used and the most preferable characteristics were identified. The conclusions, proposals and recommendations were presented. The academic teacher has to be well prepared and teach in an interesting, innovative way with a use of modern techniques and methods. Very important is to apply not only the lecture-style methods but also on-the job teaching, project-based teaching, team work-based teaching, action teaching, experiential teaching, small groups teaching, case studies, simulations, e-teaching, and even volunteering teaching. Nor without the signifcance are coaching and mentoring and the features referring to the style of teaching, like charisma, creativity, passion, and engagement, which characterise good managers and business leaders.;2014;2021-02-11T04:12:31Z;2021-02-11T04:12:31Z;NA;431-438;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;UNIV LATVIA;19 RAINA BLVD, RIGA, LV 1586, LATVIA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Latvia, Fac Econ & Management; Latvian European Community Studies Assoc; Inst CEDIMES Lettonie; Econometrists Assoc Latvia; Latvian Informat & Commun Technol Assoc; Assoc Statisticians Latvia; Balt Sea Reg Univ Network; Wellton Type: Proceedings Paper";<p>International Scientific Conference on New Challenges of Economic and Business Development, Univ Latvia, Riga, LATVIA, MAY 08-10, 2014</p>;NA;NA;NA;"academic teacher; business school; quality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MBRBNF2X;journalArticle;2014;"Kim, Minkang; Chang, Heesun";An investigation of Korean children's prejudicial attitudes toward a national tragedy in Japan;JOURNAL OF MORAL EDUCATION;NA;0305-7240;10.1080/03057240.2014.920307;NA;Prejudice against another nation or culture is often perceived as a major hindrance to world peace. This paper will report on the early emergence of such prejudices, identified in eight-year-old primary school children in Korea. The research, conducted in June 2012, investigated Korean children's reactions to the Japanese tsunami of 2011. A pedagogically embedded research methodology (PERM) was used, where the research initiative was embedded within the teaching and learning of a normal school lesson. The research reveals that young Korean children's prejudices are nationally and culturally deep-seated, and are reinforced by parochial viewpoints projected by Korean mass media programmes. These influences place constraints on children's ability to empathise with people beyond their national borders. Nevertheless, the project provides evidence that prejudicial attitudes remain malleable in children and can be changed in a challenging but supportive educational context.;2014;2021-02-11T04:12:31Z;2021-02-11T04:12:31Z;NA;282-301;NA;3, SI;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"education; empathy; moral development; prejudice";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GB77GKJ7;conferencePaper;2014;Kuroda, Ariyabhorn;Contemplative Education Approaches to Teaching Teacher Preparation Program;5TH WORLD CONFERENCE ON EDUCATIONAL SCIENCES;NA;NA;10.1016/j.sbspro.2014.01.405;NA;"The purpose of this research was to developing instructions for Teacher Preparation Program in Khon Kaen University. The main intention is to make the learner's mind more aware of the human condition and to improve program objectives and learning through contemplative approaches. The 4 courses target in the first semester of 2012 academic year were students in Art Education Program and Teaching Japanese Program; Aesthetic Education, Art for Special-Needs Children, Introduction to Educational Philosophy and Ethics for Profession Teaching. The study was involving qualitative method, contemplative education approaches were used through mindfulness, deep listening, storytelling, sharing experiences together with dialogue, world cafe technique, drawing and reflection journaling. The results from reflective papers, observation and focus group were analyzed by content analysis. The research findings found that the contemplative teaching can support the development of attention, insight, emotional self-regulation, empathy, compassion for self and others and action in order to encourage and transform self-learning, deepens learning and builds inner strengths and skills. Through these approaches they were learning to reduce stress, enhance and improve classroom climates, and were helping students to calm their bodies and minds, focus their attention, and even open their hearts by exchange of learning ideas. The contemplative education approach is enabled students to recognize and properly tend to behavioural patterns and enabled students to process facts which led to contemplation and ultimately to wisdom. (C) 2013 The Authors. Published by Elsevier Ltd.";2014;2021-02-11T04:12:31Z;2021-02-11T04:12:31Z;NA;1400-1404;NA;NA;116;NA;NA;NA;Procedia Social and Behavioral Sciences;NA;NA;NA;ELSEVIER SCIENCE BV;SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Near E Univ; Ankara Univ; Bahcesehir Univ ISSN: 1877-0428 Type: Proceedings Paper";<p>5th World Conference on Educational Sciences (WCES), Rome Sapienza Univ, Rome, ITALY, FEB 05-08, 2013</p>;NA;NA;NA;"Contemplative Education Approaches; Teacher Preparation Programs";Laborda, JC and Ozdamli, F and Maasoglu, Y;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LKE4JS6B;journalArticle;2013;"Orr, Fiona; Kellehear, Kevin; Armari, Elizabeth; Pearson, Arana; Holmes, Douglas";The distress of voice-hearing: The use of simulation for awareness, understanding and communication skill development in undergraduate nursing education;NURSE EDUCATION IN PRACTICE;NA;1471-5953;10.1016/j.nepr.2013.03.023;NA;Role-play scenarios are frequently used with undergraduate nursing students enrolled in mental health nursing subjects to simulate the experience of voice-hearing. However, role-play has limitations and typically does not involve those who hear voices. This collaborative project between mental health consumers who hear voices and nursing academics aimed to develop and assess simulated voice-hearing as an alternative learning tool that could provide a deeper understanding of the impact of voice-hearing, whilst enabling students to consider the communication skills required when interacting with voice-hearers. Simulated sounds and voices recorded by consumers on mp3 players were given to eighty final year nursing students undertaking a mental health elective. Students participated in various activities whilst listening to the simulations. Seventy-six (95%) students completed a written evaluation following the simulation, which assessed the benefits of the simulation and its implications for clinical practice. An analysis of the students' responses by an external evaluator indicated that there were three major learning outcomes: developing an understanding of voice-hearing, increasing students' awareness of its impact on functioning, and consideration of the communication skills necessary to engage with consumers who hear voices. (C) 2013 Elsevier Ltd. All rights reserved.;2013-11;2021-02-11T04:12:32Z;2021-02-11T04:12:32Z;NA;529-535;NA;6;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Simulation; Consumer; Undergraduate nursing; Voice-hearing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BKIR5VM8;journalArticle;2012;"Roxburgh, Michelle; Conlon, Margaret; Banks, Debbie";Evaluating Hub and Spoke models of practice learning in Scotland, UK: A multiple case study approach;NURSE EDUCATION TODAY;NA;0260-6917;10.1016/j.nedt.2012.05.004;NA;"Background: Most of UK students' practice learning experience is based on a rotational placement model which often leads to students lacking confidence and feeling anxious about the complexities of the care environment. Objectives: To evaluate the impact of Hub and Spoke model(s) of clinical practice placement across geographically diverse locations, with a particular focus on enhancing the student practice learning experience. Design: Multiple case study design. Setting & Participants: Comprised undergraduate student nurses from Adult, Learning Disability and Mental Health programmes from 3 Scottish Schools of Nursing. Methods: A mixed methods approach which included quantitative and qualitative date tools. Results: All three Hub and Spoke models shared two broad findings: 1) In the three Hub and Spoke models detailed in this paper, there is a continuum of student led learning which supports the process with opportunities for individual students to be positively innovative and creative in their learning approaches. Depth of learning was achieved in two ways; a) the method in which Hub placements are organised, managed and structured and, b) the depth of empathy and sensitivity to the individual at the centre of the care. 2) Placement capacity is increased: The classification of placements is reviewed to produce broader categories, Engagement of mentors/enhanced student/mentor relationship. Conclusions: Practice Learning must be seen as an academic endeavour that promotes deep, meaningful, person-centred learning rather than superficial, compartmentalised placement-centred learning. (C) 2012 Elsevier Ltd. All rights reserved.";2012-10;2021-02-11T04:12:32Z;2021-02-11T04:12:32Z;NA;782-789;NA;7, SI;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNAL PRODUCTION DEPT, ROBERT STEVENSON HOUSE, 1-3 BAXTERS PLACE, LEITH WALK, EDINBURGH EH1 3AF, MIDLOTHIAN, SCOTLAND Publisher: CHURCHILL LIVINGSTONE Type: Article;NA;NA;NA;NA;"Belongingness; Learning environments; Practice Learning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MHBGWXYG;journalArticle;2011;"McManus, I. C.; Jonvik, Hallgeir; Richards, Peter; Paice, Elisabeth";Vocation and avocation: leisure activities correlate with professional engagement, but not burnout, in a cross-sectional survey of UK doctors;BMC MEDICINE;NA;1741-7015;10.1186/1741-7015-9-100;NA;Background: Sir William Osler suggested in 1899 that avocations (leisure activities) in doctors are related to an increased sense of vocation (professional engagement) and a decreased level of burnout. This study evaluated those claims in a large group of doctors practicing in the UK while taking into account a wide range of background variables. Methods: A follow-up questionnaire was sent to 4,457 UK-qualified doctors who had been included in four previous studies of medical school selection and training, beginning in 1980, 1985, 1990 and 1989/1991. A total of 2,845 (63.8%) doctors returned the questionnaire. Questions particularly asked about work engagement, satisfaction with medicine as a career, and personal achievement (Vocation/engagement), stress, emotional exhaustion, and depersonalization (BurnedOut), and 29 different leisure activities (Avocation/Leisure), as well as questions on personality, empathy, work experience, and demography. Results: Doctors reporting more Avocation/Leisure activities tended to be women, to have older children, to be less surface-rational, more extravert, more open to experience, less agreeable, and to fantasize more. Doctors who were more BurnedOut tended to be men, to be more sleep-deprived, to report a greater workload and less choice and independence in their work, to have higher neuroticism, lower extraversion and lower agreeableness scores, and to have lower self-esteem. In contrast, doctors with a greater sense of Vocation/engagement, tended to see more patients, to have greater choice and independence at work, to have a deep approach to work, to have a more supportive-receptive work environment, to be more extravert and more conscientious, and to report greater self-esteem. Avocation/Leisure activities correlated significantly with Vocation/engagement, even after taking into account 25 background variables describing demography, work, and personality, whereas BurnedOut showed no significant correlation with Avocation/Leisure activities. Popular Culture and High Culture did not differ in their influence on Vocation/engagement, although there was a suggestion that Depersonalization was correlated with more interest in Popular Culture and less interest in High Culture. Conclusion: In this cross-sectional study there is evidence, even after taking into account a wide range of individual difference measures, that doctors with greater Avocation/Leisure activities also have a greater sense of Vocation/Engagement. In contrast, being BurnedOut did not relate to Avocation/Leisure activities (but did relate to many other measures). Osler was probably correct in recommending to doctors that, `While medicine is to be your vocation, or calling, see to it that you also have an avocation'.;2011-08-30;2021-02-11T04:12:33Z;2021-02-11T04:12:33Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: BMC Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Z8PCANLK;journalArticle;2011;Seeger, Falk;On meaning making in mathematics education: social, emotional, semiotic;EDUCATIONAL STUDIES IN MATHEMATICS;NA;0013-1954;10.1007/s10649-010-9279-9;NA;This paper is an attempt to add to the foundation of our understanding of meaning making in mathematics education. This attempt seems to be necessary as a growing body of research, primarily in developmental psychology, begins to change our view of early human development. Empathy, reciprocity, and implicit understanding seem to be more suitable concepts to describe human development and learning than the ones previously employed, based, e.g., on aggression as natural instinct or competitiveness as genetically wired basic drive.;2011-07;2021-02-11T04:12:33Z;2021-02-11T04:12:33Z;NA;207-226;NA;2-3, SI;77;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Consciousness; Emotion; Empathy; Culture; Attachment; Deep play; Implicit learning and understanding; Meaning-making; Mind; Pragmatic maxim; Pretending; Reciprocity; Semiotic; Shared intentionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3QEQHMM7;conferencePaper;2011;"Ng, Dicky; Anderson, Katie";COGNITIVE EMPATHY AND MATHEMATICS TEACHING;PROCEEDINGS OF THE 35TH CONFERENCE OF THE INTERNATIONAL GROUP FOR THE PSYCHOLOGY OF MATHEMATICS EDUCATION, VOL. 3: DEVELOPING MATHEMATICAL THINKING;978-975-429-297-8;NA;NA;NA;This study examines the nature of cognitive empathy among prospective primary teachers, specifically in its relation to teaching of mathematics. Cognitive empathy is defined as the ability for deliberate intellectual perspective taking of another person in a teaching-learning situation. Using case studies, we identified prospective primary teachers in a methods course using a 2-by-2 matrix based on their cognitive empathy and mathematical knowledge for teaching. We found that although in general prospective teachers are empathetic in nature, most of them are able to relate to struggling students from an affective aspect, and rarely from a cognitive stance. Empathy is a trait that can be developed and deep mathematical understanding is a requisite in developing cognitive empathy.;2011;2021-02-11T04:12:34Z;2021-02-11T04:12:34Z;NA;273-280;NA;NA;NA;NA;NA;NA;PME Conference Proceedings;NA;NA;NA;INT GRP PSYCHOL MATH EDUC;CHARLES UNIV PRAGUE, FAC EDUC, M D RETTIGOVE 4, PRAHA 1, 116 39, CZECH REPUBLIC;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Int Grp Psychol Math Educ ISSN: 0771-100X Type: Proceedings Paper;<p>35th Annual Conference of the International-Group-for-the-Psychology-of-Mathematics-Education (PME), Middle E Tech Univ, Ankara, TURKEY, JUL 10-15, 2011</p>;NA;NA;NA;NA;Ubuz, B;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EEZ2LM6D;journalArticle;2011;"Nordstrom, Katrina; Korpelainen, Paivi";Creativity and inspiration for problem solving in engineering education;TEACHING IN HIGHER EDUCATION;NA;1356-2517;10.1080/13562517.2011.560379;NA;Problem solving is a critical skill for engineering students and essential to development of creativity and innovativeness. Essential to such learning is an ease of communication and allowing students to address the issues at hand via the terminology, attitudes, humor and empathy, which is inherent to their frame of mind as novices, without the attempt to have to be the expert. Deep learning of scientific fact can be facilitated by using non-conventional tools for teaching, learning and presentation such as drama, video, posters, model making and other similar means. It may be time to break free of the PowerPoint tradition to generate successful approaches for establishing student engagement and maintaining such engagement.;2011;2021-02-11T04:12:34Z;2021-02-11T04:12:34Z;NA;439-450;NA;4;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"engineering education; group learning; problem solving; teaching science";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
59JJBLZ9;conferencePaper;2010;Kocoska, Jasminka;The influence of the simulation strategy over the improvement of the classroom climate;INNOVATION AND CREATIVITY IN EDUCATION;NA;NA;10.1016/j.sbspro.2010.03.583;NA;"The school climate is a process, structure of values and norms that canalize the teachers and the pupils in a direction of successful teaching and learning, increasing the effectiveness of the organizational set of the school building. The main aim of the simulation strategy is creating as much as possible closer situation to the real life or the pupils' life experience. Through this strategy the pupils learn certain principles, skills of understanding and cognitive thinking, psychomotor skills and values/ ways of behavior, connected with certain certification, influences, readiness, alertness and empathy. The aim of this research is directed to assessment of the influence of the simulation strategy over the improvement of the classroom climate. From the actions, in this research were used observant field notes, that enabled an insight of the event through direct listening and looking by the pupils, and conceptual field notes that enabled making conclusions from the observation. From the instruments for registering the data was used a protocol for observation, aimed to the students, the pupils were observed during the classes and during the break. Another instrument that was used for the research is the questionnaire, aimed to the teachers and the experts. The use of the simulation strategy has a great influence over the creation of a positive climate in the class that it isn't limited only in the process of classes realization, but it has broader and deeper dimension. It influences the positive dimension of the pupil's personality too as well as the development and straightening of the educational function of the school. That is why; in the future the teachers should continue to use this strategy and to specialize in this field so they can qualify the present and the future generations, in a quicker and easier way to solve the problems on personal, interpersonal, local and global level. (c) 2010 Elsevier Ltd. All rights reserved.";2010;2021-02-11T04:12:34Z;2021-02-11T04:12:34Z;NA;3751-3754;NA;NA;2;NA;NA;NA;Procedia Social and Behavioral Sciences;NA;NA;NA;ELSEVIER SCIENCE BV;SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 1877-0428 Issue: 2 Type: Proceedings Paper;<p>2nd World Conference on Educational Sciences (WCES-2010), Bahceschir Univ, Istanbul, TURKEY, FEB 04-08, 2010</p>;NA;NA;NA;"classroom climate; influence; pupil; Simulation strategy; teachers";Uzunboylu, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
97EG3489;journalArticle;NA;Ksiezopolska, Irena;Can Androids Write Science Fiction? Ian McEwan's Machines like Me;CRITIQUE-STUDIES IN CONTEMPORARY FICTION;NA;0011-1619;10.1080/00111619.2020.1851165;NA;McEwan's novel Machines Like Me was met with lukewarm reviews and open hostility of the sci-fi genre adherents. It seemed to have appropriated some of the key issues of the genre discourse - the question of what constitutes humanity, of the possibility of coexistence between humans and AI, of the problems of morality and consent. It also made use of time-honored devices of alternative history without treating it too seriously. Instead, the characters are enmeshed in personal problems and conundrums of science and politics, justice and empathy - and love. McEwan's commentary on the novel in various interviews only aggravated the critics who were all too ready to conclude that Machines Like Me offered little originality. This essay will demonstrate that the text is carefully layered as if to protect its own novelty hidden beneath rather conventional love triangle plot, ponderous political commentary, and genre-specific topicality. It will be an effort to understand the complex relation between the writer and conventions which come into play in his novel, and it will proceed to read the text against the authorial comments, finding suppressed hints that invite an interpretation of the text as narrated by its android hero rather than human subject.;NA;2021-02-11T04:13:19Z;2021-02-11T04:13:19Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article; Early Access";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JV2TUQX3;journalArticle;2020;Gramantieri, Riccardo;Alexithymic personality in Philip K. Dick'sDo androids dream of electric sheep?;NEOHELICON;NA;0324-4652;10.1007/s11059-020-00544-z;NA;"The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients' comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novelDo androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commentingDo androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick.";2020-12;2021-02-11T04:13:19Z;2021-02-11T04:13:19Z;NA;673-683;NA;2, SI;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Schizophrenia; Affective disorders; Alexithymia; Dick; Do androids dream of electric sheep?; Philip K";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EM67JWQP;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots;TOURISM MANAGEMENT;NA;0261-5177;10.1016/j.tourman.2019.104042;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WTVVEKVM;journalArticle;2020;"Sulistiadi, Wahyu; Nurhidayah, Siti; Asyary, Al";Evaluating the Management Information System of Integrated Medical Emergency Care in Batang Regency, Indonesia;INTERNATIONAL JOURNAL OF ONLINE AND BIOMEDICAL ENGINEERING;NA;NA;10.3991/ijoe.v16i07.14725;NA;An emergency can happen anywhere and anytime, especially in developing countries with a high potential for emergencies, such as Eastern European countries as well as Indonesia. This study aimed to find out the quality of PSC 119 Si Slamet as a prehospital emergency service innovation. The data collection in this study was carried out in a location, namely, Batang Regency, Indonesia, in May-June 2018. The qualitative data collection methods used in this study are in-depth interviews and document reviews. This study was using Service Quality (Servqual) questionnaire. The results show that PSC 119 Si Slamet provides easy access to emergency services to the community 24 hours a day and 7 days a week by simply calling 119 numbers, sending messages via SMS and WhatsApp, or using the Android-based application, with a maximum response time target of 10 minutes. Batang is one of the regencies (rural area) in Central Java province, located on the main coastline, with a hilly geographic condition with many derivatives, climbs, and sharp curves, which is one of the causes of the high number of traffic accidents in the area. This emergency care information systems, with Android-based application, was aimed at improving the quality of services in the health sector, especially emergency services. This service is of good quality as seen from the tangible, reliability, responsiveness, assurance, and empathy dimensions. However, in the implementation, the socialization aspect is not the best to some people. The recommendation given was the need to increase the PSC 119 socialization of Si Slamet not only regionally but also internationally to be massive, especially in developing countries.;2020;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;75-85;NA;7;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: KIRCHENGASSE 10-200, WIEN, A-1070, AUSTRIA Publisher: INT ASSOC ONLINE ENGINEERING Type: Article;NA;NA;NA;NA;"developing countries; health care information systems; Medical emergency; rural health services";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HT8SGZ74;conferencePaper;2019;"Anurrasyid, A.; Sumitra, I. D.";Elementary School Learning Media Application Based on Android with Customer Satisfaction Index Method;2ND INTERNATIONAL CONFERENCE ON INFORMATICS, ENGINEERING, SCIENCE, AND TECHNOLOGY (INCITEST 2019);NA;NA;10.1088/1757-899X/662/2/022017;NA;The objective of this research is to understand customer satisfaction, which is an assessment of a product or service that aims to improve the quality and service of a product or services. In this study the measurement method used is the Customer Satisfaction Index (CSI) method. This method is used to determine how much the level of user satisfaction with learning media applications. The result shows that the calculation of the level of customer satisfaction based on Tangibles, Reliability, Responsiveness, Assurance, and Empathy. The percentage value obtained is based on these five attributes using the Likert Scale, which is a scale of 1-5. Based on the results of the research conducted, the satisfaction of use in the application shows the criteria of satisfaction. This calculation is useful to find out the quality of this learning application. By knowing the value of satisfaction, it can be concluded that this application can help the learning process of children, however this application still not forgetting some suggestions from respondents to evaluate and improve the application to be even better.;2019;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;NA;NA;NA;662;NA;NA;NA;IOP Conference Series-Materials Science and Engineering;NA;NA;NA;IOP PUBLISHING LTD;DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Komputer Indonesia; RISTEKDIKTI ISSN: 1757-8981 Type: Proceedings Paper";<p>2nd International Conference on Informatics, Engineering, Science, and Technology (INCITEST) - Building Competitive Advantage to Face Industry 4.0, Bandung, INDONESIA, JUL 18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
UFGIIX8V;journalArticle;2018;"Shukla, Shanu; Sharma, Pritee";Emotions and Media Multitasking Behaviour among Indian College Students;JOURNAL OF CREATIVE COMMUNICATIONS;NA;0973-2586;10.1177/0973258618790794;NA;Media multitasking, a simultaneous consumption of two or more media, is a ubiquitous and popular behaviour among the youth. One of the reasons for its increasing growth is the structural/market-level factors (known as media factors). Although India is a growing technology hub, there have been limited efforts to identify the media multitasking behaviour among the youth in this country. Thus, this study attempts to analyse the prevalence of media multitasking behaviour among the Indian college students and its relationship with their emotions through two methods: self-report and an android-based application known as `Affective Media Landscape Survey' (AMLS). Previous studies have reported that continuous interaction with media diminishes face-to-face interaction, reduces empathy and increases the tendency to live in the virtual world. This raises the concern for emotional differences in everyday life, if any, between the high and low groups of media multitaskers. So the second objective of the study is to understand the emotional profile of the users that varies among media multitasking index. To achieve these objectives, the same two methods, the `self-report' that involves questionnaires and AMLS (an android-based app to study the frequency of media multitasking behaviour and the emotions of the users) have been employed. The study gives an insight into the emerging behavioural patterns and hence is helpful for designing communities to cater to the growing needs of the young media users.;2018-11;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;197-211;NA;3;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"emotions; Affective media landscape survey; media factors; media multitasking index";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6FPL4FPD;conferencePaper;2018;Brueckner, Sophia;Empathy Amulet: A Wearable to Connect with Strangers;ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS;978-1-4503-5967-2;NA;10.1145/3267242.3267301;NA;The Empathy Amulet is a wearable interpretation of Philip K. Dick's empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both haptically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today's world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson's theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4].;2018;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;248-253;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI; ACM SIGMOBILE; NOKIA Bell Labs; Intel; Microsoft; NAVER Lab; HUAWEI; Singapore Tourism Board; SG Singapore Type: Proceedings Paper";<p>ACM International Symposium on Wearable Computers, Google, Singapore, SINGAPORE, OCT 08-12, 2018</p>;NA;NA;NA;"Embodied cognition; haptic I/O; internet of things; prototyping; wearable electronics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WYYJQNYX;journalArticle;2018;Antsyferova, O. Yu.;PROBLEMATIZING HUMANNES, ANTICIPATING POSTHUMANSIM: PHILIP K. DICK'S “DO ANDROIDS DREAM OF ELECTRIC SHEEP?”;NOVYI FILOLOGICHESKII VESTNIK-NEW PHILOLOGICAL BULLETIN;NA;2072-9316;NA;NA;Written in 1968, the sci-fi novel by the American author Philip K. Dick “Do Androids Dream of Electric Sheep?” still retains the interest of the wide reading audience. The paper aims at elaborating upon the reasons for this lasting public enthusiasm which is claimed to relate not only to extremely successful film-versions of the book, but, even more so, to the highly topical message of the novel. In his antiutopian text, Philip K. Dick manages to put into focus the whole range of issues curraently associated with posthumanism. These are environmental problems caused by human activities, interplanet colonization escalating the conflicts of inclusion / exclusion, human / animal relations overlapping with the hybridization of natural and artificial, critical problems of future technological posthumanism manifesting themselves in highly problematic distinction between the humans and androids and in questioning the ontoethical status of the humans Philip K. Dick explores philosophical and social underpinnings of the catastrophic future which lies in wait for humanity and seems to strongly adhere to such humanistic values as empathy (the main touchstone to differentiate between humans and androids), self-reflection (the predominant feature of the protagonist Rick Deckard), search for identity and for meaning as the principal vectors of the human life, mercy for the mentally handicapped. Philip K. Dick's book can be viewed as one of the earliest caveats of the emerging trend to reconsider humanness in the sociocultural context of rapidly developing technology, various environmental threats, all kinds of hybridization and their ethical repercussions - and as such can be seen as truly prognostic, the most valuable part of it to be found in its ethical and social awareness and highly conscious refusal to suggest any final answer: essentially, the titled question seems eristically unanswerable.;2018;2021-02-11T04:13:20Z;2021-02-11T04:13:20Z;NA;197-207;NA;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MIUSSKAYA SQ 6, MOSCOW GSP-3, 125993, RUSSIA Publisher: RUSSIAN STATE UNIV HUMANITIES Type: Article;NA;NA;NA;NA;"empathy; (post)humanism; anti-utopia; historicism; humanness; ideology; Philip K. Dick";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ICLJHAF6;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-02-11T04:13:21Z;2021-02-11T04:13:21Z;NA;173-193;NA;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8RBH2ZZZ;journalArticle;2017;"Chikaraishi, Takenobu; Yoshikawa, Yuichiro; Ogawa, Kohei; Hirata, Oriza; Ishiguro, Hiroshi";Creation and Staging of Android Theatre “Sayonara” towards Developing Highly Human-Like Robots;FUTURE INTERNET;NA;1999-5903;10.3390/fi9040075;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017-12;2021-02-11T04:13:21Z;2021-02-11T04:13:21Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI AG Type: Article;NA;NA;NA;NA;"social robots; android theatre; contemporary colloquial theatre theory; robot theatre";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
JJAJSU86;journalArticle;2017;Lawrence, David;More Human than Human;CAMBRIDGE QUARTERLY OF HEALTHCARE ETHICS;NA;0963-1801;10.1017/S0963180116001158;NA;"Within the literature surrounding nonhuman animals on the one hand and cognitively disabled humans on the other, there is much discussion of where beings that do not satisfy the criteria for personhood fit in our moral deliberations. In the future, we may face a different but related problem: that we might create (or cause the creation of) beings that not only satisfy but exceed these criteria. The question becomes whether these are minimal criteria, or hierarchical, such that those who fulfill them to greater degree should be afforded greater consideration. This article questions the validity and necessity of drawing divisions among beings that satisfy the minimum requirements for personhood; considering how future beings-intelligent androids, synthezoids, even alternate-substrate sentiences-might fit alongside the “baseline” human. I ask whether these alternate beings ought to be considered different to us, and why this may or may not matter in terms of a notion of “human community.” The film Blade Runner, concerned in large part with humanity and its key synthezoid antagonist Roy Batty, forms a framing touchstone for my discussion. Batty is stronger, faster, more resilient, and more intelligent than Homo sapiens. His exploits, far beyond the capability of normal humans, are contrasted with his frailty and transient lifespan, his aesthetic appreciation of the sights he has seen, and his burgeoning empathy. Not for nothing does his creator within the mythos term him “more human than human.”";2017-07;2021-02-11T04:13:21Z;2021-02-11T04:13:21Z;NA;476-490;NA;3;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA Publisher: CAMBRIDGE UNIV PRESS Type: Article;NA;NA;NA;NA;"artificial intelligence; enhancement; humanity; novel beings; personhood; posthuman";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
87DLWU42;journalArticle;2016;"Matsuda, Goh; Hiraki, Kazuo; Ishiguro, Hiroshi";EEG-Based Mu Rhythm Suppression to Measure the Effects of Appearance and Motion on Perceived Human Likeness of a Robot;JOURNAL OF HUMAN-ROBOT INTERACTION;NA;2163-0364;10.5898/JHRI.5.1.Matsuda;NA;We performed two electroencephalogram (EEG) experiments to examine how humanoid robot appearance and motion affect human subjects' perception of the robots. Mu rhythm suppression of EEG, which is considered to reflect mirror neuron system (MNS) activation, was regarded as a neurological indicator of perceived human likeness. Video clips depicting upper-body actions performed by three agents (human, android, and mechanical robot) were presented in experiment 1. In experiment 2, point-light motion (PLM) stimuli generated from experiment 1 stimuli were presented. The results of experiment 1 revealed that only the human and android actions evoked significant mu suppression. No PLM stimulus elicited significant mu suppression in experiment 2. These findings suggest that an overall human-like form is necessary to activate the MNS.;2016;2021-02-11T04:13:21Z;2021-02-11T04:13:21Z;NA;68-81;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNAL HUMAN-ROBOT INTERACTION, STANFORD, CA 00000 USA Publisher: JOURNAL HUMAN-ROBOT INTERACTION Type: Article;NA;NA;NA;NA;"EEG; humanoid robot; android; mirror neuron; mu suppression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
R4MAIGTS;conferencePaper;2016;"Ranieri, Caetano M.; Romero, Roseli A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016;978-1-5090-3656-1;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016;2021-02-11T04:13:21Z;2021-02-11T04:13:21Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Brazilian Comp Soc; Centro Estudos Sistemas Avancados Recife; Centro Informatica UFPE; ROBOLIURE; VIRTUS IMPAVIDA; Inst Inovacao; Robolivre; CAPES; Inst SENAI Inovacao; Conselho Nacl Desenvolvimento Cientifico Tecnologico; Fundacao Amparo Ciencia Tecnologia Estado Pernambuco; IEEE Robot & Automat Soc Chapter Brazil; IEEE Latin Amer Robot Council Type: Proceedings Paper";<p>13th Latin American Robotics Symposium / 4th Brazilian Robotics Symposium (LARS/SBR), Recife, BRAZIL, OCT 08-12, 2016</p>;NA;NA;NA;NA;Cavalcante, SV and Tonidandel, F;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
EPJFJKKI;journalArticle;2016;"Lawson, Louise; Cane, Simon";Do conservators dream of electric sheep? Replicas and replication;STUDIES IN CONSERVATION;NA;0039-3630;10.1080/00393630.2016.1181348;NA;"The paper crosses the boundaries between different genres, drawing on key material and emphasising the philosophical challenges around decision-making and values in relation to replication and replicas. In 1968, Philip K. Dick wrote the book Do Androids Dream of Electric Sheep? which became the inspiration for the 1982 film Bladerunner. The book is set in Los Angeles in a post-apocalyptic future where mankind has left Earth, resulting in androids being created to develop new `off-world' colonies. The book and film create a novel and interesting framework to discuss the subject of replicas and replication within contemporary conservation practice. Key themes are decay promoting replication, original versus replica, creating empathy in replication. The debate focuses on the case study of Naum Gabo's Construction in Space (Crystal) of 1937-39; which was the sculpture replicated in the most recent replication project at Tate, completed in July 2015.";2016;2021-02-11T04:13:22Z;2021-02-11T04:13:22Z;NA;109-113;NA;2, SI;61;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"Empathy; Decay; Gabo; Original; Replica; Replicants";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6CKIL7AD;conferencePaper;2016;"Sorbello, Rosario; Chella, Antonio; Giardina, Marcello; Nishio, Shuichi; Ishiguro, Hiroshi";An Architecture for Telenoid Robot as Empathic Conversational Android Companion for Elderly People;IN℡LIGENT AUTONOMOUS SYSTEMS 13;978-3-319-08338-4 978-3-319-08337-7;NA;10.1007/978-3-319-08338-4_68;NA;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic human-android interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user.;2016;2021-02-11T04:13:22Z;2021-02-11T04:13:22Z;NA;939-953;NA;NA;302;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Univ Padova ISSN: 2194-5357 Type: Proceedings Paper;<p>13th International Conference on Intelligent Autonomous Systems (IAS), Centro Congressi Padova, Padova, ITALY, JUL 15-18, 2014</p>;NA;NA;NA;"Humanoid robot; Humanoid robot interaction; Life support empathic robot; Telenoid";Menegatti, E and Michael, N and Berns, K and Yamaguchi, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
MCSDSAYT;journalArticle;2015;"de Borst, Aline W.; de Gelder, Beatrice";Is it the real deal? Perception of virtual characters versus humans: an affective cognitive neuroscience perspective;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2015.00576;NA;Recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film, avatars, or androids. These stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control. While avatars and androids are well suited to study human cognition, they should not be equated to human stimuli. For example, the uncanny valley hypothesis theorizes that artificial agents with high human-likeness may evoke feelings of eeriness in the human observer. Here we review if, when, and how the perception of human-like avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies. First, we discuss how the appearance of virtual characters affects perception. When stimuli are morphed across categories from non-human to human, the most ambiguous stimuli, rather than the most human-like stimuli, show prolonged classification times and increased eeriness. Human-like to human stimuli show a positive linear relationship with familiarity. Secondly, we show that expressions of emotions in human-like avatars can be perceived similarly to human emotions, with corresponding behavioral, physiological and neuronal activations, with exception of physical dissimilarities. Subsequently, we consider if and when one perceives differences in action representation by artificial agents versus humans. Motor resonance and predictive coding models may account for empirical findings, such as an interference effect on action for observed human-like, natural moving characters. However, the expansion of these models to explain more complex behavior, such as empathy, still needs to be investigated in more detail. Finally, we broaden our outlook to social interaction, where virtual reality stimuli can be utilized to imitate complex social situations.;2015-05-12;2021-02-11T04:13:22Z;2021-02-11T04:13:22Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Review;NA;NA;NA;NA;"fMRI; virtual reality; social interaction; uncanny valley; action perception; emotion perception; naturalistic stimuli; virtual characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GEYX7RJF;journalArticle;2015;Pare, Zaven;The Art of Being Together with Robots: A Conversation with Professor Hiroshi Ishiguro;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0264-9;NA;The content of this article is primarily a transcription of two events: A demo of a video-conference with the Geminoid HI-2 at Osaka University (Systems Innovation Department in the Graduate School of Engineering), and a conversation about Geminoids with Professor Hiroshi Ishiguro at ATR (Advanced Telecommunication Research Institute International-Kyoto). As Professor Ishiguro says during the conversation, his quest “is harmony between humans and robots”. By creating and manipulating androids (human-like appearance robot), the roboticist reveals and highlights the assembly, disassembly and reconfigurations of human representation and human presence.;2015-02;2021-02-11T04:13:22Z;2021-02-11T04:13:22Z;NA;129-136;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Telepresence; Familiarity; Geminoid; Human likeness; Sympathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FMEICKBS;journalArticle;2014;"Hofree, Galit; Ruvolo, Paul; Bartlett, Marian Stewart; Winkielman, Piotr";Bridging the Mechanical and the Human Mind: Spontaneous Mimicry of a Physically Present Android;PLOS ONE;NA;1932-6203;10.1371/journal.pone.0099934;NA;The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android “humanlike.” These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.;2014-07-18;2021-02-11T04:13:22Z;2021-02-11T04:13:22Z;NA;NA;NA;7;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA Publisher: PUBLIC LIBRARY SCIENCE Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GZTXPW6J;conferencePaper;2014;Yamazaki, Ryuji;Conditions of Empathy in Human-Robot Interaction;SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS;978-1-61499-480-0 978-1-61499-479-4;NA;10.3233/978-1-61499-480-0-179;NA;The purpose of this paper is to consider the sociality of social robots with the focus on the notion of empathy. Social robots are designed to exploit various biological mechanisms that trigger anthropomorphizing reactions in humans and systems that seem capable of experiencing or feeling are being constructed. A question is whether empathic reactions by humans are justifiable from a conceptual and ethical point of view. I will mainly address the conceptual strand of this question and investigate whether empathy with robots is appropriate or misapplied relative to our current concept of empathy.;2014;2021-02-11T04:13:23Z;2021-02-11T04:13:23Z;NA;179-186;NA;NA;273;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;ISSN: 0922-6389 Type: Proceedings Paper;<p>Conference on Robo-Philosophy - Sociable Robotics and the Future of Social Relations, Aarhus, DENMARK, AUG 20-23, 2014</p>;NA;NA;NA;"emotion; empathy; embodiment; android; alteration; openness; subjectivity";Seibt, J and Hakli, R and Norskov, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RMIW8LSS;journalArticle;2013;Toth, Josh;Do Androids Eat Electric Sheep?: Egotism, Empathy, and the Ethics of Eating in the Work of Philip K. Dick;LIT-LITERATURE INTERPRETATION THEORY;NA;1043-6928;10.1080/10436928.2013.754238;NA;NA;2013-01-01;2021-02-11T04:13:23Z;2021-02-11T04:13:23Z;NA;65-85;NA;1;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U4B57355;journalArticle;2013;"Urgen, Burcu A.; Plank, Markus; Ishiguro, Hiroshi; Poizner, Howard; Saygin, Ayse P.";EEG theta and Mu oscillations during perception of human and robot actions;FRONTIERS IN NEUROROBOTICS;NA;1662-5218;10.3389/fnbot.2013.00019;NA;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other.;2013;2021-02-11T04:13:23Z;2021-02-11T04:13:23Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"EEG; social robotics; action perception; mirror neuron system; mu rhythm; theta rhythm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FDFAFYYJ;journalArticle;2020;"Rueda, Jon; Lara, Francisco";Virtual Reality and Empathy Enhancement: Ethical Aspects;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.506984;NA;The history of humankind is full of examples that indicate a constant desire to make human beings more moral. Nowadays, technological breakthroughs might have a significant impact on our moral character and abilities. This is the case of Virtual Reality (VR) technologies. The aim of this paper is to consider the ethical aspects of the use of VR in enhancing empathy. First, we will offer an introduction to VR, explaining its fundamental features, devices and concepts. Then, we will approach the characterization of VR as an “empathy machine,” showing why this medium has aroused so much interest and why, nevertheless, we do not believe it is the ideal way to enhance empathy. As an alternative, we will consider fostering empathy-related abilities through virtual embodiment in avatars. In the conclusion, however, we will examine some of the serious concerns related to the ethical relevance of empathy and will defend the philosophical case for a reason-guided empathy, also suggesting specific guidelines for possible future developments of empathy enhancement projects through VR embodied experiences.;2020-11-09;2021-02-11T04:15:43Z;2021-02-11T04:15:43Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; virtual reality; applied ethics; empathy enhancement; moral enhancement; moral psychology; neuroethics; virtual embodiment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4PRSL7PM;journalArticle;NA;"Dorn, A. Walter; Dawson, Peter F.";Simulating Peace Operations: New Digital Possibilities for Training and Public Education;SIMULATION & GAMING;NA;1046-8781;10.1177/1046878120968605;NA;Background and Motivation. A plethora of warfighting games exist commercially, but there is a lack of digital games that deal with peace processes. Furthermore, none simulate actual peacekeeping. The United Nations currently deploys about 100,000 peacekeepers to some of the world's most dangerous zones, where peacekeepers save lives, alleviate suffering, and help create conditions for peace. The United Nations and national militaries lack peacekeeping simulations to help train their soldiers. Additionally, the public needs to learn more about the way peacekeeping works. Thus, peacekeeping simulation and gaming are worth exploring, especially in the rapidly evolving digital space, which offers new avenues and benefits. Methods. We review the meager literature on the subject and observe that there are few digital games to directly draw from. We build on previous work that argued the need for such development, but we now assess important design principles and parameters. We draw upon peacekeeping tabletop exercises that are already well developed. Results. We conclude that excellent scenarios and simulation technologies exist that could be combined quite easily for effective peacekeeping training and public education. We find key materials and scenarios in exercises of the United Nations and of the Pearson Peacekeeping Centre. Highlighted areas for future digital design are the inclusion of non-military avatars, emphasis on soft skills development (especially empathy), and realistically complex links between actions and consequences. Conclusion. While describing some UN exploration at a proof-of-concept stage, we suggest that both the United Nations and the gaming industry should explore the idea further to achieve synergies between institutional and entertainment applications. The growing capacity of digital technology allows significant innovation, yielding results that could be useful, ethical, enjoyable, and potentially profitable.;NA;2021-02-11T04:15:43Z;2021-02-11T04:15:43Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article; Early Access";NA;NA;NA;NA;"empathy; digital games; peace operations; peace simulation; peacekeeping; stability operations; training < objective; United Nations; virtual gaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BCT34BBD;journalArticle;2020;"Patane, Ivan; Lelgouarch, Anne; Banakou, Domna; Verdelet, Gregoire; Desoche, Clement; Koun, Eric; Salemme, Romeo; Slater, Mel; Farne, Alessandro";Exploring the Effect of Cooperation in Reducing Implicit Racial Bias and Its Relationship With Dispositional Empathy and Political Attitudes;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2020.510787;NA;Previous research using immersive virtual reality (VR) has shown that after a short period of embodiment by White people in a Black virtual body, their implicit racial bias against Black people diminishes. Here we tested the effects of some socio-cognitive variables that could contribute to enhancing or reducing the implicit racial bias. The first aim of the study was to assess the beneficial effects of cooperation within a VR scenario, the second aim was to provide preliminary testing of the hypothesis that empathy and political attitudes could contribute to implicit bias about race, while the third aim was to explore the relationship between political attitudes and empathy. We had (Caucasian) participants embodied in a Black virtual body and engaged either in a cooperative (Coop group) or in a non-cooperative (Neutral group) activity with a confederate experimenter embodying another Black avatar. Before and after VR, we measured participants' implicit racial bias by means of Implicit Association Test (IAT) and their perceived closeness toward the confederate experimenter. Before VR we also assessed participants' political attitudes and empathy traits. Results revealed that, as compared to the Neutral group, the Coop group showed lower IAT scores after the social interaction. Interestingly, in the Neutral but not the Coop group the perceived closeness toward the confederate experimenter was associated with the initial racial bias: the more the participants reduced their distance, the more they reduced their IAT score. Moreover, reported traits of empathy and political attitudes significantly explained the variance observed in the initial implicit bias, with perspective-taking, empathic concern, and personal distress being significant predictors of the IAT scores. Finally, there was a relationship between political attitudes and empathy: the more participants considered themselves as left-wing voters, the higher their perspective-taking and empathic concern scores. We discuss these findings within the neuroscientific and social cognition field and encourage scholars from different domains to further explore whether and under which conditions a given manipulation for reducing racial bias could be efficiently transposed in VR.;2020-10-28;2021-02-11T04:15:43Z;2021-02-11T04:15:43Z;NA;NA;NA;NA;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; virtual reality; embodiment; cooperation; implicit association test; implicit racial bias; inclusion of the other in the self; political attitudes";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
TAUDXCY4;journalArticle;NA;Lindner, Philip;Better, Virtually: the Past, Present, and Future of Virtual Reality Cognitive Behavior Therapy;INTERNATIONAL JOURNAL OF COGNITIVE THERAPY;NA;1937-1209;10.1007/s41811-020-00090-7;NA;Virtual reality (VR) is an immersive technology capable of creating a powerful, perceptual illusion of being present in a virtual environment. VR technology has been used in cognitive behavior therapy since the 1990s and accumulated an impressive evidence base, yet with the recent release of consumer VR platforms came a true paradigm shift in the capabilities and scalability of VR for mental health. This narrative review summarizes the past, present, and future of the field, including milestone studies and discussions on the clinical potential of alternative embodiment, gamification, avatar therapists, virtual gatherings, immersive storytelling, and more. Although the future is hard to predict, clinical VR has and will continue to be inherently intertwined with what are now rapid developments in technology, presenting both challenges and exciting opportunities to do what is not possible in the real world.;NA;2021-02-11T04:15:44Z;2021-02-11T04:15:44Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND Publisher: SPRINGER INTERNATIONAL PUBLISHING AG Type: Article; Early Access";NA;NA;NA;NA;"Gamification; Virtual reality; Embodiment; Avatar; Immersion; Serious game";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BG493IC4;journalArticle;NA;"Kuester, Dennis; Swiderska, Aleksandra";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;INTERNATIONAL JOURNAL OF PSYCHOLOGY;NA;0020-7594;10.1002/ijop.12715;NA;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.;NA;2021-02-11T04:15:44Z;2021-02-11T04:15:44Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND Publisher: JOHN WILEY & SONS LTD Type: Article; Early Access";NA;NA;NA;NA;"Robots; Benevolent intentions; Dehumanisation; Mind perception; Moral typecasting theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
VSU65I8X;journalArticle;2020;"Lesur, Marte Roel; Lyn, Sonia; Lenggenhager, Bigna";How Does Embodying a Transgender Narrative Influence Social Bias? An Explorative Study in an Artistic Context;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2020.01861;NA;Virtual reality (VR) protocols inducing illusory embodiment of avatars have shown a positive impact on participants' perception of outgroup members, in line with the idea that the simulation of another's sensorimotor states might underlie prosocial behavior. These studies, however, have been mostly confined to laboratory settings with student populations and the use of artificial avatars. In an interdisciplinary effort benefiting from the heterogeneous sample within a museum, we aimed at quantifying changes in interpersonal perception induced by embodying a transgender man narrating his life. We compared an artistic methodology mixing VR and elaborate sensorimotor stimulation to a more conventional primarily audiovisual VR experience. We tested how these affect embodiment and the perception of transgender men as measured by a brief implicit association test and a questionnaire. Neither significant difference in embodiment nor changes in implicit or explicit bias was found, the latter potentially due to the initially low bias in the group. We further assessed participants' illusory embodiment as a function of age, finding a negative correlation between these. The results are discussed with respect to current theories of embodiment, differences between laboratory and real-life settings, and the intersection of art and science.;2020-08-04;2021-02-11T04:15:44Z;2021-02-11T04:15:44Z;NA;NA;NA;NA;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"social cognition; embodiment; art-science dialogue; naturalistic settings; sensorimotor sharing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2TF4K9BL;journalArticle;2020;"Landau, Daniel H.; Hasler, Beatrice S.; Friedman, Doron";Virtual Embodiment Using 180 degrees Stereoscopic Video;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2020.01229;NA;One of the most exciting possibilities of virtual reality is inducing in participants the illusion of owning a virtual body. This has become an established methodological paradigm allowing the study of the psychological and neural correlates of various scenarios that are impossible in the real world, such as gender or age switching. Thus far, full-body ownership illusions have been implemented by using real-time body tracking and avatars based on computer-generated imagery (CGI). We propose an alternative technique to induce perceived ownership over a (photorealistic) virtual body using 180 degrees stereoscopic video, synchronous touch, and narration. We describe the technical components of our novel technique and an example implementation as part of a science-art project that enables participants to experience virtual bodies of different ages, and present the results of an experimental evaluation study based on this experience. Consistent with previous virtual embodiment studies using CGI-based techniques, we found that participants accept a photorealistic virtual body as their own irrespective of its appearance as indicated by similar ratings of the strength of body ownership over a virtual body of a child versus an adult. We further show that our novel technique can alter participants' cognition in accordance with the characteristics of their virtual body. Specifically, young adult participants who were embodied in the virtual body of a child significantly overestimated the duration of the virtual reality experience compared to a control group who was embodied in a virtual body of their own age. This finding corresponds to chronological age differences in time estimations and extends previous research on virtual child embodiment. Overall, these findings provide initial evidence for the potential of our novel technique to create photorealistic embodiment experiences with comparable psychological effects as have been found using CGI-based techniques while reducing the costs and technical complexity in the production and application of virtual body ownership illusions.;2020-07-07;2021-02-11T04:15:44Z;2021-02-11T04:15:44Z;NA;NA;NA;NA;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"cognition; virtual reality; virtual embodiment; 180 degrees video; body ownership illusion; self-transformation; time perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X2VSTTFL;journalArticle;2020;"D'Agostini, Martina; Karos, Kai; Kindermans, Hanne P. J.; Vancleef, Linda M. G.";Effects of (in)validation and plain versus technical language on the experience of experimentally induced pain: A computer controlled simulation paradigm;JOURNAL OF BEHAVIOR THERAPY AND EXPERIMENTAL PSYCHIATRY;NA;0005-7916;10.1016/j.jbtep.2019.03.008;NA;"Background and objectives: Amongst social contextual influences on pain, the manner in which pain and painful procedures are communicated to patients is considered an important contributor to the subjective experience of pain. Threatening information, e.g., by the use of technical language, is suggested to increase pain reports. Validation, or communicating understanding towards another person reporting personal experiences, is suggested to reduce pain. The current study examines effects of both information language (technical vs. plain language) and validation (validation vs. invalidation) on the subjective experience of experimentally induced pain. Methods: Pain-free participants (N = 132) were randomly assigned to one of four groups as formed by manipulations of validation and information language. After reading a description concerning the upcoming thermal stimulus formulated in technical or plain language, participants engaged in a computer controlled simulation (CCS; based on virtual reality technology). Participants received three thermal stimuli while interacting with an avatar who either validated or invalidated their experience during the CCS. Pain intensity and pain unpleasantness were assessed after each stimulus. Results: The validation manipulation showed to be effective, but the information language manipulation did not induce differential threat expectancies. Results show no effect of validation or information language on subjective pain reports. Limitations: Suboptimality of the information language manipulation and shortcomings of the CCS procedure might account for current findings. Conclusions: The study offers an interesting model for the further experimental study of isolated and combined effects of (social) contextual factors on pain. Diverse future research avenues are discussed.";2020-06;2021-02-11T04:15:44Z;2021-02-11T04:15:44Z;NA;NA;NA;SI;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Context; Virtual reality; (in)validation; Computer controlled simulation; Pain communication; Pain experience; Thermal pain";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6QRFEC5J;journalArticle;2020;"Miloff, Alexander; Carlbring, Per; Hamilton, William; Andersson, Gerhard; Reuterskiold, Lena; Lindner, Philip";Measuring Alliance Toward Embodied Virtual Therapists in the Era of Automated Treatments With the Virtual Therapist Alliance Scale (VTAS): Development and Psychometric Evaluation;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/16660;NA;"Background: Automated virtual reality exposure therapies (VRETs) are self-help treatments conducted by oneself and supported by a virtual therapist embodied visually and/or with audio feedback. This simulates many of the nonspecific relational elements and common factors present in face-to-face therapy and may be a means of improving adherence to and efficacy of self-guided treatments. However, little is known about alliance toward the virtual therapist, despite alliance being an important predictor of treatment outcome. Objective: In this study, we aimed to evaluate the first alliance instrument developed for use with embodied virtual therapists in an automated treatment format-the Virtual Therapist Alliance Scale (VTAS)-by (1) assessing its psychometric properties, (2) verifying the dimensionality of the scale, and (3) determining the predictive ability of the scale with treatment outcome. Methods: A psychometric evaluation and exploratory factor analysis of the VTAS was conducted using data from two samples of spider-fearful patients treated with VRET and the help of an embodied, voice-based virtual therapist (n=70). Multiple regression models and bivariate correlations were used to assess the VTAS relationship with treatment outcome, according to self-reported fear and convergence with presence and user-friendliness process measures. Results: The VTAS showed a sound two-factor solution composed of a primary factor covering task, goal, and copresence; adequate internal consistency; and good convergent validity, including moderate correlation (r= . 310, P=.01) with outcomes over follow-up. Conclusions: These preliminary results suggest that alliance toward a virtual therapist is a significant predictor of treatment outcome, favors the importance of a task-goal over bond-factor, and should be explored in studies with larger sample sizes and in additional forms of embodiment.";2020-03-24;2021-02-11T04:15:45Z;2021-02-11T04:15:45Z;NA;NA;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"empathy; virtual reality; embodiment; presence; avatar; alliance; automated treatment; exposure therapy; psychometric; usability; virtual coach; virtual therapist";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QNACR4XE;journalArticle;2020;"Kegel, Lorena C.; Brugger, Peter; Fruhholz, Sascha; Grunwald, Thomas; Hilfiker, Peter; Kohnen, Oona; Loertscher, Miriam L.; Mersch, Dieter; Rey, Anton; Sollfrank, Teresa; Steiger, Bettina K.; Sternagel, Joerg; Weber, Michel; Jokeit, Hennric";Dynamic human and avatar facial expressions elicit differential brain responses;SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE;NA;1749-5016;10.1093/scan/nsaa039;NA;Computer-generated characters, so-called avatars, are widely used in advertising, entertainment, human-computer interaction or as research tools to investigate human emotion perception. However, brain responses to avatar and human faces have scarcely been studied to date. As such, it remains unclear whether dynamic facial expressions of avatars evoke different brain responses than dynamic facial expressions of humans. In this study, we designed anthropomorphic avatars animated with motion tracking and tested whether the human brain processes fearful and neutral expressions in human and avatar faces differently. Our fMRI results showed that fearful human expressions evoked stronger responses than fearful avatar expressions in the ventral anterior and posterior cingulate gyrus, the anterior insula, the anterior and posterior superior temporal sulcus, and the inferior frontal gyrus. Fearful expressions in human and avatar faces evoked similar responses in the amygdala. We did not find different responses to neutral human and avatar expressions. Our results highlight differences, but also similarities in the processing of fearful human expressions and fearful avatar expressions even if they are designed to be highly anthropomorphic and animated with motion tracking. This has important consequences for research using dynamic avatars, especially when processes are investigated that involve cortical and subcortical regions.;2020-03;2021-02-11T04:15:45Z;2021-02-11T04:15:45Z;NA;347-358;NA;3;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article;NA;NA;NA;NA;"fMRI; emotion; avatar; computer-generated character; face";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
I8TT9DXS;journalArticle;2019;"Wilde, Poppy; Evans, Adrienne";Empathy at play: Embodying posthuman subjectivities in gaming;CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA TECHNOLOGIES;NA;1354-8565;10.1177/1354856517709987;NA;In this article, we address the need for a posthuman account of the relationship between the avatar and player. We draw on a particular line of posthumanist theory associated closely with the work of Karen Barad, Rosi Braidotti and N. Katherine Hayles that suggests a constantly permeable, fluid and extended subjectivity, displacing the boundaries between human and other. In doing so, we propose a posthuman concept of empathy in gameplay, and we apply this concept to data from the first author's 18-month ethnographic field notes of gameplay in the MMORPG World of Warcraft. Exploring these data through our analysis of posthuman empathy, we demonstrate the entanglement of avatar-player, machine-human relationship. We show how empathy allows us to understand this relationship as constantly negotiated and in process, producing visceral reactions in the intra-connected avatar-player subject as well as moments of co-produced in-game action that require `affective matching' between subjective and embodied experiences. We argue that this account of the avatar-player relationship extends research in game culture, providing a horizontal, non-hierarchical discussion of its most necessary interaction.;2019-12;2021-02-11T04:15:45Z;2021-02-11T04:15:45Z;NA;791-806;NA;5-6;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"empathy; posthuman; embodiment; Avatar-player relationships; digital culture; MMORPG; posthuman empathy; posthuman subjectivity; World of Warcraft";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RV4DXJ5R;journalArticle;2019;"Agopyan, H.; Griffet, J.; Poirier, T.; Bredin, J.";Modification of knee flexion during walking with use of a real-time personalized avatar;HELIYON;NA;2405-8440;10.1016/j.heliyon.2019.e02797;NA;Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed.;2019-11;2021-02-11T04:15:45Z;2021-02-11T04:15:45Z;NA;NA;NA;11;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Rehabilitation; Empathy; Neuroscience; Sympathy; Avatar; Adaptation; Biomedical engineering; Knee flexion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WB8RV5T3;journalArticle;2019;"Shorey, Shefaly; Ang, Emily; Yap, John; Ng, Esperanza Debby; Lau, Siew Tiang; Chui, Chee Kong";A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education: Development Study;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/14658;NA;Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019-10-29;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"artificial intelligence; learning; communication; virtual reality; technology; nursing education; patients";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
GWSMC85H;journalArticle;2019;"Tessier, Marie-Helene; Gingras, Chloe; Robitaille, Nicolas; Jackson, Philip L.";Toward dynamic pain expressions in avatars: Perceived realism and pain level of different action unit orders;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2019.02.001;NA;"The facial expression of pain can be decomposed in three sets of Action Units (AUs), the smallest discriminating facial movements: Brow lowering (B), Nose wrinkling + Upper lip raising (N), and Orbit tightening + Eyelid closure (O). This study compared the perception of realism and pain level from different onset orders of AUs in avatars. Seven videos of facial expressions of pain were created with four different avatars (2 women): six sequential onsets combining the three sets of AUs and one synchronized onset. 45 healthy adults (22 women; aged 23.6 +/- 5.2 years) rated the realism of facial movements, and the level of intensity and unpleasantness of perceived pain. A more realistic expression was associated with the onset of O before or at the same time as N, a more intense expression was associated when B occurred last, and a higher level of unpleasantness was associated with the onset of N before B. Therefore, the sequence ONB yielded the highest ratings on both measures of realism and pain levels. These findings describe the perceived content of different orders of facial movements that could contribute to the creation of realistic pain-expressing virtual agents designed to study human-computer interactions.";2019-07;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;95-109;NA;NA;96;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Perception; Action units; Behavioral realism; Dynamic facial expressions; Pain of others; Virtual agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
B3JSMQXX;journalArticle;2019;MacDorman, Karl F.;In the uncanny valley, transportation predicts narrative enjoyment more than empathy, but only for the tragic hero;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2019.01.011;NA;"The uncanny valley is a term used to describe the phenomenon that human simulations that are nearly but not quite realistic often give viewers an uneasy, eerie feeling. Given the prevalence of computer-animated human characters and a narrative framework in videogames, serious games, and health-related scenarios, it is important to examine how the uncanny valley influences narrative empathy and enjoyment. In a 2 x 2 x 2 between-groups posttest-only experiment, 738 participants took the role of a patient in a virtual consultation with a doctor; the consultation varied in the doctor's character (hero or villain), its subplot ending (happy or tragic), and its depiction (computer animated or real). The participants' posttest results showed greater emotional empathy and enjoyment in the hero condition and no significant difference in emotional empathy for the computer animation but greater narrative enjoyment and persuasion. Just endings (hero rewarded, villain punished) elicited much greater pleasure than unjust endings. In comparing computer animation with recorded video, emotional empathy was a significantly stronger predictor of narrative enjoyment than transportation only for the real hero with a tragic ending. The enjoyment and persuasiveness of the computer-animated doctor patient consultation bodes well for the use of animation in interactive visual narratives.";2019-05;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;140-153;NA;NA;94;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Uncanny valley; Avatars; Anthropomorphism; Computer animation; Emotional empathy; Interactive narratives";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
D6Z22FB7;journalArticle;2019;"Kuester, Dennis; Krumhuber, Eva G.; Hess, Ursula";You are What You Wear: Unless You MovedEffects of Attire and Posture on Person Perception;JOURNAL OF NONVERBAL BEHAVIOR;NA;0191-5886;10.1007/s10919-018-0286-3;NA;While first impressions are often based on appearance cues, little is known about how these interact with information from other channels. The present research aimed to investigate the impact of occupational stereotypes, evoked by attire, as well as posture on person perception. For this, computer animation was used to create avatars with different types of attire (nurse, military, casual) and posture (open, closed). In Study 1 (N=164), participants attributed significantly more empathy to avatars wearing a nurse versus a military uniform or casual outfit. When adding posture as an additional cue, Study 2 (N=312) showed that ratings of empathy and dominance were affected by both attire and posture. This effect was replicated in Study 3 (N=163) for female avatars, in the sense that open postures in nurses increased empathy ratings and decreased dominance ratings, which both in turn led to greater perceived competence. By contrast, for male avatars, posture did not affect attributions of competence directly. Rather, attire predicted perceived dominance directly, as well as through perceived empathy. The present findings suggest that both posture, and occupational information evoked by attire, are used to infer personal characteristics. However, the strength of each cue may vary with the gender of the target.;2019-03;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;23-38;NA;1;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Dominance; Empathy; Body posture; Clothing; Competence; Occupational stereotypes; Warmth";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E4HJ9T2W;journalArticle;2019;"Gallup, Andrew C.; Vasilyev, Daniil; Anderson, Nicola; Kingstone, Alan";Contagious yawning in virtual reality is affected by actual, but not simulated, social presence;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-018-36570-2;NA;Contagious yawning occurs in humans and a few other highly social animals following the detection of yawns in others, yet the factors influencing the propagation of this response remain largely unknown. Stemming from earlier laboratory research, we conducted five experiments to investigate the effects of social presence on contagious yawning in virtual reality (VR). We show that, similar to a traditional laboratory setting, having a researcher present during testing significantly inhibited contagious yawning in VR, even though participants were viewing a virtual environment and unable to see the researcher. Unlike previous research, however, manipulating the social presence in VR (i.e., embedding recording devices and humanoid avatars within the simulation) did not affect contagious yawning. These experiments provide further evidence that social presence is a powerful deterrent of yawning in humans, which warrants further investigation. More generally, these findings also have important applications for the use of VR in psychological research. While participants were quite sensitive to social stimuli presented in VR, as evidenced by contagious yawning, our results suggest a major difference in the influence of social factors within real-world and virtual environments. That is, social cues in actual reality appear to dominate and supersede those in VR.;2019-01-22;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6ECVWIMH;conferencePaper;2019;"Krekhov, Andrey; Cmentowski, Sebastian; Emmerich, Katharina; Krueger, Jens";Beyond Human: Animals as an Escape from Stereotype Avatars in Virtual Reality Games;CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY;978-1-4503-6688-5;NA;10.1145/3311350.3347172;NA;Virtual reality setups are particularly suited to create a tight bond between players and their avatars up to a degree where we start perceiving the virtual representation as our own body. We hypothesize that such an illusion of virtual body ownership (IVBO) has a particularly high, yet overlooked potential for nonhumanoid avatars. To validate our claim, we use the example of three very different creatures-a scorpion, a rhino, and a bird-to explore possible avatar controls and game mechanics based on specific animal abilities. A quantitative evaluation underpins the high game enjoyment arising from embodying such nonhuman morphologies, including additional body parts and obtaining respective superhuman skills, which allows us to derive a set of novel design implications. Furthermore, the experiment reveals a correlation between IVBO and game enjoyment, which is a further indication that nonhumanoid creatures offer a meaningful design space for VR games worth further investigation.;2019;2021-02-11T04:15:46Z;2021-02-11T04:15:46Z;NA;439-451;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; Assoc Comp Machinery Type: Proceedings Paper";<p>6th ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play (CHI PLAY), Barcelona, SPAIN, OCT 22-25, 2019</p>;NA;NA;NA;"Animal avatars; animal embodiment; avatar control; IVBO; virtual creatures; virtual reality games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LGW3M5AZ;conferencePaper;2019;"Degraen, Donald; Kosmalla, Felix; Krueger, Antonio";Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications;CHI EA `19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS;978-1-4503-5971-9;NA;10.1145/3290607.3312833;NA;Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.;2019;2021-02-11T04:15:47Z;2021-02-11T04:15:47Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>CHI Conference on Human Factors in Computing Systems (CHI), Glasgow, SCOTLAND, MAY 04-09, 2019</p>;NA;NA;NA;"Ambient interfaces; ambient notifications; empathic living media; focus group";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5UY52ESC;conferencePaper;2019;"Cosmoiu, Ana Maria; Nedelcea, Catalin; Podina, Ioana Roxana";A Computerized, Gamified Intervention Training Visual Perspective-Taking. Theoretical Rationale and Proposal of a Randomized Controlled Trial;NEW TECHNOLOGIES AND REDESIGNING LEARNING SPACES, VOL I;NA;NA;10.12753/2066-026X-19-011;NA;Perspective-taking is a core theory of mind process, entailing the ability to understand and predict others' mental states. While the literature suggests that priming a perspective-taking stance increases empathic concern and intergroup cohesion and reduces implicit negative attitudes such as racial bias and prejudice, no study up to date has attempted to foster perspective-taking implicitly, by training visual perspective-taking in a computerized task. In the current paper, we propose a computerized, gamified intervention for visual perspective-taking in adolescents and young adults. The intervention is an adapted version of extant visual perspective-taking assessment protocols and is envisioned to train participants to selectively attend to the visual perspective of an animated avatar, instead of their own. By training an allocentric bias, the intervention aims to increase empathic and theory of mind abilities and to foster interpersonal communication and cohesion. An additionally hypothesized benefit of the intervention is a decrease in self-focused attention, a marker of social anxiety disorder. As such, the intervention is suited to address two different, but inter-related needs: optimizing social functioning and managing social anxiety symptomatology. Introducing users to gamification elements, such as earning badges, advancing through increasing difficulty levels, receiving feedback and leaderboards highlighting achievements, is intended to increase the intervention's efficacy and to promote adherence. Design considerations for testing the intervention in an experimental trial will additionally be proposed, with the intervention contrasted against a sham control condition that will equally train egocentric and allocentric biases in visual perspective-taking. Theoretical and practical implications for educational settings will be discussed.;2019;2021-02-11T04:15:47Z;2021-02-11T04:15:47Z;NA;91-97;NA;NA;NA;NA;NA;NA;eLearning and Software for Education;NA;NA;NA;CAROL I NATL DEFENCE UNIV PUBLISHING HOUSE;PANDURI ST, 68-72, BUCHAREST, 00000, ROMANIA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: European Secur & Def Coll; Romania Partnership Ctr; Natl Def Univ Carol I ISSN: 2066-026X Type: Proceedings Paper";<p>15th International Scientific Conference on eLearning and Software for Education (eLSE) - New Technologies and Redesigning Learning Spaces, Bucharest, ROMANIA, APR 11-12, 2019</p>;NA;NA;NA;"perspective-taking; theory of mind; computerized; gamification; training";Roceanu, I and Belgian, D and Stefan, IA and Moldoveanu, A and Matu, ST;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
24D2AZ75;journalArticle;2019;"Fusaro, M.; Tieri, G.; Aglioti, S. M.";Influence of cognitive stance and physical perspective on subjective and autonomic reactivity to observed pain and pleasure: An immersive virtual reality study;CONSCIOUSNESS AND COGNITION;NA;1053-8100;10.1016/j.concog.2018.11.010;NA;Observing others' pain may induce a reaction called personal distress that may be influenced by top-down (imagine self or other in pain, i.e., self- vs other-oriented stance) and bottom-up (physical perspective of those who suffer, i.e., first vs third person perspective- 1PP vs 3PP) processes. The different contributions of these processes have not been teased apart. By capitalizing on the power of Immersive Virtual Reality, we explored how behavioural (subjective ratings) and physiological reactivity (skin conductance reactivity, SCR) to pain and pleasure delivered to an avatar was influenced by Cognitive stance and Physical perspective. Taking an Other-Oriented stance leads to attributing higher congruent valence (i.e. pain rated as unpleasant and pleasure as pleasant) and intensity to the stimuli and induces reduced SCR. Ownership over the virtual limb was maximal in 1PP where physiological reactivity to the stimuli was comparable. Our results highlight different components underpinning reactivity to pain and pleasure.;2019-01;2021-02-11T04:15:47Z;2021-02-11T04:15:47Z;NA;86-97;NA;NA;67;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA Publisher: ACADEMIC PRESS INC ELSEVIER SCIENCE Type: Article;NA;NA;NA;NA;"Empathy; Cognitive and physical perspective-taking; Feeling of Ownership; Immersive Virtual Reality; Pleasant touch; Vicarious Pain";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Z7WRYMDJ;journalArticle;2018;"Swiderska, Aleksandra; Kuester, Dennis";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;PERCEPTION;NA;0301-0066;10.1177/0301006618809919;NA;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.;2018-12;2021-02-11T04:15:47Z;2021-02-11T04:15:47Z;NA;1139-1152;NA;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"pain; robots; empathy; mind perception; anthropomorphism; harm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7IN29MDS;journalArticle;2018;"Joyal, Christian C.; Neveu, Sarah-Michelle; Boukhalfi, Tarik; Jackson, Philip L.; Renaud, Patrice";Suppression of Sensorimotor Alpha Power Associated With Pain Expressed by an Avatar: A Preliminary EEG Study;FRONTIERS IN HUMAN NEUROSCIENCE;NA;1662-5161;10.3389/fnhum.2018.00273;NA;"Several studies using functional magnetic resonance imaging (fMRI) showed that empathic capabilities are associated with the activation (and deactivation) of relatively specific neural circuits. A growing number of electroencephalography studies also suggest that it might be useful to assess empathy. The main goal of this study was to use quantitative electroencephalography (qEEG) to test whether observation of pain expressed by an avatar (virtual reality) induces a suppression of alpha waves over sensorimotor cortical areas, as it is observed with human stimuli. Not only was it the case, but also the magnitude of alpha suppression was correlated with perspective-taking capacity of participants. Both empathy levels and magnitude of sensorimotor alpha suppression (SAS) were significantly higher in women than men. Interestingly, a significant interaction emerged between levels of individual empathy and specificity of experimental instructions, where SAS in participants with good perspective-taking was higher during passive observation of the distressed avatar, while the opposite was true during an active (trying to understand) condition. These results suggest that: (1) synthetic characters are able to elicit SAS; (2) SAS is indeed associated with perspective-taking capacities; (3) Persons with poorer perspective-taking capacities can show significant SAS when proper instructions are provided. Therefore, qEEG represents a low-cost objective approach to measure perspective-taking abilities.";2018-07-09;2021-02-11T04:15:48Z;2021-02-11T04:15:48Z;NA;NA;NA;NA;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"electroencephalography; empathy; perspective taking; assessment; avatar; alpha suppression; qEEG";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
67S85P4Z;journalArticle;2018;"Johnson, Esperanza; Hervas, Ramon; Gutierrez Lopez de la Franca, Carlos; Mondejar, Tania; Ochoa, Sergio F.; Favela, Jesus";Assessing empathy and managing emotions through interactions with an affective avatar;HEALTH INFORMATICS JOURNAL;NA;1460-4582;10.1177/1460458216661864;NA;Assistive technologies can improve the quality of life of people diagnosed with different forms of social communication disorders. We report on the design and evaluation of an affective avatar aimed at engaging the user in a social interaction with the purpose of assisting in communication therapies. A human-avatar taxonomy is proposed to assist the design of affective avatars aimed at addressing social communication disorder. The avatar was evaluated with 30 subjects to assess how effectively it conveys the desired emotion and elicits empathy from the user. Results provide evidence that users become used to the avatar after a number of interactions, and they perceive the defined behavior as being logical. The users' interactions with the avatar entail affective reactions, including the mimic emotions that users felt, and establish a preliminary ground truth about prototypic empathic interactions with avatars that is being used to train learning algorithms to support social communication disorder evaluation.;2018-06;2021-02-11T04:15:48Z;2021-02-11T04:15:48Z;NA;182-193;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"empathy; affective computing; cognitive disabilities; human-avatar interaction; social communication disorder";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
LDKD7QKU;journalArticle;2018;"Bernard, Florian; Lemee, Jean-Michel; Aubin, Ghislaine; Ter Minassian, Aram; Menei, Philippe";Using a Virtual Reality Social Network During Awake Craniotomy to Map Social Cognition: Prospective Trial;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/10332;NA;Background: In awake craniotomy, it is possible to temporarily inactivate regions of the brain using direct electrical stimulation, while the patient performs neuropsychological tasks. If the patient shows decreased performance in a given task, the neurosurgeon will not remove these regions, so as to maintain all brain functions. Objective: The objective of our study was to describe our experience of using a virtual reality (VR) social network during awake craniotomy and discuss its future applications for perioperative mapping of nonverbal language, empathy, and theory of mind. Methods: This was a single-center, prospective, unblinded trial. During wound closure, different VR experiences with a VR headset were proposed to the patient. This project sought to explore interactions with the neuropsychologist's avatar in virtual locations using a VR social network as an available experience. Results: Three patients experienced VR. Despite some limitations due to patient positioning during the operation and the limitation of nonverbal cues inherent to the app, the neuropsychologist, as an avatar, could communicate with the patient and explore gesture communication while wearing a VR headset. Conclusions: With some improvements, VR social networks can be used in the near future to map social cognition during awake craniotomy.;2018-06;2021-02-11T04:15:48Z;2021-02-11T04:15:48Z;NA;NA;NA;6;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"social cognition; virtual reality; awake surgery; neurosurgery";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
X8X2VMQX;journalArticle;2018;"Caruana, Nathan; Ham, Heidi Stieglitz; Brock, Jon; Woolgar, Alexandra; Kloth, Nadine; Palermo, Romina; McArthur, Genevieve";Joint attention difficulties in autistic adults: An interactive eye-tracking study;AUTISM;NA;1362-3613;10.1177/1362361316676204;NA;Joint attention - the ability to coordinate attention with a social partner - is critical for social communication, learning and the regulation of interpersonal relationships. Infants and young children with autism demonstrate impairments in both initiating and responding to joint attention bids in naturalistic settings. However, little is known about joint attention abilities in adults with autism. Here, we tested 17 autistic adults and 17 age- and nonverbal intelligence quotient-matched controls using an interactive eye-tracking paradigm in which participants initiated and responded to joint attention bids with an on-screen avatar. Compared to control participants, autistic adults completed fewer trials successfully. They were also slower to respond to joint attention bids in the first block of testing but performed as well as controls in the second block. There were no group differences in responding to spatial cues on a non-social task with similar attention and oculomotor demands. These experimental results were mirrored in the subjective reports given by participants, with some commenting that they initially found it challenging to communicate using eye gaze, but were able to develop strategies that allowed them to achieve joint attention. Our study indicates that for many autistic individuals, subtle difficulties using eye-gaze information persist well into adulthood.;2018-05;2021-02-11T04:15:48Z;2021-02-11T04:15:48Z;NA;502-512;NA;4;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"autism; social interaction; eye tracking; eye gaze; joint attention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
Y38NLR26;journalArticle;2018;Lawler-Dormer, Deborah;Self-styling an emotionally intelligent avatar;TECHNOETIC ARTS;NA;1477-965X;10.1386/tear.16.1.33_1;NA;Leah, created over the last three years, is a self-styled, autonomous avatar collaboratively developed with Dr Mark Sagar at the Laboratory for Animate Technologies, Auckland Bioengineering Institute at the University of Auckland, New Zealand. Using `Leah' as a technoscientific art case study, this paper will address the practical and theoretical considerations underlying the project, showing complex posthuman and bioethical relations. Leah is exhibited as an intra-active screen-based installation. It is the product of a shifting transdisciplinary collaborative process, involving artists, engineers, computer scientists and neuroscientists. Leah was developed as part of the Auckland Face Simulator project where adult faces are realistically and precisely modelled to show accurate expression. These can be used for neurophysiological and neuropsychological research into emotion, agency and empathy. This artwork engages with a deep questioning of the posthuman through bioengineering self-imaging practices and reflects on our co-evolution with technology.;2018-03;2021-02-11T04:15:49Z;2021-02-11T04:15:49Z;NA;33-42;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE MILL, PARNALL RD, BRISTOL, BS16 3JG, ENGLAND Publisher: IN℡LECT LTD Type: Article;NA;NA;NA;NA;"posthuman; avatar; art-science; media arts; technoscience; transdisciplinary";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
46KRRPUT;journalArticle;2018;"Felnhofer, Anna; Kafka, Johanna X.; Hlavacs, Helmut; Beutl, Leon; Kryspin-Exner, Ilse; Kothgassner, Oswald D.";Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2017.11.031;NA;Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the Media Equation Concept (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses. (C) 2017 Elsevier Ltd. All rights reserved.;2018-03;2021-02-11T04:15:49Z;2021-02-11T04:15:49Z;NA;399-406;NA;NA;80;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Virtual reality; Empathy; Prosocial behavior; Avatar; Agent; Social presence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2A9TAT2X;journalArticle;2018;"Hamilton-Giachritsis, Catherine; Banakou, Domna; Garcia Quiroga, Manuela; Giachritsis, Christos; Slater, Mel";Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-018-21036-2;NA;The ability to perspective-take (cognitive awareness of another's state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a `mother avatar', which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children.;2018-02-14;2021-02-11T04:15:49Z;2021-02-11T04:15:49Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
WU7CF9P9;journalArticle;2018;"Beckerman, N. L.; Wozniak, Danielle F.";Domestic violence counselors and secondary traumatic stress (STS): A brief qualitative report and strategies for support;SOCIAL WORK IN MENTAL HEALTH;NA;1533-2985;10.1080/15332985.2018.1425795;NA;Mental health counselors who provide trauma counseling to domestic violence survivors are exposed to catastrophic stories of danger, physical and emotional vulnerability. As counselors try to assess and treatment plan for and with survivors, they are often deeply affected. For some practitioners, bearing witness to these frightening narratives results in a sympathetic form of trauma known as secondary traumatic stress. This article reports on the findings from a convenience sampling of domestic violence shelter counselors (N = 11). Patterns of emotional reactions emerge as a result of two focus groups. Four themes emerged: 1) hypervigilance, 2) impact on personal life, 3) a shift in worldview and 4) methods of coping.;2018;2021-02-11T04:15:49Z;2021-02-11T04:15:49Z;NA;470-490;NA;4;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"Domestic violence; secondary traumatic stress; shelter counseling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XE2NYA4V;conferencePaper;2018;"Raffe, William L.; Garcia, Jaime A.";Combining Skeletal Tracking and Virtual Reality for Game-based Fall Prevention Training for the Elderly;2018 IEEE 6TH INTERNATIONAL CONFERENCE ON SERIOUS GAMES AND APPLICATIONS FOR HEALTH (SEGAH `18);978-1-5386-6298-4;NA;NA;NA;This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations.;2018;2021-02-11T04:15:49Z;2021-02-11T04:15:49Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Conference on Serious Games and Applications for Health;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 2330-5649 Type: Proceedings Paper;<p>IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH), Vienna, AUSTRIA, MAY 16-18, 2018</p>;NA;NA;NA;NA;Vilaca, JL and Grechenig, T and Duque, D and Rodrigues, N and Dias, N;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
L8DQVQSY;conferencePaper;2018;"Li, Chen; Yuan, Vanessa S. N.; Ip, Horace H. S.";A CASE STUDY ON DELIVERING VIRTUAL REALITY LEARNING FOR CHILDREN WITH AUTISM SPECTRUM DISORDER USING VIRTUAL REALITY HEADSETS;EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-02709-5;NA;NA;NA;Previous research studies have shown that virtual reality (VR) learning is effective for various topics of learning (e.g., social adaptation and skills, job interview, empathy, etc.) on the autism spectrum disorder (ASD) population. VR learning is always delivered using VR devices or installations. Compared to VR installations such as Cave Automatic Virtual Environment (CAVE), with the careful design of VR software, VR headsets can achieve a similar degree of immersion and interactivity at a fraction of the cost, while keeping the whole setup highly portable and requirements on the venue space at a minimum. However, there is a lack of research on delivering VR learning for the ASD population using VR headsets. In this paper, we report a case study involving four children with ASD, who were recruited to experience the prototype software for VR learning in our laboratory environment. Our observation reveals that the design allows children with ASD comprehend the threedimensional world and interact with virtual objects and avatars smoothly while using the VR headsets.;2018;2021-02-11T04:15:50Z;2021-02-11T04:15:50Z;NA;728-734;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>;NA;NA;NA;"autism; special education; virtual reality headset; Virtual reality learning";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
S63W2WPX;journalArticle;2017;"Ferguson, Christopher J.; Donnellan, M. Brent";Are Associations Between “Sexist” Video Games and Decreased Empathy Toward Women Robust? A Reanalysis of Gabbiadini et al. 2016;JOURNAL OF YOUTH AND ADOLESCENCE;NA;0047-2891;10.1007/s10964-017-0700-x;NA;"Gabbiadini, A., Riva, P., Andrighetto, L., Volpato, C., & Bushman, B, (PloS ONE, 2016) provided evidence for a connection between “sexist” video games and decreased empathy toward girls using an experimental paradigm. These claims are based on a moderated mediation model. They reported a three-way interaction between game condition, gender, and avatar identification when predicting masculine ideology in their original study. Masculine ideology was associated, in turn, with decreased empathy. However, there were no main experimental effects for video game condition on empathy. The current analysis considers the strength of the evidence for claims made in the original study on a sample of 153 adolescents (M (age) = 16.812, SD = 1.241; 44.2% male). We confirmed that there was little evidence for an overall effect of game condition on empathy toward girls or women. We tested the robustness of the original reported moderated mediation models against other, theoretically derived alternatives, and found that effects differed based on how variables were measured (using alternatives in their public data file) and the statistical model used. The experimental groups differed significantly and substantially in terms of age suggesting that there might have been issues with the procedures used to randomly assign participants to conditions. These results highlight the need for preregistration of experimental protocols in video game research and raise some concerns about how moderated mediation models are used to support causal inferences. These results call into question whether use of “sexist” video games is a causal factor in the development of reduced empathy toward girls and women among adolescents.";2017-12;2021-02-11T04:15:50Z;2021-02-11T04:15:50Z;NA;2446-2459;NA;12;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER/PLENUM PUBLISHERS Type: Article;NA;NA;NA;NA;"Empathy; Masculinity; Sexism; Video games; Violence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
E9SBMTUY;journalArticle;2017;"Hofer, Matthias; Huesser, Andreas; Prabhu, Sujay";The effect of an avatar's emotional expressions on players' fear reactions: The mediating role of embodiment;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2017.06.024;NA;This research aimed to demonstrate the effects of an avatar's emotional expressions on players' fear reactions during horror gameplay. In Study 1, we found that the emotional expressions of an avatar decreased fear reactions among players. This effect was mediated by avatar embodiment. More precisely, avatar emotional expressions lower avatar embodiment, which, in turn, positively predicts players' fear reactions. In Study 2, we replicated the findings of Study 1. In addition, we found that the effects observed in Study 1 were only present in interactive gameplay-not when players watched screen-captured footage of the game. In other words, we found evidence of a moderated mediation model in which interactivity moderates the effects of an avatar's emotional expressions on players' fear reactions through avatar embodiment. (C) 2017 Elsevier Ltd. All rights reserved.;2017-10;2021-02-11T04:15:50Z;2021-02-11T04:15:50Z;NA;883-890;NA;NA;75;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Embodiment; Agency; Fear; Horror-themed video game";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
CP7DDA6F;journalArticle;2017;"Conway, Jane R.; Lee, Danna; Ojaghi, Mobin; Catmur, Caroline; Bird, Geoffrey";Submentalizing or Mentalizing in a Level 1 Perspective-Taking Task: A Cloak and Goggles Test;JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE;NA;0096-1523;10.1037/xhp0000319;NA;It has been proposed that humans possess an automatic system to represent mental states ('implicit mentalizing'). The existence of an implicit mentalizing system has generated considerable debate however, centered on the ability of various experimental paradigms to demonstrate unambiguously such mentalizing. Evidence for implicit mentalizing has previously been provided by the `dot perspective task,' where participants are slower to verify the number of dots they can see when an avatar can see a different number of dots. However, recent evidence challenged a mentalizing interpretation of this effect by showing it was unaltered when the avatar was replaced with an inanimate arrow stimulus. Here we present an extension of the dot perspective task using an invisibility cloaking device to render the dots invisible on certain trials. This paradigm is capable of providing unambiguous evidence of automatic mentalizing, but no such evidence was found. Two further well-powered experiments used opaque and transparent goggles to manipulate visibility but found no evidence of automatic mentalizing, nor of individual differences in empathy or perspective-taking predicting performance, contradicting previous studies using the same design. The results cast doubt on the existence of an implicit mentalizing system, suggesting that previous effects were due to domain-general processes.;2017-03;2021-02-11T04:15:50Z;2021-02-11T04:15:50Z;NA;454-465;NA;3;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA Publisher: AMER PSYCHOLOGICAL ASSOC Type: Article;NA;NA;NA;NA;"theory of mind; domain-general processing; implicit mentalizing; submentalizing; visual perspective taking";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
XXRR9ZSH;journalArticle;2017;"de Visser, Ewart J.; Monfort, Samuel S.; Goodyear, Kimberly; Lu, Li; O'Hara, Martin; Lee, Mary R.; Parasuraman, Raja; Krueger, Frank";A Little Anthropomorphism Goes a Long Way: Effects of Oxytocin on Trust, Compliance, and Team Performance With Automated Agents;HUMAN FACTORS;NA;0018-7208;10.1177/0018720816687205;NA;Objective: We investigated the effects of exogenous oxytocin on trust, compliance, and team decision making with agents varying in anthropomorphism (computer, avatar, human) and reliability (100%, 50%). Background: Authors of recent work have explored psychological similarities in how people trust humanlike automation compared with how they trust other humans. Exogenous administration of oxytocin, a neuropeptide associated with trust among humans, offers a unique opportunity to probe the anthropomorphism continuum of automation to infer when agents are trusted like another human or merely a machine. Method: Eighty-four healthy male participants collaborated with automated agents varying in anthropomorphism that provided recommendations in a pattern recognition task. Results: Under placebo, participants exhibited less trust and compliance with automated aids as the anthropomorphism of those aids increased. Under oxytocin, participants interacted with aids on the extremes of the anthropomorphism continuum similarly to placebos but increased their trust, compliance, and performance with the avatar, an agent on the midpoint of the anthropomorphism continuum. Conclusion: This study provides the first evidence that administration of exogenous oxytocin affected trust, compliance, and team decision making with automated agents. These effects provide support for the premise that oxytocin increases affinity for social stimuli in automated aids. Application: Designing automation to mimic basic human characteristics is sufficient to elicit behavioral trust outcomes that are driven by neurological processes typically observed in human-human interactions. Designers of automated systems should consider the task, the individual, and the level of anthropomorphism to achieve the desired outcome.;2017-02;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;116-133;NA;1;59;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2455 ℡LER RD, THOUSAND OAKS, CA 91320 USA Publisher: SAGE PUBLICATIONS INC Type: Article;NA;NA;NA;NA;"neuroergonomics; virtual humans; autonomous agents; compliance and reliance; human-automation interaction; oxytocin; trust in automation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5VKPNQIC;journalArticle;2017;Jarvis, Liam;The Ethics of Mislocalized Selfhood: Proprioceptive drifting towards the virtual other;PERFORMANCE RESEARCH;NA;1352-8165;10.1080/13528165.2017.1348587;NA;In Psychology, proprioceptive drift' is a term that originates from the rubber hand illusion paradigm to describe the relative displacement of the perceived location of one's own hand toward the location of the rubber hand' (Wold et al, 2014). Correspondingly, drift measurements in science are used as a means of rating the intensity of a body-ownership illusion via which a participant in a controlled experiment perceives that an extracorporeal appendage, or virtual whole-body avatar is incorporated as part of one's own body schema. In this research article, I will examine an applied performance by BeAnotherLab utilising the anti-disciplinary collective's The Machine to Be Another as part of Good Chance's Encampment project - this telepresence system produces a VR body illusion intended to increase empathy and reduce proximity between an immersant's real body and that of a volunteer refugee counterpart. When scientifically-tested body illusions cross a paradigmatic boundary to be framed as immersive art, what are the ethical implications? Furthermore, are these kinds of virtual proprioceptive transactions across different kinds of social and political boundaries symptomatic of radical empathic acts, or a capitalistic desire for the acquisition of another's experiences by virtual means? This article examines illusory bodily inhabitation through a Levinasian critical lens to consider the ethics of deterritorializing the immersant's gaze and referring their sense of touch elsewhere to produce narrative immersion'.;2017;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;30-37;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8XPZAJ88;journalArticle;2017;Chin, Gabriel Patrick Wei-Hao;Observed bodies and tool selves: kinaesthetic empathy and the videogame avatar;DIGITAL CREATIVITY;NA;1462-6268;10.1080/14626268.2017.1348363;NA;This paper examines the field of Kinaesthetic Empathy and how it is studied in dance and film then interrogates whether this framework can be applied to the videogame avatar. I study the avatar as textually signifying, as an observed body, and as a prosthetic tool-limb using the works of Merleau-Ponty and Heidegger as theoretical support and Ian Bogost's procedural style of videogame reading. I perform close readings of videogame-texts Metal Gear Solid 3 and Mirror's Edge demonstrating how the former enacts a traditional kinaesthetic empathy in the same way as in dance or film and the latter complicates this observer/performer relation. My paper concludes that, though a player/reader may experience a kinaesthetic empathy that resembles the filmic mode of observer/performer kinaesthetic empathy, the videogame form engenders a deeper tool-based empathy, which is altogether different from traditional conceptions of kinaesthetic empathy.;2017;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;206-223;NA;3;28;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"empathy; avatar; body; Kinaesthetic; videogames";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
ZY7HZDJQ;journalArticle;2017;"Johnson, Esperanza; Hervas, Ramon; Gutierrez-Lopez-Franca, Carlos; Mondejar, Tania; Bravo, Jose";Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar;MOBILE INFORMATION SYSTEMS;NA;1574-017X;10.1155/2017/7932529;NA;In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues.;2017;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;NA;NA;NA;2017;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND Publisher: HINDAWI LTD Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NVAPVR9D;journalArticle;2017;"van Rijn, Biljana; Cooper, Mick; Jackson, Andrew; Wild, Ciara";Avatar-based therapy within prison settings: pilot evaluation;BRITISH JOURNAL OF GUIDANCE & COUNSELLING;NA;0306-9885;10.1080/03069885.2015.1068273;NA;The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n=4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population.;2017;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;268-283;NA;3;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"rehabilitation; mental health; Avatar-based therapy; ProReal therapy; therapy in prisons";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FVBPEAVU;conferencePaper;2017;Tedman, Raymond;REALITY VS VIRTUAL REALITY: AFFECTIVE DOMAIN LEARNING OUTCOMES IN MEDICAL ANATOMY TEACHING;9TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES (EDULEARN17);978-84-697-3777-4;NA;NA;NA;"Even after 43 years of anatomy teaching I continue to be deeply moved whenever I view a cadaver or hold a heart or brain in my hand. New teaching methodologies are increasingly using virtual world teaching, interactive models, educational games and Avatars. Through this wave of virtual reality education are important affective domain learning outcomes at risk? During the mid to late 1900s, Bloom and his colleagues recognised that learning could be divided into three categories or domains; cognitive (knowledge), affective (attitude) and psychomotor (skills). The highest level of affective domain learning outcomes involve the “development in one's personal and civic life a code of behaviour based on ethical principles consistent with democratic ideals”.(1) Domains of professionalism in relation to medical practice include ethical practice, reflection/self-awareness, responsibility for actions, respect for patients, teamwork and social responsibility.(2) So, what is the impact of studying anatomy through dissection? In answering this question, most anatomists and students will talk about the value in learning anatomy and of understanding function. While this is true, I believe it goes far beyond this simplistic view. Studying the human body or cadaver can be an emotional experience, sharing the grief of the family following the death of the person they loved as well as a source of wonder at the beauty and perfection of the human body. We are reminded of how much we take life for granted as we go about our day to day activities. In other words, it puts life into perspective. Medical training all too often remains grounded in the biomedical model, with the cognitive domain overshadowing the psychosocial development and needs of learners.(3) Some of the unique aspects of cadaveric dissection include the realistic nature of this teaching medium that allows students to grasp a clear visuo-spatial picture of the organization of human body, experience the texture of human tissues, witness and comprehend pathological conditions while learning the normal and compare the normal vs pathological.(4) Student views range from “enhances my respect for the human body” to “makes learning of anatomy more interesting”. Our results suggest that the more thorough, enduring and contextual learning experience provided by cadaveric dissections are better appreciated in clinical workplaces where the knowledge could be applied to clinical situations. This paper presents an overview of current views regarding affective domain learning outcomes and anatomy teaching methodologies. It highlights the likely importance of the use of human body parts and of dissection in the development of various domains of professionalism in relation to medical practice. As educators should we be more mindful of what learning outcomes might be threatened through replacing reality with virtual reality?";2017;2021-02-11T04:15:51Z;2021-02-11T04:15:51Z;NA;7502-7511;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>9th International Conference on Education and New Learning Technologies (EDULEARN), Barcelona, SPAIN, JUL 03-05, 2017</p>;NA;NA;NA;"empathy; virtual reality; professionalism; affective domain; Anatomy; dissection; humanising";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IDUNSL8P;conferencePaper;2017;Gabriel, Sonja;Teaching Human Rights With Video Games?;PROCEEDINGS OF THE 11TH EUROPEAN CONFERENCE ON GAMES BASED LEARNING (ECGBL 2017);978-1-911218-57-9 978-1-911218-56-2;NA;NA;NA;Serious games which deal with human rights topics have been on the rise for the last 15 years. Digital games show some unique properties that make them valuable for inducing social change. Some of the game elements that can be used to integrate values are as follows: Narration, which is one of the elements that is most obvious to players and is part of most of today's digital games, is a proper way of presenting human rights topics and can also include ideological messages. However, there are also other ways of creating empathy for certain groups as the example of Ayitii - The Cost of Life shows: If players feel responsible for the game characters, games can make players think about the topic presented. Being able to take meaningful decisions which influence the player's avatar, other non-playable characters, the narration or the game-world is a property of many recent games. Thus, ethical decisions are included in games and put players into the shoes of those who are oppressed or put in other situations where there is no easy way of deciding if something is right or wrong. Finally, the article also discusses if these serious games can affect players' real lives and change their way of thinking and attitudes. The serious game This War of Mine shows that some players think about their decisions and the topic of the game even after having stopped playing. However, there are also restrictions to transferring game contents into players' lives and induce social change. Quite often it is not enough just to play the game, teaching which must take place in a non-game context, is needed to make players aware of human rights (violations).;2017;2021-02-11T04:15:52Z;2021-02-11T04:15:52Z;NA;191-196;NA;NA;NA;NA;NA;NA;Proceedings of the European Conference on Games-Based Learning;NA;NA;NA;ACAD CONFERENCES LTD;CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: FH JOANNEUM Univ Appl Sci ISSN: 2049-0992 Type: Proceedings Paper;<p>11th European Conference on Game-Based Learning (ECGBL), Graz, AUSTRIA, OCT 05-06, 2017</p>;NA;NA;NA;"empathy; serious games; game elements; human rights; social change";Pivec, M and Grundler, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
QAUXJW44;conferencePaper;2017;"Landoni, Monica; Fedosov, Anton; Niforatos, Evangelos";Promoting CARE: Changes via Awareness, Recognition and Experience;PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017);978-1-4503-4921-5;NA;10.1145/3078072.3105877;NA;We propose to design playful solutions to help young people better understand the consequences of their use of language in a community of peers. Our system, CARE, will analyse the content of their messages and extract the emotions they are charged with, both in terms of strength (arousal) and valence (negative or positive). Their effects will be translated visually in forms suitable for the different age groups. A positive reinforcement policy will be in place where good behaviour results in awards and popularity among a restricted circle of friends. Finally a simple and cheap wearable device will be offered to young persons willing to be alerted in case they get into an aggressive mood so to raise their awareness and help control themselves better.;2017;2021-02-11T04:15:52Z;2021-02-11T04:15:52Z;NA;783-787;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>16th International ACM Conference on Interaction Design and Children (IDC), Stanford Univ, Stanford, CA, JUN 27-30, 2017</p>;NA;NA;NA;"Emotions; Empathy; Avatars; Design; Behavioural; change; characters; Experience; Playful; Synthetic";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
V3AT2H82;conferencePaper;2017;"Moosaei, Maryam; Das, Sumit K.; Popa, Dan O.; Riek, Laurel D.";Using Facially Expressive Robots to Calibrate Clinical Pain Perception;PROCEEDINGS OF THE 2017 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'17);978-1-4503-4336-7;NA;10.1145/2909824.3020216;NA;In this paper, we introduce a novel application of social robotics in healthcare: high fidelity, facially expressive, robotic patient simulators (RPSs), and explore their usage within a clinical experimental context. Current commercially-available RPSs, the most commonly used humanoid robots worldwide, are substantially limited in their usability and fidelity due to the fact that they lack one of the most important clinical interaction and diagnostic tools: an expressive face. Using autonomous facial synthesis techniques, we synthesized pain both on a humanoid robot and comparable virtual avatar. We conducted an experiment with 51 clinicians and 51 laypersons (n = 102), to explore differences in pain perception across the two groups, and also to explore the effects of embodiment (robot or avatar) on pain perception. Our results suggest that clinicians have lower overall accuracy in detecting synthesized pain in comparison to lay participants. We also found that all participants are overall less accurate detecting pain from a humanoid robot in comparison to a comparable virtual avatar, lending support to other recent findings in the HRI community. This research ultimately reveals new insights into the use of RPSs as a training tool for calibrating clinicians' pain detection skills.;2017;2021-02-11T04:15:52Z;2021-02-11T04:15:52Z;NA;32-41;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; AAAI; HFES ISSN: 2167-2121 Type: Proceedings Paper";<p>12th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Vienna, AUSTRIA, MAR 06-09, 2017</p>;NA;NA;NA;"emotion; affective communication; social robots; facial expressions; humanoid robots; human robot interaction; health informatics; medical technologies; non-verbal communication; patient simulation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8898GE7S;conferencePaper;2017;"Garnier, Francois; Berthoz, Alain; Lambrey, Simon";“Art - Distance Sharing” A Virtual 3D paradigm for the study of the influence of co-presence through avatars on the emotional perception of fine arts;PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL 2017 (ACM VRIC);978-1-4503-4858-4;NA;10.1145/3110292.3110304;NA;How to design new forms of on line behavioural and emotional interactions in digital spaces, shared virtual environments? What are the perceptual, behavioural and cognitive processes involved when actions, emotions or information are shared between several co-present users? What are the aesthetic and sociological implications of these new forms of spatial mediations? What is the influence of spatial location and emotional valence of pictures on the capacity to memorize the pictures? For this study of perceptual and cognitive processes involved when sharing and memorizing emotions online in digital spaces” we have brought together a multidisciplinary team of researchers in Art and New Media, Cognitive Sciences and Psychiatry. Our goal is to assess the relevance and limitations of new forms of mediation in online-shared spaces (also commonly referred to as “virtual worlds”). This paper presents a preliminary account of the paradigm. Here we focus on the influence of co-presence on the emotional perception of fine arts in a digital environment. This experience was developed by the “Spatial Media” group of EnsadLab in partnership with the College de France, supported and funded by PSL * Research University.;2017;2021-02-11T04:15:53Z;2021-02-11T04:15:53Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>Virtual Reality International Conference (Laval Virtual), Laval, FRANCE, MAR 22-24, 2017</p>;NA;NA;NA;"empathy; embodiment; Ars memoriae; co-presence; immersion; serendipity; sharing; spatialization of information";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RM9S2FA3;conferencePaper;2017;"Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin";Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games;VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY;978-1-4503-5548-3;NA;10.1145/3139131.3139132;NA;Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, little is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.;2017;2021-02-11T04:15:53Z;2021-02-11T04:15:53Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; ACM SIGGRAPH Type: Proceedings Paper";<p>23rd ACM Conference on Virtual Reality Software and Technology (VRST), Chalmers Univ Technol, Gothenburg, SWEDEN, NOV 08-10, 2017</p>;NA;NA;NA;"Pet Game; User Types; Virtual Pet; Virtual Reality";Spencer, SN;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
6F2NGUPC;conferencePaper;2017;Murphy, Dooley;Building a Hybrid Virtual Agent for Testing User Empathy and Arousal in Response to Avatar (Micro-)Expressions;VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY;978-1-4503-5548-3;NA;10.1145/3139131.3141217;NA;This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR.;2017;2021-02-11T04:15:53Z;2021-02-11T04:15:53Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM SIGCHI; ACM SIGGRAPH Type: Proceedings Paper";<p>23rd ACM Conference on Virtual Reality Software and Technology (VRST), Chalmers Univ Technol, Gothenburg, SWEDEN, NOV 08-10, 2017</p>;NA;NA;NA;"Virtual reality; social presence; avatar capture; social plausibility";Spencer, SN;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
4MFM33QE;journalArticle;2016;"Fusaro, M.; Tieri, G.; Aglioti, S. M.";Seeing pain and pleasure on self and others: behavioral and psychophysiological reactivity in immersive virtual reality;JOURNAL OF NEUROPHYSIOLOGY;NA;0022-3077;10.1152/jn.00489.2016;NA;Studies have explored behavioral and neural responses to the observation of pain in others. However, much less is known about how taking a physical perspective influences reactivity to the observation of others' pain and pleasure. To explore this issue we devised a novel paradigm in which 24 healthy participants immersed in a virtual reality scenario observed a virtual: needle penetrating (pain), caress (pleasure), or ball touching (neutral) the hand of an avatar seen from a first (1PP)- or a third (3PP)-person perspective. Subjective ratings and physiological responses [skin conductance responses (SCR) and heart rate (HR)] were collected in each trial. All participants reported strong feelings of ownership of the virtual hand only in 1PP. Subjective measures also showed that pain and pleasure were experienced as more salient than neutral. SCR analysis demonstrated higher reactivity in 1PP than in 3PP. Importantly, vicarious pain induced stronger responses with respect to the other conditions in both perspectives. HR analysis revealed equally lower activity during pain and pleasure with respect to neutral. SCR may reflect egocentric perspective, and HR may merely index general arousal. The results suggest that behavioral and physiological indexes of reactivity to seeing others' pain and pleasure were qualitatively similar in 1PP and 3PP. Our paradigm indicates that virtual reality can be used to study vicarious sensation of pain and pleasure without actually delivering any stimulus to participants' real body and to explore behavioral and physiological reactivity when they observe pain and pleasure from ego- and allocentric perspectives.;2016-12;2021-02-11T04:15:54Z;2021-02-11T04:15:54Z;NA;2656-2662;NA;6;116;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA Publisher: AMER PHYSIOLOGICAL SOC Type: Article;NA;NA;NA;NA;"empathy; body ownership; pleasant touch; skin conductance and heart rate";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NI68MENL;journalArticle;2016;"Tordo, Frederic; Binldey, Caroline";Auto-empathy or the others-in-oneself's evolution: Definition and clinic of virtual;EVOLUTION PSYCHIATRIQUE;NA;0014-3855;10.1016/j.evopsy.2014.02.002;NA;Objectives. - The authors propose to explore a psychic phenomenon, the “auto-empathy”, as implemented in the context of digital spaces and particularly in the situation of the player who embodies an avatar (a pixel figure) in a video game. Method. - From the perspective of a theoretical opening both phenomenological and psychoanalytic, auto empathy is the process in which, taking the position of the “other-in-oneself”, we represent our subjective world - or the all states of our subjectivity (actions, emotions, thoughts) - by an empathic relationship with ourselves. The auto-empathy relationship is a process of distancing, and symbolic appropriation, in which we are divided into halves, implementing our innate ability to be both subject and object for ourselves. Results. - The mediatization of auto-empathy in digital worlds can put ourselves instead of a figure that represents us - our avatar - so that our empathy is turned towards ourselves indirectly. This second time of empathy for a virtual figure of the self, called “mediatized auto-empathy” or “virtual auto-empathy”, would contribute thirdly to the development of empathy for oneself. Finally, the development of empathy for others would be supported in a fourth time, by the attention the players are paying to each other in network games. Discussion. - These four hypotheses, illustrated by clinical cases, open an interrogation concerning the frame of the psychoanalytical work. In the adolescent, the `work of virtualisation, which consists in the creative anticipation of its subjective possibilities, seems regularly impeded. The mental duplicity is no longer in a position to operate a symbolizing distance between the real self and the virtual self, between the subjective self and the subjectivising self. The other-in-oneself is ineffective in proposing to the adolescent an empathic dialogue with oneself. Consequently, the autorepresentation flirts with the seizure, in particular in the subjective states of breaks. Nevertheless, the digital spaces could be indirect media of appropriation of subjective experiences for the teenager. Conclusion. - Our reflections led us to think of auto-empathy as the realization of the other-in-oneself which allows us to represent our own subjective world. The auto-empathy mediatized by an avatar can thus be described as a representation by empathy of our subjective part that contains this character. From then on, the space of the video game appears as a space of subjectivation. (C) 2014 Elsevier Masson SAS. All rights reserved.;2016-06;2021-02-11T04:15:54Z;2021-02-11T04:15:54Z;NA;293-308;NA;2;81;NA;NA;NA;NA;NA;NA;NA;NA;NA;French;NA;NA;NA;NA;NA;NA;Place: 65 RUE CAMILLE DESMOULINS, CS50083, 92442 ISSY-LES-MOULINEAUX, FRANCE Publisher: ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER Type: Article;NA;NA;NA;NA;"Empathy; Phenomenology; Auto-empathy; MMORPG; Video games; Others-in-oneself; Psychoanalysis; Reflexiveness; Subjectivation; Theoretical study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FRWTCHXZ;conferencePaper;2016;"Hervas, Ramon; Johnson, Esperanza; Gutierrez Lopez de la Franca, Carlos; Bravo, Jose; Mondejar, Tania";A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars;2016 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING AND COMMUNICATIONS AND 2016 INTERNATIONAL SYMPOSIUM ON CYBERSPACE AND SECURITY (IUCC-CSS);978-1-5090-5566-1;NA;10.1109/IUCC-CSS.2016.20;NA;Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability.;2016;2021-02-11T04:15:54Z;2021-02-11T04:15:54Z;NA;93-100;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Carlos III Madrid; Univ Granada Type: Proceedings Paper";<p>15th International Conference on Ubiquitous Computing and Communications (IUCC) / 8th International Symposium on Cyberspace and Security (CSS), Granada, SPAIN, DEC 14-16, 2016</p>;NA;NA;NA;"Affective Computing; Machine Learning; Cognitive Health; Human-Avatar Interaction; Social Communication Disorders";GarciaBlas, J and Carretero, J and Ray, I and Jin, Q and Georgalas, N;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
7J3CF5P3;conferencePaper;2016;"Johnson, Esperanza; Lopez de la Franca, Carlos Gutierrez; Hervas, Ramon; Mondejar, Tania; Bravo, Jose";Analyzing Human-Avatar Interaction with Neurotypical and not Neurotypical Users;UBIQUITOUS COMPUTING AND AMBIENT IN℡LIGENCE, UCAMI 2016, PT I;978-3-319-48746-5 978-3-319-48745-8;NA;10.1007/978-3-319-48746-5_54;NA;Assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues. In this case, we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of Social Communications Disorders (SCD). The designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions, with those emotions changing according to the interactions that the user chooses to perform on the avatar. We have used Blender for the design of the emotions, which are happiness, sadness, surprise, fear and anger, plus a neutral emotion, while Unity was used to dictate the behavior of the avatar when the interactions were performed, which could be positive (caress), negative (poke) or neutral (wait). The avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users, as well as the difference between neurotypical and non-neurotypical users in terms of emotion recognition and chosen interactions. A ground truth has been established in terms of prototypic empathic interactions by the users.;2016;2021-02-11T04:15:54Z;2021-02-11T04:15:54Z;NA;525-536;NA;NA;10069;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Las Palmas Gran Canaria; MAmI Res Grp ISSN: 0302-9743 Type: Proceedings Paper";<p>10th International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI), San Bartolome de Tirajana, SPAIN, NOV 29-DEC 02, 2016</p>;NA;NA;NA;"Empathy; Affective computing; Affective avatar; Cognitive disabilities; Human-avatar interaction; Social communication disorder";Garcia, CR and CaballeroGil, P and Burmester, M and QuesadaArencibia, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IFMXRQS3;conferencePaper;2016;"Hughes, Darin E.; Vasquez, Eleazar; Nicsinger, Erika";Improving Perspective Taking and Empathy in Children with Autism Spectrum Disorder;2016 IEEE INTERNATIONAL CONFERENCE ON SERIOUS GAMES AND APPLICATIONS FOR HEALTH;978-1-5090-2209-0;NA;NA;NA;This paper discusses the design, implementation, and evaluation of a serious game intended to reinforce applied behavior analysis (ABA) techniques used with children with autism spectrum disorder (ASD) by providing a low cost and easily accessible supplement to traditional methods. The goal is develop a safe environment for social exploration and learning that boosts the child's confidence while providing calming mechanisms. Games increase children's motivation and thus increase the rate of learning in computer mediated environments. Furthermore, children with ASD are able to understand basic emotions and facial expressions in avatars more easily than in real-world interactions.;2016;2021-02-11T04:15:55Z;2021-02-11T04:15:55Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Conference on Serious Games and Applications for Health;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: UCF; Univ Central Florida, Florida Interact Entertainment Acad; Inst Politecnico Cavado Ave, Escola Superior Tecnologia; IEEE; IEEE Comp Soc ISSN: 2330-5649 Type: Proceedings Paper";<p>IEEE International Conference on Serious Games and Applications for Health, Orlando, FL, MAY 11-13, 2016</p>;NA;NA;NA;"empathy; perspective taking; autism spectrum disorder; game mechanics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
C3W5Z7JF;journalArticle;2016;"Mattan, Bradley D.; Rotshtein, Pia; Quinn, Kimberly A.";Empathy and visual perspective-taking performance;COGNITIVE NEUROSCIENCE;NA;1758-8928;10.1080/17588928.2015.1085372;NA;This study examined the extent to which visual perspective-taking performance is modulated by trait-level empathy. Participants completed a third-person visual perspective-taking task in which they judged the perspectives of two simultaneously presented avatars, designated “Self” and “Other.” Depending on the trial, these avatars either held the same view (i.e., congruent) or a different view (i.e., incongruent). Analyses focused on the relationship between empathy and two perspective-taking phenomena: Selection between competing perspectives (i.e., perspective-congruence effects) and prioritization of the Self avatar's perspective. Empathy was related to improved overall performance on this task and a reduced cost of selecting between conflicting perspectives (i.e., smaller perspective-congruence effects). This effect was asymmetric, with empathy (i.e., empathic concern) levels predicting reduced interference from a conflicting perspective, especially when adopting the Self (vs. Other) avatar's perspective. Taken together, these results highlight the importance of the self-other distinction and mental flexibility components of empathy.;2016;2021-02-11T04:15:55Z;2021-02-11T04:15:55Z;NA;170-181;NA;1-4, SI;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"Empathy; Personal relevance; Self-tagging; Visual perspective-taking";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NQCC4UF3;conferencePaper;2016;Jestice, Rebecca;Walking in Someone's Virtual Shoes: Virtual Worlds as a Tool for Developing Empathy;AMCIS 2016 PROCEEDINGS;978-0-9966831-2-8;NA;NA;NA;Empathy is an important skill for leaders. It is proposed that virtual worlds can be used effectively as a tool in developing empathy, especially perspective taking. This emerging stream of research explores the use of virtual worlds and avatar manipulation as a means to evoke perspective taking in leadership students. It is proposed that due to the Proteus Effect, virtual world users will change their behavior in a role-play based on their avatar's appearance. Further, it is proposed that this change in behaviors will lead to more insight into the perspectives of different others in a similar real world situation.;2016;2021-02-11T04:15:56Z;2021-02-11T04:15:56Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC INFORMATION SYSTEMS;P.O. BOX 2712, ATLANTA, GA 30301-2712 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>22nd Americas Conference on Information Systems (AMCIS), San Diego, CA, 2016</p>;NA;NA;NA;"empathy; Virtual worlds; leadership development";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
5CNJZHGQ;journalArticle;2015;"Patel, Himalaya; MacDorman, Karl F.";Sending an Avatar to Do a Human's Job: Compliance with Authority Persists Despite the Uncanny Valley;PRESENCE-℡EOPERATORS AND VIRTUAL ENVIRONMENTS;NA;NA;10.1162/PRES_a_00212;NA;Just as physical appearance affects social influence in human communication, it may also affect the processing of advice conveyed through avatars, computer-animated characters, and other human-like interfaces. Although the most persuasive computer interfaces are often the most human-like, they have been predicted to incur the greatest risk of falling into the uncanny valley, the loss of empathy attributed to characters that appear eerily human. Previous studies compared interfaces on the left side of the uncanny valley, namely, those with low human likeness. To examine interfaces with higher human realism, a between-groups factorial experiment was conducted through the internet with 426 midwestern U.S. undergraduates. This experiment presented a hypothetical ethical dilemma followed by the advice of an authority figure. The authority was manipulated in three ways: depiction (digitally recorded or computer animated), motion quality (smooth or jerky), and advice (disclose or refrain from disclosing sensitive information). Of these, only the advice changed opinion about the ethical dilemma, even though the animated depiction was significantly eerier than the human depiction. These results indicate that compliance with an authority persists even when using an uncannily realistic computer-animated double.;2015;2021-02-11T04:15:56Z;2021-02-11T04:15:56Z;NA;1-23;NA;1;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA Publisher: MIT PRESS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8H8L9NFE;journalArticle;2015;"Sulpizio, Valentina; Committeri, Giorgia; Metta, Emilia; Lambrey, Simon; Berthoz, Alain; Galati, Gaspare";Visuospatial transformations and personality: evidence of a relationship between visuospatial perspective taking and self-reported emotional empathy;EXPERIMENTAL BRAIN RESEARCH;NA;0014-4819;10.1007/s00221-015-4280-2;NA;In the visuospatial domain, perspective taking is the ability to imagine how a visual scene appears from an external observer's viewpoint, and can be studied by asking subjects to encode object locations in a visual scene where another individual is present and then detecting their displacement when seeing the scene from the other's viewpoint. In the current study, we explored the relationship between visuospatial perspective taking and self-report measures of the cognitive and emotional components of empathy in young adults. To this aim, we employed a priming paradigm, in which the presence of an avatar allowed to anticipate the next perceived perspective on the visual scene. We found that the emotional dimension of empathy was positively correlated with the behavioral advantage provided by the presence of the avatar, relative to unprimed perspective changes. These data suggest a link between the tendency to vicariously experience the others' emotions and the ability to perform self-other spatial transformations.;2015-07;2021-02-11T04:15:56Z;2021-02-11T04:15:56Z;NA;2091-2102;NA;7;233;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Virtual reality; Empathy; Perspective taking; Mental transformations; Personality traits; Spatial memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
M6RJPQN8;journalArticle;2015;"Jackson, Philip L.; Michon, Pierre-Emmanuel; Geslin, Erik; Carignan, Maxime; Beaudoin, Danny";EEVEE: the Empathy-Enhancing Virtual Evolving Environment;FRONTIERS IN HUMAN NEUROSCIENCE;NA;1662-5161;10.3389/fnhum.2015.00112;NA;"Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar's behavior to the observer's neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar's face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders.";2015-03-10;2021-02-11T04:15:56Z;2021-02-11T04:15:56Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"emotions; pain; empathy; affective computing; virtual reality; avatar; FACS";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NWC2LZDX;journalArticle;2015;"Marcos Pablos, Samuel; Gomez Garcia-Bermejo, Jaime; Zalama Casanova, Eduardo; Lopez, Joaquin";Dynamic Facial Emotion Recognition Oriented to HCI Applications;INTERACTING WITH COMPUTERS;NA;0953-5438;10.1093/iwc/iwt057;NA;As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176-192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human-computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response.;2015-03;2021-02-11T04:15:57Z;2021-02-11T04:15:57Z;NA;99-119;NA;2;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article;NA;NA;NA;NA;"agent-based interaction; computer vision; empirical studies in ubiquitous and mobile computing; gestural input; graphical user interfaces; intelligent avatars";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
2YCVQFIU;journalArticle;2015;"Tisseron, Serge; Tordo, Frederic; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0268-5;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015-02;2021-02-11T04:15:57Z;2021-02-11T04:15:57Z;NA;97-102;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Psychology; Human-robot interaction; Auto-empathy; Direct empathy; Empathy with robots; Intersubjective empathy; Reciprocal empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
YFIIC2L8;journalArticle;2014;"Thirioux, Berangere; Tandonnet, Louis; Jaafari, Nematollah; Berthoz, Alain";Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia: A behavioural pilot-study using virtual reality technology;BRAIN AND COGNITION;NA;0278-2626;10.1016/j.bandc.2014.06.006;NA;Behavioural and neuroimaging data have recently pointed out that empathy (feeling into someone else) is associated with mental imagery and transformation related to one's and other's visuo-spatial perspectives. Impairments of both empathic and visuo-spatial abilities have been observed in patients with schizophrenia. Especially, it has been suggested that schizophrenics are altered in spontaneously simulating another individual's first-person experience. However, there is so far only little evidence regarding the relationship between deficits in empathy and disturbances in spontaneous heterocentered coding in schizophrenia. In the present pilot-study, we tested with schizophrenic patients our behavioural paradigm that enables to measure from the bodily postures and movements whether individuals in ecologically more valid conditions are interacting with another individual by using egocentered - as in sympathy (feeling with someone else) - or heterocentered - as in empathy - visuo-spatial mechanisms. For that, ten patients and ten controls, standing and moving, interacted with a virtual tightrope walker, displayed life-sized, standing and moving as well. We show that patients with higher negative symptoms had, in most cases, deficits in spontaneously using heterocentered visuo-spatial mechanisms and employed preferentially an egocentered referencing to interact with the avatar. In contrast, preserved spontaneous heterocentered visuo-spatial strategies were not linked to a prevailing negative or positive symptomatology. Our data suggest that the severity of the negative symptoms in schizophrenia relates with disturbances of spontaneous (”online”) empathic processing in association with lower scoring self-reported trait cognitive empathy. (C) 2014 Elsevier Inc. All rights reserved.;2014-10;2021-02-11T04:15:57Z;2021-02-11T04:15:57Z;NA;87-99;NA;NA;90;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA Publisher: ACADEMIC PRESS INC ELSEVIER SCIENCE Type: Article;NA;NA;NA;NA;"Negative symptoms; Schizophrenia; Empathy; Sympathy; Executive functions; Inhibitory processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8GEBVUXA;journalArticle;2014;Kumar, Akshaya;Satyamev Jayate: Return of the Star as a Sacrificial Figure;SOUTH ASIA-JOURNAL OF SOUTH ASIAN STUDIES;NA;0085-6401;10.1080/00856401.2014.906087;NA;This paper attempts to make sense of Satyamev Jayate, a popular Indian television show hosted by film star Aamir Khan, in terms of its politics, Khan's stardom and the attempt to reframe the social on television. Grappling with the broad contours of the cultural economy of justice on national television in India, I suggest that the star descends upon television as an avatar promising empathy to a variety of victims of social injustice. In so doing, Khan converts crime news into emotional truths. The show has not only generated public debate, it also invites the public to return to a performative innocence. As television becomes the site of articulating moral authority, ritual participation and demanding social change, the political is re-assembled through Khan's stardom. The paper also enquires how and why the show compels narrative ingenuity towards what Aditya Nigam calls the implosion of the political'the erasure of the public from the street and its re-inscription in the studio. Equally notable here is the role film-stardom plays in rendering moral authority through the trope of the sacrificial.;2014-06;2021-02-11T04:15:58Z;2021-02-11T04:15:58Z;NA;239-254;NA;2;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"news; avatar; crime; entertainment; film star; political surplus; truth";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
98LUBTI8;conferencePaper;2014;"Sejima, Yoshihiro; Watanabe, Tomio; Jindai, Mitsuru";Development of an Interaction-activated Communication Model Based on a Heat Conduction Equation in Voice Communication;2014 23RD IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN);978-1-4799-6765-0;NA;NA;NA;In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication.;2014;2021-02-11T04:15:58Z;2021-02-11T04:15:58Z;NA;832-837;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; IEEE Syst, Man & Cybernet Soc ISSN: 1944-9445 Type: Proceedings Paper";<p>23rd IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Heriot Watt Univ, Edinburgh, SCOTLAND, AUG 25-29, 2014</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U2W76XCZ;conferencePaper;2014;"Di Tore, P. A.; Di Tore, S.; Mangione, G. R.; Corona, F.; Conesa Caralt, Jordi";IKeWYSe - I Know What You See An educational ontology-driven simulation game to foster perspective-taking skills;2014 INTERNATIONAL CONFERENCE ON IN℡LIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS);978-1-4799-6387-4;NA;10.1109/INCoS.2014.119;NA;This work represents the evolution for educational purposes of a video game designed for the measurement of perspective taking skills. The prototype of the game from which this study started has been developed by the University of Salerno and is aimed at assessing the age at which students develop perspective-taking and mental rotation skills. The shift from the scope of measurement to that of training required the software to be capable to adaptively suggest effective strategies appropriate to the user's profile. Notwithstanding the theoretical framework and the approach to the representation of spatial reference systems, the specific educational needs have led to a complete re-design of the application and to the introduction of a semantic layer that can adaptively support user. This paper, therefore, in the first part presents the theoretical framework behind the project and briefly describes the prototype of the game aimed at measuring the perspective taking skills, and, in the second part, presents the design of a specific ontology for the educational version.;2014;2021-02-11T04:15:58Z;2021-02-11T04:15:58Z;NA;710-715;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Politecnica Catalunya Barcelona Tech; Fukuoka Inst Technol; Kyushu Inst Technol; Hippocratica Civitas Studium Salerni; Syst Man Cybernet Soc Type: Proceedings Paper";<p>2014 International Conference on Intelligent Networking and Collaborative Systems (IEEE INCoS 2014), Univ Salerno, Salerno, ITALY, SEP 10-12, 2014</p>;NA;NA;NA;"Learning; Empathy; Avatar; Perspective Taking; Spatial reference frames";Xhafa, F and Barolli, L and Palmieri, F and Koeppen, M and Loia, V;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
3K5DNYVM;journalArticle;2013;"Hollingdale, Jack; Greitemeyer, Tobias";The changing face of aggression: the effect of personalized avatars in a violent video game on levels of aggressive behavior;JOURNAL OF APPLIED SOCIAL PSYCHOLOGY;NA;0021-9029;10.1111/jasp.12148;NA;Video game developments allow players to design their own personalized avatars. Previous research has shown that this capability increases levels of aggression within socially acceptable forms of violence. Using the general aggression model (GAM), the current study examined the effect of avatar personalization on behavioral aggression within a violent video game. Participants who played a violent video game and designed their own avatars were significantly more aggressive than those who played the same violent video game with a generic avatar, and were also more aggressive than those who played the nonviolent video game, regardless of whether or not they designed their own personalized characters. Limitations and directions for future research are discussed.;2013-09;2021-02-11T04:15:59Z;2021-02-11T04:15:59Z;NA;1862-1868;NA;9;43;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY-BLACKWELL Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
RUIDK9AZ;journalArticle;2013;"Derbyshire, Stuart W. G.; Osborn, Jody; Brown, Steven";Feeling the pain of others is associated with self-other confusion and prior pain experience;FRONTIERS IN HUMAN NEUROSCIENCE;NA;1662-5161;10.3389/fnhum.2013.00470;NA;Some chronic pain patients and healthy individuals experience pain when observing injury or others in pain. To further understand shared pain, we investigated perspective taking, bodily ownership and tooth pain sensitivity. First, participants who reported shared pain (responders) and those who did not (non-responders) viewed an avatar on a screen. Intermittently, 0-3 circles appeared. Sometimes the participant's and avatar's perspective were consistent, both directly viewed the same circles, and sometimes inconsistent, both directly viewed different circles. Responders were faster than non-responders to identify the number of circles when adopting a consistent perspective. Second, participants sat with their left hand hidden while viewing a rubber hand. All participants reported an illusory sensation of feeling stroking in the rubber hand and a sense of ownership of the rubber hand during synchronous stroking of the rubber and hidden hand. The responders also reported feeling the stroking and a sense of ownership of the rubber hand during asynchronous stroking. For experiment three, participants with either low, moderate, or high tooth sensitivity observed a series of images depicting someone eating an ice-popsicle. Low sensitivity participants never reported pain. In contrast, moderate and high sensitivity participants reported pain in response to an image depicting someone eating an ice popsicle (4 and 19% of the time, respectively) and depicting someone eating an ice-popsicle and expressing pain (23 and 40%, respectively). In summary, responders have reduced ability to distinguish their own and others' visual perspective and enhanced ability to integrate a foreign arm into their bodily representation. The tendency to share pain is also enhanced when an observed pain is commonly experienced by the observer. Shared pain may therefore when an observed pain is commonly experienced by the observer shared pain may therefore involve reactivation of pain memories or pain schema that are readily integrated into a self perspective and bodily representation.;2013-08-14;2021-02-11T04:15:59Z;2021-02-11T04:15:59Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"pain; empathy; illusion; sensitivity; vicarious";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
P8L2RA8W;journalArticle;2013;Sieg, Katrin;Wii Are Family: Performing Race in Neo-liberal Europe;THEATRE RESEARCH INTERNATIONAL;NA;0307-8833;10.1017/S030788331200096X;NA;This article examines the flash mob dance Glow by the Afro-Norwegian duo Madcon, which was performed at the Eurovision Song Contest in Oslo, Norway, in 2010. The dance was modelled on the format of popular Wii dance games, and coordinated black and white dancers, families, mass publics and prerecorded and live footage in order to choreograph European `unity in diversity'. The use of black dancers as avatars urging dancing crowds towards greater kinaesthetic sensitivity raises the questions of how race is figured in neo-liberal visions of cosmopolitan Europe, and what role gaming technology plays in facilitating cross-racial empathy and ethical responsiveness at a time when solidarity is fraying as a consequence of fiscal crises and austerity measures. Finally, the article considers Afro-European academic, activist and artistic practices as alternatives to neo-liberal regimes of race.;2013-03;2021-02-11T04:15:59Z;2021-02-11T04:15:59Z;NA;20-33;NA;1;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA Publisher: CAMBRIDGE UNIV PRESS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
DUDRR44Z;journalArticle;2013;"Rosenberg, Robin S.; Baughman, Shawnee L.; Bailenson, Jeremy N.";Virtual Superheroes: Using Superpowers in Virtual Reality to Encourage Prosocial Behavior;PLOS ONE;NA;1932-6203;10.1371/journal.pone.0055003;NA;Background: Recent studies have shown that playing prosocial video games leads to greater subsequent prosocial behavior in the real world. However, immersive virtual reality allows people to occupy avatars that are different from them in a perceptually realistic manner. We examine how occupying an avatar with the superhero ability to fly increases helping behavior. Principal Findings: Using a two-by-two design, participants were either given the power of flight (their arm movements were tracked to control their flight akin to Superman's flying ability) or rode as a passenger in a helicopter, and were assigned one of two tasks, either to help find a missing diabetic child in need of insulin or to tour a virtual city. Participants in the “super-flight” conditions helped the experimenter pick up spilled pens after their virtual experience significantly more than those who were virtual passengers in a helicopter. Conclusion: The results indicate that having the “superpower” of flight leads to greater helping behavior in the real world, regardless of how participants used that power. A possible mechanism for this result is that having the power of flight primed concepts and prototypes associated with superheroes (e.g., Superman). This research illustrates the potential of using experiences in virtual reality technology to increase prosocial behavior in the physical world.;2013-01-30;2021-02-11T04:16:00Z;2021-02-11T04:16:00Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA Publisher: PUBLIC LIBRARY SCIENCE Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U5NB9QUH;journalArticle;2013;"Bouchard, Stephane; Bernier, Francois; Boivin, Eric; Dumoulin, Stephanie; Laforest, Mylene; Guitard, Tanya; Robillard, Genevieve; Monthuy-Blanc, Johana; Renaud, Patrice";Empathy Toward Virtual Humans Depicting a Known or Unknown Person Expressing Pain;CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING;NA;2152-2715;10.1089/cyber.2012.1571;NA;This study is about pain expressed by virtual humans and empathy in users immersed in virtual reality. It focuses on whether people feel more empathy toward the pain of a virtual human when the virtual human is a realistic representation of a known individual, as opposed to an unknown person, and if social presence is related to users' empathy toward a virtual human's pain. The 42 participants were immersed in virtual reality using a large immersive cube with images retro projected on all six faces (CAVE-Like system) where they can interact in real time with virtual characters. The first immersion (baseline/control) was with a virtual animal, followed by immersions involving discussions with a known virtual human (i.e., the avatar of a person they were familiar with) or an unknown virtual human. During the verbal exchanges in virtual reality, the virtual humans expressed acute and very strong pain. The pain reactions were identical in terms of facial expressions, and verbal and nonverbal behaviors. The Conditions by Time interactions in the repeated measures analyses of variance revealed that participants were empathic toward both virtual humans, yet more empathic toward the known virtual human. Multivariate regression analyses revealed that participants' feeling of social presence-impression that the known virtual character is really there, with them-was a significant predictor of empathy.;2013-01;2021-02-11T04:16:00Z;2021-02-11T04:16:00Z;NA;61-71;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA Publisher: MARY ANN LIEBERT, INC Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HIMHCPXN;journalArticle;2012;"Creed, Christopher; Beale, Russell";User interactions with an affective nutritional coach;INTERACTING WITH COMPUTERS;NA;0953-5438;10.1016/j.intcom.2012.05.004;NA;This paper investigates how users respond to emotional expressions displayed by an embodied agent. In a between-subjects experiment (N = 50) an emotionally expressive agent (simulating the role of a nutritional coach) was perceived as significantly more likeable and caring than an unemotional version. Feedback from participants also revealed detailed insights into their perceptions of the agents and highlighted a strong preference for the emotionally expressive version. Design implications for embodied agents are discussed and future research areas identified. (C) 2012 British Informatics Society Limited. All rights reserved.;2012-09;2021-02-11T04:16:00Z;2021-02-11T04:16:00Z;NA;339-350;NA;5;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Emotion; Affect; Avatar; Behaviour change; Engagement";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
U6HZ6Q8F;journalArticle;2012;"Likowski, Katja U.; Muehlberger, Andreas; Gerdes, Antje B. M.; Wieser, Matthias J.; Pauli, Paul; Weyers, Peter";Facial mimicry and the mirror neuron system: simultaneous acquisition of facial electromyography and functional magnetic resonance imaging;FRONTIERS IN HUMAN NEUROSCIENCE;NA;1662-5161;10.3389/fnhum.2012.00214;NA;Numerous studies have shown that humans automatically react with congruent facial reactions, i.e., facial mimicry, when seeing a vis-a-vis' facial expressions. The current experiment is the first investigating the neuronal structures responsible for differences in the occurrence of such facial mimicry reactions by simultaneously measuring BOLD and facial EMG in an MRI scanner. Therefore, 20 female students viewed emotional facial expressions (happy, sad, and angry) of male and female avatar characters. During picture presentation, the BOLD signal as well as M. zygomaticus major and M. corrugator supercilii activity were recorded simultaneously. Results show prototypical patterns of facial mimicry after correction for MR related artifacts: enhanced M. zygomaticus major activity in response to happy and enhanced M. corrugator supercilii activity in response to sad and angry expressions. Regression analyses show that these congruent facial reactions correlate significantly with activations in the IFG, SMA, and cerebellum. Stronger zygomaticus reactions to happy faces were further associated to increased activities in the caudate, MTG, and PCC. Corrugator reactions to angry expressions were further correlated with the hippocampus, insula, and STS. Results are discussed in relation to core and extended models of the mirror neuron system (MNS).;2012-07-26;2021-02-11T04:16:01Z;2021-02-11T04:16:01Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"fMRI; mimicry; mirror neuron system; EMG";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
IU9AQQ9P;journalArticle;2012;"Ganesh, Shanti; van Schie, Hein T.; de Lange, Floris P.; Thompson, Evan; Wigboldus, Daniel H. J.";How the Human Brain Goes Virtual: Distinct Cortical Regions of the Person-Processing Network Are Involved in Self-Identification with Virtual Agents;CEREBRAL CORTEX;NA;1047-3211;10.1093/cercor/bhr227;NA;Millions of people worldwide engage in online role-playing with their avatar, a virtual agent that represents the self. Previous behavioral studies have indicated that many gamers identify more strongly with their avatar than with their biological self. Through their avatar, gamers develop social networks and learn new social-cognitive skills. The cognitive neurosciences have yet to identify the neural processes that underlie self-identification with these virtual agents. We applied functional neuroimaging to 22 long-term online gamers and 21 nongaming controls, while they rated personality traits of self, avatar, and familiar others. Strikingly, neuroimaging data revealed greater avatar-referential cortical activity in the left inferior parietal lobe, a region associated with self-identification from a third-person perspective. The magnitude of this brain activity correlated positively with the propensity to incorporate external body enhancements into one's bodily identity. Avatar-referencing furthermore recruited greater activity in the rostral anterior cingulate gyrus, suggesting relatively greater emotional self-involvement with one's avatar. Post-scanning behavioral data revealed superior recognition memory for avatar relative to others. Interestingly, memory for avatar positively covaried with play duration. These findings significantly advance our knowledge about the brain's plasticity to self-identify with virtual agents and the human cognitive-affective potential to live and learn in virtual worlds.;2012-07;2021-02-11T04:16:01Z;2021-02-11T04:16:01Z;NA;1577-1585;NA;7;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA Publisher: OXFORD UNIV PRESS INC Type: Article;NA;NA;NA;NA;"fMRI; virtual agents; memory; new media; self-identification";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
8JGAWQKN;journalArticle;2012;"Chen, Gwo-Dong; Lee, Jih-Hsien; Wang, Chin-Yeh; Chao, Po-Yao; Li, Liang-Yi; Lee, Tzung-Yi";An Empathic Avatar in a Computer-Aided Learning Program to Encourage and Persuade Learners;EDUCATIONAL TECHNOLOGY & SOCIETY;NA;1436-4522;NA;NA;"Animated pedagogical agents with characteristics such as facial expressions, gestures, and human emotions, under an interactive user interface are attractive to students and have high potential to promote students' learning. This study proposes a convenient method to add an embodied empathic avatar into a computer-aided learning program; learners express their emotions by mouse-clicking while reading, and the avatar motivates them accordingly. This study designs empathic responses for avatars to encourage and persuade learners to make greater reading effort. This experiment examines emotional recognition, empathy transformation, and the effect of virtual human encouragement and persuasion. Subjects identify facial expressions of the avatar, especially those expressing positive facial emotions. Compared to the contrast group, the empathic avatar increases learners' willingness to continue reading and complete exercises.";2012-04;2021-02-11T04:16:01Z;2021-02-11T04:16:01Z;NA;62-72;NA;2;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: BAG 11-222, MASSEY UNIVERSITY, PALMERSTON NORTH, NEW ZEALAND Publisher: IEEE COMPUTER SOC, LEARNING TECHNOLOGY TASK FORCE Type: Article;NA;NA;NA;NA;"Empathy; Animated pedagogical agent; Computer-aided learning; Encourage; Persuade";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
9C48IWCH;conferencePaper;2012;"Karanian, Barbara A.; Eskandari, Mona; Aggarwal, Akshit; Pincheira, Felipe; Krauthamer, Rebecca Rose; Kress, Gregory; Forouhar, Pamon; Dua, Janesha; Peng, Christine";Open Process for Entrepreneuring Team Collaboration: Story Parallels from an Academic Design Team to the Studied Start-Up;2012 ASEE ANNUAL CONFERENCE;NA;NA;NA;NA;"Increasingly, student entrepreneurial ventures begin as emotional connections, artistic experiences, and expectations for delivering on research teams. This paper explores student team progress and responses to roadblocks while helping a maturing Silicon Valley start-up IMVU consider the role of avatars, creative expression and social interaction in the virtual world. Our goal was to seek a deep understanding of why users choose to spend their time and money to take part in the online community IMVU all the while creating a productive entrepreneurial team atmosphere. This paper explores the unique dynamics of the research team during the evolving investigation and delivery phase, all the while simultaneously examining the underlying emotions and motives of participants in one virtual community. We start with the belief that every new research team is like a start-up company and there are commonalities or differences between the student academic research environment and the company's organizational culture. Our collaborative research team includes members from areas of engineering, design, psychology, and communication. In this paper, we intend to correlate the factors that make the design team effective, utilize the findings to guide new student teams, and facilitate progress across the stages of the project. Two factors set the stage for insights on entrepreneuring: 1) evolving research team dynamics, and 2) the need-finding interactions with users both inside and outside the industry environment studied (IMVU). Surprising discoveries include a strong gender imbalance in the community as well as users reporting that online “was basically real life.” A palette of stories abstractly parallels the student design team to the start-up they studied. Concepts include: self motivated, ambiguity readiness level, passion, and empathy. The team leader knowingly discussed using an open-process approach. Members noted a considerable lack of reluctance to prototype methods and team presentations; they also reported a deliberate lack of specific planning that they believe contributed to an entertaining and productive team ambiance. The full experiment offers stunning stories and compelling implications for creating effective design interventions in team-based engineering and design classes as well as for those pursuing the stories of compassion, empathy, and transformation in entrepreneuring.";2012;2021-02-11T04:16:02Z;2021-02-11T04:16:02Z;NA;NA;NA;NA;NA;NA;NA;NA;ASEE Annual Conference & Exposition;NA;NA;NA;AMER SOC ENGINEERING EDUCATION;1818 N STREET, NW SUITE 600, WASHINGTON, DC 20036 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: ASEE ISSN: 2153-5965 Type: Proceedings Paper;<p>ASEE Annual Conference, San Antonio, TX, JUN 10-13, 2012</p>;NA;NA;NA;"Empathy; Design Thinking; Entrepeneuring; IMVU; Open-team process; Social Participation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
BXJVGFNI;journalArticle;2011;"Guadagno, Rosanna E.; Swinth, Kimberly R.; Blascovich, Jim";Social evaluations of embodied agents and avatars;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2011.07.017;NA;The purpose of this study was to examine social evaluations (i.e., perceptions of empathy and positivity) following peoples' interactions with digital human representations. Female research participants engaged in a 3-min interaction while immersed in a 3-D immersive virtual environment with a “peer counselor.” Participants were led to believe that the peer counselor was either an embodied agent (i.e., computer algorithm) or an avatar (i.e., another person). During the interaction, the peer counselor either smiled or not. As predicted, a digitally-rendered smile was found to affect participants' social evaluations. However, these effects were moderated by participants' beliefs about their interaction partner. Specifically, smiles enhanced social evaluations of embodied agents but degraded them for avatars. Although these results are consistent with other findings concerning the communicative realism of embodied agents and avatars they uniquely demonstrate that people's beliefs alone, rather than actual differences in virtual representations, can impact social evaluations. (C) 2011 Elsevier Ltd. All rights reserved.;2011-11;2021-02-11T04:16:02Z;2021-02-11T04:16:02Z;NA;2380-2385;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Avatars; Facial expressions; Collaborative virtual environments; Embodied agents; Nonverbal behavior; Social interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
NHD4QRTA;journalArticle;2011;Taylor, Laramie D.;Avatars and Emotional Engagement in Asynchronous Online Communication;CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING;NA;2152-2715;10.1089/cyber.2010.0083;NA;The notion that an avatar can elicit a sense of emotional involvement or connection on the part of a user in asynchronous online communication was explored through a pair of content analyses of a popular online question-and-answer bulletin board. In the first study, questions accompanied by an avatar not only received more answers than questions without an avatar, but the answers were more likely to be characterized by expressions of empathy. In the second study, a preference for answering questions accompanied by an avatar was found to be associated with interpersonal, altruistic motives for answering questions. Results are discussed in terms of presence and alternative explanations, as well as practical implications.;2011-04;2021-02-11T04:16:03Z;2021-02-11T04:16:03Z;NA;207-212;NA;4;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA Publisher: MARY ANN LIEBERT, INC Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
22AVF4LF;journalArticle;2011;Jin, Seung-A Annie;“MY AVATAR BEHAVES WELL AND THIS FEELS RIGHT”: IDEAL AND OUGHT SELVES IN VIDEO GAMING;SOCIAL BEHAVIOR AND PERSONALITY;NA;0301-2212;10.2224/sbp.2011.39.9.1175;NA;Prosocial and violent games were investigated in relation to empathy with avatars and amount of postgame donation. Participants who played a prosocial game demonstrated greater empathy, while those who played a violent game said they would donate a greater amount of money. Flow was found to be a function of the 3-way interaction between game type, self-perception, and regulatory focus. Higgins's (1987) regulatory focus and self-discrepancy (1997) theories are used to explain the underlying theoretical mechanisms behind these results.;2011;2021-02-11T04:16:03Z;2021-02-11T04:16:03Z;NA;1175-1182;NA;9;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: P O BOX 1539, PALMERSTON NORTH 5330, NEW ZEALAND Publisher: SOC PERSONALITY RES INC Type: Article;NA;NA;NA;NA;"empathy; prosocial games; charitable donation; flow; ideal self; ought self; self-discrepancy; violent games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
KHN85QCY;conferencePaper;2011;"Karanian, Barbara A.; Kress, Gregory";Designing for Social Participation in the Virtual Universe;2011 ASEE ANNUAL CONFERENCE & EXPOSITION;NA;NA;NA;NA;"Increasingly, our emotional connections, artistic experiences and playful escapes are migrating to the virtual world. Virtual environments and online communities are growing and becoming more commonplace in society; for many, they are already a primary means of social interaction. This experiment is a preliminary investigation into the underlying emotional motivation behind participants in the IMVU virtual universe. We seek a deep understanding of why these users choose to spend their time and money to take part in creating this online community. Our collaborative research team includes members from the areas of engineering, design, psychology and communication. Our need-finding interactions with users both inside and out of the IMVU environment have given us insight into the role of avatars, creative expression and social interaction in the virtual world. We assess how users manipulate their social identity and exercise their influence to achieve personal fulfillment online. The full experiment offers compelling implications for creating effective design interventions in team-based engineering and design classes, particularly those involving distributed collaboration, as well as for those pursuing compassion, empathy and social change by design.";2011;2021-02-11T04:16:03Z;2021-02-11T04:16:03Z;NA;NA;NA;NA;NA;NA;NA;NA;ASEE Annual Conference & Exposition;NA;NA;NA;AMER SOC ENGINEERING EDUCATION;1818 N STREET, NW SUITE 600, WASHINGTON, DC 20036 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: ASEE ISSN: 2153-5965 Type: Proceedings Paper;<p>ASEE Annual Conference and Exposition, Vancouver, CANADA, JUN 26-29, 2011</p>;NA;NA;NA;"Interaction Design; IMVU; Social Participation; Emotional Response; Strength of Presence; Virtual Communities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
FBUM38ZQ;conferencePaper;2011;"Szczesna, Agnieszka; Grudzinski, Tomasz; Grudzinski, Jakub";Settings Goals in Psychology Serious Game for Preschool Children;PROCEEDINGS OF THE 5TH EUROPEAN CONFERENCE ON GAMES BASED LEARNING;978-1-908272-18-8;NA;NA;NA;The term serious game is generally used for an application that is developed using a computer game technology and game design principles but is used for non-entertainment purposes. We can say that these applications are entertaining games with non-entertainment goals. The idea is that games could be used for more serious purposes such as education, simulating real world phenomenon and relations in the world, increasing life quality through health, rehabilitation and therapy applications or raising interest in the problems in our global world. This paper focuses on psychology serious games. Generally, in psychology games users are represented by their avatar and can interact with the world and other game characters. Like in storytelling or bibliotherapy, the story itself has a therapeutic component so much as it evokes identification, empathy, resistance, opposition and disclosure of many confusing emotions. This goal oriented gaming can be used in goal oriented therapy methods. The game is played according to a scenario where the user can observe and react to different situations. This acts as a powerful tool for helping users understand and reflect on their own behavior and gives them the opportunity to learn from this virtual experience. The next stage is testing the user's new abilities with new situations by applying different games goals. The innovative use of computer in the form of psychotherapeutic games may enhance patient cooperation. This can also help to attract and sustain the interest especially in children. This paper describes the main features of serious games used in psychology based on the prototype of the game Mission - Master Your Fear. This is a serious game based on a specialist scenario founded on bibliotherapy with some therapeutic goals. It deals with issues and problems of preschool children. The result is an interesting and absorbing game for children which may help them solve some problems.;2011;2021-02-11T04:16:04Z;2021-02-11T04:16:04Z;NA;567-572;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ACAD CONFERENCES LTD;CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;"<p>5th European Conference on Games Based Learning, Natl &amp; Kapodistrian Univ Athens, Athens, GREECE, OCT 20-21, 2011</p>";NA;NA;NA;"goal-oriented games; informal learning; serious games in psychology";Gouscos, D and Meimaris, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
27N9UU6E;journalArticle;2010;Cleland, Kathy;Mixed reality interaction: audience responses to robots and virtual characters;DIGITAL CREATIVITY;NA;1462-6268;10.1080/14626261003654608;NA;This article explores the way audiences respond to screen-based (virtual) and embodied (robotic) entities in the mixed reality terrain of the gallery space. While it would seem that physical three-dimensional objects in a gallery space, especially self-moving objects such as robots, have a distinct advantage in the reality stakes over screen images, the author suggests that there is no hard and fast distinction between how audiences respond to robotic entities and to screen-based virtual characters. It is the ability of an artwork to respond to and `dialogue' with its audienceto `look back' and `talk back'that is the key factor in making it an engaging and believable social partner. Artists discussed include Mari Velonaki, Stelarc, Ruairi Glynn, Karolina Sobecka and Golan Levin.;2010;2021-02-11T04:16:04Z;2021-02-11T04:16:04Z;NA;30-38;NA;1;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND Publisher: ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"phenomenology; virtual reality; robotics; art; avatars; audience interaction; audience response; media art; mirror neurons; mixed reality; new media art; virtual worlds";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Web of Science
HYDG2VHV;journalArticle;2019;Devchand, Pallavi R.;Well. From Artificial Intelligence to Empathy?;Nuclear Receptor Research;NA;2314-5714;10.32527/2019/101436;http://www.kenzpub.com/journals/nurr/2019/101436/;NA;2019-03-30;2021-02-11T01:06:30Z;2021-02-11T01:06:30Z;2021-02-11T01:06:30Z;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.kenzpub.com;NA;Publisher: KenzPub;NA;"C:\Users\esben\Zotero\storage\DIUP9HQ4\Devchand - 2019 - Well. From Artificial Intelligence to Empathy.pdf; C:\Users\esben\Zotero\storage\VLLZK582\101436.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TERWHZR7;journalArticle;2019;Boechat, Cid;INTELIGÊNCIA ARTIFICIAL, EMPATIA E INCLUSÃO: UM PROBLEMA DE DESIGN;"Ergodesign &amp; HCI";NA;2317-8876;10.22570/ergodesignhci.v7iEspecial.1306;http://periodicos.puc-rio.br/index.php/revistaergodesign-hci/article/view/1306;Resumo 					 Pessoas já têm questões cruciais de suas vidas decididas por algoritmos matemáticos (avaliação de aprendizagem, concessão de pensões ou monitoramento de produtividade no trabalho, por exemplo). Este artigo questiona: como é a interação e a experiência dessas pessoas com essas ferramentas? Como ficam as questões de empatia e inclusão quando se tem decisões tomadas por máquinas?;2019-12-31;2021-02-11T01:06:55Z;2021-02-11T01:06:55Z;2021-02-11T01:06:55Z;51-63;NA;Especial;7;NA;NA;INTELIGÊNCIA ARTIFICIAL, EMPATIA E INCLUSÃO;NA;NA;NA;NA;NA;NA;pt;Copyright (c) 2019 Revista ErgodesignHCI;NA;NA;NA;periodicos.puc-rio.br;NA;Number: Especial;NA;"C:\Users\esben\Zotero\storage\YX93YA3E\Boechat - 2019 - INTELIGÊNCIA ARTIFICIAL, EMPATIA E INCLUSÃO UM PR.pdf; C:\Users\esben\Zotero\storage\EH58K5MM\1306.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
USJTWNTB;conferencePaper;2018;Kolonin, Anton;Resource-Constrained Social Evidence Based Cognitive Model for Empathy-Driven Artificial Intelligence;Artificial General Intelligence;978-3-319-97676-1;NA;10.1007/978-3-319-97676-1_10;NA;Working model of social aspects of human and non-human intelligence is required for social embodiment of artificial general intelligence systems to explain, predict and manage behavioral patterns in multi-agent communities. For this purpose, we propose implementation of resource-constrained social evidence based model and discuss possible implications of its application.;2018;2021-02-11T01:07:36Z;2021-02-11T01:07:36Z;NA;100-108;NA;NA;NA;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;Springer International Publishing;Cham;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\WGMQRL9N\Kolonin - 2018 - Resource-Constrained Social Evidence Based Cogniti.pdf;NA;NA;"Empathy; Artificial general intelligence; Artificial psychology; Cognitive model; Compassion; Social evidence; Social proof";"Iklé, Matthew; Franz, Arthur; Rzepka, Rafal; Goertzel, Ben";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
28ATHNDR;journalArticle;2020;Banerjee, Amitav;Empathy in the time of artificial intelligence: Fiction not fact may hold the key;Medical Journal of Dr. D.Y. Patil Vidyapeeth;NA;2589-8302;10.4103/mjdrdypu.mjdrdypu_344_19;"https://www.mjdrdypv.org/article.asp?issn=2589-8302;year=2020;volume=13;issue=2;spage=97;epage=99;aulast=Banerjee;type=0";Medical Journal of Dr DY Patil Vidyapeeth, Official publication of Dr D Y Patil Vidyapeeth, Pune (Deemed to be University), Dr DY Patil Vidyapeeth Society, Pune.;2020-01-03;2021-02-11T01:07:39Z;2021-02-11T01:07:39Z;2021-02-11T01:07:39Z;97;NA;2;13;NA;NA;Empathy in the time of artificial intelligence;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.mjdrdypv.org;NA;Company: Medknow Publications and Media Pvt. Ltd. Distributor: Medknow Publications and Media Pvt. Ltd. Institution: Medknow Publications and Media Pvt. Ltd. Label: Medknow Publications and Media Pvt. Ltd. Publisher: Medknow Publications;NA;C:\Users\esben\Zotero\storage\YXLR9NAI\article.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
7AJIILZ6;journalArticle;2020;Bhat, Vadisha Srinivas;Empathy in the time of artificial intelligence: Fiction not fact may hold the key;Medical Journal of Dr. D.Y. Patil Vidyapeeth;NA;2589-8302;10.4103/mjdrdypu.mjdrdypu_165_20;"https://www.mjdrdypv.org/article.asp?issn=2589-8302;year=2020;volume=13;issue=6;spage=703;epage=704;aulast=Bhat;type=0";Medical Journal of Dr DY Patil Vidyapeeth, Official publication of Dr D Y Patil Vidyapeeth, Pune (Deemed to be University), Dr DY Patil Vidyapeeth Society, Pune.;2020-01-11;2021-02-11T01:07:41Z;2021-02-11T01:07:41Z;2021-02-11T01:07:41Z;703;NA;6;13;NA;NA;Empathy in the time of artificial intelligence;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.mjdrdypv.org;NA;Company: Medknow Publications and Media Pvt. Ltd. Distributor: Medknow Publications and Media Pvt. Ltd. Institution: Medknow Publications and Media Pvt. Ltd. Label: Medknow Publications and Media Pvt. Ltd. Publisher: Medknow Publications;NA;C:\Users\esben\Zotero\storage\CYYA997X\article.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SCVBVB3P;journalArticle;2018;"Inkster, Becky; Sarda, Shubhankar; Subramanian, Vinod";An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study;JMIR mHealth and uHealth;NA;NA;10.2196/12106;https://mhealth.jmir.org/2018/11/e12106;"Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods.";2018-11-23;2021-02-11T01:07:42Z;2021-02-11T01:07:42Z;2021-02-11T01:07:42Z;e12106;NA;11;6;NA;NA;An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being;NA;NA;NA;NA;NA;NA;EN;"Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (""first published in JMIR mHealth and uHealth..."") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.";NA;NA;NA;mhealth.jmir.org;NA;Company: JMIR mHealth and uHealth Distributor: JMIR mHealth and uHealth Institution: JMIR mHealth and uHealth Label: JMIR mHealth and uHealth Publisher: JMIR Publications Inc., Toronto, Canada;NA;"C:\Users\esben\Zotero\storage\VQ262W6V\Inkster et al. - 2018 - An Empathy-Driven, Conversational Artificial Intel.pdf; C:\Users\esben\Zotero\storage\3ME9WWW5\e12106.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SGDQMZGT;journalArticle;2020;Kerasidou, Angeliki;Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare;Bulletin of the World Health Organization;NA;0042-9686;10.2471/BLT.19.237198;http://www.who.int/entity/bulletin/volumes/98/4/19-237198.pdf;Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote.;2020-04-01;2021-02-11T01:07:42Z;2021-02-11T01:07:42Z;2021-02-11T01:07:42Z;245-250;NA;4;98;NA;Bull. World Health Organ.;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\RQKJ8WKS\Kerasidou - 2020 - Artificial intelligence and the ongoing need for e.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
EMSSC3VY;journalArticle;2014;"Potapov, Alexey; Rodionov, Sergey";Universal empathy and ethical bias for artificial general intelligence;Journal of Experimental & Theoretical Artificial Intelligence;NA;0952-813X;10.1080/0952813X.2014.895112;https://doi.org/10.1080/0952813X.2014.895112;Rational agents are usually built to maximise rewards. However, artificial general intelligence (AGI) agents can find undesirable ways of maximising any prior reward function. Therefore, value learning is crucial for safe AGI. We assume that generalised states of the world are valuable – not rewards themselves, and propose an extension of AIXI, in which rewards are used only to bootstrap hierarchical value learning. The modified AIXI agent is considered in the multi-agent environment, where other agents can be either humans or other ‘mature’ agents, the values of which should be revealed and adopted by the ‘infant’ AGI agent. A general framework for designing such empathic agent with ethical bias is proposed as an extension of the universal intelligence model as well. Moreover, we perform experiments in the simple Markov environment, which demonstrate feasibility of our approach to value learning in safe AGI.;2014-07-03;2021-02-11T01:07:45Z;2021-02-11T01:07:45Z;2021-02-11T01:07:45Z;405-416;NA;3;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Taylor and Francis+NEJM;NA;Publisher: Taylor & Francis _eprint: https://doi.org/10.1080/0952813X.2014.895112;NA;"C:\Users\esben\Zotero\storage\4ZKW4TQN\Potapov and Rodionov - 2014 - Universal empathy and ethical bias for artificial .pdf; C:\Users\esben\Zotero\storage\BTHJBAYJ\0952813X.2014.html";NA;NA;"empathy; AIXI; multi-agent environment; representations; safe AGI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
C7DH8YG6;journalArticle;2020;"Yalçın, Özge Nilay; DiPaola, Steve";Modeling empathy: building a link between affective and cognitive processes;Artificial Intelligence Review;NA;1573-7462;10.1007/s10462-019-09753-0;https://doi.org/10.1007/s10462-019-09753-0;Computational modeling of empathy has recently become an increasingly popular way of studying human relations. It provides a way to increase our understanding of the link between affective and cognitive processes and enhance our interaction with artificial agents. However, the variety of fields contributing to empathy research has resulted in isolated approaches to modeling empathy, and this has led to various definitions of empathy and an absence of common ground regarding underlying empathic processes. Although this diversity may be useful in that it allows for an in-depth examination of various processes linked to empathy, it also may not yet provide a coherent theoretical picture of empathy. We argue that a clear theoretical positioning is required for collective progress. The aim of this article is, therefore, to call for a holistic and multilayered view of a model of empathy, taken from the rich background research from various disciplines. To achieve this, we present a comprehensive background on the theoretical foundations, followed by the working definitions, components, and models of empathy that are proposed by various fields. Following this introduction, we provide a detailed review of the existing techniques used in AI research to model empathy in interactive agents, focusing on the strengths and weaknesses of each approach. We conclude with a discussion of future directions in this emerging field.;2020-04-01;2021-02-11T01:07:45Z;2021-02-11T01:07:45Z;2021-02-11T01:07:45Z;2983-3006;NA;4;53;NA;Artif Intell Rev;Modeling empathy;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\V73B9B4I\Yalçın and DiPaola - 2020 - Modeling empathy building a link between affectiv.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
T6S45C9P;journalArticle;2011;"Boukricha, Hana; Wachsmuth, Ipke";Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach;KI - Künstliche Intelligenz;NA;1610-1987;10.1007/s13218-011-0109-8;https://doi.org/10.1007/s13218-011-0109-8;Allowing virtual humans to align to others’ perceived emotions is believed to enhance their cooperative and communicative social skills. In our work, emotional alignment is realized by endowing a virtual human with the ability to empathize. Recent research shows that humans empathize with each other to different degrees depending on several factors including, among others, their mood, their personality, and their social relationships. Although providing virtual humans with features like affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such features as factors modulating their empathic behavior. Supported by psychological models of empathy, we propose an approach to model empathy for the virtual human EMMA—an Empathic MultiModal Agent—consisting of three processing steps: First, the Empathy Mechanism by which an empathic emotion is produced. Second, the Empathy Modulation by which the empathic emotion is modulated. Third, the Expression of Empathy by which EMMA’s multiple modalities are triggered through the modulated empathic emotion. The proposed model of empathy is illustrated in a conversational agent scenario involving the virtual humans MAX and EMMA.;2011-05-19;2021-02-11T01:07:46Z;2021-02-11T01:07:46Z;2021-02-11T01:07:46Z;195;NA;3;25;NA;Künstl Intell;Empathy-Based Emotional Alignment for a Virtual Human;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\FBHIZ23Q\Boukricha and Wachsmuth - 2011 - Empathy-Based Emotional Alignment for a Virtual Hu.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NQ3MF7JA;journalArticle;2020;Kerasidou, Angeliki;Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare;Bulletin of the World Health Organization;NA;0042-9686;10.2471/BLT.19.237198;http://www.who.int/entity/bulletin/volumes/98/4/19-237198.pdf;Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote.;2020-04-01;2021-02-11T01:16:01Z;2021-02-11T01:16:01Z;2021-02-11T01:16:01Z;245-250;NA;4;98;NA;Bull. World Health Organ.;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\YS22ZG3X\Kerasidou - 2020 - Artificial intelligence and the ongoing need for e.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CMS5Y5VZ;journalArticle;2020;Ostherr, Kirsten;Artificial Intelligence and Medical Humanities;Journal of Medical Humanities;NA;1573-3645;10.1007/s10912-020-09636-4;https://doi.org/10.1007/s10912-020-09636-4;"The use of artificial intelligence in healthcare has led to debates about the role of human clinicians in the increasingly technological contexts of medicine. Some researchers have argued that AI will augment the capacities of physicians and increase their availability to provide empathy and other uniquely human forms of care to their patients. The human vulnerabilities experienced in the healthcare context raise the stakes of new technologies such as AI, and the human dimensions of AI in healthcare have particular significance for research in the humanities. This article explains four key areas of concern relating to AI and the role that medical/health humanities research can play in addressing them: definition and regulation of “medical” versus “health” data and apps; social determinants of health; narrative medicine; and technological mediation of care. Issues include data privacy and trust, flawed datasets and algorithmic bias, racial discrimination, and the rhetoric of humanism and disability. Through a discussion of potential humanities contributions to these emerging intersections with AI, this article will suggest future scholarly directions for the field.";2020-07-11;2021-02-11T01:16:01Z;2021-02-11T01:16:01Z;2021-02-11T01:16:01Z;NA;NA;NA;NA;NA;J Med Humanit;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\586D3NAI\Ostherr - 2020 - Artificial Intelligence and Medical Humanities.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
GBFWPPUQ;journalArticle;2020;Banerjee, Soumya;A Framework for Designing Compassionate and Ethical Artificial Intelligence and Artificial Consciousness;Interdisciplinary Description of Complex Systems;NA;1334-4676, 1334-4684;10.7906/indecs.18.2.2;http://indecs.eu/index.php?s=x&y=2020&p=85-95;NA;2020;2021-02-11T01:16:05Z;2021-02-11T01:16:05Z;2021-02-11T01:16:05Z;85-95;NA;2-A;18;NA;Interdiscip. Descr. Complex Syst.;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;C:\Users\esben\Zotero\storage\AIT2N346\Banerjee - 2020 - A Framework for Designing Compassionate and Ethica.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
A3NYT385;journalArticle;2019;"Bridge, Pete; Bridge, Robert";Artificial Intelligence in Radiotherapy: A Philosophical Perspective;Journal of Medical Imaging and Radiation Sciences;NA;1939-8654, 1939-8654;10.1016/j.jmir.2019.09.003;https://www.jmirs.org/article/S1939-8654(19)30502-8/abstract;<h2>Abstract</h2><p>The increasing uptake of machine learning solutions for segmentation and planning leaves no doubt that artificial intelligence (AI) will soon be providing input into a range of radiotherapy procedures. Although this promises to deliver increased speed and accuracy, the future role of AI in relation to radiotherapy should be thought through carefully. There is currently a gap between published developments and widespread adoption, which provides some space to prepare the workforce and to consider the implications on practice. It is rare to find philosophical input into a medical journal, but the advent of AI makes this perspective increasingly important. Philosophical insight can help explore the potential impact of AI, in particular, on human creativity and oversight. Without this perspective, we run the risk of focusing solely on the immediate logistical impact on patients and departments. This commentary identifies three key aspects of radiotherapy that the authors feel would suffer most under AI control: creativity, innovation, and patient safety, which all demand uniquely human attributes. The article also provides insight from a philosophical perspective with regard to human consciousness, ethics, and empathy. Philosophically we should, perhaps, retain ethical concerns about the widening role of AI in radiotherapy beyond simple quantitative interpretation and image processing. As developments continue, we have time to determine how our roles will evolve and to establish a framework for ensuring appropriate human input into patient care. Most importantly, we must start to embed a philosophical approach to adoption of AI technology from the outset if we are to prepare ourselves for the challenge that lies ahead.</p>;2019-12-01;2021-02-11T01:16:07Z;2021-02-11T01:16:07Z;2021-02-11T01:16:07Z;S27-S31;NA;4;50;NA;Journal of Medical Imaging and Radiation Sciences;Artificial Intelligence in Radiotherapy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;www.jmirs.org;NA;Publisher: Elsevier PMID: 31591033;NA;"C:\Users\esben\Zotero\storage\UYVKS8MC\Bridge and Bridge - 2019 - Artificial Intelligence in Radiotherapy A Philoso.pdf; ; C:\Users\esben\Zotero\storage\UQ54MAEI\fulltext.html";http://www.ncbi.nlm.nih.gov/pubmed/31591033;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
GSG9GP2U;journalArticle;2013;Kile, Frederick;Artificial intelligence and society: a furtive transformation;AI & SOCIETY;NA;1435-5655;10.1007/s00146-012-0396-0;https://doi.org/10.1007/s00146-012-0396-0;During the 1950s, there was a burst of enthusiasm about whether artificial intelligence might surpass human intelligence. Since then, technology has changed society so dramatically that the focus of study has shifted toward society’s ability to adapt to technological change. Technology and rapid communications weaken the capacity of society to integrate into the broader social structure those people who have had little or no access to education. (Most of the recent use of communications by the excluded has been disruptive, not integrative.) Interweaving of socioeconomic activity and large-scale systems had a dehumanizing effect on people excluded from social participation by these trends. Jobs vanish at an accelerating rate. Marketing creates demand for goods which stress the global environment, even while the global environment no longer yields readily accessible resources. Mining and petroleum firms push into ever more challenging environments (e.g., deep mines and seabed mining) to meet resource demands. These activities are expensive, and resource prices rise rapidly, further excluding groups that cannot pay for these resources. The impact of large-scale systems on society leads to mass idleness, with the accompanying threat of violent reaction as unemployed masses seek to blame both people in power as well as the broader social structure for their plight. Perhaps, the impact of large-scale systems on society has already eroded essential qualities of humanness. Humans, when they feel “socially useless,” are dehumanized. (At the same time, machines (at any scale) seem incapable of emotion or empathy.) Has the cost of technological progress been too high to pay? These issues are addressed in this paper.;2013-02-01;2021-02-11T01:16:09Z;2021-02-11T01:16:09Z;2021-02-11T01:16:09Z;107-115;NA;1;28;NA;AI & Soc;Artificial intelligence and society;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\Z3JD5QGA\Kile - 2013 - Artificial intelligence and society a furtive tra.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
IX8R8PAF;journalArticle;2020;"Liao, Jing; Hansen, Preben; Chai, Chunlei";A framework of artificial intelligence augmented design support;Human–Computer Interaction;NA;0737-0024;10.1080/07370024.2020.1733576;https://doi.org/10.1080/07370024.2020.1733576;Recent advances in Artificial Intelligence raise interest in its participation in design activity, which is commonly considered to be complex and human-dominated. In this work, we aim to examine AI roles in early design stages. The human ideation components and design tools related to AI are discussed in a framework of AI-augmented design support. The framework develops a hierarchy of design cognition (basis), approaches and principles. The cognitive models are constructed in an empirical study of 30 designers (26 for analysis, 4 for pilot study) by concurrent Think-Aloud protocol and behavior analysis. The process of producing new design ideas is explained by a transparent analysis of designers’ language and behaviors. Three strategies to organize cognitive activities in design ideation are summarized: develop structured consideration, relate to a scenario, and stick-to designing. These strategies suggest AI could act as (1) representation creation, (2) empathy trigger and (3) engagement, in principles of “knowledge-driven” and “decompose-and-integrate”. The design support with AI provides new perspectives on computer-based design tools that limit to well-defined design variables. The framework is built on a generic notion of design activity and “mimic” human design rationales, expected to benefit research of domain-independent computational design supports and cognitive supports.;2020-11-01;2021-02-11T01:16:11Z;2021-02-11T01:16:11Z;2021-02-11T01:16:11Z;511-544;NA;5-6;35;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Taylor and Francis+NEJM;NA;Publisher: Taylor & Francis _eprint: https://doi.org/10.1080/07370024.2020.1733576;NA;C:\Users\esben\Zotero\storage\QWSZZGYI\07370024.2020.html;NA;NA;"artificial intelligence; design supports; Human computer interaction theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Y4IR232V;journalArticle;2021;Irfan, Farhana;Artificial Intelligence: Help or Hindrance for Family Physicians?;Pakistan Journal of Medical Sciences;NA;1681-715X;10.12669/pjms.37.1.3351;https://pjms.org.pk/index.php/pjms/article/view/3351;"The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician’s new assistant; AI-physician combinations can act like models of ‘peaceful co-existence’. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician’s diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients’ frustration. doi: https://doi.org/10.12669/pjms.37.1.3351 How to cite this:Irfan F. Artificial Intelligence: Help or Hindrance for Family Physicians? Pak J Med Sci. 2021;37(1):288-291. doi: https://doi.org/10.12669/pjms.37.1.3351 This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.";2021;2021-02-11T01:16:12Z;2021-02-11T01:16:12Z;2021-02-11T01:16:12Z;NA;NA;1;37;NA;NA;Artificial Intelligence;NA;NA;NA;NA;NA;NA;en;Copyright (c) 2020 Pakistan Journal of Medical Sciences;NA;NA;NA;pjms.org.pk;NA;Number: 1;NA;"C:\Users\esben\Zotero\storage\VUGKGCSJ\3351.html; C:\Users\esben\Zotero\storage\8TYJYGIS\Irfan - 2021 - Artificial Intelligence Help or Hindrance for Fam.pdf";NA;NA;"Machine learning; Artificial Intelligence; Family Physicians";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
99TDIXNN;journalArticle;2020;"Davis, Anthony E.; Davis, Anthony E.";The Future of Law Firms (and Lawyers) in the Age of Artificial Intelligence;Revista Direito GV;NA;1808-2432;10.1590/2317-6172201945;http://www.scielo.br/scielo.php?script=sci_abstract&pid=S1808-24322020000100404&lng=en&nrm=iso&tlng=en;NA;2020;2021-02-11T01:16:13Z;2021-02-11T01:16:13Z;2021-02-11T01:16:13Z;NA;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;SciELO;NA;Publisher: Revista Direito GV;NA;"C:\Users\esben\Zotero\storage\9CJGRQGF\Davis and Davis - 2020 - The Future of Law Firms (and Lawyers) in the Age o.pdf; C:\Users\esben\Zotero\storage\C8JP7CQ5\scielo.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
N7XLV6DN;journalArticle;2019;"Mg, Sanal; K, Paul; S, Kumar; Nk, Ganguly";Artificial Intelligence and Deep Learning: The Future of Medicine and Medical Practice.;The Journal of the Association of Physicians of India;NA;0004-5772;NA;https://europepmc.org/article/med/31309802;Europe PMC is an archive of life sciences journal literature., Artificial Intelligence and Deep Learning: The Future of Medicine and Medical Practice.;2019-04-01;2021-02-11T01:16:14Z;2021-02-11T01:16:14Z;2021-02-11T01:16:14Z;71-73;NA;4;67;NA;J Assoc Physicians India;Artificial Intelligence and Deep Learning;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;europepmc.org;NA;PMID: 31309802;NA;"; C:\Users\esben\Zotero\storage\9N35DPSF\31309802.html";http://www.ncbi.nlm.nih.gov/pubmed/31309802;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9G8TSIVF;journalArticle;2019;"Kerr, David; Klonoff, David C.";Digital Diabetes Data and Artificial Intelligence: A Time for Humility Not Hubris;Journal of Diabetes Science and Technology;NA;1932-2968;10.1177/1932296818796508;https://doi.org/10.1177/1932296818796508;In the future artificial intelligence (AI) will have the potential to improve outcomes diabetes care. With the creation of new sensors for physiological monitoring sensors and the introduction of smart insulin pens, novel data relationships based on personal phenotypic and genotypic information will lead to selections of tailored, effective therapies that will transform health care. However, decision-making processes based exclusively on quantitative metrics that ignore qualitative factors could create a quantitative fallacy. Difficult to quantify inputs into AI-based therapeutic decision-making processes include empathy, compassion, experience, and unconscious bias. Failure to consider these “softer” variables could lead to important errors. In other words, that which is not quantified about human health and behavior is still part of the calculus for determining therapeutic interventions.;2019-01-01;2021-02-11T01:16:17Z;2021-02-11T01:16:17Z;2021-02-11T01:16:17Z;123-127;NA;1;13;NA;J Diabetes Sci Technol;Digital Diabetes Data and Artificial Intelligence;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;SAGE Journals;NA;Publisher: SAGE Publications Inc;NA;C:\Users\esben\Zotero\storage\M6S9NK8A\Kerr and Klonoff - 2019 - Digital Diabetes Data and Artificial Intelligence.pdf;NA;NA;"artificial intelligence; human behavior; big data analytics; clinical decision-making; quantitative fallacy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KC9Q3ZZW;journalArticle;2020;"Blease, C; Locher, C; Leon-Carlyle, M; Doraiswamy, M";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;DIGITAL HEALTH;NA;2055-2076;10.1177/2055207620968355;https://doi.org/10.1177/2055207620968355;"BackgroundThe potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics.ObjectiveThis study aimed to explore psychiatrists? opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practiceMethodsIn Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (?comments?) to three open-ended questions in the survey.ResultsComments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ?man and machine? would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention.ConclusionsThis study presents timely information on psychiatrists? views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020-01-01;2021-02-11T01:16:18Z;2021-02-11T01:16:18Z;2021-02-11T01:16:18Z;2055207620968355;NA;NA;6;NA;DIGITAL HEALTH;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;SAGE Journals;NA;Publisher: SAGE Publications Ltd;NA;C:\Users\esben\Zotero\storage\XXSQ6IRV\Blease et al. - 2020 - Artificial intelligence and the future of psychiat.pdf;NA;NA;"machine learning; Artificial intelligence; mental health; attitudes; future; opinions; psychiatry; qualitative research; technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FUD2JX4Z;journalArticle;2020;"Blease, C; Locher, C; Leon-Carlyle, M; Doraiswamy, M";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;DIGITAL HEALTH;NA;2055-2076;10.1177/2055207620968355;https://doi.org/10.1177/2055207620968355;"BackgroundThe potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics.ObjectiveThis study aimed to explore psychiatrists? opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practiceMethodsIn Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (?comments?) to three open-ended questions in the survey.ResultsComments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ?man and machine? would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention.ConclusionsThis study presents timely information on psychiatrists? views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020-01-01;2021-02-11T01:16:20Z;2021-02-11T01:16:20Z;2021-02-11T01:16:20Z;2055207620968355;NA;NA;6;NA;DIGITAL HEALTH;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;SAGE Journals;NA;Publisher: SAGE Publications Ltd;NA;C:\Users\esben\Zotero\storage\NFSMC3CE\Blease et al. - 2020 - Artificial intelligence and the future of psychiat.pdf;NA;NA;"machine learning; Artificial intelligence; mental health; attitudes; future; opinions; psychiatry; qualitative research; technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
YMFDHH9T;journalArticle;2018;Johnston, S. Claiborne;Anticipating and Training the Physician of the Future: The Importance of Caring in an Age of Artificial Intelligence;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000002175;https://journals.lww.com/academicmedicine/Fulltext/2018/08000/Anticipating_and_Training_the_Physician_of_the.14.aspx;Artificial intelligence and other forms of information technology are only just beginning to change the practice of medicine. The pace of change is expected to accelerate as tools improve and as demands for analyzing a rapidly growing body of knowledge and array of data increase. The medical students of today will practice in a world where information technology is sophisticated and omnipresent. In this world, the tasks of memorization and analysis will be less important to them as practicing physicians. On the other hand, the nonanalytical, humanistic aspects of medicine—most importantly, the art of caring—will remain a critical function of the physician, and facility with improving systems of care will be required. Communication, empathy, shared decision making, leadership, team building, and creativity are all skills that will continue to gain importance for physicians. These skills should be further prioritized in medical school curricula to produce an even more effective physician for the future.;2018-08;2021-02-11T01:16:21Z;2021-02-11T01:16:21Z;2021-02-11T01:16:21Z;1105–1106;NA;8;93;NA;NA;Anticipating and Training the Physician of the Future;NA;NA;NA;NA;NA;NA;en-US;NA;NA;NA;NA;journals.lww.com;NA;NA;NA;C:\Users\esben\Zotero\storage\K8NE6UTK\Anticipating_and_Training_the_Physician_of_the.14.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NMKDBUMR;journalArticle;2019;Powell, John;Trust Me, I’m a Chatbot: How Artificial Intelligence in Health Care Fails the Turing Test;Journal of Medical Internet Research;NA;NA;10.2196/16222;https://www.jmir.org/2019/10/e16222/;"Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care (such as chatbots or conversational agents). In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. [J Med Internet Res 2019;21(10):e16222]";2019;2021-02-11T01:16:24Z;2021-02-11T01:16:24Z;2021-02-11T01:16:24Z;e16222;NA;10;21;NA;NA;Trust Me, I’m a Chatbot;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.jmir.org;NA;Company: Journal of Medical Internet Research Distributor: Journal of Medical Internet Research Institution: Journal of Medical Internet Research Label: Journal of Medical Internet Research Publisher: JMIR Publications Inc., Toronto, Canada;NA;C:\Users\esben\Zotero\storage\6ZULPLVH\e16222.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
5ICSVUN2;journalArticle;2019;"Blease, Charlotte; Kaptchuk, Ted J.; Bernstein, Michael H.; Mandl, Kenneth D.; Halamka, John D.; DesRoches, Catherine M.";Artificial Intelligence and the Future of Primary Care: Exploratory Qualitative Study of UK General Practitioners’ Views;Journal of Medical Internet Research;NA;NA;10.2196/12802;https://www.jmir.org/2019/3/e12802/;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners’ (GPs’) opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPs’ opinions about the likelihood of future technology to fully replace GPs in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (“comments”) to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPs also considered clinical reasoning and the ability to provide value-based care as necessitating physicians’ judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPs believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians’ views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPs considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPs’ views.  [J Med Internet Res 2019;21(3):e12802]";2019;2021-02-11T01:16:26Z;2021-02-11T01:16:26Z;2021-02-11T01:16:26Z;e12802;NA;3;21;NA;NA;Artificial Intelligence and the Future of Primary Care;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.jmir.org;NA;Company: Journal of Medical Internet Research Distributor: Journal of Medical Internet Research Institution: Journal of Medical Internet Research Label: Journal of Medical Internet Research Publisher: JMIR Publications Inc., Toronto, Canada;NA;"C:\Users\esben\Zotero\storage\RZNBHDGA\Blease et al. - 2019 - Artificial Intelligence and the Future of Primary .pdf; C:\Users\esben\Zotero\storage\6VQN33SC\e12802.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
4HZPD964;journalArticle;2019;Asada, Minoru;Artificial Pain May Induce Empathy, Morality, and Ethics in the Conscious Mind of Robots;Philosophies;NA;NA;10.3390/philosophies4030038;https://www.mdpi.com/2409-9287/4/3/38;"In this paper, a working hypothesis is proposed that a nervous system for pain sensation is a key component for shaping the conscious minds of robots (artificial systems). In this article, this hypothesis is argued from several viewpoints towards its verification. A developmental process of empathy, morality, and ethics based on the mirror neuron system (MNS) that promotes the emergence of the concept of self (and others) scaffolds the emergence of artificial minds. Firstly, an outline of the ideological background on issues of the mind in a broad sense is shown, followed by the limitation of the current progress of artificial intelligence (AI), focusing on deep learning. Next, artificial pain is introduced, along with its architectures in the early stage of self-inflicted experiences of pain, and later, in the sharing stage of the pain between self and others. Then, cognitive developmental robotics (CDR) is revisited for two important concepts&mdash;physical embodiment and social interaction, both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, the issue of how robots (artificial systems) could be moral agents is addressed.";2019-09;2021-02-11T01:16:28Z;2021-02-11T01:16:28Z;2021-02-11T01:16:28Z;38;NA;3;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;http://creativecommons.org/licenses/by/3.0/;NA;NA;NA;www.mdpi.com;NA;Number: 3 Publisher: Multidisciplinary Digital Publishing Institute;NA;"C:\Users\esben\Zotero\storage\FX6LMNVU\Asada - 2019 - Artificial Pain May Induce Empathy, Morality, and .pdf; C:\Users\esben\Zotero\storage\6E4H3A22\38.html";NA;NA;"pain; empathy; mirror neuron system (MNS); morality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
XD4RY5KZ;journalArticle;2019;Asada, Minoru;Artificial Pain May Induce Empathy, Morality, and Ethics in the Conscious Mind of Robots;Philosophies;NA;NA;10.3390/philosophies4030038;https://www.mdpi.com/2409-9287/4/3/38;"In this paper, a working hypothesis is proposed that a nervous system for pain sensation is a key component for shaping the conscious minds of robots (artificial systems). In this article, this hypothesis is argued from several viewpoints towards its verification. A developmental process of empathy, morality, and ethics based on the mirror neuron system (MNS) that promotes the emergence of the concept of self (and others) scaffolds the emergence of artificial minds. Firstly, an outline of the ideological background on issues of the mind in a broad sense is shown, followed by the limitation of the current progress of artificial intelligence (AI), focusing on deep learning. Next, artificial pain is introduced, along with its architectures in the early stage of self-inflicted experiences of pain, and later, in the sharing stage of the pain between self and others. Then, cognitive developmental robotics (CDR) is revisited for two important concepts&mdash;physical embodiment and social interaction, both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, the issue of how robots (artificial systems) could be moral agents is addressed.";2019-09;2021-02-11T01:16:29Z;2021-02-11T01:16:29Z;2021-02-11T01:16:29Z;38;NA;3;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;http://creativecommons.org/licenses/by/3.0/;NA;NA;NA;www.mdpi.com;NA;Number: 3 Publisher: Multidisciplinary Digital Publishing Institute;NA;"C:\Users\esben\Zotero\storage\IN6X3448\Asada - 2019 - Artificial Pain May Induce Empathy, Morality, and .pdf; C:\Users\esben\Zotero\storage\2HUY2F27\38.html";NA;NA;"pain; empathy; mirror neuron system (MNS); morality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2NMWDCIS;journalArticle;2020;"Kocaballi, A Baki; Ijaz, Kiran; Laranjo, Liliana; Quiroz, Juan C; Rezazadegan, Dana; Tong, Huong Ly; Willcock, Simon; Berkovsky, Shlomo; Coiera, Enrico";Envisioning an artificial intelligence documentation assistant for future primary care consultations: A co-design study with general practitioners;Journal of the American Medical Informatics Association;NA;1527-974X;10.1093/jamia/ocaa131;https://doi.org/10.1093/jamia/ocaa131;The study sought to understand the potential roles of a future artificial intelligence (AI) documentation assistant in primary care consultations and to identify implications for doctors, patients, healthcare system, and technology design from the perspective of general practitioners.Co-design workshops with general practitioners were conducted. The workshops focused on (1) understanding the current consultation context and identifying existing problems, (2) ideating future solutions to these problems, and (3) discussing future roles for AI in primary care. The workshop activities included affinity diagramming, brainwriting, and video prototyping methods. The workshops were audio-recorded and transcribed verbatim. Inductive thematic analysis of the transcripts of conversations was performed.Two researchers facilitated 3 co-design workshops with 16 general practitioners. Three main themes emerged: professional autonomy, human-AI collaboration, and new models of care. Major implications identified within these themes included (1) concerns with medico-legal aspects arising from constant recording and accessibility of full consultation records, (2) future consultations taking place out of the exam rooms in a distributed system involving empowered patients, (3) human conversation and empathy remaining the core tasks of doctors in any future AI-enabled consultations, and (4) questioning the current focus of AI initiatives on improved efficiency as opposed to patient care.AI documentation assistants will likely to be integral to the future primary care consultations. However, these technologies will still need to be supervised by a human until strong evidence for reliable autonomous performance is available. Therefore, different human-AI collaboration models will need to be designed and evaluated to ensure patient safety, quality of care, doctor safety, and doctor autonomy.;2020-11-01;2021-02-11T01:16:29Z;2021-02-11T01:16:29Z;2021-02-11T01:16:29Z;1695-1704;NA;11;27;NA;Journal of the American Medical Informatics Association;Envisioning an artificial intelligence documentation assistant for future primary care consultations;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Silverchair;NA;NA;NA;"C:\Users\esben\Zotero\storage\2L3PMJEQ\Kocaballi et al. - 2020 - Envisioning an artificial intelligence documentati.pdf; C:\Users\esben\Zotero\storage\HIFT8YNW\5897463.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
V55MEXQ3;journalArticle;2018;"Yalcin, Ӧzge Nilay; DiPaola, Steve";A computational model of empathy for interactive agents;Biologically Inspired Cognitive Architectures;NA;2212-683X;10.1016/j.bica.2018.07.010;https://www.sciencedirect.com/science/article/pii/S2212683X18300719;Empathy has been defined in the scientific literature as the capacity to relate another’s emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018-10-01;2021-02-11T01:16:31Z;2021-02-11T01:16:31Z;2021-02-11T01:16:31Z;20-25;NA;NA;26;NA;Biologically Inspired Cognitive Architectures;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;ScienceDirect;NA;NA;NA;"C:\Users\esben\Zotero\storage\BK757FZN\Yalcin and DiPaola - 2018 - A computational model of empathy for interactive a.pdf; C:\Users\esben\Zotero\storage\DLJEN5EA\S2212683X18300719.html";NA;NA;"Empathy; Affective computing; Conversational agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
28ACX7J6;journalArticle;2016;"Haladjian, Harry Haroutioun; Montemayor, Carlos";Artificial consciousness and the consciousness-attention dissociation;Consciousness and Cognition;NA;1053-8100;10.1016/j.concog.2016.08.011;https://www.sciencedirect.com/science/article/pii/S1053810016301817;Artificial Intelligence is at a turning point, with a substantial increase in projects aiming to implement sophisticated forms of human intelligence in machines. This research attempts to model specific forms of intelligence through brute-force search heuristics and also reproduce features of human perception and cognition, including emotions. Such goals have implications for artificial consciousness, with some arguing that it will be achievable once we overcome short-term engineering challenges. We believe, however, that phenomenal consciousness cannot be implemented in machines. This becomes clear when considering emotions and examining the dissociation between consciousness and attention in humans. While we may be able to program ethical behavior based on rules and machine learning, we will never be able to reproduce emotions or empathy by programming such control systems—these will be merely simulations. Arguments in favor of this claim include considerations about evolution, the neuropsychological aspects of emotions, and the dissociation between attention and consciousness found in humans. Ultimately, we are far from achieving artificial consciousness.;2016-10-01;2021-02-11T01:16:33Z;2021-02-11T01:16:33Z;2021-02-11T01:16:32Z;210-225;NA;NA;45;NA;Consciousness and Cognition;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;ScienceDirect;NA;NA;NA;"C:\Users\esben\Zotero\storage\94AVMC2E\Haladjian and Montemayor - 2016 - Artificial consciousness and the consciousness-att.pdf; C:\Users\esben\Zotero\storage\YJP2QQVK\S1053810016301817.html";NA;NA;"Consciousness; Emotions; Artificial intelligence; Empathy; Artificial consciousness; Phenomenology; Visual attention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Y67W95DU;bookSection;2017;Bruder, Johannes;Chapter 5 - Infrastructural intelligence: Contemporary entanglements between neuroscience and AI;Progress in Brain Research;NA;NA;NA;https://www.sciencedirect.com/science/article/pii/S0079612317300547;In this chapter, I reflect on contemporary entanglements between artificial intelligence and the neurosciences by tracing the development of Google's recent DeepMind algorithms back to their roots in neuroscientific studies of episodic memory and imagination. Google promotes a new form of “infrastructural intelligence,” which excels by constantly reassessing its cognitive architecture in exchange with a cloud of data that surrounds it, and exhibits putatively human capacities such as intuition. I argue that such (re)alignments of biological and artificial intelligence have been enabled by a paradigmatic infrastructuralization of the brain in contemporary neuroscience. This infrastructuralization is based in methodologies that epistemically liken the brain to complex systems of an entirely different scale (i.e., global logistics) and has given rise to diverse research efforts that target the neuronal infrastructures of higher cognitive functions such as empathy and creativity. What is at stake in this process is no less than the shape of brains to come and a revised understanding of the intelligent and creative social subject.;2017-01-01;2021-02-11T01:16:33Z;2021-02-11T01:16:33Z;2021-02-11T01:16:33Z;101-128;NA;NA;233;NA;NA;Chapter 5 - Infrastructural intelligence;Vital Models;NA;NA;NA;Elsevier;NA;en;NA;NA;NA;NA;ScienceDirect;NA;DOI: 10.1016/bs.pbr.2017.06.004;NA;C:\Users\esben\Zotero\storage\BH9A7XHX\S0079612317300547.html;NA;NA;"Artificial intelligence; Brain imaging; Computational neuroscience; Default mode network; Google DeepMind technologies";"Mahfoud, Tara; McLean, Sam; Rose, Nikolas";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Z7HRVCTQ;journalArticle;2020;"Mawani, Aarif; Nderu, Lawrence";Towards an Online Empathy Assisted Counselling Web Application;EAI Endorsed Transactions on Context-aware Systems and Applications;NA;2409-0026;NA;https://eudl.eu/doi/10.4108/eai.23-12-2020.167792;NA;2020-12-23;2021-02-11T01:16:34Z;2021-02-11T01:16:34Z;2021-02-11T01:16:34Z;NA;NA;22;"""7""";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;eudl.eu;NA;NA;NA;"C:\Users\esben\Zotero\storage\DN2LYKA9\Mawani and Nderu - 2020 - Towards an Online Empathy Assisted Counselling Web.pdf; C:\Users\esben\Zotero\storage\72IT8TJ2\eai.23-12-2020.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Q236UETL;webpage;2019;"Musavian, Samaneh Sadat; Fardanesh, Hashem; Talaee, Ebrahim";Developing a Fuzzy Clustering-Based Method for Categorizing Young Adolescent Students Based on Their Empathy Scores and Exploring the Relationship Between Their Empathy and Learning Behaviors;International Journal of School Health;NA;NA;NA;https://doaj.org;DOAJ is a community-curated online directory that indexes and provides access to high quality, open access, peer-reviewed journals.;2019-01-01;2021-02-11T01:18:10Z;2021-02-11T01:18:10Z;2021-02-11T01:18:10Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;NA;NA;ISSN: 2345-5152, 2383-1219 Issue: 1 Pages: 1-8 Publisher: Shiraz University of Medical Sciences Volume: 6 DOI: 10.5812/intjsh.82604;NA;C:\Users\esben\Zotero\storage\YHT6CVRT\cc48336aae394333b77a50ad08f3ccf7.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
YQ7HKYQ2;journalArticle;2019;Wartman, Steven A.;The Empirical Challenge of 21st-Century Medical Education;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000002866;https://journals.lww.com/academicmedicine/Fulltext/2019/10000/The_Empirical_Challenge_of_21st_Century_Medical.9.aspx;Medical education is at a crossroads. Facing challenges wrought by science and technology as well as societal change, the curriculum is increasingly out of synch with new needs in teaching content and medical practice. The path to significant curricular reform is difficult because of a variety of factors, including deeply entrenched values, the natural resistance to change, and the accreditation process. Indeed, even the very definition of what it means to be a professional is changing with profound implications for the future role of the physician and the sacrosanct doctor–patient relationship.         In this Invited Commentary, the author enumerates challenges facing medical education in the current era. To address these challenges, the author recommends specific curricular emphases for 21st-century medical education: knowledge capture and curation, collaboration with and management of artificial intelligence applications, a deep understanding of probabilistic reasoning, and the cultivation of empathy and compassion in accordance with ethical standards. Given these needs, it is imperative that schools act today to undertake significant curricular reform and, in so doing, strive to make the hard changes necessary to produce optimal practitioners in a rapidly transforming 21st century. The author provides first steps an institution can take to begin to address these challenges.;2019-10;2021-02-11T01:18:15Z;2021-02-11T01:18:15Z;2021-02-11T01:18:15Z;1412–1415;NA;10;94;NA;NA;NA;NA;NA;NA;NA;NA;NA;en-US;NA;NA;NA;NA;journals.lww.com;NA;NA;NA;C:\Users\esben\Zotero\storage\I2SEBSKU\The_Empirical_Challenge_of_21st_Century_Medical.9.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
G97H98FI;journalArticle;2020;"Jenkins, Julian; Poel, Sheryl van der; Krüssel, Jan; Bosch, Ernesto; Nelson, Scott M.; Pinborg, Anja; Yao, Mylene M. W.";Empathetic application of machine learning may address appropriate utilization of ART;Reproductive BioMedicine Online;NA;1472-6483, 1472-6491;10.1016/j.rbmo.2020.07.005;https://www.rbmojournal.com/article/S1472-6483(20)30376-X/abstract;"<h2>Abstract</h2><p>The value of artificial intelligence to benefit infertile patients is a subject of debate. This paper presents the experience of one aspect of artificial intelligence, machine learning, coupled with patient empathy to improve utilization of assisted reproductive technology (ART), which is an important aspect of care that is under-recognized. Although ART provides very effective options for infertile patients to build families, patients often discontinue ART when further treatment is likely to be beneficial and most of these patients do not achieve pregnancy without medical aid. Use of ART is only in part dependent on financial considerations; stress and other factors play a major role, as shown by high discontinuation rates despite reimbursement. This commentary discusses challenges and strategies to providing personalized ART prognostics based on machine learning, and presents a case study where appropriate use of such prognostics in ART centres is associated with a trend towards increased ART utilization.</p>";2020-10-01;2021-02-11T01:18:16Z;2021-02-11T01:18:16Z;2021-02-11T01:18:16Z;573-577;NA;4;41;NA;Reproductive BioMedicine Online;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;www.rbmojournal.com;NA;Publisher: Elsevier PMID: 32819841;NA;"C:\Users\esben\Zotero\storage\T4WSCZCN\Jenkins et al. - 2020 - Empathetic application of machine learning may add.pdf; ; C:\Users\esben\Zotero\storage\XDUVE8YG\fulltext.html";http://www.ncbi.nlm.nih.gov/pubmed/32819841;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
49DEJICQ;journalArticle;2019;"Clavelle, Joanne T.; Sweeney, Cynthia D.; Swartwout, Ellen; Lefton, Cindy; Guney, Senem";Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition;JONA: The Journal of Nursing Administration;NA;0002-0443;10.1097/NNA.0000000000000757;https://journals.lww.com/jonajournal/Abstract/2019/06000/Leveraging_Technology_to_Sustain_Extraordinary.6.aspx;OBJECTIVE          Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing.         BACKGROUND          Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science.         METHODS          Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics.         RESULTS          The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough.         CONCLUSIONS          AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented.;2019-06;2021-02-11T01:18:21Z;2021-02-11T01:18:21Z;2021-02-11T01:18:21Z;303–309;NA;6;49;NA;NA;Leveraging Technology to Sustain Extraordinary Care;NA;NA;NA;NA;NA;NA;en-US;NA;NA;NA;NA;journals.lww.com;NA;NA;NA;C:\Users\esben\Zotero\storage\W2NDVXST\Leveraging_Technology_to_Sustain_Extraordinary.6.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TI3SHXWY;journalArticle;2021;"Alrassi, James; Katsufrakis, Peter J.; Chandran, Latha";Technology Can Augment, but Not Replace, Critical Human Skills Needed for Patient Care;Academic Medicine;NA;1040-2446;10.1097/ACM.0000000000003733;https://journals.lww.com/academicmedicine/Abstract/2021/01000/Technology_Can_Augment,_but_Not_Replace,_Critical.33.aspx;"The practice of medicine is changing rapidly as a consequence of electronic health record adoption, new technologies for patient care, disruptive innovations that breakdown professional hierarchies, and evolving societal norms. Collectively, these have resulted in the modification of the physician’s role as the gatekeeper for health care, increased shift-based care, and amplified interprofessional team-based care. Technological innovations present opportunities as well as challenges. Artificial intelligence, which has great potential, has already transformed some tasks, particularly those involving image interpretation. Ubiquitous access to information via the Internet by physicians and patients alike presents benefits as well as drawbacks: patients and providers have ready access to virtually all of human knowledge, but some websites are contaminated with misinformation and many people have difficulty differentiating between solid, evidence-based data and untruths. The role of the future physician will shift as complexity in health care increases and as artificial intelligence and other technologies advance. These technological advances demand new skills of physicians; memory and knowledge accumulation will diminish in importance while information management skills will become more important. In parallel, medical educators must enhance their teaching and assessment of critical human skills (e.g., clear communication, empathy) in the delivery of patient care. The authors emphasize the enduring role of critical human skills in safe and effective patient care even as medical practice is increasingly guided by artificial intelligence and related technology, and they suggest new and longitudinal ways of assessing essential noncognitive skills to meet the demands of the future. The authors envision practical and achievable benefits accruing to patients and providers if practitioners leverage technological advancements to facilitate the development of their critical human skills.";2021-01;2021-02-11T01:18:22Z;2021-02-11T01:18:22Z;2021-02-11T01:18:22Z;37–43;NA;1;96;NA;NA;NA;NA;NA;NA;NA;NA;NA;en-US;NA;NA;NA;NA;journals.lww.com;NA;NA;NA;C:\Users\esben\Zotero\storage\FPN3CQUW\Technology_Can_Augment,_but_Not_Replace,_Critical.33.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
DSN57RZ6;journalArticle;2019;"Wartman, Steven A.; Combs, C. Donald";Reimagining Medical Education in the Age of AI;AMA Journal of Ethics;NA;2376-6980;10.1001/amajethics.2019.146.;https://journalofethics.ama-assn.org/article/reimagining-medical-education-age-ai/2019-02;Available medical knowledge exceeds the organizing capacity of the human mind;2019-02-01;2021-02-11T01:18:24Z;2021-02-11T01:18:24Z;2021-02-11T01:18:24Z;146-152;NA;2;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;journalofethics.ama-assn.org;NA;Publisher: American Medical Association;NA;"C:\Users\esben\Zotero\storage\SA2BMBSC\Wartman and Combs - 2019 - Reimagining Medical Education in the Age of AI.pdf; C:\Users\esben\Zotero\storage\B6M9C8MK\2019-02.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
EAV9T5UL;journalArticle;2013;Sousa, Avinash De;Towards an integrative theory of consciousness: Part 2 (An anthology of various other models);Mens Sana Monographs;NA;0973-1229;10.4103/0973-1229.109341;"https://www.msmonographs.org/article.asp?issn=0973-1229;year=2013;volume=11;issue=1;spage=151;epage=209;aulast=De;type=0";The study of consciousness has today moved beyond neurobiology and cognitive models. In the past few years, there has been a surge of research into various newer areas. The present article looks at the non-neurobiological and non-cognitive theories regarding this complex phenomenon, especially ones that self-psychology, self-theory, artificial intelligence, quantum physics, visual cognitive science and philosophy have to offer. Self-psychology has proposed the need to understand the self and its development, and the ramifications of the self for morality and empathy, which will help us understand consciousness better. There have been inroads made from the fields of computer science, machine technology and artificial intelligence, including robotics, into understanding the consciousness of these machines and their implications for human consciousness. These areas are explored. Visual cortex and emotional theories along with their implications are discussed. The phylogeny and evolution of the phenomenon of consciousness is also highlighted, with theories on the emergence of consciousness in fetal and neonatal life. Quantum physics and its insights into the mind, along with the implications of consciousness and physics and their interface are debated. The role of neurophilosophy to understand human consciousness, the functions of such a concept, embodiment, the dark side of consciousness, future research needs and limitations of a scientific theory of consciousness complete the review. The importance and salient features of each theory are discussed along with certain pitfalls, if present. A need for the integration of various theories to understand consciousness from a holistic perspective is stressed.;2013-01-01;2021-02-11T01:18:25Z;2021-02-11T01:18:25Z;2021-02-11T01:18:25Z;151;NA;1;11;NA;NA;Towards an integrative theory of consciousness;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;www.msmonographs.org;NA;Company: Medknow Publications and Media Pvt. Ltd. Distributor: Medknow Publications and Media Pvt. Ltd. Institution: Medknow Publications and Media Pvt. Ltd. Label: Medknow Publications and Media Pvt. Ltd. Publisher: Medknow Publications PMID: 23678242;NA;"; C:\Users\esben\Zotero\storage\P6YAUBRH\article.html";http://www.ncbi.nlm.nih.gov/pubmed/23678242;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
S774MZXR;journalArticle;2018;Taylor, Jane;On Uncertainty;Kronos;NA;0259-0190;10.17159/2309-9585/2018/v44a11;http://www.scielo.org.za/scielo.php?script=sci_abstract&pid=S0259-01902018000100011&lng=en&nrm=iso&tlng=en;NA;2018;2021-02-11T01:18:27Z;2021-02-11T01:18:27Z;2021-02-11T01:18:27Z;181-195;NA;1;44;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;SciELO;NA;Publisher: Kronos;NA;"C:\Users\esben\Zotero\storage\4ZJGK6CG\scielo.html; C:\Users\esben\Zotero\storage\4WGKBZND\Taylor - 2018 - On Uncertainty.pdf";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
V66XSQSU;journalArticle;2019;"Lee, Yeonjoo; Ha, Miyeon; Kwon, Sujeong; Shim, Yealin; Kim, Jinwoo";Egoistic and altruistic motivation: How to induce users’ willingness to help for imperfect AI;Computers in Human Behavior;NA;0747-5632;10.1016/j.chb.2019.06.009;https://www.sciencedirect.com/science/article/pii/S0747563219302274;Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI.;2019-12-01;2021-02-11T01:18:30Z;2021-02-11T01:18:30Z;2021-02-11T01:18:30Z;180-196;NA;NA;101;NA;Computers in Human Behavior;Egoistic and altruistic motivation;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;ScienceDirect;NA;NA;NA;"C:\Users\esben\Zotero\storage\UKNFMWFE\Lee et al. - 2019 - Egoistic and altruistic motivation How to induce .pdf; C:\Users\esben\Zotero\storage\VC5I6E8H\S0747563219302274.html";NA;NA;"AI (Artificial Intelligence); Explainable AI; Food image recognition; Human in the loop (HITL); Trust; Willingness to help";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
X2DWJH9L;journalArticle;NA;"Erden, Yasemin J.; Hummerstone, Harriet; Rainey, Stephen";Automating autism assessment: What AI can bring to the diagnostic process;Journal of Evaluation in Clinical Practice;NA;1365-2753;https://doi.org/10.1111/jep.13527;https://onlinelibrary.wiley.com/doi/abs/10.1111/jep.13527;This paper examines the use of artificial intelligence (AI) for the diagnosis of autism spectrum disorder (ASD, hereafter autism). In so doing we examine some problems in existing diagnostic processes and criteria, including issues of bias and interpretation, and on concepts like the ‘double empathy problem’. We then consider how novel applications of AI might contribute to these contexts. We're focussed specifically on adult diagnostic procedures as childhood diagnosis is already well covered in the literature.;NA;2021-02-11T01:18:32Z;2021-02-11T01:18:32Z;2021-02-11T01:18:32Z;NA;NA;n/a;n/a;NA;NA;Automating autism assessment;NA;NA;NA;NA;NA;NA;en;© 2020 The Authors. Journal of Evaluation in Clinical Practice published by John Wiley & Sons Ltd.;NA;NA;NA;Wiley Online Library;NA;_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jep.13527;NA;"C:\Users\esben\Zotero\storage\7HC7FKVF\Erden et al. - Automating autism assessment What AI can bring to.pdf; C:\Users\esben\Zotero\storage\W643U39T\jep.html";NA;NA;"artificial intelligence; autism; diagnosis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KFVPGUP8;journalArticle;2019;"Mesquita, Evandro Tinoco; Souza, Aurea Lucia Alves de Azevedo Grippa de; Mesquita, Evandro Tinoco; Souza, Aurea Lucia Alves de Azevedo Grippa de";Cardiology and the Cardiologist - Yesterday, Today and Tomorrow;Arquivos Brasileiros de Cardiologia;NA;0066-782X;10.5935/abc.20190207;http://www.scielo.br/scielo.php?script=sci_abstract&pid=S0066-782X2019000900335&lng=en&nrm=iso&tlng=en;NA;2019-09;2021-02-11T01:18:33Z;2021-02-11T01:18:33Z;2021-02-11T01:18:33Z;335-338;NA;3;113;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;SciELO;NA;Publisher: Arquivos Brasileiros de Cardiologia;NA;"C:\Users\esben\Zotero\storage\ZY3QFU4J\Mesquita et al. - 2019 - Cardiology and the Cardiologist - Yesterday, Today.pdf; C:\Users\esben\Zotero\storage\5ICG5CEE\scielo.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Z9QFTYFM;journalArticle;2020;"Joda, Tim; Bornstein, Michael M.; Jung, Ronald E.; Ferrari, Marco; Waltimo, Tuomas; Zitzmann, Nicola U.";Recent Trends and Future Direction of Dental Research in the Digital Era;International Journal of Environmental Research and Public Health;NA;NA;10.3390/ijerph17061987;https://www.mdpi.com/1660-4601/17/6/1987;The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.;2020-01;2021-02-11T01:18:36Z;2021-02-11T01:18:36Z;2021-02-11T01:18:36Z;1987;NA;6;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;en;http://creativecommons.org/licenses/by/3.0/;NA;NA;NA;www.mdpi.com;NA;Number: 6 Publisher: Multidisciplinary Digital Publishing Institute;NA;"C:\Users\esben\Zotero\storage\M647Z94J\Joda et al. - 2020 - Recent Trends and Future Direction of Dental Resea.pdf; C:\Users\esben\Zotero\storage\HCDRKF4I\1987.html";NA;NA;"artificial intelligence (AI); augmented and virtual reality (AR/VR); digital transformation; machine learning (ML); patient-centered outcomes; personalized dental medicine; rapid prototyping; tele-health";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
89XI9J8G;webpage;2019;서대성;무한연결시 4차 산업기술의 이용 가능성 분석을 통한 감성 인공 지능의 자율 결정권에 관한 연구;융합정보논문지 = Journal of Convergence for Information Technology;NA;NA;NA;http://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=JAKO201924763903266;본 논문은 인공 지능 기술의 효과는 산업에 미치는 영향과 일상생활의 변화 등에 관한 연구이다. 또한 감성 인공 지능 개발은 차세대 3D 벡터 감응 인공 지능을 대비한다. 이것은 인공 지능의 의사 결정 권력의 주요 키워드를 제시한다. 특히 비 윤리적 학습의 중요성과 윤리적 가치 판단을 반영하는 의사 결정 시스템의 구현으로 인해 중요한 결과가 달성된다. 이것은 데이터 기반 시뮬레이션이며 (1) 사용 가능한 데이터, (2) 시뮬레이션 목표를 위한 기술을 필요로 한다. 실제 의도된 시뮬레이션 기반 연구의 일반적인 내용을 고려한다. 현재 기존 연구는 의미있는 연구 동기에 중점을 두고있느나, 본 연구는 기술의 방향성을 제시하는 결과이다. 그 결과 실증분석은 각국이 인공 지능에 대한 신기술 기업의 윤리 책임감에 대한 의사 결정력과 일치한다. 결론적으로, AI / ML의 기술적 측면에 대한 윤리적 주제에 대해 달성 할 수 있는 구체적인 기여와 해석이 필요하다. 이는 인공지능 의사 결정에서 인간의 공감의 분석력이 더욱 부각될 수 있다.;2019;2021-02-11T01:18:38Z;2021-02-11T01:18:38Z;2021-02-11T01:18:38Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;da;NA;NA;NA;NA;NA;NA;ISSN: 2586-1816 Issue: 8 Pages: 9-19 Publisher: Convergence Society for SMB Volume: 9;NA;C:\Users\esben\Zotero\storage\Z437P8AY\selectPORSrchArticle.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
5BT36I6V;journalArticle;2019;Bhalla, Navneet;The 3S Process: A Framework for Teaching AI Strategy in Business Education;Technology Innovation Management Review;NA;1927-0321;http://doi.org/10.22215/timreview/1290;NA;NA;2019;2021-02-11T01:19:51Z;2021-02-11T01:19:51Z;NA;36-42;NA;12;9;NA;NA;The 3S Process;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: Ottawa Publisher: Talent First Network;NA;C:\Users\esben\Zotero\storage\42CJ7A99\1290.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
RVI9Q367;journalArticle;2020;"Chiang, Ai-Hsuan; Trimi, Silvana";Impacts of service robots on service quality;Service Business;NA;1862-8508;10.1007/s11628-020-00423-8;https://doi.org/10.1007/s11628-020-00423-8;With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority.;2020-09-01;2021-02-11T01:19:57Z;2021-02-11T01:19:57Z;2021-02-11T01:19:57Z;439-459;NA;3;14;NA;Serv Bus;NA;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;Springer Link;NA;NA;NA;C:\Users\esben\Zotero\storage\HUBG82HJ\Chiang and Trimi - 2020 - Impacts of service robots on service quality.pdf;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
EC8CM2TP;journalArticle;2019;Bristol, R. Curtis;An Essay on Narrative, Reality, and Imagination;Psychoanalytic Inquiry;NA;0735-1690;10.1080/07351690.2019.1659025;https://doi.org/10.1080/07351690.2019.1659025;"Narrative is a verbal account, a story of related events which can be factual, fictional or both. Life experience and imagination are as essential to narrative as narrative is to mankind. The phylogenic perspective of literature suggests an inborn capacity for empathy, intelligence and inventiveness, whereas the ontological example is variable. Western knowledge, politics and ethics have evolved from their narrative of Greek myth, epic and drama, the few medieval writers, singularly by the Elizabethan theater, importantly the Arthurian legend and romance stories, English and Russian novels, and uniquely the American short story. This heritage progressively demarcated such life themes as the hero, maiden and adversary; love, hate and indifference; loyalty, deception and betrayal; desire, achievement and loss. These characterizations of self and other remain relevant to the contemporary novel, cinema/TV, and theater, as well as the news, commentary, and real life. Conversely, postmodern assumptions challenge that individual subjectivity determines what is real, valid or authentic, consequently the relativism of traditional, institutional and historical precedents of the truth. Further, the computer, gaming, smart device, and artificial intelligence have changed the content and function of customary narrative. Nonetheless, narrative — real and imagined, ancient and new — retains the meaning of a story about connected events which variously transcends the boundaries of difference.";2019-10-03;2021-02-11T01:19:59Z;2021-02-11T01:19:59Z;2021-02-11T01:19:59Z;476-484;NA;7;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Taylor and Francis+NEJM;NA;Publisher: Routledge _eprint: https://doi.org/10.1080/07351690.2019.1659025;NA;C:\Users\esben\Zotero\storage\CJI9EMC3\07351690.2019.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
AYSSTEYM;journalArticle;2017;"Chen, Julie; Chen, Julie";Playing to our human strengths to prepare medical students for the future;Korean Journal of Medical Education;NA;2005-727X, 2005-7288;10.3946/kjme.2017.65;http://www.kjme.kr/journal/view.php?doi=10.3946/kjme.2017.65;NA;2017-08-29;2021-02-11T01:20:00Z;2021-02-11T01:20:00Z;2021-02-11T01:20:00Z;193-197;NA;3;29;NA;Korean J Med Educ;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;www.kjme.kr;NA;Publisher: Korean Society of Medical Education;NA;"C:\Users\esben\Zotero\storage\LE7P7RRI\Chen and Chen - 2017 - Playing to our human strengths to prepare medical .pdf; C:\Users\esben\Zotero\storage\2UQM7HYR\view.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KZKRHA38;journalArticle;2019;Signes, Adrìan Todolì;En cumplimiento de la primera Ley de la robótica: Análisis de los riesgos laborales asociados a un algoritmo/inteligencia artificial dirigiendo el trabajo;Labour & Law Issues;NA;2421-2695;10.6092/issn.2421-2695/10237;https://labourlaw.unibo.it/article/view/10237;NA;2019-12-20;2021-02-11T01:20:01Z;2021-02-11T01:20:01Z;2021-02-11T01:20:01Z;C. 1-38;NA;2;5;NA;LLI;En cumplimiento de la primera Ley de la robótica;NA;NA;NA;NA;NA;NA;es;Copyright (c) 2019;NA;NA;NA;labourlaw.unibo.it;NA;Number: 2;NA;"C:\Users\esben\Zotero\storage\MT4L45JW\Signes - 2019 - En cumplimiento de la primera Ley de la robótica .pdf; C:\Users\esben\Zotero\storage\EBM7LFH9\10237.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TXIKAA63;journalArticle;2014;Gofron, Beata;La escuela en la era de Internet;Educación y Educadores;NA;2027-5358;NA;https://educacionyeducadores.unisabana.edu.co/index.php/eye/article/view/3513;NA;2014-05-21;2021-02-11T01:20:03Z;2021-02-11T01:20:03Z;2021-02-11T01:20:03Z;NA;NA;1;17;NA;educ. educ.;NA;NA;NA;NA;NA;NA;NA;es;Derechos de autor;NA;NA;NA;educacionyeducadores.unisabana.edu.co;NA;Number: 1;NA;"C:\Users\esben\Zotero\storage\T4LC6HQH\Gofron - 2014 - La escuela en la era de Internet.pdf; C:\Users\esben\Zotero\storage\4X6LX4SS\3513.html";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Y9A2NTSX;webpage;2019;"Blanco-Pérez, Carlos; Pérez-Casares, Alexandre; Rodrigáñez-Riesco, Ramón";Educating for the Future: Empowering the Human Mind and Redefining Values and Citizenship in the Age of Technological Disruption*;Cadmus;NA;NA;NA;https://doaj.org;DOAJ is a community-curated online directory that indexes and provides access to high quality, open access, peer-reviewed journals.;2019-05-01;2021-02-11T01:20:05Z;2021-02-11T01:20:05Z;2021-02-11T01:20:05Z;NA;NA;NA;NA;NA;NA;Educating for the Future;NA;NA;NA;NA;NA;NA;en;NA;NA;NA;NA;NA;NA;ISSN: 2038-5242, 2038-5250 Issue: 6 Pages: 129-147 Publisher: Risk Institute, Trieste- Geneva Volume: 3;NA;C:\Users\esben\Zotero\storage\S5YL3NKB\6933753ed6bc4ab9a7d8b2082356609b.html;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
W47IF8ZX;journalArticle;2020;"Srivastava, Tripti K; Waghmare, Lalitbhushan";Implications of Artificial Intelligence (AI) on Dynamics of Medical Education and Care: A Perspective;JOURNAL OF CLINICAL AND DIAGNOSTIC RESEARCH;NA;2249782X;10.7860/JCDR/2020/43293.13565;https://jcdr.net/article_fulltext.asp?issn=0973-709x&year=2020&volume=14&issue=3&page=JI01&issn=0973-709x&id=13565;NA;2020;2021-02-11T01:20:26Z;2021-02-11T01:20:26Z;2021-02-11T01:20:26Z;NA;NA;NA;NA;NA;JCDR;Implications of Artificial Intelligence (AI) on Dynamics of Medical Education and Care;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;DOI.org (Crossref);NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2VCXFY39;journalArticle;2013;"Leite, Iolanda; Pereira, André; Mascarenhas, Samuel; Martinho, Carlos; Prada, Rui; Paiva, Ana";The influence of empathy in human-robot relations;YIJHC International Journal of Human - Computer Studies;NA;1071-5819;NA;NA;The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human-robot interaction.<br>Highlights: ► We have developed an empathic robot that comments a chess match between two players. ► The robot displays empathic behaviours towards one of the players and behaves neutrally towards the other player. ► The empathic model is based on the idea that to obtain empathy one has to put himself/herself on the other's shoes. ► The results of a trial with 40 participants are described and discussed. ► Participants towards whom the robot behaved empathically perceived the robot as friendlier.;2013;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;250-260;NA;3;71;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5902447489;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TWUM3ED7;journalArticle;2019;"Cross ES; Riddoch KA; Pratts J; Titone S; Chaudhury B; Hortensius R";A neurocognitive investigation of the impact of socializing with a robot on empathy for pain.;Philosophical transactions of the Royal Society of London. Series B, Biological sciences;NA;0962-8436;NA;NA;To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'.;2019;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;NA;NA;1771;374;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8020591735;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
3LJ6N5IS;journalArticle;2018;"Anshar M; Williams MA";Evolving robot empathy towards humans with motor disabilities through artificial pain generation.;AIMS neuroscience;NA;NA;NA;NA;In contact assistive robots, a prolonged physical engagement between robots and humans with motor disabilities due to shoulder injuries, for instance, may at times lead humans to experience pain. In this situation, robots will require sophisticated capabilities, such as the ability to recognize human pain in advance and generate counter-responses as follow up emphatic action. Hence, it is important for robots to acquire an appropriate pain concept that allows them to develop these capabilities. This paper conceptualizes empathy generation through the realization of synthetic pain classes integrated into a robot's self-awareness framework, and the implementation of fault detection on the robot body serves as a primary source of pain activation. Projection of human shoulder motion into the robot arm motion acts as a fusion process, which is used as a medium to gather information for analyses then to generate corresponding synthetic pain and emphatic responses. An experiment is designed to mirror a human peer's shoulder motion into an observer robot. The results demonstrate that the fusion takes place accurately whenever unified internal states are achieved, allowing accurate classification of synthetic pain categories and generation of empathy responses in a timely fashion. Future works will consider a pain activation mechanism development.;2018;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;56-73;NA;1;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8583916455;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FFKJKZU7;journalArticle;2018;"Nishida, Toyoaki; Vallverdú, Jordi; Ohmoto, Yoshisama; Moran, Stuart; Lázare, Sarah";Fake Empathy and Human-Robot Interaction (HRI): A Preliminary Study;International Journal of Technology and Human Interaction (IJTHI);NA;1548-3908;NA;NA;Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call ‘fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different ‘humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi- angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment.;2018;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;44-59;NA;1;14;NA;NA;Fake Empathy and Human-Robot Interaction (HRI);NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7175996112;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9FISGRTK;journalArticle;2015;"Suzuki Y; Galli L; Ikeda A; Itakura S; Kitazaki M";Measuring empathy for human and robot hand pain using electroencephalography.;Scientific reports;NA;NA;NA;NA;This study provides the first physiological evidence of humans' ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.;2015;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5910790115;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
898QKTJJ;journalArticle;2018;NA;Emotional Empathy as a Mechanism of Synchronisation in Child-Robot Interaction;Frontiers in Psychology;NA;1664-1078;NA;NA;Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children’s brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation.;2018;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7891657455;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JBFNVT2L;journalArticle;2010;Coeckelbergh, Mark;Artificial companions: empathy and vulnerability mirroring in human-robot relations;Studies in ethics, law, and technology;NA;1941-6008;NA;NA;Under what conditions can robots become companions and what are the ethical issues that might arise in human-robot companionship relations? I argue that the possibility and future of robots as companions depends (among other things) on the robot’s capacity to be a recipient of human empathy, and that one necessary condition for this to happen is that the robot mirrors human vulnerabilities. For the purpose of these arguments, I make a distinction between empathy-as-cognition and empathy-as-feeling, connecting the latter to the moral sentiment tradition and its concept of “fellow feeling.” Furthermore, I sympathise with the intuition that vulnerability mirroring raises the ethical issue of deception. However, given the importance of appearance in social relations, problems with the concept of deception, and contemporary technologies that question the artificial-natural distinction, we cannot easily justify the underlying assumptions of the deception objection. If we want to hold on to them, we need convincing answers to these problems;2010;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;NA;NA;3;4;NA;NA;Artificial companions;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7079745743;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
344ENHS6;journalArticle;2015;"Lim, Angelica; Okuno, Hiroshi G";A Recipe for Empathy: Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an <i>emergent</i> behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (“flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence.;2015;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;35-49;NA;1;7;NA;NA;A Recipe for Empathy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5778623320;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
UQRSBW7S;journalArticle;2015;"Damiano, Luisa; Dumouchel, Paul; Lehmann, Hagen";Towards Human-Robot Affective Co-evolution Overcoming Oppositions in Constructing Emotions and Empathy;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;This article deals with contemporary research aimed at building emotional and empathic robots, and gives an overview of the field focusing on its main characteristics and ongoing transformations. It interprets the latter as precursors to a paradigmatic transition that could significantly change our social ecologies. This shift consists in abandoning the classical view of emotions as essentially individual states, and developing a relational view of emotions, which, as we argue, can create genuinely new emotional and empathic processes—dynamics of “human-robot” affective coordination supporting the development of mixed (human-robot) ecologies.;2015;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;7-18;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5778625323;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
LEWL2AN8;journalArticle;2020;NA;The Role of Personality Factors and Empathy in the Acceptance and Performance of a Social Robot for Psychometric Evaluations;Robotics;NA;2218-6581;NA;NA;Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users’ intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users’ factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user’s empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the “openness to experience”, on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests.;2020;2021-02-15T22:17:28Z;2021-02-15T22:17:28Z;NA;NA;NA;39;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8615609583;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Y4V8FXSE;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots;JTMA Tourism Management;NA;0261-5177;NA;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;NA;NA;NA;78;NA;NA;Leveraging human-robot interaction in hospitality services;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8524221774;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6YY73XNY;journalArticle;2019;"Johanson DL; Ahn HS; MacDonald BA; Ahn BK; Lim J; Hwang E; Sutherland CJ; Broadbent E";The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction: Randomized Controlled Trial.;Journal of medical Internet research;NA;1439-4456;NA;NA;BACKGROUND: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. OBJECTIVE: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. METHODS: A parallel randomized controlled trial with a 1:1:1:1 allocation ratio was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. RESULTS: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). CONCLUSIONS: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings.;2019;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;NA;NA;10;21;NA;NA;The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8270511494;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JK8D4XHK;journalArticle;2019;NA;Embodiment into a robot increases its acceptability;Scientific Reports;NA;2045-2322;NA;NA;Abstract Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects’ head movements. As a result, participants saw themselves as a robot. When participant’ and robot’s head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots’ humanoid’s appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;1-10;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8186515654;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
V5DIN8D6;journalArticle;2019;"Ventre-Dominey, J; Gibert, G; Bosse-Platiere, M; Farnè, A; Dominey, P. F; Pavani, F";Embodiment into a robot increases its acceptability;Sci Rep Scientific Reports;NA;NA;NA;NA;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects’ head movements. As a result, participants saw themselves as a robot. When participant’ and robot’s head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots’ humanoid’s appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;1-10;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8175853278;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NM52RJHM;journalArticle;2019;"Ventre-Dominey J; Gibert G; Bosse-Platiere M; Farnè A; Dominey PF; Pavani F";Embodiment into a robot increases its acceptability.;Scientific reports;NA;NA;NA;NA;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects' head movements. As a result, participants saw themselves as a robot. When participant' and robot's head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots' humanoid's appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;NA;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8176132738;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
IZIVZIQV;journalArticle;2015;"Tisseron, Serge; Tordo, Frédéric; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;97-102;NA;1;7;NA;NA;Testing Empathy with Robots;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5778625970;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
UX95F9IZ;journalArticle;2017;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe";Simulating empathic behavior in a social assistive robot;Multimed Tools Appl Multimedia Tools and Applications : An International Journal;NA;1380-7501;NA;NA;When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user’s affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot’s affective state and, consequently, the most appropriate empathic behavior. The robot’s empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.;2017;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;5073-5094;NA;4;76;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6987078628;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2Q45DKKK;journalArticle;2017;"Rouaix N; Retru-Chavastel L; Rigaud AS; Monnet C; Lenoir H; Pino M";Affective and Engagement Issues in the Conception and Assessment of a Robot-Assisted Psychomotor Therapy for Persons with Dementia.;Frontiers in psychology;NA;1664-1078;NA;NA;"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a ""control software"" for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient- therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction.";2017;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7088352818;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
GX2YW6VS;journalArticle;2020;"Trost MJ; Chrysilla G; Gold JI; Matarić M";Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children.;Pain research & management;NA;1203-6765;NA;NA;"Objectives: Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods: We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot's empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with NCT02840942. Results: Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions: Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management.";2020;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;NA;NA;NA;2020;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8585130163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
J666V68B;journalArticle;2014;"Rosenthal-von der Pütten, Astrid M; Schulte, Frank P; Eimler, Sabrina C; Sobieraj, Sabrina; Hoffmann, Laura; Maderwald, Stefan; Brand, Matthias; Krämer, Nicole C";Investigations on empathy towards humans and robots using fMRI;CHB Computers in Human Behavior;NA;0747-5632;NA;NA;• We examine emotional reactions and empathy towards robots and humans using fMRI. • Overall HHI and HRI elicit similar neural activation patterns in limbic structures. • Abusive HHI results in more neural activation than abusive HRI. • Self-report findings regarding participant’s emotional states support fMRI results.<br>Although robots are starting to enter into our professional and private lives, little is known about the emotional effects they elicit. In line with the Media Equation, humans may react towards robots as they do towards humans, making it all the more important to carefully investigate the preconditions and consequences of contact with robots. Based on assumptions on the socialness of reactions towards robots, we conducted a study that provides further insights into the question of whether humans show emotional reactions towards a robot and whether these reactions differ from those towards a human. To explore emotionality in human-robot interaction we conducted an fMRI study (<b>n</b> = 14). Participants were presented videos showing a human, a robot and an inanimate object, being treated in either an affectionate or in a violent way. Self-reported emotional states and functional imaging data revealed that participants indeed reacted emotionally when seeing the affectionate and violent videos. While no different neural activation patterns emerged for the affectionate interaction towards both, the robot and the human, we found differences in neural activity when comparing only the videos showing abusive behavior indicating that participants experience more emotional distress and show negative empathetic concern for the human in the abuse condition. This was supported by similar findings with regard to participant’s self-reported emotional states.;2014;2021-02-15T22:17:42Z;2021-02-15T22:17:42Z;NA;201-212;NA;NA;33;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5900044979;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
AN9PRN6L;journalArticle;2011;"Mazzei D; Lazzeri N; Billeci L; Igliozzi R; Mancini A; Ahluwalia A; Muratori F; De Rossi D";Development and evaluation of a social robot platform for therapy in autism.;Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference;NA;NA;NA;NA;"People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred ""affective"" state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training.";2011;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;4515-8;NA;NA;2011;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 776527824;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VLTIF6HH;journalArticle;2020;"Pepito JA; Ito H; Betriana F; Tanioka T; Locsin RC";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations.;Nursing philosophy : an international journal for healthcare professionals;NA;1466-7681;NA;NA;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.";2020;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8885013400;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
349H7JIN;journalArticle;2019;"Rincon, Jaime A; Costa, Angelo; Novais, Paulo; Julian, Vicente; Carrascosa, Carlos";A new emotional robot assistant that facilitates human interaction and persuasion;Knowl Inf Syst Knowledge and Information Systems : An International Journal;NA;0219-1377;NA;NA;The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare center in the northern area of Portugal.;2019;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;363-383;NA;1;60;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8179681335;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VAD7359N;journalArticle;2013;"Kühnlenz, Barbara; Sosnowski, Stefan; Buß, Malte; Wollherr, Dirk; Kühnlenz, Kolja; Buss, Martin";Increasing Helpfulness towards a Robot by Emotional Adaption to the User;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;This article describes an emotional adaption approach to proactively trigger increased helpfulness towards a robot in task-related human-robot interaction (HRI). Based on social-psychological predictions of human behavior, the approach aims at inducing empathy, paired with a feeling of similarity in human users towards the robot. This is achieved by two differently expressed emotional control variables: by an explicit statement of similarity before task-related interaction, and implicitly expressed by adapting the emotional state of the robot to the mood of the human user, such that the current values of the human mood in the dimensions of pleasure, arousal, and dominance (PAD) are matched. The thereby shifted emotional state of the robot serves as a basis for the generation of task-driven emotional facial- and verbal expressions, employed to induce and sustain high empathy towards the robot throughout the interaction. The approach is evaluated in a user study utilizing an expressive robot head. The effectiveness of the approach is confirmed by significant experimental results. An analysis of the individual components of the approach reveals significant effects of explicit emotional adaption on helpfulness, as well as on the HRI-key concepts anthropomorphism and animacy.;2013;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;457-476;NA;4;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5660019419;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
EDEI8SKV;journalArticle;2021;"Chang W; Wang H; Yan G; Lu Z; Liu C; Hua C";EEG based functional connectivity analysis of human pain empathy towards humans and robots.;Neuropsychologia;NA;0028-3932;NA;NA;Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots.;2021;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;NA;NA;NA;151;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8738882970;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
HZI8QVV9;journalArticle;2020;"Björling EA; Thomas K; Rose EJ; Cakmak M";Exploring Teens as Robot Operators, Users and Witnesses in the Wild.;Frontiers in robotics and AI;NA;NA;NA;NA;As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.;2020;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8894905271;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
WAM94TL8;journalArticle;2013;"Niculescu, Andreea; van Dijk, Betsy; Nijholt, Anton; Li, Haizhou; See, Swee Lan";Making Social Robots More Attractive: The Effects of Voice Pitch, Humor and Empathy;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;In this paper we explore how simple auditory/verbal features of the spoken language, such as voice characteristics (pitch) and language cues (empathy/humor expression) influence the quality of interaction with a social robot receptionist. For our experiment two robot characters were created: Olivia, the more extrovert, exuberant, and humorous robot with a higher voice pitch and Cynthia, the more introvert, calmer and more serious robot with a lower voice pitch. Our results showed that the voice pitch seemed to have a strong influence on the way users rated the overall interaction quality, as well as the robot’s appeal and overall enjoyment. Further, the humor appeared to improve the users’ perception of task enjoyment, robot personality and speaking style while the empathy showed effects on the way users evaluated the robot’s receptive behavior and the interaction ease. With our study, we would like to stress in particular the importance of voice pitch in human robot interaction and to encourage further research on this topic.;2013;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;171-191;NA;2;5;NA;NA;Making Social Robots More Attractive;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5660024121;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2AX8TN9L;journalArticle;2016;NA;Appearance of a Robot Affects the Impact of itsBehaviour on Perceived Trustworthiness andEmpathy;Paladyn: Journal of Behavioral Robotics;NA;2081-4836;NA;NA;An increasing number of companion robots havestarted reaching the public in the recent years. Theserobots vary in their appearance and behavior. Since thesetwo factors can have an impact on lasting human-robotrelationships, it is important to understand their effect forcompanion robots.We have conducted an experiment thatevaluated the impact of a robot’s appearance and its behaviourin repeated interactions on its perceived empathy,trustworthiness and anxiety experienced by a human. Theresults indicate that a highly humanlike robot is perceivedas less trustworthy and empathic than a more machinelikerobot. Moreover, negative behaviour of a machinelikerobot reduces its trustworthiness and perceived empathystronger than for highly humanlike robot. In addition, wefound that a robot which disapproves of what a humansays can induce anxiety felt towards its communicationcapabilities. Our findings suggest that more machinelikerobots can be more suitable as companions than highlyhumanlike robots. Moreover, a robot disagreeing with ahuman interaction partner should be able to provide feedbackon its understanding of the partner’s message in orderto reduce her anxiety.;2016;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7180210175;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2FRRCGXA;journalArticle;2017;"Borenstein, Jason; Arkin, Ronald C";Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior;AI & Soc AI & SOCIETY : Journal of Knowledge, Culture and Communication;NA;0951-5666;NA;NA;"An under-examined aspect of human-robot interaction that warrants further exploration is whether robots should be permitted to influence a user’s behavior for that person’s own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user’s behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user’s empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be.";2017;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;499-507;NA;4;32;NA;NA;Nudging for good;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7152279834;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
237X5HWY;journalArticle;2018;"Barakova, E. I; De Haas, M; Kuijpers, W; Irigoyen, N; Betancourt, A";Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot;Connection Science;NA;0954-0091;NA;NA;In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game - the game with the robot was seen as more challenging and the robot - as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world.;2018;2021-02-15T22:17:55Z;2021-02-15T22:17:55Z;NA;81-98;NA;1;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7301307116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
UMSC35IE;journalArticle;2013;NA;EEG Theta and Mu Oscillations during Perception of Human and Robot Actions;Frontiers in Neurorobotics;NA;1662-5218;NA;NA;Perception of others’ actions supports important social skills, such as communication, intention understanding, and empathy. Are mechanisms of action processing in human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans so they can be used as stimuli to address such questions. Here, we recorded EEG during the observation of human and robot actions. Sensorimotor mu (8-13 Hz) rhythm has been linked to the motor simulation aspect of action processing (and to human mirror neuron system, MNS) and frontal theta (4-8 Hz) rhythm to semantic and memory-related aspects. We explored whether these measures exhibit selectivity for biological entities: for whether the motion and/or the visual appearance of the observed agent is biological. Participants watched videos of three agents performing the same actions. The first was a Human, and had biological motion and appearance. The other two were a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical motion and appearance. Observation of all agents induced significant attenuation in the power of mu oscillations that was equivalent for all agents. Thus, mu suppression, considered an index of the activity of the MNS, did not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta activity thus appears to be sensitive to visual appearance, suggesting artificial agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience thus can allow us to explore functional properties of action processing on the one hand, and help inform the design of social robots on the other.;2013;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181479835;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
HLWA7PK8;journalArticle;2013;"Urgen BA; Plank M; Ishiguro H; Poizner H; Saygin AP";EEG theta and Mu oscillations during perception of human and robot actions.;Frontiers in neurorobotics;NA;1662-5218;NA;NA;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other.;2013;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5534221842;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6ZRZWXX2;journalArticle;2020;NA;Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children;Pain Research and Management;NA;1203-6765;NA;NA;"Objectives. Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods. We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot’s empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with NCT02840942. Results. Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions. Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management.";2020;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8580272503;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JVC8NVV5;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Koike, Hayashi, Eiji";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;BICA Biologically Inspired Cognitive Architectures;NA;2212-683X;NA;NA;"Companion or ‘pet’ robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots’ behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross-communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user’s expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like ‘emotion’ and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot’s social expressions that are designed to enhance the users affinity with the robot.";2016;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;51-67;NA;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6836252790;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6KV9D7CM;journalArticle;2020;NA;Differential Facial Articulacy in Robots and Humans Elicit Different Levels of Responsiveness, Empathy, and Projected Feelings;Robotics;NA;2218-6581;NA;NA;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot’s face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot’s face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) × 2 (treatment: affectionate vs. maltreated). Participants (<i>N</i> = 265; <i>M<sub>age</sub></i> = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of ‘because I feel, I believe it’s real,’ despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of ‘it is just a robot’ fades into the background and appears not relevant anymore.";2020;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;92;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8864904148;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ENV5ZF2S;journalArticle;2020;"Konijn, Elly A; Hoorn, Johan F";Differential facial articulacy in robots and humans elicit different levels of responsiveness, empathy, and projected feelings;Robotics;NA;2218-6581;NA;NA;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot’s face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot’s face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) × 2 (treatment: affectionate vs. maltreated). Participants (N = 265; Mage = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of ‘because I feel, I believe it’s real,’ despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of ‘it is just a robot’ fades into the background and appears not relevant anymore.";2020;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;1-17;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8836022524;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
428755PL;journalArticle;2017;NA;You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human-Robot Interaction;Frontiers in Psychology;NA;1664-1078;NA;NA;Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed.;2017;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;NA;NA;NA;NA;You Look Human, But Act Like a Machine;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7179291187;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6MDEPY6J;journalArticle;2016;NA;Breathing Expression for Intimate Communication Corresponding to the Physical Distance and Contact between Human and Robot;EAI Endorsed Transactions on Creative Technologies;NA;2409-9708;NA;NA;"In this paper, we propose living-being-like breathing expressions concurrent with both aspiration and utterances using a stuffed-toy robot in order to enable intimate interactions. The focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two. From the factor analysis of the impression for the word ""intimacy"" and the distance between the robot and the participants, it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility.";2016;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;1-4;NA;7;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7724317017;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
28WCDBU4;journalArticle;2017;"Wiese E; Metta G; Wykowska A";Robots As Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social.;Frontiers in psychology;NA;1664-1078;NA;NA;Robots are increasingly envisaged as our future cohabitants. However, while considerable progress has been made in recent years in terms of their technological realization, the ability of robots to interact with humans in an intuitive and social way is still quite limited. An important challenge for social robotics is to determine how to design robots that can perceive the user's needs, feelings, and intentions, and adapt to users over a broad range of cognitive abilities. It is conceivable that if robots were able to adequately demonstrate these skills, humans would eventually accept them as social companions. We argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motion/eye-tracking, electroencephalography, or functional near-infrared spectroscopy embedded in interactive human-robot paradigms. This approach requires understanding how humans interact with each other, how they perform tasks together and how they develop feelings of social connection over time, and using these insights to formulate design principles that make social robots attuned to the workings of the human brain. In this review, we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in social-cognitive processing. We first review literature related to social-cognitive processes and mechanisms involved in human-human interactions, and highlight the importance of perceiving others as intentional agents to activate these social brain areas. We then discuss how attribution of intentionality can positively affect human-robot interaction by (a) fostering feelings of social connection, empathy and prosociality, and by (b) enhancing performance on joint human-robot tasks. Lastly, we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous, and discuss challenges associated with designing social robots that are inspired by neuroscientific principles.;2017;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;NA;NA;NA;8;NA;NA;Robots As Intentional Agents;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7162799280;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9CM3TNGR;journalArticle;2013;"Vallverdú, J; Casacuberta, D; Nishida, T; Ohmoto, Y; Moran, S; Lázare, S";From Computational Emotional Models to HRI;International Journal of Robotics Applications and Technologies (IJRAT);NA;2166-7195;NA;NA;During the previous stage of our research we developed a computer simulation (called ‘The Panic Room’ or, more simply, ‘TPR’) dealing with synthetic emotions. The authors were developing the first steps towards an evolutionary machine, defining the key elements involved in the development of complex actions (that is, creating a physical intuitive ontology, from a bottom-up approach). After the successful initial results of TPR, the authors considered that it would be necessary to develop a new simulation (which the authors will call “TPR 2.0.”), more complex and with better visualisation characteristics. After this, the authors created a simulation on emotions evolution with genetic algorithms (Game Of Emotions, GOE) which results on the value of specific emotions into social domains were applied to HRI real robotic environments at Nishidalab (Japan), focused into the notions of empathy and proxemics. There the authors performed an experiment that involved humans from two different native-speaking cultures and one robot introduced as three different machines. The final HRI obtained data was analyzed under several research field perspectives: psychology, philosophy, robotic sciences and anthropology.;2013;2021-02-15T22:18:05Z;2021-02-15T22:18:05Z;NA;11-25;NA;2;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5542432010;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8NN74IKI;journalArticle;2011;Mushiaki S;Neuroscience and nanotechnologies in Japan--beyond the hope and hype of converging technologies.;Journal international de bioethique = International journal of bioethics;NA;1145-0762;NA;NA;"Nanotechnologies are often said to be ""converging"" with other technologies like biotechnology, information technology, and cognitive science. And so-called ""NBIC convergence"" is thought to enable ""enhancement"" of human performance. First, I classify various kinds of enhancement. Second, I focus on the ""cybernetic enhancement,"" to which nanotechnologies are supposed to contribute, and analyze the connection and integration of humans with machines, which could lead to the cyborgization of human beings. Third, I examine the portrayal of robot/cyborg technology in Japanese popular media, point out the tendency to empathy or ensoulment concerning robots/cyborgs, and raise the question of ""ethical issues of ethical enhancement."" Fourth, I compare nanotechnologies with neurotechnology and criticize the hype of ""converging technologies.""";2011;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;NA;NA;1;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 747346440;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SBTKCWLK;journalArticle;2015;"Han, Jeonghye; Jo, Miheon; Hyun, Eunja; So, Hyo-jeong";Examining young children's perception toward augmented reality-infused dramatic play;edutechresedeve Educational Technology Research and Development;NA;1042-1629;NA;NA;Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children's satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children's perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5-6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children's perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the olderaged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed.;2015;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;455-474;NA;3;63;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7973250872;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CL76PLTQ;journalArticle;2013;"Haffey, Anthony; Press, Clare; O'Connell, Garret; Chakrabarti, Bhismadev";Autistic Traits Modulate Mimicry of Social but not Nonsocial Rewards;AUR Autism Research;NA;1939-3792;NA;NA;Autism Spectrum Conditions (ASC) are associated with diminished responsiveness to social stimuli, and especially to social rewards such as smiles. Atypical responsiveness to social rewards, which reinforce socially appropriate behavior in children, can potentially lead to a cascade of deficits in social behavior. Individuals with ASC often show diminished spontaneous mimicry of social stimuli in a natural setting. In the general population, mimicry is modulated both by the reward value and the sociality of the stimulus (i.e., whether the stimulus is perceived to belong to a conspecific or an inanimate object). Since empathy and autistic traits are distributed continuously in the general population, this study aimed to test if and how these traits modulated automatic mimicry of rewarded social and nonsocial stimuli. High and low rewards were associated with human and robot hands using a conditioned learning paradigm. Thirty-six participants from the general population then completed a mimicry task involving performing a prespecified hand movement which was either compatible or incompatible with a hand movement presented to the participant. High autistic traits (measured using the Autism Spectrum Quotient, AQ) predicted lesser mimicry of high-reward than low-reward conditioned human hands, whereas trait empathy showed an opposite pattern of correlations. No such relations were observed for high-reward vs. low-reward conditioned robot hands. These results demonstrate how autistic traits and empathy modulate the effects of reward on mimicry of social compared to nonsocial stimuli. This evidence suggests a potential role for the reward system in underlying the atypical social behavior in individuals with ASC, who constitute the extreme end of the spectrum of autistic traits. <i><b>Autism Res</b> 2013, 6: 614-620.</i> © 2013 International Society for Autism Research, Wiley Periodicals, Inc.;2013;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;614-620;NA;6;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5496210755;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
MS8TB94B;journalArticle;2019;NA;A Survey of Behavioral Models for Social Robots;Robotics;NA;2218-6581;NA;NA;The cooperation between humans and robots is becoming increasingly important in our society. Consequently, there is a growing interest in the development of models that can enhance and enrich the interaction between humans and robots. A key challenge in the Human-Robot Interaction (HRI) field is to provide robots with cognitive and affective capabilities, by developing architectures that let them establish empathetic relationships with users. Over the last several years, multiple models were proposed to face this open-challenge. This work provides a survey of the most relevant attempts/works. In details, it offers an overview of the architectures present in literature focusing on three specific aspects of HRI: the development of adaptive behavioral models, the design of cognitive architectures, and the ability to establish empathy with the user. The research was conducted within two databases: Scopus and Web of Science. Accurate exclusion criteria were applied to screen the 4916 articles found. At the end, 56 articles were selected. For each work, an evaluation of the model is made. Pros and cons of each work are detailed by analyzing the aspects that can be improved to establish an enjoyable interaction between robots and users.;2019;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;NA;NA;3;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8186616241;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JM9K44CK;journalArticle;2020;"Sakurai, Eriko; Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea; Frati, Fulvio";Embodiment matters: toward culture-specific robotized counselling;J Reliable Intell Environ Journal of Reliable Intelligent Environments;NA;2199-4668;NA;NA;Abstract: In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures.;2020;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;129-139;NA;3;6;NA;NA;Embodiment matters;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8644462671;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
DMDT7ABD;journalArticle;2011;"Trappl, Robert; Krajewski, Markus; Ruttkay, Zsófia; Widrich, Virgil";Robots as Companions: What can we Learn from Servants and Companions in Literature, Theater, and Film?;PROCS Procedia Computer Science;NA;1877-0509;NA;NA;Many researchers are working on developing robots into adequate partners, be it at the working place, be it at home or in leisure activities, or enabling elder persons to lead a self-determined, independent life. While quite some progress has been made in e.g. speech or emotion understanding, processing and expressing, the relations between humans and robots are usually only short-term. In order to build long-term, i.e. social relations, qualities like empathy, trust building, dependability, non-patronizing, and others will be required. But these are just terms and as such no adequate starting points to “program” these capacities even more how to avoid the problems and pitfalls in interactions between humans and robots. However, a rich source for doing this is available, unused until now for this purpose: artistic productions, namely literature, theater plays, not to forget operas, and films with their multitude of examples. Poets, writers, dramatists, screen-writers, etc. have studied for centuries the facets of interactions between persons, their dynamics, and the related snags. And since we wish for human-robot relations as master-servant relations - the human obviously being the master - the study of these relations will be prominent. A procedure is proposed, with four consecutive steps, namely Selection, Analysis, Categorization, and Integration. Only if we succeed in developing robots which are seen as servants we will be successful in supporting and helping humans through robots.;2011;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;96-98;NA;NA;7;NA;NA;Robots as Companions;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 4934432445;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
J7WZNFGI;journalArticle;2017;"Slomian J; Emonts P; Vigneron L; Acconcia A; Reginster JY; Oumourgh M; Bruyère O";Meeting the Needs of Mothers During the Postpartum Period: Using Co-Creation Workshops to Find Technological Solutions.;JMIR research protocols;NA;1929-0748;NA;NA;"BACKGROUND: The postnatal period is associated with many new needs for mothers. OBJECTIVE: The aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth. METHODS: Two co-creation workshops were undertaken with parents and professionals. The aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth. The aim of the second workshop was to create solutions in response to the criteria selected during the first workshop. RESULTS: Parents and health professionals want solutions that include empathy (ie, to help fight against the feelings of abnormality and loneliness), that help mothers in daily life, that are personalized and adapted to different situations, that are educational, and that assures some continuity in their contact with health professionals. In practice, we found that parents and professionals think the solution should be accessible to everyone and available at all times. To address these criteria, technology experts proposed different solutions, such as a forum dedicated to the postpartum period that is supervised by professionals, a centralized website, a system of videoconferencing, an online exchange group, a ""gift voucher"" system, a virtual reality app, or a companion robot. CONCLUSIONS: The human component seems to be very important during the postnatal period. Nevertheless, technology could be a great ally in helping mothers during the postpartum period. Technology can help reliably inform parents and may also give them the right tools to find supportive people. However, these technologies should be tested in clinical trials.";2017;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;NA;NA;5;6;NA;NA;Meeting the Needs of Mothers During the Postpartum Period;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7029856735;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NLGYIDYN;journalArticle;2020;"Giannopulu, Irini; Etournaud, Aude; Terada, Kazunori; Velonaki, Mari; Watanabe, Tomio";Ordered interpersonal synchronisation in ASD children via robots;Sci Rep Scientific Reports;NA;NA;NA;NA;Abstract: Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8682902429;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JWGFD7T7;journalArticle;2020;NA;Ordered interpersonal synchronisation in ASD children via robots;Scientific Reports;NA;2045-2322;NA;NA;Abstract Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;1-10;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8682587081;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ZGEUIHVU;journalArticle;2020;"Giannopulu I; Etournaud A; Terada K; Velonaki M; Watanabe T";Ordered interpersonal synchronisation in ASD children via robots.;Scientific reports;NA;NA;NA;NA;Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020;2021-02-15T22:18:21Z;2021-02-15T22:18:21Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8681362712;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
34QN8EIR;journalArticle;2013;Mushiaki S;Ethica ex machina: issues in roboethics.;Journal international de bioethique = International journal of bioethics;NA;1145-0762;NA;NA;"Is ""roboethics"" the ""ethics of humans"" or the ""ethics of robots""? According to the Roboethics Roadmap (Gianmarco Veruggio), it is the human ethics of robot designers, manufacturers, and users. And ifroboethics roots deeply in society, artificial ethics (ethics of robots) might be put on the agenda some day. At the 1st International Symposium on Roboethics in San Remo, Ronald C. Arkin gave the presentation ""Bombs, Bonding, and Bondage: Human-Robot Interaction and Related Ethical Issues"" (2004). ""Bondage"" is the issue of enslavement and possible rebellion of robots. ""Bombs"" is the issue of military use of robots. And ""bonding"" is the issue of affective, emotional attachment of humans to robots. I contrast two extreme attitudes towards the issue of ""bonding"" and propose a middle ground. ""Anthropomorphism"" has two meanings. First, it means ""human-shaped-ness."" Second, it means ""attribution of human characteristics or feelings to a nonhuman being (god, animal, or object)"" (personification, empathy). Some say that Japanese (or East Asians) hold ""animism,"" which makes it easy for them to treat robots like animated beings (to anthropomorphize robots); hence ""Robot Kingdom Japan."" Cosima Wagner criticizes such exaggeration and oversimplification as ""invented tradition"". I reinforce her argument with neuroscientific findings and argue that such ""animism"" is neither Shintoistic nor Buddhistic, but a universal tendency. Roboticists, especially Japanese roboticists emphasize that robotics is ""anthropology."" It is true that through the construction of humanoid robots we can better understand human beings (so-called ""constructive approach""). But at the same time, we must not forget that robotic technology, like any other technology, changes our way of living and being--deeply: it can bring about our ontological transformation. In this sense, the governance of robotic technology is ""governed governance."" The interdisciplinary research area of technology assessment studies (TAS) will gain much importance. And we should always be ready to rethink the direction of the research and development of robotic technology, bearing the desirable future of human society in mind.";2013;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;17-26;NA;4;24;NA;NA;Ethica ex machina;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5537702789;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TTW4J2RS;journalArticle;2019;"Carlson, Zachary; Lemmon, Louise; Higgins, MacCallister; Frank, David; Salek Shahrezaie, Roya; Feil-Seifer, David";Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;"Abstract: Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable.";2019;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;727-739;NA;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8545090891;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ICEPJW9K;journalArticle;2016;"Roudposhti KK; Nunes U; Dias J";Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns.;IEEE transactions on pattern analysis and machine intelligence;NA;0162-8828;NA;NA;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.;2016;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;1679-91;NA;8;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6389012015;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NM5FKZ57;journalArticle;2014;"Hofree G; Ruvolo P; Bartlett MS; Winkielman P";Bridging the mechanical and the human mind: spontaneous mimicry of a physically present android.;PloS one;NA;NA;NA;NA;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.";2014;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;NA;NA;7;9;NA;NA;Bridging the mechanical and the human mind;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5605334158;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JERXMF4P;journalArticle;2015;"Mirnig, Nicole; Strasser, Ewald; Weiss, Astrid; Kühnlenz, Barbara; Wollherr, Dirk; Tscheligi, Manfred";Can You Read My Face?: A Methodological Variation for Assessing Facial Expressions of Robotic Heads;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants’ dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach.;2015;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;63-76;NA;1;7;NA;NA;Can You Read My Face?;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5778624819;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
DWHP9IS5;journalArticle;2017;NA;Creation and Staging of Android Theatre “Sayonara”towards Developing Highly Human-Like Robots;Future Internet;NA;1999-5903;NA;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8081433483;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
5QVTJRU5;journalArticle;2019;NA;Affective Embodied Agents and Their Effect on Decision Making;Proceedings;NA;2504-3900;NA;NA;Embodied agents, such as avatars and social robots, are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor. This influences how users perceive these technologies and how they interact with them. We report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being. Twenty-one individuals were asked to play the ultimatum game, playing the role of a responder against another person, a computer, an avatar and a robot for a total of 32 games (8 per condition). We hypothesize that affective expressions by avatars and robots influence the emotional state of the users, leading them to irrational behavior by rejecting unfair proposals. We monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder. Our results show that most fair offers were accepted while most unfair offers were rejected. However, participants rejected more very unfair offers made by people and computers than by the avatars or robots.;2019;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;NA;NA;1;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8464672719;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NHBPVBZP;journalArticle;2015;Mason, Cindy;Engineering Kindness: Building a Machine with Compassionate Intelligence;International Journal of Synthetic Emotions (IJSE);NA;1947-9093;NA;NA;The author provides first steps toward building a software agent/robot with compassionate intelligence. She approaches this goal with an example software agent, EM-2. She also gives a generalized software requirements guide for anyone wishing to pursue other means of building compassionate intelligence into an AI system. The purpose of EM-2 is not to build an agent with a state of mind that mimics empathy or consciousness, but rather to create practical applications of AI systems with knowledge and reasoning methods that positively take into account the feelings and state of self and others during decision making, action, or problem solving. To program EM-2 the author re-purposes code and architectural ideas from collaborative multi-agent systems and affective common sense reasoning with new concepts and philosophies from the human arts and sciences relating to compassion. EM-2 has predicates and an agent architecture based on a meta-cognition mental process that was used on India's worst prisoners to cultivate compassion for others, Vipassana or mindfulness. She describes and presents code snippets for common sense based affective inference and the I-TMS, an Irrational Truth Maintenance System, that maintains consistency in agent memory as feelings change over time, and provides a machine theoretic description of the consistency issues of combining affect and logic. The author summarizes the growing body of new biological, cognitive and immune discoveries about compassion and the consequences of these discoveries for programmers working with human-level AI and hybrid human-robot systems.;2015;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;1-23;NA;1;6;NA;NA;Engineering Kindness;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5890296313;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
4JVAKPUB;journalArticle;2014;NA;Bridging the mechanical and the human mind: spontaneous mimicry of a physically present android.;PLoS ONE;NA;1932-6203;NA;NA;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.";2014;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;NA;NA;7;9;NA;NA;Bridging the mechanical and the human mind;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7179929431;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ZQZ6WWQ8;journalArticle;2018;NA;Posthumain et réception, de The Tempest à Westworld;TV Series;NA;2266-0909;NA;NA;"In TV fiction, the character is a surrogate for the viewer ; through identification, the viewer is immersed in the fictional universe and experiences it as the character does. The companionship thus established between viewer and character defines the place attributed to the implict viewer inscribed in the structure of TV narratives. When the fictional universe is posthuman, the fiction stages the issue of the robot’s ontological nature and explores its relationship with human characters by using the emotional trigger of empathy. The use of dramatic irony and empathy in Westworld reveal a multi-layered use of the Shakespearean intertext which redefines the process of reception and reshuffles the narrative treatment of the posthuman.";2018;2021-02-15T22:18:35Z;2021-02-15T22:18:35Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8081252866;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TIC8KPT6;journalArticle;2018;"Liu B; Sundar SS";Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot.;Cyberpsychology, behavior and social networking;NA;2152-2715;NA;NA;When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N = 158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N = 88) interacted with a real chatbot. We tested the effect of three types of empathic expression-sympathy, cognitive empathy, and affective empathy-on individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed.;2018;2021-02-15T22:20:17Z;2021-02-15T22:20:17Z;NA;625-636;NA;10;21;NA;NA;Should Machines Express Sympathy and Empathy?;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7881648739;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SEU4R9BU;journalArticle;2019;"Shorey S; Ang E; Yap J; Ng ED; Lau ST; Chui CK";A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education: Development Study.;Journal of medical Internet research;NA;1439-4456;NA;NA;BACKGROUND: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. OBJECTIVE: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. METHODS: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. RESULTS: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. CONCLUSIONS: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019;2021-02-15T22:20:17Z;2021-02-15T22:20:17Z;NA;NA;NA;10;21;NA;NA;A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8293773349;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KXM8MIWU;journalArticle;2016;"Hernández-Castro, Carlos Javier; Barrero, David F; R-Moreno, María D";Machine learning and empathy: the Civil Rights CAPTCHA;CPE Concurrency and Computation: Practice and Experience;NA;1532-0626;NA;NA;Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7<i>%</i> of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are <i>leaking</i> too much information by unexpected ways, given non-evident design flaws. Copyright © 2015 John Wiley & Sons, Ltd.;2016;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;1310-1323;NA;4;28;NA;NA;Machine learning and empathy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5997406030;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ITU5UFF5;journalArticle;2020;"Jenkins J; van der Poel S; Krüssel J; Bosch E; Nelson SM; Pinborg A; Yao MMW";Empathetic application of machine learning may address appropriate utilization of ART.;Reproductive biomedicine online;NA;1472-6483;NA;NA;"The value of artificial intelligence to benefit infertile patients is a subject of debate. This paper presents the experience of one aspect of artificial intelligence, machine learning, coupled with patient empathy to improve utilization of assisted reproductive technology (ART), which is an important aspect of care that is under-recognized. Although ART provides very effective options for infertile patients to build families, patients often discontinue ART when further treatment is likely to be beneficial and most of these patients do not achieve pregnancy without medical aid. Use of ART is only in part dependent on financial considerations; stress and other factors play a major role, as shown by high discontinuation rates despite reimbursement. This commentary discusses challenges and strategies to providing personalized ART prognostics based on machine learning, and presents a case study where appropriate use of such prognostics in ART centres is associated with a trend towards increased ART utilization.";2020;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;573-577;NA;4;41;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8651489959;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ZISALK9Y;journalArticle;2020;"Kumar, Mohan; Khatri, Sunil Kumar; Mohammadian, Masoud";Breast cancer identification and prognosis with machine learning techniques - An elucidative review;Journal of Interdisciplinary Mathematics;NA;0972-0502;NA;NA;Cancer is the principle wellspring of death around the globe with 2.09 million cases so far in 2018 [1]. Around 627000 deaths accounting to 6.6% are caused because of female breast cancer and it ranks five amongst the list of top causes for deaths, the prime reason being prognosis being favorable in developed countries. The timely empathy of breast cancer further makes the process of prognosis better hence improving the rates of survival, because this will indorse on time treatment which is given clinically to patients. When the classification is done in an accurate way for malignant and benign tumours, it stops the suffering of patients with excessive ailments. The best possible recognizable proof of breast cancer disease and the process of characterizing into benign and malignant groups is that the main concern of a ton of investigation and research. When thrown light on its particular advantages in significant alternatives recognition from the datasets of entangled breast cancer, the generally perceived option is Machine Learning, because of the philosophy of determination in breast cancer to arrange pattern and forecast modelling. This paper will in general, survey machine learning and assessment of this particular paper, WBCD: Wisconsin Breast Cancer Database has been used as the benchmark dataset.;2020;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;503-521;NA;2;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8593327422;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
QTARLI4R;journalArticle;2019;"Imel ZE; Pace BT; Soma CS; Tanana M; Hirsch T; Gibson J; Georgiou P; Narayanan S; Atkins DC";Design feasibility of an automated, machine-learning based feedback system for motivational interviewing.;Psychotherapy (Chicago, Ill.);NA;0033-3204;NA;NA;Direct observation of psychotherapy and providing performance-based feedback is the gold-standard approach for training psychotherapists. At present, this requires experts and training human coding teams, which is slow, expensive, and labor intensive. Machine learning and speech signal processing technologies provide a way to scale up feedback in psychotherapy. We evaluated an initial proof of concept automated feedback system that generates motivational interviewing quality metrics and provides easy access to other session data (e.g., transcripts). The system automatically provides a report of session-level metrics (e.g., therapist empathy) and therapist behavior codes at the talk-turn level (e.g., reflections). We assessed usability, therapist satisfaction, perceived accuracy, and intentions to adopt. A sample of 21 novice (n = 10) or experienced (n = 11) therapists each completed a 10-min session with a standardized patient. The system received the audio from the session as input and then automatically generated feedback that therapists accessed via a web portal. All participants found the system easy to use and were satisfied with their feedback, 83% found the feedback consistent with their own perceptions of their clinical performance, and 90% reported they were likely to use the feedback in their practice. We discuss the implications of applying new technologies to evaluation of psychotherapy. (PsycINFO Database Record (c) 2019 APA, all rights reserved).;2019;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;318-328;NA;2;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8054135667;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9BEMT73R;journalArticle;2020;"Christov-Moore L; Reggente N; Douglas PK; Feusner JD; Iacoboni M";Predicting Empathy From Resting State Brain Connectivity: A Multivariate Approach.;Frontiers in integrative neuroscience;NA;1662-5145;NA;NA;Recent task fMRI studies suggest that individual differences in trait empathy and empathic concern are mediated by patterns of connectivity between self-other resonance and top-down control networks that are stable across task demands. An untested implication of this hypothesis is that these stable patterns of connectivity should be visible even in the absence of empathy tasks. Using machine learning, we demonstrate that patterns of resting state fMRI connectivity (i.e. the degree of synchronous BOLD activity across multiple cortical areas in the absence of explicit task demands) of resonance and control networks predict trait empathic concern (n = 58). Empathic concern was also predicted by connectivity patterns within the somatomotor network. These findings further support the role of resonance-control network interactions and of somatomotor function in our vicariously driven concern for others. Furthermore, a practical implication of these results is that it is possible to assess empathic predispositions in individuals without needing to perform conventional empathy assessments.;2020;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;NA;NA;NA;14;NA;NA;Predicting Empathy From Resting State Brain Connectivity;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8542389208;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VCKZD5GW;journalArticle;2016;"Xiao B; Imel ZE; Georgiou P; Atkins DC; Narayanan SS";Computational Analysis and Simulation of Empathic Behaviors: a Survey of Empathy Modeling with Behavioral Signal Processing Framework.;Current psychiatry reports;NA;1523-3812;NA;NA;Empathy is an important psychological process that facilitates human communication and interaction. Enhancement of empathy has profound significance in a range of applications. In this paper, we review emerging directions of research on computational analysis of empathy expression and perception as well as empathic interactions, including their simulation. We summarize the work on empathic expression analysis by the targeted signal modalities (e.g., text, audio, and facial expressions). We categorize empathy simulation studies into theory-based emotion space modeling or application-driven user and context modeling. We summarize challenges in computational study of empathy including conceptual framing and understanding of empathy, data availability, appropriate use and validation of machine learning techniques, and behavior signal processing. Finally, we propose a unified view of empathy computation and offer a series of open problems for future research.;2016;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;NA;NA;5;18;NA;NA;Computational Analysis and Simulation of Empathic Behaviors;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6016433445;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
MQCANABH;journalArticle;2020;"Wei L; Wu GR; Bi M; Baeken C";Effective connectivity predicts cognitive empathy in cocaine addiction: a spectral dynamic causal modeling study.;Brain imaging and behavior;NA;1931-7557;NA;NA;Social cognition plays a crucial role in the development and treatment of cocaine dependence. However, studies investigating social cognition, such as empathy and its underlying neural basis, are lacking. To explore the neural interactions among reward and memory circuits, we applied effective connectivity analysis on resting-state fMRI data collected from cocaine-dependent subjects. The relationship between effective connectivity within these two important circuits and empathy ability - evaluated with the Interpersonal Reactivity Index (IRI) - was assessed by machine learning algorithm using multivariate regression analysis. In accordance with the neurocircuitry disruptions of cocaine addiction, the results showed that cocaine-dependent subjects relative to healthy controls had altered resting state effective connectivity between parts of the memory and reward systems. Furthermore, effective connectivity between the memory and reward system could predict the fantasy empathy (FE) subscale scores in cocaine dependence. Overall, our findings provide further evidence for the neural substrates of social cognition in cocaine-dependent patients. These new insights could be useful for the development of new treatment programs for this substance dependency disorder.;2020;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;NA;NA;NA;NA;NA;NA;Effective connectivity predicts cognitive empathy in cocaine addiction;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8633871917;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
IDWG3GIM;journalArticle;2019;"Drimalla, Hanna; Landwehr, Niels; Hess, Ursula; Dziobek, Isabel";From face to face: the contribution of facial mimicry to cognitive and emotional empathy;Cognition and Emotion;NA;0269-9931;NA;NA;Despite advances in the conceptualisation of facial mimicry, its role in the processing of social information is a matter of debate. In the present study, we investigated the relationship between mimicry and cognitive and emotional empathy. To assess mimicry, facial electromyography was recorded for 70 participants while they completed the Multifaceted Empathy Test, which presents complex context-embedded emotional expressions. As predicted, inter-individual differences in emotional and cognitive empathy were associated with the level of facial mimicry. For positive emotions, the intensity of the mimicry response scaled with the level of state emotional empathy. Mimicry was stronger for the emotional empathy task compared to the cognitive empathy task. The specific empathy condition could be successfully detected from facial muscle activity at the level of single individuals using machine learning techniques. These results support the view that mimicry occurs depending on the social context as a tool to affiliate and it is involved in cognitive as well as emotional empathy.;2019;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;1672-1686;NA;8;33;NA;NA;From face to face;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8229310066;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9QJJBXYY;journalArticle;2016;"Xiao, Bo; Imel, Zac E; Georgiou, Panayiotis; Atkins, David C; Narayanan, Shrikanth S";Computational Analysis and Simulation of Empathic Behaviors: a Survey of Empathy Modeling with Behavioral Signal Processing Framework;Curr Psychiatry Rep Current Psychiatry Reports;NA;1523-3812;NA;NA;Empathy is an important psychological process that facilitates human communication and interaction. Enhancement of empathy has profound significance in a range of applications. In this paper, we review emerging directions of research on computational analysis of empathy expression and perception as well as empathic interactions, including their simulation. We summarize the work on empathic expression analysis by the targeted signal modalities (e.g., text, audio, and facial expressions). We categorize empathy simulation studies into theory-based emotion space modeling or application-driven user and context modeling. We summarize challenges in computational study of empathy including conceptual framing and understanding of empathy, data availability, appropriate use and validation of machine learning techniques, and behavior signal processing. Finally, we propose a unified view of empathy computation and offer a series of open problems for future research.;2016;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;1-11;NA;5;18;NA;NA;Computational Analysis and Simulation of Empathic Behaviors;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6015751562;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
B7S3RIEL;journalArticle;2016;"Haladjian HH; Montemayor C";Artificial consciousness and the consciousness-attention dissociation.;Consciousness and cognition;NA;1053-8100;NA;NA;Artificial Intelligence is at a turning point, with a substantial increase in projects aiming to implement sophisticated forms of human intelligence in machines. This research attempts to model specific forms of intelligence through brute-force search heuristics and also reproduce features of human perception and cognition, including emotions. Such goals have implications for artificial consciousness, with some arguing that it will be achievable once we overcome short-term engineering challenges. We believe, however, that phenomenal consciousness cannot be implemented in machines. This becomes clear when considering emotions and examining the dissociation between consciousness and attention in humans. While we may be able to program ethical behavior based on rules and machine learning, we will never be able to reproduce emotions or empathy by programming such control systems-these will be merely simulations. Arguments in favor of this claim include considerations about evolution, the neuropsychological aspects of emotions, and the dissociation between attention and consciousness found in humans. Ultimately, we are far from achieving artificial consciousness.;2016;2021-02-15T22:21:09Z;2021-02-15T22:21:09Z;NA;210-225;NA;NA;45;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6924434585;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
RZ7STXXC;journalArticle;2018;"Vaughn DA; Savjani RR; Cohen MS; Eagleman DM";Empathic Neural Responses Predict Group Allegiance.;Frontiers in human neuroscience;NA;1662-5161;NA;NA;"Watching another person in pain activates brain areas involved in the sensation of our own pain. Importantly, this neural mirroring is not constant; rather, it is modulated by our beliefs about their intentions, circumstances, and group allegiances. We investigated if the neural empathic response is modulated by minimally-differentiating information (e.g., a simple text label indicating another's religious belief), and if neural activity changes predict ingroups and outgroups across independent paradigms. We found that the empathic response was larger when participants viewed a painful event occurring to a hand labeled with their own religion (ingroup) than to a hand labeled with a different religion (outgroup). Counterintuitively, the magnitude of this bias correlated positively with the magnitude of participants' self-reported empathy. A multivariate classifier, using mean activity in empathy-related brain regions as features, discriminated ingroup from outgroup with 72% accuracy; the classifier's confidence correlated with belief certainty. This classifier generalized successfully to validation experiments in which the ingroup condition was based on an arbitrary group assignment. Empathy networks thus allow for the classification of long-held, newly-modified and arbitrarily-formed ingroups and outgroups. This is the first report of a single machine learning model on neural activation that generalizes to multiple representations of ingroup and outgroup. The current findings may prove useful as an objective diagnostic tool to measure the magnitude of one's group affiliations, and the effectiveness of interventions to reduce ingroup biases.";2018;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;NA;12;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7808493438;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
QN7979MX;journalArticle;2016;NA;Method for improving EEG based emotion recognition by combining it with synchronized biometric and eye tracking technologies in a non-invasive and low cost way;Frontiers in Computational Neuroscience;NA;1662-5188;NA;NA;Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving 44 people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods.;2016;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7180624648;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
BP86R2TE;journalArticle;2020;NA;Multilingual Transformer-Based Personality Traits Estimation;Information;NA;2078-2489;NA;NA;"Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users&#8217; information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes <i>Facebook</i> posts from the <i>myPersonality</i> dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback&#8722;Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits.";2020;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8580258136;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
RA2HUFQI;journalArticle;2019;NA;Increased similarity of neural responses to experienced and empathic distress in costly altruism;Scientific Reports;NA;2045-2322;NA;NA;Abstract Empathy—affective resonance with others’ sensory or emotional experiences—is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists’ heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize.;2019;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;1-11;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8207465742;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
QG85NHIG;journalArticle;2020;"Blease C; Locher C; Leon-Carlyle M; Doraiswamy M";Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey.;Digital health;NA;2055-2076;NA;NA;"Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists' opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice. Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (""comments"") to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that 'man and machine' would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists' views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;NA;6;NA;NA;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8698087734;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
C9MSAMK7;journalArticle;2018;"Bogatyreva, Anastasia A; Sovkov, Andrei D; Tikhomirova, Svetlana A; Vinogradova, Anna R; Samsonovich, Alexei V";Virtual pet powered by a socially-emotional BICA;PROCS Procedia Computer Science;NA;1877-0509;NA;NA;Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents.;2018;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;564-571;NA;NA;145;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7960227384;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
H82BDIQ3;journalArticle;2014;"Bedi G; Cecchi GA; Slezak DF; Carrillo F; Sigman M; de Wit H";A window into the intoxicated mind? Speech as an index of psychoactive drug effects.;Neuropsychopharmacology : official publication of the American College of Neuropsychopharmacology;NA;0893-133X;NA;NA;"Abused drugs can profoundly alter mental states in ways that may motivate drug use. These effects are usually assessed with self-report, an approach that is vulnerable to biases. Analyzing speech during intoxication may present a more direct, objective measure, offering a unique 'window' into the mind. Here, we employed computational analyses of speech semantic and topological structure after ±3,4-methylenedioxymethamphetamine (MDMA; 'ecstasy') and methamphetamine in 13 ecstasy users. In 4 sessions, participants completed a 10-min speech task after MDMA (0.75 and 1.5 mg/kg), methamphetamine (20 mg), or placebo. Latent Semantic Analyses identified the semantic proximity between speech content and concepts relevant to drug effects. Graph-based analyses identified topological speech characteristics. Group-level drug effects on semantic distances and topology were assessed. Machine-learning analyses (with leave-one-out cross-validation) assessed whether speech characteristics could predict drug condition in the individual subject. Speech after MDMA (1.5 mg/kg) had greater semantic proximity than placebo to the concepts friend, support, intimacy, and rapport. Speech on MDMA (0.75 mg/kg) had greater proximity to empathy than placebo. Conversely, speech on methamphetamine was further from compassion than placebo. Classifiers discriminated between MDMA (1.5 mg/kg) and placebo with 88% accuracy, and MDMA (1.5 mg/kg) and methamphetamine with 84% accuracy. For the two MDMA doses, the classifier performed at chance. These data suggest that automated semantic speech analyses can capture subtle alterations in mental state, accurately discriminating between drugs. The findings also illustrate the potential for automated speech-based approaches to characterize clinically relevant alterations to mental state, including those occurring in psychiatric illness.";2014;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;2340-8;NA;10;39;NA;NA;A window into the intoxicated mind?;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5615385867;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
V9LGKRZM;journalArticle;2017;"Alvarez-Fernandez, Sonia; Brown, Hallie R; Zhao, Yihong; Raithel, Jessica A; Bishop, Somer L; Kern, Sarah B; Lord, Catherine; Petkova, Eva; Di Martino, Adriana";Perceived social support in adults with autism spectrum disorder and attention-deficit/hyperactivity disorder;AUR Autism Research;NA;1939-3792;NA;NA;"Perceived social support (PSS) has been related to physical and mental well-being in typically developing individuals, but systematic characterizations of PSS in autism spectrum disorder (ASD) are limited. We compared self-report ratings of the multidimensional scale of PSS (MSPSS) among age- and IQ-matched groups of adults (18-58 years) with cognitively high-functioning ASD (<i>N</i> = 41), or attention-deficit/hyperactivity disorder (ADHD; <i>N</i> = 69), and neurotypical controls (NC; <i>N</i> = 69). Accompanying group comparisons, we used machine learning random forest (RF) analyses to explore predictors among a range of psychopathological and socio-emotional variables. Relative to both ADHD and NC, adults with ASD showed lower MSPSS ratings, specifically for the friends subscale (MSPSS-<i>f</i>). Across ASD and ADHD, interindividual differences in autism severity, affective empathy, symptoms of anxiety related to social interactions, hyperactivity/impulsivity, and somatization best predicted MSPSS-<i>f</i>. These relationships did not differ between clinical groups. While group comparisons demonstrated greater impairment in individuals with ASD, analyzing individuals' characteristics revealed cross-diagnoses similarities in regard to their MSPSS-<i>f</i> relationships. This is consistent with the Research Domain Criteria framework, supporting a trans-diagnostic approach as on the path toward “precision medicine.” <i><b>Autism Res</b> 2017, 10: 866-877</i>. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.";2017;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;866-877;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7046610928;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Q8CP9XFB;journalArticle;2016;"Juan-Miguel López-Gil; Jordi Virgili-Gomá; Rosa Gil; Roberto García";Method for improving EEG based emotion recognition by combining it with synchronized biometric and eye tracking technologies in a non-invasive and low cost way;Frontiers in Computational Neuroscience;NA;1662-5188;NA;NA;Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving 44 people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods.;2016;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8598475237;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
XTWBU8RC;journalArticle;2020;"Joda T; Bornstein MM; Jung RE; Ferrari M; Waltimo T; Zitzmann NU";Recent Trends and Future Direction of Dental Research in the Digital Era.;International journal of environmental research and public health;NA;1661-7827;NA;NA;The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.;2020;2021-02-15T22:21:20Z;2021-02-15T22:21:20Z;NA;NA;NA;6;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8555559079;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
3GFT7VIB;journalArticle;2014;"Gillinder Bedi; Guillermo A Cecchi; Diego F Slezak; Facundo Carrillo; Mariano Sigman; Harriet de Wit";A Window into the Intoxicated Mind? Speech as an Index of Psychoactive Drug Effects;Neuropsychopharmacology;NA;1740-634X;NA;NA;"Abused drugs can profoundly alter mental states in ways that may motivate drug use. These effects are usually assessed with self-report, an approach that is vulnerable to biases. Analyzing speech during intoxication may present a more direct, objective measure, offering a unique ‘window’ into the mind. Here, we employed computational analyses of speech semantic and topological structure after ±3,4-methylenedioxymethamphetamine (MDMA; ‘ecstasy’) and methamphetamine in 13 ecstasy users. In 4 sessions, participants completed a 10-min speech task after MDMA (0.75 and 1.5 mg/kg), methamphetamine (20 mg), or placebo. Latent Semantic Analyses identified the semantic proximity between speech content and concepts relevant to drug effects. Graph-based analyses identified topological speech characteristics. Group-level drug effects on semantic distances and topology were assessed. Machine-learning analyses (with leave-one-out cross-validation) assessed whether speech characteristics could predict drug condition in the individual subject. Speech after MDMA (1.5 mg/kg) had greater semantic proximity than placebo to the concepts friend, support, intimacy, and rapport. Speech on MDMA (0.75 mg/kg) had greater proximity to empathy than placebo. Conversely, speech on methamphetamine was further from compassion than placebo. Classifiers discriminated between MDMA (1.5 mg/kg) and placebo with 88% accuracy, and MDMA (1.5 mg/kg) and methamphetamine with 84% accuracy. For the two MDMA doses, the classifier performed at chance. These data suggest that automated semantic speech analyses can capture subtle alterations in mental state, accurately discriminating between drugs. The findings also illustrate the potential for automated speech-based approaches to characterize clinically relevant alterations to mental state, including those occurring in psychiatric illness.";2014;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;2340-2348;NA;NA;39;NA;NA;A Window into the Intoxicated Mind?;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8255279337;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9RII42ES;journalArticle;2020;NA;Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software;Frontiers in Psychology;NA;1664-1078;NA;NA;We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver-operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided.;2020;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;NA;NA;NA;NA;NA;NA;Assessing Risk Among Correctional Community Probation Populations;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8539293835;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9KXKD5TS;journalArticle;2019;"O'Connell K; Brethel-Haurwitz KM; Rhoads SA; Cardinale EM; Vekaria KM; Robertson EL; Walitt B; VanMeter JW; Marsh AA";Increased similarity of neural responses to experienced and empathic distress in costly altruism.;Scientific reports;NA;NA;NA;NA;Empathy-affective resonance with others' sensory or emotional experiences-is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists' heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize.;2019;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;NA;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8187722235;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
UFLH3T4D;journalArticle;2019;"Krohne LG; Wang Y; Hinrich JL; Moerup M; Chan RCK; Madsen KH";Classification of social anhedonia using temporal and spatial network features from a social cognition fMRI task.;Human brain mapping;NA;1065-9471;NA;NA;Previous studies have suggested that the degree of social anhedonia reflects the vulnerability for developing schizophrenia. However, only few studies have investigated how functional network changes are related to social anhedonia. The aim of this fMRI study was to classify subjects according to their degree of social anhedonia using supervised machine learning. More specifically, we extracted both spatial and temporal network features during a social cognition task from 70 subjects, and used support vector machines for classification. Since impairment in social cognition is well established in schizophrenia-spectrum disorders, the subjects performed a comic strip task designed to specifically probe theory of mind (ToM) and empathy processing. Features representing both temporal (time series) and network dynamics were extracted using task activation maps, seed region analysis, independent component analysis (ICA), and a newly developed multi-subject archetypal analysis (MSAA), which here aimed to further bridge aspects of both seed region analysis and decomposition by incorporating a spotlight approach.We found significant classification of subjects with elevated levels of social anhedonia when using the times series extracted using MSAA, indicating that temporal dynamics carry important information for classification of social anhedonia. Interestingly, we found that the same time series yielded the highest classification performance in a task classification of the ToM condition. Finally, the spatial network corresponding to that time series included both prefrontal and temporal-parietal regions as well as insula activity, which previously have been related schizotypy and the development of schizophrenia.;2019;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;4965-4981;NA;17;40;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8199458307;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SFTVXIZY;journalArticle;2019;"Haarsma G; Davenport S; White DC; Ormachea PA; Sheena E; Eagleman DM";Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software.;Frontiers in psychology;NA;1664-1078;NA;NA;We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver-operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided.;2019;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;NA;NA;NA;10;NA;NA;Assessing Risk Among Correctional Community Probation Populations;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8530793703;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
U5Y4VSS4;journalArticle;2020;"Wu, Haiyan; Feng, Chunliang; Lu, Xiaping; Liu, Xun; Liu, Quanying";Oxytocin effects on the resting-state mentalizing brain network;Brain Imaging and Behavior Brain Imaging and Behavior;NA;1931-7557;NA;NA;Abstract: Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual’s empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing.;2020;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;2530-2541;NA;6;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8693983042;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
7235XRIC;journalArticle;2020;"Wu H; Feng C; Lu X; Liu X; Liu Q";Oxytocin effects on the resting-state mentalizing brain network.;Brain imaging and behavior;NA;1931-7557;NA;NA;Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual's empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing.;2020;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;2530-2541;NA;6;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8513802777;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KX3IUK3P;journalArticle;2020;NA;Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey;Digital Health;NA;2055-2076;NA;NA;"Background The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.";2020;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;NA;NA;NA;NA;NA;NA;Artificial intelligence and the future of psychiatry;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8864936321;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
464PSWRS;journalArticle;2017;"Kahler CW; Lechner WJ; MacGlashan J; Wray TB; Littman ML";Initial Progress Toward Development of a Voice-Based Computer-Delivered Motivational Intervention for Heavy Drinking College Students: An Experimental Study.;JMIR mental health;NA;2368-7959;NA;NA;BACKGROUND: Computer-delivered interventions have been shown to be effective in reducing alcohol consumption in heavy drinking college students. However, these computer-delivered interventions rely on mouse, keyboard, or touchscreen responses for interactions between the users and the computer-delivered intervention. The principles of motivational interviewing suggest that in-person interventions may be effective, in part, because they encourage individuals to think through and speak aloud their motivations for changing a health behavior, which current computer-delivered interventions do not allow. OBJECTIVE: The objective of this study was to take the initial steps toward development of a voice-based computer-delivered intervention that can ask open-ended questions and respond appropriately to users' verbal responses, more closely mirroring a human-delivered motivational intervention. METHODS: We developed (1) a voice-based computer-delivered intervention that was run by a human controller and that allowed participants to speak their responses to scripted prompts delivered by speech generation software and (2) a text-based computer-delivered intervention that relied on the mouse, keyboard, and computer screen for all interactions. We randomized 60 heavy drinking college students to interact with the voice-based computer-delivered intervention and 30 to interact with the text-based computer-delivered intervention and compared their ratings of the systems as well as their motivation to change drinking and their drinking behavior at 1-month follow-up. RESULTS: Participants reported that the voice-based computer-delivered intervention engaged positively with them in the session and delivered content in a manner consistent with motivational interviewing principles. At 1-month follow-up, participants in the voice-based computer-delivered intervention condition reported significant decreases in quantity, frequency, and problems associated with drinking, and increased perceived importance of changing drinking behaviors. In comparison to the text-based computer-delivered intervention condition, those assigned to voice-based computer-delivered intervention reported significantly fewer alcohol-related problems at the 1-month follow-up (incident rate ratio 0.60, 95% CI 0.44-0.83, P=.002). The conditions did not differ significantly on perceived importance of changing drinking or on measures of drinking quantity and frequency of heavy drinking. CONCLUSIONS: Results indicate that it is feasible to construct a series of open-ended questions and a bank of responses and follow-up prompts that can be used in a future fully automated voice-based computer-delivered intervention that may mirror more closely human-delivered motivational interventions to reduce drinking. Such efforts will require using advanced speech recognition capabilities and machine-learning approaches to train a program to mirror the decisions made by human controllers in the voice-based computer-delivered intervention used in this study. In addition, future studies should examine enhancements that can increase the perceived warmth and empathy of voice-based computer-delivered intervention, possibly through greater personalization, improvements in the speech generation software, and embodying the computer-delivered intervention in a physical form.;2017;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;NA;NA;2;4;NA;NA;Initial Progress Toward Development of a Voice-Based Computer-Delivered Motivational Intervention for Heavy Drinking College Students;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7088227141;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
KGBMQGPG;journalArticle;2018;"Zwir, Igor; Arnedo, Javier; Del-Val, Coral; Pulkki-Råback, Laura; Konte, Bettina; Yang, Sarah S; Romero-Zaliz, Rocio; Hintsanen, Mirka; Cloninger, Kevin M; Garcia, Danilo; Svrakic, Dragan M; Rozsa, Sandor; Martinez, Maribel; Lyytikäinen, Leo-Pekka; Giegling, Ina; Kähönen, Mika; Hernandez-Cuervo, Helena; Seppälä, Ilkka; Raitoharju, Emma; de Erausquin, Gabriel A; Raitakari, Olli; Rujescu, Dan; Postolache, Teodor T; Sung, Joohon; Keltikangas-Järvinen, Liisa; Lehtimäki, Terho; Cloninger, C. Robert";Uncovering the complex genetics of human character;Mol Psychiatry Molecular Psychiatry;NA;1359-4184;NA;NA;Abstract: Human personality is 30–60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic–phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory.;2018;2021-02-15T22:21:32Z;2021-02-15T22:21:32Z;NA;2295-2312;NA;10;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8671687952;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FNEJ4P7S;journalArticle;2019;"Blease C; Kaptchuk TJ; Bernstein MH; Mandl KD; Halamka JD; DesRoches CM";Artificial Intelligence and the Future of Primary Care: Exploratory Qualitative Study of UK General Practitioners' Views.;Journal of medical Internet research;NA;1439-4456;NA;NA;"BACKGROUND: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. OBJECTIVE: This study aimed to explore general practitioners' (GPs') opinions about the potential impact of future technology on key tasks in primary care. METHODS: In June 2018, we conducted a Web-based survey of 720 UK GPs' opinions about the likelihood of future technology to fully replace GPs in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. RESULTS: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPs also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPs believed that the failure to adopt technological innovations could incur harms to both patients and physicians. CONCLUSIONS: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPs considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPs' views.";2019;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;NA;NA;3;21;NA;NA;Artificial Intelligence and the Future of Primary Care;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8028513010;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8Z6RJ9N2;journalArticle;2019;"Clavelle JT; Sweeney CD; Swartwout E; Lefton C; Guney S";Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition.;The Journal of nursing administration;NA;0002-0443;NA;NA;OBJECTIVE: Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND: Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS: Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS: The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS: AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented.;2019;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;303-309;NA;6;49;NA;NA;Leveraging Technology to Sustain Extraordinary Care;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8114701911;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
MX6C3USS;journalArticle;2020;NA;Recent Trends and Future Direction of Dental Research in the Digital Era;International Journal of Environmental Research and Public Health;NA;1660-4601;NA;NA;The digital transformation in dental medicine, based on electronic health data information, is recognized as one of the major game-changers of the 21st century to tackle present and upcoming challenges in dental and oral healthcare. This opinion letter focuses on the estimated top five trends and innovations of this new digital era, with potential to decisively influence the direction of dental research: (1) rapid prototyping (RP), (2) augmented and virtual reality (AR/VR), (3) artificial intelligence (AI) and machine learning (ML), (4) personalized (dental) medicine, and (5) tele-healthcare. Digital dentistry requires managing expectations pragmatically and ensuring transparency for all stakeholders: patients, healthcare providers, university and research institutions, the medtech industry, insurance, public media, and state policy. It should not be claimed or implied that digital smart data technologies will replace humans providing dental expertise and the capacity for patient empathy. The dental team that controls digital applications remains the key and will continue to play the central role in treating patients. In this context, the latest trend word is created: augmented intelligence, e.g., the meaningful combination of digital applications paired with human qualities and abilities in order to achieve improved dental and oral healthcare, ensuring quality of life.;2020;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;NA;NA;6;17;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8580241581;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
9ALLI8SX;journalArticle;2019;"Bridge P; Bridge R";Artificial Intelligence in Radiotherapy: A Philosophical Perspective.;Journal of medical imaging and radiation sciences;NA;1939-8654;NA;NA;The increasing uptake of machine learning solutions for segmentation and planning leaves no doubt that artificial intelligence (AI) will soon be providing input into a range of radiotherapy procedures. Although this promises to deliver increased speed and accuracy, the future role of AI in relation to radiotherapy should be thought through carefully. There is currently a gap between published developments and widespread adoption, which provides some space to prepare the workforce and to consider the implications on practice. It is rare to find philosophical input into a medical journal, but the advent of AI makes this perspective increasingly important. Philosophical insight can help explore the potential impact of AI, in particular, on human creativity and oversight. Without this perspective, we run the risk of focusing solely on the immediate logistical impact on patients and departments. This commentary identifies three key aspects of radiotherapy that the authors feel would suffer most under AI control: creativity, innovation, and patient safety, which all demand uniquely human attributes. The article also provides insight from a philosophical perspective with regard to human consciousness, ethics, and empathy. Philosophically we should, perhaps, retain ethical concerns about the widening role of AI in radiotherapy beyond simple quantitative interpretation and image processing. As developments continue, we have time to determine how our roles will evolve and to establish a framework for ensuring appropriate human input into patient care. Most importantly, we must start to embed a philosophical approach to adoption of AI technology from the outset if we are to prepare ourselves for the challenge that lies ahead.;2019;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;27;NA;4;50;NA;NA;Artificial Intelligence in Radiotherapy;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8270569034;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
TNXWGQKK;journalArticle;2019;"O’Connell, Katherine; Brethel-Haurwitz, Kristin M; Rhoads, Shawn A; Cardinale, Elise M; Vekaria, Kruti M; Robertson, Emily L; Walitt, Brian; VanMeter, John W; Marsh, Abigail A";Increased similarity of neural responses to experienced and empathic distress in costly altruism;Sci Rep Scientific Reports;NA;NA;NA;NA;Empathy—affective resonance with others’ sensory or emotional experiences—is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists’ heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize.;2019;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;1-11;NA;1;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8187233737;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FRWJ993Z;journalArticle;2016;"López-Gil JM; Virgili-Gomá J; Gil R; García R";Method for Improving EEG Based Emotion Recognition by Combining It with Synchronized Biometric and Eye Tracking Technologies in a Non-invasive and Low Cost Way.;Frontiers in computational neuroscience;NA;1662-5188;NA;NA;Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric, and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving forty-four people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals, and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self-regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods.;2016;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;NA;NA;NA;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6810599341;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
343MP3ZG;journalArticle;2018;"Igor Zwir; Javier Arnedo; Coral Del-Val; Laura Pulkki-Råback; Bettina Konte; Sarah S. Yang; Rocio Romero-Zaliz; Mirka Hintsanen; Kevin M. Cloninger; Danilo Garcia; Dragan M. Svrakic; Sandor Rozsa; Maribel Martinez; Leo-Pekka Lyytikäinen; Ina Giegling; Mika Kähönen; Helena Hernandez-Cuervo; Ilkka Seppälä; Emma Raitoharju; Gabriel A. de Erausquin; Olli Raitakari; Dan Rujescu; Teodor T. Postolache; Joohon Sung; Liisa Keltikangas-Järvinen; Terho Lehtimäki; C. Robert Cloninger";Uncovering the complex genetics of human character;Molecular Psychiatry;NA;1476-5578;NA;NA;Human personality is 30–60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic–phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory.;2018;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8520965238;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2X92QTLP;journalArticle;2020;"Zwir I; Arnedo J; Del-Val C; Pulkki-Råback L; Konte B; Yang SS; Romero-Zaliz R; Hintsanen M; Cloninger KM; Garcia D; Svrakic DM; Rozsa S; Martinez M; Lyytikäinen LP; Giegling I; Kähönen M; Hernandez-Cuervo H; Seppälä I; Raitoharju E; de Erausquin GA; Raitakari O; Rujescu D; Postolache TT; Sung J; Keltikangas-Järvinen L; Lehtimäki T; Cloninger CR";Uncovering the complex genetics of human character.;Molecular psychiatry;NA;1359-4184;NA;NA;Human personality is 30-60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic-phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory.;2020;2021-02-15T22:21:43Z;2021-02-15T22:21:43Z;NA;2295-2312;NA;10;25;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7863914188;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
YAVAEPC2;journalArticle;2021;"Kiesow H; Spreng RN; Holmes AJ; Chakravarty MM; Marquand AF; Yeo BTT; Bzdok D";Deep learning identifies partially overlapping subnetworks in the human social brain.;Communications biology;NA;NA;NA;NA;"Complex social interplay is a defining property of the human species. In social neuroscience, many experiments have sought to first define and then locate 'perspective taking', 'empathy', and other psychological concepts to specific brain circuits. Seldom, bottom-up studies were conducted to first identify explanatory patterns of brain variation, which are then related to psychological concepts; perhaps due to a lack of large population datasets. In this spirit, we performed a systematic de-construction of social brain morphology into its elementary building blocks, involving ~10,000 UK Biobank participants. We explored coherent representations of structural co-variation at population scale within a recent social brain atlas, by translating autoencoder neural networks from deep learning. The learned subnetworks revealed essential patterns of structural relationships between social brain regions, with the nucleus accumbens, medial prefrontal cortex, and temporoparietal junction embedded at the core. Some of the uncovered subnetworks contributed to predicting examined social traits in general, while other subnetworks helped predict specific facets of social functioning, such as the experience of social isolation. As a consequence of our population-level evidence, spatially overlapping subsystems of the social brain probably relate to interindividual differences in everyday social life.";2021;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;NA;NA;1;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8881420050;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
PM8JSSMK;journalArticle;2019;"Piumatti, Giovanni; Abbiati, Milena; Baroffio, Anne; Gerbase, Margaret W";Associations between motivational factors for studying medicine, learning approaches and empathy among medical school candidates;Adv in Health Sci Educ Advances in Health Sciences Education : Theory and Practice;NA;1382-4996;NA;NA;Previous research highlighted associations between students’ motivation for medical studies and their learning approaches on the one hand and empathy on the other. Internal motivational factors for studying medicine (e.g., care for patients, save lives) coupled with a deep approach to learning have been positively related to empathy in contrast to external motivational factors (e.g., future earning potential, prestige) and surface learning. However, assessments of these assumptions among medical school candidates are scarce. This study examined the relationship between different motivational factors and empathy among students enrolled in a selection year in medicine by testing the mediating role of learning approaches. A sample of 572 candidates for medical studies answered a self-reported questionnaire half way through their selection year. Measures included internal and external motivational factors for studying medicine, deep and surface learning approaches and empathy. Path-analysis tested the mediation effects of deep and surface approaches to learning on the relationship of internal and external motivational factors with empathy. The deep learning approach partially mediated the significant positive association between internal motivational factors and empathy, while the surface learning approach fully mediated the significant negative association between external motivational factors and empathy. These results suggest that learning approaches could be a pathway by which internal and external motives for studying medicine are related to empathy among medical school candidates. Pedagogical strategies and educational environments accounting for individual differences in motivation and learning may contribute to training students to become professional and caring doctors in the future.;2019;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;287-300;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8082508826;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
XVYIEBRZ;journalArticle;2020;NA;Transcendent Medicine and Deep Medicine Paradigm;Iranian South Medical Journal;NA;1735-4374;NA;NA;Background: Very recently, Eric Topol, a physician-scientist, introduced his “deep medicine” theory in 2019. This theory has been originated from the last two decades advancements of systems medicine and digital medicine, science and technology convergence in biological fields and formation of the precision medicine. The transcendent medicine theory that has been derived from Sadr ad-Din Shirazi’s transcendent theosophy looks to medicine with a holistic view.Materials and Methods: In extension of the theory of Transcendent medicine, we discussed paradigm shift in medicine with deep medicine theory and its three components were challenged via the viewpoints of transcendent medicine.Results: The body theosophy which has been derived from the transcendent medicine theory is the counterpart of “deep phenotyping” component of deep medicine. The speculative reason of Ibn-Sins’s science of soul which has been projected in transcendent medicine theory could be compare with “deep learning” component of deep medicine theory. With extraction of Ibn-Arabi’s concept of perfect man and its integration with transcendent medicine, the advanced model this theory could present “deep empathy”, the third component of deep medicine.Conclusion: The transcendent medicine theory expresses all three components of deep medicine in a unique form. Hence, this theory could be used as a tool in the paradigm shift of modern medicine.;2020;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;70-86;NA;1;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8580238094;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
H4YPR98A;journalArticle;2019;Minoru Asada;Artificial Pain May Induce Empathy, Morality, and Ethics in the Conscious Mind of Robots;Philosophies;NA;2409-9287;NA;NA;In this paper, a working hypothesis is proposed that a nervous system for pain sensation is a key component for shaping the conscious minds of robots (artificial systems). In this article, this hypothesis is argued from several viewpoints towards its verification. A developmental process of empathy, morality, and ethics based on the mirror neuron system (MNS) that promotes the emergence of the concept of self (and others) scaffolds the emergence of artificial minds. Firstly, an outline of the ideological background on issues of the mind in a broad sense is shown, followed by the limitation of the current progress of artificial intelligence (AI), focusing on deep learning. Next, artificial pain is introduced, along with its architectures in the early stage of self-inflicted experiences of pain, and later, in the sharing stage of the pain between self and others. Then, cognitive developmental robotics (CDR) is revisited for two important concepts—physical embodiment and social interaction, both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, the issue of how robots (artificial systems) could be moral agents is addressed.;2019;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;38-0;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8598357076;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CWNHKHBG;journalArticle;2019;NA;Artificial Pain May Induce Empathy, Morality, and Ethics in the Conscious Mind of Robots;Philosophies;NA;2409-9287;NA;NA;"In this paper, a working hypothesis is proposed that a nervous system for pain sensation is a key component for shaping the conscious minds of robots (artificial systems). In this article, this hypothesis is argued from several viewpoints towards its verification. A developmental process of empathy, morality, and ethics based on the mirror neuron system (MNS) that promotes the emergence of the concept of self (and others) scaffolds the emergence of artificial minds. Firstly, an outline of the ideological background on issues of the mind in a broad sense is shown, followed by the limitation of the current progress of artificial intelligence (AI), focusing on deep learning. Next, artificial pain is introduced, along with its architectures in the early stage of self-inflicted experiences of pain, and later, in the sharing stage of the pain between self and others. Then, cognitive developmental robotics (CDR) is revisited for two important concepts&#8212;physical embodiment and social interaction, both of which help to shape conscious minds. Following the working hypothesis, existing studies of CDR are briefly introduced and missing issues are indicated. Finally, the issue of how robots (artificial systems) could be moral agents is addressed.";2019;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;38-0;NA;3;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8207501315;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8ELJ96IZ;journalArticle;2017;Chen J;Playing to our human strengths to prepare medical students for the future.;Korean journal of medical education;NA;2005-727X;NA;NA;We are living in an age where artificial intelligence and astounding technological advances are bringing truly remarkable change to healthcare. Medical knowledge and skills which form the core responsibility of doctors such as making diagnoses may increasingly be delivered by robots. Machines are gradually acquiring human abilities such as deep learning and empathy. What, then is the role of doctors in future healthcare? And what direction should medical schools be taking to prepare their graduates? This article will give an overview of the evolving technological landscape of healthcare and examine the issues undergraduate medical education may have to address. The experience at The University of Hong Kong will serve as a case study featuring several curricular innovations that aim to empower medical graduates with the capabilities to thrive in the future.;2017;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;193-197;NA;3;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7123345718;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
C9XZB4DM;journalArticle;2017;NA;Playing to our human strengths to prepare medical students for the future;Korean Journal of Medical Education;NA;2005-727X;NA;NA;We are living in an age where artificial intelligence and astounding technological advances are bringing truly remarkable change to healthcare. Medical knowledge and skills which form the core responsibility of doctors such as making diagnoses may increasingly be delivered by robots. Machines are gradually acquiring human abilities such as deep learning and empathy. What, then is the role of doctors in future healthcare? And what direction should medical schools be taking to prepare their graduates? This article will give an overview of the evolving technological landscape of healthcare and examine the issues undergraduate medical education may have to address. The experience at The University of Hong Kong will serve as a case study featuring several curricular innovations that aim to empower medical graduates with the capabilities to thrive in the future.;2017;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;193-197;NA;3;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181368546;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
Y2RW2AJN;journalArticle;2017;Julie Chen;Playing to our human strengths to prepare medical students for the future;Korean Journal of Medical Education;NA;2005-7288;NA;NA;We are living in an age where artificial intelligence and astounding technological advances are bringing truly remarkable change to healthcare. Medical knowledge and skills which form the core responsibility of doctors such as making diagnoses may increasingly be delivered by robots. Machines are gradually acquiring human abilities such as deep learning and empathy. What, then is the role of doctors in future healthcare? And what direction should medical schools be taking to prepare their graduates? This article will give an overview of the evolving technological landscape of healthcare and examine the issues undergraduate medical education may have to address. The experience at The University of Hong Kong will serve as a case study featuring several curricular innovations that aim to empower medical graduates with the capabilities to thrive in the future.;2017;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;193-197;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8521713955;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8KD6HWTM;journalArticle;2016;NA;Personal profile of medical students selected through a knowledge-based exam only: are we missing suitable students?;Medical Education Online;NA;1087-2981;NA;NA;Introduction: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. Methods: Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. Results: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. Conclusion: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile.;2016;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;1-10;NA;0;21;NA;NA;Personal profile of medical students selected through a knowledge-based exam only;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7180044092;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
4642D5VM;journalArticle;2016;"Abbiati, Milena; Baroffio, Anne; Gerbase, Margaret W";Personal profile of medical students selected through a knowledge-based exam only: are we missing suitable students?;Medical Education Online;NA;NA;NA;NA;A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected.Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis.Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students.Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile.;2016;2021-02-15T22:22:36Z;2021-02-15T22:22:36Z;NA;NA;NA;1;21;NA;NA;Personal profile of medical students selected through a knowledge-based exam only;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7065593433;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CR8VGQHR;journalArticle;2011;"Nordstrom, Katrina; Korpelainen, Päivi";Creativity and inspiration for problem solving in engineering education;Teaching in Higher Education;NA;1356-2517;NA;NA;Problem solving is a critical skill for engineering students and essential to development of creativity and innovativeness. Essential to such learning is an ease of communication and allowing students to address the issues at hand via the terminology, attitudes, humor and empathy, which is inherent to their frame of mind as novices, without the attempt to have to be the expert. Deep learning of scientific fact can be facilitated by using non-conventional tools for teaching, learning and presentation such as drama, video, posters, model making and other similar means. It may be time to break free of the PowerPoint tradition to generate successful approaches for establishing student engagement and maintaining such engagement.;2011;2021-02-15T22:22:43Z;2021-02-15T22:22:43Z;NA;439-450;NA;4;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 4839453206;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
LKGQYL6U;journalArticle;2018;Kane, Michele;Creating a Culture of Calm: Mindfulness Unfolding in the Classroom;Gifted Education International;NA;0261-4294;NA;NA;In this article, the practice of mindfulness is examined as a useful tool to address the internal and external stressors that occur daily for gifted students and their teachers. A culture of calm can be created when these simple, effective, and inexpensive evidence-based strategies are implemented within the classroom. Beyond enhancing empathy and compassion, mindfulness sharpens awareness and strengthens executive functions, fosters keen visualization, and encourages innovation and intuition. Opportunities for deep learning are optimal when a peaceful environment is generated collaboratively which encourages focused attention and a sense of well-being.;2018;2021-02-15T22:22:43Z;2021-02-15T22:22:43Z;NA;162-172;NA;2;34;NA;NA;Creating a Culture of Calm;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;"Publisher: SAGE Publications. 2455 Teller Road, Thousand Oaks, CA 91320. Tel: 800-818-7243; Tel: 805-499-9774; Fax: 800-583-2665; e-mail: journals@sagepub.com; Web site: http://sagepub.com OCLC: 7900660989";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
46VAJA5L;journalArticle;2016;"Abbiati M; Baroffio A; Gerbase MW";Personal profile of medical students selected through a knowledge-based exam only: are we missing suitable students?;Medical education online;NA;NA;NA;NA;INTRODUCTION: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. METHODS: Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. RESULTS: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. CONCLUSION: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile.;2016;2021-02-15T22:22:43Z;2021-02-15T22:22:43Z;NA;NA;NA;NA;21;NA;NA;Personal profile of medical students selected through a knowledge-based exam only;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6024140260;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
IQLNG9N6;journalArticle;2019;Griffiths, David;When David Met Michel;RSTH Religious Studies and Theology;NA;NA;NA;NA;"I entered the Department of Religious Studies in Vancouver in the Fall of 1974. Michel was a year or two advanced and the first person to befriend me and ""show me the robes."" He is a unique individual with generosity of Geist or empathy, and deep analytical skills, wide interests, lucid thinking. His books and many students are evidence of this. It has been a deep joy to be his friend through the years. He has always helped me with intellectual projects and been attentive to personal issues, and all this without a touch of pedantry or arrogance. In addition to his deep learning in Religious Studies and related topics, he has a gift for empathic listening, and a singular capacity to think on his feet and lecture with amazing lucidity.";2019;2021-02-15T22:22:43Z;2021-02-15T22:22:43Z;NA;223-225;NA;NA;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8105257012;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
4BXLSK8T;journalArticle;2016;"Abbiati, Milena; Baroffio, Anne; Gerbase, Margaret W";Personal profile of medical students selected through a knowledge-based exam only: are we missing suitable students?;Medical Education Online;NA;NA;NA;NA;A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected.Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis.Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students.Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile.;2016;2021-02-15T22:22:43Z;2021-02-15T22:22:43Z;NA;NA;NA;1;21;NA;NA;Personal profile of medical students selected through a knowledge-based exam only;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7065593433;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
3D3NK6VN;journalArticle;2010;Sideris, Lisa;I See You: Interspecies Empathy and 'Avatar';JSRNC Journal for the Study of Religion, Nature and Culture;NA;NA;NA;NA;I explore empathic dimensions of James Cameron’s film Avatar’s central metaphor of seeing others, and the uses of empathy and empathic bonding throughout the film, both between humans and the Na’vi, and between the Na’vi and the animals that inhabit their world. Empathy entails an ability to see and feel the world from another’s perspective—feeling with rather than feeling for. Jake Sully’s identity as shifting, and boundary-crossing, makes him an especially good candidate for empathic cultivation. Sully assumes an avatar identity, stepping into a Na’vi form but also trying on a range of different perspectives, as part of his education in empathy and his spiritual transformation. The film sheds light on the complexity, fragility, and dangers of empathy, as well as its potential as an environmental and humanitarian value. Avatar suggests empathy’s perils, but also illustrates that empathy, properly oriented and cultivated, is an important environmental disposition encouraging appreciation of otherness.;2010;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;457-477;NA;NA;4;NA;NA;I See You;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5847392461;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CDSQLAAV;journalArticle;2017;Chin, Gabriel Patrick Wei-Hao;Observed bodies and tool selves: kinaesthetic empathy and the videogame avatar;Digital Creativity;NA;1462-6268;NA;NA;This paper examines the field of Kinaesthetic Empathy and how it is studied in dance and film then interrogates whether this framework can be applied to the videogame avatar. I study the avatar as textually signifying, as an observed body, and as a prosthetic tool-limb using the works of Merleau-Ponty and Heidegger as theoretical support and Ian Bogost’s procedural style of videogame reading. I perform close readings of videogame-texts Metal Gear Solid 3 and Mirror’s Edge demonstrating how the former enacts a traditional kinaesthetic empathy in the same way as in dance or film and the latter complicates this observer/performer relation. My paper concludes that, though a player/reader may experience a kinaesthetic empathy that resembles the filmic mode of observer/performer kinaesthetic empathy, the videogame form engenders a deeper tool-based empathy, which is altogether different from traditional conceptions of kinaesthetic empathy.;2017;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;206-223;NA;3;28;NA;NA;Observed bodies and tool selves;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7099357916;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8BB3WM88;journalArticle;2018;"Johnson E; Hervás R; Gutiérrez López de la Franca C; Mondéjar T; Ochoa SF; Favela J";Assessing empathy and managing emotions through interactions with an affective avatar.;Health informatics journal;NA;1460-4582;NA;NA;Assistive technologies can improve the quality of life of people diagnosed with different forms of social communication disorders. We report on the design and evaluation of an affective avatar aimed at engaging the user in a social interaction with the purpose of assisting in communication therapies. A human-avatar taxonomy is proposed to assist the design of affective avatars aimed at addressing social communication disorder. The avatar was evaluated with 30 subjects to assess how effectively it conveys the desired emotion and elicits empathy from the user. Results provide evidence that users become used to the avatar after a number of interactions, and they perceive the defined behavior as being logical. The users' interactions with the avatar entail affective reactions, including the mimic emotions that users felt, and establish a preliminary ground truth about prototypic empathic interactions with avatars that is being used to train learning algorithms to support social communication disorder evaluation.;2018;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;182-193;NA;2;24;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6924364786;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JW5EKGT8;journalArticle;2017;"Esperanza Johnson; Ramón Hervás; Carlos Gutiérrez-López-Franca; Tania Mondéjar; José Bravo";Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar;Mobile Information Systems;NA;1875-905X;NA;NA;In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues.;2017;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;NA;NA;NA;2017;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8092935383;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
2CZV26US;journalArticle;2017;NA;Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar;Mobile Information Systems;NA;1574-017X;NA;NA;In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues.;2017;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181275298;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
8UWHFKTE;journalArticle;2016;"Mattan BD; Rotshtein P; Quinn KA";Empathy and visual perspective-taking performance.;Cognitive neuroscience;NA;1758-8928;NA;NA;"This study examined the extent to which visual perspective-taking performance is modulated by trait-level empathy. Participants completed a third-person visual perspective-taking task in which they judged the perspectives of two simultaneously presented avatars, designated ""Self"" and ""Other."" Depending on the trial, these avatars either held the same view (i.e., congruent) or a different view (i.e., incongruent). Analyses focused on the relationship between empathy and two perspective-taking phenomena: Selection between competing perspectives (i.e., perspective-congruence effects) and prioritization of the Self avatar's perspective. Empathy was related to improved overall performance on this task and a reduced cost of selecting between conflicting perspectives (i.e., smaller perspective-congruence effects). This effect was asymmetric, with empathy (i.e., empathic concern) levels predicting reduced interference from a conflicting perspective, especially when adopting the Self (vs. Other) avatar's perspective. Taken together, these results highlight the importance of the self-other distinction and mental flexibility components of empathy.";2016;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;NA;NA;1-4;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6033857916;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
MXGEVZ76;journalArticle;2014;"Turkay, Selen; Kinzer, Charles K";The Effects of Avatar: Based Customization on Player Identification;International Journal of Gaming and Computer-Mediated Simulations (IJGCMS);NA;1942-3888;NA;NA;Games allow players to perceive themselves in alternate ways in imagined worlds. Player identification is one of the outcomes of gameplay experiences in these worlds and has been shown to affect enjoyment and reduce self-discrepancy. Avatar-based customization has potential to impact player identification by shaping the relationship between the player and the character. This mixed method study aims to fill the gap in the identification literature by examining the effects of avatar-based customization on players' identification with and empathy towards their characters in a massively multiplayer online game, Lord of the Rings Online (LotRO). Participants (N = 66) played LotRO either in customization or in no-customization groups for about ten hours in four sessions over two weeks in a controlled lab setting. Data were collected through interviews, surveys and observations. Results showed both time and avatar-based customization positively impacted players' identification with their avatars. Self-Determination Theory is used to interpret results.;2014;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;1-25;NA;1;6;NA;NA;The Effects of Avatar;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5669121564;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JY7BFP5W;journalArticle;2015;NA;EEVEE: the Empathy-Enhancing Virtual Evolving Environment;Frontiers in Human Neuroscience;NA;1662-5161;NA;NA;"Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, including schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. A powerful tool to enhance experimental control over such dynamic social interactions is the use of avatars in virtual reality (VR), and one way to collect information about an individual in an interaction is through the analysis of his or her neurophysiological and behavioural responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: 1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); 2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and 3) a multimodal interface linking the avatar’s behaviour to the observer’s neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar’s face (top or bottom half) does not prevent the detection of different levels of pain. Overall, this innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in number of populations suffering from neurological or psychiatric disorders.";2015;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;NA;NA;NA;NA;NA;NA;EEVEE;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7180498037;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
DY5FH6K5;journalArticle;2015;"Jackson PL; Michon PE; Geslin E; Carignan M; Beaudoin D";EEVEE: the Empathy-Enhancing Virtual Evolving Environment.;Frontiers in human neuroscience;NA;1662-5161;NA;NA;"Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar's behavior to the observer's neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar's face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders.";2015;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;NA;NA;NA;9;NA;NA;EEVEE;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5797948152;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FSLAZVGD;journalArticle;2017;"van Rijn, Biljana; Cooper, Mick; Jackson, Andrew; Wild, Ciara";Avatar-Based Therapy within Prison Settings: Pilot Evaluation;British Journal of Guidance & Counselling;NA;0306-9885;NA;NA;The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n = 4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population.;2017;2021-02-15T22:24:01Z;2021-02-15T22:24:01Z;NA;268-283;NA;3;45;NA;NA;Avatar-Based Therapy within Prison Settings;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;"Publisher: Taylor & Francis. Available from: Taylor & Francis, Ltd. 530 Walnut Street Suite 850, Philadelphia, PA 19106. Tel: 800-354-1420; Tel: 215-625-8900; Fax: 215-207-0050; Web site: http://www.tandf.co.uk/journals OCLC: 7132238123";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
YIJBN7K5;journalArticle;2013;"Bouchard S; Bernier F; Boivin É; Dumoulin S; Laforest M; Guitard T; Robillard G; Monthuy-Blanc J; Renaud P";Empathy toward virtual humans depicting a known or unknown person expressing pain.;Cyberpsychology, behavior and social networking;NA;2152-2715;NA;NA;This study is about pain expressed by virtual humans and empathy in users immersed in virtual reality. It focuses on whether people feel more empathy toward the pain of a virtual human when the virtual human is a realistic representation of a known individual, as opposed to an unknown person, and if social presence is related to users' empathy toward a virtual human's pain. The 42 participants were immersed in virtual reality using a large immersive cube with images retro projected on all six faces (CAVE-Like system) where they can interact in real time with virtual characters. The first immersion (baseline/control) was with a virtual animal, followed by immersions involving discussions with a known virtual human (i.e., the avatar of a person they were familiar with) or an unknown virtual human. During the verbal exchanges in virtual reality, the virtual humans expressed acute and very strong pain. The pain reactions were identical in terms of facial expressions, and verbal and nonverbal behaviors. The Conditions by Time interactions in the repeated measures analyses of variance revealed that participants were empathic toward both virtual humans, yet more empathic toward the known virtual human. Multivariate regression analyses revealed that participants' feeling of social presence--impression that the known virtual character is really there, with them--was a significant predictor of empathy.;2013;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;61-71;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 825871019;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
T5IQKQRU;journalArticle;2012;"Chen, Gwo-Dong; Lee, Jih-Hsien; Wang, Chin-Yeh; Chao, Po-Yao; Li, Liang-Yi; Lee, Tzung-Yi";An Empathic Avatar in a Computer-Aided Learning Program to Encourage and Persuade Learners;Educational Technology & Society;NA;1436-4522;NA;NA;"Animated pedagogical agents with characteristics such as facial expressions, gestures, and human emotions, under an interactive user interface are attractive to students and have high potential to promote students' learning. This study proposes a convenient method to add an embodied empathic avatar into a computer-aided learning program; learners express their emotions by mouse-clicking while reading, and the avatar motivates them accordingly. This study designs empathic responses for avatars to encourage and persuade learners to make greater reading effort. This experiment examines emotional recognition, empathy transformation, and the effect of virtual human encouragement and persuasion. Subjects identify facial expressions of the avatar, especially those expressing positive facial emotions. Compared to the contrast group, the empathic avatar increases learners' willingness to continue reading and complete exercises. (Contains 4 tables and 4 figures.)";2012;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;62-72;NA;2;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;"Publisher: International Forum of Educational Technology & Society. Athabasca University, School of Computing & Information Systems, 1 University Drive, Athabasca, AB T9S 3A3, Canada. Tel: 780-675-6812; Fax: 780-675-6973; Web site: http://www.ifets.info OCLC: 826377898";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
PU5737Z6;journalArticle;2017;"van Rijn, Biljana; Cooper, Mick; Jackson, Andrew; Wild, Ciara";Avatar-based therapy within prison settings: pilot evaluation;British Journal of Guidance & Counselling;NA;0306-9885;NA;NA;The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n = 4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population.;2017;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;268-283;NA;3;45;NA;NA;Avatar-based therapy within prison settings;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7065557984;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
JC8AZE2R;journalArticle;2019;NA;Modification of knee flexion during walking with use of a real-time personalized avatar;Heliyon;NA;2405-8440;NA;NA;Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed.;2019;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;e02797;NA;11;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8464682346;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
WFFPSFKH;journalArticle;2015;"Tisseron, Serge; Tordo, Frédéric; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;97-102;NA;1;7;NA;NA;Testing Empathy with Robots;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5778625970;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NBL3AEPX;journalArticle;2018;"Joyal CC; Neveu SM; Boukhalfi T; Jackson PL; Renaud P";Suppression of Sensorimotor Alpha Power Associated With Pain Expressed by an Avatar: A Preliminary EEG Study.;Frontiers in human neuroscience;NA;1662-5161;NA;NA;"Several studies using functional magnetic resonance imaging (fMRI) showed that empathic capabilities are associated with the activation (and deactivation) of relatively specific neural circuits. A growing number of electroencephalography studies also suggest that it might be useful to assess empathy. The main goal of this study was to use quantitative electroencephalography (qEEG) to test whether observation of pain expressed by an avatar (virtual reality) induces a suppression of alpha waves over sensorimotor cortical areas, as it is observed with human stimuli. Not only was it the case, but also the magnitude of alpha suppression was correlated with perspective-taking capacity of participants. Both empathy levels and magnitude of sensorimotor alpha suppression (SAS) were significantly higher in women than men. Interestingly, a significant interaction emerged between levels of individual empathy and specificity of experimental instructions, where SAS in participants with good perspective-taking was higher during passive observation of the distressed avatar, while the opposite was true during an active (trying to understand) condition. These results suggest that: (1) synthetic characters are able to elicit SAS; (2) SAS is indeed associated with perspective-taking capacities; (3) Persons with poorer perspective-taking capacities can show significant SAS when proper instructions are provided. Therefore, qEEG represents a low-cost objective approach to measure perspective-taking abilities.";2018;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;NA;NA;NA;12;NA;NA;Suppression of Sensorimotor Alpha Power Associated With Pain Expressed by an Avatar;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7787364948;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
LRH3SN93;journalArticle;2018;"Hamilton-Giachritsis C; Banakou D; Garcia Quiroga M; Giachritsis C; Slater M";Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment.;Scientific reports;NA;NA;NA;NA;The ability to perspective-take (cognitive awareness of another's state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a 'mother avatar', which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children.;2018;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7317314888;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VAJR4MNS;journalArticle;2018;NA;Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment;Scientific Reports;NA;2045-2322;NA;NA;Abstract The ability to perspective-take (cognitive awareness of another’s state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a ‘mother avatar’, which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children.;2018;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;1-10;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8080991200;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
MER3GN6I;journalArticle;2018;"Catherine Hamilton-Giachritsis; Domna Banakou; Manuela Garcia Quiroga; Christos Giachritsis; Mel Slater";Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment;Scientific Reports;NA;2045-2322;NA;NA;The ability to perspective-take (cognitive awareness of another’s state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a ‘mother avatar’, which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children.;2018;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8255404885;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SBKPL96C;journalArticle;2015;"Sulpizio V; Committeri G; Metta E; Lambrey S; Berthoz A; Galati G";Visuospatial transformations and personality: evidence of a relationship between visuospatial perspective taking and self-reported emotional empathy.;Experimental brain research;NA;0014-4819;NA;NA;In the visuospatial domain, perspective taking is the ability to imagine how a visual scene appears from an external observer's viewpoint, and can be studied by asking subjects to encode object locations in a visual scene where another individual is present and then detecting their displacement when seeing the scene from the other's viewpoint. In the current study, we explored the relationship between visuospatial perspective taking and self-report measures of the cognitive and emotional components of empathy in young adults. To this aim, we employed a priming paradigm, in which the presence of an avatar allowed to anticipate the next perceived perspective on the visual scene. We found that the emotional dimension of empathy was positively correlated with the behavioral advantage provided by the presence of the avatar, relative to unprimed perspective changes. These data suggest a link between the tendency to vicariously experience the others' emotions and the ability to perform self-other spatial transformations.;2015;2021-02-15T22:24:17Z;2021-02-15T22:24:17Z;NA;2091-102;NA;7;233;NA;NA;Visuospatial transformations and personality;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5841200833;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
GT5F73QV;journalArticle;2011;Taylor LD;Avatars and emotional engagement in asynchronous online communication.;Cyberpsychology, behavior and social networking;NA;2152-2715;NA;NA;The notion that an avatar can elicit a sense of emotional involvement or connection on the part of a user in asynchronous online communication was explored through a pair of content analyses of a popular online question-and-answer bulletin board. In the first study, questions accompanied by an avatar not only received more answers than questions without an avatar, but the answers were more likely to be characterized by expressions of empathy. In the second study, a preference for answering questions accompanied by an avatar was found to be associated with interpersonal, altruistic motives for answering questions. Results are discussed in terms of presence and alternative explanations, as well as practical implications.;2011;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;207-12;NA;4;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 712721684;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6FHEC4PW;journalArticle;2017;"Ferguson CJ; Donnellan MB";"Are Associations Between ""Sexist"" Video Games and Decreased Empathy Toward Women Robust? A Reanalysis of Gabbiadini et al. 2016.";Journal of youth and adolescence;NA;0047-2891;NA;NA;"Gabbiadini, A., Riva, P., Andrighetto, L., Volpato, C., & Bushman, B, (PloS ONE, 2016) provided evidence for a connection between ""sexist"" video games and decreased empathy toward girls using an experimental paradigm. These claims are based on a moderated mediation model. They reported a three-way interaction between game condition, gender, and avatar identification when predicting masculine ideology in their original study. Masculine ideology was associated, in turn, with decreased empathy. However, there were no main experimental effects for video game condition on empathy. The current analysis considers the strength of the evidence for claims made in the original study on a sample of 153 adolescents (M age = 16.812, SD = 1.241; 44.2% male). We confirmed that there was little evidence for an overall effect of game condition on empathy toward girls or women. We tested the robustness of the original reported moderated mediation models against other, theoretically derived alternatives, and found that effects differed based on how variables were measured (using alternatives in their public data file) and the statistical model used. The experimental groups differed significantly and substantially in terms of age suggesting that there might have been issues with the procedures used to randomly assign participants to conditions. These results highlight the need for preregistration of experimental protocols in video game research and raise some concerns about how moderated mediation models are used to support causal inferences. These results call into question whether use of ""sexist"" video games is a causal factor in the development of reduced empathy toward girls and women among adolescents.";2017;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;2446-2459;NA;12;46;NA;NA;"Are Associations Between ""Sexist"" Video Games and Decreased Empathy Toward Women Robust?";NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7088415745;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
22E8FJR2;journalArticle;2020;"Patané I; Lelgouarch A; Banakou D; Verdelet G; Desoche C; Koun E; Salemme R; Slater M; Farnè A";Exploring the Effect of Cooperation in Reducing Implicit Racial Bias and Its Relationship With Dispositional Empathy and Political Attitudes.;Frontiers in psychology;NA;1664-1078;NA;NA;Previous research using immersive virtual reality (VR) has shown that after a short period of embodiment by White people in a Black virtual body, their implicit racial bias against Black people diminishes. Here we tested the effects of some socio-cognitive variables that could contribute to enhancing or reducing the implicit racial bias. The first aim of the study was to assess the beneficial effects of cooperation within a VR scenario, the second aim was to provide preliminary testing of the hypothesis that empathy and political attitudes could contribute to implicit bias about race, while the third aim was to explore the relationship between political attitudes and empathy. We had (Caucasian) participants embodied in a Black virtual body and engaged either in a cooperative (Coop group) or in a non-cooperative (Neutral group) activity with a confederate experimenter embodying another Black avatar. Before and after VR, we measured participants' implicit racial bias by means of Implicit Association Test (IAT) and their perceived closeness toward the confederate experimenter. Before VR we also assessed participants' political attitudes and empathy traits. Results revealed that, as compared to the Neutral group, the Coop group showed lower IAT scores after the social interaction. Interestingly, in the Neutral but not the Coop group the perceived closeness toward the confederate experimenter was associated with the initial racial bias: the more the participants reduced their distance, the more they reduced their IAT score. Moreover, reported traits of empathy and political attitudes significantly explained the variance observed in the initial implicit bias, with perspective-taking, empathic concern, and personal distress being significant predictors of the IAT scores. Finally, there was a relationship between political attitudes and empathy: the more participants considered themselves as left-wing voters, the higher their perspective-taking and empathic concern scores. We discuss these findings within the neuroscientific and social cognition field and encourage scholars from different domains to further explore whether and under which conditions a given manipulation for reducing racial bias could be efficiently transposed in VR.;2020;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;NA;NA;NA;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8698096714;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
AXPMZVA6;journalArticle;2018;"Felnhofer, Anna; Kafka, Johanna X; Hlavacs, Helmut; Beutl, Leon; Kryspin-Exner, Ilse; Kothgassner, Oswald D";Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents;CHB Computers in Human Behavior;NA;0747-5632;NA;NA;Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the <ce:italic>Media Equation Concept</ce:italic> (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses.;2018;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;399-406;NA;NA;80;NA;NA;Meeting others virtually in a day-to-day setting;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7247755230;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
QWW8QG6P;journalArticle;2014;Kumar, Akshaya;Satyamev Jayate: Return of the Star as a Sacrificial Figure;South Asia: Journal of South Asian Studies;NA;0085-6401;NA;NA;This paper attempts to make sense of Satyamev Jayate, a popular Indian television show hosted by film star Aamir Khan, in terms of its politics, Khan's stardom and the attempt to reframe the social on television. Grappling with the broad contours of the cultural economy of justice on national television in India, I suggest that the star descends upon television as an avatar promising empathy to a variety of victims of social injustice. In so doing, Khan converts crime news into emotional truths. The show has not only generated public debate, it also invites the public to return to a performative innocence. As television becomes the site of articulating moral authority, ritual participation and demanding social change, the political is re-assembled through Khan's stardom. The paper also enquires how and why the show compels narrative ingenuity towards what Aditya Nigam calls the ‘implosion of the political’-the erasure of the public from the street and its re-inscription in the studio. Equally notable here is the role film-stardom plays in rendering moral authority through the trope of the sacrificial.;2014;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;239-254;NA;2;37;NA;NA;Satyamev Jayate;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5594902823;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
NHYHR2S6;journalArticle;2016;NA;"""In war, not everyone's a soldier."" A Review of This War of Mine";Press Start;NA;2055-8198;NA;NA;This article works to critically engage This War of Mine as a radically different style of war game that is rarely seen today. War games often glorify what it means to be in battle and have the player, essentially, saving their country or the world. This War of Mine, on the other hand, puts the player in the role of a survivor, someone simply trying to make it through the turmoil. This article examines the ways in which the game creates empathy for the avatar through aesthetic and narrative devices.;2016;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;70-73;NA;2;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181148179;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VADGG8RC;journalArticle;2018;NA;Open Interactivity: A Model for Audience Agency;IAFOR Journal of Cultural Studies;NA;2187-4905;NA;NA;"Artists have increasingly acknowledged the role of the audience as collaborators both in the construction of meaning (Bathes, 1977), through subjective experience (Dewey, 1934) and in contributing to the creative act by externalising the work. (Duchamp) Lucy Lippard identifies 1966-72 as a period where artists turned increasingly towards the audience, representing a ""dematerialization of the art object"" (Lippard, 1997) through ""Happenings"" and ""Fluxus"" movements. Digital media has facilitated this trajectory, implicit in the interactive computer interface (Manovich, 2005), but interactivity per se may offer no more than a series of choices put forward by the artist (Daniels, 2011). Interactivity represents interplay between artist and audience (Dinka, 1996) and is potentially a process of audience empowerment to offer agency, defined as real and creative choice (Browning, 1964).<br><br>Public screen installation ""Peoples Screen"" Guangzhou, linking China to Perth Australia (Sermon & Gould, 2015) offered a partnership between artist and audience to co-create content though playful narratives and active engagement in a drama that unfolds using improvisation and play. Initially visitors enjoy observing the self on the screen but audiences quickly start to interact with the environment and other participants. Immersed in play they lose a sense of the self (Callois, 2011) and enter a virtual third space where possibilities for creativity and direction of play are limitless. The self becomes an avatar where the audience can inhabit ""the other"" thereby exploring alternative realities through ludic play, promoting tolerance and empathy and developing collective memory.";2018;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;55-69;NA;1;3;NA;NA;Open Interactivity;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7655511608;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
49UTDP7R;journalArticle;2020;"Küster D; Swiderska A";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes.;International journal of psychology : Journal international de psychologie;NA;0020-7594;NA;NA;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.;2020;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;NA;NA;NA;NA;NA;NA;Seeing the mind of robots;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8664634571;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
BZRX55KG;journalArticle;2017;"Conway JR; Lee D; Ojaghi M; Catmur C; Bird G";Submentalizing or mentalizing in a Level 1 perspective-taking task: A cloak and goggles test.;Journal of experimental psychology. Human perception and performance;NA;0096-1523;NA;NA;It has been proposed that humans possess an automatic system to represent mental states ('implicit mentalizing'). The existence of an implicit mentalizing system has generated considerable debate however, centered on the ability of various experimental paradigms to demonstrate unambiguously such mentalizing. Evidence for implicit mentalizing has previously been provided by the 'dot perspective task,' where participants are slower to verify the number of dots they can see when an avatar can see a different number of dots. However, recent evidence challenged a mentalizing interpretation of this effect by showing it was unaltered when the avatar was replaced with an inanimate arrow stimulus. Here we present an extension of the dot perspective task using an invisibility cloaking device to render the dots invisible on certain trials. This paradigm is capable of providing unambiguous evidence of automatic mentalizing, but no such evidence was found. Two further well-powered experiments used opaque and transparent goggles to manipulate visibility but found no evidence of automatic mentalizing, nor of individual differences in empathy or perspective-taking predicting performance, contradicting previous studies using the same design. The results cast doubt on the existence of an implicit mentalizing system, suggesting that previous effects were due to domain-general processes. (PsycINFO Database Record;2017;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;454-465;NA;3;43;NA;NA;Submentalizing or mentalizing in a Level 1 perspective-taking task;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 6924428042;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SBX3BI4S;journalArticle;2017;Jarvis, Liam;The Ethics of Mislocalized Selfhood;Performance Research;NA;1352-8165;NA;NA;In Psychology, ‘proprioceptive drift’ is a term that originates from the rubber hand illusion paradigm to describe the ‘relative displacement of the perceived location of one’s own hand toward the location of the rubber hand’ (Wold et al, 2014). Correspondingly, drift measurements in science are used as a means of rating the intensity of a body-ownership illusion via which a participant in a controlled experiment perceives that an extracorporeal appendage, or virtual whole-body avatar is incorporated as part of one’s own body schema. In this research article, I will examine an applied performance by BeAnotherLab utilising the anti-disciplinary collective’s The Machine to Be Another as part of Good Chance’s Encampment project - this telepresence system produces a VR body illusion intended to increase empathy and reduce proximity between an immersant’s real body and that of a volunteer refugee counterpart. When scientifically-tested body illusions cross a paradigmatic boundary to be framed as immersive art, what are the ethical implications? Furthermore, are these kinds of virtual proprioceptive transactions across different kinds of social and political boundaries symptomatic of radical empathic acts, or a capitalistic desire for the acquisition of another’s experiences by virtual means? This article examines illusory bodily inhabitation through a Levinasian critical lens to consider the ethics of deterritorializing the immersant’s gaze and referring their sense of touch elsewhere to produce ‘narrative immersion’.;2017;2021-02-15T22:24:46Z;2021-02-15T22:24:46Z;NA;30-37;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7138533628;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
PXV72GWI;journalArticle;2011;"Guadagno, Rosanna E; Swinth, Kimberly R; Blascovich, Jim";Social evaluations of embodied agents and avatars;CHB Computers in Human Behavior;NA;0747-5632;NA;NA;The purpose of this study was to examine social evaluations (i.e., perceptions of empathy and positivity) following peoples’ interactions with digital human representations. Female research participants engaged in a 3-min interaction while immersed in a 3-D immersive virtual environment with a “peer counselor.” Participants were led to believe that the peer counselor was either an embodied agent (i.e., computer algorithm) or an avatar (i.e., another person). During the interaction, the peer counselor either smiled or not. As predicted, a digitally-rendered smile was found to affect participants’ social evaluations. However, these effects were moderated by participants’ beliefs about their interaction partner. Specifically, smiles enhanced social evaluations of embodied agents but degraded them for avatars. Although these results are consistent with other findings concerning the communicative realism of embodied agents and avatars they uniquely demonstrate that people’s beliefs alone, rather than actual differences in virtual representations, can impact social evaluations.;2011;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;2380-2385;NA;6;27;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 4930742890;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
62HDUXTC;journalArticle;2015;Lemenager, T;Psychological and Neurobiological Mechanisms of Pathological Internet Use;EURPSY European Psychiatry;NA;0924-9338;NA;NA;Background: Studies on internet gaming disorders indicate that especially online role-playing games have a high addictive potential in particular in male adolescents. These games enable the parallel gaming of multiple users in online virtual worlds with or against each other via their graphical agent (avatar). Recent findings suggest online role-playing addicts to have a deficient self-concept. The latter's potential compensation by means of a higher identification with the own avatar might be an etiological factor in the development of an online role-playing game addiction. On a neurobiological level, especially the left Angular Gyrus (AG) seems to be associated with identification and empathy processes. An according fMRI-based study on long-term gamers of online role-playing games indicated increased brain activations in the left AG during the rating of personality traits referring to the avatar relative to self-referencing and the referencing of close others (Ganesh et al., 2011). However, the extent to which these results represent specific neurobiological mechanisms that are associated with self-concept deficits or a stronger identification with the own avatar in the development of online role-playing game addiction remains unknown to date.<br>Methods: N=16 addicted and n=17 regular gamers of online role-playing games (mean age=28 and 26 years, respectively) underwent functional Magnetic Resonance Imaging (fMRI) while 1) completing a Giessen-Test (GT)-derived paradigm assessing participants’ concepts of self, ideal and avatar and 2) while viewing and evaluating images of the own person, the own avatar as well as unknown persons. Additionally, a questionnaire referring to the own body image and a Visual Analogue Scale (VAS) for the evaluation of the own as well as avatar's attractiveness, sympathy and gender identity were applied.<br>Results: Addicts of online role-playing games rated their body image, gender identity and social response (i.e. social popularity) significantly lower. Neurobiologically, they showed increased left AG activations during the reflection about their avatar (relative to their ideal and/or their self) compared to non-addicted gamers. Furthermore, within-group differences revealed left AG response during the perception of images showing their avatar (relative to images of themselves). In addition, addicted gamers had hypoactivations in the bilateral AG during the perception of images of their own person compared to the perception of unknown persons. The left-lateral AG hypoactivation positively correlated with the degree of the gender identity.<br>Discussion: In line with previous findings, our results indicate self-concept deficits in online role-playing game addicts and a stronger identification with the own avatar, which might neurobiologically be reflected in AG activations. The results could point towards problems in the formation of an own identity as a cause for online role-playing game addiction development. Longitudinal studies may shed light on these potentially causal relations.;2015;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;123;NA;NA;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5899638234;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VTZ5F9JD;journalArticle;2014;"Thirioux B; Tandonnet L; Jaafari N; Berthoz A";Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia: a behavioural pilot-study using virtual reality technology.;Brain and cognition;NA;0278-2626;NA;NA;"Behavioural and neuroimaging data have recently pointed out that empathy (feeling into someone else) is associated with mental imagery and transformation related to one's and other's visuo-spatial perspectives. Impairments of both empathic and visuo-spatial abilities have been observed in patients with schizophrenia. Especially, it has been suggested that schizophrenics are altered in spontaneously simulating another individual's first-person experience. However, there is so far only little evidence regarding the relationship between deficits in empathy and disturbances in spontaneous heterocentered coding in schizophrenia. In the present pilot-study, we tested with schizophrenic patients our behavioural paradigm that enables to measure from the bodily postures and movements whether individuals in ecologically more valid conditions are interacting with another individual by using egocentered - as in sympathy (feeling with someone else) - or heterocentered - as in empathy - visuo-spatial mechanisms. For that, ten patients and ten controls, standing and moving, interacted with a virtual tightrope walker, displayed life-sized, standing and moving as well. We show that patients with higher negative symptoms had, in most cases, deficits in spontaneously using heterocentered visuo-spatial mechanisms and employed preferentially an egocentered referencing to interact with the avatar. In contrast, preserved spontaneous heterocentered visuo-spatial strategies were not linked to a prevailing negative or positive symptomatology. Our data suggest that the severity of the negative symptoms in schizophrenia relates with disturbances of spontaneous (""on-line"") empathic processing in association with lower scoring self-reported trait cognitive empathy.";2014;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;87-99;NA;NA;90;NA;NA;Disturbances of spontaneous empathic processing relate with the severity of the negative symptoms in patients with schizophrenia;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5626805970;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
SM4PC5W8;journalArticle;2018;"Bernard F; Lemée JM; Aubin G; Ter Minassian A; Menei P";Using a Virtual Reality Social Network During Awake Craniotomy to Map Social Cognition: Prospective Trial.;Journal of medical Internet research;NA;1439-4456;NA;NA;"BACKGROUND: In awake craniotomy, it is possible to temporarily inactivate regions of the brain using direct electrical stimulation, while the patient performs neuropsychological tasks. If the patient shows decreased performance in a given task, the neurosurgeon will not remove these regions, so as to maintain all brain functions. OBJECTIVE: The objective of our study was to describe our experience of using a virtual reality (VR) social network during awake craniotomy and discuss its future applications for perioperative mapping of nonverbal language, empathy, and theory of mind. METHODS: This was a single-center, prospective, unblinded trial. During wound closure, different VR experiences with a VR headset were proposed to the patient. This project sought to explore interactions with the neuropsychologist's avatar in virtual locations using a VR social network as an available experience. RESULTS: Three patients experienced VR. Despite some limitations due to patient positioning during the operation and the limitation of nonverbal cues inherent to the app, the neuropsychologist, as an avatar, could communicate with the patient and explore gesture communication while wearing a VR headset. CONCLUSIONS: With some improvements, VR social networks can be used in the near future to map social cognition during awake craniotomy. TRIAL REGISTRATION: ClinicalTrials.gov NCT03010943; https://clinicaltrials.gov/ct2/show/NCT03010943 (Archived at WebCite at http://www.webcitation.org/70CYDil0P).";2018;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;NA;NA;6;20;NA;NA;Using a Virtual Reality Social Network During Awake Craniotomy to Map Social Cognition;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7736326135;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
DWAI9D43;journalArticle;2019;"Shorey S; Ang E; Yap J; Ng ED; Lau ST; Chui CK";A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education: Development Study.;Journal of medical Internet research;NA;1439-4456;NA;NA;BACKGROUND: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. OBJECTIVE: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. METHODS: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. RESULTS: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. CONCLUSIONS: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;NA;NA;10;21;NA;NA;A Virtual Counseling Application Using Artificial Intelligence for Communication Skills Training in Nursing Education;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8293773349;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
VMME2SSX;journalArticle;2017;"Leménager, T; Dieter, J; Hill, H; Mann, K; Kiefer, F";Internet addiction and the virtual self-image;EURPSY European Psychiatry;NA;0924-9338;NA;NA;Background: Internet gaming disorder appears to be associated with self-concept deficits and increased identification with one's avatar. For increased social network use, the few existing studies suggest striatal-related positive social feedback as an underlying factor. Furthermore, few study findings indicate that internet addicts generally have problems in emotional inhibitory control processing.<br>Methods: Pathological and addicted internet gamers as well as social network users were compared with healthy controls regarding psychometric and neurobiological measures of self-concept-related characteristics, avatar identification and emotional inhibitory control processing.<br>Results and conclusion: Psychometric results indicated that both subgroups showed higher self-concept deficits compared to healthy controls. Neurobiologically, different brain activation patterns were observed in the subgroups during self-knowledge retrieval and inhibition of emotional stimuli. Furthermore, addicted internet gamers showed a higher identification with the own avatar, mirrored in an increased left angular gyrus activation, a region functionally associated with identification processing and feelings of empathy.<br>These findings provide a starting point for the deduction of specific psychotherapeutic treatment approaches for addicted internet gamers and social network users.;2017;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;S26;NA;NA;41;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7080945013;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
5LBIC4CR;journalArticle;2019;NA;Affective Embodied Agents and Their Effect on Decision Making;Proceedings;NA;2504-3900;NA;NA;Embodied agents, such as avatars and social robots, are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor. This influences how users perceive these technologies and how they interact with them. We report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being. Twenty-one individuals were asked to play the ultimatum game, playing the role of a responder against another person, a computer, an avatar and a robot for a total of 32 games (8 per condition). We hypothesize that affective expressions by avatars and robots influence the emotional state of the users, leading them to irrational behavior by rejecting unfair proposals. We monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder. Our results show that most fair offers were accepted while most unfair offers were rejected. However, participants rejected more very unfair offers made by people and computers than by the avatars or robots.;2019;2021-02-15T22:24:58Z;2021-02-15T22:24:58Z;NA;NA;NA;1;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8464672719;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
5A5B7VD8;journalArticle;2017;NA;Creation and Staging of Android Theatre “Sayonara”towards Developing Highly Human-Like Robots;Future Internet;NA;1999-5903;NA;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8081433483;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
T6FYHB64;journalArticle;2014;"Hofree G; Ruvolo P; Bartlett MS; Winkielman P";Bridging the mechanical and the human mind: spontaneous mimicry of a physically present android.;PloS one;NA;NA;NA;NA;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.";2014;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;NA;NA;7;9;NA;NA;Bridging the mechanical and the human mind;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5605334158;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
FVDIXXHL;journalArticle;2014;NA;Bridging the mechanical and the human mind: spontaneous mimicry of a physically present android.;PLoS ONE;NA;1932-6203;NA;NA;"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android ""humanlike."" These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.";2014;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;NA;NA;7;9;NA;NA;Bridging the mechanical and the human mind;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7179929431;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
3VX7YZ2W;journalArticle;2013;NA;EEG Theta and Mu Oscillations during Perception of Human and Robot Actions;Frontiers in Neurorobotics;NA;1662-5218;NA;NA;Perception of others’ actions supports important social skills, such as communication, intention understanding, and empathy. Are mechanisms of action processing in human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans so they can be used as stimuli to address such questions. Here, we recorded EEG during the observation of human and robot actions. Sensorimotor mu (8-13 Hz) rhythm has been linked to the motor simulation aspect of action processing (and to human mirror neuron system, MNS) and frontal theta (4-8 Hz) rhythm to semantic and memory-related aspects. We explored whether these measures exhibit selectivity for biological entities: for whether the motion and/or the visual appearance of the observed agent is biological. Participants watched videos of three agents performing the same actions. The first was a Human, and had biological motion and appearance. The other two were a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical motion and appearance. Observation of all agents induced significant attenuation in the power of mu oscillations that was equivalent for all agents. Thus, mu suppression, considered an index of the activity of the MNS, did not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta activity thus appears to be sensitive to visual appearance, suggesting artificial agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience thus can allow us to explore functional properties of action processing on the one hand, and help inform the design of social robots on the other.;2013;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181479835;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
CSR2722A;journalArticle;2017;NA;Analysis of Simulators and Assistive Technologies Which Support Designers to See Like Colorblinds;Ergodesign & HCI;NA;2317-8876;NA;NA;Several kinds of colorblindness limit color perception and affect how people interact with the world, especially when colors have meanings. Even with empathy, non colorblind designers have difficulties to conceive accessible interfaces for colorblind users, because they perceive colors in a different way from users. This work analyses how colorblind simulators and assistive technology can support user interface design. We conduct a search for free software on Google, on Android app store and on Chrome extension store. We identified 4 types of colorblindness simulators (filters of image, screen, sites and mobile device camera) and 3 types of assistive technologies (web sites, mobile app and CSS editor). Secrecy, internet access, time of use and other factors were considered to analyze the use of these simulators and assistive technologies as support for user interface static and dynamic analysis, during formative and summative evaluations.;2017;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;116-128;NA;Especial;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8864976587;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
ZDPM9GUT;journalArticle;2020;NA;Evaluating the Management Information System of Integrated Medical Emergency Care in Batang Regency, Indonesia;International Journal of Online and Biomedical Engineering;NA;2626-8493;NA;NA;An emergency can happen anywhere and anytime, especially in developing countries with a high potential for emergencies, such as Eastern European countries as well as Indonesia. This study aimed to find out the quality of PSC 119 Si Slamet as a prehospital emergency service innovation. The data collection in this study was carried out in a location, namely, Batang Regency, Indonesia, in May-June 2018. The qualitative data collection methods used in this study are in-depth interviews and document reviews. This study was using Service Quality (Servqual) questionnaire. The results show that PSC 119 Si Slamet provides easy access to emergency services to the community 24 hours a day and 7 days a week by simply calling 119 numbers, sending messages via SMS and WhatsApp, or using the Android-based application, with a maximum response time target of 10 minutes. Batang is one of the regencies (rural area) in Central Java province, located on the main coastline, with a hilly geographic condition with many derivatives, climbs, and sharp curves, which is one of the causes of the high number of traffic accidents in the area. This emergency care information systems, with Android-based application, was aimed at improving the quality of services in the health sector, especially emergency services. This service is of good quality as seen from the tangible, reliability, responsiveness, assurance, and empathy dimensions. However, in the implementation, the socialization aspect is not the best to some people. The recommendation given was the need to increase the PSC 119 socialization of Si Slamet not only regionally but also internationally to be massive, especially in developing countries.;2020;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;75-85;NA;07;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8615581609;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat
6HIM5F9V;journalArticle;2013;"Urgen BA; Plank M; Ishiguro H; Poizner H; Saygin AP";EEG theta and Mu oscillations during perception of human and robot actions.;Frontiers in neurorobotics;NA;1662-5218;NA;NA;The perception of others' actions supports important skills such as communication, intention understanding, and empathy. Are mechanisms of action processing in the human brain specifically tuned to process biological agents? Humanoid robots can perform recognizable actions, but can look and move differently from humans, and as such, can be used in experiments to address such questions. Here, we recorded EEG as participants viewed actions performed by three agents. In the Human condition, the agent had biological appearance and motion. The other two conditions featured a state-of-the-art robot in two different appearances: Android, which had biological appearance but mechanical motion, and Robot, which had mechanical appearance and motion. We explored whether sensorimotor mu (8-13 Hz) and frontal theta (4-8 Hz) activity exhibited selectivity for biological entities, in particular for whether the visual appearance and/or the motion of the observed agent was biological. Sensorimotor mu suppression has been linked to the motor simulation aspect of action processing (and the human mirror neuron system, MNS), and frontal theta to semantic and memory-related aspects. For all three agents, action observation induced significant attenuation in the power of mu oscillations, with no difference between agents. Thus, mu suppression, considered an index of MNS activity, does not appear to be selective for biological agents. Observation of the Robot resulted in greater frontal theta activity compared to the Android and the Human, whereas the latter two did not differ from each other. Frontal theta thus appears to be sensitive to visual appearance, suggesting agents that are not sufficiently biological in appearance may result in greater memory processing demands for the observer. Studies combining robotics and neuroscience such as this one can allow us to explore neural basis of action processing on the one hand, and inform the design of social robots on the other.;2013;2021-02-15T22:25:31Z;2021-02-15T22:25:31Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 5534221842;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;WorldCat

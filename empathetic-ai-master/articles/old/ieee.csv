"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"SWTYWWPW","conferencePaper","2011","Polajnar, J.; Dalvandi, B.; Polajnar, D.","Does empathy between artificial agents improve agent teamwork?","IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11)","","","10.1109/COGINF.2011.6016126","","Both everyday experience and scientific studies indicate that emotional intelligence in general, and empathy in particular, improve the effectiveness of human teamwork. Research in affective computing confirms their significance in systems where humans and artificial agents interact. This paper explores the notion of empathy between artificial agents that has so far received little attention, and argues that it could have significant impact on the design of robust and resilient agent teams. Combining the formal framework of Emotional BDI agents with the principles underlying the leading model of empathy in psychology and neuroscience, we define a hierarchy of affective and behavioral responses, integrated into an algorithm that formalizes the interactions between the subject and object of empathy in the domain of artificial practical reasoning agents.","2011-08","2021-02-11 02:07:21","2021-02-11 02:07:21","","96-102","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\72F6GM85\6016126.html","","","Humans; Cognition; neurophysiology; emotional intelligence; empathy; affective computing; neuroscience; affective responses; agent teamwork; artificial agents; artificial practical reasoning agents; behavioral responses; Computer science; Electronic mail; Emotional BDI agents; human teamwork; inference mechanisms; multi-agent systems; Neuroscience; psychology; resilient agent team design; robust agent team design; Robustness; Teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11)","","","","","","","","","","","","","","",""
"NUJXZSXP","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective Intelligence: When, Where and Why","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","10.1109/Confluence47617.2020.9058000","","The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.","2020-01","2021-02-11 02:07:21","2021-02-11 02:07:21","","805-810","","","","","","Collective Intelligence","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\7EW9HMRQ\9058000.html","","","artificial intelligence; learning (artificial intelligence); machine learning; Collective Intelligence; Aggregates; Artificial Intellegence; collective intelligence; Collective intelligence; Organizations; Particle swarm optimization; smart organization; Social network services; software agents; Standards organizations; Swarm Intelligence; virtual artificially intelligent agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","","","","","","","","","","","","",""
"NT4RQEAS","conferencePaper","2020","Dixit, R.; Chinnam, R. B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","2020 IEEE Aerospace Conference","","","10.1109/AERO47225.2020.9172612","","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.","2020-03","2021-02-11 02:07:21","2021-02-11 02:07:21","","1-8","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1095-323X","","C:\Users\esben\Zotero\storage\YB9ESVJG\9172612.html","","","artificial intelligence; learning (artificial intelligence); ML; AI; neural nets; human intelligence; ample data; ample time; answer-key; artificial Intelligence techniques; cross-disciplinary decision engine; current research streams; data-rich situations; decision algorithms; decision making; defined decision-basis; experienced practitioners; informed decisions; logical formulations; logical outcome; machine Learning; neural techniques; operational decision scenarios; real-time decision making; sparse-data environments; strategic decision scenarios; successful training; sufficient learning; tactical, decision scenarios; typical implementations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 IEEE Aerospace Conference","","","","","","","","","","","","","","",""
"CBG7D925","conferencePaper","2020","Wang, Z.","Future Challenges in the Next Generation of Voice User Interface","2020 International Conference on Computing and Data Science (CDS)","","","10.1109/CDS49703.2020.00045","","With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI.","2020-08","2021-02-11 02:07:21","2021-02-11 02:07:21","","191-193","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\R7MYADZR\9276008.html","","","artificial intelligence; ethics; empathy; accessibility; artificial intelligence technology; artificial interactions; complex interaction scenarios; core technics; Data science; disabled interaction scenarios; key elements; user interface; user interfaces; voice user interface; VUI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 International Conference on Computing and Data Science (CDS)","","","","","","","","","","","","","","",""
"TPW8YUM9","conferencePaper","2019","Chiu, K. C.","Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation","2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","","","10.1109/IEEM44572.2019.8978876","","This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence.","2019-12","2021-02-11 02:07:21","2021-02-11 02:07:21","","1516-1520","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2157-362X","","C:\Users\esben\Zotero\storage\QQLZFV4Z\8978876.html","","","artificial intelligence; Artificial Intelligence; data mining; Dream Consultation; Knowledge Management; Text Mining; psychology; abstract affective words; affective expression; behavioural sciences computing; dream consultation; dream log; Semantic Analytics; text analysis; text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","","","","","","","","","","","","","","",""
"EAFXY2C5","conferencePaper","2014","Majot, A. M.; Yampolskiy, R. V.","AI safety engineering through introduction of self-reference into felicific calculus via artificial pain and pleasure","2014 IEEE International Symposium on Ethics in Science, Technology and Engineering","","","10.1109/ETHICS.2014.6893398","","In the 18th century the Utilitarianism movement produced a morality system based on the comparative pain and pleasure that an action created. Called felicific calculus, this system would judge an action to be morally right or wrong based on several factors like the amount of pleasure it would provide and how much pain the action would inflict upon others. Because of its basis as a type of “moral mathematics” felicific calculus may be a viable candidate as a working ethical system for artificial intelligent agents. This paper examines the concepts of felicific calculus and Utilitarianism in the light of their possible application to artificial intelligence, and proposes methods for its adoption in an actual intelligent machine. In order to facilitate the calculations necessary for this moral system, novel approaches to synthetic pain, pleasure, and empathy are also proposed.","2014-05","2021-02-11 02:07:21","2021-02-11 02:07:21","","1-6","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\7U4WB6YD\6893398.html","","","learning (artificial intelligence); Ethics; Artificial intelligence; Computers; Concept Learning; Intelligent Agents; Machine Learning; Perceptual Reasoning; AI safety engineering; artificial intelligent agents; artificial pain; artificial pleasure; calculus; Calculus; felicific calculus; moral mathematics; morality system; Pain; Philosophical Foundations; Safety; self-reference; Senior citizens; utilitarianism movement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 IEEE International Symposium on Ethics in Science, Technology and Engineering","","","","","","","","","","","","","","",""
"ZGUSU9B3","conferencePaper","2015","Headleand, C. J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L. A.","Does the Perceived Identity of Non-player Characters Change How We Interact with Them?","2015 International Conference on Cyberworlds (CW)","","","10.1109/CW.2015.35","","Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it.","2015-10","2021-02-11 02:07:21","2021-02-11 02:07:21","","145-152","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\D8PIUTPC\7398406.html","","","artificial intelligence; Visualization; Artificial intelligence; Computers; Robots; behavioural sciences computing; Ash; Avatars; CASA; computer games; Games; Games AI; Human Agent Interaction; Identity; nonplayer character perceived identity; NPC; online game; player behavior; unarmed NPC companion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 International Conference on Cyberworlds (CW)","","","","","","","","","","","","","","",""
"PJ4BZJVQ","conferencePaper","2019","Das, A. K.; Ashrafi, A.; Ahmmad, M.","Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","10.1109/CCOMS.2019.8821655","","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.","2019-02","2021-02-11 02:07:21","2021-02-11 02:07:21","","36-40","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\489Y55XX\8821655.html","","","learning (artificial intelligence); Task analysis; Decision making; cognition; Law; Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment; advanced artificial intelligence system; criminal punishment prediction; Forecasting; judicial system; law administration; Machine intelligence; machine learning algorithms; Machine learning algorithms; Predictive models; Women and Children Repression Prevention Act 2000","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","","","","","","","","","","","","",""
"CCJN75SK","conferencePaper","2017","Restrepo, E. G. y; Boticario, J. G.","Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","","","10.1109/ICE.2017.8280067","","This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society.","2017-06","2021-02-11 02:07:21","2021-02-11 02:07:21","","1552-1558","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\KL8B7BY3\8280067.html","","","artificial intelligence; Education; Artificial Intelligence; Empathy; Accessibility; Diversity; ACACIA European project; Afective computing; Assistive technology; Cultural differences; Economics; educational institutions; further education; Gesture recognition; higher education; intelligent systems; Intelligent systems; noninclusive design tendencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","","","","","","","","","","","","","","",""
"3AFCZK2M","conferencePaper","2013","Kwak, S. S.; Kim, Y.; Kim, E.; Shin, C.; Cho, K.","What makes people empathize with an emotional robot?: The impact of agency and physical embodiment on human empathy for a robot","2013 IEEE RO-MAN","","","10.1109/ROMAN.2013.6628441","","As empathy is important for the emotional interaction between a human and a robot, the design factors which induce human empathy toward robots need to be explored. Human empathy toward a robot can be affected by the presence of a robot. Thus, we focused on the levels of agency and the physical embodiment of a robot, which are influential factors pertaining to social presence, by executing two experiments. In the first experiment, in a 2 (levels of agency: mediated vs. simulated) between-participants experiment, participants interacted with either a mediated robot which delivers the emotional state of a remote user or a simulated robot which expresses its own emotion. Participants empathized more with the mediated robot than with the simulated robot, demonstrating that the proper form of an emotional robot is as a mediator during emotional interaction between people. In the second study, in a 2 (physical embodiment: physically embodied vs. physically disembodied) between-participants experiment design, participants interacted with either a physically embodied robot or a physically disembodied robot. The results showed that participants empathized more with a physically embodied robot than with a physically disembodied robot, indicating the impact of physical embodiment on human empathy. Implications for the design of human-robot interactions are discussed.","2013-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","180-185","","","","","","What makes people empathize with an emotional robot?","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\SG9A724T\6628441.html","","","robots; human robot interactions; Educational institutions; Human-robot interaction; Conferences; Emotion recognition; emotional interaction; emotional robot; emotional state; Face; human computer interaction; human empathy; mediated robot; physical embodiment; Service robots; simulated robot; social presence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2013 IEEE RO-MAN","","","","","","","","","","","","","","",""
"UHSZTWEW","conferencePaper","2015","Darling, K.; Nandy, P.; Breazeal, C.","Empathic concern and the effect of stories in human-robot interaction","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2015.7333675","","People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.","2015-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","770-775","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\YDIPVRXE\7333675.html; C:\Users\esben\Zotero\storage\FIJGMB3Y\Darling et al. - 2015 - Empathic concern and the effect of stories in huma.pdf","","","Media; human-robot interaction; Human-robot interaction; Robots; Atmospheric measurements; behavior indicative; empathic concern; empathic responses; human factors; Indexes; Particle measurements; people hesitation; people trait empathy; robotic object; stories; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"5RVDI8IC","conferencePaper","2019","Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.","Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming","2019 Systems and Information Engineering Design Symposium (SIEDS)","","","10.1109/SIEDS.2019.8735613","","The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.","2019-04","2021-02-11 03:17:10","2021-02-11 03:17:10","","1-6","","","","","","Ideal Warrior and Robot Relations","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\8MLL84IJ\8735613.html","","","Stress; Task analysis; empathy; human-robot interaction; robot design; Human-robot interaction; Robots; multi-agent systems; behavioural sciences computing; human computer interaction; Atmospheric measurements; Particle measurements; automated teammate; automated technologies; Battery charge measurement; battlefield; effect stress; human-machine team; Human-machine teaming; human-robot teaming; humanoid robots; ideal warrior; man-machine systems; Military aircraft; military computing; military context; military systems; military training; mobile robots; multi-robot systems; Pepper robot; social sciences computing; United States Military","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 Systems and Information Engineering Design Symposium (SIEDS)","","","","","","","","","","","","","","",""
"Z6SSRQPX","conferencePaper","2015","Seo, S. H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J. E.","Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. Categories and Subject Descriptors H.5.2 [User Interfaces]: evaluation/methodology General Terms Experimentation and Human Factors.","2015-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","125-132","","","","","","Poor Thing! Would You Feel Sorry for a Simulated Robot?","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\3G68AIAH\8520653.html","","","Computational modeling; Programming; Psychology; empathy; human-robot interaction; Human-robot interaction; Robots; simulated robot; human factors; Videos; human-robot interactions; Instruments; physical robot; robot embodiment; simulated HRI work; simulated interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"UW6JCP5K","conferencePaper","2017","Burns, H. D.; Lesseig, K.","Empathy in middle school engineering design process","2017 IEEE Frontiers in Education Conference (FIE)","","","10.1109/FIE.2017.8190669","","This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.","2017-10","2021-02-11 03:17:10","2021-02-11 03:17:10","","1-4","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\D5VZT9H4\8190669.html","","","empathy; design process; educational institutions; further education; 5G mobile communication; after-school 4-H Science Club; after-school science club; all-girls after-school STEM program; Computer bugs; educational courses; emotional intelligence model; empathy in engineering; empathy need; empathy study; empathy-based lessons; engineering; engineering education; engineering problem; k-12 schools; middle school; middle school engineering design process; middle-school engineering design pedagogy; science technology engineering and mathematics; teaching; university programs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE Frontiers in Education Conference (FIE)","","","","","","","","","","","","","","",""
"6HMCSB64","conferencePaper","2019","Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.","Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition","2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019)","","","10.1109/FG.2019.8756517","","The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.","2019-05","2021-02-11 03:17:10","2021-02-11 03:17:10","","1-5","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\49F68DSC\8756517.html","","","feature extraction; emotion recognition; human-robot interaction; actor-listener interactions; bidirectional long short-term memory network; CCC; concordance correlation coefficient; empathy perception; interpersonal relationships; intra-subject dependencies; multimodal valence-based empathy models; OMG; one-minute gradual; personalised multimodal model; unimodal valence-based empathy models; valence-based empathy recognition; visual feature extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019)","","","","","","","","","","","","","","",""
"6GL3IBCJ","conferencePaper","2014","Hayes, B.; Ullman, D.; Alexander, E.; Bank, C.; Scassellati, B.","People help robots who help others, not robots who help themselves","The 23rd IEEE International Symposium on Robot and Human Interactive Communication","","","10.1109/ROMAN.2014.6926262","","Robots that engage in social behaviors benefit greatly from possessing tools that allow them to manipulate the course of an interaction. Using a non-anthropomorphic social robot and a simple counting game, we examine the effects that empathy-generating robot dialogue has on participant performance across three conditions. In the self-directed condition, the robot petitions the participant to reduce his or her performance so that the robot can avoid punishment. In the externally-directed condition, the robot petitions on behalf of its programmer so that its programmer can avoid punishment. The control condition does not involve any petitions for empathy. We find that externally-directed petitions from the robot show a higher likelihood of motivating the participant to sacrifice his or her own performance to help, at the expense of incurring negative social effects. We also find that experiencing these emotional dialogue events can have complex and difficult to predict effects, driving some participants to antipathy, leaving some unaffected, and manipulating others into feeling empathy towards the robot.","2014-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","255-260","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\AUUA3WKW\6926262.html","","","Timing; human-robot interaction; Games; Atmospheric measurements; Particle measurements; humanoid robots; Analysis of variance; antipathy; behavioural sciences; control condition; counting game; emotional dialogue events; empathy-generating robot dialogue; externally-directed condition; externally-directed petitions; negative social effects; nonanthropomorphic social robot; participant motivation; participant performance; programmer; robot programming; Robot sensing systems; self-directed condition; social behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The 23rd IEEE International Symposium on Robot and Human Interactive Communication","","","","","","","","","","","","","","",""
"Y2EF3VF4","conferencePaper","2018","James, J.; Watson, C. I.; MacDonald, B.","Artificial Empathy in Social Robots: An analysis of Emotions in Speech","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525652","","Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.","2018-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","632-637","","","","","","Artificial Empathy in Social Robots","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\FF2FJEI5\8525652.html","","","Task analysis; Medical services; robots; emotion recognition; human-robot interaction; social robots; Human-robot interaction; service robots; artificial empathy; Robot sensing systems; Anthropomorphism; appropriate emotions; artificial speech; control engineering computing; empathetic speech; empathetically interacting robot; human perception experiment; Human Robot Interaction; human subjects; human users; humans; robot interacting; robot speech; speech synthesis; speech synthesizers; standard robotic voice; Standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"JQ4W25YL","conferencePaper","2018","Mollahosseini, A.; Abdollahi, H.; Mahoor, M. H.","Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525777","","Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.","2018-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","783-789","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\RWCHIVS9\8525777.html","","","Task analysis; robots; empathy; emotion recognition; human-robot interaction; social robots; Robots; Videos; affect-aware Ryan; automated affect perception; automated facial expression recognition system; automated FER system; emotional capabilities; empathic expression; empathic social agents; face recognition; Face recognition; human-robot-interaction experiments; likable as when facial expression; Mirrors; Observers; robot vision; social capabilities; social/interactive aspects; Speech recognition; spoken dialog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"NZ5K66H7","conferencePaper","2020","Corretjer, M. G.; Ros, R.; Martin, F.; Miralles, D.","The Maze of Realizing Empathy with Social Robots","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223466","","Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.","2020-08","2021-02-11 03:17:10","2021-02-11 03:17:10","","1334-1339","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\A94MSCLY\9223466.html","","","affective states; human-robot interaction; social robots; software agents; mobile robots; empathy model; empathy test-bed; fun collaborative scenario; intelligent agents; intelligent robots; maze; social robot work","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"UVGNDT3F","conferencePaper","2014","Williams, M.; Wang, X.; Parajuli, P.; Abedi, S.; Youssef, M.; Wang, W.","The Fugitive : A Robot In the Wild","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","The aim of the movie is to highlight some of the key challenges facing so-cial robots in the wild. The opening scene shows a PR2 leaving research laboratory venturing into the real world alone in search of meaning. Each subsequent scene in the movie raises important research questions highlighting problems that need to be addressed in the field of social service robotics. When will robots wander around buildings unsupervised? How will they navigate and localize with glass walls: this research problem is exposed when a robot finds itself having to move around a real building. The robot is independent and has a sense of self. It wants to engage in society. It solves this problem by finding a job in a cafe where it is as-signed menial tasks, but aspires to be a barista. Thus raising the question of whether PR2 robots are suited to working with hot steaming liquids. Still the robot can dream, why not. The robot realizes in order to progress it needs to learn some new skills and it is shown teaching itself a new skill and practicing to improve its performance. When it is time to put the new skill into practice, the robot has a revelation, discovering in the act of doing that there can be preconditions attached to the enaction of skills, i.e. people do not need peanut butter until they have bread to spread it on. The robot demonstrates his robust understanding of social etiquette by not only offering the peanut butter to the female-human first, but also chastising a male-human for not observing this important social protocol. The story ends with the recaptured robot being dragged back to the lab. The robot appears to be mortified by its loss of freedom and looks utterly dejected and dispirited. The robot's behavior generates empathy the human minder, but the robot is pretending to be disheartened, and is deceit-fully planning its next escapade as a Jedi Knight! Deception is a highly sophisticated cognitive skill: a capability enabled by a theory of mind which is necessary for communication, social interaction and collaboration, all critically important skills for a service robot.","2014-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","111-111","","","","","","The Fugitive","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\RP4DBHRM\8542525.html","","","human-robot interaction; Australia; service robots; social interaction; teaching; Robot sensing systems; Buildings; critically important skills; Dairy products; glass walls; highly sophisticated cognitive skill; hot steaming liquids; Human-Robot Interaction; important research questions highlighting problems; important social protocol; Lighting; menial tasks; Motion pictures; opening scene; peanut butter; PR2 leaving research laboratory venturing; PR2 robots; recaptured robot; research problem; Robots in the Wild; security of data; service robot; so-cial robots; social aspects of automation; social etiquette; Social Robotics; social service robotics; subsequent scene","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"EJ4YR36F","conferencePaper","2016","Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.","A laughing-driven pupil response system for inducing empathy","2016 IEEE/SICE International Symposium on System Integration (SII)","","","10.1109/SII.2016.7844051","","Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.","2016-12","2021-02-11 03:17:10","2021-02-11 03:17:10","","520-525","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2474-2325","","C:\Users\esben\Zotero\storage\HWQYN8ZX\7844051.html","","","Timing; empathy; affective computing; human-robot interaction; Robots; Computer science; affective response; communication system; hemispherical display; human communication; human interaction; laughing-driven pupil response system; laughter sharing; Mathematical model; media representation; Solid modeling; Speech; Three-dimensional displays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 IEEE/SICE International Symposium on System Integration (SII)","","","","","","","","","","","","","","",""
"HEW8LKKT","conferencePaper","2019","Vertesi, J.","Seeing Like a Rover: Team Work and Human-Robot Relations","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673224","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","152-152","","","","","","Seeing Like a Rover","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2148","","C:\Users\esben\Zotero\storage\2M67AUTG\8673224.html","","","cognition; human-robot interaction; Teamwork; Human-Robot Interaction; aerospace robotics; group interactions; human cognition; human team; human-robot relations; Mars; Mars Exploration Rover; NASA; planetary rovers; rescue operations; robotic spacecraft missions; robotic spacecraft teams; team work; team working","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"PICWCQ4D","conferencePaper","2011","Gonsior, B.; Sosnowski, S.; Mayer, C.; Blume, J.; Radig, B.; Wollherr, D.; Kühnlenz, K.","Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions","2011 RO-MAN","","","10.1109/ROMAN.2011.6005294","","In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application “Akinator” serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode.","2011-07","2021-02-11 03:17:10","2021-02-11 03:17:10","","350-356","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\KDA2EQPZ\6005294.html","","","human-robot interaction; Computers; Robots; computer games; control engineering computing; face recognition; robot vision; Speech; Actuators; Akinator Web-based gaming application; EDDIE robot head; HRI empathy performance; HRI subjective performance; human facial expression; Loudspeakers; Microphones; Neck; social awareness psychological model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2011 RO-MAN","","","","","","","","","","","","","","",""
"EUC9XK3X","conferencePaper","2014","Chumkamon, S.; Hayashi, E.","ConBe robot: The development of self-perception and expression in face-to-face interaction","2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)","","","10.1109/SCIS-ISIS.2014.7044703","","In social robot development of interaction system robot, it is necessary to develop the fundamental function such as the robot perception. Due to the robot should correctly interpret a behavior or mental expression of the human. If the robot has a good emotional insight of the human, it is the advantage for the robot perception. In this paper, we implement the significant technique that take an advantage to the robot such as the human detection, face detection and recognition. Basically, these techniques could further enable the robot capability of intelligent empathy from the expression of human. We intensively study the vision method for facial expression recognition (FER) to understanding the human emotion and interacting by the robot expression in particular case. The robot interaction is based on the interested person that the robot can recognize with their emotional expression. We also experiment the system in term of face-to-face between robot and user with demonstrate using the head robot along with the result, such as the performance of the perception and the behavior expression of the robot.","2014-12","2021-02-11 03:17:10","2021-02-11 03:17:10","","769-775","","","","","","ConBe robot","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\USYWARD9\7044703.html","","","social robot; emotion recognition; human-robot interaction; face recognition; robot vision; ConBe robot; face detection; face-to-face interaction; facial expression recognition; FER; human detection; human emotion; social robot development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)","","","","","","","","","","","","","","",""
"Q6FSFLIX","conferencePaper","2016","Sin, Y. M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.; Miyake, Y.","Evaluation of a head motion synchronization system in the communicative process between human and robot","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","","","10.1109/SICE.2016.7749252","","An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.","2016-09","2021-02-11 03:17:10","2021-02-11 03:17:10","","1514-1519","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\7WGHAWT6\7749252.html","","","human-robot interaction; social robots; assisted living; Human-robot interaction; Robots; Senior citizens; Acceleration; Accelerometers; Aging; assistive system; elderly rehabilitation; Head motion synchronization; head motion synchronization system; leader-follower relationship; mutual entrainment; neurocognitive impairments; one-way face-to-face human-robot communication experiments; Synchronization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","","","","","","","","","","","","","","",""
"6MMH7QBB","conferencePaper","2015","Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani-Sherman, T.","Design and Evaluation of a Peripheral Robotic Conversation Companion","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote nonaggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to-human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.","2015-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","3-10","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\SIT2UBQ9\8520619.html","","","Monitoring; Empathy; human-robot interaction; design process; Human-robot interaction; human factors; humanoid robots; Robot sensing systems; Ambient kinetic tangibles; Animation; Behavior change; Design; design goals; gaze attention; gesture recognition; human-human interaction; interactive systems; Kinetic theory; Kip1; nonaggressive conversation; peripheral empathy-evoking robotic conversation companion; reacting robot; robot autonomous behavior; Robotic companions; robotic devices; Shape; Smartphone robots.; social human character traits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"N8GQS2ZK","conferencePaper","2020","Sönmez, E. B.; Köse, H.; Barkana, D. E.","Towards a New Computational Affective System for Personal Assistive Robots","2020 28th Signal Processing and Communications Applications Conference (SIU)","","","10.1109/SIU49456.2020.9302238","","The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively.","2020-10","2021-02-11 03:17:10","2021-02-11 03:17:10","","1-4","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2165-0608","","C:\Users\esben\Zotero\storage\63LICFIK\9302238.html","","","Computational modeling; emotion recognition; affective computing; virtual human; Robots; facial expression; Face recognition; Three-dimensional displays; Faces; Feature extraction; Mood","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 28th Signal Processing and Communications Applications Conference (SIU)","","","","","","","","","","","","","","",""
"BPW7ZFLC","conferencePaper","2019","Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.","The RoPE Scale: a Measure of How Empathic a Robot is Perceived","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673082","","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.","2019-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","656-657","","","","","","The RoPE Scale","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2148","","C:\Users\esben\Zotero\storage\5AUM3L57\8673082.html","","","Psychology; Psychometrics; cognition; human-robot interaction; Indexes; Robot sensing systems; Human-Robot Interaction; emotional behaviors; empathic behaviors; interaction partners; Measurement; Perceived Empathy; RoPE scale; Social Robots; Software reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"IEGQ7ERR","conferencePaper","2019","Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.","Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals","2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN46459.2019.8956353","","Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.","2019-10","2021-02-11 03:17:10","2021-02-11 03:17:10","","1-8","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\XW5RD9GG\8956353.html","","","empathy; emotion recognition; human-robot interaction; facial expression; face recognition; robot vision; biological signals; emotion estimation system; human-robot; reflected emotion; robot expression; uncontrollable emotion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"BW3IB68E","conferencePaper","2014","Obaid, M.; Kuchenbrandt, D.; Bartneck, C.","Empathy and Yawn Contagion: Can we (Humans) Catch Yawns from Robots?","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","Empathy plays an important role in the interaction between humans and robots. The contagious effect of yawning is moderated by the degree of social closeness and empathy. We propose to analyse the contagion of yawns as an indicator for empathy. We conducted pilot studies to test different experimental procedures for this purpose. We hope to be able to report on experimental results in the near future.","2014-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","260-261","","","","","","Empathy and Yawn Contagion","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\YPV8NIVJ\8542627.html","","","Psychology; Task analysis; robots; Empathy; empathy; Human-robot interaction; Humanoid robots; human computer interaction; Atmospheric measurements; Particle measurements; humanoid robots; Humanoid; Robot; social closeness; Yawn; yawn contagion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"VIBQDQAF","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","10.1109/ICAITI.2018.8686759","","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.","2018-09","2021-02-11 03:17:10","2021-02-11 03:17:10","","208-212","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\NSYFQM36\8686759.html","","","handicapped aids; Mobile Robot; social interaction; psychology; mobile robots; Android; Android-based mobile robots; Asperger syndrome; Asperger Syndrome disorder; autistic disorder; data analysis; mobile computing; paediatrics; patient treatment; Pekanbaru children; play therapy; Rank Wilcoxon; robot control tool; smart phones; wheel-shaped robot; wheeled robot; wheels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","","","","","","","","","","","","",""
"B6PR6HZT","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.","Band of Brothers and Bolts: Caring About Your Robot Teammate","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8594324","","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.","2018-10","2021-02-11 03:17:10","2021-02-11 03:17:10","","1853-1858","","","","","","Band of Brothers and Bolts","","","","","","","","","","","","IEEE Xplore","","ISSN: 2153-0866","","C:\Users\esben\Zotero\storage\JGEW9345\8594324.html","","","human-robot interaction; Robots; computer games; Atmospheric measurements; Particle measurements; Computer bugs; Bonding; consequential behavioral pattern; empathic response; robot companion; robot teammate; Time measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","","","","","","","","","","","","",""
"5ZP86ULF","conferencePaper","2017","Anshar, M.; Williams, M.","Evolving artificial pain from fault detection through pattern data analysis","2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)","","","10.1109/RCAR.2017.8311945","","Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.","2017-07","2021-02-11 03:17:10","2021-02-11 03:17:10","","694-699","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\HZL343LQ\8311945.html; C:\Users\esben\Zotero\storage\B5MNBMHD\Anshar and Williams - 2017 - Evolving artificial pain from fault detection thro.pdf","","","robots; Pain; Robot sensing systems; data analysis; appropriate artificial pain; artificial pain generation; artificial robot pain; biomechanics; body machinery aspects; Data analysis; evolving artificial pain; extensive research works; fault detection approach; fault diagnosis; Machinery; pattern data analysis; Planning; sophisticated social skills; synthetic pain classes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)","","","","","","","","","","","","","","",""
"CCPE44P7","conferencePaper","2019","Sanoubari, E.; Seo, S. H.; Garcha, D.; Young, J. E.; Loureiro-Rodríguez, V.","Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673326","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019-03","2021-02-11 03:17:10","2021-02-11 03:17:10","","382-391","","","","","","Good Robot Design or Machiavellian?","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2148","","C:\Users\esben\Zotero\storage\MUTHQCVK\8673326.html","","","learning (artificial intelligence); Ethics; Task analysis; culture; human-robot interaction; social robots; robot design; Robots; Cultural differences; mobile robots; Shape; Mood; body language; Global communication; human-like communication techniques; in the wild; in-the-wild robot; minimal information; passersby culture; persuasive robots; Sam; social signals; social techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"3UZRKRCE","conferencePaper","2020","Ye, S.; Feigh, K.; Howard, A.","Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223437","","Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.","2020-08","2021-02-11 03:17:51","2021-02-11 03:17:51","","1186-1189","","","","","","Learning in Motion","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\FWTXNISG\9223437.html","","","cognition; human-robot interaction; computer games; humanoid robots; human-robot interactions; cognitive science literature; dance motion; dynamic interactions; embodied cognition; human perspective; human-robot interaction games trust; humanoid robot; social empathy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"JWA5FAS3","conferencePaper","2016","Ranieri, C. M.; Romero, R. A. F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","10.1109/LARS-SBR.2016.13","","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.","2016-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","31-36","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\EJTCU8NI\7783498.html","","","Emotions; Affective computing; empathy; human-robot interaction; social robots; Robots; Social robots; control engineering computing; smart phones; Android application; embodied virtual agent; emotion-aware interaction strategy; emotional reactions; facial expressions analysis; human-robot interaction improvement; Mobile devices; pleasantness; virtual character","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","","","","","","","","","","","","",""
"QLM7V8GL","conferencePaper","2015","Chumkamon, S.; Masato, K.; Hayashi, E.","Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot","2015 IEEE International Conference on Systems, Man, and Cybernetics","","","10.1109/SMC.2015.45","","This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).","2015-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","185-190","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\EWETKWNI\7379177.html","","","Animals; human-robot interaction; artificial consciousness; social interaction; Face; face recognition; robot vision; human communication; Mathematical model; facial expression recognition; Shape; animal behavior; animal robot; artificial neurotransmitter; CBA; cross-creature communication development; cross-expression; cross-perception; emotional motivation; Facial Expression Recognition; human expression; Human-Robot Interactio; Manipulators; Neurotransmitters; pet robot; phylogenesis; social cognitive; Social Robot; user expression","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE International Conference on Systems, Man, and Cybernetics","","","","","","","","","","","","","","",""
"VV6V86VF","conferencePaper","2020","Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.","Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223442","","In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.","2020-08","2021-02-11 03:17:51","2021-02-11 03:17:51","","653-658","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\62CHVINT\9223442.html; C:\Users\esben\Zotero\storage\Y28DJKT2\Mitsuno et al. - 2020 - Robot-on-Robot Gossiping to Improve Sense of Human.pdf","","","social robot; human-robot interaction; man-machine systems; control engineering computing; conversation experiment; data privacy; dialogue strategy; human-robot conversation; Likert scale evaluation; long-term user interest; natural language interfaces; privacy issue; privacy problems; robot empathy; robot-on-robot gossiping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"UU2NCDW4","conferencePaper","2018","Iranzo, R. M. G.; Padilla-Zea, N.; Paderewski-Rodríguez, P.; González-González, C. S.","Empathy and virtual agents for learning applications in symbiotic systems","2018 IEEE Global Engineering Education Conference (EDUCON)","","","10.1109/EDUCON.2018.8363298","","Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges.","2018-04","2021-02-11 03:17:51","2021-02-11 03:17:51","","694-697","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2165-9567","","C:\Users\esben\Zotero\storage\5CGFADEA\8363298.html","","","Ethics; ethics; robots; virtual agents; empathy; human-robot interaction; Robots; robot; human computer interaction; human factors; mobile robots; multi-robot systems; Observers; Biometrics (access control); bot; bots; Guidelines; HCI communication challenges; Privacy; Symbiosis; symbiotic agents; symbiotic domain; symbiotic systems; transparency; valuable asset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE Global Engineering Education Conference (EDUCON)","","","","","","","","","","","","","","",""
"MRDX7LXN","conferencePaper","2018","Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.","Learning Empathy-Driven Emotion Expressions using Affective Modulations","2018 International Joint Conference on Neural Networks (IJCNN)","","","10.1109/IJCNN.2018.8489158","","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.","2018-07","2021-02-11 03:17:51","2021-02-11 03:17:51","","1-8","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2161-4407","","C:\Users\esben\Zotero\storage\BLWAF4EI\8489158.html","","","learning (artificial intelligence); Neurons; emotion recognition; human-robot interaction; social robots; Adaptation models; Emotion recognition; humanoid robots; Robot sensing systems; face recognition; Mood; affective modulations; Convolution; deep hybrid neural model; empathy-driven emotion expressions; facial expression representations; interaction design; internal affective model; internal emotions; intrinsic affective states; multimodal affect recognition; natural interaction experience; neuro-inspired companion robot; neurocontrollers; NICO robot; reinforcement learning model; self-organising feature maps; self-organising network models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 International Joint Conference on Neural Networks (IJCNN)","","","","","","","","","","","","","","",""
"26UNSF46","conferencePaper","2010","Beck, A.; Cañamero, L.; Bard, K. A.","Towards an Affect Space for robots to display emotional body language","19th International Symposium in Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598649","","In order for robots to be socially accepted and generate empathy it is necessary that they display rich emotions. For robots such as Nao, body language is the best medium available given their inability to convey facial expressions. Displaying emotional body language that can be interpreted whilst interacting with the robot should significantly improve its sociability. This research investigates the creation of an Affect Space for the generation of emotional body language to be displayed by robots. To create an Affect Space for body language, one has to establish the contribution of the different positions of the joints to the emotional expression. The experiment reported in this paper investigated the effect of varying a robot's head position on the interpretation, Valence, Arousal and Stance of emotional key poses. It was found that participants were better than chance level in interpreting the key poses. This finding confirms that body language is an appropriate medium for robot to express emotions. Moreover, the results of this study support the conclusion that Head Position is an important body posture variable. Head Position up increased correct identification for some emotion displays (pride, happiness, and excitement), whereas Head Position down increased correct identification for other displays (anger, sadness). Fear, however, was identified well regardless of Head Position. Head up was always evaluated as more highly Aroused than Head straight or down. Evaluations of Valence (degree of negativity to positivity) and Stance (degree to which the robot was aversive to approaching), however, depended on both Head Position and the emotion displayed. The effects of varying this single body posture variable were complex.","2010-09","2021-02-11 03:17:51","2021-02-11 03:17:51","","464-469","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\ZJFWIRJ4\5598649.html","","","robots; emotion recognition; facial expressions; Robots; Atmospheric measurements; Particle measurements; Analysis of variance; control engineering computing; affect space; emotional body language display; Head; head position; Joints; Nao; pose estimation; Position measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","19th International Symposium in Robot and Human Interactive Communication","","","","","","","","","","","","","","",""
"TLRVRR93","conferencePaper","2012","Gonsior, B.; Buß, M.; Sosnowski, S.; Wollherr, D.; Kühnlenz, K.; Buss, M.","Towards transferability of theories on prosocial behavior from Social Psychology to HRI","2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)","","","10.1109/ARSO.2012.6213407","","This paper describes the transfer of theories on prosocial behavior from Social Psychology to human-robot interaction (HRI) in terms of helpfulness shown by humans towards a robot. Theoretical foundations are given, and relevant influence factors for prosocial behavior are defined. The paper provides an overview on how these factors can be transferred to HRI and are implemented in two experimental settings. In a first experiment, situational empathy towards a robot is increased. In a second experiment, similarity is induced by means of emotional adaption to the mood of the user. Results show that helpfulness towards a robot can be increased by this approach, thus, re-evaluating the transferability of theories from Social Psychology to HRI.","2012-05","2021-02-11 03:17:51","2021-02-11 03:17:51","","101-103","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2162-7576","","C:\Users\esben\Zotero\storage\QKR369EX\6213407.html; C:\Users\esben\Zotero\storage\GGJGKRS2\Gonsior et al. - 2012 - Towards transferability of theories on prosocial b.pdf","","","Context; Humans; human-robot interaction; Robots; prosocial behavior; psychology; Games; Face; Mood; emotional adaption; situational empathy; social psychology; theory transferability; user mood","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)","","","","","","","","","","","","","","",""
"P3JX5VPQ","conferencePaper","2012","Leite, I.; Castellano, G.; Pereira, A.; Martinho, C.; Paiva, A.","Modelling empathic behaviour in a robotic game companion for children: An ethnographic study in real-world settings","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1145/2157689.2157811","","The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the “degree of empathy” that social robots should be endowed with.","2012-03","2021-02-11 03:17:51","2021-02-11 03:17:51","","367-374","","","","","","Modelling empathic behaviour in a robotic game companion for children","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2148","","C:\Users\esben\Zotero\storage\I98RL3UA\6249581.html","","","children; Empathy; human-robot interaction; Educational institutions; Games; Feature extraction; Social Robots; Affect Recognition; autonomous social robots; Children; elementary school; empathic behaviour modelling; Encoding; ethnographic study; Interviews; real-world settings; Robot kinematics; robotic game companion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"WPAAE397","conferencePaper","2017","Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.","Learning human behavior for emotional body expression in socially assistive robotics","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","","","10.1109/URAI.2017.7992882","","Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots.","2017-06","2021-02-11 03:17:51","2021-02-11 03:17:51","","45-50","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\E3F6IU6Q\7992882.html","","","learning (artificial intelligence); Neurons; Psychology; Training; empathy; human-robot interaction; Human-robot interaction; Robots; humanoid robots; intelligent robots; emotional behaviors; self-organising feature maps; clustering; emotional behavior expression; emotional behavior samples; emotional body expression; emotional body expressions; emotional situations; human partners; imitation learning; infant emotional development; infant social development; Kernel; public human action dataset; self-organized neural networks; Skeleton; social referencing; socially assistive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","","","","","","","","","","","","","","",""
"3TCX3P9X","conferencePaper","2018","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.","Counseling Robot Implementation and Evaluation","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2018.00297","","A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called ""unazuki"" in Japanese, a kind of nodding to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared.","2018-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","1716-1722","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2577-1655","","C:\Users\esben\Zotero\storage\JN5FRZZ8\8616293.html","","","human-robot interaction; natural language processing; psychology; human factors; Robot sensing systems; interactive systems; Robot; body language; appropriate nodding behavior; context preserving way; context respectful counseling agent; Counseling; counseling robot implementation; CRECA; Dialog Promotion; dialog promotion nodding; dialog sentence input; Dictionaries; employee welfare; Employee welfare; enhanced experimental evaluation; industrial psychology; Japanese onomatopoeia; Natural languages; Nodding; nodding feature; occupational stress; Ontologies; psychological distress; quantitative evaluation; Reflection; reflection context; robot implementation; robot nods; unazuki; workers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","","","","","","","","","","","","",""
"G7VM5P8U","conferencePaper","2018","Tuyen, N. T. Viet; Jeong, S.; Chong, N. Y.","Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8593974","","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.","2018-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","2008-2013","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2153-0866","","C:\Users\esben\Zotero\storage\HVCMCU4H\8593974.html","","","learning (artificial intelligence); Neurons; Training; social robot; emotion recognition; human-robot interaction; Robot kinematics; Collision avoidance; cultural background; culturally competent robots; emotional bodily expressions; habitual emotional behaviors; imitated robot motions; incremental learning model; long term human-robot interaction; multiculture society; Self-organizing feature maps; Trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","","","","","","","","","","","","",""
"N8M3QWUR","conferencePaper","2018","Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.","Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525515","","Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.","2018-08","2021-02-11 03:17:51","2021-02-11 03:17:51","","275-281","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\VAMUX9K3\8525515.html","","","Task analysis; human-robot interaction; user experience; Robots; humanoid robots; Anthropomorphism; Mood; Color; Communication channels; emotional adaptation; explicit emotional adaptation condition; facial action units; human user; human-robot dialog scenario; named objects; NAO; prior robot contact; prior robot experience; robotic interaction partners; social cues; user study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"NR6Q8AAM","conferencePaper","2018","Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.","Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression","2018 15th International Conference on Ubiquitous Robots (UR)","","","10.1109/URAI.2018.8441767","","Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.","2018-06","2021-02-11 03:17:51","2021-02-11 03:17:51","","377-382","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\L3964R4L\8441767.html","","","learning (artificial intelligence); Neurons; Psychology; neural nets; Training; emotion recognition; human-robot interaction; social robots; Human-robot interaction; Robots; Cultural differences; humanoid robots; socially assistive robots; incremental learning model; Self-organizing feature maps; human emotional behavior; neural network model; social robot emotional body expression; user cultural traits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 15th International Conference on Ubiquitous Robots (UR)","","","","","","","","","","","","","","",""
"U4RRJPT8","conferencePaper","2010","Cramer, H.; Goddijn, J.; Wielinga, B.; Evers, V.","Effects of (in)accurate empathy and situational valence on attitudes towards robots","2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2010.5453224","","Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3×2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.","2010-03","2021-02-11 03:17:51","2021-02-11 03:17:51","","141-142","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2148","","C:\Users\esben\Zotero\storage\FXA8V2GD\5453224.html; C:\Users\esben\Zotero\storage\42LQJRP5\Cramer et al. - 2010 - Effects of (in)accurate empathy and situational va.pdf","","","Appraisal; empathy; human-robot interaction; social robots; Games; Emotion recognition; empathic responses; Videos; Analysis of variance; control engineering computing; between-subject video-based survey; emotional valence; Human robot interaction; Mobile robots; negative valence condition; Online Communities/Technical Collaboration; Silicon carbide; situational valence; Testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"B8CQ297I","conferencePaper","2015","Hood, D.; Lemaignan, S.; Dillenbourg, P.","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.By leveraging simulated handwriting on a synchronised tablet display, a NAo humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models.Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015-03","2021-02-11 03:17:51","2021-02-11 03:17:51","","83-90","","","","","","When Children Teach a Robot to Write","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\P5UC9XZF\8520635.html","","","feedback; Education; cognition; empathy; human-robot interaction; Humanoid robots; psychology; educational institutions; humanoid robots; mobile robots; teaching; Mathematical model; Shape; adult-written letter trajectories; autonomous teachable humanoid; computer aided instruction; deformed letters; embodied handwriting partner; human-led handwriting interventions; meta-cognition; motor capabilities; motor mimicry; NAo humanoid robot; notebook computers; optimal parameters; primary school classes; principal component analysis; Principal component analysis; robotic partner; self-esteem; simulated handwriting; statistical shape models; synchronised tablet display; teaching paradigm; user demonstrations; Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"F8WTWJ89","conferencePaper","2017","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Design of Counseling Robot for Production by 3D Printer","2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS)","","","10.1109/SITIS.2017.20","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling.","2017-12","2021-02-11 03:17:51","2021-02-11 03:17:51","","56-62","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\IU6WAU5J\8334725.html","","","Psychology; Cognition; human-robot interaction; Robots; psychology; Emotion recognition; human factors; Robot; context respectful counseling agent; Counseling; CRECA; Dialog Promotion; dialog sentence input; employee welfare; Employee welfare; industrial psychology; Japanese onomatopoeia; Nodding; occupational stress; psychological distress; Reflection; robot nods; unazuki; 3D printer; CA; counseling robot; newly developed robot; Problem-solving; social problems; unazuki-dialog promotion nodding robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS)","","","","","","","","","","","","","","",""
"T74BZXI4","conferencePaper","2014","Mok, B.; Yang, S.; Sirkin, D.; Ju, W.","Empathy: Interactions with Emotive Robotic Drawers","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.","2014-03","2021-02-11 03:17:51","2021-02-11 03:17:51","","250-251","","","","","","Empathy","","","","","","","","","","","","IEEE Xplore","","ISSN: 2167-2121","","C:\Users\esben\Zotero\storage\4Z2UWCI8\8542481.html","","","emotion recognition; human-robot interaction; Human-robot interaction; Robot sensing systems; Animation; DC motors; displayed emotions; emotive robotic drawers; empathetic drawers; Human Robot Interactions; Interaction Design; Interactive Furniture; Prototypes; Telepresence; Video Prototyping; video signal processing; video-prototype; Wizard of Oz Experiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","","","","","","","","","","",""
"AQAG4WRN","conferencePaper","2019","Costantini, S.; Gasperis, G. De; Migliarini, P.","Multi-agent System Engineering for Emphatic Human-Robot Interaction","2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","","","10.1109/AIKE.2019.00015","","Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy.","2019-06","2021-02-11 03:17:51","2021-02-11 03:17:51","","36-42","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\IK3VZP4P\8791734.html","","","perception; emotions; communication; empathy; human-robot interaction; affect; multi-agent systems; Face; human empathy; mobile robots; Face recognition; Speech recognition; intelligent agents; Robot kinematics; body posture; daily robotic interaction; emotional exchange; emphatic communication aspects; emphatic human-robot interaction; face muscles; human robot interaction; human-robot communication use cases; logic; logical agents; Multi-agent systems; multiagent system engineering; natural multimodal bidirectional communication model; Skin; skin responses; verbal exchange; voice modulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","","","","","","","","","","","","","","",""
"GHXMWXAV","conferencePaper","2016","Lewandowska-Tomaszczyk, B.; Wilson, P. A.","Compassion, empathy and sympathy expression features in affective robotics","2016 7th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","","","10.1109/CogInfoCom.2016.7804526","","The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents.","2016-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","000065-000070","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\WVGNCA2A\7804526.html","","","Context; emotions; robots; empathy; expressiveness; Robot sensing systems; Robot kinematics; action tendencies; affective robotics; British English; British English compassion; cognitive corpus linguistics; cognitive infocommunication; compassion; compassion expression features; cultural aspects; culture-specific emotion models; empathy expression features; empatia; English empathy; false negative; false positive; GRID; online sorting; Polish; Polish empatia; Polish współczucie; Pragmatics; Resonant frequency; responsiveness; sensory infocommunication; socially interactive robots; Sorting; sympathy; sympathy expression features; sympatia; valence; współczucie","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 7th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","","","","","","","","","","","","","","",""
"A3BWXBB4","conferencePaper","2014","Sejima, Y.; Watanabe, T.; Jindai, M.","Development of an interaction-activated communication model based on a heat conduction equation in voice communication","The 23rd IEEE International Symposium on Robot and Human Interactive Communication","","","10.1109/ROMAN.2014.6926356","","In a previous study, we developed an embodied virtual communication system for human interaction analysis by synthesis in avatar-mediated communication and confirmed the close relationship between speech overlap and the period for activating embodied interaction and communication through avatars. In this paper, we propose an interaction-activated communication model based on the heat conduction equation in heat-transfer engineering for enhancing empathy between a human and a robot during embodied interaction in avatar-mediated communication. Further, we perform an evaluation experiment to demonstrate the effectiveness of the proposed model in estimating the period of interaction-activated communication in avatar-mediated communication. Results suggest that the proposed model is effective in estimating interaction-activated communication.","2014-08","2021-02-11 03:17:51","2021-02-11 03:17:51","","832-837","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\MK39E9WN\6926356.html","","","human-robot interaction; Robots; control engineering computing; Mathematical model; Speech; avatar-mediated communication; avatars; Equations; heat conduction equation; Heat engines; Heating; human interaction analysis; interaction-activated communication model; Modeling; partial differential equations; speech overlap; virtual communication system; voice communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The 23rd IEEE International Symposium on Robot and Human Interactive Communication","","","","","","","","","","","","","","",""
"QRBUW3CW","conferencePaper","2019","Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","10.1109/RITAPP.2019.8932852","","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.","2019-11","2021-02-11 03:17:51","2021-02-11 03:17:51","","160-163","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\JDBQ42X2\8932852.html","","","cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","","","","","","","","","","","","",""
"QSFW2Z6R","journalArticle","2014","Boucenna, S.; Gaussier, P.; Hafemeister, L.","Development of First Social Referencing Skills: Emotional Interaction as a Way to Regulate Robot Behavior","IEEE Transactions on Autonomous Mental Development","","1943-0612","10.1109/TAMD.2013.2284065","","In this paper, we study how emotional interactions with a social partner can bootstrap increasingly complex behaviors such as social referencing. Our idea is that social referencing as well as facial expression recognition can emerge from a simple sensory-motor system involving emotional stimuli. Without knowing that the other is an agent, the robot is able to learn some complex tasks if the human partner has some “empathy” or at least “resonate” with the robot head (low level emotional resonance). Hence, we advocate the idea that social referencing can be bootstrapped from a simple sensory-motor system not dedicated to social interactions.","2014-03","2021-02-11 03:17:51","2021-02-11 03:17:51","","42-55","","1","6","","","Development of First Social Referencing Skills","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Autonomous Mental Development","","C:\Users\esben\Zotero\storage\KWMF7MKR\6672018.html","","","Emotion; Neurons; human-robot interaction; Emotion recognition; emotional interaction; Face; Robot sensing systems; Face recognition; facial expression recognition; Feature extraction; social referencing; complex behaviors; emotional resonance; emotional stimuli; human partner; human–robot interaction; robot behavior; sensory–motor architecture; social interactions; social referencing skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9L3JQ3M","conferencePaper","2017","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Context respectful counseling agent integrated with robot nodding for dialog promotion","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2017.8122833","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling.","2017-10","2021-02-11 03:17:51","2021-02-11 03:17:51","","1540-1545","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\SIK6X8DH\8122833.html","","","Cognition; human-robot interaction; Robots; natural language processing; psychology; interactive systems; Robot; body language; context respectful counseling agent; Counseling; CRECA; Dialog Promotion; Dictionaries; Employee welfare; Japanese onomatopoeia; Nodding; occupational stress; Ontologies; psychological distress; Reflection; reflection context; robot nods; unazuki; Problem-solving; client reflection; context preserving; dialogue promotion; IT personnel; ontologies (artificial intelligence); robot nodding; ubiquitous computing; unazuki dialog promotion nodding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","","","","","","","","","","","","",""
"MYHND69Z","conferencePaper","2011","Mazzei, D.; Lazzeri, N.; Billeci, L.; Igliozzi, R.; Mancini, A.; Ahluwalia, A.; Muratori, F.; Rossi, D. De","Development and evaluation of a social robot platform for therapy in autism","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","","","10.1109/IEMBS.2011.6091119","","People with ASD (Autism Spectrum Disorders) have difficulty in managing interpersonal relationships and common life social situations. A modular platform for Human Robot Interaction and Human Machine Interaction studies has been developed to manage and analyze therapeutic sessions in which subjects are driven by a psychologist through simulated social scenarios. This innovative therapeutic approach uses a humanoid robot called FACE capable of expressing and conveying emotions and empathy. Using FACE as a social interlocutor the psychologist can emulate real life scenarios where the emotional state of the interlocutor is adaptively adjusted through a semi closed loop control algorithm which uses the ASD subject's inferred ”affective” state as input. Preliminary results demonstrate that the platform is well accepted by ASDs and can be consequently used as novel therapy for social skills training.","2011-08","2021-02-11 03:17:51","2021-02-11 03:17:51","","4515-4518","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1558-4615","","C:\Users\esben\Zotero\storage\PJA3WKC3\6091119.html","","","Humans; medical robotics; Robotics; emotions; empathy; human-robot interaction; Humanoid robots; Face; interpersonal relationships; Human Robot Interaction; patient treatment; Androids; Autism; Autism Spectrum Disorders; autism therapy; Autistic Disorder; common life social situations; FACE humanoid robot; Human Machine Interaction; medical disorders; Protocols; psychologist; social interlocutor; social robot platform; social skills training; Variable speed drives","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","","","","","","","","","","","","","","",""
"M9BKRFUH","journalArticle","2016","Roudposhti, K. K.; Nunes, U.; Dias, J.","Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns","IEEE Transactions on Pattern Analysis and Machine Intelligence","","1939-3539","10.1109/TPAMI.2015.2496209","","Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.","2016-08","2021-02-11 03:18:13","2021-02-11 03:18:13","","1679-1691","","8","38","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence","","C:\Users\esben\Zotero\storage\JUG4F78V\7312488.html","","","feature extraction; Humans; Movement; Algorithms; human-robot interaction; Human-robot interaction; behavioural sciences; Three-dimensional displays; Shape; Feature extraction; Analytical models; Bayes methods; Bayes Theorem; Bayesian approach; body motion-based features analysis; body motion-based patterns; DBN technique; frequency domain; Histograms; human behavior analysis; human movement analysis; human movement descriptor; IB; interpersonal behaviors; laban movement analysis; LMA; Models, Statistical; Motion; multilayer dynamic Bayesian network technique; pattern classification; Pattern Recognition, Automated; probabilistic social behavior analysis; Social Behavior; social context; social role; Social signal processing; SR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVREQ6U6","conferencePaper","2010","Mayer, C.; Sosnowski, S.; Kühnlenz, K.; Radig, B.","Towards robotic facial mimicry: System development and evaluation","19th International Symposium in Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598629","","We introduce a facial mimicry system, which combines facial expression analysis and synthesis on a robot, utilizing the facial action coding system. The activation of action units on a user's face is automatically extracted from a video stream and mapped to the robot, thus mirroring the facial expression. As a novel approach, a user study quantifies the congruence of the initial human facial expression with the robotic facial expression. The evaluation shows that the robotic facial expression is perceived to be close to the human facial expression, from which it is derived. This is a fundamental aspect for a mimicry system, providing a basis for future research on empathy and emotional closed loop control.","2010-09","2021-02-11 03:18:13","2021-02-11 03:18:13","","198-203","","","","","","Towards robotic facial mimicry","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\WAERVZFR\5598629.html","","","Humans; emotion recognition; Robots; Face; humanoid robots; face recognition; Face recognition; Feature extraction; emotional closed loop control; Eyelids; facial action coding system; facial expression analysis; robotic facial expression; robotic facial mimicry; video stream; video streaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","19th International Symposium in Robot and Human Interactive Communication","","","","","","","","","","","","","","",""
"YSHVJH9T","conferencePaper","2015","Rasool, Z.; Masuyama, N.; Islam, M. N.; Loo, C. K.","Empathic Interaction Using the Computational Emotion Model","2015 IEEE Symposium Series on Computational Intelligence","","","10.1109/SSCI.2015.26","","This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.","2015-12","2021-02-11 03:18:13","2021-02-11 03:18:13","","109-116","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\7Q3PX9SC\7376599.html","","","Computational modeling; emotion recognition; human-robot interaction; Robots; Face; Face recognition; facial expression recognition; Shape; Mood; empathic response; Clustering algorithms; computational emotion model; computational emotional model; empathic appraisal stage; empathic expression stage; empathic interaction; empathy oriented human-robot interaction model; fuzzy logic; perception stage; pleasure-arousal scaling model; robot mood factor; robot personality; virtual facial expression simulator","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE Symposium Series on Computational Intelligence","","","","","","","","","","","","","","",""
"KPNL3P73","conferencePaper","2010","Mazzei, D.; Billeci, L.; Armato, A.; Lazzeri, N.; Cisternino, A.; Pioggia, G.; Igliozzi, R.; Muratori, F.; Ahluwalia, A.; Rossi, D. De","The FACE of autism","19th International Symposium in Robot and Human Interactive Communication","","","10.1109/ROMAN.2010.5598683","","People with autism are known to possess deficits in processing emotional states, both their own and of others. A humanoid robot, FACE (Facial Automation for Conveying Emotions), capable of expressing and conveying emotions and empathy has been constructed to enable autistic children and adults to better deal with emotional and expressive information. We describe the development of an adaptive therapeutic platform which integrates information deriving from wearable sensors carried by a patient or subject as well as sensors placed in the therapeutic ambient. Through custom developed control and data processing algorithms the expressions and movements of FACE are then tuned and modulated to harmonize with the feelings of the subject postulated by their physiological and behavioral correlates. Preliminary results demonstrating the potential of adaptive therapy are presented.","2010-09","2021-02-11 03:18:13","2021-02-11 03:18:13","","791-796","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\YBTZKIQR\5598683.html","","","medical robotics; Medical treatment; autism; Humanoid robots; Face; humanoid robots; Robot sensing systems; patient treatment; humanoid robot; Androids; Autism; Variable speed drives; adaptive therapeutic platform; adaptive therapy; FACE; facial automation for conveying emotions; therapeutic ambient; wearable sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","19th International Symposium in Robot and Human Interactive Communication","","","","","","","","","","","","","","",""
"RDBXJ2CA","journalArticle","2020","Rafique, M.; Hassan, M. A.; Jaleel, A.; Khalid, H.; Bano, G.","A Computation Model for Learning Programming and Emotional Intelligence","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3015533","","Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.","2020","2021-02-11 03:18:13","2021-02-11 03:18:13","","149616-149629","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\esben\Zotero\storage\J8HNML8U\Rafique et al. - 2020 - A Computation Model for Learning Programming and E.pdf; C:\Users\esben\Zotero\storage\UMGRXDVS\9163380.html","","","Computational modeling; Education; cognition; Robots; Emotional intelligence; teaching; basic programming; cognitive skills; computational model; computational thinking; computer science education; early education; emotional intelligence skills; empathy emotions; fundamental programming constructs; kid emotional intelligence; logical thinking; programming; programming concepts; programming instructions; Programming profession; robots based learning; screen-free interface; screen-free student interface; self-awareness; Sequential analysis; social-awareness; teaching methods; Tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAUQADH3","conferencePaper","2020","Perusquía-Hernández, M.; Balda, M. C.; Jáuregui, D. A. Gómez; Paez-Granados, D.; Dollack, F.; Salazar, J. V.","Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User’s Physiological Affective States","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223598","","Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.","2020-08","2021-02-11 03:18:13","2021-02-11 03:18:13","","1328-1333","","","","","","Robot Mirroring","","","","","","","","","","","","IEEE Xplore","","ISSN: 1944-9437","","C:\Users\esben\Zotero\storage\EGCC5BLL\9223598.html","","","Visualization; physiology; feedback; Robots; embodiment; multi-agent systems; mobile robots; Robot sensing systems; control engineering computing; artificial agent; empathy and intersubjectivity; facial body cues; haptic feedback; haptic interfaces; Haptic interfaces; haptic interoceptive patterns; health care; Heart rate; heart-rate levels; human-machine interaction; integrated visuo-haptic representations; interoceptive feedback; Physiology; robot mirroring wearable systems; self-tracking feedback; users physiological affective states; Vibrations; visual feedback; visual representations; wearable pet; wearable prototype; wearable robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","","","","","","","","","","","","",""
"8ELE8GDE","conferencePaper","2020","Malik, P.; Gautam, S.; Srivastava, S.","A Study on Behaviour Intention for using Chatbots","2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","","","10.1109/ICRITO48877.2020.9197782","","The present study uses the primary research to find out the behavior intention of an individual to use chatbots. The study has taken the five dimensions viz., reliability, responsiveness, assurance, empathy and tangibility and find out their association with behavior intention of an individual to use the chatbots. The sample of 270 respondents are taken to conclude the findings. It was concluded that out of these five dimensions, three dimensions are significantly associated with intention of using chatbots. These are reliability, empathy and tangibility.","2020-06","2021-02-11 03:35:05","2021-02-11 03:35:05","","332-338","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\KFP96LED\9197782.html","","","Artificial intelligence; Task analysis; Empathy; empathy; Chatbots; chatbots; Organizations; human computer interaction; human factors; Assurance; behaviour intention; Behaviour Intention; Customer satisfaction; Internet; reliability; Reliability; Responsiveness; tangibility; Tangibility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","","","","","","","","","","","","","","",""
"7KCMLT52","conferencePaper","2019","Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","10.1109/RITAPP.2019.8932852","","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.","2019-11","2021-02-11 03:35:05","2021-02-11 03:35:05","","160-163","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\HBY89XII\8932852.html","","","cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","","","","","","","","","","","","",""
"KIUAFYUD","conferencePaper","2020","Shin, J.; Xu, P.; Madotto, A.; Fung, P.","Generating Empathetic Responses by Looking Ahead the User’s Sentiment","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","","","10.1109/ICASSP40776.2020.9054379","","An important aspect of human conversation difficult for machines is conversing with empathy, which is to understand the user's emotion and respond appropriately. Recent neural conversation models that attempted to generate empathetic responses either focused on conditioning the output to a given emotion, or incorporating the current user emotional state. However, these approaches do not factor in how the user would feel towards the generated response. Hence, in this paper, we propose Sentiment Look-ahead, which is a novel perspective for empathy that models the future user emotional state. In short, Sentiment Look-ahead is a reward function under a reinforcement learning framework that provides a higher reward to the generative model when the generated utterance improves the user's sentiment. We implement and evaluate three different possible implementations of sentiment look-ahead and empirically show that our proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning.","2020-05","2021-02-11 03:37:19","2021-02-11 03:37:19","","7989-7993","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2379-190X","","C:\Users\esben\Zotero\storage\UHMQP6TS\9054379.html","","","generative model; learning (artificial intelligence); empathy; emotion recognition; Dialogue Systems; Empathetic Chatbots; generated utterance; human conversation difficult; Natural Language Processing; recent neural conversation models; reinforcement learning framework; sentiment look-ahead; Sentiment Look-ahead; speech processing; user emotional state","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","","","","","","","","","","","","","","",""
"8V3RT8SW","conferencePaper","2020","Dixit, R.; Chinnam, R. B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","2020 IEEE Aerospace Conference","","","10.1109/AERO47225.2020.9172612","","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.","2020-03","2021-02-11 03:37:19","2021-02-11 03:37:19","","1-8","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1095-323X","","C:\Users\esben\Zotero\storage\IB4HZZN2\9172612.html","","","artificial intelligence; learning (artificial intelligence); ML; AI; neural nets; human intelligence; ample data; ample time; answer-key; artificial Intelligence techniques; cross-disciplinary decision engine; current research streams; data-rich situations; decision algorithms; decision making; defined decision-basis; experienced practitioners; informed decisions; logical formulations; logical outcome; machine Learning; neural techniques; operational decision scenarios; real-time decision making; sparse-data environments; strategic decision scenarios; successful training; sufficient learning; tactical, decision scenarios; typical implementations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 IEEE Aerospace Conference","","","","","","","","","","","","","","",""
"A5X7X98D","conferencePaper","2019","Das, A. K.; Ashrafi, A.; Ahmmad, M.","Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","10.1109/CCOMS.2019.8821655","","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.","2019-02","2021-02-11 03:37:19","2021-02-11 03:37:19","","36-40","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\UZI6YCGQ\8821655.html","","","learning (artificial intelligence); Task analysis; Decision making; cognition; Law; Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment; advanced artificial intelligence system; criminal punishment prediction; Forecasting; judicial system; law administration; Machine intelligence; machine learning algorithms; Machine learning algorithms; Predictive models; Women and Children Repression Prevention Act 2000","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","","","","","","","","","","","","",""
"4YCJ8W38","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.","2019-12","2021-02-11 03:37:19","2021-02-11 03:37:19","","1564-1571","","","","","","Predicting Future Alleviation of Mental Illness in Social Media","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\Q2UZENB5\9047291.html","","","learning (artificial intelligence); Big Data; data mining; psychology; decision making; Cloud computing; Distributed processing; dynamic feature-rich networks; Electromagnetic interference; empathic interactions identification; empathy-based social network perspective; Erbium; future alleviation prediction; human psychological characteristics; hybrid deep learning algorithm; information sources; machine learning detectors; mental illness; Social computing; social media posts; social media, mental illness, social network, deep learning, online empathy.; social networking (online); therapeutic decision making; time dynamics; time-aware social networks; user behaviour; users posts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","","","","","","","","","","","","",""
"9KMJXA67","conferencePaper","2007","Rett, J.; Dias, J.","Human-robot interface with anticipatory characteristics based on Laban Movement Analysis and Bayesian models","2007 IEEE 10th International Conference on Rehabilitation Robotics","","","10.1109/ICORR.2007.4428436","","In this work we contribute to the field of human-machine interaction with a system that anticipates human movements using the concept of Laban Movement Analysis (LMA). The implementation uses a Bayesian model for learning and classification and results are presented for the application to online gesture recognition. The merging of assistive robotics and socially interactive robotics has recently led to the definition of socially assistive robotics. What is necessary and we found still missing are socially interactive robots with a higher level cognitive system which analyzes deeply the observed human movement. In this article we provide a framework for cognitive processes to be implemented in human-machine-interfaces based on nowadays technologies. We present LMA as a concept that helps to identify useful low-level features, defines a framework of mid-level descriptors for movement-properties and helps to develop a classifier of expressive actions. Our interface anticipates a performed action observed from a stream of monocular camera images by using a Bayesian framework. With this work we define the required qualities and characteristics of future embodied agents in terms of social interaction with humans. This article searches for human qualities like anticipation and empathy and presents possible ways towards implementation in the cognitive system of a social robot. We present results through its embodiment in the social robot 'Nicole' in the context of a person performing gestures and 'Nicole' reacting by means of audio output and robot movement.","2007-06","2021-02-11 03:37:19","2021-02-11 03:37:19","","257-268","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1945-7901","","C:\Users\esben\Zotero\storage\253W5PWM\4428436.html","","","medical robotics; Rehabilitation robotics; Robot sensing systems; gesture recognition; Shape; Human robot interaction; Mobile robots; Bayes methods; anticipatory characteristics; audio output; Bayesian methods; Bayesian models; Cameras; Cognitive robotics; Face detection; human-robot interface; Laban movement analysis; Merging; monocular camera images; robot movement; robot Nicole","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2007 IEEE 10th International Conference on Rehabilitation Robotics","","","","","","","","","","","","","","",""
"MHLE5UTL","conferencePaper","2015","Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.","Real-time sociometrics from audio-visual features for two-person dialogs","2015 IEEE International Conference on Digital Signal Processing (DSP)","","","10.1109/ICDSP.2015.7251991","","This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.","2015-07","2021-02-11 03:37:19","2021-02-11 03:37:19","","823-827","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2165-3577","","C:\Users\esben\Zotero\storage\Q24CF4Y2\7251991.html","","","feature extraction; learning (artificial intelligence); machine learning; Visualization; emotion recognition; Conferences; behavioural sciences; Speech; Feature extraction; Accuracy; audio-visual features; audio-visual recordings; audio-visual systems; audiovisual analysis; automatic inference; dialog; image recognition; machine learning algorithm; Microsoft kinect device; real time sociometrics; real-time; Real-time systems; Signal processing; social behavior analysis; social indicators; social sciences; sociometrics; speech cues; speech recognition; two person dialogs; visual cues","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE International Conference on Digital Signal Processing (DSP)","","","","","","","","","","","","","","",""
"3PT2A366","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective Intelligence: When, Where and Why","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","10.1109/Confluence47617.2020.9058000","","The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.","2020-01","2021-02-11 03:37:19","2021-02-11 03:37:19","","805-810","","","","","","Collective Intelligence","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\2X25LSI2\9058000.html","","","artificial intelligence; learning (artificial intelligence); machine learning; Collective Intelligence; Aggregates; Artificial Intellegence; collective intelligence; Collective intelligence; Organizations; Particle swarm optimization; smart organization; Social network services; software agents; Standards organizations; Swarm Intelligence; virtual artificially intelligent agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","","","","","","","","","","","","",""
"YUSKQ853","conferencePaper","2020","Filho, L. A. D. Lusquino; Oliveira, L. F. R.; Carneiro, H. C. C.; Guarisa, G. P.; Filho, A. L.; França, F. M. G.; Lima, P. M. V.","A weightless regression system for predicting multi-modal empathy","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","","","10.1109/FG47880.2020.00086","","This work takes into account the benefits of machine learning in order to estimate the valence of emotions on the OMG Empathy dataset, considering the information obtained from face expressions and dialogue of interlocutors. RegressionWiSARD and ClusRegressionWiSARD n-tuple regressors and its ensembles were employed to this end. The best performance achieved among all the combinations of weightless neural models considered (evaluated using the CCC metric) was 0.25 in validation set of the Personalized Track.","2020-11","2021-02-11 03:37:19","2021-02-11 03:37:19","","657-661","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\MYT8Z9TA\9320218.html","","","Computational modeling; Training; Predictive models; Videos; Bagging; empathy prediction; Mel frequency cepstral coefficient; Random access memory; regression wisard; weightless artificial neural network; wisard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","","","","","","","","","","","","","","",""
"BUUZC68R","conferencePaper","2019","Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","10.1109/RITAPP.2019.8932852","","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.","2019-11","2021-02-11 03:38:02","2021-02-11 03:38:02","","160-163","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\XLBJ99JY\8932852.html","","","cognitive science; learning (artificial intelligence); deep learning; emotion recognition; affective computing; psychology; behavioural sciences computing; emotional state; human computer interaction; face recognition; human emotion; computer science; emotionally aware chatbots; emotionally aware technology; facial expression detection; facial expression tracking; interdisciplinary field; OpenCV deep; posttherapy session survey chatbot; scripted chatbot; tracked facial expressions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","","","","","","","","","","","","",""
"VTDQURZT","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.","2019-12","2021-02-11 03:38:02","2021-02-11 03:38:02","","1564-1571","","","","","","Predicting Future Alleviation of Mental Illness in Social Media","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\KB6VH64S\9047291.html","","","learning (artificial intelligence); Big Data; data mining; psychology; decision making; Cloud computing; Distributed processing; dynamic feature-rich networks; Electromagnetic interference; empathic interactions identification; empathy-based social network perspective; Erbium; future alleviation prediction; human psychological characteristics; hybrid deep learning algorithm; information sources; machine learning detectors; mental illness; Social computing; social media posts; social media, mental illness, social network, deep learning, online empathy.; social networking (online); therapeutic decision making; time dynamics; time-aware social networks; user behaviour; users posts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","","","","","","","","","","","","",""
"J3REWPG2","conferencePaper","2018","Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.","Learning Empathy-Driven Emotion Expressions using Affective Modulations","2018 International Joint Conference on Neural Networks (IJCNN)","","","10.1109/IJCNN.2018.8489158","","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.","2018-07","2021-02-11 03:38:02","2021-02-11 03:38:02","","1-8","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2161-4407","","C:\Users\esben\Zotero\storage\H2PMJEZV\8489158.html","","","learning (artificial intelligence); Neurons; emotion recognition; human-robot interaction; social robots; Adaptation models; Emotion recognition; humanoid robots; Robot sensing systems; face recognition; Mood; affective modulations; Convolution; deep hybrid neural model; empathy-driven emotion expressions; facial expression representations; interaction design; internal affective model; internal emotions; intrinsic affective states; multimodal affect recognition; natural interaction experience; neuro-inspired companion robot; neurocontrollers; NICO robot; reinforcement learning model; self-organising feature maps; self-organising network models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 International Joint Conference on Neural Networks (IJCNN)","","","","","","","","","","","","","","",""
"3C3TY3KV","conferencePaper","2005","Broadway, F. S.; Qammar, H. K.; Evans, E. A.; Spickard-Prettyman, S.","The use of reflective journals for student learning and development","Proceedings Frontiers in Education 35th Annual Conference","","","10.1109/FIE.2005.1612042","","For three years, undergraduate freshman through senior participants were required to submit a reflective journal each week during a design project. In our first implementation, we found that reflective journals were meaningful as assessment tools because they communicated how the participants learned. We show in this three-year study how subsequent use of reflective journaling leads to intellectual development on the part of one student. The form of this paper is a first-person autobiographical narrative of a third year (junior) student through which different and multiple identities and knowledge unfold. The authors of the study create a narrator based on knowledge, experiences, concepts, and ideas that a chemical engineering student constructed, reconstructed, and deconstructed in his journal entries. Through these stories, the student showed a deep understanding of teamwork, developed empathy and a sense of belonging, and demonstrated the ability to explain, interpret and apply chemical engineering content knowledge","2005-10","2021-02-11 03:38:02","2021-02-11 03:38:02","","F2C-13","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2377-634X","","C:\Users\esben\Zotero\storage\P6G7DFXG\1612042.html","","","project management; Educational institutions; design; Teamwork; Calculus; team working; Testing; Assimilative learning; Autobiographical narrative; chemical engineering; Chemical engineering; chemical engineering student; content knowledge; content management; design project; educational aids; Engineering profession; first-person autobiographical narrative; intellectual development; knowledge management; Project management; Reflective journal; reflective journals; student development; student learning; teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings Frontiers in Education 35th Annual Conference","","","","","","","","","","","","","","",""
"VIBLHL73","journalArticle","2015","Runciman, B.","Bladerunner Begins","ITNOW","","1746-5710","10.1093/itnow/bwv086","","Without getting too tabloidy, Volume 27 Issue 4 of Interacting with Computers is looking at the emotion that played a key role in Philip K Dick’s Do Androids Dream of Electric Sheep - empathy. Brian Runciman MBCS reports.","2015-09","2021-02-11 03:39:00","2021-02-11 03:39:00","","65-65","","3","57","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: ITNOW","","C:\Users\esben\Zotero\storage\3EHI9B8L\8138959.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3M6UDCJ3","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","10.1109/ICAITI.2018.8686759","","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.","2018-09","2021-02-11 03:39:00","2021-02-11 03:39:00","","208-212","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\CNYN5SYA\8686759.html","","","handicapped aids; Mobile Robot; social interaction; psychology; mobile robots; Android; Android-based mobile robots; Asperger syndrome; Asperger Syndrome disorder; autistic disorder; data analysis; mobile computing; paediatrics; patient treatment; Pekanbaru children; play therapy; Rank Wilcoxon; robot control tool; smart phones; wheel-shaped robot; wheeled robot; wheels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","","","","","","","","","","","","",""
"UDJGURWP","conferencePaper","2016","Ranieri, C. M.; Romero, R. A. F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","10.1109/LARS-SBR.2016.13","","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.","2016-10","2021-02-11 03:39:00","2021-02-11 03:39:00","","31-36","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","C:\Users\esben\Zotero\storage\8XWF58QB\7783498.html","","","Emotions; Affective computing; empathy; human-robot interaction; social robots; Robots; Social robots; control engineering computing; smart phones; Android application; embodied virtual agent; emotion-aware interaction strategy; emotional reactions; facial expressions analysis; human-robot interaction improvement; Mobile devices; pleasantness; virtual character","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","","","","","","","","","","","","",""
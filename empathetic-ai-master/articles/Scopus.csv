"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"GCN6Y89T","journalArticle","2021","Cominelli, L.; Feri, F.; Garofalo, R.; Giannetti, C.; Meléndez-Jiménez, M.A.; Greco, A.; Nardelli, M.; Scilingo, E.P.; Kirchkamp, O.","Promises and trust in human–robot interaction","Scientific Reports","","20452322","10.1038/s41598-021-88622-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105440198&doi=10.1038%2fs41598-021-88622-9&partnerID=40&md5=8c892c097d8e210e475cacdab9bad379","Understanding human trust in machine partners has become imperative due to the widespread use of intelligent machines in a variety of applications and contexts. The aim of this paper is to investigate whether human-beings trust a social robot—i.e. a human-like robot that embodies emotional states, empathy, and non-verbal communication—differently than other types of agents. To do so, we adapt the well-known economic trust-game proposed by Charness and Dufwenberg (2006) to assess whether receiving a promise from a robot increases human-trust in it. We find that receiving a promise from the robot increases the trust of the human in it, but only for individuals who perceive the robot very similar to a human-being. Importantly, we observe a similar pattern in choices when we replace the humanoid counterpart with a real human but not when it is replaced by a computer-box. Additionally, we investigate participants’ psychophysiological reaction in terms of cardiovascular and electrodermal activity. Our results highlight an increased psychophysiological arousal when the game is played with the social robot compared to the computer-box. Taken all together, these results strongly support the development of technologies enhancing the humanity of robots. © 2021, The Author(s).","2021","2021-05-19 13:26:03","2021-05-19 13:26:03","","","","1","11","","","","","","","","","","English","","","","","","","Publisher: Nature Research","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUI32IRE","journalArticle","2021","Cambra-Badii, I.; Guardiola, E.; Baños, J.-E.","Frankenstein; or, the modern Prometheus: a classic novel to stimulate the analysis of complex contemporary issues in biomedical sciences","BMC Medical Ethics","","14726939","10.1186/s12910-021-00586-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101400240&doi=10.1186%2fs12910-021-00586-7&partnerID=40&md5=19817584595dd07a32d471c1efefce55","Background: Advances in biomedicine can substantially change human life. However, progress is not always followed by ethical reflection on its consequences or scientists’ responsibility for their creations. The humanities can help health sciences students learn to critically analyse these issues; in particular, literature can aid discussions about ethical principles in biomedical research. Mary Shelley’s Frankenstein; or, the modern Prometheus (1818) is an example of a classic novel presenting complex scenarios that could be used to stimulate discussion. Main text: Within the framework of the 200th anniversary of the novel, we searched PubMed to identify works that explore and discuss its value in teaching health sciences. Our search yielded 56 articles, but only two of these reported empirical findings. Our analysis of these articles identified three main approaches to using Frankenstein in teaching health sciences: discussing the relationship between literature and science, analysing ethical issues in biomedical research, and examining the importance of empathy and compassion in healthcare and research. After a critical discussion of the articles, we propose using Frankenstein as a teaching tool to prompt students to critically analyse ethical aspects of scientific and technological progress, the need for compassion and empathy in medical research, and scientists’ responsibility for their discoveries. Conclusion: Frankenstein can help students reflect on the personal and social limits of science, the connection between curiosity and scientific progress, and scientists’ responsibilities. Its potential usefulness in teaching derives from the interconnectedness of science, ethics, and compassion. Frankenstein can be a useful tool for analysing bioethical issues related to scientific and technological advances, such as artificial intelligence, genetic engineering, and cloning. Empirical studies measuring learning outcomes are necessary to confirm the usefulness of this approach. © 2021, The Author(s).","2021","2021-05-19 13:26:03","2021-05-19 13:26:03","","","","1","22","","","","","","","","","","English","","","","","","","Publisher: BioMed Central Ltd","<p>cited By 0</p>","","","artificial intelligence; learning; empathy; teaching; bioethics; responsibility; article; empiricism; genetic engineering; human; human experiment; medical research; Medline; systematic review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVU3JSC7","journalArticle","2021","Kiesow, H.; Spreng, R.N.; Holmes, A.J.; Chakravarty, M.M.; Marquand, A.F.; Yeo, B.T.T.; Bzdok, D.","Deep learning identifies partially overlapping subnetworks in the human social brain","Communications Biology","","23993642","10.1038/s42003-020-01559-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099382680&doi=10.1038%2fs42003-020-01559-z&partnerID=40&md5=6fa716c14a9bf81828cfd5652c23f05f","Complex social interplay is a defining property of the human species. In social neuroscience, many experiments have sought to first define and then locate ‘perspective taking’, ‘empathy’, and other psychological concepts to specific brain circuits. Seldom, bottom-up studies were conducted to first identify explanatory patterns of brain variation, which are then related to psychological concepts; perhaps due to a lack of large population datasets. In this spirit, we performed a systematic de-construction of social brain morphology into its elementary building blocks, involving 10,000 UK Biobank participants. We explored coherent representations of structural co-variation at population scale within a recent social brain atlas, by translating autoencoder neural networks from deep learning. The learned subnetworks revealed essential patterns of structural relationships between social brain regions, with the nucleus accumbens, medial prefrontal cortex, and temporoparietal junction embedded at the core. Some of the uncovered subnetworks contributed to predicting examined social traits in general, while other subnetworks helped predict specific facets of social functioning, such as the experience of social isolation. As a consequence of our population-level evidence, spatially overlapping subsystems of the social brain probably relate to interindividual differences in everyday social life. © 2021, The Author(s).","2021","2021-05-19 13:26:03","2021-05-19 13:26:03","","","","1","4","","","","","","","","","","English","","","","","","","Publisher: Nature Research","<p>cited By 0</p>","","","deep learning; language; social interaction; article; human; human experiment; adult; autoencoder; biobank; brain region; female; major clinical study; male; medial prefrontal cortex; nerve cell network; nucleus accumbens; social isolation; social life; temporoparietal junction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3WY5BTU","journalArticle","2021","Bulagang, A.F.; Mountstephens, J.; Teo, J.","Multiclass emotion prediction using heart rate and virtual reality stimuli","Journal of Big Data","","21961115","10.1186/s40537-020-00401-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098996733&doi=10.1186%2fs40537-020-00401-x&partnerID=40&md5=40364836f606d2bda836d890f230b353","Background: Emotion prediction is a method that recognizes the human emotion derived from the subject’s psychological data. The problem in question is the limited use of heart rate (HR) as the prediction feature through the use of common classifiers such as Support Vector Machine (SVM), K-Nearest Neighbor (KNN) and Random Forest (RF) in emotion prediction. This paper aims to investigate whether HR signals can be utilized to classify four-class emotions using the emotion model from Russell’s in a virtual reality (VR) environment using machine learning. Method: An experiment was conducted using the Empatica E4 wristband to acquire the participant’s HR, a VR headset as the display device for participants to view the 360° emotional videos, and the Empatica E4 real-time application was used during the experiment to extract and process the participant's recorded heart rate. Findings: For intra-subject classification, all three classifiers SVM, KNN, and RF achieved 100% as the highest accuracy while inter-subject classification achieved 46.7% for SVM, 42.9% for KNN and 43.3% for RF. Conclusion: The results demonstrate the potential of SVM, KNN and RF classifiers to classify HR as a feature to be used in emotion prediction in four distinct emotion classes in a virtual reality environment. The potential applications include interactive gaming, affective entertainment, and VR health rehabilitation. © 2021, The Author(s).","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","1","8","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBUI9AVY","journalArticle","2021","Wang, P.; Bai, X.; Billinghurst, M.; Zhang, S.; Zhang, X.; Wang, S.; He, W.; Yan, Y.; Ji, H.","AR/MR Remote Collaboration on Physical Tasks: A Review","Robotics and Computer-Integrated Manufacturing","","07365845","10.1016/j.rcim.2020.102071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105298901&doi=10.1016%2fj.rcim.2020.102071&partnerID=40&md5=282a12f04e71fd82b3d91dc627de280a","This paper provides a review of research into using Augmented Reality (AR) and Mixed Reality(MR) for remote collaboration on physical tasks. AR/MR-based remote collaboration on physical tasks has recently become more prominent in academic research and engineering applications. It has great potential in many fields, such as real-time remote medical consultation, education, training, maintenance, remote assistance in engineering, and other remote collaborative tasks. However, to the best of our knowledge there has not been any comprehensive review of research in AR/MR remote collaboration on physical tasks. Therefore, this paper presents a comprehensive survey of research between 2000 and 2018 in this domain. We collected 215 papers, more than 80% of which were published between 2010 and 2018, and all relevant works are discussed at length. Then we elaborate on the review from typical architectures, applications (e.g., industry, telemedicine, architecture, teleducation and others), and empathic computing. Next, we made an in-depth review of the papers from seven aspects: (1) collection and classification research, (2) using 3D scene reconstruction environments and live panorama, (3) periodicals and conducting research, (4) local and remote user interfaces, (5) features of user interfaces commonly used, (6) architecture and sharing non-verbal cues, (7) applications and toolkits. We find that most papers (160 articles, 74.4%) are published in conferences, using co-located collaboration to emulate remote collaboration is adopted by more than half (126, 58.6%) of the reviewed papers, the shared non-verbal cues can be mainly classified into five types (Virtual Replicas or Physical Proxy(VRP), AR Annotations or a Cursor Pointer(ARACP), avatar, gesture, and gaze), the local/remote interface is mainly divided into four categories (Head-Mounted Displays(HMD), Spatial Augmented Reality(SAR), Windows-Icon-Menu-Pointer(WIMP) and Hand-Held Displays(HHD)). From this, we can draw ten conclusions. Following this we report on issues for future works. The paper also provides an overall academic roadmap and useful insight into the state-of-the-art of AR/MR remote collaboration on physical tasks. This work will be useful for current and future researchers who are interested in collaborative AR/MR systems. © 2021 Elsevier Ltd","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","","72","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 0</p>","","","Mixed reality; Augmented reality; Agricultural robots; Collaborative tasks; User interfaces; Remote collaboration; 3D scene reconstruction; Architecture; Co-located collaboration; Engineering applications; Head mounted displays; Helmet mounted displays; Remote user interfaces; Spatial augmented realities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IVM54A9","journalArticle","2021","Jang, S.; Kim, J.-J.; Kim, S.-J.; Hong, J.; Kim, S.; Kim, E.","Mobile app-based chatbot to deliver cognitive behavioral therapy and psychoeducation for adults with attention deficit: A development and feasibility/usability study","International Journal of Medical Informatics","","13865056","10.1016/j.ijmedinf.2021.104440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103373094&doi=10.1016%2fj.ijmedinf.2021.104440&partnerID=40&md5=95237e5772b5c33dbb30b650a904a03d","Background: Attention deficit is a growing problem in adults, and early diagnosis and treatment are needed. Previous studies have shown that cognitive behavioral therapy (CBT) is effective in improving attention deficit symptoms. However, many patients are not receiving adequate treatment due to time, space, and cost constraints. Recently, in other mental illnesses, mobile-based chatbots delivering CBT and psychoeducation have been used for symptom mitigation and treatment. Objective: This study aimed to investigate the feasibility and usability of a short-term intervention, specifically a mobile-based interactive chatbot application, in alleviating attention deficit symptoms. Methods: This was a randomized, non-blind parallel-group pilot study conducted from September 2019 to March 2020. Forty-six individuals with attention deficit aged 19–60 were randomly allocated to the chatbot (n = 23) and information-only control groups (n = 23) for 4 weeks. The former group was instructed to use the chatbot application “Todaki,” while the latter group was provided with a book on managing attention deficit symptoms. Participants were administered questionnaires to assess their symptoms of attention deficit, depression, and anxiety and evaluated at baseline and 4 weeks after the intervention. The post-intervention survey assessed the chatbot's usability, acceptability, and side effects. Results: The average age of the participants was 25.1 years (standard deviation [SD] 7.5 years), and 56.5 % (26/46) participants were female. Intention-to-treat analysis (chatbot, n = 23; control, n = 23) revealed a significant reduction of attention deficit symptoms only in the chatbot group, which is represented by group-by-time interaction in Conner's Adult ADHD Rating Scale subscales of Diagnostic and Statistical Manual-IV Attention-Deficit/Hyperactivity Disorder (ADHD) Hyperactive-Impulsive symptoms (F = 4.39; p =.04) and ADHD symptoms total (F = 6.74, p =.01). Further, the results of the paired t-test were significant only in the chatbot group. The average number of times the chatbots were used in 4 weeks was 20.32 (SD 12.89). The total average usage time was 1 h 15 min (SD 1 h 20 min). The degree of improvement in the ADHD symptoms total score was correlated with the number of times the psychoeducation program was used. According to the participants, the empathic/friendly character and unnatural flow of conversation were the best and worst features of the chatbot, respectively. Conclusions: This study identified the feasibility and usability of using the mobile-based chatbot to improve attention deficit and its associated psychiatric symptoms. Using this novel intervention to conduct CBT would provide a useful digital therapeutic tool that allows easy accessibility and self-guided management for people with attention deficit, which should be verified through the large scale randomized controlled trial. © 2021 Elsevier B.V.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","","150","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ireland Ltd","<p>cited By 0</p>","","","Surveys; Attention deficit; Diseases; Diagnosis; Patient treatment; Average numbers; Cognitive-behavioral therapies; Cost constraints; Post interventions; Randomized controlled trial; Standard deviation; Therapeutic tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAVBSNNW","journalArticle","2021","Küster, D.; Swiderska, A.","Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes","International Journal of Psychology","","00207594","10.1002/ijop.12715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090926311&doi=10.1002%2fijop.12715&partnerID=40&md5=93cd342d1b06662a239ccc999e6dde9d","According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation. © 2020 The Authors. International Journal of Psychology published by John Wiley & Sons Ltd on behalf of International Union of Psychological Science.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","454-465","","3","56","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Ltd","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XI5PLXF6","journalArticle","2021","Pozharliev, R.; De Angelis, M.; Rossi, D.; Romani, S.; Verbeke, W.; Cherubino, P.","Attachment styles moderate customer responses to frontline service robots: Evidence from affective, attitudinal, and behavioral measures","Psychology and Marketing","","07426046","10.1002/mar.21475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102376850&doi=10.1002%2fmar.21475&partnerID=40&md5=580e99d22b71187f8d39c58e61bf0f5b","Despite the growing application of interactive technologies like service robots in customer service, there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees. Moreover, it is unclear whether all customers respond to the interaction with frontline service robots in the same way. Our research looks at how individual differences in social behaviors, specifically in customers' attachment styles, influence three types of customer responses: affective responses (experienced pleasantness), attitudinal responses (perceived empathy, satisfaction), and behavioral responses (word-of-mouth). Three experimental studies reveal that customers with low (vs. high) scores on anxious attachment style (AAS) measures respond more negatively to frontline service robot (compared to a frontline human agent). We investigate alternative explanations for these findings, such as robots' level of anthropomorphism and we show that human-likeness features such as voice type and level of human-like physical appearance, cannot explain our findings. Our results indicate that for low-AAS customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots, leading to possible implications on customer segmentation, targeting, and marketing communication. © 2021 Wiley Periodicals LLC","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","881-895","","5","38","","","","","","","","","","English","","","","","","","Publisher: John Wiley and Sons Inc","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3WLR8QS","journalArticle","2021","Aqajari, S.A.H.; Cao, R.; Naeini, E.K.; Calderon, M.-D.; Zheng, K.; Dutt, N.; Liljeberg, P.; Salanterä, S.; Nelson, A.M.; Rahmani, A.M.","Pain assessment tool with electrodermal activity for postoperative patients: Method validation study","JMIR mHealth and uHealth","","22915222","10.2196/25258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105522128&doi=10.2196%2f25258&partnerID=40&md5=ad861611992a06028530ec1999e1898d","Background: Accurate, objective pain assessment is required in the health care domain and clinical settings for appropriate pain management. Automated, objective pain detection from physiological data in patients provides valuable information to hospital staff and caregivers to better manage pain, particularly for patients who are unable to self-report. Galvanic skin response (GSR) is one of the physiologic signals that refers to the changes in sweat gland activity, which can identify features of emotional states and anxiety induced by varying pain levels. This study used different statistical features extracted from GSR data collected from postoperative patients to detect their pain intensity. To the best of our knowledge, this is the first work building pain models using postoperative adult patients instead of healthy subjects. Objective: The goal of this study was to present an automatic pain assessment tool using GSR signals to predict different pain intensities in noncommunicative, postoperative patients. Methods: The study was designed to collect biomedical data from postoperative patients reporting moderate to high pain levels. We recruited 25 participants aged 23-89 years. First, a transcutaneous electrical nerve stimulation (TENS) unit was employed to obtain patients' baseline data. In the second part, the Empatica E4 wristband was worn by patients while they were performing low-intensity activities. Patient self-report based on the numeric rating scale (NRS) was used to record pain intensities that were correlated with objectively measured data. The labels were down-sampled from 11 pain levels to 5 different pain intensities, including the baseline. We used 2 different machine learning algorithms to construct the models. The mean decrease impurity method was used to find the top important features for pain prediction and improve the accuracy. We compared our results with a previously published research study to estimate the true performance of our models. Results: Four different binary classification models were constructed using each machine learning algorithm to classify the baseline and other pain intensities (Baseline [BL] vs Pain Level [PL] 1, BL vs PL2, BL vs PL3, and BL vs PL4). Our models achieved higher accuracy for the first 3 pain models than the BioVid paper approach despite the challenges in analyzing real patient data. For BL vs PL1, BL vs PL2, and BL vs PL4, the highest prediction accuracies were achieved when using a random forest classifier (86.0, 70.0, and 61.5, respectively). For BL vs PL3, we achieved an accuracy of 72.1 using a k-nearest-neighbor classifier. Conclusions: We are the first to propose and validate a pain assessment tool to predict different pain levels in real postoperative adult patients using GSR signals. We also exploited feature selection algorithms to find the top important features related to different pain intensities. © 2021 JMIR Publications. All rights reserved.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","5","9","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T67K7F6I","conferencePaper","2021","Li, Y.; Deng, K.","Application of Virtual Reality Technology in the Health Field Based on the Background of Big Data","Journal of Physics: Conference Series","","","10.1088/1742-6596/1883/1/012175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105486110&doi=10.1088%2f1742-6596%2f1883%2f1%2f012175&partnerID=40&md5=16999b6e4cf7389f753542cf8b211306","With the development of big data and artificial intelligence, virtual reality technology has penetrated into every aspect of daily life. Among them, the application of virtual reality technology in the health field is of great significance. Virtual reality technology can assist clinical medicine in the treatment of patients, and can also simulate the physical feelings of panic disorder and some disabilities to induce emotions similar to patients, produce empathy effects, enhance normal people's understanding of patients, or improve health The effect of dissemination. This article discusses the current status of the application of virtual reality technology in the context of big data, and analyzes how virtual reality technology can promote health communication, disperse pain, treatment of psychological disorders, and begin to provide services for the elderly, which has great social and practical significance. This article reviews and compares the recent applications of virtual reality technology in the health field at home and abroad, and analyzes its prospects and shortcomings. © Published under licence by IOP Publishing Ltd.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","","1883","","","","","","","","IOP Publishing Ltd","","English","","","","","","","ISSN: 17426588 Issue: 1","<p>cited By 0; Conference of 2021 2nd International Conference on Computer Information and Big Data Applications, CIBDA 2021 ; Conference Date: 26 March 2021 Through 28 March 2021; Conference Code:168715</p>","","","Virtual reality; Artificial intelligence; Big data; Virtual reality technology; Patient treatment; Clinical medicine; Current status; Daily lives; Health communication; Medicine; Psychological disorders","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGFHUL8F","conferencePaper","2021","Svikhnushina, E.; Pu, P.","Key Qualities of Conversational Chatbots-the PEACE Model","International Conference on Intelligent User Interfaces, Proceedings IUI","978-1-4503-8017-1","","10.1145/3397481.3450643","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104565760&doi=10.1145%2f3397481.3450643&partnerID=40&md5=710a3b9e50777c95a2640a756745a35d","Open-domain chatbots engage in natural conversations with the user to socialize and establish bonds. However, designing and developing an effective open-domain chatbot is challenging. It is unclear what qualities of such chatbots most correspond to users' expectations. Even though existing work has considered a wide range of aspects, some key components are still missing. More importantly, the consistency and validity of the combined criteria have not been tested. In this paper, we describe a large-scale survey using a consolidated model to elicit users' preferences, expectations, and concerns. We apply structural equation modeling methods to further validate the data collected from the user survey. The outcome supports the consistency, validity, and reliability of the model, which we call PEACE (Politeness, Entertainment, Attentive Curiosity, and Empathy). PEACE, therefore, defines the key determinants most predictive of user acceptance. This has allowed us to develop a set of implications useful for the development of compelling open-domain chatbots. © 2021 ACM.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","520-530","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 26th International Conference on Intelligent User Interfaces: Where HCI Meets AI, IUI 2021 ; Conference Date: 14 April 2021 Through 17 April 2021; Conference Code:168377</p>","","","Surveys; Chatbots; User interfaces; Key determinants; Key qualities; Large scale surveys; Still missing; Structural equation modeling method; User acceptance; User surveys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YYKLQUL3","journalArticle","2021","Salmeron, J.L.; Ruiz-Celma, 0000-0002-8358-419X, A.","Synthetic emotions for empathic building","Mathematics","","22277390","10.3390/math9070701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103342133&doi=10.3390%2fmath9070701&partnerID=40&md5=a377e49d683f026b2810afd68f98ec74","Empathic buildings are intelligent ones that aim to measure and execute the best user experience. A smoother and intuitive environment leads to a better mood. The system gathers data from sensors that measure things like air quality, occupancy, noise and analyse it for the better experience of the users. This research proposes an artificial intelligence-based approach to detect synthetic emotions based on Thayer’s emotional model and Fuzzy Cognitive Maps. This emotional model is based on a biopsychological approach to the analysis of the humans’ emotional state. In this research, Fuzzy Grey Cognitive Maps are used, which are an extension of the fuzzy cognitive maps using the grey systems theory to model uncertainty. Fuzzy Cognitive Grey Maps (FGCMs) have become a very valuable theory for modeling high-uncertainty systems when small and incomplete discrete data sets are available. This research includes experiments with a couple of synthetic case studies for testing this proposal. This proposal provides an innovative way for simulating synthetic emotions and designing an empathic building. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","2021","2021-05-19 13:26:04","2021-05-19 13:26:04","","","","7","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRZVYII2","journalArticle","2021","Zhang, Z.; Citardi, D.; Wang, D.; Genc, Y.; Shan, J.; Fan, X.","Patients' perceptions of using artificial intelligence (AI)-based technology to comprehend radiology imaging data","Health informatics journal","","17412811","10.1177/14604582211011215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105112796&doi=10.1177%2f14604582211011215&partnerID=40&md5=cd29d398761b74523c69f4ce17df566d","Results of radiology imaging studies are not typically comprehensible to patients. With the advances in artificial intelligence (AI) technology in recent years, it is expected that AI technology can aid patients' understanding of radiology imaging data. The aim of this study is to understand patients' perceptions and acceptance of using AI technology to interpret their radiology reports. We conducted semi-structured interviews with 13 participants to elicit reflections pertaining to the use of AI technology in radiology report interpretation. A thematic analysis approach was employed to analyze the interview data. Participants have a generally positive attitude toward using AI-based systems to comprehend their radiology reports. AI is perceived to be particularly useful in seeking actionable information, confirming the doctor's opinions, and preparing for the consultation. However, we also found various concerns related to the use of AI in this context, such as cyber-security, accuracy, and lack of empathy. Our results highlight the necessity of providing AI explanations to promote people's trust and acceptance of AI. Designers of patient-centered AI systems should employ user-centered design approaches to address patients' concerns. Such systems should also be designed to promote trust and deliver concerning health results in an empathetic manner to optimize the user experience.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","14604582211011215","","2","27","","","","","","","","","","English","","","","","","","Publisher: NLM (Medline)","<p>cited By 0</p>","","","perception; artificial intelligence; empathy; trust; consumer; article; human; adult; female; male; consultation; thematic analysis; clinical article; attitude; AIDS patient; computer security; medical record; radiology; semi structured interview; user-centered design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZYDAKNZ","journalArticle","2021","Cuzzocrea, A.; Pilato, G.","A composite framework for supporting user emotion detection based on intelligent taxonomy handling","Logic Journal of the IGPL","","13670751","10.1093/jigpal/jzaa047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104992788&doi=10.1093%2fjigpal%2fjzaa047&partnerID=40&md5=d8fdabadee43a66a688e7a37acf6f40e","One of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her. The first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper. The system can analyze the Twitter ID of the new acquaintance, trying to detect the IAB (Interactive Advertising Bureau) Tier 1 categories that possibly can let arise in him/her a joyful feeling. Furthermore, it can retrieve news about that category and report them to the user, hopefully increasing his/her curiosity towards the system, improving the naturalness of the interaction. Moreover, the system is capable of querying Wikipedia in order to clarify any doubts that may arise in the user. A sample of a possible interaction is reported at the end of the paper. © 2021 The Author(s).","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","207-219","","2","29","","","","","","","","","","English","","","","","","","Publisher: Oxford University Press","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JNGP9TAJ","journalArticle","2021","Dorn, A.W.; Dawson, P.F.","Simulating Peace Operations: New Digital Possibilities for Training and Public Education","Simulation and Gaming","","10468781","10.1177/1046878120968605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095452183&doi=10.1177%2f1046878120968605&partnerID=40&md5=fa1122832b21ccc429123ceace2be44d","Background and Motivation.: A plethora of warfighting games exist commercially, but there is a lack of digital games that deal with peace processes. Furthermore, none simulate actual peacekeeping. The United Nations currently deploys about 100,000 peacekeepers to some of the world’s most dangerous zones, where peacekeepers save lives, alleviate suffering, and help create conditions for peace. The United Nations and national militaries lack peacekeeping simulations to help train their soldiers. Additionally, the public needs to learn more about the way peacekeeping works. Thus, peacekeeping simulation and gaming are worth exploring, especially in the rapidly evolving digital space, which offers new avenues and benefits. Methods.: We review the meager literature on the subject and observe that there are few digital games to directly draw from. We build on previous work that argued the need for such development, but we now assess important design principles and parameters. We draw upon peacekeeping tabletop exercises that are already well developed. Results.: We conclude that excellent scenarios and simulation technologies exist that could be combined quite easily for effective peacekeeping training and public education. We find key materials and scenarios in exercises of the United Nations and of the Pearson Peacekeeping Centre. Highlighted areas for future digital design are the inclusion of non-military avatars, emphasis on soft skills development (especially empathy), and realistically complex links between actions and consequences. Conclusion.: While describing some UN exploration at a proof-of-concept stage, we suggest that both the United Nations and the gaming industry should explore the idea further to achieve synergies between institutional and entertainment applications. The growing capacity of digital technology allows significant innovation, yielding results that could be useful, ethical, enjoyable, and potentially profitable. © 2020 SAGE Publications.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","226-242","","2","52","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCIHKARU","journalArticle","2021","Wilson, J.C.; Nair, S.; Scielzo, S.; Larson, E.C.","Objective Measures of Cognitive Load Using Deep Multi-Modal Learning","Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies","","24749567","10.1145/3448111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103662941&doi=10.1145%2f3448111&partnerID=40&md5=9f5d9f8258847190318aaebf259d9538","The capability of measuring human performance objectively is hard to overstate, especially in the context of the instructor and student relationship within the process of learning. In this work, we investigate the automated classification of cognitive load leveraging the aviation domain as a surrogate for complex task workload induction. We use a mixed virtual and physical flight environment, given a suite of biometric sensors utilizing the HTC Vive Pro Eye and the E4 Empatica. We create and evaluate multiple models. And we have taken advantage of advancements in deep learning such as generative learning, multi-modal learning, multi-task learning, and x-vector architectures to classify multiple tasks across 40 subjects inclusive of three subject types-pilots, operators, and novices. Our cognitive load model can automate the evaluation of cognitive load agnostic to subject, subject type, and flight maneuver (task) with an accuracy of over 80%. Further, this approach is validated with real-flight data from five test pilots collected over two test and evaluation flights on a C-17 aircraft. © 2021 ACM.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","","","1","5","","","","","","","","","","English","","","","","","","Publisher: Association for Computing Machinery","<p>cited By 0</p>","","","Human performance; Deep learning; Automated classification; Biometric sensors; Flight environment; Multi-modal learning; Multi-task learning; Process of learning; Test and evaluation; Vector architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INU8C4G2","conferencePaper","2021","Urakami, J.; Sutthithatip, S.","Building a collaborative relationship between human and robot through verbal and non-verbal interaction","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8290-8","","10.1145/3434074.3447171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102771962&doi=10.1145%2f3434074.3447171&partnerID=40&md5=fecbf983f69e99c7fb201e98b4f4d83e","Interpersonal communication and relationship building promote successful collaborations. This study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partner. Participants interacted with two robots that differed in their nonverbal and verbal expressiveness. The interactive robot actively engaged the participant in a conversation before, during and after a collaborative task whereas the non-interactive robot remained passive. The robots' nonverbal and verbal interactions increased participants' perception of the robot as a social actor and strengthened bonding and relationship building between human and robot. The results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact, the robot is attributed a certain personality, and the robot is perceived as being alive. Our study could not show that an interactive robot receives more help by the collaboration partner. Future research should investigate additional factors that facilitate helpful behavior among humans, such as similarity, attributional judgement and empathy. © 2021 ACM.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","257-261","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 2021 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2021 ; Conference Date: 8 March 2021 Through 11 March 2021; Conference Code:167645</p>","","","Social robots; Agricultural robots; Collaboration partner; Collaborative relationships; Collaborative tasks; Inter-personal communications; Interactive robot; Man machine systems; Relationship building; Robot learning; Social actors; Verbal interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXSF9ZVE","conferencePaper","2021","Chirapornchai, C.; Bremner, P.; Daly, J.E.","Helper's high with a robot pet","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8290-8","","10.1145/3434074.3447165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102737723&doi=10.1145%2f3434074.3447165&partnerID=40&md5=c942af818e402ab356da6eb5f8cb4f0c","Helper's high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement. This study investigates if a robot pet can, like a real pet, induce helpers high in people interacting with it. A Vector robot was programmed to express the need for daily exercise and attention, and participants were instructed how to help the robot meet those needs. Our within subjects design had two conditions: with and without emotional behaviour modifiers to the robot's behaviour. Our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants, which would create a stronger helper's high effect than purely functional need expression behaviours. We present a long-term (4 day) remote study design that not only facilitates the kind of interactions needed for helper's high, but abides by government guidelines on Covid-19 safety (under which a laboratory study is not possible). Preliminary results suggest that Vector was able to improve the mood of some participants, and mood changes tend to be greater when Vector expressed behaviours with emotional components. Our post-study interview data suggests that individual differences in living environment and mood impacting external factors, affected Vector's efficacy in mood influencing. © 2021 ACM.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","229-233","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 2021 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2021 ; Conference Date: 8 March 2021 Through 11 March 2021; Conference Code:167645</p>","","","Human robot interaction; Agricultural robots; Man machine systems; External factors; Individual Differences; Laboratory studies; Living environment; Machine design; Purely functional; Research questions; Study design; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"376T8T8W","conferencePaper","2021","Burns, R.B.; Seifi, H.; Lee, H.; Kuchenbecker, K.J.","A haptic empathetic robot animal for children with autism","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8290-8","","10.1145/3434074.3446352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102758346&doi=10.1145%2f3434074.3446352&partnerID=40&md5=1f83557d0708ea962c1cbd0d5a94b468","Children with autism and their families could greatly benefit from increased support resources. While robots are already being introduced into autism therapy and care, we propose that these robots could better understand the child's needs and provide enriched interaction if they utilize touch. We present our plans, both completed and ongoing, for a touch-perceiving robot companion for children with autism. We established and validated touch-perception requirements for an ideal robot companion through interviews with 11 autism specialists. Currently, we are evaluating custom fabric-based tactile sensors that enable the robot to detect and identify various touch communication gestures. Finally, our robot companion will react to the child's touches through an emotion response system that will be customizable by a therapist or caretaker. © 2021 Owner/Author.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","583-585","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 2021 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2021 ; Conference Date: 8 March 2021 Through 11 March 2021; Conference Code:167645</p>","","","Social robots; Agricultural robots; Man machine systems; Diseases; Robot companion; Children with autisms; Autism therapies; Customizable; Response systems; Tactile sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4Q43RN3","journalArticle","2021","Yoo, S.; Jeong, O.","EP-Bot: Empathetic Chatbot Using Auto-Growing Knowledge Graph","Computers, Materials and Continua","","15462218","10.32604/cmc.2021.015634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102464397&doi=10.32604%2fcmc.2021.015634&partnerID=40&md5=8a357df1b8364b38802847ffe7ae14a9","People occasionally interact with each other through conversation. In particular, we communicate through dialogue and exchange emotions and information from it. Emotions are essential characteristics of natural language. Conversational artificial intelligence is an integral part of all the technologies that allow computers to communicate like humans. For a computer to interact like a human being, it must understand the emotions inherent in the conversation and generate the appropriate responses. However, existing dialogue systems focus only on improving the quality of understanding natural language or generating natural language, excluding emotions. We propose a chatbot based on emotion, which is an essential element in conversation. EP-Bot (an Empathetic PolarisX-based chatbot) is an empathetic chatbot that can better understand a person’s utterance by utilizing PolarisX, an auto-growing knowledge graph. PolarisX extracts new relationship information and expands the knowledge graph automatically. It is helpful for computers to understand a person’s common sense. The proposed EP-Bot extracts knowledge graph embedding using PolarisX and detects emotion and dialog act from the utterance. Then it generates the next utterance using the embeddings. EP-Bot could understand and create a conversation, including the person’s common sense, emotion, and intention. We verify the novelty and accuracy of EP-Bot through the experiments. © 2021 Tech Science Press. All rights reserved.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","2807-2817","","3","67","","","","","","","","","","English","","","","","","","Publisher: Tech Science Press","<p>cited By 0</p>","","","Natural languages; Data mining; Human being; Essential elements; Speech processing; Dialogue systems; Common sense; Embeddings; Essential characteristic; Integral part; Knowledge graphs; Knowledge representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5IJTMVK","journalArticle","2021","Gelbrich, K.; Hagel, J.; Orsingher, C.","Emotional support from a digital assistant in technology-mediated services: Effects on customer satisfaction and behavioral persistence","International Journal of Research in Marketing","","01678116","10.1016/j.ijresmar.2020.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087007055&doi=10.1016%2fj.ijresmar.2020.06.004&partnerID=40&md5=5e8d054d7a0372176cb562392598b88c","In their traditional role, digital assistants in technology-mediated services provide customers with information, guidance, and suggestions. However, as the opportunities offered by technology and artificial intelligence increase, digital assistants can also provide emotional support, which refers to empathetic, reassuring expressions for customers who have failed or succeeded in fulfilling a task. We show across four experiments that emotional support offered by a digital assistant increases customer satisfaction (Study 1 and 2) and persistence (Study 3 and 4) in using technology-mediated services. The increase in satisfaction occurs via the perceived warmth of the digital assistant, and the increase in persistence via the serial mediation of perceived warmth and satisfaction. Further, the results of a moderated serial mediation show that the effect on persistence only occurs when a digital (but not when a human) assistant provides emotional support in technology-mediated services. Finally, the effect of emotional support on persistence occurs independently of the digital assistant's embodiment. Practitioners learn how to imbue technology-mediated services with a human touch, inducing favorable customer outcomes. © 2020 Elsevier B.V.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","176-193","","1","38","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5IHLBW8","journalArticle","2021","Kim, T.-H.; Vanloo, J.; Kim, W.S.","3D Origami Sensing Robots for Cooperative Healthcare Monitoring","Advanced Materials Technologies","","2365709X","10.1002/admt.202000938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099904146&doi=10.1002%2fadmt.202000938&partnerID=40&md5=2f414d05875b5ae013cc5505c4bc6f0d","In this study, cooperative healthcare sensing robots that closely monitor and evaluate the patients’ muscle functions through gait analysis and electromyography (EMG) are developed. By integrating the biological sensors, the sensing robot can recognize the vital signs. The sensing robots are developed by the design and optimization of their architectures and materials using a green strategy. To achieve mechanically durable robot designs, 3D origami structures are used with specific optimum criteria. Different sensing robot applications are created through the 3D origami insole and humanoid hands for healthcare monitoring. The smart insole built with 3D origami monitors the foot pressure distribution for gait analysis of patients, and the humanoid hand equipped with the 3D origami-structured EMG fingers cooperatively detects EMG signals. Such cooperative sensing robots hold considerable promise for healthcare monitoring with convenience for patients with quality of care, because the robots can derive empathetic adaptability with humans. © 2021 Wiley-VCH GmbH","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","","","3","6","","","","","","","","","","English","","","","","","","Publisher: John Wiley and Sons Inc","<p>cited By 0</p>","","","Robots; Health care; Machine design; 3d origami structures; Biological sensors; Cooperative sensing; Design and optimization; Gait analysis; Healthcare monitoring; Muscle function; Optimum criteria; Quality of care; Robot applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXY9928J","journalArticle","2021","Andreotta, A.J.","The hard problem of AI rights","AI and Society","","09515666","10.1007/s00146-020-00997-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085877284&doi=10.1007%2fs00146-020-00997-x&partnerID=40&md5=bd9018524171b9ac98aa2157ae1ac084","In the past few years, the subject of AI rights—the thesis that AIs, robots, and other artefacts (hereafter, simply ‘AIs’) ought to be included in the sphere of moral concern—has started to receive serious attention from scholars. In this paper, I argue that the AI rights research program is beset by an epistemic problem that threatens to impede its progress—namely, a lack of a solution to the ‘Hard Problem’ of consciousness: the problem of explaining why certain brain states give rise to experience. To motivate this claim, I consider three ways in which to ground AI rights—namely: superintelligence, empathy, and a capacity for consciousness. I argue that appeals to superintelligence and empathy are problematic, and that consciousness should be our central focus, as in the case of animal rights. However, I also argue that AI rights is disanalogous from animal rights in an important respect: animal rights can proceed without a solution to the ‘Hard Problem’ of consciousness. Not so with AI rights, I argue. There we cannot make the same kinds of assumptions that we do about animal consciousness, since we still do not understand why brain states give rise to conscious mental states in humans. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","19-32","","1","36","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0</p>","","","Animals; Animal rights; Brain state; Hard problems; Mental state; Moral concerns; Research programs; Superintelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9L32XXR","journalArticle","2021","Riddoch, K.A.; Cross, E.S.","“Hit the Robot on the Head With This Mallet” – Making a Case for Including More Open Questions in HRI Research","Frontiers in Robotics and AI","","22969144","10.3389/frobt.2021.603510","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102476565&doi=10.3389%2ffrobt.2021.603510&partnerID=40&md5=f5a5c2b9d0bd196319223ba0af859cd1","Researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents, as opposed to objects. One such approach involves asking participants to inflict ‘harm’ on a robot. Researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying, and propose that relatively long periods of hesitation might reflect empathy for the robot, and perhaps even attribution of human-like qualities, such as agency and sentience. In a recent experiment, we adapted the so-called ‘hesitance to hit’ paradigm, in which participants were instructed to hit a humanoid robot on the head with a mallet. After standing up to do so (signaling intent to hit the robot), participants were stopped, and then took part in a semi-structured interview to probe their thoughts and feelings during the period of hesitation. Thematic analysis of the responses indicate that hesitation not only reflects perceived socialness, but also other factors including (but not limited to) concerns about cost, mallet disbelief, processing of the task instruction, and the influence of authority. The open-ended, free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism, perceived power imbalances, and feelings of connection toward the robot. In addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots, we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics. © Copyright © 2021 Riddoch and Cross.","2021","2021-05-19 13:26:05","2021-05-19 13:26:05","","","","","8","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHHE3P4C","conferencePaper","2021","Sowmya Dhanalakshmi, C.; Madhu, P.; Hemachandran, N.; Muthukumar, V.E.; Harish Arvinth, L.B.","Design and Fabrication of Robotic Arm for the assembly of Phase Selector Switch","IOP Conference Series: Materials Science and Engineering","","","10.1088/1757-899X/1059/1/012032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101579756&doi=10.1088%2f1757-899X%2f1059%2f1%2f012032&partnerID=40&md5=f19c5aea9287fc4898ef3b317ddb2496","This paper explores the robot arm where the ability of human to do a project is restrained however now not with the aid of his mental electricity however through his bodily energy. A humanoid mechanical technology is another difficult field. To co-work with people, humanoid robots not just need to include human like structure and structure, yet more significantly, they should arrange human like conduct with respect to the movement, correspondence and intelligence. In environmental factors where human exchange can't be conceivable to do a specific errand, the robots can do. Robots are used for lean industrial processes and have diversified their contributions to meeting lines inside the production international. The main focus of this project is to design and develop the mechanism for robotic arm for lifting. It is a type of mechanical arm, usually programmable, with similar functions to a human arm. The arm might be a unit system or might be an aspect of a more unpredictable mechanical cycle. The end effectors or mechanical hand can be intended to play out any ideal undertaking, for example, welding, holding, turning etc., depending on the application. The mechanical arm is planned and designed with four degrees of freedom and modified to achieve precisely basic light material lifting undertaking to aid the creation line in any industry. 3D printing strategy is utilized in this undertaking to create the parts of the automated arm. Hence, it gave more exact measurements and gigantic time and cost expensive in creation. The automated arm is furnished with 4 servo engines to interface the parts and bring arm development. A sequential construction mechanical system can improve its efficiency through developing the assembling pace and its consistency. They additionally spare individuals from dreary and tedious mechanical production system employments. Many industries are yet to implement such automation in their meeting traces, as they do no longer have the technical recognize how of the changeover, or the concern of failure of investment. It is proposed to layout and increase a low price assembly robotic which could overcome the above drawbacks. We have also included Design Thinking process before starting to do this experiment. The stages of Design Thinking such as Empathize, Define, Ideate, Prototype & test, Evolve are performed in the complete fabrication of the robotic arm. Many industries are yet to implement such automation in their assembly lines, as they do not have the technical knowhow of the changeover, or the fear of failure of investment. To proceed in this direction, a case study was conducted at a phase selector switch making company. Presently the company does manual assembly of the switches, which is a hindrance to the growth of the company. This process required a pilot study to explore the possibility as well as the implementations issues of robots in the assembly. The present system uses a belt conveyor system which has no feedback signals and the speed of the conveyor is not synchronized with the rate of assembly. It is generally not advised to transfer small size components in a conveyor since picking, orienting and inserting the components will be cumbersome. When the size of the component is considerably small, manual assembly is not recommended as per the guidelines of DFMA (Design for manufacture and assembly). Manual error is more prone to assembly of the part in a wrong orientation, especially for those components that are symmetrical. The parts to be assembled are both axi-symmetric as well as prismatic in shape. Constraints in loading and unloading of casing were also reported. In this work, the design and development of a low cost assembly robot is done which can overcome the above drawbacks. © Published under licence by IOP Publishing Ltd.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","1059","","","","","","","","IOP Publishing Ltd","","English","","","","","","","ISSN: 17578981 Issue: 1","<p>cited By 0; Conference of 2nd International Conference on Materials, Manufacturing and Machining for Industry 4.0, ICMMM 2020 ; Conference Date: 9 October 2020 Through 10 October 2020; Conference Code:167166</p>","","","","","Kumar M., Kalidasan B., Dinesh D., Pradeep A.D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4FI36F9","conferencePaper","2021","Prabha, A.; Yadav, J.; Rani, A.; Singh, V.","Non-invasive Diabetes Mellitus Detection System using Machine Learning Techniques","Proceedings of the Confluence 2021: 11th International Conference on Cloud Computing, Data Science and Engineering","978-0-7381-3160-3","","10.1109/Confluence51648.2021.9377138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103856727&doi=10.1109%2fConfluence51648.2021.9377138&partnerID=40&md5=75ac7ea15945982eab8f7fd0fa9aa3cb","This work presents an automated diabetes mellitus detection system (DMDS), based on wrist photoplethysmography (PPG) signal and physiological parameters. The PPG signal with an average duration of 2.5 minutes is obtained using the handle Empatica E4 Wristband from 217 patients. The mel frequency cepstral coefficients (MFCC) features are extracted from 5 second segments of the PPG signal. The extracted features and physiological parameters constitute the input for machine learning (ML) systems. K-nearest neighbors (KNN) and Support Vector machine (SVM) algorithms are used for classification. 83.87% and 84.49% classification accuracy is achieved with KNN and radial basis function (RBF) Kernel SVM based DMDS respectively. Further principal component analysis is used on the input feature set to the SVM classifier which provides 7.79% improvement in the performance. The performance of the developed systems is also analysed using entropy triangle. Results reveal the effectiveness of proposed DMDS for non-invasive DM detection. The designed wrist band identifies the diabetic and pre-diabetic cases in real time on the basis of short duration PPG signal and physiological parameters. © 2021 IEEE","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","948-953","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 11th International Conference on Cloud Computing, Data Science and Engineering, Confluence 2021 ; Conference Date: 28 January 2021 Through 29 January 2021; Conference Code:167955</p>","","","Physiology; Cloud computing; K nearest neighbor (KNN); Learning systems; Support vector machines; Machine learning techniques; Data Science; Nearest neighbor search; Physiological models; Classification accuracy; Mel-frequency cepstral coefficients; Photoplethysmography; Photoplethysmography (PPG); Physiological parameters; Radial Basis Function(RBF); Support vector machine algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69228RKX","journalArticle","2021","Babel, F.; Kraus, J.M.; Baumann, M.","Development and Testing of Psychological Conflict Resolution Strategies for Assertive Robots to Resolve Human–Robot Goal Conflict","Frontiers in Robotics and AI","","22969144","10.3389/frobt.2020.591448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100979428&doi=10.3389%2ffrobt.2020.591448&partnerID=40&md5=1559635c8cb5c0ff77d426050b3d793f","As service robots become increasingly autonomous and follow their own task-related goals, human-robot conflicts seem inevitable, especially in shared spaces. Goal conflicts can arise from simple trajectory planning to complex task prioritization. For successful human-robot goal-conflict resolution, humans and robots need to negotiate their goals and priorities. For this, the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user. In this paper, conflict resolution strategies for service robots (public cleaning robot, home assistant robot) are developed by transferring psychological concepts (e.g., negotiation, cooperation) to HRI. Altogether, fifteen strategies were grouped by the expected affective outcome (positive, neutral, negative). In two online experiments, the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts (public: n1 = 61; private: n2 = 93). To obtain a comparative value, the strategies were also applied by a human. As additional outcomes trust, fear, arousal, and valence, as well as perceived politeness of the agent were assessed. The positive/neutral strategies were found to be more acceptable and effective than negative strategies. Some negative strategies (i.e., threat, command) even led to reactance and fear. Some strategies were only positively evaluated and effective for certain agents (human or robot) or only acceptable in one of the two application contexts (i.e., approach, empathy). Influences on strategy acceptance and compliance in the public context could be found: acceptance was predicted by politeness and trust. Compliance was predicted by interpersonal power. Taken together, psychological conflict resolution strategies can be applied in HRI to enhance robot task effectiveness. If applied robot-specifically and context-sensitively they are accepted by the user. The contribution of this paper is twofold: conflict resolution strategies based on Human Factors and Social Psychology are introduced and empirically evaluated in two online studies for two application contexts. Influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed. © Copyright © 2021 Babel, Kraus and Baumann.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","7","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ37M558","journalArticle","2021","Chang, W.; Wang, H.; Yan, G.; Lu, Z.; Liu, C.; Hua, C.","EEG based functional connectivity analysis of human pain empathy towards humans and robots","Neuropsychologia","","00283932","10.1016/j.neuropsychologia.2020.107695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097757961&doi=10.1016%2fj.neuropsychologia.2020.107695&partnerID=40&md5=95c990a62e5739f884d45547193f3cab","Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots. © 2020 Elsevier Ltd","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","151","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 0</p>","","","empathy; robotics; functional connectivity; human; human experiment; adult; brain region; female; male; Article; electroencephalogram; event related potential; hand pain; normal human; pain empathy; pain threshold; reaction time; stimulus response; young adult","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6T6G5R6A","journalArticle","2021","Nanetti, A.","Defining Heritage Science: A Consilience Pathway to Treasuring the Complexity of Inheritable Human Experiences through Historical Method, AI, and ML","Complexity","","10762787","10.1155/2021/4703820","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101919974&doi=10.1155%2f2021%2f4703820&partnerID=40&md5=fceda71679aaa01c381e4c6403c44245","Societies have always used their heritage to remain resilient and to express their cultural identities. Today, all the still-available experiences accrued by human societies over time and across space are, in principle, essential in coping with the twenty-first century grand challenges of humanity (refer to the 17 UN Sustainable Development Goals). Artificial intelligence and machine learning algorithms can assist the next generation of historians, heritage stakeholders, and decision-makers in (1) decoding unstructured knowledge and wisdom embedded in selected cultural artefacts and social rituals, (2) encoding data in machine-readable systems, (3) aggregating information according to the user's needs in real time, and (4) simulating the consequences of either erasing, neglecting, putting in latency, or preserving and sharing specific human experiences. What our global society needs is a multilingual and transcultural approach to decode-encode the treasure of human experience and transmit it to the next generation of world citizens. This approach can be the pathway to work on a new science of heritage, its ethics, and empathy. © 2021 Andrea Nanetti.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","2021","","","","","","","","","","English","","","","","","","Publisher: Hindawi Limited","<p>cited By 0</p>","","","Machine learning; Decoding; Decision making; Cultural identity; Decision makers; Embedded systems; Encoding (symbols); Encoding data; Global society; Grand Challenge; Historical methods; Human society; Learning algorithms; Real time systems; Time sharing systems; User's needs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSCR3ZQP","journalArticle","2021","Balle, S.N.","Empathic responses and moral status for social robots: an argument in favor of robot patienthood based on K. E. Løgstrup","AI and Society","","09515666","10.1007/s00146-021-01211-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104950822&doi=10.1007%2fs00146-021-01211-2&partnerID=40&md5=3787db2c2f40a90ea3212ba2a25225a5","Empirical research on human–robot interaction (HRI) has demonstrated how humans tend to react to social robots with empathic responses and moral behavior. How should we ethically evaluate such responses to robots? Are people wrong to treat non-sentient artefacts as moral patients since this rests on anthropomorphism and ‘over-identification’ (Bryson and Kime, Proc Twenty-Second Int Jt Conf Artif Intell Barc Catalonia Spain 16–22:1641–1646, 2011)—or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood, such that social robots become our ‘Others’ (Gunkel, Robot rights, MIT Press, London, 2018; Coeckelbergh, Kairos J Philos Sci 20:141–158, 2018)?. In this research paper, I weave extant HRI studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots, on which the ethical evaluation of moral behavior toward them is dependent. Patienthood for robots has standardly been thought to obtain on some intrinsic ground, such as being sentient, conscious, or having interest. But since these attempts neglect moral experience and are curbed by epistemic difficulties, I take inspiration from Coeckelbergh and Gunkel’s ‘relational approach’ to explore an alternative way of accounting for robot patienthood based on extrinsic premises. Based on the ethics of Danish theologian K. E. Løgstrup (1905–1981) I argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjects—even if they emerge from social interaction afforded by robots we have anthropomorphized. I ultimately develop an argument in defense of treating robots as moral patients. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0</p>","","","Social robots; Philosophical aspects; Robot interactions; Social interactions; Human subjects; Catalonia; Empirical research; Research papers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63PFUFUA","journalArticle","2021","Pashevich, E.","Can communication with social robots influence how children develop empathy? Best-evidence synthesis","AI and Society","","09515666","10.1007/s00146-021-01214-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105417711&doi=10.1007%2fs00146-021-01214-z&partnerID=40&md5=3450c898fc3bbd8515987bb1735a8566","Social robots are gradually entering children’s lives in a period when children learn about social relationships and exercise prosocial behaviors with parents, peers, and teachers. Designed for long-term emotional engagement and to take the roles of friends, teachers, and babysitters, such robots have the potential to influence how children develop empathy. This article presents a review of the literature (2010–2020) in the fields of human–robot interaction (HRI), psychology, neuropsychology, and roboethics, discussing the potential impact of communication with social robots on children’s social and emotional development. The critical analysis of evidence behind these discussions shows that, although robots theoretically have high chances of influencing the development of empathy in children, depending on their design, intensity, and context of use, there is no certainty about the kind of effect they might have. Most of the analyzed studies, which showed the ability of robots to improve empathy levels in children, were not longitudinal, while the studies observing and arguing for the negative effect of robots on children’s empathy were either purely theoretical or dependent on the specific design of the robot and the situation. Therefore, there is a need for studies investigating the effects on children’s social and emotional development of long-term regular and consistent communication with robots of various designs and in different situations. © 2021, The Author(s).","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0</p>","","","Social robots; Machine design; Robot interactions; Social relationships; Economic and social effects; CAN communications; Context of use; Critical analysis; Emotional engagements; Neuropsychology; Potential impacts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3B7ZXNGW","journalArticle","2021","Croes, E.A.J.; Antheunis, M.L.","Can we be friends with Mitsuku? A longitudinal study on the process of relationship formation between humans and a social chatbot","Journal of Social and Personal Relationships","","02654075","10.1177/0265407520959463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091422686&doi=10.1177%2f0265407520959463&partnerID=40&md5=7a1fafb08fcca7eb9c8e2df2e58c3779","This explorative study investigated (a) whether social attraction, self-disclosure, interaction quality, intimacy, empathy and communicative competence play a role in getting-acquainted interactions between humans and a chatbot, and (b) whether humans can build a relationship with a chatbot. Although human-machine communication research suggests that humans can develop feelings for computers, this does not automatically imply that humans experience feelings of friendship with a chatbot. In this longitudinal study, 118 participants had seven interactions with chatbot Mitsuku over a 3-week period. After each interaction participants filled out a questionnaire. The results showed that the social processes decreased after each interaction and feelings of friendship were low. In line with the ABCDE model of relationship development, the social processes that aid relationship continuation decrease, leading to deterioration of the relationship. Furthermore, a novelty effect was at play after the first interaction, after which the chatbot became predictable and the interactions less enjoyable. © The Author(s) 2020.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","279-300","","1","38","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 2</p>","","","friendship; friend; questionnaire; article; human; human experiment; adult; female; major clinical study; male; deterioration; longitudinal study; self disclosure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8H37WPQZ","journalArticle","2021","Vargas Martin, M.; Pérez Valle, E.; Horsburgh, S.","Artificial Empathy for Clinical Companion Robots with Privacy-By-Design","Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","","18678211","10.1007/978-3-030-70569-5_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104418757&doi=10.1007%2f978-3-030-70569-5_23&partnerID=40&md5=d3890f65cafff1ceba3086b0fd4212bf","We present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families. Our approach removes the need for Cloud-based automatic speech recognition systems to address healthcare privacy expectations. Furthermore, we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation. Our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","351-361","","","362 LNICST","","","","","","","","","","English","","","","","","","ISBN: 9783030705688 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 9th EAI International Conference on Wireless Mobile Communication and Healthcare, MobiHealth 2020 ; Conference Date: 19 November 2020 Through 19 November 2020; Conference Code:255799</p>","","","Mental health; Health care; Companion robot; Speech recognition; Human robot interaction; Humanoid robot; Machine design; Robot interactions; Anthropomorphic robots; Facial Expressions; Privacy by design; Automatic speech recognition system; Cloud-based; Mobile telecommunication systems","","Ye J., Yordanova K., O'Grady M.J., Civitarese G.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z52BHRTH","journalArticle","2021","Irfan, F.","Artificial intelligence: Help or hindrance for family physicians?","Pakistan Journal of Medical Sciences","","1682024X","10.12669/pjms.37.1.3351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096989073&doi=10.12669%2fpjms.37.1.3351&partnerID=40&md5=c41326d8fd2999819e37ec0e1a8eb331","The use of Artificial Intelligence (AI) and related technologies is rapidly increasing and its application in clinical practice is a promising area of development. Artificial Intelligence can be a solution in the future as a physician’s new assistant; AI-physician combinations can act like models of ‘peaceful co-existence’. While it has the potential to mold many dimensions of patient care and can augment quality improvement, it cannot replace a family physician’s diagnostic intelligence, empathy and relationships. Physicians need to strike a balance between these combinations for better health outcomes without increasing patients’ frustration. © 2021, Professional Medical Publications. All rights reserved.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","1-4","","1","37","","","","","","","","","","English","","","","","","","Publisher: Professional Medical Publications","<p>cited By 0</p>","","","artificial intelligence; machine learning; empathy; article; human; adult; clinical practice; frustration; general practitioner; outcome assessment; patient care; total quality management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A4XGQQ3","journalArticle","2021","Malinowska, J.K.","What Does It Mean to Empathise with a Robot?","Minds and Machines","","09246495","10.1007/s11023-021-09558-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103210495&doi=10.1007%2fs11023-021-09558-7&partnerID=40&md5=399cfc5d10e16a1b04196e0ba6b26a9c","Given that empathy allows people to form and maintain satisfying social relationships with other subjects, it is no surprise that this is one of the most studied phenomena in the area of human–robot interaction (HRI). But the fact that the term ‘empathy’ has strong social connotations raises a question: can it be applied to robots? Can we actually use social terms and explanations in relation to these inanimate machines? In this article, I analyse the range of uses of the term empathy in the field of HRI studies and social robotics, and consider the substantial, functional and relational positions on this issue. I focus on the relational (cooperational) perspective presented by Luisa Damiano and Paul Dumouchel, who interpret emotions (together with empathy) as being the result of affective coordination. I also reflect on the criteria that should be used to determine when, in such relations, we are dealing with actual empathy. © 2021, The Author(s).","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 0</p>","","","Artificial intelligence; Social robots; Social robotics; Philosophical aspects; Robot interactions; Social relationships","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KXCSDVU","journalArticle","2021","Ouatu, B.-I.; Gifu, D.","Chatbot, the future of learning?","Smart Innovation, Systems and Technologies","","21903018","10.1007/978-981-15-7383-5_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091525926&doi=10.1007%2f978-981-15-7383-5_23&partnerID=40&md5=f9363ac641c9960fc5f4e48ffad9ce37","Our position is that, in order to improve the quality of Romanian education, an intelligent learning system could become a substantial and versatile tool for aiding the achievement of every student’s potential, always aiding and encouraging him/her. The limits of the conventional learning process and mental health are major issues in many education systems. Chatbots are centered on assisting humans in performing their tasks efficiently and require a low amount of digital literacy to interact with. Chatbots have been shown to be effective in the fields of education and well-being. Due to the substantial difference between artificial intelligence technology waves, the interaction process can occur in several ways depending on the communication interface. How can we combine both traditional and automated educational approaches in the digital age? On one hand, an artificial intelligence tutor does not get angry or annoyed explaining the same problem at the student’s discretion and can also function as a personal therapist, while a human professor could be empathic, trying to keep a balanced teaching method adapted to all students. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2021.","2021","2021-05-19 13:26:06","2021-05-19 13:26:06","","263-268","","","197","","","","","","","","","","English","","","","","","","ISBN: 9789811573828 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 5th International Conference on Smart Learning Ecosystems and Regional Development, SLERD 2020 ; Conference Date: 25 May 2020 Through 27 May 2020; Conference Code:245159</p>","","","Artificial intelligence; Students; Artificial intelligence technologies; Learning systems; Ecosystems; Communication interface; Digital literacies; Education systems; Educational approach; Intelligent learning systems; Interaction process; Regional planning; Teaching methods","","Mealha O., Rebedea T., Rehm M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRWFEPR5","journalArticle","2021","Park, J.; Jindal, A.; Kuo, P.; Tanana, M.; Lafata, J.E.; Tai-Seale, M.; Atkins, D.C.; Imel, Z.E.; Smyth, P.","Automated rating of patient and physician emotion in primary care visits","Patient Education and Counseling","","07383991","10.1016/j.pec.2021.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099559374&doi=10.1016%2fj.pec.2021.01.004&partnerID=40&md5=ed75a3047e5b33becde76fc7643102d4","Objective: Train machine learning models that automatically predict emotional valence of patient and physician in primary care visits. Methods: Using transcripts from 353 primary care office visits with 350 patients and 84 physicians (Cook, 2002 [1], Tai-Seale et al., 2015 [2]), we developed two machine learning models (a recurrent neural network with a hierarchical structure and a logistic regression classifier) to recognize the emotional valence (positive, negative, neutral) (Posner et al., 2005 [3]) of each utterance. We examined the agreement of human-generated ratings of emotional valence with machine learning model ratings of emotion. Results: The agreement of emotion ratings from the recurrent neural network model with human ratings was comparable to that of human-human inter-rater agreement. The weighted-average of the correlation coefficients for the recurrent neural network model with human raters was 0.60, and the human rater agreement was also 0.60. Conclusions: The recurrent neural network model predicted the emotional valence of patients and physicians in primary care visits with similar reliability as human raters. Practice implications: As the first machine learning-based evaluation of emotion recognition in primary care visit conversations, our work provides valuable baselines for future applications that might help monitor patient emotional signals, supporting physicians in empathic communication, or examining the role of emotion in patient-centered care. © 2021 Elsevier B.V.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","","","","","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ireland Ltd","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZXHEUJX","journalArticle","2021","Zhang, L.; Zhang, T.; Ren, Z.; Jiang, G.","Predicting compassion fatigue among psychological hotline counselors using machine learning techniques","Current Psychology","","10461310","10.1007/s12144-021-01776-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105246350&doi=10.1007%2fs12144-021-01776-7&partnerID=40&md5=f7db6e6f582da3cdd2f31631832c8533","During the outbreak of coronavirus disease 2019, psychological hotline counselors frequently address help-seekers’ traumatic experiences from time to time, which possibly causes counselors’ compassion fatigue. The present study aimed to explore the predictors of compassion fatigue among a high-risk population of psychological hotline counselors. Seven hundred and twelve psychological hotline counselors were recruited from the Mental Health Service Platform at Central China Normal University, Ministry of Education, then were asked to complete the questionnaires measuring compassion fatigue, trait empathy, social support, trait mindfulness, counselor’s self-efficacy, humor, life meaning, and post-traumatic growth. A chi-square test was utilized to filter for the top-20 predictive variables. Machine learning techniques, including logistic regression, decision tree, random forest, k-nearest neighbor, support vector machine, and naïve Bayes were employed to predict compassion fatigue. The results showed that the most important predictors of compassion fatigue were meaning in life, counselors’ self-efficacy, mindfulness, and empathy. Except for the decision tree, the rest machine learning techniques obtained good performance. Naïve Bayes presented the highest area under the receiver operating characteristic curve of 0.803. Random forest achieved the least classification error of 23.64, followed by Naïve Bayes with a classification error of 23.85. These findings support the potential application of machine learning techniques in the prediction of compassion fatigue. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJG4AVZD","journalArticle","2021","Toquero, C.M.D.","‘Sana all’ inclusive education amid COVID-19: Challenges, strategies, and prospects of special education teachers [Educación inclusiva “sana all” en medio de COVID-19: Desafíos, estrategias y perspectivas de los maestros de educación especial]","International and Multidisciplinary Journal of Social Sciences","","20143680","10.17583/rimcis.2021.6316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104007310&doi=10.17583%2frimcis.2021.6316&partnerID=40&md5=56117ecfa21101610eeda94063b7cc02","People with Special Educational Needs and Disabilities (SEND) are confronted with diverse challenges as COVID-19 caused tremendous disruption in face-to-face educational settings. Apart from this situation, teachers are also facing difficulties in making their lessons adaptive and responsive to the educational learning needs of people with SEND. This article explores the challenges, strategies, and prospects of teachers for inclusive education during the pandemic. Using a qualitative approach, the researcher gathered data through Messenger chatbot and emails from five special education teachers in the Philippines. Findings revealed that the teachers’ experience educational apprehensions, intermittent virtual socialization, and psychological crisis. Nevertheless, the teachers assisted the parents in supervising their children with disabilities’ through online communication, homeschooling, parental engagement, psychological safety, and empathetic language strategies. The special education teachers also look forward to inclusivity in school policies and government-driven emergency interventions for people with developmental disabilities. © 2021, Hipatia Editorial. All rights reserved.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","30-51","","1","10","","","","","","","","","","English","","","","","","","Publisher: Hipatia Editorial","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVTDCBE5","conferencePaper","2021","Srinivasan, R.; Uchino, K.","The role of arts in shaping AI ethics","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101201598&partnerID=40&md5=1dadc0b933af226f4dda649f7c5def66","Despite the significant progress made in recent years, there seems to be a visible bottleneck in transforming artificial intelligence (AI) technologies into large scale systems of ethical value. Biases in training data coupled with algorithmic biases adversely affect many stakeholders. It has been shown that AI based decisions exhibit discrimination based on sensitive attributes such as age, gender, and race, to name a few. One of the ways of addressing this issue is by incorporating the voices of people impacted by AI into the AI pipeline. However, historical power structures and impacts of discrimination against specific communities worldwide poses several challenges. Towards this end, art shows tremendous promise as a powerful platform to promote AI education, as a medium of expression, and to enhance empathy; thereby facilitating diversity and inclusion in the AI pipeline. In this work, we highlight some emerging work in this area, discuss pathways that art offers towards enhancing AI ethics, and outline some open research directions. We hope our work serves as a prequel to discussions concerning the design and development of tools that leverage art in an effort towards enhancing AI ethics. Copyright © 2021, for this paper by its authors.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","1-6","","","2812","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 2021 Workshop on Reframing Diversity in AI: Representation, Inclusion and Power, RDAI 2021 ; Conference Date: 9 February 2021; Conference Code:167023</p>","","","Artificial intelligence; Philosophical aspects; Artificial intelligence technologies; Design and Development; Ethical values; Large scale systems; Pipelines; Power structures; Sensitive attribute; Training data","","Fokoue A., Hobson S., Agunwa C., Lee K., Quigley L.T.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTS4HC73","journalArticle","2021","Dante, A.; Marcotullio, A.; Masotta, V.; Caponnetto, V.; La Cerra, C.; Bertocchi, L.; Petrucci, C.; Alfes, C.M.","From high-fidelity patient simulators to robotics and artificial intelligence: A discussion paper on new challenges to enhance learning in nursing education","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-52287-2_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090093657&doi=10.1007%2f978-3-030-52287-2_11&partnerID=40&md5=6638dc93c7218d61f45dee01b2f4cd9f","High-fidelity simulation (HFS) is an educational method based on technological mannequins which faithfully reproduces both physiological or physiopathological human body responses to specific clinical conditions and nursing care. When the traditional education is integrated with HFS, improvements in nursing students’ knowledge, performance, self-efficacy, self-confidence, problem solving ability, and critical thinking were reported, as well as relational and empathic skills. The level of realism reached in HFS sessions, defined as the ‘degree to which a simulated experience approaches reality’ demonstrated a positive association with students’ learning outcomes. Most of high-fidelity patient simulators are computer-driven static mannequins which resemble adult or child human body dimensions. However, they show limits that should be overcome to provide a more realistic full-body experience in nursing education. In this regard, robotics and artificial intelligence have a key role for the technological evolution of nursing educational systems and their introduction in the simulation field is opening new perspectives that will produce unavoidably the redefinition of educational standards with beneficial implications for future nursing care. In this perspective, new challenges for nursing education has been discussed in this paper. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","111-118","","","1236 AISC","","","","","","","","","","English","","","","","","","ISBN: 9783030522865 Publisher: Springer","<p>cited By 0; Conference of 10th International Conference in Methodologies and Intelligent Systems for Technology Enhanced Learning, MIS4℡ 2020 ; Conference Date: 17 June 2020 Through 19 June 2020; Conference Code:243009</p>","","","Robotics; Intelligent systems; Students; Learning systems; Educational robots; Nursing; Problem solving; Physiological models; Educational standards; Educational systems; High-fidelity simulations; Human body dimension; Implications for futures; Medical computing; Problem-solving abilities; Technological evolution; Traditional educations","","Kubincova Z., Gil A.B., Lancia L., Popescu E., Nakayama M., Scarano V.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQ5UJMUR","journalArticle","2021","Aledhari, M.; Razzak, R.; Parizi, R.M.; Srivastava, G.","Deep Neural Networks for Detecting Real Emotions Using Biofeedback and Voice","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-68799-1_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103460753&doi=10.1007%2f978-3-030-68799-1_21&partnerID=40&md5=60b91bc35a4e35c9705ab1acfb611a06","When people are in an interview, with the interview questions, people’s emotions will change differently. Therefore, it is very helpful to detect people’s emotions in real-time. To do so, comprehensive data collection was performed through the voice recording platform and the Empatica E4 wristband (biofeedback). Also, through using both existing feed-forward deep neural network technology and machine learning, we implemented an artificial deep neural network that aims to detect real emotions using multiple sensors: voice and biometrics. The artificial deep neural network we implemented consistently achieved an accuracy of 85% in our testing set and 79% in validation sets to determine the emotional scale. The research also assists with understanding how to detect emotional ranges and the important role that it plays in interviews and conversations. © 2021, Springer Nature Switzerland AG.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","302-309","","","12664 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030687984 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 25th International Conference on Pattern Recognition Workshops, ICPR 2020 ; Conference Date: 10 January 2021 Through 15 January 2021; Conference Code:255789</p>","","","Neural networks; Speech recognition; Real time; Deep neural networks; Biofeedback; Data collection; Feed forward; Multiple sensors; Validation sets","","Del Bimbo A., Vezzani R., Cucchiara R., Sclaroff S., Farinella G.M., Mei T., Bertini M., Escalante H.J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRBA6GP4","conferencePaper","2021","Zafar, Z.; Ashok, A.; Berns, K.","Personality traits assessment using p.A.D. Emotional space in human-robot interaction","VISIGRAPP 2021 - Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications","978-989-758-488-6","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974518&partnerID=40&md5=579d9d515e2e418c556711a934135b57","Cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings. Humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish human-human interaction. Similarly, assessment of human personality is highly critical in realizing natural and intelligent human-robot interaction. Numerous personality traits assessment systems have been reported in the literature; however, most of them target the big five personality traits. From only visual information, this work proposes to use pleasure, arousal, and dominance emotional space for the assessment of personality traits based on the work of Mehrabian. To validate the system, three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot. Experimental results show that the system can assess human personality traits with 84% accuracy in real-time and, hence, it can adapt its behavior according to the perceived personality of the interaction partner. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","111-118","","","2","","","","","","","","SciTePress","","English","","","","","","","","<p>cited By 0; Conference of 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2021 ; Conference Date: 8 February 2021 Through 10 February 2021; Conference Code:167535</p>","","","Computer vision; Social robots; Social robotics; Humanoid robot; Personality traits; Man machine systems; Anthropomorphic robots; Assessment system; Computer graphics; Human being; Human-human interactions; Real time; Visual information","","Paljic A., Bouatouch K., Peck T., Braz J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R6B668TQ","journalArticle","2021","Erel, H.; Trayman, D.; Levy, C.; Manor, A.; Mikulincer, M.; Zuckerman, O.","Enhancing Emotional Support: The Effect of a Robotic Object on Human–Human Support Quality","International Journal of Social Robotics","","18754791","10.1007/s12369-021-00779-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105378198&doi=10.1007%2fs12369-021-00779-5&partnerID=40&md5=31fccb98f281cb4956d06a3377775de0","Emotional support in the context of psychological caregiving is an important aspect of human–human interaction that can significantly increase well-being. In this study, we tested if non-verbal gestures of a non-humanoid robot can increase emotional support in a human–human interaction. Sixty-four participants were invited in pairs to take turns in disclosing a personal problem and responding in a supportive manner. In the experimental condition, the robotic object performed emphatic gestures, modeled according to the behavior of a trained therapist. In the baseline condition, the robotic object performed up-and-down gestures, without directing attention towards the participants. Findings show that the robot’s empathy-related gestures significantly improved the emotional support quality provided by one participant to another, as indicated by both subjective and objective measures. The non-humanoid robot was perceived as peripheral to the natural human–human interaction and influenced participants’ behavior without interfering. We conclude that non-humanoid gestures of a robotic object can enhance the quality of emotional support in intimate human–human interaction. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 0</p>","","","Robotics; Social robots; Humanoid robot; Agricultural robots; Anthropomorphic robots; Human interactions; Base-line conditions; Emotional supports; Experimental conditions; Human support; Subjective and objective measures; Well being","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNADSGKM","journalArticle","2021","Richards, P.","Public authority and its demons: The Sherbro leopard murders in Sierra Leone","Africa","","00019720","10.1017/S0001972021000048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102143821&doi=10.1017%2fS0001972021000048&partnerID=40&md5=88762cc02f6e82f005fbf6f74c54eaca","Demonization is a widespread aspect of political discourse. We are familiar with the demonization of Brussels bureaucrats as a tool for pursuing the British exit from the European Union, and we take stories about the compulsory straightening of bananas with a pinch of salt, however frustrating it might be that some disaffected voters choose to accept these canards as true. But somehow, stories about the demonic in Africa have been accorded much greater ontological respect, not only by colonial powers keen to boost their own legitimacy through claims to a civilizing mission, but also by anthropologists anxious to understand their informants' imaginative concerns, perhaps without fully appreciating the political craft or guile with which these discourses are invested. In seeking to void the charge of delusion, an empathetic reading of demonization risks missing the strategic significance of mythic interventions intended to extract political advantage. This article examines an instance of mythic creativity in the politics of late nineteenth-century interior Sierra Leone as an example of the stagecraft sometimes implicit in African public authority. The case is that of the human leopard, an avatar of commercially compromised chieftaincy. The article asks whether the alleged activities of these leopards were the straight bananas of a certain form of anti-colonial political resistance. In a concluding discussion, some consequences for understanding current forms and practices of local public authority are inferred. Copyright © The Author(s), 2021. Published by Cambridge University Press.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","226-248","","","","","","","","","","","","","English","","","","","","","Publisher: Cambridge University Press","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YN526243","journalArticle","2021","Dollmat, K.S.; Abdullah, N.A.","Machine learning in emotional intelligence studies: a survey","Behaviour and Information Technology","","0144929X","10.1080/0144929X.2021.1877356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099954220&doi=10.1080%2f0144929X.2021.1877356&partnerID=40&md5=b645897ea31110c75104d7291155ee95","Research has proven that having high level of emotional intelligence (EI) can reduce the chance of getting mental illness. EI, and its component, can be improved with training, but currently the process is less flexible and very time-consuming. Machine learning (ML), on the other hand, can analyse huge amount of data to discover useful trends and patterns in shortest time possible. Despite the benefits, ML usage in EI training is scarce. In this paper, we studied 92 journal articles to discover the trend of the ML utilisation in the study of EI and its components. This survey aims to pave way for future studies that could lead to implementation of ML in EI training, and to rope in researchers in psychology and computer science to find possibilities of having a generic ML algorithm for every EI’s components. Our findings show an increasing trend to apply ML on EI components, and Support Vector Machine and Neural Network are the two most popular ML algorithms used in those researches. We also found that social skill and empathy are the least exposed EI components to ML. Finally, we provide recommendations for future research direction of ML in EI domain, and EI in ML. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","","","","","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Ltd.","<p>cited By 0</p>","","","Surveys; Emotional intelligence; Diseases; Future research directions; Journal articles; Learning systems; Mental illness; Ml algorithms; Social skills; Support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSXEQX2H","conferencePaper","2021","D'auria, D.; Persia, F.","Robots against the Coronavirus: The need for a new generation of robots to help global society","Proceedings - 2021 IEEE 15th International Conference on Semantic Computing, ICSC 2021","978-1-72818-899-7","","10.1109/ICSC50631.2021.00087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102632638&doi=10.1109%2fICSC50631.2021.00087&partnerID=40&md5=4d3c1a75e38629db578e5bc0dfd54453","The explosion of the pandemic and the need for social distancing has meant that robotics has more and more space in our daily lives. The Coronavirus epidemic (COVID-19 or SARS-CoV-2) presents us with a challenge that we are currently facing, and which globally highlights our fragility. This fragility and consequent loneliness is perceived more and more every day; that implies the importance of using new technologies able to cope with a new aspect that had not been thought of so far, but which is now dictated by the pandemic consequences. As a result, these new issues brought by the pandemic imply an increasing need to make robots more and more intelligent and empathic with human beings. © 2021 IEEE.","2021","2021-05-19 13:26:07","2021-05-19 13:26:07","","421-424","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 15th IEEE International Conference on Semantic Computing, ICSC 2021 ; Conference Date: 27 January 2021 Through 29 January 2021; Conference Code:167666</p>","","","Semantics; Robots; Global society; Human being; Social aspects; Daily lives; Coronaviruses","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B7BBGI63","journalArticle","2021","Bahador, N.; Ferreira, D.; Tamminen, S.; Kortelainen, J.","Deep learning-based multimodal data fusion: Case study in food intake episodes detection using wearable sensors","JMIR mHealth and uHealth","","22915222","10.2196/21926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100658132&doi=10.2196%2f21926&partnerID=40&md5=e145f47c5899e72f146bcd688c9eddd9","Background: Multimodal wearable technologies have brought forward wide possibilities in human activity recognition, and more specifically personalized monitoring of eating habits. The emerging challenge now is the selection of most discriminative information from high-dimensional data collected from multiple sources. The available fusion algorithms with their complex structure are poorly adopted to the computationally constrained environment which requires integrating information directly at the source. As a result, more simple low-level fusion methods are needed. Objective: In the absence of a data combining process, the cost of directly applying high-dimensional raw data to a deep classifier would be computationally expensive with regard to the response time, energy consumption, and memory requirement. Taking this into account, we aimed to develop a data fusion technique in a computationally efficient way to achieve a more comprehensive insight of human activity dynamics in a lower dimension. The major objective was considering statistical dependency of multisensory data and exploring intermodality correlation patterns for different activities. Methods: In this technique, the information in time (regardless of the number of sources) is transformed into a 2D space that facilitates classification of eating episodes from others. This is based on a hypothesis that data captured by various sensors are statistically associated with each other and the covariance matrix of all these signals has a unique distribution correlated with each activity which can be encoded on a contour representation. These representations are then used as input of a deep model to learn specific patterns associated with specific activity. Results: In order to show the generalizability of the proposed fusion algorithm, 2 different scenarios were taken into account. These scenarios were different in terms of temporal segment size, type of activity, wearable device, subjects, and deep learning architecture. The first scenario used a data set in which a single participant performed a limited number of activities while wearing the Empatica E4 wristband. In the second scenario, a data set related to the activities of daily living was used where 10 different participants wore inertial measurement units while performing a more complex set of activities. The precision metric obtained from leave-one-subject-out cross-validation for the second scenario reached 0.803. The impact of missing data on performance degradation was also evaluated. Conclusions: To conclude, the proposed fusion technique provides the possibility of embedding joint variability information over different modalities in just a single 2D representation which results in obtaining a more global view of different aspects of daily human activities at hand, and yet preserving the desired performance level in activity recognition. © Nooshin Bahador, Denzil Ferreira, Satu Tamminen, Jukka Kortelainen. Originally published in JMIR mHealth and uHealth (http://mhealth.jmir.org), 28.01.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR mHealth and uHealth, is properly cited. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.","2021","2021-05-19 13:26:08","2021-05-19 13:26:08","","","","1","9","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 0</p>","","","Humans; Algorithms; Deep Learning; human; algorithm; Activities of Daily Living; daily life activity; eating; Eating; electronic device; Wearable Electronic Devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82M9AJP6","journalArticle","2021","Tsutsui, Y.; Mitake, Y.; Hosono, S.; Nemoto, Y.; Sholihah, M.; Shimomura, Y.","A context analysis method for empathy in co-creative innovation","Journal of Advanced Mechanical Design, Systems and Manufacturing","","18813054","10.1299/JAMDSM.2021JAMDSM0014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105062714&doi=10.1299%2fJAMDSM.2021JAMDSM0014&partnerID=40&md5=4d22e28f5009f5f04aabf85516e6b60e","In industrialised countries, the competitiveness of the products/services of the manufacturing industries in the global market is declining due to many factors, including commoditisation, rapid technological growth in developing countries and a lack of creativity within manufacturing companies. For this reason, designers in industrialised countries are required to create more innovative products/services whose novelty does not depend on their own original technology alone but on flexible resource integration among diverse actors. In order to design innovative products/services, empathy must be developed among diverse actors around the premise of the design. However, the ways to understand rationalities of each other is still unclear in extant research. As a result, diverse actors with heterogeneous rationalities fail to empathise to others, and designing innovative products/services as intended is difficult. To address this issue, this study aims to develop a practical method that achieve to understand the rationality of other actor in design innovative products/services. To achieve this, a context analysis method is proposed that captures the other actor’s context in formalised procedure. The proposed method includes four steps: conducting an interview to extract information of context, modelling the context, understanding the context and carrying out the depth interview to understand a target actor’s rationality completely based on the context modelling result. The proposed method was applied to therapy robot development, which is in its early stage of innovative service design. Moreover, the application result can encourage an actor to understand the other actor’s rationality by utilising the proposed method. © 2021 The Japan Society of Mechanical Engineers","2021","2021-05-19 13:26:08","2021-05-19 13:26:08","","","","2","15","","","","","","","","","","English","","","","","","","Publisher: Japan Society of Mechanical Engineers","<p>cited By 0</p>","","","Developing countries; Machine design; Product design; Competition; Context modelling; Extract informations; Flexible resources; Innovative product; International trade; Manufacture; Manufacturing companies; Manufacturing industries; Robot development; Technological growth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4EBSUD4","journalArticle","2020","Wales, J.J.","Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots","Frontiers in Artificial Intelligence and Applications","","09226389","10.3233/FAIA200906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65","According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","114-124","","","335","","","","","","","","","","English","","","","","","","ISBN: 9781643681542 Publisher: IOS Press BV","<p>cited By 0; Conference of 4th Conference on Robophilosophy 2020: Culturally Sustainable Social Robotics ; Conference Date: 18 August 2020 Through 21 August 2020; Conference Code:165874</p>","","","Robotics; Social robots; Philosophical aspects; Training data; Augustine; Bodily movement; Consumer products; Educational robots; Instrumentalization; Personal robot; Users' satisfactions","","Norskov M., Quick O.S., Seibt J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNJL48WH","journalArticle","2020","Schmetkamp, S.","Understanding A.I. — Can and Should we Empathize with Robots?","Review of Philosophy and Psychology","","18785158","10.1007/s13164-020-00473-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083955575&doi=10.1007%2fs13164-020-00473-x&partnerID=40&md5=8c5a1a9139fa546337a1ecdeea7e1f49","Expanding the debate about empathy with human beings, animals, or fictional characters to include human-robot relationships, this paper proposes two different perspectives from which to assess the scope and limits of empathy with robots: the first is epistemological, while the second is normative. The epistemological approach helps us to clarify whether we can empathize with artificial intelligence or, more precisely, with social robots. The main puzzle here concerns, among other things, exactly what it is that we empathize with if robots do not have emotions or beliefs, since they do not have a consciousness in an elaborate sense. However, by comparing robots with fictional characters, the paper shows that we can still empathize with robots and that many of the existing accounts of empathy and mindreading are compatible with such a view. By so doing, the paper focuses on the significance of perspective-taking and claims that we also ascribe to robots something like a perspectival experience. The normative approach examines the moral impact of empathizing with robots. In this regard, the paper critically discusses three possible responses: strategic, anti-barbarizational, and pragmatist. The latter position is defended by stressing that we are increasingly compelled to interact with robots in a shared world and that to take robots into our moral consideration should be seen as an integral part of our self- and other-understanding. © 2020, Springer Nature B.V.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","881-897","","4","11","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PEY232JG","journalArticle","2020","Gramantieri, R.","Alexithymic personality in Philip K. Dick’s Do androids dream of electric sheep?","Neohelicon","","03244652","10.1007/s11059-020-00544-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745112&doi=10.1007%2fs11059-020-00544-z&partnerID=40&md5=d7ae68506033a119722c578a57aa02bd","The official definition for alexithymia dates back to 1973, when Sifneos described its symptoms. Persons affected by this condition are unable to verbally describe their feelings. For many years this condition was relatively little known, but nowadays people are talking about it more and more. In forums in which the patients’ comments are posted, it is often underscored how this particular mental state is similar to that of the androids described in the novel Do androids dream of electric sheep? by Philip K. Dick. The Dickian clinical references were those in use during the 1960s. Therefore, to special characteristics that Philip Dick attributed to his robots (coldness and lack of human empathy, and simultaneous desire for social acceptance), the writer, and then the critics, assigned the label of schizophrenia, the only one that the psychiatric manuals of that time associated to such symptoms. Today, if Dick were alive and were to write about his androids, he most likely would no longer use the term schizophrenics, but instead the term alexithymics, which are more socially adaptive than schizophrenics, just like his androids. Making retrospective diagnoses of literary characters is anachronistic; as it was done for decades by critics to consider the Dickian androids schizophrenics: in the fiction story they are not schizophrenics but robots. However a new psychological trait such as alexithymia can revisit that same story by giving it a new symbolic meaning. The aims of this article are: to highlight how the old nosological categories of schizophrenia, generally referred to when commenting Do androids dream of electric sheep?, should be supplemented by the category of alexithymia; to analyze the scenes in which the characters have typical alexithymic behaviors, trying to prove that alexithymia is actually best suited for describing the androids invented by Dick. © 2020, Akadémiai Kiadó, Budapest, Hungary.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","673-683","","2","47","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YXZH2LT","journalArticle","2020","Konijn, E.A.; Hoorn, J.F.","Differential facial articulacy in robots and humans elicit different levels of responsiveness, empathy, and projected feelings","Robotics","","22186581","10.3390/robotics9040092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096119375&doi=10.3390%2frobotics9040092&partnerID=40&md5=16358e35deb385522e159e206aa5199e","Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot’s face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot’s face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) × 2 (treatment: affectionate vs. maltreated). Participants (N = 265; Mage = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of ‘because I feel, I believe it’s real,’ despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of ‘it is just a robot’ fades into the background and appears not relevant anymore. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","1-17","","4","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFA2FYXI","journalArticle","2020","Ma, Y.; Nguyen, K.L.; Xing, F.Z.; Cambria, E.","A survey on empathetic dialogue systems","Information Fusion","","15662535","10.1016/j.inffus.2020.06.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086995406&doi=10.1016%2fj.inffus.2020.06.011&partnerID=40&md5=660453ec5aa92f1e1073d95f3fca9152","Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain. © 2020 Elsevier B.V.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","50-70","","","64","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 12</p>","","","Emotional state; Learning systems; Machine learning techniques; Behavioral research; Human like; Speech processing; Dialogue systems; Key feature; Knowledge accessibilities; Personal preferences; Research and development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5ZS8PX7","journalArticle","2020","Giannopulu, I.; Etournaud, A.; Terada, K.; Velonaki, M.; Watanabe, T.","Ordered interpersonal synchronisation in ASD children via robots","Scientific Reports","","20452322","10.1038/s41598-020-74438-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092659030&doi=10.1038%2fs41598-020-74438-6&partnerID=40&md5=ba25cca4d93dfcc0d9b69aa2ee0148d5","Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping. © 2020, The Author(s).","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","","","1","10","","","","","","","","","","English","","","","","","","Publisher: Nature Research","<p>cited By 0</p>","","","Female; Humans; Male; Robotics; autism; robotics; child; heart rate; Autism Spectrum Disorder; Child; Heart Rate; human; female; male; human relation; Interpersonal Relations; pathophysiology; Preschool; preschool child","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VRPUYLF","journalArticle","2020","Wu, H.; Feng, C.; Lu, X.; Liu, X.; Liu, Q.","Oxytocin effects on the resting-state mentalizing brain network","Brain Imaging and Behavior","","19317557","10.1007/s11682-019-00205-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078296284&doi=10.1007%2fs11682-019-00205-5&partnerID=40&md5=f30603b1709820ae105c35485f9a0096","Oxytocin (OT) has modulatory effects in both human behavior and in the brain, which is not limited in the specific brain area but also with the potential effect on connectivity with other brain regions. Evidence indicates that OT effects on human behavior are multifaceted, such as trust behavior, decrease anxiety, empathy and bonding behavior. For the vital role of mentalizing in understanding others, here we examine whether OT has a general effect on mentalizing brain network which is associated to the effect of related social behavioral and personality traits. Using a randomized, double-blind placebo-controlled group design, we investigate the resting-state functional magnetic resonance imaging after intranasal OT or placebo. The functional connectivity (FC) maps with seed in left/right temporoparietal junction (lTPJ/rTPJ) showed that OT significantly increased connectivity between rTPJ and default attention network (DAN), but decreased the FC between lTPJ and medial prefrontal network (MPN). With machine learning approach, we report that identified altered FCs of TPJ can classify OT and placebo (PL) group. Moreover, individual’s empathy trait can modulate the FC between left TPJ and right rectus (RECT), which shows a positive correlation with empathic concern in PL group but a negative correlation in OT group. These results demonstrate that OT has significant effect on FC with lTPJ and rTPJ, brain regions where are critical for mentalizing, and the empathy concern can modulate the FC. These findings advance our understanding of the neural mechanisms by which OT modulates social behaviors, especially in social interaction involving mentalizing. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","2530-2541","","6","14","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 3</p>","","","Brain; Humans; brain; machine learning; Magnetic Resonance Imaging; empathy; behavior; social interaction; functional magnetic resonance imaging; Oxytocin; functional connectivity; personality; oxytocin; human; human experiment; adult; brain region; male; medial prefrontal cortex; nerve cell network; temporoparietal junction; Article; young adult; Administration; attention network; college student; controlled study; default mode network; diagnostic imaging; dorsal attention network; double blind procedure; Double-Blind Method; frontoparietal network; functional neuroimaging; inferior frontal gyrus; inferior parietal lobule; Intranasal; intranasal drug administration; mentalization; Mentalization; mentalizing network; nuclear magnetic resonance imaging; precuneus; priority journal; randomized controlled trial; resting state network; sensitivity and specificity; social behavior; ventral attention network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CF37Z3AK","journalArticle","2020","Anders, S.; Beck, C.; Domin, M.; Lotze, M.","Empathic responses to unknown others are modulated by shared behavioural traits","Scientific Reports","","20452322","10.1038/s41598-020-57711-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079033463&doi=10.1038%2fs41598-020-57711-6&partnerID=40&md5=11ee3ac3971f3b9982cad1011e93fa60","How empathically people respond to a stranger’s pain or pleasure does not only depend on the situational context, individual traits and intentions, but also on interindividual factors. Here we ask whether empathic responses towards unknown others are modulated by behavioural similarity as a potential marker of genetic relatedness. Participants watched two supposed human players who were modelled as having a strong (player LP) or weak (player NLP) tendency to lead in social situations executing penalty shots in a virtual reality robot soccer game. As predicted, empathic response were modulated by shared behavioural traits: participants whose tendency to lead was more similar to player LP’s tendency to lead experienced more reward, and showed stronger neural activity in reward-related brain regions, when they saw player LP score a goal, and participants whose tendency to lead was more similar to player NLP’s tendency to lead showed stronger empathic responses when they saw player NLP score a goal. These findings highlight the potentially evolutionary grounded role of phenotypic similarity for neural processes underlying human social perception. © 2020, The Author(s).","2020","2021-05-19 13:26:08","2021-05-19 13:26:08","","","","1","10","","","","","","","","","","English","","","","","","","Publisher: Nature Research","<p>cited By 0</p>","","","Brain; Adult; Brain Mapping; Female; Humans; Male; Young Adult; perception; brain; physiology; pain; Reward; Behavior; Empathy; empathy; behavior; virtual reality; robotics; psychology; Pain; reward; Social Perception; article; human; human experiment; adult; brain region; female; male; young adult; procedures; punishment; Photic Stimulation; photostimulation; psychomotor performance; Psychomotor Performance; brain mapping; genetic marker; soccer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BH2SKJHI","journalArticle","2020","Ionta, S.; Costantini, M.; Ferretti, A.; Galati, G.; Romani, G.L.; Aglioti, S.M.","Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain","Cortex","","00109452","10.1016/j.cortex.2020.09.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096170636&doi=10.1016%2fj.cortex.2020.09.028&partnerID=40&md5=4d40f0d2a87002c233cdeaa183165b3c","Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by low- and high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively. © 2020 The Author(s)","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","295-308","","","133","","","","","","","","","","English","","","","","","","Publisher: Masson SpA","<p>cited By 0</p>","","","pain; empathy; child; functional magnetic resonance imaging; human; adult; female; male; Article; normal human; young adult; controlled study; clinical article; animal experiment; animal model; anterior cingulate; brain function; data analysis software; nonhuman; psychological aspect; supramarginal gyrus; tactile stimulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZG4YS8X7","journalArticle","2020","Rueda, J.; Lara, F.","Virtual Reality and Empathy Enhancement: Ethical Aspects","Frontiers in Robotics and AI","","22969144","10.3389/frobt.2020.506984","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096676765&doi=10.3389%2ffrobt.2020.506984&partnerID=40&md5=4b19807309d5e5fc09617f353c543157","The history of humankind is full of examples that indicate a constant desire to make human beings more moral. Nowadays, technological breakthroughs might have a significant impact on our moral character and abilities. This is the case of Virtual Reality (VR) technologies. The aim of this paper is to consider the ethical aspects of the use of VR in enhancing empathy. First, we will offer an introduction to VR, explaining its fundamental features, devices and concepts. Then, we will approach the characterization of VR as an “empathy machine,” showing why this medium has aroused so much interest and why, nevertheless, we do not believe it is the ideal way to enhance empathy. As an alternative, we will consider fostering empathy-related abilities through virtual embodiment in avatars. In the conclusion, however, we will examine some of the serious concerns related to the ethical relevance of empathy and will defend the philosophical case for a reason-guided empathy, also suggesting specific guidelines for possible future developments of empathy enhancement projects through VR embodied experiences. © Copyright © 2020 Rueda and Lara.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","","","","7","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69M8U22G","conferencePaper","2020","Heljakka, K.I.; Ihamäki, P.J.; Lamminen, A.I.","Playing with the opposite of uncanny: Empathic responses to learning with a companion-technology robot dog vs. real dog","CHI PLAY 2020 - Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play","978-1-4503-7587-0","","10.1145/3383668.3419900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096780350&doi=10.1145%2f3383668.3419900&partnerID=40&md5=38eec78b3f6cd0f5c29a83f7362d667b","Social robots are becoming increasingly common in the contexts of education and healthcare. This paper reports on the findings of the first stage of an exploratory study conducted with (n=16) Finnish preschoolers aged 5-7 years. The multidisciplinary study intertwining the areas of early education pedagogics, smart toys and interactive technologies, employed both a commercial robot dog and a real dog to study the potential of these artificial and living entities to support and facilitate social-emotional learning (SEL) through a guided playful learning approach. We performed a research intervention including facilitation, observation and video- recordings of three play sessions organized in March-May 2020. The preliminary findings indicate how guided playing with the robot dog supported SEL through conversation about human relationships, while interaction with the real dog facilitated empathic responses through spontaneous reactions on the animal's behavior. The contribution of our research is an understanding of that a robotic dog more than a living dog may assist in simulating human interaction more than human- animal interaction and is in this way suitable to support playful learning of social-emotional competencies. © 2020 ACM.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","262-266","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 1; Conference of 7th ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play, CHI PLAY 2020 ; Conference Date: 2 November 2020 Through 4 November 2020; Conference Code:164617</p>","","","Animals; Social robots; Educational robots; Human computer interaction; Exploratory studies; Human interactions; Video recording; Interactive computer systems; Artificial life; Emotional learning; Human relationships; Human-animal interactions; Interactive technology; Learning approach; Spontaneous reactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z3JQZ2FA","journalArticle","2020","Van, N.T.T.; Vrana, V.; Duy, N.T.; Minh, D.X.H.; Dzung, P.T.; Mondal, S.R.; Das, S.","The role of human–machine interactive devices for post-COVID-19 innovative sustainable tourism in Ho Chi Minh City, Vietnam","Sustainability (Switzerland)","","20711050","10.3390/su12229523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096085421&doi=10.3390%2fsu12229523&partnerID=40&md5=0cbfd291021ef5206e50026ca77b674a","In this research article, we aim to study the proposed role of human–machine interactive (HMI) technologies, including both artificial intelligence (AI) and virtual reality (VR)-enabled applications, for the post-COVID-19 revival of the already depleted tourism industry in Vietnam’s major tourist destination and business hub of Ho Chi Minh City. The researchers aim to gather practical knowledge regarding tourists’ intentions for such service enhancements, which may drive the sector to adopt a better conclusive growth pattern in post-COVID-19 times. In this study, we attempt to focus on travelers who look for paramount safety with the assurance of empathetic, personalized care in post-COVID-19 times. In the current study, the authors employ structural equation modeling to evaluate the intentions of tourists both structurally and empirically for destination tourism with data collected from tourists with previous exposure to various kinds of these devices. The study shows that human–machine interactive devices are integrating AI and VR and have a significant effect on overall service quality, leading to tourist satisfaction and loyalty. The use of such social interactive gadgets within tourism and mostly in hospitality services requires an organization to make a commitment to futuristic technologies, along with building value by enriching service quality expectations among fearful tourists. This research shows that tourists mainly focus on the use of such HMI devices from the perspective of technology acceptance factors, qualitative value-enhancing service and trustworthy information-sharing mechanisms. The concept of the tour bubble framework is also discussed in detail. The analysis of this discussion gives us a more profound understanding of the novel opportunities which various administrative agencies may benefit from to position these devices better in smart, sustainable destination tourism strategies for the future so that, collectively, service 5.0 with HMI devices can possibly bring back tourism from being disintegrated. Such service applications are the new social innovations leading to sustainable service and a sophisticated experience for all tourists. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","1-30","","22","12","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","artificial intelligence; virtual reality; safety; ecotourism; service quality; Ho Chi Minh City; innovation; instrumentation; machinery; tourist destination; Viet Nam","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FD379D9S","journalArticle","2020","Reis, J.; Melão, N.; Salvadorinho, J.; Soares, B.; Rosete, A.","Service robots in the hospitality industry: The case of Henn-na hotel, Japan","Technology in Society","","0160791X","10.1016/j.techsoc.2020.101423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091677265&doi=10.1016%2fj.techsoc.2020.101423&partnerID=40&md5=0e6de587da7d874bb158b5b429fc5363","Services are changing at an impressive pace boosted by the technological advances felt in Robotics, Big Data, and Artificial Intelligence (AI) that have uncovered new research opportunities. Our objective is to contribute to the literature by exploring the pros and cons of the use of service robots in the hospitality industry and to practice, by presenting the architectural and technological characteristics of a fully automated plant based on a relevant case. To achieve such goal, this article uses a systematic literature review to assess the state-of-the-art, characterize the unit of analysis, and find new avenues for further research. The results indicate that, in high customer contact settings, service robots tend to outperform humans when performing standardized tasks, because of their mechanical and analytical nature. Evidence also shows that, in some cases, service robots have not yet achieved the desired technological maturity to proficiently replace humans. In other words, the technology is not quite there yet, but this does not contradict the fact that new robot technologies, enabled by AI, will be able to replace the employees’ empathetic intelligence. In practical terms, organizations are facing challenges where they have to decide whether service robots are capable of completely replacing human labor or if they should rather invest in balanced options, such as human-robot systems, that seem to be a much more rational choice today. © 2020 Elsevier Ltd","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","","","","63","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 0</p>","","","artificial intelligence; Artificial intelligence; Social robots; robotics; Mobile robots; hospitality industry; State of the art; Intelligent robots; Hospitality industry; Service industry; advanced technology; Human-robot systems; industrial technology; Japan; Research opportunities; Systematic literature review; Technological advances; Technological characteristics; Unit of analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPV4XHTF","conferencePaper","2020","Filho, L.A.D.L.; Oliveira, L.F.R.; Carneiro, H.C.C.; Guarisa, G.P.; Filho, A.L.; Franca, F.M.G.; Lima, P.M.V.","A weightless regression system for predicting multi-modal empathy","Proceedings - 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2020","978-1-72813-079-8","","10.1109/FG47880.2020.00086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099593837&doi=10.1109%2fFG47880.2020.00086&partnerID=40&md5=cda155ca74a9de8e4f0d0c5482d47a5a","This work takes into account the benefits of machine learning in order to estimate the valence of emotions on the OMG Empathy dataset, considering the information obtained from face expressions and dialogue of interlocutors. RegressionWiSARD and ClusRegressionWiSARD n-tuple regressors and its ensembles were employed to this end. The best performance achieved among all the combinations of weightless neural models considered (evaluated using the CCC metric) was 0.25 in validation set of the Personalized Track. © 2020 IEEE.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","657-661","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 15th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2020 ; Conference Date: 16 November 2020 Through 20 November 2020; Conference Code:166624</p>","","","Gesture recognition; Face expressions; Multi-modal; Neural models","","Struc V., Gomez-Fernandez F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5VLB2X8","journalArticle","2020","Liao, J.; Hansen, P.; Chai, C.","A framework of artificial intelligence augmented design support","Human-Computer Interaction","","07370024","10.1080/07370024.2020.1733576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084312865&doi=10.1080%2f07370024.2020.1733576&partnerID=40&md5=098f22d0398c863d6ad804592ff100f6","Recent advances in Artificial Intelligence raise interest in its participation in design activity, which is commonly considered to be complex and human-dominated. In this work, we aim to examine AI roles in early design stages. The human ideation components and design tools related to AI are discussed in a framework of AI-augmented design support. The framework develops a hierarchy of design cognition (basis), approaches and principles. The cognitive models are constructed in an empirical study of 30 designers (26 for analysis, 4 for pilot study) by concurrent Think-Aloud protocol and behavior analysis. The process of producing new design ideas is explained by a transparent analysis of designers’ language and behaviors. Three strategies to organize cognitive activities in design ideation are summarized: develop structured consideration, relate to a scenario, and stick-to designing. These strategies suggest AI could act as (1) representation creation, (2) empathy trigger and (3) engagement, in principles of “knowledge-driven” and “decompose-and-integrate”. The design support with AI provides new perspectives on computer-based design tools that limit to well-defined design variables. The framework is built on a generic notion of design activity and “mimic” human design rationales, expected to benefit research of domain-independent computational design supports and cognitive supports. © 2020 Taylor & Francis Group, LLC.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","511-544","","5-6","35","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Inc.","<p>cited By 0</p>","","","Artificial intelligence; Behavior analysis; Cognitive activities; Computational design supports; Computer aided design; Computer based designs; Domain independents; Early design stages; Empirical studies; Think-aloud protocol","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BV6EI58B","journalArticle","2020","Bagheri, E.; Esteban, P.G.; Cao, H.-L.; Beir, A.D.; Lefeber, D.; Vanderborght, B.","An autonomous cognitive empathy model responsive to users' facial emotion expressions","ACM Transactions on Interactive Intelligent Systems","","21606455","10.1145/3341198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097225306&doi=10.1145%2f3341198&partnerID=40&md5=6b3056773f580546273a9ec06bea4681","Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot. © 2020 ACM.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","","","3","10","","","","","","","","","","English","","","","","","","Publisher: Association for Computing Machinery","<p>cited By 0</p>","","","Human robot interaction; Humanoid robot; Anthropomorphic robots; Affective state; Auto encoders; Facial emotions; Facial Expressions; Human robot Interaction (HRI); Humanoid interaction; Users' affective state","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCSXIQ24","journalArticle","2020","Baki Kocaballi, A.; Ijaz, K.; Laranjo, L.; Quiroz, J.C.; Rezazadegan, D.; Tong, H.L.; Willcock, S.; Berkovsky, S.; Coiera, E.","Envisioning an artificial intelligence documentation assistant for future primary care consultations: A co-design study with general practitioners","Journal of the American Medical Informatics Association","","10675027","10.1093/jamia/ocaa131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096355732&doi=10.1093%2fjamia%2focaa131&partnerID=40&md5=8bfdd5fbd3064e7bb5b25a8cc185ccb9","Objective: The study sought to understand the potential roles of a future artificial intelligence (AI) documentation assistant in primary care consultations and to identify implications for doctors, patients, healthcare system, and technology design from the perspective of general practitioners. Materials and Methods: Co-design workshops with general practitioners were conducted. The workshops focused on (1) understanding the current consultation context and identifying existing problems, (2) ideating future solutions to these problems, and (3) discussing future roles for AI in primary care. The workshop activities included affinity diagramming, brainwriting, and video prototyping methods. The workshops were audio-recorded and transcribed verbatim. Inductive thematic analysis of the transcripts of conversations was performed. Results: Two researchers facilitated 3 co-design workshops with 16 general practitioners. Three main themes emerged: professional autonomy, human-AI collaboration, and new models of care. Major implications identified within these themes included (1) concerns with medico-legal aspects arising from constant recording and accessibility of full consultation records, (2) future consultations taking place out of the exam rooms in a distributed system involving empowered patients, (3) human conversation and empathy remaining the core tasks of doctors in any future AI-enabled consultations, and (4) questioning the current focus of AI initiatives on improved efficiency as opposed to patient care. Conclusions: AI documentation assistants will likely to be integral to the future primary care consultations. However, these technologies will still need to be supervised by a human until strong evidence for reliable autonomous performance is available. Therefore, different human-AI collaboration models will need to be designed and evaluated to ensure patient safety, quality of care, doctor safety, and doctor autonomy. © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","1695-1704","","11","27","","","","","","","","","","English","","","","","","","Publisher: Oxford University Press","<p>cited By 1</p>","","","Decision Making; Humans; artificial intelligence; User-Computer Interface; Artificial Intelligence; empathy; qualitative research; medical informatics; primary health care; Forecasting; article; human; adult; general practitioner; patient care; clinical evaluation; consultation; conversation; documentation; drug safety; genetic transcription; legal aspect; patient safety; thematic analysis; videorecording; Computer-Assisted; General Practitioners; Primary Health Care; computer interface; forecasting; Attitude of Health Personnel; attitude to computers; Attitude to Computers; decision support system; Documentation; electronic health record; Electronic Health Records; health personnel attitude; patient referral; Professional Autonomy; professional practice; Referral and Consultation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGJPEYGS","journalArticle","2020","Imtiaz, D.; Anwar, Y.; Khan, A.","Wearable sensors and a multisensory music and reminiscence therapies application: To help reduce behavioral and psychological symptoms in person with dementia","Smart Health","","23526483","10.1016/j.smhl.2020.100140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096215885&doi=10.1016%2fj.smhl.2020.100140&partnerID=40&md5=c436ab4fcb6546a2d779ccb233bf3070","Dementia is a growing problem and 86% of people affected with dementia acquire behavioral and psychological symptoms of dementia (BPSD). BPSD can cause agitation, irritation, stress and frustration, that can potentially lead to devastating consequences. One of the major concerning symptom is agitation which can lead to wandering and occasionally life threatening situations to the affected person and or the caregiver. A mobile multimodal app was developed for the Android platform which would take as input a set of multisensory recorded memories such as videos, photos and music from a special memorable event in the affected person's life and turn them into a multimedia presentation that can be viewed or listened to. 34 healthy recruited participants were asked to wear the Empatica E4 sensor to record the heart rate variability and electrodermal activity of the skin. Data analysis revealed that the participants reacted positively to happy multimedia presentations. Implying a combination of music and reminiscence therapy can have a positive impact in the reduction of stress and agitation. © 2020 The Author(s)","2020","2021-05-19 13:26:09","2021-05-19 13:26:09","","","","","18","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 0</p>","","","psychotherapy; dementia; human; adult; Article; data analysis software; agitation; electrodermal response; heart rate variability; irritability; music therapy; reminiscence therapy; skin conductance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TDJ3UYT","journalArticle","2020","Nasseri, M.; Nurse, E.; Glasstetter, M.; Böttcher, S.; Gregg, N.M.; Laks Nandakumar, A.; Joseph, B.; Pal Attia, T.; Viana, P.F.; Bruno, E.; Biondi, A.; Cook, M.; Worrell, G.A.; Schulze-Bonhage, A.; Dümpelmann, M.; Freestone, D.R.; Richardson, M.P.; Brinkmann, B.H.","Signal quality and patient experience with wearable devices for epilepsy management","Epilepsia","","00139580","10.1111/epi.16527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085941436&doi=10.1111%2fepi.16527&partnerID=40&md5=6980fc83810ea442fedc4930bb91bf6b","Noninvasive wearable devices have great potential to aid the management of epilepsy, but these devices must have robust signal quality, and patients must be willing to wear them for long periods of time. Automated machine learning classification of wearable biosensor signals requires quantitative measures of signal quality to automatically reject poor-quality or corrupt data segments. In this study, commercially available wearable sensors were placed on patients with epilepsy undergoing in-hospital or in-home electroencephalographic (EEG) monitoring, and healthy volunteers. Empatica E4 and Biovotion Everion were used to record accelerometry (ACC), photoplethysmography (PPG), and electrodermal activity (EDA). Byteflies Sensor Dots were used to record ACC and PPG, the Activinsights GENEActiv watch to record ACC, and Epitel Epilog to record EEG data. PPG and EDA signals were recorded for multiple days, then epochs of high-quality, marginal-quality, or poor-quality data were visually identified by reviewers, and reviewer annotations were compared to automated signal quality measures. For ACC, the ratio of spectral power from 0.8 to 5 Hz to broadband power was used to separate good-quality signals from noise. For EDA, the rate of amplitude change and prevalence of sharp peaks significantly differentiated between good-quality data and noise. Spectral entropy was used to assess PPG and showed significant differences between good-, marginal-, and poor-quality signals. EEG data were evaluated using methods to identify a spectral noise cutoff frequency. Patients were asked to rate the usability and comfort of each device in several categories. Patients showed a significant preference for the wrist-worn devices, and the Empatica E4 device was preferred most often. Current wearable devices can provide high-quality data and are acceptable for routine use, but continued development is needed to improve data quality, consistency, and management, as well as acceptability to patients. © 2020 International League Against Epilepsy","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","S25-S35","","S1","61","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Inc.","<p>cited By 9</p>","","","Adult; Female; Humans; Male; Young Adult; electroencephalography; Middle Aged; Epilepsy; physiology; Monitoring; signal processing; clinical trial; human; adult; female; male; Article; young adult; controlled study; priority journal; aged; Aged; middle aged; devices; Computer-Assisted; Photoplethysmography; electronic device; Wearable Electronic Devices; electrodermal response; accelerometry; Accelerometry; Ambulatory; ambulatory monitoring; data quality; electroencephalography monitoring; epilepsy; Galvanic Skin Response; patient preference; Patient Preference; photoelectric plethysmography; Signal Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IP79D4UC","journalArticle","2020","Patané, I.; Lelgouarch, A.; Banakou, D.; Verdelet, G.; Desoche, C.; Koun, E.; Salemme, R.; Slater, M.; Farnè, A.","Exploring the Effect of Cooperation in Reducing Implicit Racial Bias and Its Relationship With Dispositional Empathy and Political Attitudes","Frontiers in Psychology","","16641078","10.3389/fpsyg.2020.510787","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095935756&doi=10.3389%2ffpsyg.2020.510787&partnerID=40&md5=792c83d8c15eb412507f81480740cbdb","Previous research using immersive virtual reality (VR) has shown that after a short period of embodiment by White people in a Black virtual body, their implicit racial bias against Black people diminishes. Here we tested the effects of some socio-cognitive variables that could contribute to enhancing or reducing the implicit racial bias. The first aim of the study was to assess the beneficial effects of cooperation within a VR scenario, the second aim was to provide preliminary testing of the hypothesis that empathy and political attitudes could contribute to implicit bias about race, while the third aim was to explore the relationship between political attitudes and empathy. We had (Caucasian) participants embodied in a Black virtual body and engaged either in a cooperative (Coop group) or in a non-cooperative (Neutral group) activity with a confederate experimenter embodying another Black avatar. Before and after VR, we measured participants’ implicit racial bias by means of Implicit Association Test (IAT) and their perceived closeness toward the confederate experimenter. Before VR we also assessed participants’ political attitudes and empathy traits. Results revealed that, as compared to the Neutral group, the Coop group showed lower IAT scores after the social interaction. Interestingly, in the Neutral but not the Coop group the perceived closeness toward the confederate experimenter was associated with the initial racial bias: the more the participants reduced their distance, the more they reduced their IAT score. Moreover, reported traits of empathy and political attitudes significantly explained the variance observed in the initial implicit bias, with perspective-taking, empathic concern, and personal distress being significant predictors of the IAT scores. Finally, there was a relationship between political attitudes and empathy: the more participants considered themselves as left-wing voters, the higher their perspective-taking and empathic concern scores. We discuss these findings within the neuroscientific and social cognition field and encourage scholars from different domains to further explore whether and under which conditions a given manipulation for reducing racial bias could be efficiently transposed in VR. © Copyright © 2020 Patané, Lelgouarch, Banakou, Verdelet, Desoche, Koun, Salemme, Slater and Farnè.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","","11","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2TLKHKK","conferencePaper","2020","Chromik, M.; Lachner, F.; Butz, A.","ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research","ACM International Conference Proceeding Series","978-1-4503-7579-5","","10.1145/3419249.3420163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095825746&doi=10.1145%2f3419249.3420163&partnerID=40&md5=57bb98a9ac0c0565b43777fe83bbcc28","Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML's impact on current UXR activities and practitioners' predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users' emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research. © 2020 ACM.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society, NordiCHI 2020 ; Conference Date: 25 October 2020 Through 29 October 2020; Conference Code:164330</p>","","","Machine learning; Academic work; Complex domains; Data driven; Human computer interaction; Machine learning techniques; On currents; Predictive analytics; Semi structured interviews; User data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NC66JKPW","conferencePaper","2020","De Nieva, J.O.; Joaquin, J.A.; Tan, C.B.; Marc Te, R.K.; Ong, E.","Investigating Students Use of a Mental Health Chatbot to Alleviate Academic Stress","ACM International Conference Proceeding Series","978-1-4503-8829-0","","10.1145/3431656.3431657","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100372208&doi=10.1145%2f3431656.3431657&partnerID=40&md5=34b7f3d9443a5e1262c26059ae92a8f9","The amount of academic workload in schools can cause students to experience stress and become more susceptible to mental health problems. However, because of fear of societal stigma, students may find it more difficult to approach others about the stress they experience. A chatbot can provide an alternative avenue for students to freely share the stressful situations they are experiencing. In this study, we investigated the use of Woebot as a mechanism to help senior high school students alleviate stress from academic workload. 25 participants who engaged in daily conversations with Woebot for a two-week period rated the chatbot's likeness to a human with a mean score of 5.56 out of 8, while its ability to understand the feelings of the participants and empathize with them had a mean score of 5.61. An analysis of the chat logs showed that the participants valued Woebot's lessons and stories while they faced challenges in cases when the chatbot generated inappropriate responses. We discuss our findings and provide design suggestions that could make conversational agents like Woebot be more useful in helping the general student population cope with stress. © 2020 ACM.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","1-10","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 6th International Human-Computer Interaction and User Experience Conference: Fostering Digital Innovation, CHIuXiD 2020 ; Conference Date: 21 October 2020 Through 23 October 2020; Conference Code:166740</p>","","","Mental health; Conversational agents; Chatbot; User experience; Students; Human computer interaction; Chat logs; Design suggestions; Indium compounds; Senior high school students; Student populations","","Kurniawan Y., Asfarian A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFUBQIWW","conferencePaper","2020","Daher, K.; Casas, J.; Khaled, O.A.; Mugellini, E.","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020","978-1-4503-7586-3","","10.1145/3383652.3423864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096965302&doi=10.1145%2f3383652.3423864&partnerID=40&md5=fe8b298b7d7e4ba7330d713c3261bfca","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12). © 2020 Owner/Author.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020 ; Conference Date: 20 October 2020 Through 22 October 2020; Conference Code:164271</p>","","","Chatbots; Chatbot; Human robot interaction; Diagnosis; Intelligent virtual agents; Physical health; Short term","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3QN5TG5","journalArticle","2020","McDonald, N.; Pan, S.","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proceedings of the ACM on Human-Computer Interaction","","25730142","10.1145/3415218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094204706&doi=10.1145%2f3415218&partnerID=40&md5=e91f074cfe55852594702ade8fcff795","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course. © 2020 ACM.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","CSCW2","4","","","","","","","","","","English","","","","","","","Publisher: Association for Computing Machinery","<p>cited By 0</p>","","","Artificial intelligence; Data mining; Students; Philosophical aspects; Benefits distribution; Critical resources; Future generations; Information and computer science; Intrinsic features; Privacy by design; Qualitative interviews; Risk assessment; Social participation; Surveillance technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCLYRTE3","journalArticle","2020","Simons, A.; Doyle, T.; Musson, D.; Reilly, J.","Impact of Physiological Sensor Variance on Machine Learning Algorithms","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","21682216","10.1109/SMC42975.2020.9282912","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098881647&doi=10.1109%2fSMC42975.2020.9282912&partnerID=40&md5=aed1cdba61a248647ba16e81e6e1462c","Machine learning based acute stress detection systems use physiological sensor data to objectively predict acute stress. However, machine learning algorithms developed for stress detection do not consider how machine learning algorithm performance may be affected based on a change(s) in the deployment environment. In this study, the deployment environment changes that are investigated are sensor type and sensor placement. Electrodermal activity (EDA) and skin temperature (TEMP) data from two different sensors, the RespiBAN Professional (RespiBAN) and the Empatica E4 are used to train three different machine learning models. The RespiBAN records the EDA data from the rectus abdominis and records the skin TEMP data from the sternum. The Empatica E4 sensor records both EDA and skin TEMP data from the wrist. Three different support vector machine (SVM) models were trained to classify no-stress versus stress states using EDA and skin TEMP data. The first model was trained using data from the RespiBAN wearable sensor (SVM-R), the second model was trained using data from the Empatica E4 sensor (SVM-E) and third model was trained using data from both sensors (SVM-RE). The accuracy of SVM-R on a test set recorded by the RespiBAN sensor was 100%. The accuracy of SVM-E on a test set recorded by the Empatica E4 sensor was 99%. The accuracy of SVM-RE on a test set recorded by both the RespiBAN and Empatica E4 sensor was 82%. The accuracy of the SVM-R on a test set recorded by the Empatica E4 was 64%. These results suggest that research and development cannot be hardware or placement agnostic with wearable sensing data. Sensor type and placement must be taken into consideration when reporting performance metrics of physiological based stress detection machine learning algorithms. © 2020 IEEE.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","241-247","","","2020-October","","","","","","","","","","English","","","","","","","ISBN: 9781728185262 Publisher: Institute of Electrical and Electronics Engineers Inc.","<p>cited By 0; Conference of 2020 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2020 ; Conference Date: 11 October 2020 Through 14 October 2020; Conference Code:165855</p>","","","Physiology; Learning algorithms; Learning systems; Support vector machines; Wearable sensors; Research and development; Electrodermal activity; Environment change; Machine learning models; Performance metrics; Physiological sensors; Skin temperatures; Stresses; Wearable sensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJT9APM7","conferencePaper","2020","Sonmez, E.B.; Kose, H.; Barkana, D.E.","Towards a New Computational Affective System for Personal Assistive Robots","2020 28th Signal Processing and Communications Applications Conference, SIU 2020 - Proceedings","978-1-72817-206-4","","10.1109/SIU49456.2020.9302238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100292356&doi=10.1109%2fSIU49456.2020.9302238&partnerID=40&md5=1c6d4cdda7d6442c842e9caac9ed4e0b","The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively. © 2020 IEEE.","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","Turkish","","","","","","","","<p>cited By 0; Conference of 28th Signal Processing and Communications Applications Conference, SIU 2020 ; Conference Date: 5 October 2020 Through 7 October 2020; Conference Code:166413</p>","","","Robotics; Social robots; Signal processing; Emotional state; Developmental robotics; Educational robots; Affective state; Human computer interaction; Assistive robots; Association reactions; Cognitive architectures; Computation theory; Emergent behaviors; External stimulus; Social interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQJQSBJR","journalArticle","2020","Pepito, J.A.; Ito, H.; Betriana, F.; Tanioka, T.; Locsin, R.C.","Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations","Nursing Philosophy","","14667681","10.1111/nup.12318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088269058&doi=10.1111%2fnup.12318&partnerID=40&md5=9764df20ca03d74991df8a514f7e7133","Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology. © 2020 John Wiley & Sons Ltd","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","4","21","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Ltd","<p>cited By 2</p>","","","artificial intelligence; empathy; robotics; article; human; human experiment; anticipation; health care industry; nursing practice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MIBVTWFA","journalArticle","2020","Stokes, F.; Palmer, A.","Artificial Intelligence and Robotics in Nursing: Ethics of Caring as a Guide to Dividing Tasks Between AI and Humans","Nursing Philosophy","","14667681","10.1111/nup.12306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087300287&doi=10.1111%2fnup.12306&partnerID=40&md5=98ac75134c2826c40f6c13f43324780e","Nurses have traditionally been regarded as clinicians that deliver compassionate, safe, and empathetic health care (Nurses again outpace other professions for honesty & ethics, 2018). Caring is a fundamental characteristic, expectation, and moral obligation of the nursing and caregiving professions (Nursing: Scope and standards of practice, American Nurses Association, Silver Spring, MD, 2015). Along with caring, nurses are expected to undertake ever-expanding duties and complex tasks. In part because of the growing physical, intellectual and emotional demandingness, of nursing as well as technological advances, artificial intelligence (AI) and AI care robots are rapidly changing the healthcare landscape. As technology becomes more advanced, efficient, and economical, opportunities and pressure to introduce AI into nursing care will only increase. In the first part of the article, we review recent and existing applications of AI in nursing and speculate on future use. Second, situate our project within the recent literature on the ethics of nursing and AI. Third, we explore three dominant theories of caring and the two paradigmatic expressions of caring (touch and presence) and conclude that AI—at least for the foreseeable future—is incapable of caring in the sense central to nursing and caregiving ethics. We conclude that for AI to be implemented ethically, it cannot transgress the core values of nursing, usurp aspects of caring that can only meaningfully be carried out by human beings, and it must support, open, or improve opportunities for nurses to provide the uniquely human aspects of care. © 2020 John Wiley & Sons Ltd","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","","","4","21","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Ltd","<p>cited By 1</p>","","","artificial intelligence; robotics; article; human; human experiment; nurse; care behavior; medical ethics; nursing care; touch","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBJFTSVD","journalArticle","2020","Zwir, I.; Arnedo, J.; Del-Val, C.; Pulkki-Råback, L.; Konte, B.; Yang, S.S.; Romero-Zaliz, R.; Hintsanen, M.; Cloninger, K.M.; Garcia, D.; Svrakic, D.M.; Rozsa, S.; Martinez, M.; Lyytikäinen, L.-P.; Giegling, I.; Kähönen, M.; Hernandez-Cuervo, H.; Seppälä, I.; Raitoharju, E.; de Erausquin, G.A.; Raitakari, O.; Rujescu, D.; Postolache, T.T.; Sung, J.; Keltikangas-Järvinen, L.; Lehtimäki, T.; Cloninger, C.R.","Uncovering the complex genetics of human character","Molecular Psychiatry","","13594184","10.1038/s41380-018-0263-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054357876&doi=10.1038%2fs41380-018-0263-6&partnerID=40&md5=cc28474ea2ceb53ab46558d20cfb0cd7","Human personality is 30–60% heritable according to twin and adoption studies. Hundreds of genetic variants are expected to influence its complex development, but few have been identified. We used a machine learning method for genome-wide association studies (GWAS) to uncover complex genotypic–phenotypic networks and environmental interactions. The Temperament and Character Inventory (TCI) measured the self-regulatory components of personality critical for health (i.e., the character traits of self-directedness, cooperativeness, and self-transcendence). In a discovery sample of 2149 healthy Finns, we identified sets of single-nucleotide polymorphisms (SNPs) that cluster within particular individuals (i.e., SNP sets) regardless of phenotype. Second, we identified five clusters of people with distinct profiles of character traits regardless of genotype. Third, we found 42 SNP sets that identified 727 gene loci and were significantly associated with one or more of the character profiles. Each character profile was related to different SNP sets with distinct molecular processes and neuronal functions. Environmental influences measured in childhood and adulthood had small but significant effects. We confirmed the replicability of 95% of the 42 SNP sets in healthy Korean and German samples, as well as their associations with character. The identified SNPs explained nearly all the heritability expected for character in each sample (50 to 58%). We conclude that self-regulatory personality traits are strongly influenced by organized interactions among more than 700 genes despite variable cultures and environments. These gene sets modulate specific molecular processes in brain for intentional goal-setting, self-reflection, empathy, and episodic learning and memory. © 2018, The Author(s).","2020","2021-05-19 13:26:10","2021-05-19 13:26:10","","2295-2312","","10","25","","","","","","","","","","English","","","","","","","Publisher: Springer Nature","<p>cited By 26</p>","","","Adult; Humans; Young Adult; brain; Middle Aged; machine learning; Individuality; empathy; memory; child; cooperation; Child; article; human; human experiment; adult; female; major clinical study; male; young adult; Preschool; preschool child; 80 and over; adolescent; Adolescent; adulthood; aged; Aged; character; Character; childhood; Finland; Finn (citizen); gene locus; gene mutation; genetic association; genetic polymorphism; genetics; genome-wide association study; Genome-Wide Association Study; genotype; Germany; heritability; individuality; middle aged; phenotype; Polymorphism; Republic of Korea; self transcendence; Single Nucleotide; single nucleotide polymorphism; South Korea; temperament; Temperament; very elderly","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4E6Y6ZEE","conferencePaper","2020","Abate, A.F.; Castiglione, A.; Nappi, M.; Passero, I.","DELEX: A DEep Learning Emotive eXperience: Investigating empathic HCI","ACM International Conference Proceeding Series","978-1-4503-7535-1","","10.1145/3399715.3399820","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093106730&doi=10.1145%2f3399715.3399820&partnerID=40&md5=09a6b3d2a3c90137de12cddc6b53f73b","Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel. This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters. © 2020 ACM.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 2020 International Conference on Advanced Visual Interfaces, AVI 2020 ; Conference Date: 28 September 2020 Through 2 October 2020; Conference Code:163613</p>","","","Deep learning; User experience; Controlled experiment; Physiological models; Subjective evaluations; User emotions; Physiological parameters; Body postures; Interactive applications; Performance measurements; Software design; User characteristics","","Tortora G., Winckler M., Vitiello G.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSQKUNJW","conferencePaper","2020","Sohrab, F.; Raitoharju, J.; Gabbouj, M.","Facial expression based satisfaction index for empathic buildings","UbiComp/ISWC 2020 Adjunct - Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers","978-1-4503-8076-8","","10.1145/3410530.3414443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091836628&doi=10.1145%2f3410530.3414443&partnerID=40&md5=64269f8f653ba11edfb095c8a5fa582e","In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings. © 2020 ACM.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","704-707","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and 2020 ACM International Symposium on Wearable Computers, UbiComp/ISWC 2020 ; Conference Date: 12 September 2020 Through 17 September 2020; Conference Code:162964</p>","","","Intelligent buildings; Face recognition; Facial Expressions; Facial expression recognition; Wearable computers; Ubiquitous computing; Automatic facial expression recognition; Building environment; Building platforms; Light intensity; Tampere; Working stations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDF97RLT","conferencePaper","2020","Pollmann, K.; Ziegler, D.","Personal quizmaster: A pattern approach to personalized interaction experiences with the MiRo robot","ACM International Conference Proceeding Series","978-1-4503-7540-5","","10.1145/3404983.3410414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091771263&doi=10.1145%2f3404983.3410414&partnerID=40&md5=9ec79575623cc2dfc31dbfba2af27c7b","In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes. © 2020 Owner/Author.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","485-489","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 1; Conference of 2020 Conference on Mensch und Computer, MuC 2020 ; Conference Date: 6 September 2020 Through 9 September 2020; Conference Code:162854</p>","","","Social robots; Wizard of Oz; User experience; Behavioral patterns; Interaction experiences; Design Patterns; Interaction model; Interactive video; Personalizations; Technical background","","Alt F., Hornecker E., Schneegass S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQRPMBSH","journalArticle","2020","Sumitani, M.; Osumi, M.; Abe, H.; Azuma, K.; Tsuchida, R.; Sumitani, M.","A robot has a mind of its own because we intuitively share it","Applied Sciences (Switzerland)","","20763417","10.3390/APP10186531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092052101&doi=10.3390%2fAPP10186531&partnerID=40&md5=a762af7a2f4504e3ab0a34c226cec3de","People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we 'share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent). © 2020 by the authors.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","","","18","10","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I9VXNRW4","journalArticle","2020","Blechar, L.; Zalewska, P.","The role of robots in the improving work of nurses","Pielegniarstwo XXI Wieku","","17301912","10.2478/pielxxiw-2019-0026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078406987&doi=10.2478%2fpielxxiw-2019-0026&partnerID=40&md5=d88831d66d344bb1b7e2098f3f5b0133","Introduction. Currently we observe a change in the labor market. It is caused by the new developments in the field of artificial Intelligence. Aim. We would like to present current trends affecting the work of nurses and midwives around the world in order to raise the social awareness of these changes among Polish healthcare workers. Moreover, we want to emphasize the fact that it is necessary to involve them as the stakeholders in the ongoing discussions and research projects in order to better understand their needs and expectations. Discussion. The article revolves around the current state of technology. We begin by outlining the framework of the perceived changes in the nurses' structures and tasks around the world. Then we provide the examples of a variety of robots already executing those tasks. We start with the robots whose purpose is the elimination of simple, routine activities such as TUG or HOMER. After doing so, we move on to possible solutions how to eliminate the need for personal involvement in invasive (such as BloodBot) and non-invasive procedures (CLARA). We finish by introducing the machines used to replicate animal therapy, which can be used to treat patients who have difficulties with communicating their needs. Conclusions. We would like to present the future of nursing closely related to machines. We want to emphasize the element of complementarity of this relation and the fact that performing some tasks by robots is not connected with replacing people, but rather with enabling them to shift their focus from the performance of arduous duties to spending more time on empathic work with the patient. © 2019 Łukasz Blechar et al., published by Sciendo.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","174-182","","3","18","","","","","","","","","","English; Polish","","","","","","","Publisher: Sciendo","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJAUP5BF","journalArticle","2020","Casas-Bocanegra, D.; Gomez-Vargas, D.; Pinto-Bernal, M.J.; Maldonado, J.; Munera, M.; Villa-Moreno, A.; Stoelen, M.F.; Belpaeme, T.; Cifuentes, C.A.","An open-source social robot based on compliant soft robotics for therapy with children with ASD","Actuators","","20760825","10.3390/act9030091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091488098&doi=10.3390%2fact9030091&partnerID=40&md5=dc856e58ed58106d604f91635b9c107a","Therapy with robotic tools is a promising way to help improve verbal and nonverbal communication in children. The robotic tools are able to increase aspects such as eye contact and the ability to followinstructions and to empathizewith others. Thiswork presents the designmethodology, development, and experimental validation of a novel social robot based on CompliAnt SofT Robotics called the CASTOR robot, which intends to be used as an open-source platform for the long-term therapy of children with autism spectrum disorder (CwASD). CASTOR integrates the concepts of soft actuators and compliant mechanisms to create a replicable robotic platform aimed at real therapy scenarios involving physical interaction between the children and the robot. The validation shows promising results in terms of robustness and the safety of the user and robot. Likewise, mechanical tests assess the robot's response to blocking conditions for two critical modules (i.e., neck and arm) in interaction scenarios. Future works should focus on the validation of the robot's effectiveness in the therapy of CwASD. © 2020 by the authors.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","","","3","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQM62CDW","journalArticle","2020","Sakurai, E.; Kurashige, K.; Tsuruta, S.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.; Frati, F.","Embodiment matters: toward culture-specific robotized counselling","Journal of Reliable Intelligent Environments","","21994668","10.1007/s40860-020-00109-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087487620&doi=10.1007%2fs40860-020-00109-y&partnerID=40&md5=bbf9e8b747887c35e9498c0749840555","In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","129-139","","3","6","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUEFG55T","journalArticle","2020","Ireland, A.","A posthuman ecology of simulated human patients: Eidolons, empathy and fidelity in the uncanny embodiment of nursing practice","Explorations in Media Ecology","","15397785","10.1386/eme_00048_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100739027&doi=10.1386%2feme_00048_1&partnerID=40&md5=e591392271d2b1f4a60b842766fc47cd","The reproduction of the human form has been a universal practice amongst human ecologies for millennia. Over the past 200 years, popular culture has considered the imaginary consequences of the danger to humanity and human-ness of replicating the autonomous human form too faithfully. Today, the seductive allure of technologically advanced simulated human bodies and advances in robotics and artificial intelligence has brought us closer to facing this possibility. Alongside the simultaneous aversion and fascination of the possibility that autonomous simulated human forms may become indistinguishable from human beings is the deep-rooted uncanniness of the automaton in its strange familiarity – not only to ourselves but to our pleasant childhood imaginings of playing with dolls. As such, simulated human bodies are often enrolled in medical and nursing education models with the assumption that making the simulation teaching spaces seem as close to clinical spaces as possible will allow students to practise potentially harmful clinical skills without causing any harm to human patients. However similar the simulated human bodies may appear to a living, breathing human, a tension between the embodiment of particularly human attributes and their replication persists. How can computerized human patient simulators be enrolled to teach people to develop the necessary attributes of compassion and empathy when caring for human beings? This article explores the uncanny ecologies of simulated human patients in nursing education by presenting a posthuman analysis of the practices of nurse educators as they enrol these digital objects in their teaching. Guided by a selection of heuristics offered as a mode of interviewing digital objects, the analysis enrolled ‘Gathering Anecdotes’ and ‘Unravelling Translations’ to attune to the ways in which these uncanny posthuman assemblages become powerful modes of knowing to mobilize learning about human attributes within uncanny posthuman ecologies. © 2020 Intellect Ltd Article.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","299-318","","3","19","","","","","","","","","","English","","","","","","","Publisher: Intellect Ltd.","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z24HW8JZ","journalArticle","2020","Ranjbartabar, H.; Richards, D.; Bilgin, A.A.; Kutay, C.; Mascarenhas, S.","Adapting a virtual advisor’s verbal conversation based on predicted user preferences: A study of neutral, empathic and tailored dialogue","Multimodal Technologies and Interaction","","24144088","10.3390/mti4030055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090258978&doi=10.3390%2fmti4030055&partnerID=40&md5=f8479bf5d6189de6e0a5974e5738d391","Virtual agents that improve the lives of humans need to be more than user-aware and adaptive to the user’s current state and behavior. Additionally, they need to apply expertise gained from experience that drives their adaptive behavior based on deep understanding of the user’s features (such as gender, culture, personality, and psychological state). Our work has involved extension of FAtiMA (Fearnot AffecTive Mind Architecture) with the addition of an Adaptive Engine to the FAtiMA cognitive agent architecture. We use machine learning to acquire the agent’s expertise by capturing a collection of user profiles into a user model and development of agent expertise based on the user model. In this paper, we describe a study to evaluate the Adaptive Engine, which compares the benefit (i.e., reduced stress, increased rapport) of tailoring dialogue to the specific user (Adaptive group) with dialogues that are either empathic (Empathic group) or neutral (Neutral group). Results showed a significant reduction in stress in the empathic and neutral groups, but not the adaptive group. Analyses of rule accuracy, participants’ dialogue preferences, and individual differences reveal that the three groups had different needs for empathic dialogue and highlight the importance and challenges of getting the tailoring right. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","1-24","","3","4","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9ZEE7L2","journalArticle","2020","Ivkov, M.; Blešić, I.; Dudić, B.; Bartáková, G.P.; Dudić, Z.","Are future professionals willing to implement service robots? Attitudes of hospitality and tourism students towards service robotization","Electronics (Switzerland)","","20799292","10.3390/electronics9091442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093903132&doi=10.3390%2felectronics9091442&partnerID=40&md5=0042f4d6afbcca5932415c05a7c3f97f","This paper aims to examine attitudes of hospitality and tourism students, as future professionals, towards willingness to implement service robots. The study proposes a new theoretical conceptual model that includes new constructs and items, differentiating it from the others. The model was formed based on the extensive literature review and the interview with an eight-member focus group (hotel managers and academic researchers). Data collection was performed in two stages, pilot research based on 82 respondents and the main study, with the final number of respondents being 236. The initial results of the exploratory factor analysis were further tested using the confirmatory factor analysis. After the exclusion of several items due to low factor loadings and in order to improve model validity, analyses further suggested a nine-dimensional solution with 45 items. The study findings reveal a positive relationship between seven constructs and students’ willingness to implement service robots, with the expected business outcome being the most influencing one. On the other hand, positive relation was not found for empathy and social influence constructs. Theoretical contributions and practical implications are discussed in the paper. In conclusion, study limitations and future research suggestions are provided. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","1-16","","9","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMIZKEJN","journalArticle","2020","Sarkadi; Casmana, A.R.; Cahyana, U.; Paristiowati, M.","The Application of Mobile Learning for University Students in the Pancasila Education Modul in Developing Character of Students' Empathy","Universal Journal of Educational Research","","23323205","10.13189/ujer.2020.080905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090322563&doi=10.13189%2fujer.2020.080905&partnerID=40&md5=6b590515ca55be0e70b759af8a00a634","The main purpose of this study is to improve students’ empathy attitudes in Pancasila education courses using applications in mobile phones. It is a tool application or media that is used by educators to be able to transfer knowledge to their students. This is used to be able to increase the interaction and learning motivation of students, so they can obtain maximum learning resources. The name of the application is Pancasila Mobile learning, and it is available on Playstore for Android users and web-based page. Meanwhile, the empathy characters need to be developed by the school to be able to grow in students. As such, this study focuses on growing empathy by using mobile learning applications. The research method used is quantitative. The data collection technique used was an online questionnaire, which was filled by 119 students at universities in Jakarta. They are students who have already or are studying Pancasila in college. The results of this study indicate that the use of mobile learning applications in learning Pancasila in the classroom can increase empathy attitudes towards students. They can carry out positive activities, and feel pleasure and comfort when using mobile learning applications in the learning process. Thus, the use of mobile learning needs to be continuously developed by educators both in universities and schools. Copyright ©2020 by authors, all rights reserved.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","3825-3833","","9","8","","","","","","","","","","English","","","","","","","Publisher: Horizon Research Publishing","<p>cited By 0</p>","","","e-learning; education; empathy; data analysis; questionnaire; human; human experiment; Article; normal human; character; descriptive research; Indonesian; information processing; mobile application; quantitative study; university student","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJUE7NRQ","journalArticle","2020","Sakamoto, T.; Yamashita, H.; Goto, M.; Iwanaga, J.","Model for relational analysis of posted articles and reactions on restaurant guide sites","Industrial Engineering and Management Systems","","15987248","10.7232/iems.2020.19.3.669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093862693&doi=10.7232%2fiems.2020.19.3.669&partnerID=40&md5=fdb2e6a9bbce1d4cf8653879ff665693","Recently, restaurant guide sites providing restaurant information posted by users on the Internet have been widely used as effective tools for consumers. Users, on a restaurant guide site, utilize IDs to post their recommendation articles on restaurants, and these posted articles are a valuable information source for other users. Open users can search for restaurants and read recommendation articles posted by other users. Furthermore, they can react (e.g., “like”) to a recommendation article when they feel it is helpful or they feel like visiting the restaurant. On a target restaurant guide site, each post includes the user ID, restaurant name, recommendation sentences, etc., and the number of reactions is considered to depend on these posted contents. For users who post recommendation articles, the number of reactions to their posts represents the degree of empathy from other users and is an important motivation for posting. Therefore, posting users will benefit from guidelines on how to write good recommendation sentences to increase the number of reactions. Moreover, the number of reactions can be regarded as an important indicator of the activity level of the restaurant guide site from the viewpoint of the service operating company. Therefore, an analytical model developed using historical information such as posts and reactions by users would be useful for determining the relationship between posted contents and the number of reactions. Therefore, this paper proposes a model based on the machine learning approach to analyze the relation between the number of reactions and posted contents. Finally, we demonstrate the analysis based on the proposed model using practical data. © 2020 KIIE","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","669-679","","3","19","","","","","","","","","","English","","","","","","","Publisher: Korean Institute of Industrial Engineers","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BH4SFE23","conferencePaper","2020","Corretjer, M.G.; Ros, R.; Martin, F.; Miralles, D.","The Maze of Realizing Empathy with Social Robots","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","978-1-72816-075-7","","10.1109/RO-MAN47096.2020.9223466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095760531&doi=10.1109%2fRO-MAN47096.2020.9223466&partnerID=40&md5=0898316eb3582aa6430fa85f72edb83b","Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy. © 2020 IEEE.","2020","2021-05-19 13:26:11","2021-05-19 13:26:11","","1334-1339","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:164066</p>","","","Social robots; Agricultural robots; Affective state; Basic elements; Equipment testing; Intelligent agents; Key elements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMRKHH2D","conferencePaper","2020","Cinieri, S.; Kapralos, B.; Uribe-Quevedo, A.; Lamberti, F.","Eye Tracking and Speech Driven Human-Avatar Emotion-Based Communication","2020 IEEE 8th International Conference on Serious Games and Applications for Health, SeGAH 2020","978-1-72819-042-6","","10.1109/SeGAH49190.2020.9201874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092743436&doi=10.1109%2fSeGAH49190.2020.9201874&partnerID=40&md5=69a18548064c1ffc5d460cba2c56c51d","Feelings, emotions, and empathy play an important role in many daily activities including verbal and non-verbal communication. Their automatic recognition and interpretation is important in a variety of applications requiring communication skills that are difficult to reproduce in computer-simulated environments, including those involving human-avatar interactions. Our recent work has begun investigating the development of intelligent avatars capable of detecting user (human) emotions to allow for realistic human-avatar interactions within medical-based virtual simulations and serious games. In this paper, we present a system that couples eye tracking and dialogue interpretation to allow for intelligent and realistic human-avatar communication. Although formal testing is required, preliminary results are promising, showing the potential of the system. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 8th IEEE International Conference on Serious Games and Applications for Health, SeGAH 2020 ; Conference Date: 12 August 2020 Through 14 August 2020; Conference Code:163264</p>","","","Serious games; Speech recognition; Communication skills; Human computer interaction; Automatic recognition; Avatar communications; Avatar interaction; Daily activity; Eye tracking; Non-verbal communications; Simulated environment; Speech communication; Virtual simulations","","Rodrigues N., Duque D., Smith R., Dias N., Vilaca J.L., Qayumi K., Oliveira E.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"236BFPVA","conferencePaper","2020","Perusquia-Hemandez, M.; Balda, M.C.; Gomez Jauregui, D.A.; Paez-Granados, D.; Dollack, F.; Salazar, J.V.","Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","978-1-72816-075-7","","10.1109/RO-MAN47096.2020.9223598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095745482&doi=10.1109%2fRO-MAN47096.2020.9223598&partnerID=40&md5=f2b4aa17536e3404041a17e644e85abf","Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","1328-1333","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:164066</p>","","","Social robots; Artificial agents; Wearable technology; Agricultural robots; Machine design; Affective state; Affective representations; Haptic feedbacks; Undesired behavior; Visual representations; Wearable prototypes; Wearable systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3CND2JS","conferencePaper","2020","Wang, Z.","Future challenges in the next generation of voice user interface","Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020","978-1-72817-106-7","","10.1109/CDS49703.2020.00045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098868220&doi=10.1109%2fCDS49703.2020.00045&partnerID=40&md5=5242ff50af9fa8ad1855ea7df90463e7","With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI. © 2020 IEEE","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","191-193","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 2020 International Conference on Computing and Data Science, CDS 2020 ; Conference Date: 1 August 2020 Through 2 August 2020; Conference Code:165680</p>","","","Artificial intelligence; Artificial intelligence technologies; Key elements; Data Science; Future challenges; User interfaces; Voice user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6TTTU7H","conferencePaper","2020","Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.","Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","978-1-72816-075-7","","10.1109/RO-MAN47096.2020.9223442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095730396&doi=10.1109%2fRO-MAN47096.2020.9223442&partnerID=40&md5=ac2ec563cda67bf4704bb20f32ef0b07","In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","653-658","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:164066</p>","","","Social robots; Agricultural robots; Dialogue strategy; Human robots; Intention to use; Likert scale; Privacy issue; Privacy problems; Private information; User interests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32Z4SDMP","conferencePaper","2020","Ye, S.; Feigh, K.; Howard, A.","Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","978-1-72816-075-7","","10.1109/RO-MAN47096.2020.9223437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095735091&doi=10.1109%2fRO-MAN47096.2020.9223437&partnerID=40&md5=74bfb142371d9fab0e75afbaa05d3b0c","Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","1186-1189","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:164066</p>","","","Cognitive science; Social robots; Humanoid robot; Embodied cognition; Agricultural robots; Man machine systems; Anthropomorphic robots; Dynamic interaction; Greek letters; Human perspectives; Touch screens","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RX65HKXL","conferencePaper","2020","Rossi, S.; Dell'aquila, E.; Russo, D.; Maggi, G.","Increasing Engagement with Chameleon Robots in Bartending Services","29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020","978-1-72816-075-7","","10.1109/RO-MAN47096.2020.9223488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095753002&doi=10.1109%2fRO-MAN47096.2020.9223488&partnerID=40&md5=a440efcfee2d66eaa8d58c44e958ffcd","As the field of service robotics has been rapidly growing, it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way. This is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users' experience. In this paper, we address the question of whether a specific behavioral style of a barman-robot, acted through para-verbal and non-verbal behaviors, can affect users' engagement and the creation of positive emotions. To that end, we endowed a barman-robot taking drink orders from human customers, with an empathic behavioral style. This aims at triggering to alignment process by mimicking the conversation partner's behavior. This behavioral style is compared to an entertaining style, aiming at creating a positive relationship with the users, and a neutral style for control. Results suggest that when participants experienced more positive emotions, the robot was perceived as safer, so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement. Indeed, when the empathic robot modulates its behavior according to the user's one, this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in public-service contexts. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","464-469","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:164066</p>","","","Social robots; User experience; Nonverbal behavior; Agricultural robots; Behavioral research; Customer relationships; Public relations; Affective interaction; Bartending; Positive emotions; Public services; Service robotics; Users' experiences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYL2LCA8","conferencePaper","2020","Girardi, D.; Ferrari, A.; Novielli, N.; Spoletini, P.; Fucci, D.; Huichapa, T.","The Way it Makes you Feel Predicting Users' Engagement during Interviews with Biofeedback and Supervised Learning","Proceedings of the IEEE International Conference on Requirements Engineering","978-1-72817-438-9","","10.1109/RE48521.2020.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093954079&doi=10.1109%2fRE48521.2020.00016&partnerID=40&md5=72a48c869a7323b1162ad07376d168d7","Capturing users' engagement is crucial for gathering feedback about the features of a software product. In a market-driven context, current approaches to collect and analyze users' feedback are based on techniques leveraging information extracted from product reviews and social media. These approaches are hardly applicable in bespoke software development, or in contexts in which one needs to gather information from specific users. In such cases, companies need to resort to face-To-face interviews to get feedback on their products. In this paper, we propose to utilize biofeedback to complement interviews with information about the engagement of the user on the discussed features and topics. We evaluate our approach by interviewing users while gathering their biometric data using an Empatica E4 wristband. Our results show that we can predict users' engagement by training supervised machine learning algorithms on the biometric data. The results of our work can be used to facilitate the prioritization of product features and to guide the interview based on users' engagement. © 2020 IEEE.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","32-43","","","2020-August","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 1090705X","<p>cited By 0; Conference of 28th IEEE International Requirements Engineering Conference, RE 2020 ; Conference Date: 31 August 2020 Through 4 September 2020; Conference Code:163887</p>","","","Surveys; Learning algorithms; Supervised learning; Supervised machine learning; Requirements engineering; Biometrics; Biofeedback; Software design; Biometric data; Face-to-face interview; Market driven; Prioritization; Product feature; Product reviews; Software products","","Breaux T., Glinz M., Zisman A., Fricker S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55XRDMM8","conferencePaper","2020","Patro, K.; Rathore, P.S.","A sociolinguistic route to the characterization and detection of the credibility of events on twitter","Proceedings of the 31st ACM Conference on Hypertext and Social Media, HT 2020","978-1-4503-7098-1","","10.1145/3372923.3404795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089516445&doi=10.1145%2f3372923.3404795&partnerID=40&md5=86ad6588a315d37ddc51ad57b1a75638","Although Twitter constitutes as one of the primary sources of real-time news with users acting as the sensors updating the content from all across the globe, yet the spread of rumours via Twitter is becoming an increasingly alarming issue and is known to have caused significant damage already. We propose a credibility analysis approach based on the linguistic structure of the tweets. We not only characterize the Twitter events but also predict their perceived credibility of them by a novel deep learning architecture. We use the huge CREDBANK data to conduct our experiments. Some of our exciting findings are that standard LIWC categories like 'negate', 'discrep', 'cogmech', 'swear' and the Empath categories like 'hate', 'poor', 'government', 'worship' and 'swearing-terms' correlate negatively with the credibility of events. While some of our results resonate with the earlier literature others represent novel insights of the fake and legitimate twitter events. Using the above observations and the current deep learning architecture we predict the credibility of an event (a four-class classification problem in our case) with an accuracy of 0.54 that improves the best-known state-of-the-art (current accuracy 0.43) by ∼ 26%. A fascinating observation is that even by looking at the first few tweets of an event, it is possible to make the prediction almost as accurate as in the case where the entire volume of tweets is observed. © 2020 ACM.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","241-250","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 31st ACM Conference on Hypertext and Social Media, HT 2020 ; Conference Date: 13 July 2020 Through 15 July 2020; Conference Code:161736</p>","","","Deep learning; Linguistics; Forecasting; Real time; Social networking (online); State of the art; Classification (of information); Analysis approach; Hypertext systems; Learning architectures; Linguistic structure; Primary sources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K99ZD65X","conferencePaper","2020","Chen, Z.; Lu, Y.; Nieminen, M.P.; Lucero, A.","Creating a chatbot for and with migrants: Chatbot personality drives co-design activities","DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference","978-1-4503-6974-9","","10.1145/3357236.3395495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090504800&doi=10.1145%2f3357236.3395495&partnerID=40&md5=f1462d9b4b9746c6d634685538c4ee2d","Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria. © 2020 Owner/Author.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","219-230","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 2020 ACM Conference on Designing Interactive Systems, DIS 2020 ; Conference Date: 6 July 2020 Through 10 July 2020; Conference Code:161555</p>","","","Surveys; Co-design approach; Design criteria; Information overloads; Information portals; Information seeking; Information seeking process; Information use; Online questionnaire; Social integrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GGKGEL7J","conferencePaper","2020","Bulagang, A.F.; Mountstephens, J.; Wi, J.T.T.","Tuning Support Vector Machines for Improving Four-Class Emotion Classification in Virtual Reality (VR) using Heart Rate Features","Journal of Physics: Conference Series","","","10.1088/1742-6596/1529/5/052069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087438376&doi=10.1088%2f1742-6596%2f1529%2f5%2f052069&partnerID=40&md5=3186b9548a5feb222e499101b65ba24c","The main objective of this paper is to conduct three experiments using Support Vector Machine (SVM) with different parameter settings to find and compare the accuracy of each SVM setting. Heart rate (HR) signals were collected with a medical-grade wearable heart rate monitor from Empatica (E4 Wristband) and processed using the Empatica Realtime Monitor application during this investigation. HR was employed as the method to capture the test subjects' physiological signals via plethysmography. The three experiments were conducted using a wrist-worn monitor to gain HR signal, and a VR Headset for subjects to view 360 degrees video stimuli. A total of 10 subjects participated in this experiment. Data from the 10 subjects were then processed with Python with SVM. The data was classified for four distinct emotion classes using both inter-subject classification and intra-subject classification testing approaches, with inter-subject classification yielding an accuracy of 53.39% while intra-subject classification ranges from 56.92% to 86.15%. These results demonstrate the potential of achieving higher accuracy results using different parameter settings via the use of HR as the input feature to the machine learning classifier, which appears to be a promising sensor modality for four-class emotion classification in virtual reality using wearable technology. © 2020 IOP Publishing Ltd. All rights reserved.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","","","","1529","","","","","","","","Institute of Physics Publishing","","English","","","","","","","ISSN: 17426588 Issue: 5","<p>cited By 0; Conference of 2nd Joint International Conference on Emerging Computing Technology and Sports, JICETS 2019 ; Conference Date: 25 November 2019 Through 27 November 2019; Conference Code:161273</p>","","","Virtual reality; Wearable technology; Emotion classification; Learning systems; Support vector machines; Classification (of information); Biomedical signal processing; Heart; Heart-rate monitors; Input features; Parameter setting; Patient monitoring; Physiological signals; Real-time monitor; Sensor modality; Sports; Subject classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGSSUGPM","journalArticle","2020","de Kervenoael, R.; Hasan, R.; Schwob, A.; Goh, E.","Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors’ intentions to use social robots","Tourism Management","","02615177","10.1016/j.tourman.2019.104042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075628508&doi=10.1016%2fj.tourman.2019.104042&partnerID=40&md5=f56ef158af2d44659553121590311519","Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies. © 2019 Elsevier Ltd","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","","","","78","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 22</p>","","","artificial intelligence; robotics; conceptual framework; ecotourism; hospitality industry; numerical model; service quality; Singapore [Southeast Asia]; tourism management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SICU2W56","journalArticle","2020","Rossi, S.; Conti, D.; Garramone, F.; Santangelo, G.; Staffa, M.; Varrasi, S.; Di Nuovo, A.","The role of personality factors and empathy in the acceptance and performance of a social robot for psychometric evaluations","Robotics","","22186581","10.3390/ROBOTICS9020039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086668483&doi=10.3390%2fROBOTICS9020039&partnerID=40&md5=c2ec5388361d460022f6c3d10f29ebcb","Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the ""openness to experience"", on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests. © 2020 by the authors.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","","","2","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UTFVV3X","conferencePaper","2020","Svoren, H.; Thambawita, V.; Halvorsen, P.; Jakobsen, P.; Garcia-Ceja, E.; Noori, F.M.; Hammer, H.L.; Lux, M.; Riegler, M.A.; Hicks, S.A.","Toadstool: A dataset for training emotional intelligent machines playing Super Mario Bros","MMSys 2020 - Proceedings of the 2020 Multimedia Systems Conference","978-1-4503-6845-2","","10.1145/3339825.3394939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086766534&doi=10.1145%2f3339825.3394939&partnerID=40&md5=b3f4379d504e2eab563bd4d2a31ddc20","Games are often defined as engines of experience, and they are heavily relying on emotions, they arouse in players. In this paper, we present a dataset called Toadstool as well as a reproducible methodology to extend on the dataset. The dataset consists of video, sensor, and demographic data collected from ten participants playing Super Mario Bros, an iconic and famous video game. The sensor data is collected through an Empatica E4 wristband, which provides high-quality measurements and is graded as a medical device. In addition to the dataset and the methodology for data collection, we present a set of baseline experiments which show that we can use video game frames together with the facial expressions to predict the blood volume pulse of the person playing Super Mario Bros. With the dataset and the collection methodology we aim to contribute to research on emotionally aware machine learning algorithms, focusing on reinforcement learning and multimodal data fusion. We believe that the presented dataset can be interesting for a manifold of researchers to explore exciting new interdisciplinary questions. © 2020 ACM.","2020","2021-05-19 13:26:12","2021-05-19 13:26:12","","309-314","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 11th ACM Multimedia Systems Online Conference, MMSys 2020 ; Conference Date: 8 June 2020 Through 11 June 2020; Conference Code:160186</p>","","","Reinforcement learning; Learning algorithms; Facial Expressions; Human computer interaction; Intelligent machine; Multimedia systems; Blood volume pulse; Data fusion; Demographic data; High-quality measurements; Medical Devices; Multimodal data fusion; Online systems; Super Mario Bros","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4NUXXLU","journalArticle","2020","Howard, D.; Maslej, M.M.; Lee, J.; Ritchie, J.; Woollard, G.; French, L.","Transfer learning for risk classification of social media posts: Model evaluation study","Journal of Medical Internet Research","","14388871","10.2196/15371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084692930&doi=10.2196%2f15371&partnerID=40&md5=3e06d03127688661c2d5c846a1c566f4","Background: Mental illness affects a significant portion of the worldwide population. Online mental health forums can provide a supportive environment for those afflicted and also generate a large amount of data that can be mined to predict mental health states using machine learning methods. Objective: This study aimed to benchmark multiple methods of text feature representation for social media posts and compare their downstream use with automated machine learning (AutoML) tools. We tested on datasets that contain posts labeled for perceived suicide risk or moderator attention in the context of self-harm. Specifically, we assessed the ability of the methods to prioritize posts that a moderator would identify for immediate response. Methods: We used 1588 labeled posts from the Computational Linguistics and Clinical Psychology (CLPsych) 2017 shared task collected from the Reachout.com forum. Posts were represented using lexicon-based tools, including Valence Aware Dictionary and sEntiment Reasoner, Empath, and Linguistic Inquiry and Word Count, and also using pretrained artificial neural network models, including DeepMoji, Universal Sentence Encoder, and Generative Pretrained Transformer-1 (GPT-1). We used Tree-based Optimization Tool and Auto-Sklearn as AutoML tools to generate classifiers to triage the posts. Results: The top-performing system used features derived from the GPT-1 model, which was fine-tuned on over 150,000 unlabeled posts from Reachout.com. Our top system had a macroaveraged F1 score of 0.572, providing a new state-of-the-art result on the CLPsych 2017 task. This was achieved without additional information from metadata or preceding posts. Error analyses revealed that this top system often misses expressions of hopelessness. In addition, we have presented visualizations that aid in the understanding of the learned classifiers. Conclusions: In this study, we found that transfer learning is an effective strategy for predicting risk with relatively little labeled data and noted that fine-tuning of pretrained language models provides further gains when large amounts of unlabeled text are available. © Derek Howard, Marta M Maslej, Justin Lee, Jacob Ritchie, Geoffrey Woollard, Leon French.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","5","22","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 3</p>","","","Humans; machine learning; social media; model; automation; mental health; risk assessment; Mental Health; human; Article; information processing; software; automutilation; metadata; Risk Assessment; Social Media; suicide","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35ISQV7R","journalArticle","2020","Hooyer, K.; Ruffalo, L.; Franco, Z.","Tracings of trauma: Engaging learners and challenging veteran stigma through collaborative research-based theater","Journal of Higher Education Outreach and Engagement","","15346102","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084578722&partnerID=40&md5=6002785a2191f4351dca285289f6a9d1","Military veterans are stereotyped in the media as either broken human beings or invincible heroes, often creating implicit bias and affecting medical providers' ability to establish trusting relationships. Interactive learning methods can challenge stigma and create empathic connections with veterans in a manner that conveys sensitivity. Communityengaged theater has been successfully used in health education to transfer knowledge on both emotional and cognitive levels. This article reports on a research-based theater intervention, Tracings of Trauma, codesigned by veterans and aimed at orienting medical/allied health students to the unique experiences of combat veterans. Early stage assessment demonstrated statistically significant improvement in students' self-perceived awareness of stigma and their ability to talk to veterans and empathize with veterans' experiences. Results suggest that interactive, performance-driven dissemination can provide deeper learning experiences regarding stigmatized groups who experience trauma. Evaluating long-term impact on practice will be critical in linking this intervention to clinical outcomes. © 2020 by the University of Georgia.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","127-142","","1","24","","","","","","","","","","English","","","","","","","Publisher: University of Georgia","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGT4CHZV","conferencePaper","2020","Ahn, Y.; Zhang, Y.; Park, Y.; Lee, J.","A chatbot solution to chat app problems: Envisioning a chatbot counseling system for teenage victims of online sexual exploitation","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-6819-3","","10.1145/3334480.3383070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090204199&doi=10.1145%2f3334480.3383070&partnerID=40&md5=56ff72e5e3d1f979f7410f7abca8fc9c","In recent years, online sexual exploitation targeting teenagers has been on the rise. Given teenagers' growing reluctance toward face-to-face communication, using a counseling chatbot could be a more effective way to provide teenage victims with necessary information and emotional support. There is a small number of counseling chatbots for victims of sexual crime, but none targeting teenagers specifically. This research suggests design guidelines for building a counseling chatbot for teenage victims of online sexual exploitation with a focus on establishing rapport by empathizing with their stories and providing them with the proper information. We conducted in-depth interviews with peer counselors at the Teenage Women's Human Rights Center, who have been consulting teenage victims in their age group using online messengers. The four key findings from our research suggested using open-ended questions, using teenager-friendly language, helping teenagers understand that they are victims and offering age-relevant information. © 2020 Owner/Author.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 2020 ACM CHI Conference on Human Factors in Computing Systems, CHI EA 2020 ; Conference Date: 25 April 2020 Through 30 April 2020; Conference Code:160405</p>","","","Chatbots; Chatbot; Human engineering; Human rights; Emotional supports; Age groups; Face-to-face communications; In-depth interviews; Open-ended questions; Software engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TB8G7IP2","conferencePaper","2020","Xiao, Z.; Zhou, M.X.; Chen, W.; Yang, H.; Chi, C.","If i Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-6708-0","","10.1145/3313831.3376131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091298502&doi=10.1145%2f3313831.3376131&partnerID=40&md5=fa591edf08fae5f9c2b8e589115c914d","Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-The abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks. © 2020 ACM.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 4; Conference of 2020 ACM CHI Conference on Human Factors in Computing Systems, CHI 2020 ; Conference Date: 25 April 2020 Through 30 April 2020; Conference Code:160500</p>","","","Surveys; Chatbots; Chatbot; User experience; AI Technologies; Human engineering; Open-ended questions; Active listening; Design implications; Free texts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q88W8SL6","conferencePaper","2020","Troiano, G.M.; Wood, M.; Harteveld, C.","""and This, Kids, Is How i Met Your Mother"": Consumerist, Mundane, and Uncanny Futures with Sex Robots","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-6708-0","","10.1145/3313831.3376598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091290084&doi=10.1145%2f3313831.3376598&partnerID=40&md5=9bd687aac056f57a4fa6ddbaefa19201","Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM. © 2020 ACM.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 2; Conference of 2020 ACM CHI Conference on Human Factors in Computing Systems, CHI 2020 ; Conference Date: 25 April 2020 Through 30 April 2020; Conference Code:160500</p>","","","Robots; Machine design; Economic and social effects; Human engineering; Completion methods; Critical design; Multiple perspectives; Science fictions; Social impact; Thematic analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGMMM3L6","conferencePaper","2020","Toxtli, C.; Richmond-Fuller, A.; Savage, S.","Reputation Agent: Prompting Fair Reviews in Gig Markets","The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","978-1-4503-7023-3","","10.1145/3366423.3380199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589321&doi=10.1145%2f3366423.3380199&partnerID=40&md5=8235c305e0974c8f0c5d3911f16d1058","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker's control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker's control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers' performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers. © 2020 ACM.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","1228-1240","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 29th International World Wide Web Conference, WWW 2020 ; Conference Date: 20 April 2020 Through 24 April 2020; Conference Code:160505</p>","","","Deep learning; Commerce; Controlled experiment; Intelligent interface; Job opportunities; Traditional approaches; Transparency; Workers'; World Wide Web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L46JMUAL","journalArticle","2020","Kerasidou, A.","Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare [L'intelligence artificielle et le besoin constant d’empathie, de compassion et de confiance dans le secteur de la santé] [La inteligencia artificial y la continua necesidad de empatía, compasión y confianza en la atención sanitaria]","Bulletin of the World Health Organization","","00429686","10.2471/BLT.19.237198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083246717&doi=10.2471%2fBLT.19.237198&partnerID=40&md5=cb5246773745079c64d8a27e85022353","Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote. © 2020, World Health Organization. All rights reserved.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","245-250","","4","98","","","","","","","","","","English","","","","","","","Publisher: World Health Organization","<p>cited By 4</p>","","","Humans; artificial intelligence; Artificial Intelligence; Empathy; empathy; trust; Trust; health care; article; human; adult; Delivery of Health Care; detection method; health care delivery; health care system; public health; vision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2KSZ5NHF","journalArticle","2020","Hauser-Ulrich, S.; Künzli, H.; Meier-Peterhans, D.; Kowatsch, T.","A smartphone-based health care chatbot to promote self-management of chronic pain (SELMA): Pilot randomized controlled trial","JMIR mHealth and uHealth","","22915222","10.2196/15806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083041276&doi=10.2196%2f15806&partnerID=40&md5=1bdea439df11e79c08a569809ef29092","Background: Ongoing pain is one of the most common diseases and has major physical, psychological, social, and economic impacts. A mobile health intervention utilizing a fully automated text-based health care chatbot (TBHC) may offer an innovative way not only to deliver coping strategies and psychoeducation for pain management but also to build a working alliance between a participant and the TBHC. Objective: The objectives of this study are twofold: (1) to describe the design and implementation to promote the chatbot painSELfMAnagement (SELMA), a 2-month smartphone-based cognitive behavior therapy (CBT) TBHC intervention for pain self-management in patients with ongoing or cyclic pain, and (2) to present findings from a pilot randomized controlled trial, in which effectiveness, influence of intention to change behavior, pain duration, working alliance, acceptance, and adherence were evaluated. Methods: Participants were recruited online and in collaboration with pain experts, and were randomized to interact with SELMA for 8 weeks either every day or every other day concerning CBT-based pain management (n=59), or weekly concerning content not related to pain management (n=43). Pain-related impairment (primary outcome), general well-being, pain intensity, and the bond scale of working alliance were measured at baseline and postintervention. Intention to change behavior and pain duration were measured at baseline only, and acceptance postintervention was assessed via self-reporting instruments. Adherence was assessed via usage data. Results: From May 2018 to August 2018, 311 adults downloaded the SELMA app, 102 of whom consented to participate and met the inclusion criteria. The average age of the women (88/102, 86.4%) and men (14/102, 13.6%) participating was 43.7 (SD 12.7) years. Baseline group comparison did not differ with respect to any demographic or clinical variable. The intervention group reported no significant change in pain-related impairment (P=.68) compared to the control group postintervention. The intention to change behavior was positively related to pain-related impairment (P=.01) and pain intensity (P=.01). Working alliance with the TBHC SELMA was comparable to that obtained in guided internet therapies with human coaches. Participants enjoyed using the app, perceiving it as useful and easy to use. Participants of the intervention group replied with an average answer ratio of 0.71 (SD 0.20) to 200 (SD 58.45) conversations initiated by SELMA. Participants’ comments revealed an appreciation of the empathic and responsible interaction with the TBHC SELMA. A main criticism was that there was no option to enter free text for the patients’ own comments. Conclusions: SELMA is feasible, as revealed mainly by positive feedback and valuable suggestions for future revisions. For example, the participants’ intention to change behavior or a more homogenous sample (eg, with a specific type of chronic pain) should be considered in further tailoring of SELMA. © Sandra Hauser-Ulrich, Hansjörg Künzli, Danielle Meier-Peterhans, Tobias Kowatsch.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","4","8","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85F8GJPM","conferencePaper","2020","Carper, B.; McGowan, D.; Miller, S.; Nelson, J.; Palombi, L.; Romeo, L.; Spigelman, K.; Doryab, A.","Modeling Biological Rhythms to Predict Mental and Physical Readiness","2020 Systems and Information Engineering Design Symposium, SIEDS 2020","978-1-72817-145-6","","10.1109/SIEDS49339.2020.9106683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087077092&doi=10.1109%2fSIEDS49339.2020.9106683&partnerID=40&md5=0a3633d43557a60f70d29ce6528de4e5","The human body is composed of various biological clocks that impact physical and mental health functioning. Modeling biological rhythms provides the means to understand the effect of internal and external factors on human mental and physical performance. So far, biological rhythms have mostly been studied in controlled laboratory settings thus limiting the long term study and modeling of these rhythms. This paper presents the results of our exploratory study of modeling human rhythms with longitudinal physiological data collected from consumer devices in the wild. We used data from four people continuously wearing Empatica (E4) wristbands and Oura smart rings for approximately four months to build models of human rhythms. We then used those model parameters in a machine learning approach to predict mental and physical readiness. Our results showed that most models built with a combination of sensors and rhythmic features obtained a prediction accuracy above the baseline measure of 66% (Max accuracy = 82.7%). These results provide insights into the feasibility of using consumer devices to model biological rhythms and use them to assess human and performance and health. © 2020 IEEE.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 2020 Systems and Information Engineering Design Symposium, SIEDS 2020 ; Conference Date: 24 April 2020; Conference Code:160546</p>","","","Forecasting; Exploratory studies; Engineering; Prediction accuracy; Physiological data; Controlled laboratories; Industrial engineering; Internal and external factors; Machine learning approaches; Physical performance; Rhythmic features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W95C579M","journalArticle","2020","Leonardi, S.; Monti, D.; Rizzo, G.; Morisio, M.","Multilingual transformer-based personality traits estimation","Information (Switzerland)","","20782489","10.3390/info11040179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085080344&doi=10.3390%2finfo11040179&partnerID=40&md5=590d131e1ea07c10f6d5c564ed07dc18","Intelligent agents have the potential to understand personality traits of human beings because of their every day interaction with us. The assessment of our psychological traits is a useful tool when we require them to simulate empathy. Since the creation of social media platforms, numerous studies dealt with measuring personality traits by gathering users' information from their social media profiles. Real world applications showed how natural language processing combined with supervised machine learning algorithms are effective in this field. These applications have some limitations such as focusing on English text only and not considering polysemy in text. In this paper, we propose a multilingual model that handles polysemy by analyzing sentences as a semantic ensemble of interconnected words. The proposed approach processes Facebook posts from the myPersonality dataset and it turns them into a high-dimensional array of features, which are then exploited by a deep neural network architecture based on transformer to perform regression. We prove the effectiveness of our work by comparing the mean squared error of our model with existing baselines and the Kullback-Leibler divergence between the relative data distributions. We obtained state-of-the-art results in personality traits estimation from social media posts for all five personality traits. © 2020 by the authors.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","","","4","11","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 0</p>","","","Semantics; Personality traits; Learning algorithms; Intelligent agents; Data distribution; Deep neural networks; High-dimensional; Kullback Leibler divergence; Mean square error; Mean squared error; NAtural language processing; Natural language processing systems; Network architecture; Social media platforms; Social networking (online); Supervised learning; Supervised machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XAV9FWZU","conferencePaper","2020","Kim, J.; Baek, K.; Jang, J.","Petbe: Projecting a real being onto a social robot using contextual data for a pet monitoring method","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3378236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083192737&doi=10.1145%2f3371382.3378236&partnerID=40&md5=db254c7b6ce64376dfa4c904274380e1","The demand for pet monitoring devices is growing due to the increasing number of one-person households raising pets. However, current monitoring methods using video camera entail various problems, which may lead to discontinued usage. To overcome this problem, we propose Petbe, a social robot that projects your own pet using a context-aware approach based on BLE beacons and Raspberry Pis. The corresponding smartphone application provides various robot status updates (robot head) and movements (robot body). With the development of Petbe, we conducted an exploratory study to verify the advancement of the above issues on monitoring user's own pets with the following factors: privacy concern, companionship, awareness, connectivity, and satisfaction. The outcomes indicate that Petbe helps to reduce privacy concerns and build companionship through empathetic interaction. © 2020 ACM.","2020","2021-05-19 13:26:13","2021-05-19 13:26:13","","290-292","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 2; Conference of 15th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2020 ; Conference Date: 23 March 2020 Through 26 March 2020; Conference Code:158851</p>","","","Monitoring; Social robots; Agricultural robots; Man machine systems; Exploratory studies; Video cameras; Smart-phone applications; Context-aware approaches; Current monitoring; Monitoring device; Monitoring methods; Privacy concerns; Status updates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2LEF8IVX","conferencePaper","2020","Li, Y.; Zhao, T.; Shen, X.","Attention-based multimodal fusion for estimating human emotion in real-world HRI","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3378261","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083245813&doi=10.1145%2f3371382.3378261&partnerID=40&md5=068a3d02ae8cec66950df316bed84f64","Toward empathetic and harmonious human-robot interaction (HRI), automatic estimation of human emotion has attracted increasing attention from multidisciplinary research fields. In this report, we propose an attention-based multimodal fusion approach that explores the space between traditional early and late fusion approaches, to deal with the problem of asynchronous multimodal inputs while considering their relatedness. The proposed approach enables the robot to align the human's visual and speech signals (more specifically, facial, acoustic, and lexical information) extracted by its cameras, microphones, and processing modules and is expected to achieve robust estimation performance in real-world HRI. © 2020 ACM.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","340-342","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 15th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2020 ; Conference Date: 23 March 2020 Through 26 March 2020; Conference Code:158851</p>","","","Human robot interaction; Agricultural robots; Man machine systems; Human robot Interaction (HRI); Audio signal processing; Automatic estimation; Lexical information; Multi-disciplinary research; Multi-modal fusion; Multimodal inputs; Processing modules; Robust estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZIXLB3J","conferencePaper","2020","Arnett, M.; Luo, Z.; Paladugula, P.K.; Cardenas, I.S.; Kim, J.-H.","Robots teaching recycling: Towards improving environmental literacy of children","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3379462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083168399&doi=10.1145%2f3371382.3379462&partnerID=40&md5=f2c5deecfbb5b7dbc8343530bb6d2c03","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle. © 2020 ACM.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","615-616","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 15th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2020 ; Conference Date: 23 March 2020 Through 26 March 2020; Conference Code:158851</p>","","","Human robot interaction; Agricultural robots; Man machine systems; Elementary schools; Pollution problems; Recycling; Vision recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VC37NADM","conferencePaper","2020","Connolly, J.; Mocz, V.; Salomons, N.; Valdez, J.; Tsoi, N.; Scassellati, B.; Vazquez, M.","Prompting prosocial human interventions in response to robot mistreatment","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-6746-2","","10.1145/3319502.3374781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082005598&doi=10.1145%2f3319502.3374781&partnerID=40&md5=5ca37572e421853f75ed741b638c5e9a","Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 betweensubjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI. © 2020 Association for Computing Machinery.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","211-220","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 6; Conference of 15th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2020 ; Conference Date: 23 March 2020 Through 26 March 2020; Conference Code:158224</p>","","","Social robots; Human robot interaction; Prosocial behavior; Man machine systems; Human robot Interaction (HRI); Behavioral research; Economic and social effects; Emotional reactions; Human intervention; Social influence; User study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YPT2RBEZ","conferencePaper","2020","Dixit, R.; Chinnam, R.B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","IEEE Aerospace Conference Proceedings","978-1-72812-734-7","","10.1109/AERO47225.2020.9172612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092594173&doi=10.1109%2fAERO47225.2020.9172612&partnerID=40&md5=0e5e0dbad1bd51bfa0c0a6e225195406","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once 'trained,' can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to 'techies' from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further. © 2020 IEEE.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 1095323X","<p>cited By 0; Conference of 2020 IEEE Aerospace Conference, AERO 2020 ; Conference Date: 7 March 2020 Through 14 March 2020; Conference Code:162583</p>","","","Decision making; Reinforcement learning; Learning systems; Cross-disciplinary; Decision algorithms; Dimensionality reduction; Human intelligence; Informed decision; Learning reinforcements; Qualitative characteristics; Real time decision-making; Strategic decisions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPEXHQNP","journalArticle","2020","Narayanan, S.; Polys, N.; Bukvic, I.I.","Cinemacraft: exploring fidelity cues in collaborative virtual world interactions","Virtual Reality","","13594338","10.1007/s10055-019-00382-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064680748&doi=10.1007%2fs10055-019-00382-0&partnerID=40&md5=dcd2da03ef2ca3ff1b7ba9539b82b370","The research presented in this paper explores the contribution of avatar fidelity to social interaction in virtual environments and how sensory fusion can improve these interactions. Specifically, we vary levels of interaction fidelity to investigate how responsiveness and behavioural realism affect people’s experience of interacting with virtual humans. This is accomplished through the creation of Cinemacraft, a technology-mediated immersive platform for collaborative human–computer interaction. Cinemacraft leverages a voxel game engine similar to Minecraft to facilitate collaborative interaction in a virtual 3D world and incorporates sensory fusion to improve the fidelity of real-time collaboration. The primary hypothesis of the study is that embodied interactions result in a higher degree of presence, and that sensory fusion can improve the quality of presence and co-presence. We tested our hypothesis through a user-study of 24 participants. Based on suggestions from existing literature, we sidestep the uncanny valley effect through the use of low fidelity avatars (a la Minecraft) and identify cues that impact users ratings of presence, co-presence and successful collaboration. The findings and ensuing data in this research can be applied to produce a more compelling platform for live collaborative interactions, performances, and empathetic storytelling. This research contributes to the field of immersive, collaborative interaction by making transparent the platform, methodology, instruments and code accessible for team members with less technological expertise, as well as developers aspiring to use interactive 3D media to promote further experimentation and conceptual discussions. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","53-73","","1","24","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 0</p>","","","Virtual reality; Virtual worlds; Human computer interaction; Information systems; Interactive computer graphics; Embodied interaction; Software engineering; Collaborative interaction; Collaborative virtual worlds; Computer interaction; Computing methodologies; Motion capture; Real-time collaboration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K583ZPL6","journalArticle","2020","McBride, N.","Robot Enhanced Therapy for Autistic Children: An Ethical Analysis","IEEE Technology and Society Magazine","","02780097","10.1109/MTS.2020.2967493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082031020&doi=10.1109%2fMTS.2020.2967493&partnerID=40&md5=7ee555189c1a7a2bf1f6ae1bc24dce07","The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in <italic>IEEE Technology and Society Magazine</italic>, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions. © 1982-2012 IEEE.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","51-60","","1","39","","","","","","","","","","English","","","","","","","Publisher: Institute of Electrical and Electronics Engineers Inc.","<p>cited By 1</p>","","","Social robots; Philosophical aspects; Autistic children; Ethical concerns; Richardson; Social environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EX4ICQNG","journalArticle","2020","Björling, E.A.; Thomas, K.; Rose, E.J.; Cakmak, M.","Exploring Teens as Robot Operators, Users and Witnesses in the Wild","Frontiers in Robotics and AI","","22969144","10.3389/frobt.2020.00005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081700133&doi=10.3389%2ffrobt.2020.00005&partnerID=40&md5=b3727eb4331051d6aa27b67a53ab255c","As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot. © Copyright © 2020 Björling, Thomas, Rose and Cakmak.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","","","","7","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DWWWDBJ5","journalArticle","2020","Kumar, M.; Khatri, S.K.; Mohammadian, M.","Breast cancer identification and prognosis with machine learning techniques - An elucidative review","Journal of Interdisciplinary Mathematics","","09720502","10.1080/09720502.2020.1731963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084855111&doi=10.1080%2f09720502.2020.1731963&partnerID=40&md5=63f81c27e48424c44143c5d87af974d3","Cancer is the principle wellspring of death around the globe with 2.09 million cases so far in 2018 [1]. Around 627000 deaths accounting to 6.6% are caused because of female breast cancer and it ranks five amongst the list of top causes for deaths, the prime reason being prognosis being favorable in developed countries. The timely empathy of breast cancer further makes the process of prognosis better hence improving the rates of survival, because this will indorse on time treatment which is given clinically to patients. When the classification is done in an accurate way for malignant and benign tumours, it stops the suffering of patients with excessive ailments. The best possible recognizable proof of breast cancer disease and the process of characterizing into benign and malignant groups is that the main concern of a ton of investigation and research. When thrown light on its particular advantages in significant alternatives recognition from the datasets of entangled breast cancer, the generally perceived option is Machine Learning, because of the philosophy of determination in breast cancer to arrange pattern and forecast modelling. This paper will in general, survey machine learning and assessment of this particular paper, WBCD: Wisconsin Breast Cancer Database has been used as the benchmark dataset. © 2020, © 2020 Taru Publications.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","503-521","","2","23","","","","","","","","","","English","","","","","","","Publisher: Taru Publications","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNHC4M9Q","journalArticle","2020","Christov-Moore, L.; Reggente, N.; Douglas, P.K.; Feusner, J.D.; Iacoboni, M.","Predicting Empathy From Resting State Brain Connectivity: A Multivariate Approach","Frontiers in Integrative Neuroscience","","16625145","10.3389/fnint.2020.00003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081050035&doi=10.3389%2ffnint.2020.00003&partnerID=40&md5=14a6c372c5d3617e327c91f2225d221e","Recent task fMRI studies suggest that individual differences in trait empathy and empathic concern are mediated by patterns of connectivity between self-other resonance and top-down control networks that are stable across task demands. An untested implication of this hypothesis is that these stable patterns of connectivity should be visible even in the absence of empathy tasks. Using machine learning, we demonstrate that patterns of resting state fMRI connectivity (i.e. the degree of synchronous BOLD activity across multiple cortical areas in the absence of explicit task demands) of resonance and control networks predict trait empathic concern (n = 58). Empathic concern was also predicted by connectivity patterns within the somatomotor network. These findings further support the role of resonance-control network interactions and of somatomotor function in our vicariously driven concern for others. Furthermore, a practical implication of these results is that it is possible to assess empathic predispositions in individuals without needing to perform conventional empathy assessments. © Copyright © 2020 Christov-Moore, Reggente, Douglas, Feusner and Iacoboni.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","","","","14","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 5</p>","","","brain; machine learning; empathy; functional magnetic resonance imaging; article; human; human experiment; adult; female; major clinical study; male; controlled study; BOLD signal; somatomotor network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6Z3H6YJ","journalArticle","2020","Haarsma, G.; Davenport, S.; White, D.C.; Ormachea, P.A.; Sheena, E.; Eagleman, D.M.","Assessing Risk Among Correctional Community Probation Populations: Predicting Reoffense With Mobile Neurocognitive Assessment Software","Frontiers in Psychology","","16641078","10.3389/fpsyg.2019.02926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079140899&doi=10.3389%2ffpsyg.2019.02926&partnerID=40&md5=d66fb33965d78c0e0dfa4f599eabf818","We seek to address current limitations of forensic risk assessments by introducing the first mobile, self-scoring, risk assessment software that relies on neurocognitive testing to predict reoffense. This assessment, run entirely on a tablet, measures decision-making via a suite of neurocognitive tests in less than 30 minutes. The software measures several cognitive and decision-making traits of the user, including impulsivity, empathy, aggression, and several other traits linked to reoffending. Our analysis measured whether this assessment successfully predicted recidivism by testing probationers in a large urban city (Houston, TX, United States) from 2017 to 2019. To determine predictive validity, we used machine learning to yield cross-validated receiver–operator characteristics. Results gave a recidivism prediction value of 0.70, making it comparable to commonly used risk assessments. This novel approach diverges from traditional self-reporting, interview-based, and criminal-records-based approaches, and can also add a protective layer against bias, while strengthening model accuracy in predicting reoffense. In addition, subjectivity is eliminated and time-consuming administrative efforts are reduced. With continued data collection, this approach opens the possibility of identifying different levels of recidivism risk, by crime type, for any age, or gender, and seeks to steer individuals appropriately toward rehabilitative programs. Suggestions for future research directions are provided. © Copyright © 2020 Haarsma, Davenport, White, Ormachea, Sheena and Eagleman.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","","","","10","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKERI63Z","journalArticle","2020","de Gennaro, M.; Krumhuber, E.G.; Lucas, G.","Effectiveness of an Empathic Chatbot in Combating Adverse Effects of Social Exclusion on Mood","Frontiers in Psychology","","16641078","10.3389/fpsyg.2019.03061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079193135&doi=10.3389%2ffpsyg.2019.03061&partnerID=40&md5=cb20f694f15c0763646e54f9995eaf2c","From past research it is well known that social exclusion has detrimental consequences for mental health. To deal with these adverse effects, socially excluded individuals frequently turn to other humans for emotional support. While chatbots can elicit social and emotional responses on the part of the human interlocutor, their effectiveness in the context of social exclusion has not been investigated. In the present study, we examined whether an empathic chatbot can serve as a buffer against the adverse effects of social ostracism. After experiencing exclusion on social media, participants were randomly assigned to either talk with an empathetic chatbot about it (e.g., “I’m sorry that this happened to you”) or a control condition where their responses were merely acknowledged (e.g., “Thank you for your feedback”). Replicating previous research, results revealed that experiences of social exclusion dampened the mood of participants. Interacting with an empathetic chatbot, however, appeared to have a mitigating impact. In particular, participants in the chatbot intervention condition reported higher mood than those in the control condition. Theoretical, methodological, and practical implications, as well as directions for future research are discussed. © Copyright © 2020 de Gennaro, Krumhuber and Lucas.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","","","","10","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VT8D9FJN","conferencePaper","2020","Harilal, N.; Shah, R.; Sharma, S.; Bhutani, V.","CARO: An empathetic health conversational chatbot for people with major depression","ACM International Conference Proceeding Series","978-1-4503-7738-6","","10.1145/3371158.3371220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078410875&doi=10.1145%2f3371158.3371220&partnerID=40&md5=3419d09ec6e1d6b35349045f8bc72474","There has been a rise in the number of patients suffering from major depression over the past decade. Most of the patients are reluctant and do not open up for councelling services. Conversational applications such as chatbots have been found efficient in overcoming alcohol addiction. Effective treatments can tackle depression, but only 10% of affected patients are able to avail such treatments mainly due to lack of resources and social stigma associated with mental disorders. We propose CARO, a chatbot app, which is capable of performing empathetic conversations and providing medical advice for people with major depression. CARO will be able to sense the conversational context, its intent and the associated emotions. © 2020 Association for Computing Machinery.","2020","2021-05-19 13:26:14","2021-05-19 13:26:14","","349-350","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 3; Conference of ACM India Joint 7th ACM IKDD Conference on Data Science and 25th International Conference on Management of Data, CoDS-COMAD 2020 ; Conference Date: 5 January 2020 Through 7 January 2020; Conference Code:156814</p>","","","Chatbots; Chatbot; Depression; Empathetic Response; Medical Advice; Computer applications; Computer programming; Mental disorders; Alcohol addiction; Major depressions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MXU4YPYZ","conferencePaper","2020","Ravi, A.; Yadav, A.K.S.; Chauhan, J.; Dholakia, J.; Jain, N.","Sentemoji: A dataset to generate empathising conversations","ACM International Conference Proceeding Series","978-1-4503-7738-6","","10.1145/3371158.3371218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078411780&doi=10.1145%2f3371158.3371218&partnerID=40&md5=0bc1621a71993b93cf7db57a229cc50e","Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach. © 2020 Association for Computing Machinery.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","345-346","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of ACM India Joint 7th ACM IKDD Conference on Data Science and 25th International Conference on Management of Data, CoDS-COMAD 2020 ; Conference Date: 5 January 2020 Through 7 January 2020; Conference Code:156814</p>","","","Chatbots; Chatbot; User study; Computer applications; Computer programming; Public dataset; User rating","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NNTGR27","journalArticle","2020","Hessler, D.","Whose pain is it, anyway? On avatar embodiment, slapstick performances, and virtual pain","Comedy Studies","","2040610X","10.1080/2040610X.2019.1692550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076436399&doi=10.1080%2f2040610X.2019.1692550&partnerID=40&md5=d872de6c4466bad572991bb70e9c5a3c","This article investigates the relationship of the player and her avatar in humorous single-player video games. Referring to slapstick performance characteristics and their perception as described by Louise Peacock (2014), it discusses the concepts of empathic and goal-oriented engagement by Petri Lankoski (2010), and proxy embodiment by Rune Klevjer (2012) along Manual Samuel (Perfectly Paranormal 2016), and Octodad: Dadliest Catch (Young Horses 2014). Considering mastery in ludic performance, and punishment for lack thereof, it focuses the tension between pain represented in avatar corporeality, and pain experienced by the player due to failing. Thus, this article provides a perspective that constructs the avatar-player-relationship in single-player video games as a central double act typical to slapstick performances. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","85-103","","1","11","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Ltd.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7J5NW8Q","journalArticle","2020","Zhou, L.; Gao, J.; Li, D.; Shum, H.-Y.","The design and implementation of xiaoice, an empathetic social chatbot","Computational Linguistics","","08912017","10.1162/COLI_a_00368","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083075056&doi=10.1162%2fCOLI_a_00368&partnerID=40&md5=39996513f70d36c3d274711ac4349c2c","This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human– machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations. © 2020 Association for Computational Linguistics.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","53-93","","1","46","","","","","","","","","","English","","","","","","","Publisher: MIT Press Journals","<p>cited By 23</p>","","","Decision making; Behavioral research; Emotional connections; Artifical intelligence; Design and implementations; Dialogue manager; Intelligent quotient; Long-term relationships; Markov Decision Processes; Markov processes; System architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEQRQXC9","journalArticle","2020","Barnett, A.; Savic, M.; Pienaar, K.; Carter, A.; Warren, N.; Sandral, E.; Manning, V.; Lubman, D.I.","Enacting ‘more-than-human’ care: Clients’ and counsellors’ views on the multiple affordances of chatbots in alcohol and other drug counselling","International Journal of Drug Policy","","09553959","10.1016/j.drugpo.2020.102910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092491969&doi=10.1016%2fj.drugpo.2020.102910&partnerID=40&md5=0f08dee53cf0128ca481fdd081ce7da2","Forms of artificial intelligence (AI), such as chatbots that provide automated online counselling, promise to revolutionise alcohol and other drug treatment. Although the replacement of human counsellors remains a speculative prospect, chatbots for ‘narrow AI’ tasks (e.g., assessment and referral) are increasingly being used to augment clinical practice. Little research has addressed the possibilities for care that chatbots may generate in the future, particularly in the context of alcohol and other drug counselling. To explore these issues, we draw on the concept of technological ‘affordances’ and identify the range of possibilities for care that emerging chatbot interventions may afford and foreclose depending on the contexts in which they are implemented. Our analysis is based on qualitative data from interviews with clients (n=20) and focus group discussions with counsellors (n=8) conducted as part of a larger study of an Australian online alcohol and other drug counselling service. Both clients and counsellors expressed a concern that chatbot interventions lacked a ‘human’ element, which they valued in empathic care encounters. Most clients reported that they would share less information with a chatbot than a human counsellor, and they viewed this as constraining care. However, clients and counsellors suggested that the use of narrow AI might afford possibilities for performing discrete tasks, such as screening, triage or referral. In the context of what we refer to as ‘more-than-human’ care, our findings reveal complex views about the types of affordances that chatbots may produce and foreclose in online care encounters. We conclude by discussing implications for the potential ‘addiction futures’ and care trajectories that AI technologies offer, focussing on how they might inform alcohol and other drug policy, and the design of digital healthcare. © 2020 Elsevier B.V.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TPS3V5A","journalArticle","2020","Blease, C.; Locher, C.; Leon-Carlyle, M.; Doraiswamy, M.","Artificial intelligence and the future of psychiatry: Qualitative findings from a global physician survey","Digital Health","","20552076","10.1177/2055207620968355","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094669527&doi=10.1177%2f2055207620968355&partnerID=40&md5=5e2909e410f68527e010deb3b1f9b7b3","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. Objective: This study aimed to explore psychiatrists’ opinions about the potential impact innovations in artificial intelligence and machine learning on psychiatric practice Methods: In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written responses (“comments”) to three open-ended questions in the survey. Results: Comments were classified into four major categories in relation to the impact of future technology on: (1) patient-psychiatrist interactions; (2) the quality of patient medical care; (3) the profession of psychiatry; and (4) health systems. Overwhelmingly, psychiatrists were skeptical that technology could replace human empathy. Many predicted that ‘man and machine’ would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. Conclusions: This study presents timely information on psychiatrists’ views about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues. © The Author(s) 2020.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","6","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 2</p>","","","attention; artificial intelligence; machine learning; empathy; mental health; psychiatry; qualitative research; article; human; adult; male; attitude; medical care; occupation; practice guideline; psychiatrist; spring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MZL3TRY","journalArticle","2020","Chiang, A.-H.; Trimi, S.","Impacts of service robots on service quality","Service Business","","18628516","10.1007/s11628-020-00423-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089085301&doi=10.1007%2fs11628-020-00423-8&partnerID=40&md5=845fde74db3c352ab9c164b287bcc23f","With rapid advances in technologies, especially in artificial intelligence, smart sensors, big data analytics, and robotics, the service industry began introducing robots to perform a variety of functions. While the main purpose of deploying robots has been productivity improvement, the current COVID-19 pandemic has brought more urgent purpose, providing contactless service for social distancing. This study explores the service quality provided by robots based on real data in a hotel setting. A sample of 201 guests provided their expected service quality by robots and the actual performance experience after the service. We analyzed this relationship using importance performance analysis (IPA) and the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). The results revealed that customers’ top priorities for robots’ service quality are assurance and reliability, while tangible and empathy were not as important. Customers were not satisfied with robots’ responsiveness, but this construct was found to be a low priority. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3JC9PUI","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective intelligence: When, where and why","Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering","978-1-72812-791-0","","10.1109/Confluence47617.2020.9058000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083999561&doi=10.1109%2fConfluence47617.2020.9058000&partnerID=40&md5=dc43e7ffcf6adf8f724ffaf9d79a8e30","The term 'Collective' is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief. © 2020 IEEE.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","805-810","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 10th International Conference on Cloud Computing, Data Science and Engineering, Confluence 2020 ; Conference Date: 29 January 2020 Through 31 January 2020; Conference Code:159162</p>","","","Artificial intelligence; Cloud computing; Human being; Intelligent virtual agents; Intelligent agents; Collective intelligences; Computer environments; Computer technology; Flock of Birds; ITS applications; New terms; Personality characteristic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7WBZZM7G","journalArticle","2020","Rosete, A.; Soares, B.; Salvadorinho, J.; Reis, J.; Amorim, M.","Service Robots in the Hospitality Industry: An Exploratory Literature Review","Lecture Notes in Business Information Processing","","18651348","10.1007/978-3-030-38724-2_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080863550&doi=10.1007%2f978-3-030-38724-2_13&partnerID=40&md5=74f7c8a07cdc69ddf8045e3cc9f06b5d","The service sector is changing drastically due the use of robotics and other technologies, such as Artificial Intelligence (AI), Internet of things (IoT), Big Data and Biometrics. Consequently, further research opportunities in the service industry domain are also expected. In light of the above, the purpose of this paper is to explore the potentialities and limitations of service robots in the hospitality industry. To this end, this paper uses a conceptual approach based on a literature review. As a result, we found that in contexts of high customer contact, service robots should be considered to perform standardized tasks due to social/emotional and cognitive/analytical complexity. The hospitality industry is therefore considered closely related to empathic intelligence, as the integration of service robots has not yet reached the desired stage of service delivery. In a seemingly far-fetched context of our reality, organizations will have to decide whether the AI will allow the complete replacement of humans with robots capable of performing the necessary cognitive and emotional tasks. Or investing in balanced capacities by integrating robot-human systems that seems a reasonable option these days. © Springer Nature Switzerland AG 2020.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","174-186","","","377 LNBIP","","","","","","","","","","English","","","","","","","ISBN: 9783030387235 Publisher: Springer","<p>cited By 5; Conference of 10th International Conference on Exploring Service Science, IESS 2020 ; Conference Date: 5 February 2020 Through 7 February 2020; Conference Code:237279</p>","","","Artificial intelligence; Social robots; Big data; Service robots; Mobile robots; Internet of things; Intelligent robots; Hospitality industry; Service industry; Research opportunities; Conceptual approaches; Digital transformation; Integration of services; Internet of Things (IOT); Metadata; Robot-human system","","Novoa H., Kuhl N., Dragoicea M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WBMWC97H","journalArticle","2020","James, J.; Balamurali, B.T.; Watson, C.I.; MacDonald, B.","Empathetic Speech Synthesis and Testing for Healthcare Robots","International Journal of Social Robotics","","18754791","10.1007/s12369-020-00691-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090755646&doi=10.1007%2fs12369-020-00691-4&partnerID=40&md5=e6d2fbb614c296ba7d803a31715e7357","One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot’s voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people’s acceptance of social robots. © 2020, Springer Nature B.V.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 0</p>","","","Social robots; Health care; Prosody modelling; Agricultural robots; Human users; Affective response; Health care application; Major factors; Pilot studies; Pilot tests; Speech synthesis; Synthetic voices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8N5TDWZ","journalArticle","2020","Bagheri, E.; Roesler, O.; Cao, H.-L.; Vanderborght, B.","A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots","International Journal of Social Robotics","","18754791","10.1007/s12369-020-00683-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091144365&doi=10.1007%2fs12369-020-00683-4&partnerID=40&md5=f3b6bad671fdea58d1e7adfee9eb2754","Robots that express human’s social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better. © 2020, Springer Nature B.V.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science+Business Media B.V.","<p>cited By 0</p>","","","Reinforcement learning; Social robots; Humanoid robot; Agricultural robots; Anthropomorphic robots; Learning systems; Affective state; Facial emotions; Behavioral research; Human like; Human users; Learning models; Reinforcement learning models; Social norm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTICU6PL","journalArticle","2020","Trost, M.J.; Chrysilla, G.; Gold, J.I.; Matarić, M.","Socially-Assistive Robots Using Empathy to Reduce Pain and Distress during Peripheral IV Placement in Children","Pain Research and Management","","12036765","10.1155/2020/7935215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083881603&doi=10.1155%2f2020%2f7935215&partnerID=40&md5=ea3dec2f225f6047f5a5282c0de25503","Objectives. Socially-assistive robots (SAR) have been used to reduce pain and distress in children in medical settings. Patients who perceive empathic treatment have increased satisfaction and improved outcomes. We sought to determine if an empathic SAR could be developed and used to decrease pain and fear associated with peripheral IV placement in children. Methods. We conducted a pilot study of children receiving IV placement. Participating children were randomized to interact with (1) no robot, or a commercially available 3D printed humanoid SAR robot programmed with (2) empathy or (3) distraction conditions. Children and parents completed demographic surveys, and children used an adapted validated questionnaire to rate the robot's empathy on an 8-point Likert scale. Survey scores were compared by the t-test or chi-square test. Pain and fear were measured by self-report using the FACES and FEAR scales, and video tapes were coded using the CHEOPS and FLACC. Scores were compared using repeated measures 2-way ANOVA. This trial is registered with NCT02840942. Results. Thirty-one children with an average age of 9.6 years completed the study. For all measures, mean pain and fear scores were lowest in the empathy group immediately before and after IV placement. Children were more likely to attribute characteristics of empathy to the empathic condition (Likert score 7.24 v. 4.70; p=0.012) and to report that having the empathic vs. distraction robot made the IV hurt less (7.45 vs. 4.88; p=0.026). Conclusions. Children were able to identify SAR designed to display empathic characteristics and reported it helped with IV insertion pain and fear. Mean scores of self-reported or objective pain and fear scales were the lowest in the empathy group and the highest in the distraction condition before and after IV insertion. This result suggests empathy improves SAR functionality when used for painful medical procedures and informs future research into SAR for pain management. © 2020 Margaret J Trost et al.","2020","2021-05-19 13:26:15","2021-05-19 13:26:15","","","","","2020","","","","","","","","","","English","","","","","","","Publisher: Hindawi Limited","<p>cited By 3</p>","","","Female; Humans; Male; Robotics; pain; Empathy; empathy; satisfaction; robotics; psychology; Pain; child; questionnaire; Child; human; female; male; Article; Preschool; preschool child; Administration; controlled study; randomized controlled trial; videorecording; Likert scale; adverse event; analgesia; clinical article; devices; distractibility; distress syndrome; fear; health care survey; Intravenous; intravenous drug administration; Pain Management; parent; patient satisfaction; Pilot Projects; pilot study; procedures; school child; self report; socially assistive robot; Surveys and Questionnaires; three dimensional printing; vein catheterization; vein puncture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQZN5JLL","journalArticle","2020","Perugia, G.; Paetzel, M.; Castellano, G.","On the Role of Personality and Empathy in Human-Human, Human-Agent, and Human-Robot Mimicry","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-62056-1_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097197855&doi=10.1007%2f978-3-030-62056-1_11&partnerID=40&md5=95f5dab4e658c63f6012ff6fc072f43a","Facial mimicry is crucial in social interactions as it communicates the intent to bond with another person. While human-human mimicry has been extensively studied, human-agent and human-robot mimicry have been addressed only recently, and the individual characteristics that affect them are still unknown. This paper explores whether the humanlikeness and embodiment of an agent affect human facial mimicry and which personality and empathy traits are related to facial mimicry of human and artificial agents. We exposed 46 participants to the six basic emotions displayed by a video-recorded human and three artificial agents (a physical robot, a video-recorded robot, and a virtual agent) differing in humanlikeness (humanlike, characterlike, and a morph between the two). We asked participants to recognize the facial expressions performed by each agent and measured their facial mimicry using automatic detection of facial action unit activation. Results showed that mimicry was affected by the agents’ embodiment, but not by their humanlikeness, and that it correlated both with individual traits denoting sociability and sympathy and with traits advantageous for emotion recognition. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","120-131","","","12483 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783030620554 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 12th International Conference on Social Robotics, ICSR 2020 ; Conference Date: 14 November 2020 Through 18 November 2020; Conference Code:251579</p>","","","Robotics; Robots; Emotion recognition; Face recognition; Artificial agents; Human likeness; Facial Expressions; Social interactions; Automatic Detection; Individual characteristics; Physical robots","","Wagner A.R., Sam Ge S., Feil-Seifer D., Haring K.S., Rossi S., Williams T., He H.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNYRI8IC","conferencePaper","2020","Buono, P.; Castellano, G.; Decarolis, B.; MacChiarulo, N.","Social assistive robots in elderly care: Exploring the role of empathy","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094831887&partnerID=40&md5=9c71a17ac85c7fe16e8b3521eec02d0e","The COVID-19 emergency has shown that elderly people living in Assisted Living Houses (ALHs) have been highly exposed to the virus. Besides health problems, during the social distancing restrictions, the elderly were also strongly affected by loneliness due to a lack of contact with their loved ones. Innovative solutions for ALH based on Social Assistive Robotics can reduce the risk of infection and, at the same time, improve the quality of life of elderly people. In this work, after a brief overview on the Pepper4Elderly project, we focus on the role of empathy and affective behaviors in human-robot interaction when the robot is used as a caring agent to assist and entertain the elderly guests of ALHs. © 2020 CEUR-WS. All rights reserved.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","12-19","","","2702","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 1; Conference of 1st International Workshop on Empowering People in Dealing with Internet of Things Ecosystems, EMPATHY 2020 ; Conference Date: 29 September 2020; Conference Code:164030</p>","","","Social robots; Assistive robots; Behavioral research; Affective behaviors; Assisted living; Assistive robotics; Ecosystems; Elderly care; Elderly people; Exposed to; Innovative solutions; Internet of things; Quality of life; Viruses","","Desolda G., Treccani B., Deufemia V., Gena C., Matera M., Paterno F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6KHIDECT","journalArticle","2020","Lima Dantas, D.; Filgueiras, L.V.L.; Brandão, A.A.F.; Machado Domingues, M.C.; Ferreira, M.R.","Detecting IoT Applications Opportunities and Requirements Elicitation: A Design Thinking Based Approach","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-50344-4_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740148&doi=10.1007%2f978-3-030-50344-4_7&partnerID=40&md5=82f5cd968cdecbc941b929dd7ba6216c","IoT development is complex. To reduce this complexity, IoT platforms provide a set of resources and functionalities to enable application development and support its execution. In this work, we present a human-centered approach for requirements elicitation and mapping them to application resources in IoT platforms, using empathy, definition and ideation methods. A previous study by the authors has identified 11 categories of resources provided by 47 IoT platforms to developers in their application layers. From this set, 6 categories were selected for this work: schedulers and triggers, message and notification triggers, big data and analytics, artificial intelligence and machine learning, dashboards, and services. We invited 18 members of 8 projects for a workshop and divided them in 4 teams, according their project areas, which are: Industry 4.0 (6 participants), Environmental Disasters (4 participants), Environmental Management (3 participants) and Pollution (5 participants). We divided the workshop in 3 phases: warm-up, with user journey mapping, requirements identification using “how might we” questions as a trigger and requirements clustering the questions by the 6 selected categories of resources or an extra category named “others” for those which could not be related to any previous category. Our contribution for the IoT application development is an approach for turning easier requirements elicitation using DT techniques, covering the stages of empathise, definition and ideation, with well-available materials and considering the resources present at application layer of IoT platforms. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","85-100","","","12203 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030503437 Publisher: Springer","<p>cited By 0; Conference of 8th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242499</p>","","","Artificial intelligence; Project management; Design thinking; Human computer interaction; Internet of things; Advanced Analytics; Application development; Application Layer; Environmental disasters; Environmental management; Human resource management; Ideation methods; IOT applications; Mapping; Requirements elicitation; Requirements engineering; Warm up","","Streitz N., Konomi S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJXCX4DR","journalArticle","2020","Ryumina, E.V.; Karpov, A.A.","Analytical review of methods for emotion recognition by human face expressions","Scientific and Technical Journal of Information Technologies, Mechanics and Optics","","22261494","10.17586/2226-1494-2020-20-2-163-176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097370600&doi=10.17586%2f2226-1494-2020-20-2-163-176&partnerID=40&md5=2badd0cb9911649264b6b665b8528cbd","Recognition of human emotions by facial expressions is an important research problem that covers many areas and disciplines, such as computer vision, artificial intelligence, medicine, psychology and security. This paper provides an analytical overview of video facial expression databases and approaches to recognition emotions by facial expressions, which include three main stages of image analysis, such as pre-processing, feature extraction and classification. The paper presents both traditional approaches to recognition of human emotions by visual facial features, and approaches based on deep learning using deep neural networks. We give the current results of some existing algorithms. In the review of scientific and technical literature we empathized mainly the sources containing theoretical and research information of the methods under consideration, as well as comparison of traditional methods and methods based on deep neural networks, which were supported by experimental studies. Analysis of scientific and technical literature describing methods and algorithms for study and recognition of facial expressions, as well as the results of world scientific research, have shown that traditional methods for classification of facial expressions are second in speed and accuracy to artificial neural networks. The main contribution of this review is providing a common understanding of modern approaches to recognition of facial expressions, which will enable new researchers to understand the main components and trends in the field of recognition of facial expressions. Moreover, comparison of world scientific findings has shown that a combination of traditional approaches and approaches based on deep neural networks achieves better classification accuracy, but artificial neural networks are the best classification methods. The paper may be useful to specialists and researchers in the field of computer vision. © 2020, ITMO University. All rights reserved.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","163-176","","","2","","","","","","","","","","Russian","","","","","","","Publisher: ITMO University","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LI4GFGS2","journalArticle","2020","Kim, H.C.; Cha, M.C.; Ji, Y.G.","The effect of empathy on human-agent interaction","ICIC Express Letters, Part B: Applications","","21852766","10.24507/icicelb.11.06.551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085004414&doi=10.24507%2ficicelb.11.06.551&partnerID=40&md5=2a2ed44f0075def60a3d405839efaab1","Technology development and information communication have led to an in-crease of human-agent communication and provided an opportunity to overcome the ex-isting limitation human-human communication. Psychological counseling studies suggest conventional face-to-face counseling method can replace the role of a counselor by ap-plying agent technology. The present study has been established to identify the effects of empathy in human-agent interaction. In order to do so, we designed and conducted a pilot study of a prototype of counseling conversation based on psychological counseling theory. We have found that empathic agents resulted in lower score on counselor’s as-sessment and lower level of empathy perceived by the subjects. The simple empathy used in this study may have given the participants a sense of imitating a clumsy human be-ing and have caused a higher level of displeasure and discomfort compared to the agents without empathy response. This study is meaningful in that it provides basic data for developing and improving an artificial intelligence-based psychological counseling system by designing artificial intelligence counseling agents and varying levels of empathy. © ICIC International 2020.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","551-557","","6","11","","","","","","","","","","English","","","","","","","Publisher: ICIC International","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVX4MRZB","journalArticle","2020","Doraiswamy, P.M.; Blease, C.; Bodner, K.","Artificial intelligence and the future of psychiatry: Insights from a global physician survey","Artificial Intelligence in Medicine","","09333657","10.1016/j.artmed.2019.101753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075551716&doi=10.1016%2fj.artmed.2019.101753&partnerID=40&md5=b4a9a1356b687200ae8a504ac235d20d","Background: Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. Objective: To characterize the global psychiatrist community's opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Design: Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. Main outcome measures: We measured opinions about the likelihood that AI/ML tools would be able to fully replace – not just assist – the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist's perceptions about whether benefits of AI/ML would outweigh the risks. Results: Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Conclusions: Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care. © 2019 Elsevier B.V.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","","","","102","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 17</p>","","","Adult; Female; Humans; Male; perception; artificial intelligence; Employment; Middle Aged; machine learning; Deep learning; Surveys; Artificial intelligence; deep learning; Artificial Intelligence; Empathy; empathy; Autonomous agents; Mental health; psychiatry; Health care; Machine Learning; questionnaire; article; human; human experiment; adult; female; male; outcome assessment; Risk assessment; middle aged; Surveys and Questionnaires; psychiatrist; physician; Physicians; Europe; medical record; patient referral; Referral and Consultation; Asia; Autonomous technology; cost of illness; Cost of Illness; Cross-Sectional Studies; cross-sectional study; Felt; Future technologies; Global networking; Integrate technologies; Medical record; mental health care; North America; Outcome measures; Psychiatry; Risk perception; social stigma; Social Stigma; South America; stratified sample","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7NJ6H3T6","conferencePaper","2020","Guarese, R.; De Jesus Oliveira, V.; Calepso, A.; Valer, R.; Iquiapaza, Y.; Nedel, L.; MacIel, A.","E-mpathy and the phantom limb sensation: A multisensory experience for embodiment of amputation","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818321&partnerID=40&md5=9987bba9a555676ea0699ec2b68a35dd","In the context of promoting empathy among people without disabilities, we propose an application to allow users to experience having an amputated arm. By providing both visual and haptic feedback, our application offers a multisensory experience to enhance the sense of embodiment. The user of our application should still feel their real limb attached to their bodies, and yet see their virtual avatar and interact with the virtual environment as an amputee. A simple task of handling and positioning objects in a table is proposed for users to experience the difficulties of having a missing arm. Additionally, experiment participants are asked to answer a self-presence questionnaire regarding their embodiment of the virtual avatar. Copyright © 2020 for this paper by its authors.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","13-16","","","2618","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 2020 XChange Reality!, XCR 2020 ; Conference Date: 27 April 2020 Through 30 April 2020; Conference Code:160631</p>","","","User experience; Haptic feedbacks; Artificial limbs; Multisensory; Phantoms; Self presences; Virtual avatar","","Moser T., Bruckner F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A6PENFAC","journalArticle","2020","Erden, Y.J.; Hummerstone, H.; Rainey, S.","Automating autism assessment: What AI can bring to the diagnostic process","Journal of Evaluation in Clinical Practice","","13561294","10.1111/jep.13527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097612678&doi=10.1111%2fjep.13527&partnerID=40&md5=e4fff3517d81410cf748b34bfdb6bf25","This paper examines the use of artificial intelligence (AI) for the diagnosis of autism spectrum disorder (ASD, hereafter autism). In so doing we examine some problems in existing diagnostic processes and criteria, including issues of bias and interpretation, and on concepts like the ‘double empathy problem’. We then consider how novel applications of AI might contribute to these contexts. We're focussed specifically on adult diagnostic procedures as childhood diagnosis is already well covered in the literature. © 2020 The Authors. Journal of Evaluation in Clinical Practice published by John Wiley & Sons Ltd.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","","","","","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Ltd","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JDYMMYE","conferencePaper","2020","Luca, A.I.; Podina, I.R.","The influence of moral factors on bullying behaviors in adolescence: Theoretical considerations and proposal for a vr intervention to promote perspective-taking skills","eLearning and Software for Education Conference","","","10.12753/2066-026X-20-005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096480125&doi=10.12753%2f2066-026X-20-005&partnerID=40&md5=25daff84e3f0c87d7fb3307f68449e84","In the last decade, bullying and cyberbullying has known a rapid growth with worrisome consequences in regards to adolescent mental health. In the process of understanding the factors that influence bullying behaviours, researchers turned towards investigating moral factors, such as moral emotions, especially disgust and anger, and particularly a process called” moral disengagement” (MD; [22]). Moral disengagement is thought to contribute to the reason why some individuals, although they express disgust and anger in response to bullying behaviors, do not intervene in such situations. The objective of this research is to propose a VR based intervention aimed at increasing prosocial behaviour by improving perspective taking-skills and empathy concern. In the current paper, we suggest an interactive training simulation program where adolescent volunteers will take their own perspective or the perspective of the avatar in virtual reality, being instructed to try and understand its mental states. The situations encountered in VR are meant to trigger feelings of disgust, anger or elevation, the latter being an emotion elicited by witnessing acts of moral goodness. By increasing the propensity to take the perspective of the avatar, we aim to decrease the process of moral disengagement, especially in bullying and cyberbullying situations and increase prosocial behavior in adolescents. © 2020, National Defence University - Carol I Printing House. All rights reserved.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","415-476","","","","","","","","","","","National Defence University - Carol I Printing House","","English","","","","","","","ISSN: 2066026X","<p>cited By 0; Conference of 16th International Scientific Conference on eLearning and Software for Education, eLSE 2020 ; Conference Date: 30 April 2020 Through 1 May 2020; Conference Code:243719</p>","","","","","I, ROCEANU","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWZZQQSJ","journalArticle","2020","Xiao, G.; Tu, G.; Zheng, L.; Zhou, T.; Li, X.; Ahmed, S.H.; Jiang, D.","Multi-modality Sentiment Analysis in Social Internet of Things based on Hierarchical Attentions and CSATTCN with MBM Network","IEEE Internet of Things Journal","","23274662","10.1109/JIOT.2020.3015381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099552559&doi=10.1109%2fJIOT.2020.3015381&partnerID=40&md5=00cb27c2be4c5b7cab3cc2add96681ec","Multi-modality sentiment analysis in the social internet of things is a developing field, which is basic to empathetic mechanisms, affective computing, and artificial intelligence. Current works in this domain do not explicitly consider the influence of contextual information fusion based on correlation coefficient and memory network with branch structure for sentiment analysis. Unlike present works, this paper presents a Hierarchical Self-attention Fusion (H-SATF) model for capturing contextual information better among utterances, a Contextual Self-attention Temporal Convolutional Network (CSAT-TCN) for the sentiment recognition in social internet of things, and a Multi Branches Memory (MBM) network that stores self-speaker and inter-speaker sentimental states into global memories. For the MOSI datasets, the hybrid H-SATF-CSAT-TCN-MBM model outperforms the state-of-art networks and shows 0.31 9.93% improvement. IEEE","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","","","","","","","","","","","","","","English","","","","","","","Publisher: Institute of Electrical and Electronics Engineers Inc.","<p>cited By 5</p>","","","Sentiment analysis; Affective Computing; Internet of things; Convolutional neural networks; Correlation coefficient; ART networks; Arts computing; Branch structure; Contextual information; Convolutional networks; Memory network; Multi modality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MX7I35JZ","conferencePaper","2020","Baggio, B.","AI and education reborn","ICSIT 2020 - 11th International Conference on Society and Information Technologies, Proceedings","978-1-950492-30-5","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085913813&partnerID=40&md5=c04d7d1a2cb21e5464fb3932a7117e19","AI (Artificial Intelligence) will have enormous impacts on education, learning and talent development in K-12, higher Education and workplace learning. AIEd has barely scratched the surface. It will redefine the role of the teacher and support creative and human acts that provide ingenuity and empathy in support of learning. The gold is in the data. As AI interprets data, examines the role of the teacher or expert, supports classroom evolution and provides one on one tutoring, AIEd will be inextricably linked to the future of AI. AI comes with opportunities and many challenges. The adoption rate of new AI technologies seems to be on a path unprecedented in history. AI will need to provide insight in to learning and measure innate characteristics like curiosity and creativity. New pedagogies, research into existing learning sciences and learning contexts are needed. © 2020 by the International Institute of Informatics and Systemics. All rights reserved.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","34-39","","","","","","","","","","","International Institute of Informatics and Systemics, IIIS","","English","","","","","","","","<p>cited By 0; Conference of 11th International Conference on Society and Information Technologies, ICSIT 2020 ; Conference Date: 10 March 2020 Through 13 March 2020; Conference Code:159864</p>","","","AI Technologies; Higher education; Learning context; Learning science; One-on-one tutoring; Talent development; Workplace learning","","Callaos N.C., Tremante A., Robertson L., Sanchez B.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQPSKAGU","journalArticle","2020","Satterfield, D.; Abel, T.D.","Ai is the new ux: Emerging research innovations in ai, user experience, and design as they apply to industry, business, and education, and ethics","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-51057-2_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088740950&doi=10.1007%2f978-3-030-51057-2_26&partnerID=40&md5=ac737ca7adf299c3a9ec15214fde0e20","Emerging applications of artificial intelligence (AI) such as: predictive software integrated into websites like Amazon Prime, autonomous features integrated into automobiles, or smart home technologies such as those found in Alexa or Siri, have an ever-increasing impact on business, industry, research, and higher education. New trends and innovations in the use of AI technology in design, user experience, and behavioral psychology will change how we design for user experiences, how we interact with technology and it will fundamentally change us as humans. Steven Pinker describes the 21st century as the “Conceptual Age.” He says that we have progressed from the agriculture Age to the Industrial Age to the Information Age and now to the Conceptual Age. It is characterized by technology and globalization with an emphasis on creators, empathizers, pattern recognizers and meaning makers. This transition leads to the EQ-Based AI areas where those skills are a focus (Pink 2006). © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","182-188","","","1208 AISC","","","","","","","","","","English","","","","","","","ISBN: 9783030510565 Publisher: Springer","<p>cited By 0; Conference of AHFE Virtual Conference on the Human Side of Service Engineering, 2020 ; Conference Date: 16 July 2020 Through 20 July 2020; Conference Code:242519</p>","","","Artificial intelligence; Intelligent buildings; User experience; Agricultural robots; Behavioral research; AI Technologies; Higher education; Engineering education; Automation; Information age; Application programs; Behavioral psychologies; Conceptual ages; Emerging applications; Pattern recognizers; Smart Home Technology","","Spohrer J., Leitner C.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMNGN9Y6","conferencePaper","2020","Abdulrahman, A.; Richards, D.","Modelling working alliance using user-aware explainable embodied conversational agents for behavior change: Framework and empirical evaluation","40th International Conference on Information Systems, ICIS 2019","978-0-9966831-9-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084711738&partnerID=40&md5=12e39fee9fe7ed932a2de4bcdbbdf17d","The utilisation of embodied conversational agents (ECAs) to build a human-agent working alliance holds promise to promote health behavior change and improve health outcomes. Although ECAs have been shown to build empathic relationships with users, there is no complete framework to model working alliance. In this paper, we developed a framework that is grounded on theories and findings from social science and artificial intelligence to design a cognitive architecture for a user-aware explainable ECA. An empirical evaluation with 68 undergraduate students found differences in the efficacy of explanation to change behavior intention, build trust and working alliance depending on gender, stress levels and achievement aims; confirming the imperative of incorporating shared planning and user-tailored explanation in one framework. The empirical evaluation was limited in tailoring the explanation to the user's beliefs only; however, the analyses confirmed the need for considering adequate user information such as user's goals and preferences to build a user-aware explainable agent for behavior change towards improved health outcomes. © 40th International Conference on Information Systems, ICIS 2019. All rights reserved.","2020","2021-05-19 13:26:16","2021-05-19 13:26:16","","","","","","","","","","","","","Association for Information Systems","","English","","","","","","","","<p>cited By 2; Conference of 40th International Conference on Information Systems, ICIS 2019 ; Conference Date: 15 December 2019 Through 18 December 2019; Conference Code:158277</p>","","","Health; Trust; Embodied conversational agent; Students; Human computer interaction; Cognitive architectures; Information use; Information systems; Empirical evaluations; Health behaviors; Undergraduate students; User information; Working alliance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLARR7IG","journalArticle","2020","Ostherr, K.","Artificial Intelligence and Medical Humanities","Journal of Medical Humanities","","10413545","10.1007/s10912-020-09636-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088927968&doi=10.1007%2fs10912-020-09636-4&partnerID=40&md5=53ea81de6d941d02b11180d7678fa092","The use of artificial intelligence in healthcare has led to debates about the role of human clinicians in the increasingly technological contexts of medicine. Some researchers have argued that AI will augment the capacities of physicians and increase their availability to provide empathy and other uniquely human forms of care to their patients. The human vulnerabilities experienced in the healthcare context raise the stakes of new technologies such as AI, and the human dimensions of AI in healthcare have particular significance for research in the humanities. This article explains four key areas of concern relating to AI and the role that medical/health humanities research can play in addressing them: definition and regulation of “medical” versus “health” data and apps; social determinants of health; narrative medicine; and technological mediation of care. Issues include data privacy and trust, flawed datasets and algorithmic bias, racial discrimination, and the rhetoric of humanism and disability. Through a discussion of potential humanities contributions to these emerging intersections with AI, this article will suggest future scholarly directions for the field. © 2020, The Author(s).","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9U8NUWW","journalArticle","2020","Johnson, J.","Delegating strategic decision-making to machines: Dr. Strangelove Redux?","Journal of Strategic Studies","","01402390","10.1080/01402390.2020.1759038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084253030&doi=10.1080%2f01402390.2020.1759038&partnerID=40&md5=6b22890c802c9b5864b40f003515f307","Will the use of artificial intelligence (AI) in strategic decision-making be stabilizing or destabilizing? What are the risks and trade-offs of pre-delegating military force (or automating escalation) to machines? How might non-nuclear state and non-state actors leverage AI to put pressure on nuclear states? This article analyzes the impact of strategic stability of the use of AI in the strategic decision-making process, in particular, the risks and trade-offs of pre-delegating military force (or automating escalation) to machines. It argues that AI-enabled decision support tools, by substituting the role of human critical thinking, empathy, creativity, and intuition in the strategic decision-making process, will be fundamentally destabilizing if defense planners come to view AI’s ‘support’ function as a panacea for the cognitive fallibilities and human analysis and decision-making. The article also considers the nefarious use of AI-enhanced fake news, deepfakes, bots, and other forms of social media by non-state actors and state proxy actors, which might cause states to exaggerate a threat from ambiguous or manipulated information, increasing instability. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","","","","","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8B7KUQZH","conferencePaper","2020","Cuzzocrea, A.; Pilato, G.; Fadda, E.","User Emotion Detection via Taxonomy Management: An Innovative System","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090910046&partnerID=40&md5=1c4cc85cd34e6ad583f7d0a421bc953d","Catching the attention of a new acquaintance and empathize with her can improve the social skills of a robot. For this reason, we illus-trate here the first step towards a system which can be used by a social robot in order to ""break the ice""between a robot and a new acquain-tance. After a training phase, the robot acquires a sub-symbolic coding of the main concepts being expressed in tweets about the IAB Tier-1 categories. Then this knowledge is used to catch the new acquaintance interests, which let arouse in her a joyful sentiment. The analysis process is done alongside a general small talk, and once the process is finished, the robot can propose to talk about something that catches the attention of the user, hopefully letting arise in him a mix of feelings which involve surprise and joy, triggering, therefore, an engagement between the user and the social robot. ©2020 for this paper by its authors.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","334-342","","","2646","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 28th Italian Symposium on Advanced Database Systems, SEBD 2020 ; Conference Date: 21 June 2020 Through 24 June 2020; Conference Code:162162</p>","","","Social robots; Social skills; Educational robots; Database systems; User emotions; Analysis process; Innovative systems; Sub-symbolic; Training phase","","Agosti M., Tanca L., Atzori M., Ciaccia P.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NK9PK8ZM","journalArticle","2020","Hickton, L.; Lewis, M.; Cañamero, L.","Expression of Grounded Affect: How Much Emotion Can Arousal Convey?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-63486-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231","In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","234-248","","","12228 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783030634858 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 21th Annual Conference on Towards Autonomous Robotics, TAROS 20120 ; Conference Date: 16 September 2020 Through 16 September 2020; Conference Code:252749</p>","","","Robotics; Social robots; Humanoid robot; Anthropomorphic robots; Affective state; Control robots; Exploratory studies; Hexapod robots; Simple modeling","","Mohammad A., Russo M., Dong X.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q28YISCM","journalArticle","2020","Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.","Emotion Synchronization Method for Robot Facial Expression","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-49062-1_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20","Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","644-653","","","12182 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030490614 Publisher: Springer","<p>cited By 0; Conference of Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242229</p>","","","Robots; Synchronization; Communication robot; Emotion estimation; Facial Expressions; Human computer interaction; Human robots; Biological signals; Human emotion; Subjective impressions; Synchronization method","","M, Kurosu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3CEQYS7","journalArticle","2020","Sulistiadi, W.; Nurhidayah, S.; Asyary, Al","Evaluating the management information system of integrated medical emergency care in batang regency, Indonesia","International journal of online and biomedical engineering","","26268493","10.3991/ijoe.v16i07.14725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089019653&doi=10.3991%2fijoe.v16i07.14725&partnerID=40&md5=30a783d732c6318be26f5be2d426c911","An emergency can happen anywhere and anytime, especially in developing countries with a high potential for emergencies, such as Eastern European countries as well as Indonesia. This study aimed to find out the quality of PSC 119 Si Slamet as a prehospital emergency service innovation. The data collection in this study was carried out in a location, namely, Batang Regency, Indonesia, in May-June 2018. The qualitative data collection methods used in this study are in-depth interviews and document reviews. This study was using Service Quality (Servqual) questionnaire. The results show that PSC 119 Si Slamet provides easy access to emergency services to the community 24 hours a day and 7 days a week by simply calling 119 numbers, sending messages via SMS and WhatsApp, or using the Android-based application, with a maximum response time target of 10 minutes. Batang is one of the regencies (rural area) in Central Java province, located on the main coastline, with a hilly geographic condition with many derivatives, climbs, and sharp curves, which is one of the causes of the high number of traffic accidents in the area. This emergency care information systems, with Android-based application, was aimed at improving the quality of services in the health sector, especially emergency services. This service is of good quality as seen from the tangible, reliability, responsiveness, assurance, and empathy dimensions. However, in the implementation, the socialization aspect is not the best to some people. The recommendation given was the need to increase the PSC 119 socialization of Si Slamet not only regionally but also internationally to be massive, especially in developing countries. © 2020 Kassel University Press GmbH.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","75-85","","7","16","","","","","","","","","","English","","","","","","","Publisher: Kassel University Press GmbH","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W6KBFRX","journalArticle","2020","Fowler, M.; Hayes, A.; Binzani, K.","The social net of sentiment: Improving the base sentiment analysis of high impact events with lexical category exploration","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-29513-4_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072846786&doi=10.1007%2f978-3-030-29513-4_22&partnerID=40&md5=921e4281b8adfcb37cbe2942a73a1bc8","Social networking has created a large source of peoples’ opinions and statements available on the internet. This is particularly true in the case of high impact events, such as the Parkland school shooting in Florida. This paper approaches the analysis of high impact events in two ways. First, tweet sentiment analysis using the NLTK machine learning standard with TextBlob is applied. This approach is then augmented with lexical categorical analysis using the Python tool Empath as an added analysis step. The TextBlob standards are compared to Empath’s sentiment analysis results to compare the accuracy of the two methods. The paper presents this combined approach to improve sentiment analysis by using Empath as an added analysis step and briefly discuss future further refinements. © Springer Nature Switzerland AG 2020.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","312-320","","","1038","","","","","","","","","","English","","","","","","","ISBN: 9783030295127 Publisher: Springer Verlag","<p>cited By 0; Conference of Intelligent Systems Conference, IntelliSys 2019 ; Conference Date: 5 September 2019 Through 6 September 2019; Conference Code:231009</p>","","","Sentiment analysis; Intelligent systems; Empath; Florida; High impact events; Lexical categories; NLTK; Two ways","","Bi Y., Kapoor S., Bhatia R.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2I32JEQ","journalArticle","2020","Davis, A.E.","The future of law firms (and lawyers) in the age of artificial intelligence [O Futuro dos escritorios de advocacia (e dos advogados) na era da inteligencia artificial]","Revista Direito GV","","23176172","10.1590/2317-6172201945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090527121&doi=10.1590%2f2317-6172201945&partnerID=40&md5=fc37caa4e681a8f07c4ae6a46375adb7","This article explores the future for lawyers and law firms in the light of the changes that Artificial Intelligence (""AI"") is already bringing to the universe of legal services. Part I briefly describes some of the ways AI is already in use in ordinary life-from facial recognition, through medical diagnosis to translation services. Part II describes how AI is transforming what it means to provide legal services in six primary areas: Litigation review; expertise automation; legal research; contract analytics; contract and litigation document generation; and predictive analytics. Part III explores who are the providers of these AI driven legal services-often non-lawyer legal service providers-and how these providers are replacing at least some of what clients have traditionally sought from lawyers. Part III also discusses the implications of all these changes both for the future role of lawyers individually, and in particular what services will clients still need lawyers to perform: Judgment, empathy, creativity and adaptability. In turn, this Part examines what will these changes mean for the size, shape, composition and economic model of law firms, as well as the implications of these changes for legal education and lawyer training. Part IV identifies the principal legal, ethical, regulatory and risk management issues raised by the use of AI in the provision of legal services. Finally, in Part V the article considers who will be the likely providers of AI based services other than law firms: Legal publishers, major accounting firms and venture capital funded businesses. © 2020 Fundacao Getulio Vargas, Escola de Direito de Sao Paulo. All rights reserved.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","1DUMMT","","1","16","","","","","","","","","","English","","","","","","","Publisher: Fundacao Getulio Vargas, Escola de Direito de Sao Paulo","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FEAVG67D","journalArticle","2020","Ho, J.C.F.; Ng, R.","Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion","Behaviour and Information Technology","","0144929X","10.1080/0144929X.2020.1864018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098553464&doi=10.1080%2f0144929X.2020.1864018&partnerID=40&md5=78bc6d559d259fece1c757b340b9b1ba","This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters–NPCs in a prosocial VR game–influences players’ in-game empathy towards NPCs and game immersion. Participants first experienced either a robot’s perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants’ game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players’ weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","","","","","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Ltd.","<p>cited By 0</p>","","","Virtual reality; empathy; virtual reality; Robots; robotics; Perspective taking; intimacy; immersion; article; human; human experiment; adult; female; male; Human computer interaction; Digital games; Game design; Gameplay experiences; Indirect effects; Non-player character; theoretical study; video game; Video game; Weekly exposures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R38UZTQ2","journalArticle","2020","Johanson, D.L.; Ahn, H.S.; Broadbent, E.","Improving Interactions with Healthcare Robots: A Review of Communication Behaviours in Social and Healthcare Contexts","International Journal of Social Robotics","","18754791","10.1007/s12369-020-00719-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095992051&doi=10.1007%2fs12369-020-00719-9&partnerID=40&md5=f3f195ead2052764e3a972a247dbf24f","A growing shortfall exists between the number of older individuals who require healthcare support and the number of qualified healthcare professionals who can provide this. Robots offer the potential to provide healthcare support to patients both at home and in healthcare settings. However, in order for robots to be successfully implemented in these environments, they need to behave in ways that are appropriate and acceptable to human users. One way to identify appropriate social behaviours for healthcare robots is to model their behaviour on interactions between healthcare professionals and patients. This literature review aimed to inform healthcare robotics research by highlighting communication behaviours that are important within the context of healthcare. The review focussed on relevant research in human clinical interactions, followed by a review of similar factors in social robotics research. Three databases were searched for terms relating to healthcare professional communication behaviours associated with patient outcomes. The results identified key communication behaviours that can convey clinical empathy, including humour, self-disclosure, facial expressions, eye gaze, body posture, and gestures. A further search was conducted to identify research examining these key behaviours within the context of social and healthcare robotics. Research into these factors in human–robot interaction in healthcare is limited to date, and this review provides a useful guide for future research. © 2020, Springer Nature B.V.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 0</p>","","","Robotics; Social robots; Health care; Agricultural robots; Robot interactions; Facial Expressions; Clinical research; Health care professionals; Healthcare robotics; Healthcare support; Literature reviews; Similar factors; Social behaviour","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9T3RS9M","journalArticle","2020","Rehman, F.; Munawar, A.; Iftikhar, A.; Hassan, J.; Samiullah, F.; Gilani, M.B.A.; Qasim, A.; Qasim, N.","Design and development of ai-based mirror neurons agent towards emotion and empathy","International Journal of Advanced Computer Science and Applications","","2158107X","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083223916&partnerID=40&md5=8442281cfab2a9fa3c207ade4eb4b124","Since numerous years, researchers have to outline keen operators to accomplish the Artificial General Intelligence. Each new science revelation is an open challenge to all researchers. More than twenty years prior to a group of researchers discovered exceptional cerebrum cells, called reflect neurons in monkeys. These cells gave off an impression of being actuated both when the monkey accomplished something itself and when the monkey basically watched another monkey do a similar thing. This new discovery opened a new door for a scientist because of Mirror Neurons functionalities that can be huge contribute to cognitive science, neuroscience, impacting on Artificial General Intelligence. Mirror neuron functionality improves the Machine's learning. This research paper develops models for social interaction in which a machine may have the ability to learn the next person emotional state using mirror neurons and show empathy towards emotions. © 2020, Science and Information Organization.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","386-395","","3","11","","","","","","","","","","English","","","","","","","Publisher: Science and Information Organization","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IP93VS4Y","journalArticle","2020","Salamea, C.; Narvaez, E.; Montalvo, M.","Database Proposal for Correlation of Glucose and Photoplethysmography Signals","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-32033-1_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075832713&doi=10.1007%2f978-3-030-32033-1_5&partnerID=40&md5=45bbbf2fd9db65145859d2c97a62f1e8","This work presents a Database that contains Photoplethysmography signals, glucose levels, weight, height and age of 217 patients. The information of biologic activity was obtained using the handle Empatica E4 Wristband, the glucose level using laboratory blood chemistry analyzers (Cobas 6000), and the physical parameters using standardized instruments. The database comprises a forward training a total of 5576 samples and another segment of validation to a total of 2164 samples. The Database has been used to evaluate different prediction techniques based on Machine Learning (Random Forest, Artificial Neural Network, Support Vector Machine, Gradient Boosting Machine). The implementation of these algorithms provides up to 90% average accuracy, a correlation of 0.88 and a satisfactory evaluation in the Error Diagram of Clarke. According to the results obtained, the proposed database is appropriate for training and verification of existing correlation between photoplethysmography signals and blood glucose level. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:17","2021-05-19 13:26:17","","44-53","","","1067","","","","","","","","","","English","","","","","","","ISBN: 9783030320324 Publisher: Springer","<p>cited By 1; Conference of 1st International Conference on Advances in Emerging Trends and Technologies, ICAETT 2019 ; Conference Date: 29 May 2019 Through 31 May 2019; Conference Code:233339</p>","","","Neural networks; Machine learning; Blood; Learning systems; Support vector machines; Decision trees; Database systems; Photoplethysmography; Adaptive boosting; Biologic activities; Blood chemistry; Blood glucose level; Error diagrams; Glucose; Gradient boosting; MFCCs; Physical parameters; Prediction techniques","","Botto-Tobar M., Montiel Diaz P., Leon-Acurio J., Diaz Cadena A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9EKHR6V","conferencePaper","2020","Diederich, S.; Janßen-Müller, M.; Brendel, A.B.; Morana, S.","Emulating empathetic behavior in online service encounters with sentiment-adaptive responses: Insights from an experiment with a conversational agent","40th International Conference on Information Systems, ICIS 2019","978-0-9966831-9-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084712323&partnerID=40&md5=3bac47ce26f79d1c1ad3069daa0798f2","Conversational agents currently attract strong interest for technology-based service provision due to increased capabilities driven by advances in machine learning and natural language processing. The interaction via natural language in combination with a human-like design promises service that is always available, fast, and with a consistent quality and at the same time resembles a human service encounter. However, current conversational agents exhibit the same inherent limitation that every interactive technology has, which is a lack of social skills. In this study, we make a first step towards overcoming this limitation by presenting a design approach that combines automatic sentiment analysis with adaptive responses to emulate empathy in a service encounter. By means of an experiment with 112 participants, we evaluate the approach and find empirical support that a CA with sentiment-adaptive responses is perceived as more empathetic, human-like, and socially present and, in particular, yields a higher service encounter satisfaction. © 40th International Conference on Information Systems, ICIS 2019. All rights reserved.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","","","","","","","","","","","","Association for Information Systems","","English","","","","","","","","<p>cited By 4; Conference of 40th International Conference on Information Systems, ICIS 2019 ; Conference Date: 15 December 2019 Through 18 December 2019; Conference Code:158277</p>","","","Sentiment analysis; Empathy; Conversational agents; Learning algorithms; Information use; Anthropomorphic design; Information systems; Interactive services; Response theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EALK4FC5","journalArticle","2020","El Kamali, M.; Angelini, L.; Caon, M.; Lalanne, D.; Abou Khaled, O.; Mugellini, E.","An embodied and ubiquitous e-coach for accompanying older adults towards a better lifestyle","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-49065-2_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088749526&doi=10.1007%2f978-3-030-49065-2_2&partnerID=40&md5=1a62194f602971512a9ca4bd5e312c38","The population of people age 65 or over is increasing especially in Europe [3]. Granting to this target population a longer and healthier life is paramount for the European Community. In the context of the H2020 EU funded project “NESTORE” [11], an embodied and ubiquitous e-coach is being developed seeking to change the lifestyle of seniors in different domains of wellbeing. NESTORE e-coach is known as a personalized embodied and ubiquitous e-coach that plays three essential roles in elderly’s wellbeing: a coach, a friend and a companion. As a coach, NESTORE will give trainings and advice following a wellbeing path that is proposed by experts in wellbeing. As a friend, this e-coach knows and understands the user. As a companion, this e-coach has the ability to detect the user’s emotion and aims at building empathy with the user based by providing support throughout their daily training. The NESTORE e-coach is based on three different intervention medium: a mobile application, a chatbot and an embodied vocal assistant. These interfaces have different forms, different capabilities and different visions. Users can communicate with the NESTORE e-coach through different interfaces exclusively, sequentially, concurrently and synergistically. The interaction can be initiated from the user side to different interfaces and/or from the e-coach side. In this paper, we present the NESTORE’s full vision for building the three essential roles of this e-coach which are: a coach, a companion and a friend for seniors. Furthermore, we explain the NESTORE system design, architecture, capabilities and how the different interfaces of this E-coach contribute to make a multi-modal system. Finally, we conclude our work with the state of this H2020 project. © Springer Nature Switzerland AG 2020.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","23-35","","","12183 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030490645 Publisher: Springer","<p>cited By 4; Conference of Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242229</p>","","","Computer architecture; Chatbot; Wellbeing; Human computer interaction; Different domains; European community; Mobile applications; Multimodal system; Older adults","","M, Kurosu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYWX4I3Y","journalArticle","2020","Bae, B.-C.; Kim, H.-J.","A cooperative storytelling card game for conflict resolution and empathy","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-50164-8_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088745007&doi=10.1007%2f978-3-030-50164-8_27&partnerID=40&md5=fcbbebb6f3c1f3a09c94bdbf6d0e5ece","In this paper we present a prototype for a cooperative storytelling card game focusing on the resolution of conflict and empathy in a narrative. The story-making process in the proposed prototype design is based on Maslow’s hierarchy of needs, and consists of five types of story cards(characters, setting, objects/actions, goals, and emotions) as its story elements. We have developed and tested a prototype game using Unity3D game engine on an Android platform with two play modes - single-player and multi-player. In the multi-player mode, three players can play together: each player is assigned the role of an initiator, a conflictor and a mediator in wireless network environments. Our ultimate goal is to encourage players to empathize with other players by letting them create and resolve (or mediate) emotional conflicts through the process of perspective-taking in a collaborative storytelling game. © Springer Nature Switzerland AG 2020.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","375-384","","","12211 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030501631 Publisher: Springer","<p>cited By 0; Conference of 2nd International Conference on HCI in Games, HCI-Games 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242399</p>","","","Perspective taking; Human computer interaction; Android platforms; Computer games; Conflict Resolution; Cooperative storytelling; Game Engine; Making process; Prototype designs; Wireless network environment","","X, Fang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78EHW354","journalArticle","2020","Wei, L.; Wu, G.-R.; Bi, M.; Baeken, C.","Effective connectivity predicts cognitive empathy in cocaine addiction: a spectral dynamic causal modeling study","Brain Imaging and Behavior","","19317557","10.1007/s11682-020-00354-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088566060&doi=10.1007%2fs11682-020-00354-y&partnerID=40&md5=835728f0a909b8384890b1442ede8006","Social cognition plays a crucial role in the development and treatment of cocaine dependence. However, studies investigating social cognition, such as empathy and its underlying neural basis, are lacking. To explore the neural interactions among reward and memory circuits, we applied effective connectivity analysis on resting-state fMRI data collected from cocaine-dependent subjects. The relationship between effective connectivity within these two important circuits and empathy ability - evaluated with the Interpersonal Reactivity Index (IRI) - was assessed by machine learning algorithm using multivariate regression analysis. In accordance with the neurocircuitry disruptions of cocaine addiction, the results showed that cocaine-dependent subjects relative to healthy controls had altered resting state effective connectivity between parts of the memory and reward systems. Furthermore, effective connectivity between the memory and reward system could predict the fantasy empathy (FE) subscale scores in cocaine dependence. Overall, our findings provide further evidence for the neural substrates of social cognition in cocaine-dependent patients. These new insights could be useful for the development of new treatment programs for this substance dependency disorder. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7E9HMBI","journalArticle","2020","Sejima, Y.; Sato, Y.; Watanabe, T.","Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-20441-9_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b","Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","95-102","","","952","","","","","","","","","","English","","","","","","","ISBN: 9783030204402 Publisher: Springer Verlag","<p>cited By 0; Conference of AHFE International Conference on Affective and Pleasurable Design, 2019 ; Conference Date: 24 July 2019 Through 28 July 2019; Conference Code:226989</p>","","","Empathy; Human robot interaction; Pupil response; Man machine systems; Non-verbal communications; Body contacts; Emotional expressions; Face to face; Measurement device; Pet Robots","","S, Fukuda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8K84D5C","conferencePaper","2020","Sedoc, J.; Buechel, S.; Nachmany, Y.; Buffone, A.; Ungar, L.","Learning word ratings for empathy and distress from document-level user responses","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings","979-10-95546-34-4","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096597898&partnerID=40&md5=5c3de64d2b5ef62d84ba3bb9cec6e99e","Despite the excellent performance of black box approaches to modeling sentiment and emotion, lexica (sets of informative words and associated weights) that characterize different emotions are indispensable to the NLP community because they allow for interpretable and robust predictions. Emotion analysis of text is increasing in popularity in NLP; however, manually creating lexica for psychological constructs such as empathy has proven difficult. This paper automatically creates empathy word ratings from document-level ratings. The underlying problem of learning word ratings from higher-level supervision has to date only been addressed in an ad hoc fashion and has not used deep learning methods. We systematically compare a number of approaches to learning word ratings from higher-level supervision against a Mixed-Level Feed Forward Network (MLFFN), which we find performs best, and use the MLFFN to create the first-ever empathy lexicon. We then use Signed Spectral Clustering to gain insights into the resulting words. The empathy and distress lexica are publicly available at: http://www.wwbp.org/lexica.html. © European Language Resources Association (ELRA), licensed under CC-BY-NC","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","1664-1673","","","","","","","","","","","European Language Resources Association (ELRA)","","English","","","","","","","","<p>cited By 1; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>","","","Deep learning; Clustering algorithms; Learning systems; Natural language processing systems; Approaches to learning; Black box approach; Emotion analysis; Feed-forward network; Feedforward neural networks; Gain insight; Learning methods; Robust predictions; Spectral clustering","","Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35QFVLV8","journalArticle","2020","Sevİm, C.; Atasoy, R.","Evaluation Of Inclusive Practices According To The Opinions Of Special Education Teachers [Özel Eğİtİm Öğretmenlerİnİn Görüşlerİne Göre Kaynaştirma Uygulamalarinin Değerlendİrİlmesİ]","Milli Egitim","","13025600","10.37669/milliegitim.588614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103327890&doi=10.37669%2fmilliegitim.588614&partnerID=40&md5=1838522a4bbd1e802d09ee6512860697","In this study, it is aimed to evaluate inclusive practices in schools according to the opinions of special education teachers working in TRNC. The research is designed in qualitative research methods, phenomenology patterns using interview techniques. The study group consists of 17 special education teachers. The data were analyzed by content analysis. In the study, it was concluded that there are problems arising from legal and administrative deficiencies within the Ministry of National Education. It has been revealed that the problems encountered in inclusion practices are not simple enough to be overcome only by legal regulations, but that these problems are a system problem. Deficiencies in managerial processes affect all processes of inclusion practices. This situation hinders the academic and social development of the inclusion student and it is concluded that it plays a slowing role in achieving the desired integration objectives. Another important result of the study is that the social and cultural context is effective as the source of the problems related to inclusion practices. It was concluded that this situation leads to deep turmoil in the emotion world of inclusion students. In this context, it has been revealed that the empathy, knowledge and awareness levels of all stakeholders related to inclusion should be improved. In addition, it was emphasized that the inclusion process contributes positively to the attitudes, behaviors and learning of students who show normal development. Another result is revealed that all stakeholders, from top level decision makers, to education administrators, from teachers to students and parents, should take responsibility concerning inclusion policies in a coordinated and planned manner, in order to achieve the standard and quality in the education systems of developed countries. In addition, instead of focusing on academic achievement to overcome the difficulties experienced and support stakeholders, it was emphasized that take into account individual differences and necessity of the use of technology, artificial intelligence and robotic applications in learning processes. The research is important for educational and managerial analysis of inclusion practices in school organizations. © 2020, Milli Egitim. All Rights Reserved.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","215-239","","228","49","","","","","","","","","","Turkish","","","","","","","Publisher: T.C. Milli Egitim Bakanligi","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2PWQV5Y","conferencePaper","2020","Firdaus, M.; Ekbal, A.; Bhattacharyya, P.","Incorporating politeness across languages in customer care responses: Towards building a multi-lingual empathetic dialogue agent","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings","979-10-95546-34-4","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096584871&partnerID=40&md5=7e8e8d8f2bef5ac7638ad3b967c8b7f7","Customer satisfaction is an essential aspect of customer care systems. It is imperative for such systems to be polite while handling the customer requests or demands. In this paper, we present a large multi-lingual conversational dataset for English and Hindi. We choose data from Twitter having both generic and courteous responses between customer care agents and aggrieved users. We also propose strong baselines that can induce courteous behaviour in generic customer care response in a multi-lingual scenario. We build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agent's responses. Our system is competent in generating responses in different languages (here, English and Hindi) depending on the customer's preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention. Experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system. Qualitative and quantitative analysis show that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction. © European Language Resources Association (ELRA), licensed under CC-BY-NC","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","4172-4182","","","","","","","","","","","European Language Resources Association (ELRA)","","English","","","","","","","","<p>cited By 0; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>","","","Deep learning; Linguistics; Customer satisfaction; Sales; Customer care; Customer care systems; Information shared; Large dataset; Learning frameworks; Qualitative and quantitative analysis","","Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E6WFDILN","journalArticle","2020","Chung, S.-E.; Ryoo, H.-Y.","Gesture design attribute and level value of social robot: A user experience based study","Journal of System and Management Sciences","","18166075","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3","This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","108-121","","2","10","","","","","","","","","","English","","","","","","","Publisher: Success Culture Press","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWEV5B6B","journalArticle","2020","Bergen, J.P.","Love(rs) in the making: Moral subjectivity in the face of sexbots","Paladyn","","20814836","10.1515/pjbr-2020-0016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088011901&doi=10.1515%2fpjbr-2020-0016&partnerID=40&md5=a1955bd5c3aa900399f2f1c1ffd6180d","This article offers a novel reading of the criticisms of sex robots put forward by the Campaign Against Sex Robots (CASR). Focusing on the implication of a loss of empathy, it structures CASR's worries as an argument from moral degradation centered around the potential effects on sexbot users' sexual and moral subjectivity. This argument is subsequently explored through the combined lenses of postphenomenology and the ethical phenomenology of Emmanuel Levinas. In so doing, it describes the type of human-technology relations that sexbots invite, identifying alterity as a central feature. It also highlights how alterity, responsibility, and subjectivity are intimately connected. However, that connection is distinctly different in sexual circumstances, making current versions of Levinasian roboethics largely inapplicable for the ethics of sexbots. To overcome this, the article delves into Levinas' phenomenology of Eros and identifies voluptuousness as a type of enjoyment of the Other that is different from the enjoyment invited by current sexbots and is compatible with responsibility. Based on this, the article provides examples of how this phenomenology of Eros can inspire the design of future sexbots in ways that alleviate some of CASR's concerns. © 2020 Jan Peter Bergen, published by De Gruyter 2020.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","284-300","","1","11","","","","","","","","","","English","","","","","","","Publisher: De Gruyter","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WY6VIJCV","journalArticle","2020","Balistreri, M.; Casile, F.","Care Robots: From Tools of Care to Training Opportunities. Moral Considerations","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-23884-1_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068643881&doi=10.1007%2f978-3-030-23884-1_3&partnerID=40&md5=ddeacd68dcfb7fbd19f08f5b10213563","New technology should not perceived as a threat: on the contrary, it is a resource. It is our job to use it in the most appropriate way. Moreover, new technology can make a significant contribution to nurse training: for example, immersion into virtual reality with a visor and a simple application does not only allow one to experience fantastic adventures, but also to enjoy a relationship with the patient through simulation. Also, virtual reality can promote patient/teacher interaction: both, for example, can be projected or immersed in virtual reality, or the teacher can project his ‘virtual’ image into a real scenario. However, robots too could contribute to training nursing staff: health operator training courses today widely use dummies which are appropriately planned for standing training. They are increasingly true-to-life, favouring empathy with the clinical situation simulated each time and allowing the student to exercise not only technical abilities, but also critical thinking, the ability to work in a team and communication skills. We shall examine some moral questions linked to the increasingly frequent use of human-faceted robots to train nursing staff. © 2020, Springer Nature Switzerland AG.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","18-25","","","1008","","","","","","","","","","English","","","","","","","ISBN: 9783030238834 Publisher: Springer Verlag","<p>cited By 3; Conference of 9th International Conference in Methodologies and Intelligent Systems for Technology Enhanced Learning, MIS4℡ 2019 ; Conference Date: 26 June 2019 Through 28 June 2019; Conference Code:227919</p>","","","Virtual reality; Robots; Intelligent systems; Communication skills; Critical thinking; Students; Bioethics; Learning systems; Carebots; Clinical situations; Nursing; Nursing staff; Operator training; Personnel training","","Popescu E., Mavroudi A., Belen Gil A., Lancia L., Simona Sica L.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCH46ULA","journalArticle","2020","Księżopolska, I.","Can Androids Write Science Fiction? Ian McEwan’s Machines like Me","Critique - Studies in Contemporary Fiction","","00111619","10.1080/00111619.2020.1851165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096586219&doi=10.1080%2f00111619.2020.1851165&partnerID=40&md5=f654e96e86eeb1f62ef29028328451ef","McEwan’s novel Machines Like Me was met with lukewarm reviews and open hostility of the sci-fi genre adherents. It seemed to have appropriated some of the key issues of the genre discourse–the question of what constitutes humanity, of the possibility of coexistence between humans and AI, of the problems of morality and consent. It also made use of time-honored devices of alternative history without treating it too seriously. Instead, the characters are enmeshed in personal problems and conundrums of science and politics, justice and empathy–and love. McEwan’s commentary on the novel in various interviews only aggravated the critics who were all too ready to conclude that Machines Like Me offered little originality. This essay will demonstrate that the text is carefully layered as if to protect its own novelty hidden beneath rather conventional love triangle plot, ponderous political commentary, and genre-specific topicality. It will be an effort to understand the complex relation between the writer and conventions which come into play in his novel, and it will proceed to read the text against the authorial comments, finding suppressed hints that invite an interpretation of the text as narrated by its android hero rather than human subject. © 2020 Taylor & Francis Group, LLC.","2020","2021-05-19 13:26:18","2021-05-19 13:26:18","","","","","","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"989ZZA9H","conferencePaper","2020","Costantini, S.; de Gasperis, G.; Di Mascio, T.; Migliarini, P.; Salutari, A.","Proposal of a empathic multi-agent robot design based on theory of mind","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094832966&partnerID=40&md5=35662413b3c3c302f4898cbd82eb8251","We propose a reference design of a social robot controller with the capability to have an emotional communication with a human, e.g. a robot who can recognize and show emotions; the proposed design is based on a multi-channel input-output pattern and a reasoning system that takes into account the states and the values of those channels. The multi-agent system can meet the needs of the design requirements and bring it closer to the human behaviour through application of a recently formalized theory of mind in the implementation of agents. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2020","2021-05-19 13:26:19","2021-05-19 13:26:19","","16-17","","","2696","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 2020 Workshop on Adapted Interaction with Social Robots, cAESAR 2020 ; Conference Date: 17 March 2020; Conference Code:163832</p>","","","Social robots; Machine design; Behavioral research; Multi agent systems; Theory of minds; Emotional communications; Human behaviours; Multi agent; Multi channel; Reasoning system; Reference designs; Robot controller","","De Carolis B., Sciutti A., Gena C., Lieto A., Rossi S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WF84PS7M","journalArticle","2020","Pribbenow, C.M.; Caldwell, K.E.H.; Dantzler, D.D.; Brown, Jr., P.; Carnes, M.","Decreasing Racial Bias Through A Facilitated Game and Workshop: The Case of Fair Play","Simulation and Gaming","","10468781","10.1177/1046878120983384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098243099&doi=10.1177%2f1046878120983384&partnerID=40&md5=d34a04335f4fc627541d343be8135d8e","Introduction. Fair Play is an avatar-based role-playing video game in which Jamal Davis, a Black graduate student at a research university, navigates implicit forms of racial bias to reach the win-state of earning his PhD and becoming a professor. Fair Play was designed to educate players on the existence of racial bias in science, technology, engineering, mathematics, and medicine (STEMM) fields in an experiential way and to encourage perspective-taking. Research has found that taking the perspective of another can induce empathy, which improves the empathizer’s attitudes towards individuals and groups. Paired with a facilitated workshop, Fair Play was also designed to teach bias concepts to increase participants’ bias literacy. Intervention. Research on workshops to reduce gender bias suggests that it increased awareness of personal bias, the motivation and self-efficacy to practice bias-reducing strategies, and a more welcoming department climate and the hiring of more women faculty three years after the intervention. Capitalizing on these findings, a 3-hour workshop was developed to reduce race-based bias against Black/African Americans in STEMM using Fair Play. Conclusions. The facilitation of the workshops and Fair Play requires particular competencies due to its topic (racial bias) and player’s skepticism about the reality of the bias incidents. Our data suggest that participants who identify as a person of color are more likely to believe that bias exists compared to White players, which can lead to a discussion about how the incidents in the game were designed and scripted. The facilitator also needs to be versed in a number of intentional design choices, such as Jamal not having voiceover and his success. Finally, this paper describes the Facilitator Game, which was developed as a complement to the game and allows a facilitator to jump to bias incidents quickly while debriefing and discussing the game to further participant learning. © 2020 SAGE Publications.","2020","2021-05-19 13:26:19","2021-05-19 13:26:19","","","","","","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HS7EKX4","journalArticle","2020","Tammvee, M.; Anbarjafari, G.","Human activity recognition-based path planning for autonomous vehicles","Signal, Image and Video Processing","","18631703","10.1007/s11760-020-01800-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092649407&doi=10.1007%2fs11760-020-01800-6&partnerID=40&md5=268f4bc715c07a4803c37f1e75e634f3","Human activity recognition (HAR) is a wide research topic in a field of computer science. Improving HAR can lead to massive breakthrough in humanoid robotics, robots used in medicine and in the field of autonomous vehicles. The system that is able to recognise human and its activity without any errors and anomalies would lead to safer and more empathetic autonomous systems. During this research work, multiple neural networks models, with different complexity, are being investigated. Each model is re-trained on the proposed unique data set, gathered on automated guided vehicle (AGV) with the latest and the modest sensors used commonly on autonomous vehicles. The best model is picked out based on the final accuracy for action recognition. Best models pipeline is fused with YOLOv3, to enhance the human detection. In addition to pipeline improvement, multiple action direction estimation methods are proposed. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","2020","2021-05-19 13:26:19","2021-05-19 13:26:19","","","","","","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 1</p>","","","Pipelines; Anthropomorphic robots; Pattern recognition; Humanoid robotics; Action recognition; Automated guided vehicles; Automatic guided vehicles; Autonomous systems; Autonomous vehicles; Direction estimation; Human activity recognition; Human detection; Multiple neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VNKF7P5","conferencePaper","2020","Ito, K.; Murata, M.; Ohno, T.; Matsubara, S.","Relation between degree of empathy for narrative speech and type of responsive utterance in attentive listening","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings","979-10-95546-34-4","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512903&partnerID=40&md5=1ff80d168c8d91743e767819a0d7b887","Nowadays, spoken dialogue agents such as communication robots and smart speakers listen to narratives of humans. In order for such an agent to be recognized as a listener of narratives and convey the attitude of attentive listening, it is necessary to generate responsive utterances. Moreover, responsive utterances can express empathy to narratives and showing an appropriate degree of empathy to narratives is significant for enhancing speaker's motivation. The degree of empathy shown by responsive utterances is thought to depend on their type. However, the relation between responsive utterances and degrees of the empathy has not been explored yet. This paper describes the classification of responsive utterances based on the degree of empathy in order to explain that relation. In this research, responsive utterances are classified into five levels based on the effect of utterances and literature on attentive listening. Quantitative evaluations using 37,995 responsive utterances showed the appropriateness of the proposed classification. © European Language Resources Association (ELRA), licensed under CC-BY-NC","2020","2021-05-19 13:26:19","2021-05-19 13:26:19","","696-701","","","","","","","","","","","European Language Resources Association (ELRA)","","English","","","","","","","","<p>cited By 0; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>","","","Social robots; Communication robot; Quantitative evaluation; Spoken dialogue","","Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H22LZNMD","journalArticle","2020","Rafique, M.; Hassan, M.A.; Jaleel, A.; Khalid, H.; Bano, G.","A Computation Model for Learning Programming and Emotional Intelligence","IEEE Access","","21693536","10.1109/ACCESS.2020.3015533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091848953&doi=10.1109%2fACCESS.2020.3015533&partnerID=40&md5=184fadf767e187ea5ac11feef75422fd","Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface. © 2013 IEEE.","2020","2021-05-19 13:26:19","2021-05-19 13:26:19","","149616-149629","","","8","","","","","","","","","","English","","","","","","","Publisher: Institute of Electrical and Electronics Engineers Inc.","<p>cited By 1</p>","","","Emotional intelligence; Students; Computation theory; Computation model; Computational model; Computational thinkings; Education computing; Learning programming; Programming concepts; Programming instruction; Robot programming; Social awareness; State of the art","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93VKZP4G","journalArticle","2019","Garry, T.; Harwood, T.","Cyborgs as frontline service employees: a research agenda","Journal of Service Theory and Practice","","20556225","10.1108/JSTP-11-2018-0241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074584047&doi=10.1108%2fJSTP-11-2018-0241&partnerID=40&md5=15f55b8c562c90163fc7f349181f357f","Purpose: The purpose of this paper is to identify and explore potential applications of cyborgian technologies within service contexts and how service providers may leverage the integration of cyborgian service actors into their service proposition. In doing so, the paper proposes a new category of “melded” frontline employees (FLEs), where advanced technologies become embodied within human actors. The paper presents potential opportunities and challenges that may arise through cyborg technological advancements and proposes a future research agenda related to these. Design/methodology/approach: This study draws on literature in the fields of services management, artificial intelligence, robotics, intelligence augmentation (IA) and human intelligence to conceptualise potential cyborgian applications. Findings: The paper examines how cyborg bio- and psychophysical characteristics may significantly differentiate the nature of service interactions from traditional “unenhanced” service interactions. In doing so, the authors propose “melding” as a conceptual category of technological impact on FLEs. This category reflects the embodiment of emergent technologies not previously captured within existing literature on cyborgs. The authors examine how traditional roles of FLEs will be potentially impacted by the integration of emergent cyborg technologies, such as neural interfaces and implants, into service contexts before outlining future research directions related to these, specifically highlighting the range of ethical considerations. Originality/value: Service interactions with cyborg FLEs represent a new context for examining the potential impact of cyborgs. This paper explores how technological advancements will alter the individual capacities of humans to enable such employees to intuitively and empathetically create solutions to complex service challenges. In doing so, the authors augment the extant literature on cyborgs, such as the body hacking movement. The paper also outlines a research agenda to address the potential consequences of cyborgian integration. © 2019, Emerald Publishing Limited.","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","415-437","","4","29","","","","","","","","","","English","","","","","","","Publisher: Emerald Group Publishing Ltd.","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SUG22CSN","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting future alleviation of mental illness in social media: An empathy-based social network perspective","Proceedings - 2019 IEEE Intl Conf on Parallel and Distributed Processing with Applications, Big Data and Cloud Computing, Sustainable Computing and Communications, Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019","978-1-72814-328-6","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085484201&doi=10.1109%2fISPA-BDCloud-SustainCom-SocialCom48970.2019.00230&partnerID=40&md5=b25cfa36d495be8d70325de2a2fd3932","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed. © 2019 IEEE.","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","1564-1571","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 17th IEEE International Conference on Parallel and Distributed Processing with Applications, 9th IEEE International Conference on Big Data and Cloud Computing, 9th IEEE International Conference on Sustainable Computing and Communications, 12th IEEE International Conference on Social Computing and Networking, ISPA/BDCloud/SustainCom/SocialCom 2019 ; Conference Date: 16 December 2019 Through 18 December 2019; Conference Code:158833</p>","","","Deep learning; Decision making; Big data; Forecasting; Predictive models; Cloud computing; Learning algorithms; Diseases; Social networking (online); Behavioral research; Dynamic features; Early intervention; Efficient computation; Filtration; Information loss; Information sources; Psychological characteristics; User behaviour","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQ7ZUQTH","journalArticle","2019","Wilde, P.; Evans, A.","Empathy at play: Embodying posthuman subjectivities in gaming","Convergence","","13548565","10.1177/1354856517709987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070362093&doi=10.1177%2f1354856517709987&partnerID=40&md5=aab7a0ce8378b091e336a622000c3483","In this article, we address the need for a posthuman account of the relationship between the avatar and player. We draw on a particular line of posthumanist theory associated closely with the work of Karen Barad, Rosi Braidotti and N. Katherine Hayles that suggests a constantly permeable, fluid and extended subjectivity, displacing the boundaries between human and other. In doing so, we propose a posthuman concept of empathy in gameplay, and we apply this concept to data from the first author’s 18-month ethnographic field notes of gameplay in the MMORPG World of Warcraft. Exploring these data through our analysis of posthuman empathy, we demonstrate the entanglement of avatar–player, machine–human relationship. We show how empathy allows us to understand this relationship as constantly negotiated and in process, producing visceral reactions in the intra-connected avatar–player subject as well as moments of co-produced in-game action that require ‘affective matching’ between subjective and embodied experiences. We argue that this account of the avatar–player relationship extends research in game culture, providing a horizontal, non-hierarchical discussion of its most necessary interaction. © The Author(s) 2017.","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","791-806","","5-6","25","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4D74BPS","conferencePaper","2019","Chiu, K.C.","Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation","IEEE International Conference on Industrial Engineering and Engineering Management","978-1-72813-804-6","","10.1109/IEEM44572.2019.8978876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079589864&doi=10.1109%2fIEEM44572.2019.8978876&partnerID=40&md5=9e2b70a2e94f2f185efda9854aa1323f","This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence. © 2019 IEEE.","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","1516-1520","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21573611","<p>cited By 0; Conference of 2019 IEEE International Conference on Industrial Engineering and Engineering Management, IEEM 2019 ; Conference Date: 15 December 2019 Through 18 December 2019; Conference Code:157321</p>","","","Semantics; Text mining; Artificial intelligence; Dream Consultation; Abstracting; Affective words; Knowledge management; Semantic-analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMG3JA9J","journalArticle","2019","Lee, Y.; Ha, M.; Kwon, S.; Shim, Y.; Kim, J.","Egoistic and altruistic motivation: How to induce users’ willingness to help for imperfect AI","Computers in Human Behavior","","07475632","10.1016/j.chb.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069643866&doi=10.1016%2fj.chb.2019.06.009&partnerID=40&md5=28cafea9d01522cf0bc054743c000c61","Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI. © 2019","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","180-196","","","101","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 4</p>","","","artificial intelligence; Artificial intelligence; empathy; trust; Trust; Willingness to help; reward; motivation; article; human; human experiment; AI systems; Food image; Human-in-the-loop; Image recognition; Monetary rewards; Motivation; Social study; sociology; stimulus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7I859D5F","journalArticle","2019","Carlson, Z.; Lemmon, L.; Higgins, M.C.; Frank, D.; Salek Shahrezaie, R.; Feil-Seifer, D.","Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers","International Journal of Social Robotics","","18754791","10.1007/s12369-019-00599-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074582945&doi=10.1007%2fs12369-019-00599-8&partnerID=40&md5=cda66cf87d85769abf9cea41a774b3cf","Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable. © 2019, The Author(s).","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","727-739","","5","11","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 5</p>","","","Sensory perception; Social robots; Mistreatment; Agricultural robots; Robot interactions; Behavioral research; Computer agents; Emotional feeling; Robot cooperation; Social settings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DYFUS2G","journalArticle","2019","Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farnè, A.; Dominey, P.F.; Pavani, F.","Embodiment into a robot increases its acceptability","Scientific Reports","","20452322","10.1038/s41598-019-46528-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069005120&doi=10.1038%2fs41598-019-46528-7&partnerID=40&md5=c7b84e03aa3b4bd20eb345fc595e7e4e","Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects’ head movements. As a result, participants saw themselves as a robot. When participant’ and robot’s head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots’ humanoid’s appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable. © 2019, The Author(s).","2019","2021-05-19 13:26:19","2021-05-19 13:26:19","","","","1","9","","","","","","","","","","English","","","","","","","Publisher: Nature Publishing Group","<p>cited By 5</p>","","","Female; Humans; Male; Young Adult; Robotics; Emotions; emotion; physiology; neuroscience; robotics; intimacy; social competence; article; human; human experiment; adult; female; male; young adult; human relation; Interpersonal Relations; procedures; attitude; Attitude; awareness; Awareness; eye; head movement; Head Movements; sensation; Social Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUDYNBDC","journalArticle","2019","O’Connell, K.; Brethel-Haurwitz, K.M.; Rhoads, S.A.; Cardinale, E.M.; Vekaria, K.M.; Robertson, E.L.; Walitt, B.; VanMeter, J.W.; Marsh, A.A.","Increased similarity of neural responses to experienced and empathic distress in costly altruism","Scientific Reports","","20452322","10.1038/s41598-019-47196-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069733023&doi=10.1038%2fs41598-019-47196-3&partnerID=40&md5=d20042af6e49a051649ad067549d4110","Empathy—affective resonance with others’ sensory or emotional experiences—is hypothesized to be an important precursor to altruism. However, it is not known whether real-world altruists’ heightened empathy reflects true self-other mapping of multi-voxel neural response patterns. We investigated this relationship in adults who had engaged in extraordinarily costly real-world altruism: donating a kidney to a stranger. Altruists and controls completed fMRI testing while anticipating and experiencing pain, and watching as a stranger anticipated and experienced pain. Machine learning classifiers tested for shared representation between experienced and observed distress. Altruists exhibited more similar representations of experienced and observed fearful anticipation spontaneously and following an empathy prompt in anterior insula and anterior/middle cingulate cortex, respectively, suggesting heightened empathic proclivities and abilities for fear. During pain epochs, altruists were distinguished by spontaneous empathic responses in anterior insula, anterior/mid-cingulate cortex and supplementary motor area, but showed no difference from controls after the empathy prompt. These findings (1) link shared multi-voxel representations of the distress of self and others to real-world costly altruism, (2) reinforce distinctions between empathy for sensory states like pain and anticipatory affective states like fear, and (3) highlight the importance of differentiating between the proclivity and ability to empathize. © 2019, The Author(s).","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","","","1","9","","","","","","","","","","English","","","","","","","Publisher: Nature Publishing Group","<p>cited By 3</p>","","","Brain; Adult; Female; Humans; Male; brain; physiology; Magnetic Resonance Imaging; Empathy; empathy; altruism; psychology; human; adult; female; male; diagnostic imaging; functional neuroimaging; nuclear magnetic resonance imaging; distress syndrome; Altruism; donor; Functional Neuroimaging; kidney; Kidney; Psychological Distress; Tissue Donors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R6QK2BX2","journalArticle","2019","Krohne, L.G.; Wang, Y.; Hinrich, J.L.; Moerup, M.; Chan, R.C.K.; Madsen, K.H.","Classification of social anhedonia using temporal and spatial network features from a social cognition fMRI task","Human Brain Mapping","","10659471","10.1002/hbm.24751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070672968&doi=10.1002%2fhbm.24751&partnerID=40&md5=a024b6f27ce7b57e61c0dcaee4172c31","Previous studies have suggested that the degree of social anhedonia reflects the vulnerability for developing schizophrenia. However, only few studies have investigated how functional network changes are related to social anhedonia. The aim of this fMRI study was to classify subjects according to their degree of social anhedonia using supervised machine learning. More specifically, we extracted both spatial and temporal network features during a social cognition task from 70 subjects, and used support vector machines for classification. Since impairment in social cognition is well established in schizophrenia-spectrum disorders, the subjects performed a comic strip task designed to specifically probe theory of mind (ToM) and empathy processing. Features representing both temporal (time series) and network dynamics were extracted using task activation maps, seed region analysis, independent component analysis (ICA), and a newly developed multi-subject archetypal analysis (MSAA), which here aimed to further bridge aspects of both seed region analysis and decomposition by incorporating a spotlight approach.We found significant classification of subjects with elevated levels of social anhedonia when using the times series extracted using MSAA, indicating that temporal dynamics carry important information for classification of social anhedonia. Interestingly, we found that the same time series yielded the highest classification performance in a task classification of the ToM condition. Finally, the spatial network corresponding to that time series included both prefrontal and temporal-parietal regions as well as insula activity, which previously have been related schizotypy and the development of schizophrenia. © 2019 Wiley Periodicals, Inc.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","4965-4981","","17","40","","","","","","","","","","English","","","","","","","Publisher: John Wiley and Sons Inc.","<p>cited By 2</p>","","","Brain; Female; Humans; Male; Young Adult; perception; brain; social cognition; Theory of Mind; physiology; Magnetic Resonance Imaging; Schizophrenia; Empathy; empathy; classification; theory of mind; Social Behavior; Support Vector Machine; schizophrenia; functional magnetic resonance imaging; functional connectivity; support vector machine; Image Processing; Social Perception; human; adult; female; major clinical study; male; Article; young adult; college student; diagnostic imaging; nuclear magnetic resonance imaging; priority journal; social behavior; adolescent; Adolescent; anhedonia; Anhedonia; Computer-Assisted; image analysis; image processing; independent component analysis; schizophrenia spectrum disorder; supervised machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXS4T7N2","conferencePaper","2019","Franzius, M.","Towards beauty: Robot following aesthetics gradients","2019 19th International Conference on Advanced Robotics, ICAR 2019","978-1-72812-467-4","","10.1109/ICAR46387.2019.8981647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084280149&doi=10.1109%2fICAR46387.2019.8981647&partnerID=40&md5=5aab4dbd2d2b0576245555cffdf9136a","Increasing numbers of devices are equipped with cameras generating large amounts of images. State of the art technologies allow to automatically identify relevant and aesthetically pleasing images after they were stored. Here, we demonstrate a robot that estimates the gradient of image aesthetics in its environment and actively navigates towards the maximum. Aesthetics navigation is integrated into a modified robotic lawnmower, switching online between tasks based on estimated aesthetics scores. This behavior generates higher aesthetics scores than offline selection of images captured during standard behavior. The proposed system extends robotic behavior from the purely functional towards a cooperative and empathic level. © 2019 IEEE.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","55-60","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 19th International Conference on Advanced Robotics, ICAR 2019 ; Conference Date: 2 December 2019 Through 6 December 2019; Conference Code:157426</p>","","","Robotics; Robots; Agricultural robots; Purely functional; Image Aesthetics; Large amounts; Offline; Robotic behavior; State-of-the-art technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52WWGWU2","journalArticle","2019","Drimalla, H.; Landwehr, N.; Hess, U.; Dziobek, I.","From face to face: the contribution of facial mimicry to cognitive and emotional empathy","Cognition and Emotion","","02699931","10.1080/02699931.2019.1596068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063194475&doi=10.1080%2f02699931.2019.1596068&partnerID=40&md5=bb539c57b010be437f0ec7ff35e632e7","Despite advances in the conceptualisation of facial mimicry, its role in the processing of social information is a matter of debate. In the present study, we investigated the relationship between mimicry and cognitive and emotional empathy. To assess mimicry, facial electromyography was recorded for 70 participants while they completed the Multifaceted Empathy Test, which presents complex context-embedded emotional expressions. As predicted, inter-individual differences in emotional and cognitive empathy were associated with the level of facial mimicry. For positive emotions, the intensity of the mimicry response scaled with the level of state emotional empathy. Mimicry was stronger for the emotional empathy task compared to the cognitive empathy task. The specific empathy condition could be successfully detected from facial muscle activity at the level of single individuals using machine learning techniques. These results support the view that mimicry occurs depending on the social context as a tool to affiliate and it is involved in cognitive as well as emotional empathy. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","1672-1686","","8","33","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 15</p>","","","Adult; Female; Humans; Male; Young Adult; machine learning; Emotions; emotion; Cognition; Individuality; physiology; cognition; Empathy; empathy; facial expression; imitation; Facial Expression; article; human; human experiment; adult; female; major clinical study; male; young adult; controlled study; adolescent; Adolescent; individuality; procedures; electromyography; Electromyography; face muscle; Facial Muscles; Imitative Behavior; muscle function; social environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VNCBCW8","conferencePaper","2019","Zelenskaya, M.; Harvey, L.","Virtual Avatars as a tool for audience engagement","Proceedings - VRCAI 2019: 17th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry","978-1-4503-7002-8","","10.1145/3359997.3365717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077133838&doi=10.1145%2f3359997.3365717&partnerID=40&md5=fc364fd39e3f691041acc54bb5226e18","Modern motion capture tools can be used to animate sophisticated digital characters in real time. Through these virtual avatars hu-man performers can communicate with live audience, creating a promising new area of application for public engagement. This study describes a social experiment where a real-time multimedia setup was used to facilitate an interaction between a digital char-acter and visitors at a public venue. The technical implementation featured some innovative elements, such as using iPhone TrueDepth Camera as part of the performance capture pipeline. The study examined public reactions during the experiment in order to explore the empathic potential of virtual avatars and as-sess their ability to engage live audience. © 2019 Association for Computing Machinery.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 17th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry, VRCAI 2019 ; Conference Date: 14 November 2019 Through 16 November 2019; Conference Code:155494</p>","","","Virtual reality; Virtual avatar; Social experiments; Interactive computer graphics; Audience engagement; Digital characters; Performance capture; Real-time motion; Realtime multimedia; Technical implementation","","S.N, Spencer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SYAF7JM","conferencePaper","2019","Carranza, K.A.L.R.; Manalili, J.; Bugtai, N.T.; Baldovino, R.G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019","978-1-72813-118-4","","10.1109/RITAPP.2019.8932852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077990918&doi=10.1109%2fRITAPP.2019.8932852&partnerID=40&md5=dd864870552f309bda80eae491e820d7","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds. © 2019 IEEE.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","160-163","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019 ; Conference Date: 1 November 2019 Through 3 November 2019; Conference Code:156064</p>","","","Deep learning; Surveys; Cognitive science; Affective Computing; Chatbot; Face recognition; Emotional state; Facial Expressions; Behavioral research; Facial expression detections; Intelligent robots; Interdisciplinary fields; Software testing; Tracking accuracy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TXAIHWN","journalArticle","2019","Agopyan, H.; Griffet, J.; Poirier, T.; Bredin, J.","Modification of knee flexion during walking with use of a real-time personalized avatar","Heliyon","","24058440","10.1016/j.heliyon.2019.e02797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074684962&doi=10.1016%2fj.heliyon.2019.e02797&partnerID=40&md5=7dafd73a008abab427e577e1f020b1af","Visual feedback is used in different research areas, including clinical science and neuroscience. In this study, we investigated the influence of the visualization of a real-time personalized avatar on gait parameters, focusing on knee flexion during the swing phase. We also studied the impact of the modification of avatar's knee amplitude on kinematic of the knee of healthy subjects. For this purpose, we used an immersive reality treadmill equipment and developed a 3D avatar, with instantly modifiable parameters for knee flexion and extension (acceleration or deceleration). Fourteen healthy young adults, equipped with motion capture markers, were asked to walk at a self-selected pace on the treadmill. A real-time 3D image of their lower limbs was modelized and projected on the screen ahead of them, as if in a walking motion from left to right. The subjects were instructed to continue walking. When we initiated an increase in the knee flexion of the avatar, we observed a similar increase in the subjects' knee flexion. No significant results were observed when the modification involved a decrease in knee flexion. The results and their significance are discussed using theories encompassing empathy, sympathy and sensory re-calibration. The prospect of using this type of modified avatar for stroke rehabilitation is discussed. © 2019 The Author(s)","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","","","11","5","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCMIIMZZ","conferencePaper","2019","Esfandbod, A.; Rokhi, Z.; Taheri, A.; Alemi, M.; Meghdari, A.","Human-Robot Interaction based on Facial Expression Imitation","ICRoM 2019 - 7th International Conference on Robotics and Mechatronics","978-1-72816-604-9","","10.1109/ICRoM48714.2019.9071837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084358069&doi=10.1109%2fICRoM48714.2019.9071837&partnerID=40&md5=ae795b1eb257f51d3eebb251402352f6","Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database., which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants, viewpoints on the imitation capability of the robot of 4.1 out of 5. © 2019 IEEE.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","69-73","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 7th International Conference on Robotics and Mechatronics, ICRoM 2019 ; Conference Date: 20 November 2019 Through 21 November 2019; Conference Code:159414</p>","","","Robotics; Human robot interaction; Agricultural robots; Facial Expressions; Non-verbal communications; Face to face; Convolutional neural networks; Facial expression recognition; Robotic platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRLDFE8G","conferencePaper","2019","Franzoni, V.; Milani, A.; Biondi, G.; Micheli, F.","A preliminary work on dog emotion recognition","Proceedings - 2019 IEEE/WIC/ACM International Conference on Web Intelligence Workshops, WI 2019 Companion","978-1-4503-6988-6","","10.1145/3358695.3361750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074373338&doi=10.1145%2f3358695.3361750&partnerID=40&md5=28643a3c506d284761d30c4e16a889af","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications. The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs' basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence. © 2019 Copyright held by the owner/author(s).","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","91-96","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 2; Conference of 19th IEEE/WIC/ACM International Conference on Web Intelligence Workshop, WI 2019 ; Conference Date: 14 October 2019 Through 17 October 2019; Conference Code:152685</p>","","","Neural networks; Artificial intelligence; Animals; Affective Computing; Emotion recognition; Speech recognition; Learning systems; Behavioral research; Basic emotions; Future applications; Learning by imitation; Mirror neurons; Neurology; Social behavior; Transfer learning","","Barnaghi P., Vakali A., Gottlob G., Katsaros D., Manolopoulos Y., Pandey R., Tzouramanis T.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JII5SHU5","journalArticle","2019","Bristol, R.C.","An Essay on Narrative, Reality, and Imagination","Psychoanalytic Inquiry","","07351690","10.1080/07351690.2019.1659025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074169447&doi=10.1080%2f07351690.2019.1659025&partnerID=40&md5=e63ea1dc96732323847d76ffb96ead71","Narrative is a verbal account, a story of related events which can be factual, fictional or both. Life experience and imagination are as essential to narrative as narrative is to mankind. The phylogenic perspective of literature suggests an inborn capacity for empathy, intelligence and inventiveness, whereas the ontological example is variable. Western knowledge, politics and ethics have evolved from their narrative of Greek myth, epic and drama, the few medieval writers, singularly by the Elizabethan theater, importantly the Arthurian legend and romance stories, English and Russian novels, and uniquely the American short story. This heritage progressively demarcated such life themes as the hero, maiden and adversary; love, hate and indifference; loyalty, deception and betrayal; desire, achievement and loss. These characterizations of self and other remain relevant to the contemporary novel, cinema/TV, and theater, as well as the news, commentary, and real life. Conversely, postmodern assumptions challenge that individual subjectivity determines what is real, valid or authentic, consequently the relativism of traditional, institutional and historical precedents of the truth. Further, the computer, gaming, smart device, and artificial intelligence have changed the content and function of customary narrative. Nonetheless, narrative — real and imagined, ancient and new — retains the meaning of a story about connected events which variously transcends the boundaries of difference. ©, Copyright © Melvin Bornstein, Joseph Lichtenberg, Donald Silver.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","476-484","","7","39","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUAV7JBD","journalArticle","2019","Powell, J.","Trust me, i'm a chatbot: How artificial intelligence in health care fails the turing test","Journal of Medical Internet Research","","14388871","10.2196/16222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074230200&doi=10.2196%2f16222&partnerID=40&md5=f07051700ad8b816ddd71e05e867d094","Over the next decade, one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized, along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision, often handling large areas of uncertainty and balancing competing risks. Arguably, medicine requires wisdom more than intelligence, artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals, and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care, artificial intelligence needs to pass the implementation game, not the imitation game. © 2019 John Powell.","2019","2021-05-19 13:26:20","2021-05-19 13:26:20","","","","10","21","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 11</p>","","","Humans; artificial intelligence; machine learning; Artificial Intelligence; empathy; trust; medical informatics; imitation; Machine Learning; decision making; article; human; adult; consultation; procedures; Medical Informatics; telehealth; telemedicine; Telemedicine; uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IY4ZN6PX","conferencePaper","2019","Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.","Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals","2019 28th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2019","978-1-72812-622-7","","10.1109/RO-MAN46459.2019.8956353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078837141&doi=10.1109%2fRO-MAN46459.2019.8956353&partnerID=40&md5=7d59754dade81e0ffa2bdbd5efe9a98a","Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion. © 2019 IEEE.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 28th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2019 ; Conference Date: 14 October 2019 Through 18 October 2019; Conference Code:156864</p>","","","Robots; Emotion estimation; Facial Expressions; Human robots; Biological signals; Unobservable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NX88EJA","journalArticle","2019","Johanson, D.L.; Ahn, H.S.; MacDonald, B.A.; Ahn, B.K.; Lim, J.; Hwang, E.; Sutherland, C.J.; Broadbent, E.","The effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction: Randomized controlled trial","Journal of Medical Internet Research","","14388871","10.2196/13667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072908937&doi=10.2196%2f13667&partnerID=40&md5=244df67bd1698544f060020541459c91","Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings. © Deborah L Johanson, Ho Seok Ahn, Bruce A MacDonald, Byeong Kyu Ahn, JongYoon Lim, Euijun Hwang, Craig J Sutherland, Elizabeth Broadbent.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","","","10","21","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 6</p>","","","Attention; Adult; Female; Humans; Male; Young Adult; attention; perception; simulation; Middle Aged; Robotics; physiology; emotional intelligence; empathy; Emotional Intelligence; intelligence; social interaction; robotics; article; human; human experiment; adult; female; major clinical study; male; young adult; self disclosure; human relation; Interpersonal Relations; controlled study; randomized controlled trial; videorecording; 80 and over; adolescent; Adolescent; aged; Aged; middle aged; very elderly; procedures; self report; medical receptionist; pitch; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FB9JS5FF","conferencePaper","2019","Okanda, M.; Taniguchi, K.; Itakura, S.","The role of animism tendencies and empathy in adult evaluations of robot","HAI 2019 - Proceedings of the 7th International Conference on Human-Agent Interaction","978-1-4503-6922-0","","10.1145/3349537.3351891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077124144&doi=10.1145%2f3349537.3351891&partnerID=40&md5=e9499c2611c38d3507959f62e604ef78","We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness. © 2019 ACM.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","51-58","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 4; Conference of 7th International Conference on Human-Agent Interaction, HAI 2019 ; Conference Date: 6 October 2019 Through 10 October 2019; Conference Code:155501</p>","","","Surveys; Empathy; Human robot interaction; Major factors; Animism; Man made objects; Social agents; University students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3IGJV43","conferencePaper","2019","Roth, D.; Bloch, C.; Schmitt, J.; Frischlich, L.; Latoschik, M.E.; Bente, G.","Perceived Authenticity, Empathy, and Pro-social Intentions evoked through Avatar-mediated Self-disclosures","ACM International Conference Proceeding Series","978-1-4503-7198-8","","10.1145/3340764.3340797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072795574&doi=10.1145%2f3340764.3340797&partnerID=40&md5=4d0f505abddc6a24356b7791c9830f61","Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one’s avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","21-30","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 2019 Conference on Mensch und Computer, MuC 2019 ; Conference Date: 8 September 2019 Through 11 September 2019; Conference Code:151593</p>","","","Empathy; Avatars; Self-disclosure; Social interactions; Computer applications; Computer programming; Anonymity and privacy; Authentication; Non-verbal behaviours; Social perception; Virtual character","","Alt F., Doring T., Bulling A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DL9UVHV","conferencePaper","2019","Dipaola, S.; Yalcin, O.N.","A multi-layer artificial intelligence and sensing based affective conversational embodied agent","2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019","978-1-72813-891-6","","10.1109/ACIIW.2019.8925291","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077818348&doi=10.1109%2fACIIW.2019.8925291&partnerID=40&md5=49ce11dd00a59cacaee1067695a622c4","Building natural and conversational virtual humans is a task of formidable complexity. We believe that, especially when building agents that affectively interact with biological humans in real-time, a cognitive science-based, multilayered sensing and artificial intelligence (AI) systems approach is needed. For this demo, we show a working version (through human interaction with it) our modular system of natural, conversation 3D virtual human using AI or sensing layers. These including sensing the human user via facial emotion recognition, voice stress, semantic meaning of the words, eye gaze, heart rate, and galvanic skin response. These inputs are combined with AI sensing and recognition of the environment using deep learning natural language captioning or dense captioning. These are all processed by our AI avatar system allowing for an affective and empathetic conversation using an NLP topic-based dialogue capable of using facial expressions, gestures, breath, eye gaze and voice language-based two-way back and forth conversations with a sensed human. Our lab has been building these systems in stages over the years. © 2019 IEEE.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","91-92","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019 ; Conference Date: 3 September 2019 Through 6 September 2019; Conference Code:155963</p>","","","Electrophysiology; Semantics; Deep learning; Virtual reality; Artificial intelligence; Affective Computing; Conversational agents; Speech recognition; Real time systems; Biosensing; Cognitive systems; Embodied agent; Embodied characters; FORTH (programming language); Intelligent computing; Sensing systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVTU5QBT","journalArticle","2019","Nishio, T.; Yoshikawa, Y.; Ogawa, K.; Ishiguro, H.","Development of an effective information media using two android robots","Applied Sciences (Switzerland)","","20763417","10.3390/app9173442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072289072&doi=10.3390%2fapp9173442&partnerID=40&md5=4b662e336d3750e31f65cb44577492d3","Conversational robots have been used to convey information to people in the real world. Android robots, which have a human-like appearance, are expected to be able to convey not only objective information but also subjective information, such as a robot's feelings. Meanwhile, as an approach to realize attractive conversation, multi-party conversation by multiple robots was the focus of this study. By collaborating among several robots, the robots provide information while maintaining the naturalness of conversation. However, the effectiveness of interaction with people has not been surveyed using this method. In this paper, to develop more efficient media to convey information, we propose a scenario-based, semi-passive conversation system using two androids. To verify its effectiveness, we conducted a subjective experiment comparing it to a system that does not include any interaction with people, and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids. The experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids. © 2019 by the authors.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","","","17","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5ZNE96V","conferencePaper","2019","Ghandeharioun, A.; McDuff, D.; Czerwinski, M.; Rowan, K.","EMMA: An Emotion-Aware Wellbeing Chatbot","2019 8th International Conference on Affective Computing and Intelligent Interaction, ACII 2019","978-1-72813-888-6","","10.1109/ACII.2019.8925455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077788226&doi=10.1109%2fACII.2019.8925455&partnerID=40&md5=9c25cf0c19223577d4dbfee95f855798","The delivery of mental health interventions via ubiquitous devices has shown much promise. A conversational chatbot is a promising oracle for delivering appropriate just-in-time interventions. However, designing emotionally-aware agents, specially in this context, is under-explored. Furthermore, the feasibility of automating the delivery of just-in-time mHealth interventions via such an agent has not been fully studied. In this paper, we present the design and evaluation of EMMA (EMotion-Aware mHealth Agent) through a two-week long human-subject experiment with N=39 participants. EMMA provides emotionally appropriate micro-activities in an empathetic manner. We show that the system can be extended to detect a user's mood purely from smartphone sensor data. Our results show that our personalized machine learning model was perceived as likable via self-reports of emotion from users. Finally, we provide a set of guidelines for the design of emotion-aware bots for mHealth. © 2019 IEEE.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","15-21","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 7; Conference of 8th International Conference on Affective Computing and Intelligent Interaction, ACII 2019 ; Conference Date: 3 September 2019 Through 6 September 2019; Conference Code:155962</p>","","","Affective Computing; Mental health; mHealth; Emotional intelligence; Mobile applications; Agents; Design and evaluations; Machine learning models; Intelligent computing; Human subject experiments; Just in time; Just in time production; Ubiquitous devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UWWLA676","conferencePaper","2019","Ghandeharioun, A.; McDuff, D.; Czerwinski, M.; Rowan, K.","Towards Understanding Emotional Intelligence for Behavior Change Chatbots","2019 8th International Conference on Affective Computing and Intelligent Interaction, ACII 2019","978-1-72813-888-6","","10.1109/ACII.2019.8925433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077801754&doi=10.1109%2fACII.2019.8925433&partnerID=40&md5=e758d5ed4d6a13c3ad8ca39f166531e0","A natural conversational interface that allows longitudinal symptom tracking would be extremely valuable in health/wellness applications. However, the task of designing emotionally-aware agents for behavior change is still poorly understood. In this paper, we present the design and evaluation of an emotion-aware chatbot that conducts experience sampling in an empathetic manner. We evaluate it through a human-subject experiment with N=39 participants over the course of a week. Our results show that extraverts preferred the emotion-aware chatbot significantly more than introverts. Also, participants reported a higher percentage of positive mood reports when interacting with the empathetic bot. Finally, we provide guidelines for the design of emotion-aware chatbots for potential use in mHealth contexts. © 2019 IEEE.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","8-14","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 5; Conference of 8th International Conference on Affective Computing and Intelligent Interaction, ACII 2019 ; Conference Date: 3 September 2019 Through 6 September 2019; Conference Code:155962</p>","","","Affective Computing; Mental health; Emotional intelligence; Behavior change; Mobile applications; Agents; Design and evaluations; Intelligent computing; Human subject experiments; Conversational interface; Experience sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEFHVDXU","conferencePaper","2019","Lopez-Martinez, D.; El-Haouij, N.; Picard, R.","Detection of Real-World Driving-Induced Affective State Using Physiological Signals and Multi-View Multi-Task Machine Learning","2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019","978-1-72813-891-6","","10.1109/ACIIW.2019.8925190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077823786&doi=10.1109%2fACIIW.2019.8925190&partnerID=40&md5=2ebee175abda03ce81e1ef2bd2733145","Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance. © 2019 IEEE.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","356-361","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019 ; Conference Date: 3 September 2019 Through 6 September 2019; Conference Code:155963</p>","","","Machine learning; Physiology; Affective state; User interfaces; Physiological models; Physiological response; Physiological data; Physiological signals; Intelligent computing; Automobile drivers; Digital storage; Interface states; Machine learning methods; Motor transportation; Multi-views; Real-world drivings; Situation awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTLZG38Z","journalArticle","2019","Nadarzynski, T.; Miles, O.; Cowie, A.; Ridge, D.","Acceptability of artificial intelligence (AI)-led chatbot services in healthcare: A mixed-methods study","Digital Health","","20552076","10.1177/2055207619871808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071722067&doi=10.1177%2f2055207619871808&partnerID=40&md5=de557d219e98a4b46f52cb2af3ddd826","Background: Artificial intelligence (AI) is increasingly being used in healthcare. Here, AI-based chatbot systems can act as automated conversational agents, capable of promoting health, providing education, and potentially prompting behaviour change. Exploring the motivation to use health chatbots is required to predict uptake; however, few studies to date have explored their acceptability. This research aimed to explore participants’ willingness to engage with AI-led health chatbots. Methods: The study incorporated semi-structured interviews (N-29) which informed the development of an online survey (N-216) advertised via social media. Interviews were recorded, transcribed verbatim and analysed thematically. A survey of 24 items explored demographic and attitudinal variables, including acceptability and perceived utility. The quantitative data were analysed using binary regressions with a single categorical predictor. Results: Three broad themes: ‘Understanding of chatbots’, ‘AI hesitancy’ and ‘Motivations for health chatbots’ were identified, outlining concerns about accuracy, cyber-security, and the inability of AI-led services to empathise. The survey showed moderate acceptability (67%), correlated negatively with perceived poorer IT skills OR = 0.32 [CI95%:0.13–0.78] and dislike for talking to computers OR = 0.77 [CI95%:0.60–0.99] as well as positively correlated with perceived utility OR = 5.10 [CI95%:3.08–8.43], positive attitude OR = 2.71 [CI95%:1.77–4.16] and perceived trustworthiness OR = 1.92 [CI95%:1.13–3.25]. Conclusion: Most internet users would be receptive to using health chatbots, although hesitancy regarding this technology is likely to compromise engagement. Intervention designers focusing on AI-led health chatbots need to employ user-centred and theory-based approaches addressing patients’ concerns and optimising user experience in order to achieve the best uptake and utilisation. Patients’ perspectives, motivation and capabilities need to be taken into account when developing and assessing the effectiveness of health chatbots. © The Author(s) 2019.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","","","","5","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 38</p>","","","artificial intelligence; social media; Internet; motivation; article; human; adult; genetic transcription; skill; computer security; semi structured interview; comparative effectiveness; quantitative analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7YAXH9YQ","journalArticle","2019","Gong, C.; Lin, F.; Zhou, X.; Lu, X.","Amygdala-inspired affective computing: To realize personalized intracranial emotions with accurately observed external emotions","China Communications","","16735447","10.23919/JCC.2019.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072068065&doi=10.23919%2fJCC.2019.08.011&partnerID=40&md5=3572d915fbee1668aed2dea06ab6916b","Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected. © 2013 China Institute of Communications.","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","115-129","","8","16","","","","","","","","","","English","","","","","","","Publisher: Editorial Department of China Communications","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVKJWEVL","journalArticle","2019","Tsiourti, C.; Weiss, A.; Wac, K.; Vincze, M.","Multimodal Integration of Emotional Signals from Voice, Body, and Context: Effects of (In)Congruence on Emotion Recognition and Attitudes Towards Robots","International Journal of Social Robotics","","18754791","10.1007/s12369-019-00524-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065214595&doi=10.1007%2fs12369-019-00524-z&partnerID=40&md5=e3887d0bbd35da2e90f52d0279d59270","Humanoid social robots have an increasingly prominent place in today’s world. Their acceptance in social and emotional human–robot interaction (HRI) scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users. In this article, we incorporate recent findings from psychology, neuroscience, human–computer interaction, and HRI, to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots, with a particular emphasis on the effects of incongruence. In a social HRI laboratory experiment, we investigated contextual incongruence (i.e., the conflict situation where a robot’s reaction is incongrous with the socio-emotional context of the interaction) and cross-modal incongruence (i.e., the conflict situation where an observer receives incongruous emotional information across the auditory (vocal prosody) and visual (whole-body expressions) modalities). Results showed that both contextual incongruence and cross-modal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot. This, in turn, gives the impression that the robot is unintelligent or unable to express “empathic” behaviour and leads to profoundly harmful effects on likability and believability. Our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way. We offer recommendations regarding design choices and discuss future research areas in the direction of multimodal HRI. © 2019, The Author(s).","2019","2021-05-19 13:26:21","2021-05-19 13:26:21","","555-573","","4","11","","","","","","","","","","English","","","","","","","Publisher: Springer Science and Business Media B.V.","<p>cited By 18</p>","","","Social robots; Speech recognition; Robot emotions; Agricultural robots; Machine design; Robot interactions; Anthropomorphic robots; Human computer interaction; Body language; Believability; Multi-Modal Interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMKZQXF8","journalArticle","2019","Brocker, L.; Fazilleau, C.; Naudin, D.","Artificial intelligence in medicine: benefits and limits [L'intelligence artificielle en médecine: intérêts et limites]","Oxymag","","09901310","10.1016/j.oxy.2019.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074056912&doi=10.1016%2fj.oxy.2019.06.003&partnerID=40&md5=57183ca6f74749e13959cc6e9b952387","Artificial intelligence (AI) has been developed in the field of healthcare in order to help professionals improve their efficiency, their productivity and their consistency in the quality of care provided to patients. The use of artificial intelligence in fields such as imaging or medicines management has proved to be effective. There is no doubt that it exceeds the analysis capability of humans. Nevertheless, in many other fields, AI cannot equal human intelligence as the latter's complexity cannot be copied. The brain's ability to adapt, consciousness and subjectivity as well as qualities essential for decision-making such as empathy still remain unique to humans. © 2019 Elsevier Masson SAS L’intelligence artificielle a été développée dans le domaine de la santé afin d’aider les professionnels à améliorer leur efficacité, leur productivité et leur constance dans la qualité des soins apportés aux patients Ses applications dans des domaines tels que l’imagerie ou la gestion des médicaments ont montré son efficacité Sans nul doute, l’intelligence artificielle dépasse la capacité d’analyse humaine Dans bien d’autres domaines, elle ne peut pourtant égaler l’intelligence humaine dont la complexité ne peut être copiée La capacité du cerveau à s’adapter, à laquelle s’ajoutent la conscience et la subjectivité, ainsi que les qualités essentielles à la prise de décision comme l’empathie, restent encore le propre de l’homme. © 2019 Elsevier Masson SAS","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","8-13","","167","32","","","","","","","","","","English; French","","","","","","","Publisher: Elsevier Masson SAS","<p>cited By 1</p>","","","artificial intelligence; machine learning; emotion; deep learning; empathy; neuroscience; intelligence; reliability; reward; human; Article; algorithm; clinical decision making; clinical decision support system; comprehension; lateral prefrontal cortex; man machine interaction; medical technology; medicine; punishment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5T3XJP7","journalArticle","2019","Lerrigo, R.; Coffey, J.T.R.; Kravitz, J.L.; Jadhav, P.; Nikfarjam, A.; Shah, N.H.; Jurafsky, D.; Sinha, S.R.","The emotional toll of inflammatory bowel disease: Using machine learning to analyze online community forum discourse","Crohn's and Colitis 360","","2631827X","10.1093/crocol/otz011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079143243&doi=10.1093%2fcrocol%2fotz011&partnerID=40&md5=72c7a794561e07f4aeb1d98863c33220","Background: Patients with inflammatory bowel disease are using online community forums (OCFs) to seek emotional support. The impact of OCFs on well-being and their emotional content are unknown. Methods: We used an unsupervised machine learning algorithm to identify the thematic content of 51,591 public, online posts from the Crohn's & Colitis Foundation Community Forum. Results: We identified 10,702 (20.8%) posts expressing: gratitude (40%), anxiety/fear (20.8%), empathy (18.2%), anger/frustration (13.4%), hope (13.2%), happiness (10.0%), sadness/depression (5.8%), shame/guilt (2.5%), and/or loneliness (2.5%). A common subtheme was the importance of fostering social support. Conclusions: High-throughput, machine learning-directed analysis of OCFs may help identify psychosocial impacts of inflammatory bowel disease on patients and their caregivers. © 2019 Crohn's & Colitis Foundation. Published by Oxford University Press on behalf of Crohn's & Colitis Foundation.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","","","2","1","","","","","","","","","","English","","","","","","","Publisher: Oxford University Press","<p>cited By 3</p>","","","emotion; depression; empathy; literature; human; adult; female; major clinical study; male; Article; frustration; controlled study; priority journal; thematic analysis; fear; anger; chronic disease; gratitude; happiness; hope; inflammatory bowel disease; loneliness; medical history; sadness; shame; social support; unsupervised machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"66NMRVTN","journalArticle","2019","Sena, J.R.; Cabatuan, M.","Deep learning-based facial expression recognition and analysis for filipino gamers","International Journal of Recent Technology and Engineering","","22773878","10.35940/ijrte.B1027.078219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286","This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","1822-1827","","2","8","","","","","","","","","","English","","","","","","","Publisher: Blue Eyes Intelligence Engineering and Sciences Publication","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZEX4PG6","journalArticle","2019","Rincon, J.A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.","A new emotional robot assistant that facilitates human interaction and persuasion","Knowledge and Information Systems","","02191377","10.1007/s10115-018-1231-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049128718&doi=10.1007%2fs10115-018-1231-9&partnerID=40&md5=5c66a64dc9959c1533168f3b8df3e72e","The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare center in the northern area of Portugal. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","363-383","","1","60","","","","","","","","","","English","","","","","","","Publisher: Springer London","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WKHDQW2W","conferencePaper","2019","Montesinos, V.; Dell'Agnola, F.; Arza, A.; Aminifar, A.; Atienza, D.","Multi-Modal Acute Stress Recognition Using Off-the-Shelf Wearable Devices","Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS","978-1-5386-1311-5","","10.1109/EMBC.2019.8857130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077869366&doi=10.1109%2fEMBC.2019.8857130&partnerID=40&md5=f0d88598e90649d738e805ed1902e85d","Monitoring stress and, in general, emotions has attracted a lot of attention over the past few decades. Stress monitoring has many applications, including high-risk missions and surgical procedures as well as mental/emotional health monitoring. In this paper, we evaluate the possibility of stress and emotion monitoring using off-the-shelf wearable sensors. To this aim, we propose a multi-modal machine-learning technique for acute stress episodes detection, by fusing the information careered in several biosignals and wearable sensors. Furthermore, we investigate the contribution of each wearable sensor in stress detection and demonstrate the possibility of acute stress recognition using wearable devices. In particular, we acquire the physiological signals using the Shimmer3 ECG Unit and the Empatica E4 wristband. Our experimental evaluation shows that it is possible to detect acute stress episodes with an accuracy of 84.13%, for an unseen test set, using multi-modal machinelearning and sensor-fusion techniques. © 2019 IEEE.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","2196-2201","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 1557170X","<p>cited By 3; Conference of 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2019 ; Conference Date: 23 July 2019 Through 27 July 2019; Conference Code:152547</p>","","","Stress; Humans; machine learning; Emotions; emotion; mental health; Machine Learning; Mental Health; human; Learning systems; Machine learning techniques; Psychological; Experimental evaluation; Wearable sensors; electronic device; Wearable Electronic Devices; Physiological signals; Health monitoring; Health risks; mental stress; Stress monitoring; Stress recognition; Surgical procedures; Wearable devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQKEXJF5","conferencePaper","2019","Zsom, A.; Lafrance, W.C.; Blum, A.S.; Li, P.; La, W.; Shaikh, M.A.; Sharma, G.; Ranieri, R.; Zhang, L.; Tsekhan, S.; Hamid, T.; Levin, J.; Truccolo, W.","Ictal autonomic activity recorded via wearable-sensors plus machine learning can discriminate epileptic and psychogenic nonepileptic seizures","Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS","978-1-5386-1311-5","","10.1109/EMBC.2019.8857552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077878986&doi=10.1109%2fEMBC.2019.8857552&partnerID=40&md5=c962103e86ecb0cda0d6cc3244791677","Differentiating epileptic seizures (ES) and psychogenic nonepileptic seizures (PNES) is commonly based on electroencephalogram and concurrent video recordings (vEEG). Here, we demonstrate that these two types of seizures can be discriminated based on signals related to autonomic nervous system activity recorded via wearable sensors. We used Empatica E4 Wristband sensors worn on both arms in vEEG confirmed seizures, and machine learning methods to train classifiers, specifically, extreme gradient boosting (XGBoost). Classification performance achieved a predictive accuracy of 78 ± 1.5% on previously unseen data for whether a seizure was epileptic or psychogenic, which is 6 standard deviations above the baseline of 68% accuracy. Our dataset contained altogether 35 seizures from 18 patients out of which 8 patients had 13 convulsive seizures. Prediction of seizure type was based on simple features derived from the segments of autonomic activity measurements (electrodermal activity, body temperature, blood volume pulse, and heart rate) and forearm acceleration. Features related to heart rate and electrodermal activity were ranked as the top predictors in XGBoost classifiers. We found that patients with PNES had a higher ictal heart rate and electrodermal activity than patients with ES. In contrast to existing published studies of mainly convulsive seizures, our classifier focuses on autonomic signals to differentiate convulsive or nonconvulsive semiology ES from PNES. Our results show that autonomic activity recorded via wearable sensors provides promising signals for detection and discrimination of psychogenic and epileptic seizures, but more work is necessary to improve the predictive power of the model. © 2019 IEEE.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","3502-3506","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 1557170X","<p>cited By 1; Conference of 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2019 ; Conference Date: 23 July 2019 Through 27 July 2019; Conference Code:152547</p>","","","Neurophysiology; Humans; electroencephalography; Electroencephalography; machine learning; Machine learning; Epilepsy; Autonomic Nervous System; Electrodes; Machine Learning; human; devices; Video recording; Wearable sensors; Standard deviation; electronic device; Wearable Electronic Devices; epilepsy; Electrodermal activity; Biomedical signal processing; Heart; Adaptive boosting; Machine learning methods; autonomic nervous system; Autonomic nervous system activities; Classification performance; Detection and discriminations; Epileptic seizures; Predictive accuracy; seizure; Seizures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2J45LBMM","conferencePaper","2019","Antle, A.N.; Sadka, O.; Radu, I.; Gong, B.; Cheung, V.; Baishya, U.","Emototent: Reducing school violence through embodied empathy games","Proceedings of the 18th ACM International Conference on Interaction Design and Children, IDC 2019","978-1-4503-6690-8","","10.1145/3311927.3326596","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068777726&doi=10.1145%2f3311927.3326596&partnerID=40&md5=97a693937d75a70c18a1fc709fe74d36","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being. © 2019 Association for Computing Machinery.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","755-760","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 3; Conference of 18th ACM International Conference on Interaction Design and Children, IDC 2019 ; Conference Date: 12 June 2019 Through 15 June 2019; Conference Code:148754</p>","","","Robotics; Empathy; Children; Experiential learning; Learning systems; Human computer interaction; Intelligent robots; Biosensing; Embodied learning; Holographic displays; Holographic environments; Holography; Mind-body interaction; Robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYRQQGYE","conferencePaper","2019","Giakoumis, D.; Segkouli, S.; Votis, K.; Paliokas, I.; Altsitsiadis, E.; Tzovaras, D.","Smart, personalized and adaptive ICT solutions for active, healthy and productive ageing with enhanced workability","ACM International Conference Proceeding Series","978-1-4503-6232-0","","10.1145/3316782.3322767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069208290&doi=10.1145%2f3316782.3322767&partnerID=40&md5=b3583fb9b2fcb522526c6a16b0fee905","Along with population ageing comes the increasingly intensified phenomenon of a shrinking and ageing workforce. Novel solutions are needed so as to help ageing workers maintain workability and productivity, along with a balance between work and personal life, which supports them into good quality of life, active and healthy ageing. In this line, the “Ageing@work” project, initiated by the European Union, develops a novel ICT-based, personalized system to support ageing workers (aged 50+) into designing fit for purpose work environments and managing flexibly their evolving needs. On top of personalized, dynamically adapted worker and workplace models, computational intelligence will assess user specificities and needs i.r.t. work conditions, both in terms of ergonomics, health and safety issues and task assignments. Recommendations will then be provided both to the worker and company, under strict privacy restrictions, on how the working conditions must adapt. The worker models will be populated by unobtrusive worker sensing, both at work, at home and on the move. To foster workability and productivity, personalized, intuitive, age-friendly productivity, co-design enhancement tools will be developed, including ones for AR/VR-based context-awareness and telepresence, lifelong learning and knowledge sharing. On top of these, a novel Ambient Virtual Coach (AVC) will encompass an empathic mirroring avatar for subtle notifications provision, an adaptive Visual Analytics - based personal dashboard, and a reward-based motivation system targeting positive and balanced worker behavior at work and personal life, towards a novel paradigm of ambient support into workability and well-being. The integrated system will be developed by user-centered design and will be evaluated at two pilot sites, related to core Industry 4.0 processes of mining and machines production. © 2019 Association for Computing Machinery.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","442-447","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 2; Conference of 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2019 ; Conference Date: 5 June 2019 Through 7 June 2019; Conference Code:149147</p>","","","eHealth; User centered design; Ageing workforce; Context- awareness; Ergonomics; Health and safety issues; Integrated systems; Personnel; Privacy restrictions; Productivity; Virtual user models; Visual communication; Workability; Workforce management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MC7XX7V8","journalArticle","2019","Clavelle, J.T.; Sweeney, C.D.; Swartwout, E.; Lefton, C.; Guney, S.","Leveraging Technology to Sustain Extraordinary Care: A Qualitative Analysis of Meaningful Nurse Recognition","Journal of Nursing Administration","","00020443","10.1097/NNA.0000000000000757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931093&doi=10.1097%2fNNA.0000000000000757&partnerID=40&md5=c67866ef50603649810f548af2d47672","Meaningful recognition of nurses submitted by patients and families using interactive patient care (IPC) technology was analyzed using artificial intelligence (AI) to identify the themes and behaviors associated with extraordinary nursing. BACKGROUND Meaningful recognition positively impacts nursing and organizational outcomes. The use of AI techniques such as natural language processing and machine learning to identify and describe behaviors impacting patient experiences is an emerging science. METHODS Nurse recognition comments were collected from a convenience sample of 3 organizations via an IPC inpatient platform and analyzed using the AI techniques of natural language processing, machine learning, sentiment analytics, and corollary dictionaries based on rules of linguistics. RESULTS The top theme of nursing recognition comments was courtesy and respect with the behaviors of empathy/compassion, helpfulness, kindness, attentiveness, and emotional comfort. The theme of skills/knowledge was the 2nd most common, with the behaviors of being professional, knowledgeable, keeping track, competence, dedication, and being thorough. CONCLUSIONS AI techniques for qualitative analysis of comments collected through IPC reveal nurse themes and behaviors most meaningful to patients and their family members. Nurses can advance the science of AI and guide its evolution so that nurse caring behaviors associated with establishing human connections that positively influence patient and family experience are accurately represented. © Wolters Kluwer Health, Inc. All rights reserved.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","303-309","","6","49","","","","","","","","","","English","","","","","","","Publisher: Lippincott Williams and Wilkins","<p>cited By 2</p>","","","Humans; attention; artificial intelligence; machine learning; Artificial Intelligence; Empathy; empathy; natural language processing; cooperation; article; human; adult; female; male; patient care; clinical article; case report; Clinical Competence; comfort; convenience sample; hospital patient; linguistics; nurse; Nurse-Patient Relations; Nurses; Nursing Care; organization; Professional-Family Relations; qualitative analysis; Qualitative Research; skill; Technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC4QMHMS","journalArticle","2019","Catlin, D.; Blamires, M.","Designing Robots for Special Needs Education","Technology, Knowledge and Learning","","22111662","10.1007/s10758-018-9378-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052052320&doi=10.1007%2fs10758-018-9378-8&partnerID=40&md5=7234761420cead0050a751c2d695055b","In 1969, Seymour Papert invented the first educational robot called a Turtle. It was an addition to the computer language Logo, which he’d designed in 1965 specifically for educating children. Papert did not simply invent some technology, he offered a revolutionary way of educating children. He gave teachers practical tools to realise constructionist developmental theories in the classroom. We will show that Papert’s work forms a Kuhnian Paradigm which has endured for nearly 50 years and provides the foundation for all work with educational robots. The use of educational robots in special needs education was one of many benefits that grew out of the resulting environment. The early robots designs didn’t pay attention the needs of this area of education. So early researchers used the available robots and started to ask and seek answers to relevant questions. We analyse this historical research and report on their findings. We find modern research simply confirms the original work. We will introduce the Papert Paradigm and show how it empathised with the changing attitudes towards special needs education. We look at a deepening understanding of the technology provided by the Educational Robot Application Principles. And by combining this information with the Universal Design for Learning ideas we find a set of guidelines to help create better robots for special needs education. © 2018, Springer Nature B.V.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","291-313","","2","24","","","","","","","","","","English","","","","","","","Publisher: Springer Netherlands","<p>cited By 6</p>","","","Robots; Teaching; Machine design; Educational robots; Educational robotics; Logo; Seymour Papert; Special needs; Special needs educations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YINDDX3Y","journalArticle","2019","Hueso, L.C.","Ethics in design for the development of an artificial intelligence, trustworthy robotics and big data and their utility for the law [Ética en el diseño para el desarrollo de una inteligencia artificial, robótica y big data confiables y su utilidad desde el derecho]","Revista Catalana de Dret Public","","18858252","10.2436/rcdp.i58.2019.3303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602971&doi=10.2436%2frcdp.i58.2019.3303&partnerID=40&md5=863eada5a2fd83cae50e563f874c41e9","The study deals with the ethics of artificial intelligence (AI). Firstly, we explain the proclamation of the ethics and its necessity in the different international reference documents, although the analysis is focused on the actions carried out in the European Union. It is precisely in the EU where there is a special commitment to developing an ethics for a trustworthy AI in design and made in Europe, to position itself in front of United States and especially China, two countries that don’t pay much attention to the issue. Firstly, we describe the content of ethics of AI and its essential principles from the point of view of the dignity and rights; second, we describe the main five principles contained in the international declarations. Third, we include other basic principles which arise from the demands of empathy with humans. From a somewhat sceptical perspective, we argue the potential utilities of ethics of AI for the law: it is considered to be an especially preventive instrument and that an ethical governance of AI can be developed, following the examples of policies and frameworks on public ethics and institutional integrity. The phases to be followed are described in this regard. We explain in detail the opportunity and the basic content of codes of conduct and committees and other control systems. Finally, we make an appeal for the design of algorithms that serve as guardians of regulatory compliance and the ethics of AI. © 2019, Public Administration School of Catalonia. All rights reserved.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","29-48","","58","2019","","","","","","","","","","Spanish","","","","","","","Publisher: Public Administration School of Catalonia","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8N8W9WN","conferencePaper","2019","Costantini, S.; De Gasperis, G.; Migliarini, P.","Multi-agent system engineering for emphatic human-robot interaction","Proceedings - IEEE 2nd International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2019","978-1-72811-488-0","","10.1109/AIKE.2019.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071453043&doi=10.1109%2fAIKE.2019.00015&partnerID=40&md5=3f40048836bffb6e0cc5a9b52df01a87","Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy. © 2019 IEEE.","2019","2021-05-19 13:26:22","2021-05-19 13:26:22","","36-42","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 4; Conference of 2nd IEEE International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2019 ; Conference Date: 3 June 2019 Through 5 June 2019; Conference Code:150750</p>","","","Sensory perception; Emotions; Communication; Affect; Empathy; Human robot interaction; Man machine systems; Intelligent agents; Speech communication; Behavioral research; Intelligent robots; Bi-directional communication; Human-robot communication; Intelligent action; Knowledge engineering; Logic; Multi agent systems; Robotic interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CN9DQDA","journalArticle","2019","Imel, Z.E.; Pace, B.T.; Soma, C.S.; Tanana, M.; Hirsch, T.; Gibson, J.; Georgiou, P.; Narayanan, S.; Atkins, D.C.","Design feasibility of an automated, machine-learning based feedback system for motivational interviewing","Psychotherapy","","00333204","10.1037/pst0000221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063985695&doi=10.1037%2fpst0000221&partnerID=40&md5=20d1cfc6e7033bf619a267c74e7e1fa9","Direct observation of psychotherapy and providing performance-based feedback is the gold-standard approach for training psychotherapists. At present, this requires experts and training human coding teams, which is slow, expensive, and labor intensive. Machine learning and speech signal processing technologies provide a way to scale up feedback in psychotherapy. We evaluated an initial proof of concept automated feedback system that generates motivational interviewing quality metrics and provides easy access to other session data (e.g., transcripts). The system automatically provides a report of session-level metrics (e.g., therapist empathy) and therapist behavior codes at the talk-turn level (e.g., reflections). We assessed usability, therapist satisfaction, perceived accuracy, and intentions to adopt. A sample of 21 novice (n = 10) or experienced (n = 11) therapists each completed a 10-min session with a standardized patient. The system received the audio from the session as input and then automatically generated feedback that therapists accessed via a web portal. All participants found the system easy to use and were satisfied with their feedback, 83% found the feedback consistent with their own perceptions of their clinical performance, and 90% reported they were likely to use the feedback in their practice. We discuss the implications of applying new technologies to evaluation of psychotherapy. © 2019 American Psychological Association.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","318-328","","2","56","","","","","","","","","","English","","","","","","","Publisher: American Psychological Association Inc.","<p>cited By 6</p>","","","Adult; Female; Humans; Male; perception; machine learning; Feedback; psychotherapy; empathy; satisfaction; Machine Learning; psychology; motivational interviewing; article; human; adult; female; male; controlled study; genetic transcription; clinical article; procedures; Clinical Competence; clinical competence; Feasibility Studies; feasibility study; feedback system; mental disease; Mental Disorders; Motivational Interviewing; proof of concept; Psychological; psychological feedback","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4572QUJS","conferencePaper","2019","Langen, M.; Heinrich, S.","Humanoid Robots: Use Cases as AI-Lab Companion : An empathic and collaborative digital companion motivate innovation?","Proceedings - 2019 IEEE International Conference on Engineering, Technology and Innovation, ICE/ITMC 2019","978-1-72813-401-7","","10.1109/ICE.2019.8792614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071458291&doi=10.1109%2fICE.2019.8792614&partnerID=40&md5=3e312b0ea8dc45f69fafb926fee82d1e","This paper describes several use cases for a humanoid robot in an innovation lab environment. They are implemented on Pepper, a commercially available robot. Pepper is used as digital consultant in the Siemens AI-Lab. The different functionalities range from being a concierge for new guests to being a tutor for AI or do answering questions in open and project-specific domains. Besides the built-in speech and visual recognition system provided by the robot our own developed AI technologies are integrated. © 2019 IEEE.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 25th IEEE International Conference on Engineering, Technology and Innovation, ICE/ITMC 2019 ; Conference Date: 17 June 2019 Through 19 June 2019; Conference Code:150797</p>","","","Artificial intelligence; Speech recognition; Human robot interaction; Humanoid robot; Anthropomorphic robots; AI Technologies; Engineering research; digital companion; Laboratories; Siemens; Visual recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5FYE9IX8","journalArticle","2019","Black, D.","Machines with Faces: Robot Bodies and the Problem of Cruelty","Body and Society","","1357034X","10.1177/1357034X19839122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063932245&doi=10.1177%2f1357034X19839122&partnerID=40&md5=9cecd73ef6a32f0fe42a737f17b52f83","Even if it is never possible to create a sentient robot that might lay claim to the status of personhood, a convincingly realistic robotic simulation of the human body could alter how human beings act towards one another. This article argues that the human face exerts a powerful influence over interpersonal interaction, creating empathetic connections that limit our capacity to engage in acts of cruelty; an ability to convincingly simulate the human face would detach it from the attribution of human personhood and so encourage a dismissal of its affective charge. This possibility can be understood in the context of existing attempts to inoculate individuals against the appeal of the face so as to facilitate organised killing. © The Author(s) 2019.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","3-27","","2","25","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QDVG6FJG","conferencePaper","2019","Degraen, D.; Kosmalla, F.; Krüger, A.","Overgrown: Supporting plant growth with an endoskeleton for ambient notifications","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-5971-9","","10.1145/3290607.3312833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067302392&doi=10.1145%2f3290607.3312833&partnerID=40&md5=737e704d963e985c7fe9415be110f795","Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments. © 2019 Copyright held by the owner/author(s).","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 3; Conference of 2019 CHI Conference on Human Factors in Computing Systems, CHI EA 2019 ; Conference Date: 4 May 2019 Through 9 May 2019; Conference Code:147771</p>","","","Ambient interfaces; Living environment; Human computer interaction; Ambient notifications; Empathic living media; Essential elements; Focus groups; Human engineering; Robotic structures; Social experiments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQGIMATI","journalArticle","2019","Sanal, M.G.; Paul, K.; Kumar, S.; Ganguly, N.K.","Artificial intelligence and deep learning: The future of medicine and medical practice","Journal of Association of Physicians of India","","00045772","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067569100&partnerID=40&md5=cc6799f54fa56c639d845a3e9b5806d1","Artificial Intelligence (AI) and access to “Big Data” together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (“wiki”) with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition. © 2019, Journal of Association of Physicians of India. All rights reserved.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","71-73","","May","67","","","","","","","","","","English","","","","","","","Publisher: Journal of Association of Physicians of India","<p>cited By 5</p>","","","Humans; artificial intelligence; Algorithms; Artificial Intelligence; Deep Learning; human; Delivery of Health Care; health care delivery; algorithm; Diabetes Mellitus; non insulin dependent diabetes mellitus; physician; Physicians; Type 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIFDYCPY","journalArticle","2019","Sabeti, E.; Gryak, J.; Derksen, H.; Biwer, C.; Ansari, S.; Isenstein, H.; Kratz, A.; Najarian, K.","Learning Using Concave and Convex Kernels: Applications in predicting quality of sleep and level of fatigue in fibromyalgia","Entropy","","10994300","10.3390/e21050442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066627348&doi=10.3390%2fe21050442&partnerID=40&md5=507af163e3f33df7e2069faa4327e188","Fibromyalgia is a medical condition characterized by widespread muscle pain and tenderness and is often accompanied by fatigue and alteration in sleep, mood, and memory. Poor sleep quality and fatigue, as prominent characteristics of fibromyalgia, have a direct impact on patient behavior and quality of life. As such, the detection of extreme cases of sleep quality and fatigue level is a prerequisite for any intervention that can improve sleep quality and reduce fatigue level for people with fibromyalgia and enhance their daytime functionality. In this study, we propose a new supervised machine learning method called Learning Using Concave and Convex Kernels (LUCCK). This method employs similarity functions whose convexity or concavity can be configured so as to determine a model for each feature separately, and then uses this information to reweight the importance of each feature proportionally during classification. The data used for this study was collected from patients with fibromyalgia and consisted of blood volume pulse (BVP), 3-axis accelerometer, temperature, and electrodermal activity (EDA), recorded by an Empatica E4 wristband over the courses of several days, as well as a self-reported survey. Experiments on this dataset demonstrate that the proposed machine learning method outperforms conventional machine learning approaches in detecting extreme cases of poor sleep and fatigue in people with fibromyalgia. © 2019 by the authors.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","5","21","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FI3H538Y","conferencePaper","2019","Barbieri, F.; Guizzo, E.; Lucchesi, F.; Maffei, G.; Del Prado Martín, F.M.; Weyde, T.","Towards a multimodal time-based empathy prediction system","Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019","978-1-72810-089-0","","10.1109/FG.2019.8756532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070472384&doi=10.1109%2fFG.2019.8756532&partnerID=40&md5=68ba6051cdf7332258f7450ae3a6e899","We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community. © 2019 IEEE.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019 ; Conference Date: 14 May 2019 Through 18 May 2019; Conference Code:149544</p>","","","Deep learning; Gesture recognition; Emotion recognition; Multi-modal; Evaluation results; Late fusion; Multiple modalities; Prediction systems; Research communities; Time based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5HDEAI44","journalArticle","2019","Van Pham, H.; Asadi, F.; Abut, N.; Kandilli, I.","Hybrid spiral STC-hedge algebras model in knowledge reasonings for robot coverage path planning and its applications","Applied Sciences (Switzerland)","","20763417","10.3390/app9091909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067170888&doi=10.3390%2fapp9091909&partnerID=40&md5=9b46fa93d1bf8a023e1d00056b886dcf","Robotics is a highly developed field in industry, and there is a large research effort in terms of humanoid robotics, including the development of multi-functional empathetic robots as human companions. An important function of a robot is to find an optimal coverage path planning, with obstacle avoidance in dynamic environments for cleaning and monitoring robotics. This paper proposes a novel approach to enable robotic path planning. The proposed approach combines robot reasoning with knowledge reasoning techniques, hedge algebra, and the Spiral Spanning Tree Coverage (STC) algorithm, for a cleaning and monitoring robot with optimal decisions. This approach is used to apply knowledge inference and hedge algebra with the Spiral STC algorithm to enable autonomous robot control in the optimal coverage path planning, with minimum obstacle avoidance. The results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot. Experimental results are compared with current methods under the same conditions. The proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates. Experiments are done with real robots for cleaning in dynamic environments. © 2019 by the authors.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","9","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5SL229W","journalArticle","2019","Piumatti, G.; Abbiati, M.; Baroffio, A.; Gerbase, M.W.","Associations between motivational factors for studying medicine, learning approaches and empathy among medical school candidates","Advances in Health Sciences Education","","13824996","10.1007/s10459-018-9866-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056658658&doi=10.1007%2fs10459-018-9866-6&partnerID=40&md5=03617490c381649c560fcd1583bafa25","Previous research highlighted associations between students’ motivation for medical studies and their learning approaches on the one hand and empathy on the other. Internal motivational factors for studying medicine (e.g., care for patients, save lives) coupled with a deep approach to learning have been positively related to empathy in contrast to external motivational factors (e.g., future earning potential, prestige) and surface learning. However, assessments of these assumptions among medical school candidates are scarce. This study examined the relationship between different motivational factors and empathy among students enrolled in a selection year in medicine by testing the mediating role of learning approaches. A sample of 572 candidates for medical studies answered a self-reported questionnaire half way through their selection year. Measures included internal and external motivational factors for studying medicine, deep and surface learning approaches and empathy. Path-analysis tested the mediation effects of deep and surface approaches to learning on the relationship of internal and external motivational factors with empathy. The deep learning approach partially mediated the significant positive association between internal motivational factors and empathy, while the surface learning approach fully mediated the significant negative association between external motivational factors and empathy. These results suggest that learning approaches could be a pathway by which internal and external motives for studying medicine are related to empathy among medical school candidates. Pedagogical strategies and educational environments accounting for individual differences in motivation and learning may contribute to training students to become professional and caring doctors in the future. © 2018, Springer Nature B.V.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","287-300","","2","24","","","","","","","","","","English","","","","","","","Publisher: Springer Netherlands","<p>cited By 2</p>","","","Adult; Female; Humans; Male; Young Adult; learning; Learning; Reward; Empathy; empathy; altruism; psychology; decision making; reward; motivation; Students; questionnaire; article; human; human experiment; adult; female; male; young adult; adolescent; Adolescent; self report; Motivation; Altruism; Career Choice; Medical; medical school; medical student; path analysis; Self Report; Socioeconomic Factors; socioeconomics; Switzerland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YATQFEUR","conferencePaper","2019","Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.","Performance analysis of unimodal and multimodal models in valence-based empathy recognition","Proceedings - 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019","978-1-72810-089-0","","10.1109/FG.2019.8756517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070455625&doi=10.1109%2fFG.2019.8756517&partnerID=40&md5=cf50721db883d29dc85761df97f9ee76","The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, humanrobot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set. © 2019 IEEE.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 14th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2019 ; Conference Date: 14 May 2019 Through 18 May 2019; Conference Code:149544</p>","","","Gesture recognition; Human robot interaction; Acoustic features; Correlation coefficient; Interpersonal relationship; Multimodal modeling; Multimodal models; Performance analysis; Short term memory; Subject dependencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PSSQP2R","journalArticle","2019","Cross, E.S.; Riddoch, K.A.; Pratts, J.; Titone, S.; Chaudhury, B.; Hortensius, R.","A neurocognitive investigation of the impact of socializing with a robot on empathy for pain","Philosophical Transactions of the Royal Society B: Biological Sciences","","09628436","10.1098/rstb.2018.0034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062693788&doi=10.1098%2frstb.2018.0034&partnerID=40&md5=2571e9a19730d18d3a12e4bda31d9487","To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'. © 2019 The Author(s) Published by the Royal Society. All rights reserved.","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","","","1771","374","","","","","","","","","","English","","","","","","","Publisher: Royal Society Publishing","<p>cited By 9</p>","","","Brain; Adult; Female; Humans; Male; Young Adult; brain; Robotics; Cognition; physiology; Magnetic Resonance Imaging; pain; cognition; plasticity; Empathy; empathy; robotics; Pain; human; adult; female; male; young adult; human relation; Interpersonal Relations; nuclear magnetic resonance imaging; social behavior; hypothesis testing; neurology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQ565MCA","conferencePaper","2019","Jean-Charles, N.; Haas, G.; Drennan, A.","Using machine learning to convey emotions during requirements elicitation interviews","ACMSE 2019 - Proceedings of the 2019 ACM Southeast Conference","978-1-4503-6251-1","","10.1145/3299815.3314484","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065911844&doi=10.1145%2f3299815.3314484&partnerID=40&md5=95c5fb9b50f63b877831289145b62e48","In an effort to assist in an ongoing research project where stakeholders have been interviewed using voice recording platforms and the Empatica E4 wristband to gather biofeedback data, the purpose of this research project in relation to the aforementioned research is to be able to determine the stakeholder’s emotional range during a requirements elicitation interview. In doing so, the requirements analyst is supported during the requirements elicitation interview because conveying the emotional range of the stakeholder can help eliminate any miscommunication or misunderstandings between the requirements analyst and the stakeholder due to ambiguity in questions, statements, and responses. Therefore, knowing the range of the emotional state of the stakeholder, in real-time, can allow the requirements analyst to recover or make adjustments to questions (i.e. sensitive topics) during the requirements elicitation interview. The main questions are: (1) What machine learning technique(s) would be most efficient in conveying the emotional range of the stakeholder through the voice recording data and biofeedback data? (2) What features would result in optimal performance from the chosen machine learning technique(s)? The objective is to use supervised machine learning techniques in order to convey an emotional range from the retrieved dataset. To accomplish this, exploring the most efficient machine learning technique for emotion detection for voice recordings and biofeedback data and finding a way to construct or utilize the techniques in an effective manner will be necessary. In conclusion, the machine learning technique(s) chosen will convey a range of emotion from the stakeholder based on the retrieved data. The machine learning technique(s) will be used to support a requirements analyst during requirements elicitation interviews and will help the analyst identify problems or concerns in the communication to better assess and engage the stakeholder. © 2019 Copyright held by the owner/author(s).","2019","2021-05-19 13:26:23","2021-05-19 13:26:23","","266-267","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 2019 ACM Southeast Conference, ACMSE 2019 ; Conference Date: 18 April 2019 Through 20 April 2019; Conference Code:147761</p>","","","Machine learning; Emotional state; Learning algorithms; Machine learning techniques; Supervised learning; Supervised machine learning; Requirements elicitation; Requirements engineering; Emotion detection; Biofeedback; Optimal performance; Recording data; Requirements analyst","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T436T735","conferencePaper","2019","Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.","Ideal warrior and robot relations: Stress and empathy's role in human-robot teaming","2019 Systems and Information Engineering Design Symposium, SIEDS 2019","978-1-72810-998-5","","10.1109/SIEDS.2019.8735613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068571842&doi=10.1109%2fSIEDS.2019.8735613&partnerID=40&md5=ccc21f2fe0c8fc29e283088fe64aa7f2","The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design. © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 2019 Systems and Information Engineering Design Symposium, SIEDS 2019 ; Conference Date: 26 April 2019; Conference Code:148712</p>","","","Human robot interaction; Machine design; Human robots; Automated technology; Human-machine; Maximum Efficiency; Military training; Robot designs; Subjective assessments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFDSJAFA","journalArticle","2019","Haynes, A.; Simons, M.F.; Helps, T.; Nakamura, Y.; Rossiter, J.","A wearable skin-stretching tactile interface for human-robot and human-human communication","IEEE Robotics and Automation Letters","","23773766","10.1109/LRA.2019.2896933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063310844&doi=10.1109%2fLRA.2019.2896933&partnerID=40&md5=afeb631d352349915cfb13c97dad658e","Currently, the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user. While this can be very effective, vibration as a physical stimulation is limited in modality and is uncommon in the natural world. In many cases, for human-robot and human-human interaction, a more natural, affective tactile interaction is needed to provide comfortable and varied stimuli. In this letter, we present the super-cutaneous wearable electrical empathic stimulator (SCWEES), a tactile device that gently stretches and squeezes the surface of the skin. Our hypothesis is that this device can create a pleasant, unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts. We describe the design of the SCWEES, a lightweight 3D-printed semi-flexible structure that attaches to the skin at two points and actuates via two shape-memory alloy coil actuators. We evaluate the SCWEES through a range of human interaction experiments: Stimulation strength and pleasantness, contraction and extension, and the conveyance of non-disruptive notifications. Quantitative and qualitative results show that the SCWEES generates a pleasant sensation, can convey useful information in human-machine interactions, and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task. © 2016 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","1641-1646","","2","4","","","","","","","","","","English","","","","","","","Publisher: Institute of Electrical and Electronics Engineers Inc.","<p>cited By 7</p>","","","Human robot interaction; Haptic interfaces; Wearable technology; Man machine systems; Human-human interactions; Human computer interaction; 3D printers; Social human-robot interactions; Wearable robots; Robot applications; Flexible structures; Haptics and haptic interfaces; Human machine interaction; Human-human communication; Semi-flexible structure; Shape-memory alloy; Tactile stimulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2AX9993","conferencePaper","2019","Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.","The RoPE Scale: A Measure of How Empathic a Robot is Perceived","ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","10.1109/HRI.2019.8673082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063988065&doi=10.1109%2fHRI.2019.8673082&partnerID=40&md5=bb92abeea2fde8a7291997b624203491","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting. © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","656-657","","","2019-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 2; Conference of 14th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2019 ; Conference Date: 11 March 2019 Through 14 March 2019; Conference Code:146545</p>","","","Psychometrics; Social robots; Perceived Empathy; Human robot interaction; Man machine systems; Human robot Interaction (HRI)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQEIN4NG","conferencePaper","2019","Sanoubari, E.; Seo, S.H.; Garcha, D.; Young, J.E.; Loureiro-Rodriguez, V.","Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","10.1109/HRI.2019.8673326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064013532&doi=10.1109%2fHRI.2019.8673326&partnerID=40&md5=790f12ed481e2a7fd36f88f62a4c702b","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable? © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","382-391","","","2019-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 4; Conference of 14th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2019 ; Conference Date: 11 March 2019 Through 14 March 2019; Conference Code:146545</p>","","","Social robots; Human robot interaction; Man machine systems; Machine design; Human like; Knowledge management; Robot designs; Body language; Cell culture; Communication techniques; Minimal information; Persuasive robots; Social signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUMGNBVJ","conferencePaper","2019","Vertesi, J.","Seeing Like a Rover: Team Work and Human-Robot Relations","ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","10.1109/HRI.2019.8673224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064000114&doi=10.1109%2fHRI.2019.8673224&partnerID=40&md5=8408e02463168815ec87397c3fa3c02f","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' 'eyes' on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life. © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","152","","","2019-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 14th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2019 ; Conference Date: 11 March 2019 Through 14 March 2019; Conference Code:146545</p>","","","Robotics; Teamwork; NASA; Human robot interaction; Man machine systems; Emotional connections; Human cognition; Mars exploration rover missions; Martian surface analysis; Meaning makings; Robotic spacecrafts; Scientific discovery; Search and rescue operations; Space flight","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGT3QD6W","conferencePaper","2019","Roy, S.; Kieson, E.; Abramson, C.; Crick, C.","Mutual Reinforcement Learning with Robot Trainers","ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","10.1109/HRI.2019.8673284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063999356&doi=10.1109%2fHRI.2019.8673284&partnerID=40&md5=ef8ef3c964093140f6aaf2f1f9bb2ac6","The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners. © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","572-573","","","2019-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 0; Conference of 14th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2019 ; Conference Date: 11 March 2019 Through 14 March 2019; Conference Code:146545</p>","","","Machine learning; Reinforcement learning; Human robot interaction; Man machine systems; Intelligent agents; Human robots; Human cognition; In-buildings; Mutual reinforcement; Reinforcement learning agent; Reinforcement model; Shared model; Skill transfer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6UC9NE8","journalArticle","2019","Küster, D.; Krumhuber, E.G.; Hess, U.","You are What You Wear: Unless You Moved—Effects of Attire and Posture on Person Perception","Journal of Nonverbal Behavior","","01915886","10.1007/s10919-018-0286-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055966865&doi=10.1007%2fs10919-018-0286-3&partnerID=40&md5=dfd97f867726dfa1ea0958eb2409c58f","While first impressions are often based on appearance cues, little is known about how these interact with information from other channels. The present research aimed to investigate the impact of occupational stereotypes, evoked by attire, as well as posture on person perception. For this, computer animation was used to create avatars with different types of attire (nurse, military, casual) and posture (open, closed). In Study 1 (N = 164), participants attributed significantly more empathy to avatars wearing a nurse versus a military uniform or casual outfit. When adding posture as an additional cue, Study 2 (N = 312) showed that ratings of empathy and dominance were affected by both attire and posture. This effect was replicated in Study 3 (N = 163) for female avatars, in the sense that open postures in nurses increased empathy ratings and decreased dominance ratings, which both in turn led to greater perceived competence. By contrast, for male avatars, posture did not affect attributions of competence directly. Rather, attire predicted perceived dominance directly, as well as through perceived empathy. The present findings suggest that both posture, and occupational information evoked by attire, are used to infer personal characteristics. However, the strength of each cue may vary with the gender of the target. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","23-38","","1","43","","","","","","","","","","English","","","","","","","Publisher: Springer New York LLC","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH7SSC5L","conferencePaper","2019","Carranza, K.A.R.; Day, N.J.B.; Lin, L.M.S.; Ponce, A.R.; Reyes, W.R.O.; Abad, A.C.; Baldovino, R.G.","Akibot: A telepresence robot for medical teleconsultation","2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management, HNICEM 2018","978-1-5386-7767-4","","10.1109/HNICEM.2018.8666283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064112074&doi=10.1109%2fHNICEM.2018.8666283&partnerID=40&md5=b809f1bea743c4cb1a0c7b43476bfdce","One problem in the healthcare industry in the Philippines is the maldistribution of doctors. This greatly affects the accessibility of patients to proper healthcare. As a matter of fact, in 2015, 59.2% of deaths in the Philippines are attributed as deaths unattended by a doctor. Although there are current government programs, which aim to solve this problem, the use of telepresence systems can be another viable solution as doctors can still provide quality healthcare services even when located in a remote area. One limitation of medical telepresence robots is the lack of medical features. For this reason, the developed telepresence system includes a telepresence robot called Akibot with integrated medical devices such as otoscope, stethoscope, and ultrasound probe. Akibot is a highly maneuverable remotely controlled telepresence robot designed for general practice medical consultation between doctors and a patient on a remote area. Akibot has an empathic exterior with 4.6 out of 5 rating on its perceived quality of appearance and is equipped with modular medical devices and highly customizable screen, tested on an Android and Windows OS. © 2018 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 10th IEEE International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management, HNICEM 2018 ; Conference Date: 29 November 2018 Through 2 December 2018; Conference Code:146034</p>","","","Robots; Health care; Machine design; Environmental management; Telemedicine; Robot designs; Visual communication; General practice medical consultation; Government projects; Healthcare industry; Medical applications; Nanotechnology; Quality healthcare; Tele-presence systems; Teleconsultation; Telepresence robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QDNPXXG","journalArticle","2019","Alves-Oliveira, P.; Sequeira, P.; Melo, F.S.; Castellano, G.; Paiva, A.","Empathic Robot for Group Learning: A Field Study","ACM Transactions on Human-Robot Interaction","","25739522","10.1145/3300188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068536369&doi=10.1145%2f3300188&partnerID=40&md5=38936e838e88debca3eecfa94296497b","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning. © 2019 ACM.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","","","1","8","","","","","","","","","","English","","","","","","","Publisher: Association for Computing Machinery","<p>cited By 20</p>","","","Robots; Students; Agricultural robots; Research questions; Educational robots; Collaborative learning; Field studies; Group learning; Learning Activity; Learning gain; Learning outcome; Sustainability education; Sustainable development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFVL9I6C","journalArticle","2019","Blease, C.; Kaptchuk, T.J.; Bernstein, M.H.; Mandl, K.D.; Halamka, J.D.; Desroches, C.M.","Artificial intelligence and the future of primary care: exploratory qualitative study of UK general practitioners' views","Journal of Medical Internet Research","","14388871","10.2196/12802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063303215&doi=10.2196%2f12802&partnerID=40&md5=41136ee763c24454922fbdbed2e48d68","Background: The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics and related fields. Objective: This study aimed to explore general practitioners' (GPS') opinions about the potential impact of future technology on key tasks in primary care. Methods: In June 2018, we conducted a Web-based survey of 720 UK GPS' opinions about the likelihood of future technology to fully replace GPS in performing 6 key primary care tasks, and, if respondents considered replacement for a particular task likely, to estimate how soon the technological capacity might emerge. This study involved qualitative descriptive analysis of written responses (""comments"") to an open-ended question in the survey. Results: Comments were classified into 3 major categories in relation to primary care: (1) limitations of future technology, (2) potential benefits of future technology, and (3) social and ethical concerns. Perceived limitations included the beliefs that communication and empathy are exclusively human competencies; many GPS also considered clinical reasoning and the ability to provide value-based care as necessitating physicians' judgments. Perceived benefits of technology included expectations about improved efficiencies, in particular with respect to the reduction of administrative burdens on physicians. Social and ethical concerns encompassed multiple, divergent themes including the need to train more doctors to overcome workforce shortfalls and misgivings about the acceptability of future technology to patients. However, some GPS believed that the failure to adopt technological innovations could incur harms to both patients and physicians. Conclusions: This study presents timely information on physicians' views about the scope of artificial intelligence (AI) in primary care. Overwhelmingly, GPS considered the potential of AI to be limited. These views differ from the predictions of biomedical informaticians. More extensive, stand-alone qualitative work would provide a more in-depth understanding of GPS' views. © 2019 Journal of Medical Internet Research. All rights reserved.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","","","3","21","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 19</p>","","","Female; Humans; Male; expectation; prediction; artificial intelligence; Middle Aged; machine learning; Artificial Intelligence; empathy; qualitative research; primary health care; decision making; questionnaire; article; human; adult; female; male; general practitioner; middle aged; procedures; Surveys and Questionnaires; Qualitative Research; General Practitioners; informatician; Primary Health Care; treatment failure; United Kingdom; workforce","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDMUTSHJ","conferencePaper","2019","Salaken, S.M.; Nahavandi, S.; McGinn, C.; Hossny, M.; Kelly, K.; Abobakr, A.; Nahavandi, D.; Iskander, J.","Development of a cloud-based computational framework for an empathetic robot","ACM International Conference Proceeding Series","978-1-4503-6287-0","","10.1145/3313991.3314018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064612068&doi=10.1145%2f3313991.3314018&partnerID=40&md5=63ff43c5b27f0b4f09c443d56e71a480","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator’s voice is presented. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","102-108","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 1; Conference of 11th International Conference on Computer and Automation Engineering, ICCAE 2019 ; Conference Date: 23 February 2019 Through 25 February 2019; Conference Code:147275</p>","","","Deep learning; Robots; Emotion classification; Machine design; Behavioral research; Cloud based platforms; Cloud control; Computational burden; Computational framework; Computational resources; Safety engineering; System optimizations; Theoretical framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NPXD293T","conferencePaper","2019","Das, A.K.; Ashrafi, A.; Ahmmad, M.","Joint cognition of both human and machine for predicting criminal punishment in judicial system","2019 IEEE 4th International Conference on Computer and Communication Systems, ICCCS 2019","978-1-72811-322-7","","10.1109/CCOMS.2019.8821655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071115729&doi=10.1109%2fCCOMS.2019.8821655&partnerID=40&md5=c2141b9cb6d314f80753bcccba34ada4","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can’t only perform faster but also predict better than human. But a human has some qualities which can never be gained by a Machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to ‘Women and Children Repression Prevention Act, 2000’. We apply several Machine learning algorithms to make a Machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide Machine for judging a delinquent. © 2019 IEEE.","2019","2021-05-19 13:26:24","2021-05-19 13:26:24","","36-40","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 7; Conference of 4th IEEE International Conference on Computer and Communication Systems, ICCCS 2019 ; Conference Date: 23 February 2019 Through 25 February 2019; Conference Code:151726</p>","","","Machine learning; Judge; Forecasting; Critical thinking; Learning algorithms; Learning systems; Artificial intelligence systems; Computer aided software engineering; Human guided; Judicial systems; Online surveys; Predict punishment; Predictive power","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXF3VVJD","journalArticle","2019","Wartman, S.A.; Combs, C.D.","Reimagining medical education in the age of AI","AMA Journal of Ethics","","23766980","10.1001/amajethics.2019.146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061990597&doi=10.1001%2famajethics.2019.146&partnerID=40&md5=eb1325df514ae1ebc5c6e2532c89d224","Available medical knowledge exceeds the organizing capacity of the human mind, yet medical education remains based on information acquisition and application. Complicating this information overload crisis among learners is the fact that physicians' skill sets now must include collaborating with and managing artificial intelligence (AI) applications that aggregate big data, generate diagnostic and treatment recommendations, and assign confidence ratings to those recommendations. Thus, an overhaul of medical school curricula is due and should focus on knowledge management (rather than information acquisition), effective use of AI, improved communication, and empathy cultivation. ©2019 American Medical Association.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","146-152","","2","21","","","","","","","","","","English","","","","","","","Publisher: American Medical Association","<p>cited By 23</p>","","","Adult; Female; Humans; Male; artificial intelligence; Middle Aged; Education; Artificial Intelligence; education; curriculum; medical education; human; adult; female; male; middle aged; procedures; Medical; Curriculum; health care personnel; Health Information Management; Health Personnel; medical information system; organization and management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW238EMC","conferencePaper","2019","Shvo, M.","Towards empathetic planning and plan recognition","AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","978-1-4503-6324-2","","10.1145/3306618.3314307","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070635759&doi=10.1145%2f3306618.3314307&partnerID=40&md5=69bd49013c7283146e3d8efb1d0c94a9","Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants. © 2019 Copyright held by the owner/author(s).","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","525-526","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 1; Conference of 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019 ; Conference Date: 27 January 2019 Through 28 January 2019; Conference Code:149526</p>","","","AI planning; Philosophical aspects; Affective state; Computational approach; Plan recognition; Planning and plan recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EDNV8JNJ","conferencePaper","2019","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.","Counseling Robot Implementation and Evaluation","Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018","978-1-5386-6650-0","","10.1109/SMC.2018.00297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062214049&doi=10.1109%2fSMC.2018.00297&partnerID=40&md5=430fc180d5787ab662d9003595001288","A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called 'unazuki' in Japanese, a kind of nodding to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared. © 2018 IEEE.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","1716-1722","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 3; Conference of 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018 ; Conference Date: 7 October 2018 Through 10 October 2018; Conference Code:144462</p>","","","Robots; Counseling; Dialog Promotion; Nodding; unazuki; Quantitative evaluation; Cybernetics; Experimental evaluation; Psychological distress; Robot implementation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZCZQSQP","journalArticle","2019","Luo, X.; Tong, S.; Fang, Z.; Qu, Z.","Frontiers: Machines vs. humans: The impact of artificial intelligence chatbot disclosure on customer purchases","Marketing Science","","07322399","10.1287/mksc.2019.1192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076479809&doi=10.1287%2fmksc.2019.1192&partnerID=40&md5=a51159b04876baf695f282b32cef9d71","Empowered by artificial intelligence (AI), chatbots are surging as new technologies with both business potential and customer pushback. This study exploits field experiment data on more than 6,200 customers who are randomized to receive highly structured outbound sales calls from chatbots or human workers. Results suggest that undisclosed chatbots are as effective as proficient workers and four times more effective than inexperienced workers in engendering customer purchases. However, a disclosure of chatbot identity before the machine–customer conversation reduces purchase rates by more than 79.7%. Additional analyses find that these results are robust to nonresponse bias and hang-ups, and the chatbot disclosure substantially decreases call length. Exploration of the mechanisms reveals that when customers know the conversational partner is not a human, they are curt and purchase less because they perceive the disclosed bot as less knowledgeable and less empathetic. The negative disclosure effect seems to be driven by a subjective human perception against machines, despite the objective competence of AI chatbots. Fortunately, such negative impact can be mitigated by a late disclosure timing strategy and customer prior AI experience. These findings offer useful implications for chatbot applications, customer targeting, and advertising in conversational commerce. © 2019 INFORMS.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","937-947","","6","38","","","","","","","","","","English","","","","","","","Publisher: INFORMS Inst.for Operations Res.and the Management Sciences","<p>cited By 50</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6SVVFDD","journalArticle","2019","Varlamov, O.O.; Chuvikov, D.A.; Adamova, L.E.; Petrov, M.A.; Zabolotskaya, I.K.; Zhilina, T.N.","Logical, philosophical and ethical aspects of AI in medicine","International Journal of Machine Learning and Computing","","20103700","10.18178/ijmlc.2019.9.6.885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077569724&doi=10.18178%2fijmlc.2019.9.6.885&partnerID=40&md5=b1dc5825375f976debfee3cffa094d4c","The logical type of Artificial Intelligence is presented in the article. MIVAR (Multidimensional Informational Variable Adaptive Reality) technology is based on the gnoseological triplet concept ""Thing - Property - Relationship."" The unlimited number of MIVAR units fill the MIVAR space that makes it communicatory, discrete, and scalable. MIVAR information processing allows creating complicated algorithms for medicine. We have chosen the clinical model of pain in the heart for preparation ontology for doctors. Knowledge expert model MIVAR WiMi ""Chest Pain"" is shown. The logical Artificial Intelligence (expert model) can help doctors fast, precisely and in the best way in the decision-making process. Except medical ontology Artificial Intelligence must have an empathic, emotional experience, without that medical care cannot be imagined. MIVAR technology is the closest to human thinking among other Artificial Intelligence technologies; it differs from the Artificial network of Mirror neurons, related to emotional perception, but MIVAR space with rules and constraints can imitate emotions and empathy. © 2019 International Association of Computer Science and Information Technology.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","868-873","","6","9","","","","","","","","","","English","","","","","","","Publisher: International Association of Computer Science and Information Technology","<p>cited By 7</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2IG7HJYR","journalArticle","2019","Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.","Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects","Lecture Notes in Electrical Engineering","","18761100","10.1007/978-3-030-04672-9_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f","The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","101-113","","","540","","","","","","","","","","English","","","","","","","ISBN: 9783030046712 Publisher: Springer Verlag","<p>cited By 0; Conference of 8th Italian Forum on Ambient Assisted Living, ForitAAL 2017 ; Conference Date: 12 June 2017 Through 15 June 2017; Conference Code:223489</p>","","","Robotics; Animals; Empathy; Robots; Social robotics; Human-object continuum; Living-nonliving continuum; Social distance; Assisted living","","Casiddu N., Monteriu A., Porfirione C., Cavallo F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQW4Z2KD","conferencePaper","2019","Takano, M.; Tsunoda, T.","Self-disclosure of bullying experiences and social support in avatar communication: Analysis of verbal and nonverbal communications","Proceedings of the 13th International Conference on Web and Social Media, ICWSM 2019","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070376669&partnerID=40&md5=c4980b3e2f1fec8b0a980aab67deb0fa","Avatar communication through the Internet has great potential to be an appropriate environment for self-disclosure and social support. Anonymity and ease of access drive self-disclosure of even the most serious problems. Rich nonverbal communication, co-presence, and real-time interaction increase emotional closeness. However, there has not been much research with regard to examining social support in avatar communication. In this paper, we aim to facilitate self-disclosure and social support for bullied people through avatar communication. For this purpose, we analyzed verbal and nonverbal communication about bullying experiences through an avatar communication service. We demonstrate that people who emotionally disclosed their bullying experiences received better social support. In addition, people who provided social support used emotional expressions to convey emotional empathy. These were observed in conversations with a few acquaintances in closed spaces. Our findings reveal areas where we can improve upon the design of avatar communication spaces for effective social support. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","473-481","","","","","","","","","","","Association for the Advancement of Artificial Intelligence","","English","","","","","","","","<p>cited By 1; Conference of 13th International Conference on Web and Social Media, ICWSM 2019 ; Conference Date: 11 June 2019 Through 14 June 2019; Conference Code:149465</p>","","","Self-disclosure; Social support; Avatar communications; Non-verbal communications; Social networking (online); Emotional expressions; Closed spaces; Co-presence; Real time interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJI8R6GH","journalArticle","2019","Shorey, S.; Ang, E.; Yap, J.; Ng, E.D.; Lau, S.T.; Chui, C.K.","A virtual counseling application using artificial intelligence for communication skills training in nursing education: Development study","Journal of Medical Internet Research","","14388871","10.2196/14658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074280727&doi=10.2196%2f14658&partnerID=40&md5=7a03884a7f18dacaff1c265fa63f57a2","Background: The ability of nursing undergraduates to communicate effectively with health care providers, patients, and their family members is crucial to their nursing professions as these can affect patient outcomes. However, the traditional use of didactic lectures for communication skills training is ineffective, and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts, a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients, their family members, and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation, design, and development, followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine, Google Cloud's Dialogflow, and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman, (2) taking the history of a depressed patient, (3) escalating a bleeding episode of a postoperative patient to a physician, and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development, technological limitations, and expectations management, which can be resolved by contingency planning, open communication, constant program updates, refinement, and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However, given the infancy stage of this project, further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation. © Shefaly Shorey, Emily Ang, John Yap, Esperanza Debby Ng, Siew Tiang Lau, Chee Kong Chui.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","","","10","21","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 8</p>","","","Female; Humans; artificial intelligence; Communication; Education; Artificial Intelligence; virtual reality; nursing education; Counseling; Virtual Reality; interpersonal communication; human; female; procedures; Nursing; Clinical Competence; clinical competence; counseling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTW7FGU8","conferencePaper","2019","Weisz, J.D.; Jain, M.; Joshi, N.N.; Johnson, J.; Lange, I.","BigBlueBot: Teaching strategies for successful human-agent interactions","International Conference on Intelligent User Interfaces, Proceedings IUI","","","10.1145/3301275.3302290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065584647&doi=10.1145%2f3301275.3302290&partnerID=40&md5=f65fcd8c30c030f91d0e8fa4ff25c7f7","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future. © 2019 Association for Computing Machinery.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","448-459","","","Part F147615","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 7; Conference of 24th ACM International Conference on Intelligent User Interfaces, IUI 2019 ; Conference Date: 17 March 2019 Through 20 March 2019; Conference Code:147615</p>","","","Conversational agents; Chatbots; User interfaces; Bridges; Human agent interactions; Learning experiences; Mechanical turks; Repair strategy; Teaching strategy; Technical capabilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRHF9GYJ","conferencePaper","2019","Gu, X.; Xu, W.; Zhang, C.","Neural emotional response generation via adversarial transfer learning","ACM International Conference Proceeding Series","978-1-4503-6128-6","","10.1145/3319921.3319933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066503947&doi=10.1145%2f3319921.3319933&partnerID=40&md5=5b34d3ff3ffd1557f68b68d62f9fe1f0","Emotional response generation is a key step to build an empathetic chatbot. However, previous emotional chatting models mainly focus on single-turn conversation, and multi-turn context emotional response generation has not been explored. In this paper, we propose an adversarial transfer emotional chatting (ATEC) model for multi-turn conversation which is based on conditional variational autoencoders (CVAE). ATEC has two alternate training phases: supervised training and transfer training. In the supervised training stage, we train the CVAE model, a content discriminator and an emotional classifier based on ground truth corpus. And in the transfer training stage, we change the target emotion and use the content discriminator to force the model to transfer the multi-turn context information, while the emotional classifier regularizes the emotions expressed in the generated responses. Experiments show that the proposed approach achieves state of the art performance with diverse responses and accurate emotional expression. © 2019 Association for Computing Machinery. All rights reserved.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","106-110","","","Part F148152","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 3rd International Conference on Innovation in Artificial Intelligence, ICIAI 2019 ; Conference Date: 15 March 2019 Through 18 March 2019; Conference Code:148152</p>","","","Learning systems; Emotional expressions; Classification (of information); Speech processing; Dialogue systems; Autoencoders; Context information; Emotion transfer; Emotional Classifiers; State-of-the-art performance; Supervised trainings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLX66VS5","conferencePaper","2019","Spring, T.; Casas, J.; Daher, K.; Mugellini, E.; Khaled, O.A.","Empathic response generation in chatbots","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073223333&partnerID=40&md5=e0494f270e72ed0bf93d01d6e98a9271","Recent years show an increasing popularity of chatbots, with latest efforts aiming to make them more empathic and human-like, finding application for example in customer service or in treating mental illnesses. Thereby, emphatic chatbots can understand the user’s emotional state and respond to it on an appropriate emotional level. This survey provides an overview of existing approaches used for emotion detection and empathic response generation. These approaches raise at least one of the following profound challenges: the lack of quality training data, balancing emotion and content level information, considering the full end-to-end experience and modelling emotions throughout conversations. Furthermore, only few approaches actually cover response generation. We state that these approaches are not yet empathic in that they either mirror the user’s emotional state or leave it up to the user to decide the emotion category of the response. Empathic response generation should select appropriate emotional responses more dynamically and express them accordingly, for example using emojis. Copyright © 2019 for this paper by its authors.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","","","","2458","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 4th Swiss Text Analytics Conference, SwissText 2019 ; Conference Date: 18 June 2019 Through 19 June 2019; Conference Code:151982</p>","","","Emotional state; Emotional response; Diseases; Mental illness; Customer services; Emotion detection; Content level; Quality training; Response generation","","Cieliebak M., Benites F., Tuggener D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57Q8LBHU","journalArticle","2019","Heudin, J.-C.","Artificial and human intelligence [Intelligence artificielle et intelligence humaine]","Futuribles: Analyse et Prospective","","0337307X","10.3917/futur.428.0093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060581172&doi=10.3917%2ffutur.428.0093&partnerID=40&md5=6a4596299e68d8dbf8891295e00b6299","Also as part of our special dossier on research into the brain and learning processes, a major question is raised in this article: are recent advances in artificial intelligence (Al), and particularly the rise of neural networks, liable to put in doubt the supremacy of the human brain? What differences in nature, what conflicts or complementarities are there between these two forms of intelligence? After reminding us of the birth of the neural networks field, the advances made with such networks and their recent successes, Jean-Claude Heudin lays out their limitations. He goes on to explain the specificity of neural networks and Al, which, he writes, ""are not complex systems, but ordered Systems"" that may have superior capacities to humans with respect to certain tasks. By contrast, human intelligence is ""manyfaceted, emotional and empathie""; for that reason, it has superior abilities to Al when it cornes to performing many other tasks and functioning in a complex environment. Lastly, taking pains to demonstrate the different forms of intelligence, Heudin condudes that Al and human intelligence are complementary. © 2019 Futuribles: Analyse et Prospective. All rights reserved.","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","93-105","","428","2019-February","","","","","","","","","","French","","","","","","","Publisher: Futuribles","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IG4AY9MV","journalArticle","2019","Vanman, E.J.; Kappas, A.","“Danger, Will Robinson!” The challenges of social robots for intergroup relations","Social and Personality Psychology Compass","","17519004","10.1111/spc3.12489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070056360&doi=10.1111%2fspc3.12489&partnerID=40&md5=df6ade6d0336dd74942733c534399eb2","Society's increasing reliance on robots in everyday life provides exciting opportunities for social psychologists to work with engineers in the nascent field of social robotics. In contrast to industrial robots that, for example, may be used on an assembly line, social robots are designed specifically to interact with humans and/or other robots. People tend to perceive social robots as autonomous and capable of having a mind. As such, they are also more likely to be subject to social categorization by humans. As social robots become more human like, people may also feel greater empathy for them and treat robots more like (human) ingroup members. On the other hand, as they become more human like, robots also challenge our human distinctiveness, threaten our identity, and elicit suspicion about their ability to deceive us with their human-like qualities. We review relevant research to explore this apparent paradox, particularly from an intergroup relations perspective. We discuss these findings and propose three research questions that we believe social psychologists are ideally suited to address. © 2019 John Wiley & Sons Ltd","2019","2021-05-19 13:26:25","2021-05-19 13:26:25","","","","8","13","","","","","","","","","","English","","","","","","","Publisher: Wiley-Blackwell","<p>cited By 5</p>","","","empathy; robotics; psychologist; identity; article; human; human experiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TLWM4NF","journalArticle","2019","Omokawa, R.; Kobayashi, M.; Matsuura, S.","Expressing the Personality of a Humanoid Robot as a Talking Partner in an Elementary School Classroom","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-23560-4_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069875511&doi=10.1007%2f978-3-030-23560-4_36&partnerID=40&md5=6fcb8f37cfa76597c0643f0aa6619d9d","A humanoid robot NAO was introduced as a talking partner of teaching AI and robot to the elementary school students to stimulate empathy for the intelligent machines. Two dialog types were defined. First, the query type dialog was defined as a robot’s answer to human questioning. Second, the phatic type dialogs were defined to express the personality of the robot. While the former type dialog is initiated by formulated questioning, the latter type response can even be induced by misrecognition of human speech. Applying this simple method, the same unit sessions for each of the three classrooms on AI and robot were conducted. During the sessions, students’ burst of laughter was induced at 83% of the phatic type dialog, and the laughing response was found at 44% of the query type dialogs. By this representation, it became easier for the students to empathize with the robot. After this session, a questionnaire survey on the preference of robot pet, on what the students wanted to talk with the robot that dreams at night, and on their view of life if AI robots replaced human workers was conducted. The results suggested that the students got to imagine a virtual subjectivity of the intelligent machines and considered a better life for the human with them. © 2019, Springer Nature Switzerland AG.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","494-506","","","11572 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030235598 Publisher: Springer Verlag","<p>cited By 0; Conference of 13th International Conference on Universal Access in Human-Computer Interaction, UAHCI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228809</p>","","","Surveys; Virtual reality; Empathy; Humanoid robot; Students; Anthropomorphic robots; Human computer interaction; Elementary schools; Intelligent robots; Humanoid robot NAO; Intelligent machine; Phatic dialog; Query processing; Questionnaire surveys; SIMPLE method","","Antona M., Stephanidis C.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5T8D4UEI","journalArticle","2019","Parviainen, J.; van Aerschot, L.; Särkikoski, T.; Pekkarinen, S.; Melkas, H.; Hennala, L.","Motions with emotions? A phenomenological approach to understanding the simulated aliveness of a robot body","Techne: Research in Philosophy and Technology","","10918264","10.5840/techne20191126106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081323649&doi=10.5840%2ftechne20191126106&partnerID=40&md5=378eb5e3022a3bfccf7c5f223679272b","This article examines how the interactive capabilities of companion robots, particularly their materiality and animate movements, appeal to human users and generate an image of aliveness. Building on Husserl's phenomenological notion of a 'double body' and theories of emotions as affective responses, we develop a new understanding of the robots' simulated aliveness. Analyzing empirical findings of a field study on the use of the robot Zora in care homes for older people, we suggest that the aliveness of companion robots is the result of a combination of four aspects: 1) material ingredients, 2) morphology, 3) animate movements guided by software programs and human operators as in Wizard of Oz-settings and 4) anthropomorphising narratives created by their users to support the robot's performance. We suggest that narratives on affective states, such as, sleepiness or becoming frightened attached to the robot trigger users' empathic feelings, caring and tenderness toward the robot. © 2019 Philosophy Documentation Center. All rights reserved.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","318-341","","3","23","","","","","","","","","","English","","","","","","","Publisher: Philosophy Documentation Center","<p>cited By 10</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6PVEZYK","journalArticle","2019","Bechade, L.; Dubuisson-Duplessis, G.; Pittaro, G.; Garcia, M.; Devillers, L.","Towards metrics of evaluation of pepper robot as a social companion for the elderly","Lecture Notes in Electrical Engineering","","18761100","10.1007/978-3-319-92108-2_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051821641&doi=10.1007%2f978-3-319-92108-2_11&partnerID=40&md5=8e0a7038b7789a80354b8b452f4e83cb","For the design of socially acceptable robots, field studies in Human-Robot Interaction are necessary. Constructing dialogue benchmarks can have a meaning only if researchers take into account the evaluation of robot, human, and their interaction. This paper describes a study aiming at finding an objective evaluation procedure of the dialogue with a social robot. The goal is to build an empathic robot (JOKER project) and it focuses on elderly people, the end-users expected by ROMEO2 project. The authors carried out three experimental sessions. The first time, the robot was NAO, and it was with a Wizard of Oz (emotions were entered manually by experimenters as inputs to the program). The other times, the robot was Pepper, and it was totally autonomous (automatic detection of emotions and decision according to). Each interaction involved various scenarios dealing with emotion recognition, humor, negotiation and cultural quiz. The paper details the system functioning, the scenarios and the evaluation of the experiments. © 2019, Springer International Publishing AG, part of Springer Nature.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","89-101","","","510","","","","","","","","","","English","","","","","","","ISBN: 9783319921075 Publisher: Springer Verlag","<p>cited By 7; Conference of 8th International Workshop on Spoken Dialogue Systems, IWSDS 2017 ; Conference Date: 6 June 2017 Through 9 June 2017; Conference Code:216749</p>","","","Emotion recognition; Human robot interaction; Evaluation; Man machine systems; Machine design; Human computer interaction; Elderly people; Speech processing; Data collection; Automatic detection of emotion; End users; Metrics; Objective evaluation","","Devillers L., Mariani J., Eskenazi M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"646LJCH9","journalArticle","2019","Pham, H.V.; Lam, T.N.","A new method using knowledge reasoning techniques for improving robot performance in coverage path planning","International Journal of Computer Applications in Technology","","09528091","10.1504/IJCAT.2019.099503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065560164&doi=10.1504%2fIJCAT.2019.099503&partnerID=40&md5=e7982a99368838b44c4dc1ece5b58627","Robots are a rapidly evolving development field encompassing variable domains ranging from industrial robots to empathetic robots for human companions. Future robots will be highly dependent on the ability to understand, interpret, and generate a representation of the environment in which they are operating, ideally in both a human and machine-readable formalism. An important element in this process lies in Path Planning (PP) with obstacle avoidance in dynamic environments (including cleaning and monitoring in robotics) to identify optimal coverage paths. The study in this paper presents a new approach which combines knowledge reasoning techniques with Breadth First Search to find the optimal path for a cleaning robot in a dynamic environment. This approach is used to apply knowledge inference with conventional coverage PP algorithms to enable robot control and avoid obstacles with optimal coverage PP. The experimental results show that using the proposed approach a robot avoids fixed and mobile obstacles, optimal PP reducing both computational cost and time. When compared to other current approaches, the proposed approach with high-coverage rate and low-repetition rate in coverage performs better than the conventional robot algorithms. © 2019 Inderscience Enterprises Ltd.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","57-64","","1","60","","","","","","","","","","English","","","","","","","Publisher: Inderscience Publishers","<p>cited By 7</p>","","","Collision avoidance; Robot programming; Automated reasoning; Breadth-first search; Conventional robots; Coverage path planning; Dynamic environments; Industrial robots; Inference engines; Knowledge reasoning; Low repetition rate; Robot path","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NX477N66","journalArticle","2019","Bhalla, N.","The 3S process: A framework for teaching AI strategy in business education","Technology Innovation Management Review","","19270321","10.22215/timreview/1290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082424709&doi=10.22215%2ftimreview%2f1290&partnerID=40&md5=71f1e049ab206f1122d9f31a5dba4ee8","A gap has emerged in teaching artificial intelligence (AI) in business education, where a style of curriculum based on strategy is missing. This article presents a new framework, the 3S Process, as a method for teaching leaders how to strategically adopt AI within their organizations. At a high-level, the 3S Process consists of three stages (Story, Strategy, and Solution), which are described in detail in the article. Stage 1: Story in the process is inspired by the Harvard Case Method to provide context for a problem. Stage 2: Strategy uses Design Thinking to produce candidate solutions. The substage of Empathy in Design Thinking plays a crucial role to reduce bias in designing AI. Virtualization technology is a tool for students to experience hands-on learning in prototype development. Stage 3: Solution is where students advocate for their conceptual AI solution in the context of the case study. AI is a type of complex system; therefore, students should consider feedback loops and the potential for unintended biases to enter a deployed solution. The presentation of the 3S Process in this article is conceptual. Further empirical studies, including evaluations of the 3S Process in classroom settings, will be considered in the future. © 2019 Carleton University. All Rights Reserved.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","36-42","","12","9","","","","","","","","","","English","","","","","","","Publisher: Carleton University","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXP6KBFE","journalArticle","2019","Reddrop, A.; Mapunda, G.","Listening skills: Accountancy educators in retreat?","Australasian Accounting, Business and Finance Journal","","18342000","10.14453/aabfj.v13i1.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070264597&doi=10.14453%2faabfj.v13i1.4&partnerID=40&md5=26666b8b11e81c1416534d278adc5809","Purpose: to gain insight into the training received by accountancy graduates in soft skills with a major focus on listening skills; and, both, in light of findings, and impelled by the pleas of accountants’ clients, to urge educators to introduce them in curricula. Approach: content analysis of Australian accountancy schools’ courses placed on the web followed by direct contact with schools whose Web descriptions might plausibly have indicated listening skills’ inclusion; Findings: while the Institute of Chartered Accountants in Australia and CPA Australia required in their Professional Accounting Guidelines, 2009' that as a condition of their accreditation higher education programs address ‘generic skills’ including the interpersonal, ‘particularly the ability to listen effectively’, this was scarcely complied with by accredited schools. Subsequent to the 2009 ICAA/CPA directive successive pronouncements of the Institutions reduced or effectively eliminated the requirement to teach listening skills. Practical implications: accountancy graduates will enter the profession without groundwork in a skill which successful exponents will increasingly be required to exercise. This will need to be remedied. Originality value: empathetic listening skills are seen to be indispensable by reference to the demands of a party not considered in previous studies, namely practising accountants’ clients. Nor have previous studies adequately recognised the critical importance of these skills as artificial intelligence (AI) erodes accountants’ standing as dispensers of technical knowledge. © 2019 Australasian Accounting Business and Finance Journal and Authors.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","76-89","","1","13","","","","","","","","","","English","","","","","","","Publisher: University of Wollongong","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZW9727I","conferencePaper","2019","Self, B.P.; Widmann, J.","Access for all: Promoting universal design thinking in a rehabilitation engineering course","Proceedings of the 8th Research in Engineering Education Symposium, REES 2019 - Making Connections","978-0-7992-2600-3","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071475285&partnerID=40&md5=6a52fd874b773b65de7b8084345f0ba4","Service learning is a high impact practice that can greatly increase motivation and promote deep learning. We have developed a project-based Rehabilitation Engineering course that included both Biomedical Engineering and Mechanical Engineering students. Projects were supplied by local non-profit community partners (for example Special Olympics), and focused on developing products for people with mobility impairments. In addition to the projects, student assignments included reflection prompts, four hours of community service (two of which had to involve direct contact with people of different abilities), and a sensory deprivation experience to develop empathy. Qualitative evaluation of student responses showed that students were able to develop some aspects of design empathy and understood the importance of accessibility and universal design. Copyright © 2019 Brian Self and Jim Widmann.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","369-377","","","","","","","","","","","Research in Engineering Education Network","","English","","","","","","","","<p>cited By 1; Conference of 8th Research in Engineering Education Symposium: Making Connections, REES 2019 ; Conference Date: 10 July 2019 Through 12 July 2019; Conference Code:150283</p>","","","Deep learning; Design; Service learning; Students; Community services; Curricula; Developing product; Engineering education; Engineering research; Human rehabilitation engineering; Mechanical engineering students; Non-profit community; Qualitative evaluations; Rehabilitation engineering; Student assignments; Technical presentations","","B, Kloot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNCNU8QW","journalArticle","2019","Franzoni, V.; Milani, A.","Emotion Recognition for Self-aid in Addiction Treatment, Psychotherapy, and Nonviolent Communication","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-24296-1_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069166203&doi=10.1007%2f978-3-030-24296-1_32&partnerID=40&md5=9fd3cca43de6e1c5747776bab3c03cf0","This position paper aims to highlight possible future directions of applications for Affective Computing (AC) and Emotion Recognition (ER) for self-aid applications, as they emerge from the experience of the ACER-EMORE Workshops Series. ER in Artificial Intelligence offers a growing number of problem-solving multidisciplinary opportunities. Most current AC and ER applications are focused on a somewhat controversial enterprise-centered approach, i.e., recognizing user emotions to enable a third-party to achieve its own goals, in areas such as e-commerce, cybersecurity, behavior profiling, user experience. In this work we propose to explore a human-centered research direction, aiming at using AC/ER to enhance user consciousness of emotional states, ultimately supporting the development of self-aid applications. The use of facial ER and text ER to help forms of assistive technologies in the fields of Psychotherapy and Communication is an example of such a human-centered approach. A general framework for ER in Self-aid is depicted, and some relevant application domains are suggested and discussed: dependencies treatment (DT) (e.g., workaholism, sexaholism); non-violent communication (NVC) for people in leading roles using e-mail or chat communication; empathy learning for parents and teachers in the circle-of-security (COS) caring environment. Far from being complete and comprehensive, the purpose of this work is to trigger discussions and ideas for feasible studies and applications of ER in self-aid, which we hope to see published in the future editions of our workshops, believing that it may be one of the drops needed in the ocean of a better world. © 2019, Springer Nature Switzerland AG.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","391-404","","","11620 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030242954 Publisher: Springer Verlag","<p>cited By 4; Conference of 19th International Conference on Computational Science and Its Applications, ICCSA 2019 ; Conference Date: 1 July 2019 Through 4 July 2019; Conference Code:227949</p>","","","Affective Computing; Assistive technology; Emotion recognition; Speech recognition; User experience; Behavioral research; Circle of security; Cobalt; Possible futures; Problem solving; Sexaholics; Workaholics","","Misra S., Apduhan B.O., Gervasi O., Murgante B., Stankova E., Korkhov V., Torre C., Tarantino E., Rocha A.M.A.C., Taniar D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R594A9MJ","conferencePaper","2019","Gemeinboeck, P.; Saunders, R.","Exploring social co-presence through movement in human-robot encounters","2019 AISB Convention","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075273167&partnerID=40&md5=25ec4efb84ecdc0459bba9ce60def3df","This paper explores the social capacity of robots as an emergent phenomenon of the exchange between humans and robots, rather than an intrinsic property of robots as is often assumed in social robotics research. Using our Performative Body Mapping (PBM) approach, we have developed a robotic object for studying how social meaning is enacted when movement qualities meet kinesthetic empathy. In this paper we introduce PBM and how it harnesses performers' kinesthetic imagination and movement expertise for designing the movement potential and movement qualities of abstract, non-humanlike robots. We then present our recent study of how the social presence of our robotic object-in-motion emerges in an encounter, involving experts from performance and design. Preliminary results of this study show that our robotic object can successfully convey movement qualities and their intended expressions as embodied by a dancer as part of the PBM process. Finally, we discuss how our observations can shift our focus from attributing qualities to the object to an emergence of qualities, propelled by the encounter. We believe our study provides a glimpse into the dynamic enactment of agency and how it requires both sides to 'give' for the robotic object's characteristics and the participants' experience to evolve. © 2019 AISB Convention.All right reserved.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","31-37","","","","","","","","","","","The Society for the Study of Artificial Intelligence and Simulation of Behaviour","","English","","","","","","","","<p>cited By 1; Conference of 2019 Convention of the Society for the Study of Artificial Intelligence and the Simulation of Behaviour, AISB 2019 ; Conference Date: 16 April 2019 Through 18 April 2019; Conference Code:152955</p>","","","Robotics; Robots; Social robotics; Social presence; Human robots; Co-presence; Body mappings; Emergent phenomenon; Humanlike robots; Intrinsic property","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HW7SQTTZ","journalArticle","2019","Griffiths, D.B.","When David met Michel","Religious Studies and Theology","","08292922","10.1558/RSTH.38299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071428686&doi=10.1558%2fRSTH.38299&partnerID=40&md5=8aff8e71418d01a4196fb32b0f3976e8","I entered the Department of Religious Studies in Vancouver in the Fall of 1974. Michel was a year or two advanced and the first person to befriend me and ""show me the robes."" He is a unique individual with generosity of Geist or empathy, and deep analytical skills, wide interests, lucid thinking. His books and many students are evidence of this. It has been a deep joy to be his friend through the years. He has always helped me with intellectual projects and been attentive to personal issues, and all this without a touch of pedantry or arrogance. In addition to his deep learning in Religious Studies and related topics, he has a gift for empathic listening, and a singular capacity to think on his feet and lecture with amazing lucidity. © Equinox Publishing Ltd. 2019.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","223-225","","1-2","38","","","","","","","","","","English","","","","","","","Publisher: Equinox Publishing Ltd","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RYQNFBP","journalArticle","2019","Pilato, G.; Yarushev, S.A.; Averkin, A.N.","Prediction and detection of user emotions based on neuro-fuzzy neural networks in social networks","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-01821-4_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058506914&doi=10.1007%2f978-3-030-01821-4_13&partnerID=40&md5=fc3ca19fd17bb83a08f821062dc40e82","In this paper we propose a neuro-fuzzy method for emotions prediction. On one hand we suggest a taxonomy-based detection of user joyful interests through the use of semantic spaces and, on the other hand, we propose a neuro-fuzzy method for prediction of emotions used in Twitter posts. Catching the attention of a new acquaintance and empathize with her can improve the social skills of a robot. For this reason, we illustrate here the first step towards a system which can be used by a social robot in order to “break the ice” with a new acquaintance. © Springer Nature Switzerland AG. 2019.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","118-125","","","875","","","","","","","","","","English","","","","","","","ISBN: 9783030018207 Publisher: Springer Verlag","<p>cited By 2; Conference of 3rd International Scientific Conference on Intelligent Information Technologies for Industry, IITI 2018 ; Conference Date: 17 September 2018 Through 21 September 2018; Conference Code:221799</p>","","","Semantics; Social robots; Forecasting; Social skills; Semantic Space; User emotions; Fuzzy logic; Fuzzy inference; Fuzzy neural networks; Neuro-Fuzzy; Neuro-fuzzy methods; Twitter posts","","Tarassov V., Snasel V., Kovalev S., Sukhanov A., Abraham A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2XV38T9","journalArticle","2019","Zhang, Y.; Qi, S.","User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-22335-9_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825","With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","350-366","","","11588 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030223342 Publisher: Springer Verlag","<p>cited By 2; Conference of 6th International Conference on HCI in Business, Government, and Organizations, HCIBGO 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228649</p>","","","Robotics; Surveys; Decision making; Robots; User experience; Hospitality; Service quality management; Human computer interaction; User interfaces; Consumer behavior; Decision making process; Hotels; Quality of service; Quantitative research; Regression analysis; Research objectives; Service expectations; User classification; Wages","","Nah F.F.-H., Siau K.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRG2EYEY","conferencePaper","2019","Cosmo, A.M.; Nedelcea, C.; Podina, I.R.","A computerized, gamified intervention training visual perspective-taking. Theoretical rationale and proposal of a randomized controlled trial","eLearning and Software for Education Conference","","","10.12753/2066-026X-19-011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085163945&doi=10.12753%2f2066-026X-19-011&partnerID=40&md5=37c8f370aeb6060bce464df25cab3dd9","Perspective-taking is a core theory of mind process, entailing the ability to understand and predict others’ mental states. While the literature suggests that priming a perspective-taking stance increases empathic concern and intergroup cohesion and reduces implicit negative attitudes such as racial bias and prejudice, no study up to date has attempted to foster perspective-taking implicitly, by training visual perspective-taking in a computerized task. In the current paper, we propose a computerized, gamified intervention for visual perspective-taking in adolescents and young adults. The intervention is an adapted version of extant visual perspective-taking assessment protocols and is envisioned to train participants to selectively attend to the visual perspective of an animated avatar, instead of their own. By training an allocentric bias, the intervention aims to increase empathic and theory of mind abilities and to foster interpersonal communication and cohesion. An additionally hypothesized benefit of the intervention is a decrease in self-focused attention, a marker of social anxiety disorder. As such, the intervention is suited to address two different, but inter-related needs: optimizing social functioning and managing social anxiety symptomatology. Introducing users to gamification elements, such as earning badges, advancing through increasing difficulty levels, receiving feedback and leaderboards highlighting achievements, is intended to increase the intervention’s efficacy and to promote adherence. Design considerations for testing the intervention in an experimental trial will additionally be proposed, with the intervention contrasted against a sham control condition that will equally train egocentric and allocentric biases in visual perspective-taking. Theoretical and practical implications for educational settings will be discussed. © 2019, National Defence University - Carol I Printing House. All rights reserved.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","91-97","","","","","","","","","","","National Defence University - Carol I Printing House","","English","","","","","","","ISSN: 2066026X","<p>cited By 0; Conference of 15th International Scientific Conference on eLearning and Software for Education, eLSE 2019 ; Conference Date: 11 April 2019 Through 12 April 2019; Conference Code:239599</p>","","","","","I, Roceanu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VLJCLM4","conferencePaper","2019","Arriaga, O.; Valdenegro-Toro, M.; Plöger, P.G.","Real-time convolutional neural networks for emotion and gender classification","ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning","978-2-87587-065-0","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2","Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.","2019","2021-05-19 13:26:26","2021-05-19 13:26:26","","221-226","","","","","","","","","","","ESANN (i6doc.com)","","English","","","","","","","","<p>cited By 6; Conference of 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2019 ; Conference Date: 24 April 2019 Through 26 April 2019; Conference Code:149793</p>","","","Neural networks; Machine learning; Convolutional neural network; Convolution; Real time; Computation time; Facial feature; Gender classification; Gender recognition; Open source license; Open systems; Real time evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9SLPHH8","journalArticle","2019","Matsuyama, Y.; Asahi, Y.","High Sensitivity Layer Feature Analysis in Food Market","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-22649-7_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335","It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.","2019","2021-05-19 13:26:27","2021-05-19 13:26:27","","232-243","","","11570 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030226480 Publisher: Springer Verlag","<p>cited By 1; Conference of Thematic Area on Human Interface and the Management of Information, HIMI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228569</p>","","","Deep learning; Intelligent systems; Testing; Decision tree analysis; Innovation theory; Test marketing; Human computer interaction; Commerce; Conducting tests; Decision theory; Decision trees; Feature analysis; Generalized models; High sensitivity; Image analysis; Market researches; Sales; Text processing","","Yamamoto S., Mori H.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQN3B54D","conferencePaper","2019","Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.","Digital empathy secures Frankenstein’s monster","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210","People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.","2019","2021-05-19 13:26:27","2021-05-19 13:26:27","","335-349","","","2348","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 4; Conference of 5th Collaborative European Research Conference, CERC 2019 ; Conference Date: 29 March 2019 Through 30 March 2019; Conference Code:147497</p>","","","Speech recognition; Diagnosis; Computation theory; Computer games; Computational model; Image recognition; Asian games; Expert systems; General practitioners; Large datasets; Medical imaging; Robotic surgery; Surgery; Surgical operation","","Walsh P., Low R., Burkhardt D., Bleimann U., Regier S., Stengel I., Humm B.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSTGBRVA","journalArticle","2019","Provoost, S.; Ruwaard, J.; van Breda, W.; Riper, H.; Bosse, T.","Validating automated sentiment analysis of online cognitive behavioral therapy patient texts: An exploratory study","Frontiers in Psychology","","16641078","10.3389/fpsyg.2019.01065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068465654&doi=10.3389%2ffpsyg.2019.01065&partnerID=40&md5=2abceb720e1d533fe4b7beab9f01bf0d","Introduction: Sentiment analysis may be a useful technique to derive a user's emotional state from free text input, allowing for more empathic automated feedback in online cognitive behavioral therapy (iCBT) interventions for psychological disorders such as depression. As guided iCBT is considered more effective than unguided iCBT, such automated feedback may help close the gap between the two. The accuracy of automated sentiment analysis is domain dependent, and it is unclear how well the technology is applicable to iCBT. This paper presents an empirical study in which automated sentiment analysis by an algorithm for the Dutch language is validated against human judgment. Methods: A total of 493 iCBT user texts were evaluated on overall sentiment and the presence of five specific emotions by an algorithm, and by 52 psychology students who evaluated 75 randomly selected texts each, providing about eight human evaluations per text. Inter-rater agreement (IRR) between algorithm and humans, and humans among each other, was analyzed by calculating the intra-class correlation under a numerical interpretation of the data, and Cohen's kappa, and Krippendorff's alpha under a categorical interpretation. Results: All analyses indicated moderate agreement between the algorithm and average human judgment with respect to evaluating overall sentiment, and low agreement for the specific emotions. Somewhat surprisingly, the same was the case for the IRR among human judges, which means that the algorithm performed about as well as a randomly selected human judge. Thus, considering average human judgment as a benchmark for the applicability of automated sentiment analysis, the technique can be considered for practical application. Discussion/Conclusion: The low human-human agreement on the presence of emotions may be due to the nature of the texts, it may simply be difficult for humans to agree on the presence of the selected emotions, or perhaps trained therapists would have reached more consensus. Future research may focus on validating the algorithm against a more solid benchmark, on applying the algorithm in an application in which empathic feedback is provided, for example, by an embodied conversational agent, or on improving the algorithm for the iCBT domain with a bottom-up machine learning approach. © 2019 Provoost, Ruwaard, van Breda, Riper and Bosse.","2019","2021-05-19 13:26:27","2021-05-19 13:26:27","","","","MAY","10","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KPYCN7P","conferencePaper","2018","Viet Tuyen, N.T.; Jeong, S.; Chong, N.Y.","Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","IEEE International Conference on Intelligent Robots and Systems","978-1-5386-8094-0","","10.1109/IROS.2018.8593974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062987621&doi=10.1109%2fIROS.2018.8593974&partnerID=40&md5=755c3fc2f1c863f79b55e63646138d4d","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator. © 2018 IEEE.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","2008-2013","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 21530858","<p>cited By 8; Conference of 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018 ; Conference Date: 1 October 2018 Through 5 October 2018; Conference Code:144267</p>","","","Social robots; Human robot interaction; Long-term interaction; Intelligent robots; Cultural backgrounds; Cultural traits; Emotional behavior; Incremental learning; Motion space; Transformation model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRD3MMI2","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.","Band of Brothers and Bolts: Caring about Your Robot Teammate","IEEE International Conference on Intelligent Robots and Systems","978-1-5386-8094-0","","10.1109/IROS.2018.8594324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062974656&doi=10.1109%2fIROS.2018.8594324&partnerID=40&md5=3d70c11d1788c11aba3e15e67bb7dd7b","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected. © 2018 IEEE.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","1853-1858","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 21530858","<p>cited By 2; Conference of 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018 ; Conference Date: 1 October 2018 Through 5 October 2018; Conference Code:144267</p>","","","Intelligent robots; Behavior modifications; Behavioral patterns; Experimental trials; Robot companion; Time-to-capture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5FG34XV6","journalArticle","2018","Swiderska, A.; Küster, D.","Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots","Perception","","03010066","10.1177/0301006618809919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058656094&doi=10.1177%2f0301006618809919&partnerID=40&md5=2d29a1feddf28df7efb1c2f080d656ba","Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain. © The Author(s) 2018.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","1139-1152","","12","47","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 6</p>","","","Female; Humans; Male; Young Adult; Robotics; Theory of Mind; pain; Empathy; empathy; behavior; morality; theory of mind; robotics; psychology; Pain; human; female; male; young adult; human relation; Interpersonal Relations; procedures; Psychological; facial recognition; Facial Recognition; injury; Intention; Morale; perceptive discrimination; Photic Stimulation; photostimulation; Signal Detection; Wounds and Injuries","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A67EPSHA","journalArticle","2018","Obaid, M.; Aylett, R.; Barendregt, W.; Basedow, C.; Corrigan, L.J.; Hall, L.; Jones, A.; Kappas, A.; Küster, D.; Paiva, A.; Papadopoulos, F.; Serholt, S.; Castellano, G.","Endowing a robotic tutor with empathic qualities: Design and pilot evaluation","International Journal of Humanoid Robotics","","02198436","10.1142/S0219843618500251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058160758&doi=10.1142%2fS0219843618500251&partnerID=40&md5=60f7dbb32b8b7344ac5c0d8be964a7cb","As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions. © 2018 World Scientific Publishing Company.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","","","6","15","","","","","","","","","","English","","","","","","","Publisher: World Scientific Publishing Co. Pte Ltd","<p>cited By 8</p>","","","Robotics; Education; children; empathy; Robots; tutor; Educational robots; Educational context; Learning effects; Learning scenarios; Maps; Multi-touch tables; Quality control; Technical architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I75C3JXD","journalArticle","2018","Hamilton-Giachritsis, C.; Banakou, D.; Garcia Quiroga, M.; Giachritsis, C.; Slater, M.","Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment","Scientific Reports","","20452322","10.1038/s41598-018-21036-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042078955&doi=10.1038%2fs41598-018-21036-2&partnerID=40&md5=fb96ebbd43cee03a0b332b62bfa1347d","The ability to perspective-take (cognitive awareness of another's state) and empathise (emotional/affective response) are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 20 non-high risk Spanish mothers (a pilot study with 12 mothers is reported in supplementary files). Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and with virtual and real body movements synchronised. They interacted with a 'mother avatar', which responded either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological data indicated greater stress in the Negative than Positive condition. Although further research is required to assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior has the potential to impact on developmental outcomes for children. © 2018 The Author(s).","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","","","1","8","","","","","","","","","","English","","","","","","","Publisher: Nature Publishing Group","<p>cited By 12</p>","","","Perception; Female; Humans; Male; perception; Emotions; emotion; Cognition; cognition; Empathy; empathy; virtual reality; psychology; Virtual Reality; Child; human; female; male; Preschool; preschool child; child parent relation; defense mechanism; mother; Mothers; Negativism; Parenting; risk; Risk; Spain; virtual reality exposure therapy; Virtual Reality Exposure Therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J7YCZUN2","conferencePaper","2018","Kumar, H.V.; Nagaraj, J.; Irfan, M.; Maheshwari, N.; Balusani, P.; Chatterjee, P.; Srinivasa, G.","PESUBot: An Empathetic Goal Oriented Chatbot","2018 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2018","978-1-5386-5314-2","","10.1109/ICACCI.2018.8554916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060036309&doi=10.1109%2fICACCI.2018.8554916&partnerID=40&md5=3c5d8f2229e834c98ba4e3bec7db5533","'PESUBot', a robot-receptionist, is a chatbot that is designed to be deployed in university premises to answer questions related to the university and also maintains a general conversation with its user. The chatbot was built specifically for PES University, Bangalore. The dataset used for building this chatbot was PES University specific data which was scraped from the university's website, personality data of the chatbot which was custom formulated and the general conversation dataset was curated from reddit data. The chatbot is composed of 2 prominent models, one of which is a retrieval-based model that can answer questions about the university and about the chatbot itself while the other is a generative model that answers any other general question that is passed on to it by the first model. Both these models are built using Recurrent Neural Networks. The first model had an average per response accuracy of 92% while the second model had an average BLEU score of 0.53. © 2018 IEEE.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","1083-1089","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 7th International Conference on Advances in Computing, Communications and Informatics, ICACCI 2018 ; Conference Date: 19 September 2018 Through 22 September 2018; Conference Code:143262</p>","","","Deep learning; Chatbot; Natural language processing systems; Goal-oriented; Recurrent neural networks; Bangalore; Bleu scores; Generative model; Natural language understanding; Question Answering; Text generations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BF7VTB26","conferencePaper","2018","James, J.; Watson, C.I.; MacDonald, B.","Artificial Empathy in Social Robots: An analysis of Emotions in Speech","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","978-1-5386-7980-7","","10.1109/ROMAN.2018.8525652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055010165&doi=10.1109%2fROMAN.2018.8525652&partnerID=40&md5=dc6f59a151e5db0e00c350424b2adb5f","Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots. © 2018 IEEE.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","632-637","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 7; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>","","","Robotics; Social robots; Human robot interaction; Emotional state; Human robot Interaction (HRI); Behavioral research; Human users; Speech synthesis; Human perception; Human subjects; Language content; Speech synthesizer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPSPPE6W","conferencePaper","2018","Mollahosseini, A.; Abdollahi, H.; Mahoor, M.H.","Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","978-1-5386-7980-7","","10.1109/ROMAN.2018.8525777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058084838&doi=10.1109%2fROMAN.2018.8525777&partnerID=40&md5=0bd7cd6c5c720a217ec19787cc5218c6","Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer. © 2018 IEEE.","2018","2021-05-19 13:26:27","2021-05-19 13:26:27","","783-789","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 3; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>","","","Social robots; Human robot interaction; Facial Expressions; Human robot Interaction (HRI); Human computer interaction; Deep neural networks; Economic and social effects; Facial expression recognition; Social agents; Human subjects; Automation; Human observers; Spoken dialogs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9E2YZ78","conferencePaper","2018","Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.","Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","978-1-5386-7980-7","","10.1109/ROMAN.2018.8525515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058099794&doi=10.1109%2fROMAN.2018.8525515&partnerID=40&md5=64fa73971c77b5ebeb7809d94607f32a","Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found. © 2018 IEEE.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","275-281","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 3; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>","","","Human robot interaction; User experience; Human robot Interaction (HRI); Human robots; Behavioral research; Social behavior; Robotic interaction; Bonding phase; Facial action; Training purpose","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NJTM4KV","conferencePaper","2018","Hieida, C.; Horii, T.; Nagai, T.","Emotion Differentiation based on Decision-Making in Emotion Model","RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication","978-1-5386-7980-7","","10.1109/ROMAN.2018.8525579","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058082859&doi=10.1109%2fROMAN.2018.8525579&partnerID=40&md5=a8b97edffc128454fce9f7f211968e30","Having emotions is essential for robots in order for them to understand and sympathize with people's feelings. In addition, it may allow robots to be accepted in human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions is proposed based on various neurological and psychological findings related to empathic communication between humans and robots. Subsequently, a decision-making mechanism based on affects using convolutional long short-term memory and deep deterministic policy gradient is examined. We set a 'facial expression' task simulating mother-child interactions and verified emotion differentiation during the task. © 2018 IEEE.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","659-665","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>","","","Decision making; Robots; Human society; Facial Expressions; Behavioral research; Emotion modeling; Decision-making mechanisms; Policy gradient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9FIRE9DA","journalArticle","2018","Inkster, B.; Sarda, S.; Subramanian, V.","An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study","JMIR mHealth and uHealth","","22915222","10.2196/12106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f","Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","","","11","6","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 68</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CVTDAEN","journalArticle","2018","Weber, A.S.","Emerging medical ethical issues in healthcare and medical robotics","International Journal of Mechanical Engineering and Robotics Research","","22780149","10.18178/ijmerr.7.6.604-607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056576175&doi=10.18178%2fijmerr.7.6.604-607&partnerID=40&md5=497839d4cdb779d178e34f97ca54283a","Due to the increasing sophistication and complexity of autonomous machines, Artificial Intelligence, Computerized Decision Support Systems (CDSS), natural language question-answering robots, and social / emotive medical robots, new medical ethics conundrums are arising. Unresolved questions revolve around autonomy, responsibility, empathy, trust, moral agency and the social and economic impacts of medical robots. © 2018 Int. J. Mech. Eng. Rob. Res.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","604-607","","6","7","","","","","","","","","","English","","","","","","","Publisher: International Journal of Mechanical Engineering and Robotics Research","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IXUW3XA2","journalArticle","2018","Shukla, S.; Sharma, P.","Emotions and Media Multitasking Behaviour among Indian College Students","Journal of Creative Communications","","09732586","10.1177/0973258618790794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053427916&doi=10.1177%2f0973258618790794&partnerID=40&md5=aa44bb6595f8efc8632f378247c70b8e","Media multitasking, a simultaneous consumption of two or more media, is a ubiquitous and popular behaviour among the youth. One of the reasons for its increasing growth is the structural/market-level factors (known as media factors). Although India is a growing technology hub, there have been limited efforts to identify the media multitasking behaviour among the youth in this country. Thus, this study attempts to analyse the prevalence of media multitasking behaviour among the Indian college students and its relationship with their emotions through two methods: self-report and an android-based application known as ‘Affective Media Landscape Survey’ (AMLS). Previous studies have reported that continuous interaction with media diminishes face-to-face interaction, reduces empathy and increases the tendency to live in the virtual world. This raises the concern for emotional differences in everyday life, if any, between the high and low groups of media multitaskers. So the second objective of the study is to understand the emotional profile of the users that varies among media multitasking index. To achieve these objectives, the same two methods, the ‘self-report’ that involves questionnaires and AMLS (an android-based app to study the frequency of media multitasking behaviour and the emotions of the users) have been employed. The study gives an insight into the emerging behavioural patterns and hence is helpful for designing communities to cater to the growing needs of the young media users. © 2018 Mudra Institute of Communications, Ahmedabad, India.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","197-211","","3","13","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IXEIT2WC","journalArticle","2018","Giannopulu, I.; Terada, K.; Watanabe, T.","Emotional empathy as a mechanism of synchronisation in child-robot interaction","Frontiers in Psychology","","16641078","10.3389/fpsyg.2018.01852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055052507&doi=10.3389%2ffpsyg.2018.01852&partnerID=40&md5=4e3455fc4099810d57dbf0e2e66d93bf","Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation. © 2018 Giannopulu, Terada and Watanabe.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","","","OCT","9","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZU8S545K","conferencePaper","2018","Roberts, J.","Using affective computing for proxemic interactions in mixed-reality","SUI 2018 - Proceedings of the Symposium on Spatial User Interaction","978-1-4503-5708-1","","10.1145/3267782.3274692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058491355&doi=10.1145%2f3267782.3274692&partnerID=40&md5=bd488c50ec71dcf4617ad164038a42df","Immersive technologies have been touted as empathetic mediums. This capability has yet to be fully explored through machine learning integration. Our demo seeks to explore proxemics in mixed-reality (MR) human-human interactions. The author developed a system, where spatial features can be manipulated in real time by identifying emotions corresponding to unique combinations of facial micro-expressions and tonal analysis. The Magic Leap One is used as the interactive interface, the first commercial spatial computing head mounted (virtual retinal) display (HUD). A novel spatial user interface visualization element is prototyped that leverages the affordances of mixed-reality by introducing both a spatial and affective component to interfaces. © 2018 Copyright is held by the owner/author(s).","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","176","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 1; Conference of 6th ACM Symposium on Spatial User Interaction, SUI 2018 ; Conference Date: 13 October 2018 Through 14 October 2018; Conference Code:142407</p>","","","Affective Computing; Mixed reality; Augmented reality; Proxemics; Human-human interactions; Learning systems; Human computer interaction; User interfaces; Affective components; Immersive technologies; Interactive interfaces; Spatial computing; Spatial user interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IYLII9VJ","conferencePaper","2018","Ota, K.; Furuhashi, T.; Jimenez, F.; Yoshikawa, T.","Sympathy-expression method for educational-support robots based on writing times","IEEE International Conference on Fuzzy Systems","978-1-5090-6020-7","","10.1109/FUZZ-IEEE.2018.8491635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060439771&doi=10.1109%2fFUZZ-IEEE.2018.8491635&partnerID=40&md5=bb05013fbccee792d961a98ce5644476","In recent years, educational-support robots that can assist human learners have been attracting the attention of researchers. However, learners feel that these robots have monotonous behaviors, making collaborative learning with the robot a boring experience. To solve this problem, a previous study proposed using the sympathy-expression method in which the robot expresses its own emotions autonomously on the basis of the answer time. However, we propose the notion that the writing time should also be considered. The writing time is defined as the time taken by the learners to answer the questions. When learners wrote a lot, the answer time became long and the robot (in the previous method) used to express emotions of sleep. To empathize with the learners, it is important for the robot to express emotions of arousal. Therefore, in this paper, we propose the sympathy-expression method, which expresses emotions based on the writing time. © 2018 IEEE.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","","","","2018-July","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 10987584","<p>cited By 0; Conference of 2018 IEEE International Conference on Fuzzy Systems, FUZZ 2018 ; Conference Date: 8 July 2018 Through 13 July 2018; Conference Code:141062</p>","","","Robots; Learning systems; Educational robots; Collaborative learning; SD method; Background subtraction; Express emotions; Fuzzy systems; Sympathy expression method","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BW6YPXEB","conferencePaper","2018","Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.","Learning Empathy-Driven Emotion Expressions using Affective Modulations","Proceedings of the International Joint Conference on Neural Networks","978-1-5090-6014-6","","10.1109/IJCNN.2018.8489158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056556433&doi=10.1109%2fIJCNN.2018.8489158&partnerID=40&md5=14dfc5df0848f6da4a7837cf8b02c2d7","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users. © 2018 IEEE.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","","","","2018-July","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 8; Conference of 2018 International Joint Conference on Neural Networks, IJCNN 2018 ; Conference Date: 8 July 2018 Through 13 July 2018; Conference Code:141067</p>","","","Reinforcement learning; Interaction design; Human robot interaction; Machine design; Human robot Interaction (HRI); Reinforcement learning models; Behaviour modelling; Hybrid neural modeling; Motivation for learning; Natural interactions; Physical capabilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53IMFKHX","conferencePaper","2018","Brueckner, S.","Empathy amulet: A wearable to connect with strangers","Proceedings - International Symposium on Wearable Computers, ISWC","978-1-4503-5967-2","","10.1145/3267242.3267301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056848773&doi=10.1145%2f3267242.3267301&partnerID=40&md5=348865050bbc443fed58ea7b8b213996","The Empathy Amulet is a wearable interpretation of Philip K. Dick’s empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both hap-tically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today’s world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson’s theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4]. Copyright © 2018 ACM.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","248-253","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","ISSN: 15504816","<p>cited By 1; Conference of 22nd International Symposium on Wearable Computers, ISWC 2018 ; Conference Date: 8 October 2018 Through 12 October 2018; Conference Code:141193</p>","","","Wearable technology; Embodied cognition; Internet of things; Haptic I/O; Health consequences; S-theory; Shared experiences; Software prototyping; Subjective experiences; Wearable computers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"737RD9EJ","journalArticle","2018","Liu, B.; Sundar, S.S.","Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot","Cyberpsychology, Behavior, and Social Networking","","21522715","10.1089/cyber.2018.0110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055080779&doi=10.1089%2fcyber.2018.0110&partnerID=40&md5=6111bd02c236f7c8ae5e9e32b516323c","When we ask a chatbot for advice about a personal problem, should it simply provide informational support and refrain from offering emotional support? Or, should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications, do we want the same from a chatbot, or do we simply reject it due to its artificiality and uncanniness? To answer this question, we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1, participants (N = 158) simply read a dialogue between a chatbot and a human user. In Study 2, participants (N = 88) interacted with a real chatbot. We tested the effect of three types of empathic expression - sympathy, cognitive empathy, and affective empathy - on individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice, in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical, methodological, and practical implications are discussed. © Copyright 2018, Mary Ann Liebert, Inc., publishers.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","625-636","","10","21","","","","","","","","","","English","","","","","","","Publisher: Mary Ann Liebert Inc.","<p>cited By 44</p>","","","Perception; Adult; Female; Humans; Male; Young Adult; perception; Middle Aged; User-Computer Interface; Emotions; Communication; emotion; Empathy; empathy; interpersonal communication; human; adult; female; male; young adult; aged; Aged; middle aged; computer interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIH8LA77","journalArticle","2018","Yalcin, O.N.; Dipaola, S.","A computational model of empathy for interactive agents","Biologically Inspired Cognitive Architectures","","2212683X","10.1016/j.bica.2018.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050357957&doi=10.1016%2fj.bica.2018.07.010&partnerID=40&md5=6cb0808ca3ac7e67ad477c8fee67392d","Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents. © 2018 Elsevier B.V. All rights reserved.","2018","2021-05-19 13:26:28","2021-05-19 13:26:28","","20-25","","","26","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 11</p>","","","Artificial intelligence; Cognitive science; Affective Computing; Empathy; Conversational agents; Computation theory; Computational model; Biology; Computational methods; Intelligence communities; Interactive agents; Scientific literature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JL9F3T9J","conferencePaper","2018","Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.","Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression","2018 15th International Conference on Ubiquitous Robots, UR 2018","978-1-5386-6334-9","","10.1109/URAI.2018.8441767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053513255&doi=10.1109%2fURAI.2018.8441767&partnerID=40&md5=0e071356103385e8abbf327f361ed75a","Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture. © 2018 IEEE.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","377-382","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 15th International Conference on Ubiquitous Robots, UR 2018 ; Conference Date: 27 June 2018 Through 30 June 2018; Conference Code:138974</p>","","","Human robot interaction; Facial Expressions; Behavioral research; Cultural backgrounds; Cultural traits; Emotional behavior; Incremental learning; Batch learning; Conformal mapping; Neural network model; Self organizing maps; Socially assistive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMUHG5BC","journalArticle","2018","Indraganti, M.","Enquiry-based learning workshop for deep learning in Middle Eastern classrooms–an action research approach","Educational Action Research","","09650792","10.1080/09650792.2017.1379423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030566118&doi=10.1080%2f09650792.2017.1379423&partnerID=40&md5=72f80c0548a60d68ea625828ff23a134","The senior year design students and I were dismayed when my linear teaching and their habitual rote learning failed in a Middle Eastern University. The gulf between the curricular objectives and our teaching-learning methods intrigued me. I turned this into an action research project that sought to answer the questions, ‘What paradigm shift might we need to migrate from traditional rote learning to deep learning? What attitudinal change and philosophical beliefs would that call for in an instructor?’ The search for a solution metamorphosed me from a disengaged instructor into an empathizing reflecting practitioner. It led my students to active engagement in an enquiry-based learning workshop, which significantly improved their performance. This paper celebrates the journey of our collective deep learning. It explicates how I built my personal theory of teaching praxis through critical consciousness and meta reflection. This knowledge-creation process is empowering and may draw many teacher researchers towards meta-reflexive engagement with the social systems around. These change drivers can initiate institutional overhaul to effect systemic reforms. © 2017, © 2017 Educational Action Research.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","603-625","","4","26","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTGXSJLB","journalArticle","2018","Johnston, S.C.","Anticipating and Training the Physician of the Future: The Importance of Caring in an Age of Artificial Intelligence","Academic medicine : journal of the Association of American Medical Colleges","","1938808X","10.1097/ACM.0000000000002175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050403831&doi=10.1097%2fACM.0000000000002175&partnerID=40&md5=ba7c843dd7d3e8f51b8914002c463db1","Artificial intelligence and other forms of information technology are only just beginning to change the practice of medicine. The pace of change is expected to accelerate as tools improve and as demands for analyzing a rapidly growing body of knowledge and array of data increase. The medical students of today will practice in a world where information technology is sophisticated and omnipresent. In this world, the tasks of memorization and analysis will be less important to them as practicing physicians. On the other hand, the nonanalytical, humanistic aspects of medicine-most importantly, the art of caring-will remain a critical function of the physician, and facility with improving systems of care will be required. Communication, empathy, shared decision making, leadership, team building, and creativity are all skills that will continue to gain importance for physicians. These skills should be further prioritized in medical school curricula to produce an even more effective physician for the future.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","1105-1106","","8","93","","","","","","","","","","English","","","","","","","Publisher: NLM (Medline)","<p>cited By 19</p>","","","Humans; artificial intelligence; Artificial Intelligence; Empathy; empathy; Forecasting; trends; human; procedures; doctor patient relationship; forecasting; Physician-Patient Relations; standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ93U4TW","journalArticle","2018","Vaughn, D.A.; Savjani, R.R.; Cohen, M.S.; Eagleman, D.M.","Empathic Neural Responses Predict Group Allegiance","Frontiers in Human Neuroscience","","16625161","10.3389/fnhum.2018.00302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054818270&doi=10.3389%2ffnhum.2018.00302&partnerID=40&md5=b969317edbd81945e006fad82823c283","Watching another person in pain activates brain areas involved in the sensation of our own pain. Importantly, this neural mirroring is not constant; rather, it is modulated by our beliefs about their intentions, circumstances, and group allegiances. We investigated if the neural empathic response is modulated by minimally-differentiating information (e.g., a simple text label indicating another's religious belief), and if neural activity changes predict ingroups and outgroups across independent paradigms. We found that the empathic response was larger when participants viewed a painful event occurring to a hand labeled with their own religion (ingroup) than to a hand labeled with a different religion (outgroup). Counterintuitively, the magnitude of this bias correlated positively with the magnitude of participants' self-reported empathy. A multivariate classifier, using mean activity in empathy-related brain regions as features, discriminated ingroup from outgroup with 72% accuracy; the classifier's confidence correlated with belief certainty. This classifier generalized successfully to validation experiments in which the ingroup condition was based on an arbitrary group assignment. Empathy networks thus allow for the classification of long-held, newly-modified and arbitrarily-formed ingroups and outgroups. This is the first report of a single machine learning model on neural activation that generalizes to multiple representations of ingroup and outgroup. The current findings may prove useful as an objective diagnostic tool to measure the magnitude of one's group affiliations, and the effectiveness of interventions to reduce ingroup biases. © 2018 Vaughn, Savjani, Cohen and Eagleman.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","","","","12","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"345TAAYK","journalArticle","2018","Joyal, C.C.; Neveu, S.-M.; Boukhalfi, T.; Jackson, P.L.; Renaud, P.","Suppression of sensorimotor alpha power associated with pain expressed by an avatar: A preliminary EEG study","Frontiers in Human Neuroscience","","16625161","10.3389/fnhum.2018.00273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054880498&doi=10.3389%2ffnhum.2018.00273&partnerID=40&md5=fc408903253633371b024fcb0042b21e","Several studies using functional magnetic resonance imaging (fMRI) showed that empathic capabilities are associated with the activation (and deactivation) of relatively specific neural circuits. A growing number of electroencephalography studies also suggest that it might be useful to assess empathy. The main goal of this study was to use quantitative electroencephalography (qEEG) to test whether observation of pain expressed by an avatar (virtual reality) induces a suppression of alpha waves over sensorimotor cortical areas, as it is observed with human stimuli. Not only was it the case, but also the magnitude of alpha suppression was correlated with perspective-taking capacity of participants. Both empathy levels and magnitude of sensorimotor alpha suppression (SAS) were significantly higher in women than men. Interestingly, a significant interaction emerged between levels of individual empathy and specificity of experimental instructions, where SAS in participants with good perspective-taking was higher during passive observation of the distressed avatar, while the opposite was true during an active (trying to understand) condition. These results suggest that: (1) synthetic characters are able to elicit SAS; (2) SAS is indeed associated with perspective-taking capacities; (3) Persons with poorer perspective-taking capacities can show significant SAS when proper instructions are provided. Therefore, qEEG represents a low-cost objective approach to measure perspective-taking abilities. © 2018 Joyal, Neveu, Boukhalfi, Jackson and Renaud.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","","","","12","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YH6Y2WA9","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness of Android-Based Mobile Robots for Children Asperger Syndrome","Proceedings of ICAITI 2018 - 1st International Conference on Applied Information Technology and Innovation: Toward A New Paradigm for the Design of Assistive Technology in Smart Home Care","978-1-5386-6726-2","","10.1109/ICAITI.2018.8686759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753069&doi=10.1109%2fICAITI.2018.8686759&partnerID=40&md5=af11f585df846db5c051b6434459ed42","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially. © 2018 IEEE.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","208-212","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 1st International Conference on Applied Information Technology and Innovation, ICAITI 2018 ; Conference Date: 4 September 2018 Through 5 September 2018; Conference Code:147304</p>","","","Android; Rank Wilcoxon; Mobile robots; Social interactions; Engineering research; Automation; Asperger syndromes; Asperger's syndrome; Descriptive analysis; Developmental disorders; Robots for children","","Sonatha Y., Rahmayuni I., Hidayat R., Alanda A., Humaira MT.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHCPIJFA","journalArticle","2018","Martens, A.L.; Grover, C.A.; Saucier, D.A.; Morrison, B.A.","An examination of gender differences versus similarities in a virtual world","Computers in Human Behavior","","07475632","10.1016/j.chb.2018.03.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046006497&doi=10.1016%2fj.chb.2018.03.012&partnerID=40&md5=84b401e567f56ffb7c994166162ecbb3","We derived competing hypotheses from the gender similarities perspective versus the gender differences perspective to examine participants’ behavior in an online virtual world in which we manipulated participants’ gender. To manipulate participants’ gender in the virtual environment, we randomly assigned them to one of three avatars (female, male, or robot). Using a screen recording device, we measured the percentage of time participants spent interacting with empathizing (e.g., options for shopping, telephone) and systemizing (e.g., weapons, options for building) objects in a virtual reality house that we constructed to reflect evidence put forth by the differences perspective. Because we derived competing hypotheses we expected to find support for either the similarities perspective or the differences perspective; however, our results suggested support for both. Consistent with the differences perspective hypotheses, participants paid attention to objects in the environment that were consistent with the social representation of their own gender. However, our results were consistent with the similarities perspective hypotheses, such that the avatars’ gender also played a role in the percentage of time participants spent interacting with empathizing and systemizing objects. Therefore, we conclude that observable differences between men and women are the consequence of both biological and social forces, and research should focus on the interaction between the two as etiologies and explanations for sex and gender differences and similarities. © 2018 Elsevier Ltd","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","404-409","","","84","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 2</p>","","","Virtual reality; Gender differences; Virtual worlds; E-learning; Gender similarities; Recording devices; Social representations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFN9QMWS","conferencePaper","2018","Raffe, W.L.; Garcia, J.A.","Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly","2018 IEEE 6th International Conference on Serious Games and Applications for Health, SeGAH 2018","978-1-5386-6298-4","","10.1109/SeGAH.2018.8401371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050191845&doi=10.1109%2fSeGAH.2018.8401371&partnerID=40&md5=131e80406d278219c3234b216c481603","This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations. © 2018 IEEE.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","1-7","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 6th IEEE International Conference on Serious Games and Applications for Health, SeGAH 2018 ; Conference Date: 16 May 2018 Through 18 May 2018; Conference Code:137631</p>","","","Serious games; Virtual reality; E-learning; Accident prevention; Exercise programs; Fall prevention; Independent living; Integrated interface; Interactive computer graphics; Microsoft kinect; Reality visualization; Stepping motion; Virtual reality technology","","Vilaca J.L., Grechenig T., Duque D., Rodrigues N., Dias N.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZ8W6Q9W","journalArticle","2018","Johnson, E.; Hervás, R.; Gutiérrez López de la Franca, C.; Mondéjar, T.; Ochoa, S.F.; Favela, J.","Assessing empathy and managing emotions through interactions with an affective avatar","Health Informatics Journal","","14604582","10.1177/1460458216661864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046768759&doi=10.1177%2f1460458216661864&partnerID=40&md5=7d10b56caf5c71b81ef6a0d346406804","Assistive technologies can improve the quality of life of people diagnosed with different forms of social communication disorders. We report on the design and evaluation of an affective avatar aimed at engaging the user in a social interaction with the purpose of assisting in communication therapies. A human–avatar taxonomy is proposed to assist the design of affective avatars aimed at addressing social communication disorder. The avatar was evaluated with 30 subjects to assess how effectively it conveys the desired emotion and elicits empathy from the user. Results provide evidence that users become used to the avatar after a number of interactions, and they perceive the defined behavior as being logical. The users’ interactions with the avatar entail affective reactions, including the mimic emotions that users felt, and establish a preliminary ground truth about prototypic empathic interactions with avatars that is being used to train learning algorithms to support social communication disorder evaluation. © 2016, © The Author(s) 2016.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","182-193","","2","24","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Ltd","<p>cited By 12</p>","","","Adult; Female; Humans; Male; User-Computer Interface; Affect; Empathy; empathy; affect; virtual reality; psychology; Internet; Virtual Reality; human; adult; female; male; computer interface; communication disorder; complication; quality of life; Quality of Life; Social Communication Disorder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZXD4RL8","journalArticle","2018","Costa, S.; Brunete, A.; Bae, B.-C.; Mavridis, N.","Emotional storytelling using virtual and robotic agents","International Journal of Humanoid Robotics","","02198436","10.1142/S0219843618500068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044083324&doi=10.1142%2fS0219843618500068&partnerID=40&md5=f1ae706a4c06ac4f13be7bf00be78272","In order to create effective storytelling agents three fundamental questions must be answered: first, is a physically embodied agent preferable to a virtual agent or a voice-only narration? Second, does a human voice have an advantage over a synthesized voice? Third, how should the emotional trajectory of the different characters in a story be related to a storyteller's facial expressions during storytelling time, and how does this correlate with the apparent emotions on the faces of the listeners? The results of two specially designed studies indicate that the physically embodied robot produces more narrative attention to the listener as compared to a virtual embodiment, that a human voice is preferable over the current state of the art of text-to-speech, and that there is a complex yet interesting relation between the emotion lines of the story, the facial expressions of the narrating agent, and the emotions of the listener, and that the empathizing of the listener is evident through its facial expressions. This work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximize their effectiveness. © World Scientific Publishing Company.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","","","3","15","","","","","","","","","","English","","","","","","","Publisher: World Scientific Publishing Co. Pte Ltd","<p>cited By 14</p>","","","Virtual reality; Virtual agent; Robots; Non-verbal communications; Affective response; Eye blink; Facial expression analysis; Posture analysis; Storytelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SBKZUKZ","conferencePaper","2018","Iranzo, R.M.G.; Padilla-Zea, N.; Paderewski-Rodriguez, P.; Gonzalez-Gonzalez, C.S.","Empathy and virtual agents for learning applications in symbiotic systems","IEEE Global Engineering Education Conference, EDUCON","978-1-5386-2957-4","","10.1109/EDUCON.2018.8363298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048111659&doi=10.1109%2fEDUCON.2018.8363298&partnerID=40&md5=62f6bfb9db56637dd5db81cf57ef1d67","Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges. © 2018 IEEE.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","694-697","","","2018-April","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21659559","<p>cited By 0; Conference of 2018 IEEE Global Engineering Education Conference - Emerging Trends and Challenges of Engineering Education, EDUCON 2018 ; Conference Date: 17 April 2018 Through 20 April 2018; Conference Code:136691</p>","","","ethics; Virtual agent; empathy; Robots; E-learning; Philosophical aspects; Future generations; Transparency; Engineering education; Botnet; Key Issues","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4C7YBU57","journalArticle","2018","Da Silva, J.G.G.; Kavanagh, D.J.; Belpaeme, T.; Taylor, L.; Beeson, K.; Andrade, J.","Experiences of a motivational interview delivered by a robot: Qualitative study","Journal of Medical Internet Research","","14388871","10.2196/jmir.7737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047565681&doi=10.2196%2fjmir.7737&partnerID=40&md5=7dd9b0971c10c80a2171a08d5982fe77","Background: Motivational interviewing is an effective intervention for supporting behavior change but traditionally depends on face-to-face dialogue with a human counselor. This study addressed a key challenge for the goal of developing social robotic motivational interviewers: creating an interview protocol, within the constraints of current artificial intelligence, which participants will find engaging and helpful. Objective: The aim of this study was to explore participants' qualitative experiences of a motivational interview delivered by a social robot, including their evaluation of usability of the robot during the interaction and its impact on their motivation. Methods: NAO robots are humanoid, child-sized social robots. We programmed a NAO robot with Choregraphe software to deliver a scripted motivational interview focused on increasing physical activity. The interview was designed to be comprehensible even without an empathetic response from the robot. Robot breathing and face-tracking functions were used to give an impression of attentiveness. A total of 20 participants took part in the robot-delivered motivational interview and evaluated it after 1 week by responding to a series of written open-ended questions. Each participant was left alone to speak aloud with the robot, advancing through a series of questions by tapping the robot's head sensor. Evaluations were content-analyzed utilizing Boyatzis' steps: (1) sampling and design, (2) developing themes and codes, and (3) validating and applying the codes. Results: Themes focused on interaction with the robot, motivation, change in physical activity, and overall evaluation of the intervention. Participants found the instructions clear and the navigation easy to use. Most enjoyed the interaction but also found it was restricted by the lack of individualized response from the robot. Many positively appraised the nonjudgmental aspect of the interview and how it gave space to articulate their motivation for change. Some participants felt that the intervention increased their physical activity levels. Conclusions: Social robots can achieve a fundamental objective of motivational interviewing, encouraging participants to articulate their goals and dilemmas aloud. Because they are perceived as nonjudgmental, robots may have advantages over more humanoid avatars for delivering virtual support for behavioral change. © Joana Galvão Gomes da Silva, David J Kavanagh, Tony Belpaeme, Lloyd Taylor, Konna Beeson, Jackie Andrade.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","","","5","20","","","","","","","","","","English","","","","","","","Publisher: JMIR Publications Inc.","<p>cited By 11</p>","","","Humans; Robotics; qualitative research; robotics; motivational interviewing; human; procedures; Qualitative Research; Motivational Interviewing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBTEBYQR","journalArticle","2018","Huang, M.-H.; Rust, R.T.","Artificial Intelligence in Service","Journal of Service Research","","10946705","10.1177/1094670517752459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041406987&doi=10.1177%2f1094670517752459&partnerID=40&md5=8976ab64c2f47e5c149dacfb64f7488f","Artificial intelligence (AI) is increasingly reshaping service by performing various tasks, constituting a major source of innovation, yet threatening human jobs. We develop a theory of AI job replacement to address this double-edged impact. The theory specifies four intelligences required for service tasks—mechanical, analytical, intuitive, and empathetic—and lays out the way firms should decide between humans and machines for accomplishing those tasks. AI is developing in a predictable order, with mechanical mostly preceding analytical, analytical mostly preceding intuitive, and intuitive mostly preceding empathetic intelligence. The theory asserts that AI job replacement occurs fundamentally at the task level, rather than the job level, and for “lower” (easier for AI) intelligence tasks first. AI first replaces some of a service job’s tasks, a transition stage seen as augmentation, and then progresses to replace human labor entirely when it has the ability to take over all of a job’s tasks. The progression of AI task replacement from lower to higher intelligences results in predictable shifts over time in the relative importance of the intelligences for service employees. An important implication from our theory is that analytical skills will become less important, as AI takes over more analytical tasks, giving the “softer” intuitive and empathetic skills even more importance for service employees. Eventually, AI will be capable of performing even the intuitive and empathetic tasks, which enables innovative ways of human–machine integration for providing service but also results in a fundamental threat for human employment. © 2018, © The Author(s) 2018.","2018","2021-05-19 13:26:29","2021-05-19 13:26:29","","155-172","","2","21","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 307</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CPDSP4B","conferencePaper","2018","Hu, T.; Xu, A.; Liu, Z.; You, Q.; Guo, Y.; Sinha, V.; Luo, J.; Akkiraju, R.","Touch your heart: A tone-aware chatbot for customer care on social media","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-5620-6 978-1-4503-5621-3","","10.1145/3173574.3173989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046976830&doi=10.1145%2f3173574.3173989&partnerID=40&md5=ff5924a8f291ca74170b41a9ac2f6e9b","Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone-aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents. Copyright © 2018 ACM.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","","","","2018-April","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 32; Conference of 2018 CHI Conference on Human Factors in Computing Systems, CHI 2018 ; Conference Date: 21 April 2018 Through 26 April 2018; Conference Code:135975</p>","","","Deep learning; Chatbot; User experience; Social media; Social networking (online); Human engineering; Sales; Customer care; Human agent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U3AEG9UK","conferencePaper","2018","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Design of counseling robot for production by 3D printer","Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017","978-1-5386-4283-2","","10.1109/SITIS.2017.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048855912&doi=10.1109%2fSITIS.2017.20&partnerID=40&md5=56c2a96a7c71f8e67c1dd1dcc7fee57d","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called 'unazuki' in Japanese, a kind of 'nodding' to greatly promote dialogue, often accompanying 'un-un' (meaning 'exactly') of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a 'unazuki' or 'dialog promotion nodding' robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such 'unazuki', the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling. © 2017 IEEE.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","56-62","","","2018-January","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017 ; Conference Date: 4 December 2017 Through 7 December 2017; Conference Code:135826</p>","","","Robots; Counseling; Dialog Promotion; Nodding; Machine design; Experimental evaluation; Psychological distress; 3D printers; Application fields; Counseling agents; Unazuki","","Dipanda A., Gallo L., Chbeir R., Nain N., Yetongnon K.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH6FWHIM","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Dey, A.; Tossell, C.; Finomore, V.","He who hesitates is lost (..in thoughts over a robot)","ACM International Conference Proceeding Series","978-1-4503-5420-2","","10.1145/3183654.3183703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048734329&doi=10.1145%2f3183654.3183703&partnerID=40&md5=b3763171447b67063b193bdef1ec99ee","In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams. © 2018 Copyright held by the owner/author(s).","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 6; Conference of 2018 Technology, Mind, and Society Conference, TechMindSociety 2018 ; Conference Date: 5 April 2018 Through 7 April 2018; Conference Code:136844</p>","","","Robotics; Empathy; Robots; Anthropomorphism; User study; Computer applications; Computer programming; Human-machine; Robot companion; AS relationships; Peak performance; Simulation systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RM8GSBT","journalArticle","2018","Clinton, M.; Madi, M.; Doumit, M.; Ezzeddine, S.; Rizk, U.","“My Greatest Fear Is Becoming a Robot”: The Paradox of Transitioning to Nursing Practice in Lebanon","SAGE Open","","21582440","10.1177/2158244018782565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049921992&doi=10.1177%2f2158244018782565&partnerID=40&md5=057e8c632a83add587e50d082bc548cf","We investigated the challenges final-year nursing students (FYNSs) and first-year registered nurses (FYRNs) face as they transition to nursing practice in Lebanon. Our purpose was to understand the challenges of transition from the perspective of FYNS and FYRNs. We conducted focus group discussions with FYNSs and FYRNs recruited from four leading universities. Thematic analysis identified an unexpected paradox that has implications for quality of nursing care and retention of graduates. While humanoids are marketed to communicate empathically with patients, FYNSs in Lebanon struggle to resist becoming robots. © 2018, The Author(s) 2018.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","","","2","8","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SF8VN7ZB","conferencePaper","2018","Anshar, M.; Williams, M.-A.","Evolving artificial pain from fault detection through pattern data analysis","2017 IEEE International Conference on Real-Time Computing and Robotics, RCAR 2017","978-1-5386-2034-2","","10.1109/RCAR.2017.8311945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050694528&doi=10.1109%2fRCAR.2017.8311945&partnerID=40&md5=e13b223e149d6fdfdfed4b5bf7088696","Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment. © 2017 IEEE.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","694-699","","","2017-July","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 2017 IEEE International Conference on Real-Time Computing and Robotics, RCAR 2017 ; Conference Date: 14 July 2017 Through 18 July 2017; Conference Code:135217</p>","","","Robotics; Health; Machinery; Human robot interaction; Social skills; Broad application; Detection approach; Fault detection; Human interactions; Internal state; Joint motion; Joint stiffness; Pattern recognition; Preventive action","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWEC6PLA","journalArticle","2018","Felnhofer, A.; Kafka, J.X.; Hlavacs, H.; Beutl, L.; Kryspin-Exner, I.; Kothgassner, O.D.","Meeting others virtually in a day-to-day setting: Investigating social avoidance and prosocial behavior towards avatars and agents","Computers in Human Behavior","","07475632","10.1016/j.chb.2017.11.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037057403&doi=10.1016%2fj.chb.2017.11.031&partnerID=40&md5=c6ba24850a8392df3ff56ebe5b4f75bd","Given the increasing use of virtual characters, research is challenged to gain sufficient knowledge on the effects they may have on human cognitions, emotions and behaviors. Thus, this study set out to examine social avoidance tendencies and prosocial behaviors towards human controlled (avatars) and computer controlled entities (agents). A total of N = 95 healthy young adults were randomly assigned to an avatar or agent condition. Participants were exposed to a virtual stranger asking to sit at the table (prosocial behavior) as well as a virtual waiter handing over the false drink (social avoidance). Empathy, interaction anxiety, social and physical presence as well as subjective stress levels were assessed to control for confounding influences. Empathy emerged as a significant predictor of prosocial behavior. Social avoidance, in turn, was not predicted by any of the included variables. Also, there was no effect of agency on social presence, physical presence, social interaction anxiety and stress. Yet, participants showed significantly more social avoidance and prosocial behavior towards avatars. These seemingly contradictory results may be explained by an extension of prior theories: While intuitive responses (e.g., stress) follow the Media Equation Concept (Nass & Moon, 2000), more complex processes (e.g., empathy) may modulate agency dependent responses. © 2017 Elsevier Ltd","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","399-406","","","80","","","","","","","","","","English","","","","","","","Publisher: Elsevier Ltd","<p>cited By 13</p>","","","anxiety; Virtual reality; Empathy; empathy; virtual reality; social interaction; stress; Prosocial behavior; Avatar; Social presence; human; adult; female; major clinical study; male; young adult; randomized controlled trial; Social interactions; Behavioral research; Virtual character; Agents; Avatars and agents; avoidance behavior; Complex Processes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y56L8I5L","conferencePaper","2018","Björling, E.A.; Rose, E.; Ren, R.","Teen-Robot Interaction: A Pilot Study of Engagement with a Low-fidelity Prototype","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045253387&doi=10.1145%2f3173386.3177068&partnerID=40&md5=7e37fee6758bc871489fac3d9259145c","Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies. © 2018 Authors.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","69-70","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 8; Conference of 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135192</p>","","","engagement; Human robot interaction; prototype; Man machine systems; Machine design; Robot interactions; Pilot studies; Human-centered designs; Interaction studies; Low fidelities; Preliminary design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NALFATVA","conferencePaper","2018","Kang, D.; Kim, S.; Kwak, S.S.","The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045233579&doi=10.1145%2f3173386.3177023&partnerID=40&md5=ccd02586641d7f3d562f91a4cbdde86f","We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand. © 2018 Authors.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","143-144","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 1; Conference of 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135192</p>","","","empathy; Human robot interaction; functional intimacy; knowledgeableness; sociability; Social distance; Man machine systems; Accident prevention; Computer supported cooperative work; Physical contacts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXP2ICL3","conferencePaper","2018","Lehmann, H.; Broz, F.","Contagious Yawning in Human-Robot Interaction","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045279372&doi=10.1145%2f3173386.3177063&partnerID=40&md5=c34b27a9315cc4b991b432223e771e6a","This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data. © 2018 Authors.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","173-174","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 2; Conference of 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135192</p>","","","empathy; Social robots; Human robot interaction; behavior contagion; yawning; Man machine systems; Interaction behavior; Preliminary analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45NWMJBY","conferencePaper","2018","Hieida, C.; Horii, T.; Nagai, T.","Decision-Making in Emotion Model","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045237190&doi=10.1145%2f3173386.3177048&partnerID=40&md5=a95302384b63d75523508fee400571fa","Having emotions is essential for robots to understand and sympathize with the feelings of people. In addition, it may allow the robots to be accepted into human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions based on various neurological and psychological findings that are related to empathic communication between humans and robots is proposed. Subsequently, a mechanism of decision-making that is based on affects using convolutional LSTM and deep Q-network is examined. © 2018 Authors.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","127-128","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 4; Conference of 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135192</p>","","","Decision making; Human robot interaction; empathic hri; Man machine systems; Human society; Behavioral research; Long short-term memory; Emotion modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PSH2UP7","conferencePaper","2018","Tan, X.Z.; Vázquez, M.; Carter, E.J.; Morales, C.G.; Steinfeld, A.","Inducing Bystander Interventions during Robot Abuse with Social Mechanisms","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4953-6","","10.1145/3171221.3171247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045140290&doi=10.1145%2f3171221.3171247&partnerID=40&md5=bac2950cb09c0f0ed97baf4cdbeefdfd","We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participants performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all. © 2018 ACM.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","169-177","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 17; Conference of 13th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135041</p>","","","Empathy; Robots; Human robot interaction; Bullying; Man machine systems; Behavioral research; Economic and social effects; Social influence; Abuse; Peer intervention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NL6K3BQA","conferencePaper","2018","Correia, F.; Mascarenhas, S.; Prada, R.; Melo, F.S.; Paiva, A.","Group-based Emotions in Teams of Humans and Robots","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4953-6","","10.1145/3171221.3171252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045153556&doi=10.1145%2f3171221.3171252&partnerID=40&md5=545acc745afe80d9bf6537715a5b6bbf","Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions. © 2018 ACM.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","261-269","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 26; Conference of 13th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2018 ; Conference Date: 5 March 2018 Through 8 March 2018; Conference Code:135041</p>","","","Emotion; Robotics; Trust; Human robot interaction; Man machine systems; Human robots; Behavioral research; Group effects; Identification (control systems); Inter-group; Self-categorisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXLLA3HY","journalArticle","2018","Lazzeri, N.; Mazzei, D.; Cominelli, L.; Cisternino, A.; De Rossi, D.E.","Designing the mind of a social robot","Applied Sciences (Switzerland)","","20763417","10.3390/app8020302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042288683&doi=10.3390%2fapp8020302&partnerID=40&md5=f591b4833f67b0a59b4a1bda155206f2","Humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with human-inspired capabilities and traits. In the last few decades, this has become a reality with enormous advances in hardware performance, computer graphics, robotics technology, and artificial intelligence. New interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social, empathetic and affective capabilities. This paper presents the design, implementation, and test of a human-inspired cognitive architecture for social robots. State-of-the-art design approaches and methods are thoroughly analyzed and discussed, cases where the developed system has been successfully used are reported. The tests demonstrated the system's ability to endow a social humanoid robot with human social behaviors and with in-silico robotic emotions. © 2018 by the authors.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","","","2","8","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 14</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYA66SJ4","conferencePaper","2018","Y Restrepo, E.G.; Boticario, J.G.","Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future","2017 International Conference on Engineering, Technology and Innovation: Engineering, Technology and Innovation Management Beyond 2020: New Challenges, New Approaches, ICE/ITMC 2017 - Proceedings","978-1-5386-0774-9","","10.1109/ICE.2017.8280067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047627034&doi=10.1109%2fICE.2017.8280067&partnerID=40&md5=dcfa25236d464d9783d4a9c0c7675df2","This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society. © 2017 IEEE.","2018","2021-05-19 13:26:30","2021-05-19 13:26:30","","1552-1558","","","2018-January","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 23rd International Conference on Engineering, Technology and Innovation, ICE/ITMC 2017 ; Conference Date: 27 June 2017 Through 29 June 2017; Conference Code:134550</p>","","","Artificial intelligence; Empathy; Accessibility; Diversity; Afective computing; Intelligent systems; Higher education; Engineering education; Engineering research; Advanced technology; Inclusive design; Professional development","","Mendonca J.P., Pallot M., Jardim-Goncalves R., Martins J., Zarli A., Marques M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPBKCGU9","journalArticle","2018","Küster, D.","Social Effects of Tears and Small Pupils Are Mediated by Felt Sadness: An Evolutionary View","Evolutionary Psychology","","14747049","10.1177/1474704918761104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044715787&doi=10.1177%2f1474704918761104&partnerID=40&md5=91719e26f1dce97cd71752d00e9c56cb","Small pupils elicit empathic socioemotional responses comparable to those found for emotional tears. This might be understood in an evolutionary context. Intense emotional tearing increases tear film volume and disturbs tear layer uniformity, resulting in blurry vision. A constriction of the pupils may help to mitigate this handicap, which in turn may have resulted in a perceptual association of both signals. However, direct empirical evidence for a role of pupil size in tearful emotional crying is still lacking. The present study examined socioemotional responses to different pupil sizes, combined with the presence (absence) of digitally added tears superimposed upon expressively neutral faces. Data from 50 subjects showed significant effects of observing digitally added tears in avatars, replicating previous findings for increased perceived sadness elicited by tearful photographs. No significant interactions were found between tears and pupil size. However, small pupils likewise elicited a significantly greater wish to help in observers. Further analysis showed a significant serial mediation of the effects of tears on perceived wish to help via perceived and then felt sadness. For pupil size, only felt sadness emerged as a significant mediator of the wish to help. These findings support the notion that pupil constriction in the context of intense sadness may function to counteract blurry vision. Pupil size, like emotional tears, appears to have acquired value as a social signal in this context. © 2018, © SAGE Publications Inc. 2018.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","","","1","16","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 8</p>","","","Female; Humans; Male; Young Adult; Emotions; emotion; physiology; Empathy; empathy; facial expression; psychology; Facial Expression; human; female; male; young adult; adolescent; Adolescent; Photic Stimulation; photostimulation; crying; Crying; lacrimal fluid; miosis; Miosis; Tears","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWGFXM97","journalArticle","2018","Barakova, E.I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.","Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot","Connection Science","","09540091","10.1080/09540091.2017.1350938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034210275&doi=10.1080%2f09540091.2017.1350938&partnerID=40&md5=abe1cbc4737c660b91d193a7ede94cf5","In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game–the game with the robot was seen as more challenging and the robot–as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","81-98","","1","30","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Ltd.","<p>cited By 10</p>","","","Education; Robots; Humanoid robot; engagement robot/computer; Anthropomorphic robots; Educational robots; Computer games; Computer agents; Intelligent robots; Economic game theory; Game strategies; Game theory; Social engagement; Social strategy; Technological solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CPXJEKB","journalArticle","2018","Fung, P.; Bertero, D.; Wan, Y.; Dey, A.; Chan, R.H.Y.; Siddique, F.B.; Yang, Y.; Wu, C.-S.; Lin, R.","Towards empathetic human-robot interactions","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-75487-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044421406&doi=10.1007%2f978-3-319-75487-1_14&partnerID=40&md5=ca502ecd8e28514076a32d3b1ad09d25","Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can ‘understand’ human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get ‘smarter’ and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people’s lives. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","173-193","","","9624 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319754864 Publisher: Springer Verlag","<p>cited By 1; Conference of 17th International Conference on Intelligent Text Processing and Computational Linguistics, CICLing 2016 ; Conference Date: 3 April 2016 Through 9 April 2016; Conference Code:212219</p>","","","Deep learning; Sentiment analysis; Artificial intelligence; Human robot interaction; Signal processing; Man machine systems; Learning algorithms; Facial Expressions; Human computer interaction; Speech communication; Behavioral research; Text processing; Cartoon characters; Communication features; Computational linguistics; Customer services; Prototype system; Robot movements; Signal processing technique; Software systems","","A, Gelbukh","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VUKV7IA","conferencePaper","2018","Marda, M.; Economou, D.; Bouki, V.","Enhancing deeper learning using empathy and creativity in serious games role-play simulations","Proceedings of the European Conference on Games-based Learning","978-1-911218-99-9","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058967153&partnerID=40&md5=756601e3f4f9ed506dd13d9e12ecdbfa","There is a shift in education towards adopting pedagogical approaches that nurture deeper learning. Educators recognise that effective and active approaches to teaching are more closely associated with deeper learning. These active approaches aim to develop higher order skills, encouraging learners’ critical thinking and decision-making as well as enhancing their capacity to be agile, flexible and adaptable. Among those active approaches stand serious games, which are powerful learning environments that are seen as an emergent and engaging new way of experiment situations and construct knowledge. Serious games, in the form of role-play simulations, are scenario-based games that are used to simulate real life situations. Although serious games and simulations have been widely used in serving educational purposes, there is little evidence on their use in achieving deeper learning. In addition, there is lack of guidelines or a framework for designing serious games to support learners achieve deep learning. This paper proposes a theoretical framework, based on Bloom’s educational model for Mastery Learning, which illustrates the design of instructional process adapted for serious games using empathy and creativity as an approach of designing serious games for achieving deeper learning. It describes an approach of evaluating this framework by designing a serious game focusing on raising awareness about domestic violence and abuse. © 2018, Dechema e.V. All rights reserved.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","785-791","","","2018-October","","","","","","","","Dechema e.V.","","English","","","","","","","ISSN: 20490992","<p>cited By 1; Conference of 12th European Conference on Game Based Learning, ECGBL 2018 ; Conference Date: 4 October 2018 Through 5 October 2018; Conference Code:142835</p>","","","Serious games; Deep learning; Decision making; Empathy; Formative assessment; Creativity; Education computing; Computer aided instruction; Deeper learning; Role play","","M, Ciussi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJ2WGGJH","journalArticle","2018","Qureshi, S.; Hagelbäck, J.; Iqbal, S.M.Z.; Javaid, H.; Lindley, C.A.","Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-030-01054-6_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206","With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","347-363","","","868","","","","","","","","","","English","","","","","","","ISBN: 9783030010539 Publisher: Springer Verlag","<p>cited By 0; Conference of Intelligent Systems Conference, IntelliSys 2018 ; Conference Date: 6 September 2018 Through 7 September 2018; Conference Code:220949</p>","","","Neural networks; Vision; Electrophysiology; Electroencephalography; Intelligent systems; Human robot interaction; Human Computer Interaction (HCI); K nearest neighbor (KNN); Learning algorithms; Support vector machines; Human computer interaction; Machine learning techniques; Bayesian networks; Classification (of information); Emotion detection; Forestry; Human environment; Nearest neighbor search; Regression trees; Robot technology; Tower of Hanoi; Trees (mathematics)","","Arai K., Bhatia R., Kapoor S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8PWLNLZX","journalArticle","2018","Vallverdú, J.; Nishida, T.; Ohmoto, Y.; Moran, S.; Lázare, S.","Fake empathy and human- robot interaction (HRI): A preliminary study","International Journal of Technology and Human Interaction","","15483908","10.4018/IJTHI.2018010103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033380873&doi=10.4018%2fIJTHI.2018010103&partnerID=40&md5=e8c1b39365a7dd4fb4e56730f51ebee7","Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call 'fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different 'humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi- angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment. © Copyright 2018, IGI Global.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","44-59","","1","14","","","","","","","","","","English","","","","","","","Publisher: IGI Global","<p>cited By 3</p>","","","Emotions; Surveys; Empathy; Robots; Human robot interaction; Fake; Man machine systems; Social relationships; Human robot Interaction (HRI); Basic emotions; Human response; Robot skills; Video recording","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CU77GUCB","journalArticle","2018","Anshar, M.; Williams, M.-A.","Evolving robot empathy towards humans with motor disabilities through artificial pain generation","AIMS Neuroscience","","23737972","10.3934/NEUROSCIENCE.2018.1.56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046542640&doi=10.3934%2fNEUROSCIENCE.2018.1.56&partnerID=40&md5=94774a1cfd673260d0b54325f0e577c0","In contact assistive robots, a prolonged physical engagement between robots and humans with motor disabilities due to shoulder injuries, for instance, may at times lead humans to experience pain. In this situation, robots will require sophisticated capabilities, such as the ability to recognize human pain in advance and generate counter-responses as follow up emphatic action. Hence, it is important for robots to acquire an appropriate pain concept that allows them to develop these capabilities. This paper conceptualizes empathy generation through the realization of synthetic pain classes integrated into a robot's self-awareness framework, and the implementation of fault detection on the robot body serves as a primary source of pain activation. Projection of human shoulder motion into the robot arm motion acts as a fusion process, which is used as a medium to gather information for analyses then to generate corresponding synthetic pain and emphatic responses. An experiment is designed to mirror a human peer's shoulder motion into an observer robot. The results demonstrate that the fusion takes place accurately whenever unified internal states are achieved, allowing accurate classification of synthetic pain categories and generation of empathy responses in a timely fashion. Future works will consider a pain activation mechanism development. © 2018 the Author(s).","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","56-73","","1","5","","","","","","","","","","English","","","","","","","Publisher: AIMS Press","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VIHZ9GS","conferencePaper","2018","Asada, M.; Kolonin, A.","Resource-constrained social evidence based cognitive model for empathy-driven artificial intelligence","CEUR Workshop Proceedings","978-3-319-97675-4","","10.1007/978-3-319-97676-1_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051425417&doi=10.1007%2f978-3-319-97676-1_10&partnerID=40&md5=10c85a843431a41274b2e5042aaa682a","Working model of social aspects of human and non-human intelligence is required for social embodiment of artificial general intelligence systems to explain, predict and manage behavioral patterns in multi-agent communities. For this purpose, we propose implementation of resource-constrained social evidence based model and discuss possible implications of its application. © 2018, Springer Nature Switzerland AG.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","100-108","","","10999 LNAI","","","","","","","","Springer Verlag","","English","","","","","","","ISSN: 03029743 Journal Abbreviation: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","<p>cited By 0; Conference of 11th International Conference on Artificial General Intelligence, AGI 2018 ; Conference Date: 22 August 2018 Through 25 August 2018; Conference Code:216699</p>; <p>cited By 0; Conference of 2019 Papers of the Towards Conscious AI Systems Symposium, TOCAIS 2019 ; Conference Date: 25 March 2019 Through 27 March 2019; Conference Code:143406</p>","","","Empathy; Artificial psychology; Cognitive model; Compassion; Social evidence; Social proof; Multi agent systems; Artificial general intelligences; Social aspects","","Ikle M., Goertzel B., Franz A., Rzepka R.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8USJX8RM","conferencePaper","2018","Kouzov, O.","Art, social and culture education supported by artificial intelligence tools","Digital Presentation and Preservation of Cultural and Scientific Heritage","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063348999&partnerID=40&md5=4ee842958b24c16cf7fad0f082796b2c","The use of tools, based on AI, will become a regular practice in education due to the dynamic social development. The role of the artificial intelligence in social sciences, arts and culture is key to the achievement of emotional empathy of people in view of the future symbiosis of man and machine. © 2018 Digital Presentation and Preservation of Cultural and Scientific Heritage.All Rights Reserved.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","111-119","","","8","","","","","","","","Bulgarian Academy of Sciences, Institute of Mathematics and Informatics","","English","","","","","","","ISSN: 13144006","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A5BTT93","journalArticle","2018","Ghosh, D.; Olewnik, A.; Lewis, K.","Application of autoencoders in cyber-empathic design","Design Science","","20534701","10.1017/dsj.2018.11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058042510&doi=10.1017%2fdsj.2018.11&partnerID=40&md5=65de3388dba8628f19c28f3b715e46e7","A critical task in product design is mapping information from the consumer space to the design space. This process is largely dependent on the designer to identify and relate psychological and consumer level factors to engineered product attributes. In this way, current methodologies lack provision to test a designer's cognitive reasoning and may introduce bias through the mapping process. Prior work on Cyber-Empathic Design (CED) supports this mapping by relating user-product interaction data from embedded sensors to psychological constructs. To understand consumer perceptions, a network of psychological constructs is developed using Structural Equation Modeling for parameter estimation and hypothesis testing, making the framework falsifiable in nature. The focus of this technical brief is toward automating CED through unsupervised deep learning to extract features from raw data. Additionally, Partial Least Square Structural Equation Modeling is used with extracted sensor features as inputs. To demonstrate the effectiveness of the approach a case study involving sensor-integrated shoes compares three models - a survey-only model (no sensor data), the existing CED approach with manually extracted sensor features, and the proposed deep learning based CED approach. The deep learning based approach results in improved model fit. Copyright © The Author(s) 2018.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","","","","4","","","","","","","","","","English","","","","","","","Publisher: Cambridge University Press","<p>cited By 1</p>","","","Deep learning; Data mining; Sensors; Learning systems; Mapping; Product design; Cognitive reasoning; Empathic designs; Engineered products; Learning-based approach; Least squares approximations; Mapping information; Partial least square (PLS); Product interaction; Shoe manufacture; Structural equation modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZJM95LR","journalArticle","2018","Tory Toole, J.; Kurian, P.; Craddock, T.J.A.","Coherent energy transfer and the potential implications for consciousness","Journal of Cognitive Science","","15982327","10.17791/jcs.2018.19.2.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050143668&doi=10.17791%2fjcs.2018.19.2.115&partnerID=40&md5=ceeeecd1e033f898418e72908f6fc7cc","The argument that biological systems are too ""warm and wet"" to support quantum effects is becoming increasingly antiquated as research in the field of quantum biology progresses. In fact, not only is it becoming apparent that quantum processes may regularly take place in biological systems, but these processes may underlie the mechanisms of consciousness and propel our models of conceptualizing the human brain into the next era of scientific understanding. The phenomena of consciousness have allured scientists and philosophers for thousands of years, while a precise technical understanding has remained elusive. If possible, developing this understanding will likely be one of humanity's greatest achievements. Knowing the fundamental processes that create conscious experience has far-reaching implications, from the potential birth of true artificial intelligence to a better understanding of mental health disorder etiologies and treatments. One major challenge in the mental health professions, and, ultimately, in empathy of any kind, is being able to see from and appreciate another person's unique, subjective experience. Discoveries in the field of consciousness could help bridge this gap. © 2018 Institute for Cognitive Science, Seoul National University.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","115-124","","2","19","","","","","","","","","","English","","","","","","","Publisher: Seoul National University, Institute for Cognitive Science","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVJTPPUI","journalArticle","2018","Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.","Approaches for generating empathy: A systematic mapping","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-54978-1_89","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f","Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.","2018","2021-05-19 13:26:31","2021-05-19 13:26:31","","715-722","","","558","","","","","","","","","","English","","","","","","","ISBN: 9783319549774 Publisher: Springer Verlag","<p>cited By 5; Conference of 14th International Conference on Information Technology - New Generations, ITNG 2017 ; Conference Date: 10 April 2017 Through 12 April 2017; Conference Code:195369</p>","","","Robotics; Virtual reality; Empathy; Human robot interaction; Customer satisfaction; Rapport; Secondary study; Teaching; Human computer interaction; Social interactions; Mapping; Computer games; Computer supported cooperative work; Computer aided instruction; Collaborative learning environment; Collaborative systems; Customer relationships; Public relations; Systematic mapping studies","","S, Latifi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YAVTQYJK","journalArticle","2018","Kohori, T.; Hirayama, S.; Hara, T.; Muramatsu, M.; Naganuma, H.; Yamano, M.; Ichikawa, K.; Matsumoto, H.; Uchiyama, H.","Development and evaluation of an interactive therapy robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-76270-8_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043505794&doi=10.1007%2f978-3-319-76270-8_6&partnerID=40&md5=9a33e24baf10f8235290981d937942ce","Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","66-83","","","10714 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319762692 Publisher: Springer Verlag","<p>cited By 1; Conference of 14th International Conference on Advances in Computer Entertainment Technology, ACE 2017 ; Conference Date: 14 December 2017 Through 16 December 2017; Conference Code:211429</p>","","","Animals; Robots; Companion robot; Machine design; Design elements; Housing; Interactive functions; Internet survey; Research groups; Risk of damage; Therapeutic effects; Therapeutic robots","","Inami M., Cheok A.D., Romao T., Cheok A.D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8CA4ATN","conferencePaper","2018","Rincon, J.A.; Martin, A.; Costa, A.; Novais, P.; Julian, V.; Carrascosa, C.","EmIR: An emotional intelligent robot assistant","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052709722&partnerID=40&md5=ce9bc64a438e015843ae7c9faca4c4c1","The development of robots that are truly sociable requires understanding how human interactions can be applied to the interaction between humans and robots. A sociable robot must be able to interact with people taking into account aspects like verbal and non-verbal communications (emotions, postures, gestures). This work presents a social robot which main goal is to provide assistance to older people in carrying out their daily activities (through suggestions or reminders). In addition, the robot presents non-verbal communications like perceiving emotions and displaying human identifiable emotions in order to express empathy. A prototype of the robot is being tested in a daycare centre in the northern area of Portugal. © 2018 CEUR-WS. All rights reserved.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","","","","2166","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 2nd Workshop on Affective Computing and Context Awareness in Ambient Intelligence, AfCAI 2018 ; Conference Date: 19 April 2018 Through 20 April 2018; Conference Code:138514</p>","","","Artificial intelligence; Social robots; Human robot interaction; Ambient assisted living; Emotional models; Daily activity; Non-verbal communications; Assisted living; Intelligent robots; Human interactions; Ambient intelligence; Day-care centres; Sociable robots","","Novais P., Costa A., Julian V., Mendez J.T.P., Carrascosa C., Nalepa G.J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGMA3339","journalArticle","2018","Kwon, O.; Kim, J.; Jin, Y.; Lee, N.","Impact of human-robot interaction on user satisfaction with humanoid-based healthcare","International Journal of Engineering and Technology(UAE)","","2227524X","10.14419/ijet.v7i2.12.11038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911","Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","68-75","","2","7","","","","","","","","","","English","","","","","","","Publisher: Science Publishing Corporation Inc","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFLP65FJ","journalArticle","2018","Cuzzocrea, A.; Pilato, G.","Taxonomy-based detection of user emotions for advanced artificial intelligent applications","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-92639-1_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048865847&doi=10.1007%2f978-3-319-92639-1_48&partnerID=40&md5=d63bdaefc4becbb9ef01791ad80e737b","Catching the attention of a new acquaintance and empathize with her can improve the social skills of a robot. For this reason, we illustrate here the first step towards a system which can be used by a social robot in order to “break the ice” between a robot and a new acquaintance. After a training phase, the robot acquires a sub-symbolic coding of the main concepts being expressed in tweets about the IAB Tier-1 categories. Then this knowledge is used to catch the new acquaintance interests, which let arouse in her a joyful sentiment. The analysis process is done alongside a general small talk, and once the process is finished, the robot can propose to talk about something that catches the attention of the user, hopefully letting arise in him a mix of feelings which involve surprise and joy, triggering, therefore, an engagement between the user and the social robot. © Springer International Publishing AG, part of Springer Nature 2018.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","573-585","","","10870 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319926384 Publisher: Springer Verlag","<p>cited By 7; Conference of 13th International Conference on Hybrid Artificial Intelligent Systems, HAIS 2018 ; Conference Date: 20 June 2018 Through 22 June 2018; Conference Code:214349</p>","","","","","Herrero A., de la Cal E.A., Quintian H., Antonio Saez J., Corchado E., de Cos Juez F.J., Villar J.R.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWAZQQ83","journalArticle","2018","Lukan, J.; Gjoreski, M.; Mauersberger, H.; Hoppe, A.; Hess, U.; Luštrek, M.","Analysing physiology of interpersonal conflicts using a wrist device","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-03062-9_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056487546&doi=10.1007%2f978-3-030-03062-9_13&partnerID=40&md5=255bbd68af2d682cf19c9a211dffe35d","We present a study in which 59 participants logged their interpersonal conflicts while wearing an Empatica E4 wristband. They marked the beginnings and endings of the conflicts, as well as their intensity. In this paper, the dataset is described and a preliminary analysis is performed. We describe data segmentation and feature calculation process. Next, the interrelationships between the features and labels are explored. A logistic regression model for conflict recognition was built and significant features were selected. Finally, we constructed a machine learning model and proposed how to improve it. © Springer Nature Switzerland AG 2018.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","162-167","","","11249 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783030030612 Publisher: Springer Verlag","<p>cited By 0; Conference of 14th European Conference on Ambient Intelligence, AmI 2018 ; Conference Date: 12 November 2018 Through 14 November 2018; Conference Code:220219</p>","","","Context; Artificial intelligence; Learning systems; Regression analysis; Preliminary analysis; Ambient intelligence; Machine learning models; Calculation process; Interpersonal conflicts; Iodine compounds; Logistic Regression modeling; Real life; Wrist device","","Stathis K., Kameas A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VI8PE6FJ","journalArticle","2018","Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.","Smiles of children with ASD may facilitate helping behaviors to the robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-030-05204-1_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5","Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","55-64","","","11357 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783030052034 Publisher: Springer Verlag","<p>cited By 0; Conference of 10th International Conference on Social Robotics, ICSR 2018 ; Conference Date: 28 November 2018 Through 30 November 2018; Conference Code:221569</p>","","","Robotics; Robots; Helping behavior; Smile; Diseases; Autism spectrum disorders; Children with autisms; Positive correlations; Social communications","","Broadbent E., Wagner A.R., Ge S.S., Salichs M.A., Castro-Gonzalez A., He H., Cabibihan J.-J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SCP4XMY","journalArticle","2018","Ragot, M.; Martin, N.; Em, S.; Pallamin, N.; Diverrez, J.-M.","Emotion recognition using physiological signals: Laboratory vs. wearable sensors","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-60639-2_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021738722&doi=10.1007%2f978-3-319-60639-2_2&partnerID=40&md5=ff0b20ff56ddff1f177f0d5195b25892","Emotion recognition is an important research topic. Physiological signals seem to be an appropriate way for emotion recognition and specific sensors are required to collect these data. Therefore, laboratory sensors are commonly used while the number of wearable devices including similar physiological sensors is growing up. Many studies have been completed to evaluate the signal quality obtained by these sensors but without focusing on their emotion recognition capabilities. In the current study, Machine Learning models were trained to compare the Biopac MP150 (laboratory sensor) and Empatica E4 (wearable sensor) in terms of emotion recognition accuracy. Results show similar accuracy between data collected using laboratory and wearable sensors. These results support the reliability of emotion recognition outside laboratory. © Springer International Publishing AG 2018.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","15-22","","","608","","","","","","","","","","English","","","","","","","ISBN: 9783319606385 Publisher: Springer Verlag","<p>cited By 22; Conference of AHFE 2017 International Conference on Advances in Human Factors and Wearable Technologies, 2017 ; Conference Date: 17 July 2017 Through 21 July 2017; Conference Code:193349</p>","","","Education; Artificial intelligence; Emotion recognition; Speech recognition; Physiology; Wearable technology; Learning systems; Human engineering; Wearable sensors; Machine learning models; Physiological sensors; Biomedical signal processing; Physiological signals; Wearable devices; Laboratories; Research topics; Signal quality; Specific sensors","","Falcao C., Ahram T.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"66LU6W3U","journalArticle","2018","Kolivand, H.; Ehsani Rad, A.; Tully, D.","Virtual Sex: Good, Bad or Ugly?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-76369-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043604704&doi=10.1007%2f978-3-319-76369-9_3&partnerID=40&md5=ae7db712e31759df56db5c332365de86","Computers have created a new world which enables people to have different experiences that may not be available or appropriate to have in the real world. Sexual activities are also a part this. Nowadays, sex relationships between humans and robots are set to become commonplace. The advances of new technologies need to be taken into account for new progress. It is not uncommon from the first neurophysiological evidence of humans’ ability to empathise with robots. Sex robots are going to be more focused in robotic industry in case of how they look and what rolls that can play. This study attempts to critically review the characters and characteristics of cutting edge ideas of virtual sex in real and virtual environments to provide researchers with backgrounds on what is going on in the future of sexual human needs. We have tried to find out advances, advantages and disadvantages sex with robots and virtual objects in different aspects. Most importantly, in this investigation we tried to find appropriate answers for some of the highlighted questions against virtual sex. © 2018, Springer International Publishing AG, part of Springer Nature.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","26-36","","","10715 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319763682 Publisher: Springer Verlag","<p>cited By 2; Conference of 3rd International Conference on Love and Sex with Robots, LSR 2017 ; Conference Date: 19 December 2017 Through 20 December 2017; Conference Code:211439</p>","","","Virtual reality; Robots; Cutting edges; Human needs; New technologies; Real-world; Robotic industry; Virtual objects","","Cheok A.D., Cheok A.D., Levy D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RH4FE46X","conferencePaper","2018","Spaulding, S.; Chen, H.; Ali, S.; Kulinski, M.; Breazeal, C.","A social robot system for modeling children's word pronunciation","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","978-1-5108-6808-3","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054767511&partnerID=40&md5=95360a691bf7eda4b2a57ed9db9c5b2b","Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors. © 2018 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","1658-1666","","","3","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","","English","","","","","","","ISSN: 15488403","<p>cited By 8; Conference of 17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018 ; Conference Date: 10 July 2018 Through 15 July 2018; Conference Code:139890</p>","","","Social robots; Autonomous agents; Human robot interaction; Students; Teaching; Pipelines; Economic and social effects; Knowledge management; Intelligent robots; Multi agent systems; Computer aided instruction; Intelligent tutoring system; Computational formulations; Curricular materials; Educational experiences; Gaussian process regression; Geophysical prospecting; Ground penetrating radar systems; Speech-based systems; Student Modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAA9V78P","conferencePaper","2018","Dao, M.-S.; Dang-Nguyen, D.-T.; Kasem, A.; Tran-The, H.","Healthy classroom a proof-of-concept study for discovering students’ daily moods and classroom emotions to enhance a learning-teaching process using heterogeneous sensors","ICPRAM 2018 - Proceedings of the 7th International Conference on Pattern Recognition Applications and Methods","978-989-758-276-9","","10.5220/0006749106850691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052025813&doi=10.5220%2f0006749106850691&partnerID=40&md5=0e5d1fa602b5a6dff38ea719619d83cf","This paper introduces an interactive system that discovers students’ daily moods and classroom emotions to enhance the teaching and learning process using heterogeneous sensors. The system is designed to enable (1) detecting students daily moods and classroom emotions using physiological, physical activities, and event tags data coming from wristband sensors and smart-phones, (2) discovering association/correlation between students’ lifestyle and daily moods, and (3) displaying statistical reports and the distribution of daily moods and classroom emotions of students, both in individual and group modes. A pilot proof-of-concept study was carried out using Empatica E4 wristband sensors and Android smart-phones, and preliminary evaluation and findings showing promising results are reported and discussed. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","685-691","","","2018-January","","","","","","","","SciTePress","","English","","","","","","","","<p>cited By 3; Conference of 7th International Conference on Pattern Recognition Applications and Methods, ICPRAM 2018 ; Conference Date: 16 January 2018 Through 18 January 2018; Conference Code:134802</p>","","","Students; Learning systems; Pattern recognition; Teaching and learning; Smartphones; Android smart phones; Heterogeneous sensors; Interactive system; Physical activity; Proof of concept; Statistical report; Teaching process","","De Marsico M., Fred A., di Baja G.S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DW736KI2","journalArticle","2018","Sancar, A.E.; Battini Sönmez, E.","A model for an emotional respondent robot","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-67934-1_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030167102&doi=10.1007%2f978-3-319-67934-1_37&partnerID=40&md5=fa973e11e625a3847ce9b2b2e7082ffc","The aim of this study is to design an emotional regulation model based on facial expressions. It is argued that emotions serve a critical function in intelligent behavior and some researchers posed the questions of whether a robot could be intelligent without emotions. As a result, emotion recognition and adequate reaction are essential requirements for enhancing the quality of human robot interaction. This study proposes a computational model of emotion capable of clustering the perceived facial expression, and using cognitive reappraisal to switch its internal state so as to give a human-like reaction over the time. That is, the agent learns the person’s facial expression by using Self Organizing Map, and gives it a meaning by mapping the perceived expression into its internal state diagram. As a result, the presented model implements empathy with the aim to enhance human-robot communication. © Springer International Publishing AG 2018.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","406-416","","","678","","","","","","","","","","English","","","","","","","ISBN: 9783319679334 Publisher: Springer Verlag","<p>cited By 0; Conference of 3rd International Symposium on Signal Processing and Intelligent Recognition Systems, SIRS 2017 ; Conference Date: 13 September 2017 Through 16 September 2017; Conference Code:198749</p>","","","Robots; Emotion recognition; Human robot interaction; Signal processing; Facial Expressions; Human computer interaction; Behavioral research; Computational model; Intelligent robots; Human-robot communication; Conformal mapping; Self organizing maps; Internal state; Critical functions; Intelligent behavior; Regulation models","","Das S., Thampi S.M., Krishnan S., Corchado Rodriguez J.M., Wozniak M., Al-Jumeily D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"428C97P5","conferencePaper","2018","Spaulding, S.","Personalized robot tutors that learn from multimodal data","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","978-1-5108-6808-3","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054731801&partnerID=40&md5=570c51b3cbbd8493f091b7af0ee5955e","As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks. © 2018 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","1781-1783","","","3","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","","English","","","","","","","ISSN: 15488403","<p>cited By 1; Conference of 17th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2018 ; Conference Date: 10 July 2018 Through 15 July 2018; Conference Code:139890</p>","","","Robotics; Autonomous agents; Human robot interaction; Social robotics; Students; Teaching; Facial Expressions; One-on-one tutoring; Multi agent systems; Multi-Modal Interactions; Educational experiences; Modal analysis; Models of the user; Multi-modal data; Task performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQWDVKIH","conferencePaper","2018","Averkin, A.N.; Pilato, G.; Yarushev, S.A.","An approach for prediction of user emotions based on ANFIS in social networks","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058171055&partnerID=40&md5=c8052eb9c42e6ae545bd4b8400f7eb04","In this paper, we propose an approach for emotions prediction. We suggest a taxonomy-based detection of user joyful interests with semantic spaces and also we propose an ANFIS method for prediction of emotions used in Twitter posts. Catching the attention of a new acquaintance and empathize with her can improve the social skills of a robot. For this reason, we illustrate here the first step towards a system which can be used by a social robot in order to ""break the ice"" with a new acquaintance. © 2018 CEUR-WS. All rights reserved.","2018","2021-05-19 13:26:32","2021-05-19 13:26:32","","126-130","","","2258","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 1; Conference of 2nd International Scientific and Practical Conference &quot;&quot;Fuzzy Technologies in the Industry - FTI&quot;&quot;, FTI 2018 ; Conference Date: 23 October 2018 Through 25 October 2018; Conference Code:142671</p>","","","Semantics; Social robots; Forecasting; Social skills; Semantic Space; User emotions; Fuzzy inference; Twitter posts; ANFIS method","","Sosnin P., Yarushkina N., Moshkin V., Afanasyeva T.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48SZYC8J","conferencePaper","2018","Kowatsch, T.; Nißen, M.; Rüegger, D.; Stieger, M.; Flückiger, C.; Allemand, M.; Von Wangenheim, F.","The impact of interpersonal closeness cues in text-based healthcare chatbots on attachment bond and the desire to continue interacting: An experimental design","26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052961056&partnerID=40&md5=ea614d0bfe759b29a1dc7f99a9de87b3","Working alliance describes an important relationship quality between health professionals and patients and is robustly linked to treatment success. However, due to limited resources of health professionals, working alliance cannot always be promoted just-in-time in a ubiquitous fashion. To address this scalability problem, we investigate the direct effect of interpersonal closeness cues of text-based healthcare chatbots (THCBs) on attachment bond from the working alliance construct and the indirect effect on the desire to continue interacting with THCBs. The underlying research model and hypotheses are informed by counselling psychology and research on conversational agents. In order to investigate the hypothesized effects, we first develop a THCB codebook with 12 design dimensions on interpersonal closeness cues that are categorized into visual cues (i.e. avatar), verbal cues (i.e. greetings, address, jargon, T-V-distinction), quasi-nonverbal cues (i.e. emoticons) and relational cues (i.e. small talk, self-disclosure, empathy, humor, meta-relational talk and continuity). In a second step, four distinct THCB designs are developed along the continuum of interpersonal closeness (i.e. institutional-like, expert-like, peer-like and myself-like THCBs) and a corresponding study design for an interactive THCB-based online experiment is presented to test our hypotheses. We conclude this work-in-progress by outlining our future work. © 26th European Conference on Information Systems: Beyond Digitization - Facets of Socio-Technical Change, ECIS 2018. All Rights Reserved.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","","","","","","","","","","","","Association for Information Systems","","English","","","","","","","","<p>cited By 7; Conference of 26th European Conference on Information Systems, ECIS 2018 ; Conference Date: 23 June 2018 Through 28 June 2018; Conference Code:143975</p>","","","Conversational agents; Chatbot; Human computer interaction; Information use; Information systems; Counselling Psychology; Design of experiments; Health professionals; Interpersonal closeness; Patient treatment; Relationship qualities; Scalability problems; Working Alliance","","Frank U., Bednar P.M., Kautz K.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFQA5RSE","conferencePaper","2018","Shetty, D.; Xu, J.","Strategies to address ""Design thinking"" in engineering curriculum","ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)","978-0-7918-5206-4","","10.1115/IMECE2018-87816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060289006&doi=10.1115%2fIMECE2018-87816&partnerID=40&md5=c3c26deda706705f100c7d880ba1b9e2","It is suggested by many scholars that if the goal of engineering education is to produce engineers who can critically design and create, then providing students with early opportunities to engage in creative engineering design is important. While basic design is focused on the development of new products for the individual, working towards a more sustainable world demands greater attention to designing for and with communities. Improving design education and examining design-learning outcomes requires a kind of targeted approach that could match the best practices to personalize student learning. Design is complex and design includes balancing the needs of multiple stakeholders. However, there is a gap in the preparation of design education that will be needed in a challenging environment. This paper reviews the history of design thinking in the engineering curriculum. Design thinking education starts with an understanding of its importance with socioeconomic relevance. Through observation and empathy, mapping the designer uses the listening and learning tools for mapping users unarticulated needs, working in a team environment. The designer takes time to think carefully why a certain project is considered and details which aspects of machine learning application can be applied from functional to complete success for the end users. The availability of powerful virtual reality methodologies, have made it possible to consider the realistic needs and visualize scenarios and to explore the design alternatives with new ideas before full scale resource allocation on new ideas. Mid-to-advanced level courses with experimental assignments require that students apply through experimentation the principles and concepts learned in foundation courses. The basic design tools such as axiomatic thinking, theory of inventive problem solving, design iteration and simulation using hardware-in-the loop are discussed with case studies. Consideration of product sustainability with the thoughts of design for disassembly and disposal has emerged as a major part of design thinking. Senior engineering courses center on cross and interdisciplinary design and capstone experiences so that students experience fully guided practice of device design and problem solving, simulating what they are likely to experience in the world. This paper examines the critical issues of design thinking in a curriculum from observation, empathy mapping, validation of the idea, and improvement of idea by virtual reality and machine learning, optimization of the idea by tools such as axiomatic design, hardware in the loop simulation, and finally examining product sustainability causes. Copyright © 2018 ASME.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","","","","5","","","","","","","","American Society of Mechanical Engineers (ASME)","","English","","","","","","","","<p>cited By 2; Conference of ASME 2018 International Mechanical Engineering Congress and Exposition, IMECE 2018 ; Conference Date: 9 November 2018 Through 15 November 2018; Conference Code:144113</p>","","","Virtual reality; Economics; Ecodesign; Students; Learning systems; Mapping; Sustainable development; Curricula; Engineering education; Problem solving; Computer aided instruction; Availability; Balancing; Capstone experience; Creative engineering; Engineering curriculum; Hard-ware-in-the-loop; Hardware-in-the-loop simulation; Inter-disciplinary designs; Iterative methods; Machine learning applications; Multiple stakeholders; Product design; Synthetic apertures; Theory of inventive problem solving; Traction (friction)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FW654ECL","conferencePaper","2018","Bogatyreva, A.A.; Sovkov, A.D.; Tikhomirova, S.A.; Vinogradova, A.R.; Samsonovich, A.V.","Virtual pet powered by a socially-emotional BICA","Procedia Computer Science","","","10.1016/j.procs.2018.11.101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059446525&doi=10.1016%2fj.procs.2018.11.101&partnerID=40&md5=641bddc567abf82308667be9f87f06ff","Cognitive architectures are used to build intelligent agents, and nowadays special attention in this area is drawn to emotion modelling. The purpose of this study is to compare two models describing social-emotional behavior, one of which is based on a traditional machine learning algorithm, and the other on a cognitive architecture supporting social emotionality. It is hypothesized that the second model will be more efficient in eliciting user's empathy to a virtual cobot based on this model. Here the object of study is a virtual pet: a penguin. Two models controlling the pet were compared: a reinforcement learning model (a Q-learning algorithm) and the emotional cognitive architecture eBICA (Samsonovich, 2013). The second approach was based on a semantic map of pet's emotional states, that was constructed based on the human ranking. It is found that the eBICA model scores higher in participant's empathy compared to the model based on reinforcement learning. This article compares strengths and weaknesses of both methods. In conclusion, the findings indicate advantages of the approach based on eBICA compared to more traditional techniques. Results will have broad implications for building intelligent social agents. © 2018 The Authors. Published by Elsevier B.V.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","564-571","","","145","","","","","","","","Elsevier B.V.","","English","","","","","","","ISSN: 18770509","<p>cited By 1; Conference of 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 ; Conference Date: 22 August 2018 Through 24 August 2018; Conference Code:143244</p>","","","Semantics; Reinforcement learning; Emotional intelligence; Learning algorithms; Cognitive architectures; Intelligent agents; Reinforcement learning models; Virtual character; Intelligent social agents; Q-learning algorithms; Semantic Space; Traditional techniques","","A.V, Samsonovich","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZQ9XR2Z","journalArticle","2018","Korać, S.T.","Depersonalisation of killing: Towards a 21st century use of force “beyond good and evil?” [Depersonalizacija ubijanja ka upotrebi sile u 21. Veku „s onu stranu dobra i zla?“]","Filozofija i Drustvo","","03535738","10.2298/FID1801049K","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059193212&doi=10.2298%2fFID1801049K&partnerID=40&md5=87fab0df617879e99bff27aab7f6a083","The article analyses how robotisation as the latest advance in military technology can depersonalise the methods of killing in the 21st century by turning enemy soldiers and civilians into mere objects devoid of moral value. The departing assumption is that robotisation of warfare transforms military operations into automated industrial processes with the aim of removing empathy as a redundant ‘cost’. The development of autonomous weapons systems raises a number of sharp ethical controversies related to the projected moral insensitivity of robots regarding the treatment of enemies and civilian population. The futurist vision of war as a foreign policy instrument entirely ‘purified’ of the risk of morally wrong actions is in opposition with the negative effects of the use of drones. The author concludes that the use of lethal robots in combat would eventually remove enemy soldiers and civilians from the realm of ethical reasoning and deprive them of human dignity. Decision to kill in military operations ought to be based on human conscience as the only proper framework of making decisions by reasoning whether an action is right or wrong. © 2018, University of Belgrade - Institute for Philosophy and Social Theory. All rights reserved.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","49-64","","1","29","","","","","","","","","","English","","","","","","","Publisher: University of Belgrade - Institute for Philosophy and Social Theory","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLJBT56M","journalArticle","2018","Kajiwara, Y.; Kubo, Y.; Kimura, H.","Estimation of evocation of friendship based on similarity of pulse rate variability of users for event-based social networks","Sensors and Materials","","09144935","10.18494/SAM.2018.1777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049905275&doi=10.18494%2fSAM.2018.1777&partnerID=40&md5=4bfc723f0e62ef5c77681b965445a2a1","In contrast to traditional social network services (SNSs), event-based social networks determine close friendships (CFs) of users who share experiences and emotions with candidate friends in offline events. However, we could not provide feedback to cyberspace regarding the place, time, and target of a user realizing friendship since there is no technique for conveniently measuring the evocation of friendship during offline events. In this research, we propose a method of estimating the evocation of friendship using the similarity in the pulse rate variabilities (PRVs) of users when empathy is evoked between them. The user can be made aware of friendship estimated automatically through machine learning by wearing a wristwatch-type pulsimeter. CFs are more likely to evoke empathy than superficial friendships (SFs). To demonstrate the usefulness of this method, we conducted an experiment assuming an event where a group of four people are enjoying their time in an amusement park. From the experimental results, we showed that the similarity of the PRVs in CFs is greater than that in SFs when the favorability rating is high and the users like each other. Moreover, we showed that the proposed method estimated the evocation of friendship during the attraction experience with an f-measure of 0.74 at maximum and during an offline event with a mean f-measure of 0.78. The results showed the usefulness and effectiveness of this method. © MYU K.K.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","1407-1426","","7","30","","","","","","","","","","English","","","","","","","Publisher: M Y U Scientific Publishing Division","<p>cited By 0</p>","","","Artificial intelligence; Social network services; Friendship; Learning systems; Social networking (online); Internet of things; Amusement parks; Cyberspaces; Event-based; F measure; Favorability; Pulse rate variability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EZKJZU5","journalArticle","2018","Chen, A.C.-Y.; Lin, Y.-C.","Warm Robot Classroom_Using Wearable Technology as a Gateway to Culturally Responsive Teaching","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-91152-6_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050464253&doi=10.1007%2f978-3-319-91152-6_19&partnerID=40&md5=1c19f03d879291cd2cc0f914750ebf1e","[Warm Robot classroom] is related to answer the question of introduce computational thinking teaching aids and course design by studies robots and wearables with social humanity. The discussion is about how to cultivate students with the rational technology thinking and humanity empathy? The research method includes design and research on cultural response teaching curriculum with the composition of product designers and electronic engineers, planning of teaching contents, and solicitation of teaching and learning of cultural responses from more than five kinds of different cultural backgrounds through the a one semester course. Develop the performances from different cultural groups through 3D printing, laser cutting and digital embroidery creations and assess the applicability of course design. This course was held with 64 participants (9 different countries, 5 backgrounds). We describe our experience in designing and organizing a wearable course. We will show that (1) Three interactive modules of difficult levels of soft wearable prototypes. (2) The culturally responsive curriculum. (3) The learning outcome of the teaching implementations with interactive toolkits from the final performance. The result shows that curriculum with different background works together can built students from either side to response to each other. © 2018, Springer International Publishing AG, part of Springer Nature.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","239-253","","","10925 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319911519 Publisher: Springer Verlag","<p>cited By 0; Conference of 5th International Conference on Learning and Collaboration Technologies, LCT 2018 Held as Part of HCI International 2018 ; Conference Date: 15 July 2018 Through 20 July 2018; Conference Code:216129</p>","","","Robots; Interactive design; Smart textiles; Wearable technology; Teaching; Machine design; Wearable prototypes; Computational thinkings; Curricula; Engineering education; Cultural backgrounds; Product design; Collaboration technology; Culturally-responsive teaching; Teaching and learning; Teaching curriculum; Textile printing; Textiles","","Zaphiris P., Ioannou A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IJYNKYP6","conferencePaper","2018","Coman, A.C.; Zara, G.; Nechaev, Y.; Barlacchi, G.; Moschitti, A.","Exploiting deep neural networks for tweet-based emoji prediction","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057887474&partnerID=40&md5=05bb99e39d4261ed76708c15a4c0e94e","For many years now, emojis have been used in social networks and chat services in order to enrich written text with auxiliary graphical content, achieving a higher degree of empathy. In particular, given the wide use of this medium, emojis are now available in such a number and variety that every basic concept and mood is covered by at least one. For this reason, the connection between the emoji and its semantical meaning grows stronger. In this paper, we will be describing the work performed in order to develop a Machine Learning based tool that, given a tweet, predicts the most likely emoji associated with the text. The task resembles the one presented by Barbieri et al., [23], and is placed within the context of the International Workshop on Semantic Evaluation (SemEval) 2018. We designed a baseline with standard Support Vector Machines and another baseline based on fastText, which was provided as part of the Workshop. In addition, we implemented several models based on Neural Networks such as Bidirectional Long Short-Term Memory Recurrent Neural Networks and Convolutional Neural Networks. We found that the latter is the most effective since it outperformed all our models and ranks in the 6th position out of 47 total participants. Our work aims to illustrate the potential of simpler models, which, thanks to the fine-tuning of hyper-parameters, could achieve accuracy comparable to the more complex models of the challenge. © 2018 CEUR-WS. All rights reserved.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","116-128","","","2244","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 0; Conference of 2nd Workshop on Natural Language for Artificial Intelligence, NL4AI 2018 ; Conference Date: 22 November 2018 Through 23 November 2018; Conference Code:141962</p>","","","Semantics; Twitter; Convolutional neural network; Learning systems; Support vector machines; Deep neural networks; Text processing; Classification (of information); Emoji; FastText; Hyper-parameter; International workshops; Long short-term memory; Semantic evaluations; Text classification","","Dell'Orletta F., Basile V., Guerini M., Basile P., Croce D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUNXF7HF","journalArticle","2018","Baylor, A.L.","Three research directions for affective learning technologies","Proceedings of International Conference of the Learning Sciences, ICLS","","18149316","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852093&partnerID=40&md5=f752722081155797b31c18bfb8421fc9","Looking to the future of advanced learning technology research, understanding, supporting and explicitly designing for the role of affect is of great importance. I highlight three emerging areas of research with current research exemplars. First, simulating affect is necessary to enhance human-like relationships with technology; for example, with artificially intelligent virtual agents, or teachable robots as learning companions. Second, sensing and responding to learner affect in immersive learning experiences as well as learning at scale is rapidly evolving; for example, through affective intelligent tutoring systems, or dashboards driven by multimodal analytics. Third, designing technology-based learning experiences that promote, elicit and support affective outcomes requires theory building within the learning sciences; for example, to realize outcomes such as empathy or curiosity and formulate linkages to learning. Finally, I suggest how research in these areas of affective technology afford new opportunities to prepare learners for future learning and work environments. © ISLS.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","1843-1846","","2018-June","3","","","","","","","","","","English","","","","","","","Publisher: International Society of the Learning Sciences (ISLS)","<p>cited By 0; Conference of 13th International Conference of the Learning Sciences, ICLS 2018: Rethinking Learning in the Digital Age: Making the Learning Sciences Count ; Conference Date: 23 June 2018 Through 27 June 2018; Conference Code:138742</p>","","","E-learning; Teaching; Learning systems; Intelligent virtual agents; Learning science; Intelligent robots; Computer aided instruction; Advanced learning; Affective learning; Immersive learning; Intelligent tutoring system; Learning companions; Technology-based learning; Work environments","","Luckin R., Kay J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FH87DSAN","conferencePaper","2018","Vallejo-Jiménez, M.M.; Martínez-Puerta, J.J.; Agudelo, S.B.; Salgado, N.D.","SENA Tecnoacademia Risaralda and Caldas as a collaborative learning scenario in robotics","CEUR Workshop Proceedings","978-956-09-2820-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062656500&partnerID=40&md5=dffca2434457967c2b9144db0e10a2d5","The Research, Technological Development and Innovation System of SENA (SENNOVA) of Colombia, has the purpose of strengthening the standards of quality and relevance, through programs and projects as Tecnoacademias, defined as a STEM learning scenario, equipped with emerging technologies to develop innovation-oriented skills, through project training, to students of basic and secondary education, in courses such as Mathematics, Physics, Chemistry, Biology, applied sciences such as Robotics, Nanotechnology, Biotechnology and Virtual Technologies. This work presents some of the activities carried out by the apprentices through the Educational Robotics in Tecnoacademia Risaralda and Tecnoacademia Caldas sites, based on Industrial and Mechatronic Design methodologies, using LEGO MINDSTORM EV3 kits and Design Thinking for educators and LEGO, successfully applied in the EducarChile program. It is based on three fundamental pillars, which are empathy, collaboration and experimentation, which are presented in the five (5) phases of the methodology. It should be noted that the tools of innovation and prototyping per se, do not serve much if the team that executes them is not immersed in a culture of tolerance, teamwork, leadership and if there is no feedback and if the capacities are not taken into account and strengths of the work team. All this was achieved through different prototypes of robots of light and robust type originated in a PON scenario (problem, opportunity, needs). © 2018 CEUR-WS. All rights reserved.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","","","","2312","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 1; Conference of 4th Congress on Robotics and Neuroscience, CRoNe 2018 ; Conference Date: 15 November 2018 Through 17 November 2018; Conference Code:145723</p>","","","Robotics; Students; Neurology; Collaborative learning; Engineering education; Learning scenarios; Educational robotics; Emerging technologies; Innovation system; Mechatronic design methodologies; Technological development; Virtual technology","","Nettle C.J., Solis M.A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63UU7BJB","journalArticle","2018","Conradie, K.","The aesthetic disposition as psychotherapeutic quality in a mainly apathetic, digitalised environment [Die estetiese ingesteldheid as psigoterapeutiese kwaliteitinŉhoofsaaklikapatiese, gedigitaliseerde omgewing]","Tydskrif vir Geesteswetenskappe","","00414751","10.17159/2224-7912/2018/v58n4-2a7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059644920&doi=10.17159%2f2224-7912%2f2018%2fv58n4-2a7&partnerID=40&md5=8cef206499c97d8ea35482d45ff792f6","The psychotherapeutic space is characterised by, inter alia, empathetic participation, that is, sensitivity for the problematic nature of the existence and meaning of everything. The aesthetic disposition is a demand made on the therapist to be receptive to la condition humaine in an existential manner. In this article, I contend that in the face of an unbridled digital culture, the above-mentioned psychotherapeutic quality may be threatened. Furthermore, I scrutinise the nature of this concern in the light of interwoven theoretical and philosophical approaches, and of examples from poetry and literary prose. It is suggested that the training of postgraduate psychology students in general and educational psychology students in particular who have grown up with digital media ought to be reviewed. When online digital media become the predominant tool with which meaning is unlocked and interpreted it probably says something about the way people approach their world epistemologically and ontologically. In this regard, the ever-expanding digital consumerism, characterised by utility and immediacy, increasingly serves as hubris through which humanity appears to be doomed to collapse. This collapse would not necessarily mean the disappearance of Homo sapiens, but rather refers to an impoverishment of the function of language and thought in humankind's pursuit of meaning creation. Recent research contends that the rapid hybridisation (that is, the fusion of human being and android/machine) to which humankind is exposed occurs at the expense of certain knowledge-gaining and meaning-creating functions. One of these functions is the search for coherence by means of in-depth interpretation frameworks in order to steer away from chaos and fragmentation at the social and personal-psychological levels. Specifically, it concerns the impoverished role of language and thought as vital conditions for the articulation of the fine network of nuances of events and experiences. A predominantly digitalised culture in which the rich register of personal experiences is hardly given a place can lead to the ontology of existence being reduced to filtered, instant experiences and knowledge fragments stripped of their essential nuances. Another factor contributing to indifference in the context of the psychotherapist's thinking actions is the inherent fragmentation of the profession of psychology. This often makes it difficult for therapists who pursue the humanistic principles of solicitude and endeavour to fathom the greatest depths of humanity, to position themselves simultaneously within various social systems. Gardner believes “an effective counsellor must radically change his or her perspective on a client throughout the day, viewing the client first through the client's own eyes; then through the eyes of a legal authority or insurance entity; and possibly even through the eyes of a particular agency or school, whose own policies may differ widely from the counsellor, client, or payer” (Gardner 2016:88). According to Gardner, the orientation of metamodernism, characterised by continuous movement and reform, can serve as a conciliatory paradigm to deal with fragmentation and conflicting contexts peculiar to psychotherapeutic practice. She illustrates this fragmentation with reference, in particular, to the one-dimensional reliance on “neo-medical strategies” (Gardner 2016:89), namely rigid treatment plans, diagnostic criteria and DSM1 codes and categories, as opposed to a humanistic approach characterised by human autonomy and integrity. It is suggested that metamodernism as an attitude becomes a way for the educational psychologist of positioning herself in ambivalent environments by means of a to-and-fro movement between conflicting contexts and metaphysical issues related to psychology, such as good/evil, male/female, conscious/unconscious, psychological distress/prosperity, rather than a total rejection of boundaries as in postmodernism. In this article, with reference to several theories in philosophy and psychology, analytical literary discussions and recent information science research findings, I endeavour to gain clarity about how the culture of digital media relates to the need for an aesthetic disposition, specifically as a psychotherapeutic quality. In considering this, I explain how art as a direction indicator of the aesthetic disposition can be applied to advance and enrich the thinking of the psychotherapist and educational psychologist. © 2018 Society of Powder Technology. All Rights Reserved.","2018","2021-05-19 13:26:33","2021-05-19 13:26:33","","976-991","","4","58","","","","","","","","","","English","","","","","","","Publisher: South African Academy for Science and the Arts","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXCQWIRI","conferencePaper","2017","Burns, H.D.; Lesseig, K.","Empathy in middle school engineering design process","Proceedings - Frontiers in Education Conference, FIE","978-1-5090-5919-5","","10.1109/FIE.2017.8190669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043250525&doi=10.1109%2fFIE.2017.8190669&partnerID=40&md5=2de94d98be1bbb33936099368e3ff4f4","This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word ""empathy"" is not used, these problems are defined from an empathetic perspective as ""situations people want to change"" of ""social and global significance."" However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design. © 2017 IEEE.","2017","2021-05-19 13:26:33","2021-05-19 13:26:33","","1-4","","","2017-October","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 15394565","<p>cited By 1; Conference of 47th IEEE Frontiers in Education Conference, FIE 2017 ; Conference Date: 18 October 2017 Through 21 October 2017; Conference Code:133822</p>","","","Science; Empathy; technology; Emotional intelligence; Standards; Design; Students; Teaching; Education computing; Technology; After-school science club; Design process; Engineering; Engineering and Mathematics; engineering and mathematics); Engineering design process; Middle school; Qualitative case studies; STEM (science","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6WE6KN7","journalArticle","2017","Moritz, J.","Augmented humanity","Technoetic Arts","","1477965X","10.1386/tear.15.3.341_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042419209&doi=10.1386%2ftear.15.3.341_1&partnerID=40&md5=6a9d2d151fb5d856a706e0b47ec99161","Augmented Reality (AR) is commonly defined as a digital layer of information viewed on top of the physical world through a smartphone, tablet or eyewear. Increasingly, this understanding of AR is shifting to a dynamic framework of 'smart things', including wearable technology, sensors and artificial intelligence (AI), with the ability to intercede in key moments and to deliver contextual and meaningful experiences. The things that come into context are the logical next steps in an evolutionary development towards computers that are better able to show empathy in relation to people: even more human-oriented, anticipative and ubiquitous. Thus, this outsourcing of meaning to empathic technologies points to one of the fundamental questions concerning the relation of human and technology - the nature of the trust that users place in technology. © 2017 Intellect Ltd.","2017","2021-05-19 13:26:33","2021-05-19 13:26:33","","341-352","","3","15","","","","","","","","","","English","","","","","","","Publisher: Intellect Ltd.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEWMMC84","journalArticle","2017","Ferguson, C.J.; Donnellan, M.B.","Are Associations Between “Sexist” Video Games and Decreased Empathy Toward Women Robust? A Reanalysis of Gabbiadini et al. 2016","Journal of Youth and Adolescence","","00472891","10.1007/s10964-017-0700-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021122350&doi=10.1007%2fs10964-017-0700-x&partnerID=40&md5=603ebd5a0a8567a347e39875ef17c332","Gabbiadini, A., Riva, P., Andrighetto, L., Volpato, C., &amp; Bushman, B, (PloS ONE, 2016) provided evidence for a connection between “sexist” video games and decreased empathy toward girls using an experimental paradigm. These claims are based on a moderated mediation model. They reported a three-way interaction between game condition, gender, and avatar identification when predicting masculine ideology in their original study. Masculine ideology was associated, in turn, with decreased empathy. However, there were no main experimental effects for video game condition on empathy. The current analysis considers the strength of the evidence for claims made in the original study on a sample of 153 adolescents (Mage = 16.812, SD = 1.241; 44.2% male). We confirmed that there was little evidence for an overall effect of game condition on empathy toward girls or women. We tested the robustness of the original reported moderated mediation models against other, theoretically derived alternatives, and found that effects differed based on how variables were measured (using alternatives in their public data file) and the statistical model used. The experimental groups differed significantly and substantially in terms of age suggesting that there might have been issues with the procedures used to randomly assign participants to conditions. These results highlight the need for preregistration of experimental protocols in video game research and raise some concerns about how moderated mediation models are used to support causal inferences. These results call into question whether use of “sexist” video games is a causal factor in the development of reduced empathy toward girls and women among adolescents. © 2017, Springer Science+Business Media New York.","2017","2021-05-19 13:26:33","2021-05-19 13:26:33","","2446-2459","","12","46","","","","","","","","","","English","","","","","","","Publisher: Springer New York LLC","<p>cited By 9</p>","","","Female; Humans; Male; Young Adult; perception; empathy; psychology; child; ideology; Masculinity; Sexism; Violence; Social Perception; human; female; major clinical study; male; young adult; controlled study; adolescent; video game; aggression; Aggression; crime victim; Crime Victims; experimental model; girl; masculinity; sexism; statistical model; theoretical model; Video Games; violence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FRE9IJI","conferencePaper","2017","Kurashige, K.; Sakurai, E.; Knauf, R.; Tsuruta, S.; Sakurai, Y.; Damiani, E.","Context respectful counseling agent integrated with robot nodding for dialog promotion","2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017","978-1-5386-1645-1","","10.1109/SMC.2017.8122833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044231442&doi=10.1109%2fSMC.2017.8122833&partnerID=40&md5=9b50118f2dd3ce8a24156a3edb15f411","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling. © 2017 IEEE.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","1540-1545","","","2017-January","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017 ; Conference Date: 5 October 2017 Through 8 October 2017; Conference Code:133297</p>","","","Robots; Counseling; Dialog Promotion; Nodding; Cybernetics; Body language; Experimental evaluation; Psychological distress; Counseling agents; Unazuki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LM36LKRK","conferencePaper","2017","Murphy, D.","Building a hybrid virtual agent for testing user empathy and arousal in response to avatar (micro-)expressions","Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","978-1-4503-5548-3","","10.1145/3139131.3141217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038598502&doi=10.1145%2f3139131.3141217&partnerID=40&md5=c1d14dd71b245eeb29f6de44b13ffa26","This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR. © 2017 Copyright held by the owner/author(s).","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","","Part F131944","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 2; Conference of 23rd ACM Conference on Virtual Reality Software and Technology, VRST 2017 ; Conference Date: 8 November 2017 Through 10 November 2017; Conference Code:131944</p>","","","Virtual reality; Virtual agent; Social presence; Facial Expressions; 3-d modeling; Avatar capture; Eye movements; Micro-expressions; Rapid movements; Social plausibility; Video cameras","","S.N, Spencer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EU2HAPI","conferencePaper","2017","Lin, C.; Faas, T.; Dombrowski, L.; Brady, E.","Beyond cute: Exploring user types and design opportunities of virtual reality pet games","Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","978-1-4503-5548-3","","10.1145/3139131.3139132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038583884&doi=10.1145%2f3139131.3139132&partnerID=40&md5=f83b808eee343e0466b0933a733a4d62","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, little is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games. © 2017 Copyright is held by the owner/author(s).","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","","Part F131944","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 3; Conference of 23rd ACM Conference on Virtual Reality Software and Technology, VRST 2017 ; Conference Date: 8 November 2017 Through 10 November 2017; Conference Code:131944</p>","","","Surveys; Virtual reality; Human computer interaction; Video game; Online surveys; Interactive computer graphics; Gameplay; Handhelds; User type","","S.N, Spencer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZPF4FIE","journalArticle","2017","Chikaraishi, T.; Yoshikawa, Y.; Ogawa, K.; Hirata, O.; Ishiguro, H.","Creation and staging of android theatre ""Sayonara"" towards developing highly human-like robots","Future Internet","","19995903","10.3390/fi9040075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040790411&doi=10.3390%2ffi9040075&partnerID=40&md5=7741ec53279dea95f8e1cde8863ea639","Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world. © 2016 by the authors.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","4","9","","","","","","","","","","English","","","","","","","Publisher: MDPI AG","<p>cited By 4</p>","","","Robots; Social robots; Human robot interaction; Human computer interaction; Cultural backgrounds; Android theatre; Contemporary colloquial theatre theory; Human like robots; Long term exposure; Performance system; Robot theatres; Theaters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STN2NJWA","journalArticle","2017","Borenstein, J.; Arkin, R.C.","Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior","AI and Society","","09515666","10.1007/s00146-016-0684-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000443585&doi=10.1007%2fs00146-016-0684-1&partnerID=40&md5=aeb23d28928c11d0e8a8c5616b33c63b","An under-examined aspect of human–robot interaction that warrants further exploration is whether robots should be permitted to influence a user’s behavior for that person’s own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user’s behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user’s empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be. © 2016, Springer-Verlag London.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","499-507","","4","32","","","","","","","","","","English","","","","","","","Publisher: Springer London","<p>cited By 13</p>","","","Empathy; Robots; Companion robot; Human robot interaction; Charity; Design ethics; Nudges; Robot ethics; Machine design; Philosophical aspects; Behavioral research","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2JSMYQJ","conferencePaper","2017","Vieira, S.; Maritan, T.; Santos, A.; Aschoff, M.; Costa, R.; Veríssimo, V.","A study on the use of multiple avatars in 3D sign language dictionaries","WebMedia 2017 - Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web","978-1-4503-5096-9","","10.1145/3126858.3126865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035022193&doi=10.1145%2f3126858.3126865&partnerID=40&md5=dc3f278f2adca9d4a8b9a0f54aad8165","Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors. © 2017 ACM.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","325-332","","","","","","","","","","","Association for Computing Machinery, Inc","","Portuguese","","","","","","","","<p>cited By 1; Conference of 23rd Brazillian Symposium on Multimedia and the Web, WebMedia 2017 ; Conference Date: 17 October 2017 Through 20 October 2017; Conference Code:131253</p>","","","Accessibility; Avatar; Computational linguistics; Computer aided language translation; Machine translations; Retargeting; Sign language; Space platforms; Three dimensional computer graphics; Translation (languages); Transportation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N9XBI3RI","conferencePaper","2017","Shamsuddin, S.; Ahmad, I.F.; Zulkifli, W.Z.; Hwee, L.T.; Yussof, H.","Preliminary study on the use of therapeutic seal robot for patients with depression","IRIS 2016 - 2016 IEEE 4th International Symposium on Robotics and Intelligent Sensors: Empowering Robots with Smart Sensors","978-1-5090-6084-9","","10.1109/IRIS.2016.8066065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050181832&doi=10.1109%2fIRIS.2016.8066065&partnerID=40&md5=aaa2c6d57c6f75d00256f3cedd73eae6","Depression is a serious mental health challenge. If left untreated, it could lead to other critical symptoms, even suicide. In Malaysia, the prevalence is estimated between 8-10% of the population but it is often under-recognized and undertreated. This study is the first one in Malaysia to propose an animal robot to provide mental support to patients with depression. The main objective of this paper is to introduce PARO the seal robot as a remedy to reduce the need for psychotropic drugs during depression therapy at a rehabilitation center. Patients with depression requires repetitive conditioning and motivation. A robotic animal is a proposed solution to provide constant mental support and induce warm and empathetic feelings from the patients. Comparing assessment scores of pre and post robotic therapy shall shed light on the suitability of PARO to help patients with depression. © 2016 IEEE.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","52-56","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 4th IEEE International Symposium on Robotics and Intelligent Sensors, IRIS 2016 ; Conference Date: 17 December 2016 Through 20 December 2016; Conference Code:137496</p>","","","Robotics; Animals; depression; Mental health; Human robot interaction; Intelligent robots; Patient treatment; PARO; Animal robot; Intelligent control; Malaysia; Patient rehabilitation; Psychotropic drugs; Robotic therapies; Smart sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63HP2LCU","conferencePaper","2017","Valverde, I.; Cochrane, T.","Senses Places: Soma-tech mixed-reality participatory performance installation/environment","ACM International Conference Proceeding Series","978-1-4503-5273-4","","10.1145/3106548.3106613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032491826&doi=10.1145%2f3106548.3106613&partnerID=40&md5=5260373363569959041c6f6306604860","We present the latest developments of the art-tech research project Senses Places, a somatic-technological (soma-tech) mixed-reality participatory performance installation/environment, engaging expanded modes of embodied physical-virtual interaction. This ongoing somatic-technological dance/performance collaborative trans-disciplinary approach gathers artists and developer researchers, working remotely and physically in analogical-digital intermedia interfaces and their expanded experience design and choreography. The sensorial expansion and integration sought through human-computer interaction links participants, avatars, images and physical-virtual environments. They constitute different organic-artificial sensorial-expressive channels of visual, audio, tactile, and somatic/kinesthetic shared tuning/engagement/experience. At the core of this long-term intervention lies the common urging desire for more encompassing and empathic embodied interactivity among physical and remote subjects and places. With a cross-cultural somatic and dance practices, Senses Places critically experiments with different informational, communicational and biomedical technologies available, wishing to contribute to understand the world's and humans becoming through what we have been conceiving as posthuman corporealities [1] within a posthuman condition and emerging somatic epistemology [2]. © 2017 Copyright is held by the owner/author(s).","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","195-197","","","Part F130947","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 1; Conference of 8th International Conference on Digital Arts, ARTECH 2017 ; Conference Date: 6 September 2017 Through 8 September 2017; Conference Code:130947</p>","","","Virtual reality; Interaction design; Posthuman corporealities; Somatic epistemology; Somatics; Mixed reality; Human computer interaction; Interactive arts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XCRMLF3","journalArticle","2017","Liu, X.; Xie, L.; Wang, Z.","Empathizing with emotional robot based on cognition reappraisal","China Communications","","16735447","10.1109/CC.2017.8068769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032186341&doi=10.1109%2fCC.2017.8068769&partnerID=40&md5=04cbaacff71cb7cc56daa753df57a9e8","This paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive person's expressions. It integrates a guiding cognitive reappraisal strategy into the HMM (Hidden Markov Model) emotional interactive model for empathizing between robot and person. The emotion is considered as a source in the 3D space (Arousal, Valence, and Stance). State transition and emotion intensity can be quantitatively analyzed in the continuous space. This cognition-emotion interactive model have been verified by the expression and behavior robot. Empathizing is the main distinguishing feature of our work, and it is realized by the emotional regulation which operated in a continuous 3D emotional space enabling a wide range of intermediate emotions. The experiment results provide evidence with acceptability, accuracy, richness, fluency, interestingness, friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the human-robot interaction (HRI). © 2013 IEEE.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","100-113","","9","14","","","","","","","","","","English","","","","","","","Publisher: Editorial Department of China Communications","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6ALXMT8","journalArticle","2017","Paiva, A.; Leite, I.; Boukricha, H.; Wachsmuth, I.","Empathy in virtual agents and robots: A survey","ACM Transactions on Interactive Intelligent Systems","","21606455","10.1145/2912150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030721207&doi=10.1145%2f2912150&partnerID=40&md5=0ee6b019cd9a77afad3da844eab99772","This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user's or another agent's emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent's situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future. Copyright is held by the owner/author(s).","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","3","7","","","","","","","","","","English","","","","","","","Publisher: Association for Computing Machinery","<p>cited By 52</p>","","","Surveys; Virtual reality; Affective Computing; Empathy; Virtual agent; Robots; Social robots; Human robot interaction; Artificial agents; Human computer interaction; Lead users","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUVQM9ZL","journalArticle","2017","Abubshait, A.; Wiese, E.","You look human, but act like a machine: Agent appearance and behavior modulate different aspects of human-robot interaction","Frontiers in Psychology","","16641078","10.3389/fpsyg.2017.01393","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028087757&doi=10.3389%2ffpsyg.2017.01393&partnerID=40&md5=7c76b89b0bf2a723ace310a3123236ab","Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed. © 2017 Abubshait and Wiese.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","AUG","8","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 34</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5HID532","conferencePaper","2017","Frueh, C.; Sud, A.; Kwatra, V.","Headset removal for virtual and mixed reality","ACM SIGGRAPH 2017 Talks, SIGGRAPH 2017","978-1-4503-5008-2","","10.1145/3084363.3085083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033392160&doi=10.1145%2f3084363.3085083&partnerID=40&md5=3fc59bde777ffe20e3006febdc899e1c","Virtual Reality (VR) has advanced significantly in recent years and allows users to explore novel environments (both real and imaginary), play games, and engage with media in a way that is unprecedentedly immersive. However, compared to physical reality, sharing these experiences is difficult because the user's virtual environment is not easily observable from the outside and the user's face is partly occluded by the VR headset. Mixed Reality (MR) is a medium that alleviates some of this disconnect by sharing the virtual context of a VR user in a flat video format that can be consumed by an audience to get a feel for the user's experience. Even though MR allows audiences to connect actions of the VR user with their virtual environment, empathizing with them is difficult because their face is hidden by the headset. We present a solution to address this problem by virtually removing the headset and revealing the face underneath it using a combination of 3D vision, machine learning and graphics techniques. We have integrated our headset removal approach with Mixed Reality, and demonstrate results on several VR games and experiences. © Copyright 2017 Authors.","2017","2021-05-19 13:26:34","2021-05-19 13:26:34","","","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 8; Conference of ACM SIGGRAPH 2017 Talks - International Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 2017 ; Conference Date: 30 July 2017 Through 3 August 2017; Conference Code:129484</p>","","","Virtual reality; Mixed reality; Computer graphics; Learning systems; Interactive computer graphics; 3-D vision; Facial synthesis; Immersive; Physical reality; Real and imaginary; Video format; Virtual addresses; Virtual contexts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5TJ4V3RQ","conferencePaper","2017","Tuyen, N.T.V.; Jeong, S.; Chong, N.Y.","Learning human behavior for emotional body expression in socially assistive robotics","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2017","978-1-5090-3055-2","","10.1109/URAI.2017.7992882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034217006&doi=10.1109%2fURAI.2017.7992882&partnerID=40&md5=9ad61da9fc07256c0888f6888db1c4a2","Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots. © 2017 IEEE.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","45-50","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 5; Conference of 14th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2017 ; Conference Date: 28 June 2017 Through 1 July 2017; Conference Code:129563</p>","","","Artificial intelligence; Robots; clustering; emotional body expression; Human robot interaction; Man machine systems; Behavioral research; Economic and social effects; Assistive robotics; Intelligent robots; Emotional behavior; Socially assistive robots; Ambient intelligence; Imitation learning; Infant development; Self-organized neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PWXFTFXJ","journalArticle","2017","Chin, G.P.W.-H.","Observed bodies and tool selves: kinaesthetic empathy and the videogame avatar","Digital Creativity","","14626268","10.1080/14626268.2017.1348363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025148899&doi=10.1080%2f14626268.2017.1348363&partnerID=40&md5=c7661dcdf2925cb93633714b0755ded6","This paper examines the field of Kinaesthetic Empathy and how it is studied in dance and film then interrogates whether this framework can be applied to the videogame avatar. I study the avatar as textually signifying, as an observed body, and as a prosthetic tool-limb using the works of Merleau-Ponty and Heidegger as theoretical support and Ian Bogost’s procedural style of videogame reading. I perform close readings of videogame-texts Metal Gear Solid 3 and Mirror’s Edge demonstrating how the former enacts a traditional kinaesthetic empathy in the same way as in dance or film and the latter complicates this observer/performer relation. My paper concludes that, though a player/reader may experience a kinaesthetic empathy that resembles the filmic mode of observer/performer kinaesthetic empathy, the videogame form engenders a deeper tool-based empathy, which is altogether different from traditional conceptions of kinaesthetic empathy. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","206-223","","3","28","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 1</p>","","","empathy; avatar; body; Kinaesthetic; Video game; Interactive computer graphics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q2EDLUS","journalArticle","2017","Lawrence, D.","More human than human","Cambridge Quarterly of Healthcare Ethics","","09631801","10.1017/S0963180116001158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019997561&doi=10.1017%2fS0963180116001158&partnerID=40&md5=e3142c138b00fcf2ae2397005a02231c","Within the literature surrounding nonhuman animals on the one hand and cognitively disabled humans on the other, there is much discussion of where beings that do not satisfy the criteria for personhood fit in our moral deliberations. In the future, we may face a different but related problem: That we might create (or cause the creation of) beings that not only satisfy but exceed these criteria. The question becomes whether these are minimal criteria, or hierarchical, such that those who fulfill them to greater degree should be afforded greater consideration. This article questions the validity and necessity of drawing divisions among beings that satisfy the minimum requirements for personhood; considering how future beings - intelligent androids, synthezoids, even alternate-substrate sentiences - might fit alongside the baseline human. I ask whether these alternate beings ought to be considered different to us, and why this may or may not matter in terms of a notion of human community. The film Blade Runner, concerned in large part with humanity and its key synthezoid antagonist Roy Batty, forms a framing touchstone for my discussion. Batty is stronger, faster, more resilient, and more intelligent than Homo sapiens. His exploits, far beyond the capability of normal humans, are contrasted with his frailty and transient lifespan, his aesthetic appreciation of the sights he has seen, and his burgeoning empathy. Not for nothing does his creator within the mythos term him more human than human. © Cambridge University Press 2017.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","476-490","","3","26","","","","","","","","","","English","","","","","","","Publisher: Cambridge University Press","<p>cited By 5</p>","","","Humans; artificial intelligence; ethics; Animals; Artificial Intelligence; morality; Personhood; personhood; human; animal; biomedical enhancement; Biomedical Enhancement; Morals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8T9L4C3","journalArticle","2017","Rouaix, N.; Retru-Chavastel, L.; Rigaud, A.-S.; Monnet, C.; Lenoir, H.; Pino, M.","Affective and engagement issues in the conception and assessment of a robot-assisted psychomotor therapy for persons with dementia","Frontiers in Psychology","","16641078","10.3389/fpsyg.2017.00950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021340604&doi=10.3389%2ffpsyg.2017.00950&partnerID=40&md5=76571d1aa765fd440c392484c9fc5bae","The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a ""control software"" for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient- therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction. © 2017 Rouaix, Retru-Chavastel, Rigaud, Monnet, Lenoir and Pino.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","","","JUN","8","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XPTL6HP","conferencePaper","2017","Ruiz-Garcia, A.; Elshaw, M.; Altahhan, A.; Palade, V.","Stacked deep convolutional auto-encoders for emotion recognition from facial expressions","Proceedings of the International Joint Conference on Neural Networks","978-1-5090-6181-5","","10.1109/IJCNN.2017.7966040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031041686&doi=10.1109%2fIJCNN.2017.7966040&partnerID=40&md5=045aaee2dbe5de9d34abffbcb519a458","Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system. © 2017 IEEE.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","1586-1593","","","2017-May","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 25; Conference of 2017 International Joint Conference on Neural Networks, IJCNN 2017 ; Conference Date: 14 May 2017 Through 19 May 2017; Conference Code:128847</p>","","","Neural networks; Convolutional neural network; Emotion recognition; Face recognition; Speech recognition; Convolution; Emotional state; Learning systems; Facial Expressions; Deep neural networks; Classification (of information); Feature vectors; Initial weights; Local minimums; Signal encoding; Spatial informations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L25YBHIT","journalArticle","2017","van Rijn, B.; Cooper, M.; Jackson, A.; Wild, C.","Avatar-based therapy within prison settings: pilot evaluation","British Journal of Guidance and Counselling","","03069885","10.1080/03069885.2015.1068273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937883419&doi=10.1080%2f03069885.2015.1068273&partnerID=40&md5=eea27491822516edfa435a9ecda8e06b","The paper presents an introduction of a newly developed, avatar-based virtual reality therapy, as an addition to the therapeutic programme, within a therapeutic community prison in the UK. The participants had six group sessions facilitated by a counsellor. The aim of the project was to investigate whether this approach would improve mental health outcomes for the prisoners, interpersonal relationships within the prison and facilitate the achievement of personal goals for the prisoners. The sample size (n = 4) was insufficient to make firm conclusions about the mental health outcomes. However, the qualitative analysis showed a strong engagement with the programme in addressing personal issues, the development of insight and empathy, and improvements in relationships within the participants and with the counsellor. Further research with a larger sample is needed to establish efficacy of this type of therapy with the prison population. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","268-283","","3","45","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 10</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5QN6WNN7","conferencePaper","2017","Tong, X.; Ulas, S.; Jin, W.; Gromala, D.; Shaw, C.","The design and evaluation of a body-sensing video game to foster empathy towards chronic pain patients","ACM International Conference Proceeding Series","978-1-4503-6363-1","","10.1145/3154862.3154869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055989941&doi=10.1145%2f3154862.3154869&partnerID=40&md5=5e5c7a5c80904cdcb2071e511384877a","Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations. © 2017 Association for Computing Machinery.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","244-250","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 3; Conference of 11th EAI International Conference on Pervasive Computing Technologies for Healthcare, PervasiveHealth 2017 ; Conference Date: 23 May 2017 Through 26 May 2017; Conference Code:115071</p>","","","Serious games; Empathy; Health care; Human computer interaction; Interactive computer graphics; Body-Sensing Games; Chronic pain; Embodied Simulation; Gaming For A Purpose; Ubiquitous computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRY7HRDQ","conferencePaper","2017","Xu, A.; Liu, Z.; Guo, Y.; Sinha, V.; Akkiraju, R.","A new chatbot for customer service on social media","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-4655-9","","10.1145/3025453.3025496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454411&doi=10.1145%2f3025453.3025496&partnerID=40&md5=eb0554245b67f51b2c89e08ecccdd3ec","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric. © 2017 ACM.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","3506-3510","","","2017-May","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 156; Conference of 2017 ACM SIGCHI Conference on Human Factors in Computing Systems, CHI 2017 ; Conference Date: 6 May 2017 Through 11 May 2017; Conference Code:127654</p>","","","Deep learning; Search engines; Chatbot; Social media; Social networking (online); State of the art; Human engineering; Sales; Customer services; Automatic evaluation; Conversational systems; Human judgments; Learning techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3LIVN9P","journalArticle","2017","Alvarez-Fernandez, S.; Brown, H.R.; Zhao, Y.; Raithel, J.A.; Bishop, S.L.; Kern, S.B.; Lord, C.; Petkova, E.; Di Martino, A.","Perceived social support in adults with autism spectrum disorder and attention-deficit/hyperactivity disorder","Autism Research","","19393792","10.1002/aur.1735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019558593&doi=10.1002%2faur.1735&partnerID=40&md5=e545d47342863040e107738960f8fe69","Perceived social support (PSS) has been related to physical and mental well-being in typically developing individuals, but systematic characterizations of PSS in autism spectrum disorder (ASD) are limited. We compared self-report ratings of the multidimensional scale of PSS (MSPSS) among age- and IQ-matched groups of adults (18–58 years) with cognitively high-functioning ASD (N = 41), or attention-deficit/hyperactivity disorder (ADHD; N = 69), and neurotypical controls (NC; N = 69). Accompanying group comparisons, we used machine learning random forest (RF) analyses to explore predictors among a range of psychopathological and socio-emotional variables. Relative to both ADHD and NC, adults with ASD showed lower MSPSS ratings, specifically for the friends subscale (MSPSS-f). Across ASD and ADHD, interindividual differences in autism severity, affective empathy, symptoms of anxiety related to social interactions, hyperactivity/impulsivity, and somatization best predicted MSPSS-f. These relationships did not differ between clinical groups. While group comparisons demonstrated greater impairment in individuals with ASD, analyzing individuals' characteristics revealed cross-diagnoses similarities in regard to their MSPSS-f relationships. This is consistent with the Research Domain Criteria framework, supporting a trans-diagnostic approach as on the path toward “precision medicine.” Autism Res 2017, 10: 866–877. © 2017 International Society for Autism Research, Wiley Periodicals, Inc. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","866-877","","5","10","","","","","","","","","","English","","","","","","","Publisher: John Wiley and Sons Inc.","<p>cited By 4</p>","","","Adult; Female; Humans; Male; Young Adult; Middle Aged; social cognition; New York; emotion; empathy; autism; social interaction; psychology; perceived social support; Autism Spectrum Disorder; human; adult; female; major clinical study; male; Article; young adult; controlled study; priority journal; adolescent; Adolescent; middle aged; self report; social support; mental disease; Self Report; anxiety disorder; attention deficit disorder; Attention Deficit Disorder with Hyperactivity; disease severity; impulsiveness; New York City; Social Support; somatization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5RJNR7S","journalArticle","2017","Jarvis, L.","The Ethics of Mislocalized Selfhood: Proprioceptive drifting towards the virtual other","Performance Research","","13528165","10.1080/13528165.2017.1348587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029772572&doi=10.1080%2f13528165.2017.1348587&partnerID=40&md5=c0fc49b30428a3e8f4e132804abaebbd","In Psychology, ‘proprioceptive drift’ is a term that originates from the rubber hand illusion paradigm to describe the ‘relative displacement of the perceived location of one’s own hand toward the location of the rubber hand’ (Wold et al, 2014). Correspondingly, drift measurements in science are used as a means of rating the intensity of a body-ownership illusion via which a participant in a controlled experiment perceives that an extracorporeal appendage, or virtual whole-body avatar is incorporated as part of one’s own body schema. In this research article, I will examine an applied performance by BeAnotherLab utilising the anti-disciplinary collective’s The Machine to Be Another as part of Good Chance’s Encampment project–this telepresence system produces a VR body illusion intended to increase empathy and reduce proximity between an immersant’s real body and that of a volunteer refugee counterpart. When scientifically-tested body illusions cross a paradigmatic boundary to be framed as immersive art, what are the ethical implications? Furthermore, are these kinds of virtual proprioceptive transactions across different kinds of social and political boundaries symptomatic of radical empathic acts, or a capitalistic desire for the acquisition of another’s experiences by virtual means? This article examines illusory bodily inhabitation through a Levinasian critical lens to consider the ethics of deterritorializing the immersant’s gaze and referring their sense of touch elsewhere to produce ‘narrative immersion’. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","30-37","","3","22","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65YW2VAN","conferencePaper","2017","Hieida, C.; Nagai, T.","A model of emotion for empathic communication","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4885-0","","10.1145/3029798.3038299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016441933&doi=10.1145%2f3029798.3038299&partnerID=40&md5=983067b86cb469361136f28943794500","Most people believe that robots have no emotions, and nor do they need them. However, we strongly believe that having emotions is essential for robots to understand and sympathize with the feelings of people, thereby allowing them to be accepted into the human society. In this paper, we propose a model of emotion based on some neurological and psychological findings concerning empathic communication between humans and robots. Then, we examine a method for generating affect for given visual stimuli using a recurrent neural network as a first step. © 2017 Authors.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","133-134","","","","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 3; Conference of 12th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2017 ; Conference Date: 6 March 2017 Through 9 March 2017; Conference Code:126657</p>","","","Robots; Human robot interaction; Man machine systems; Human society; Recurrent neural networks; Attention model; Visual stimulus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V9T5JJP6","journalArticle","2017","Stein, J.-P.; Ohler, P.","Venturing into the uncanny valley of mind—The influence of mind attribution on the acceptance of human-like characters in a virtual reality setting","Cognition","","00100277","10.1016/j.cognition.2016.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007427341&doi=10.1016%2fj.cognition.2016.12.010&partnerID=40&md5=4590f308a7dbb4a4bf03c17f438e106b","For more than 40 years, the uncanny valley model has captivated researchers from various fields of expertise. Still, explanations as to why slightly imperfect human-like characters can evoke feelings of eeriness remain the subject of controversy. Many experiments exploring the phenomenon have emphasized specific visual factors in connection to evolutionary psychological theories or an underlying categorization conflict. More recently, studies have also shifted away focus from the appearance of human-like entities, instead exploring their mental capabilities as basis for observers' discomfort. In order to advance this perspective, we introduced 92 participants to a virtual reality (VR) chat program and presented them with two digital characters engaged in an emotional and empathic dialogue. Using the same pre-recorded 3D scene, we manipulated the perceived control type of the depicted characters (human-controlled avatars vs. computer-controlled agents), as well as their alleged level of autonomy (scripted vs. self-directed actions). Statistical analyses revealed that participants experienced significantly stronger eeriness if they perceived the empathic characters to be autonomous artificial intelligences. As human likeness and attractiveness ratings did not result in significant group differences, we present our results as evidence for an “uncanny valley of mind“ that relies on the attribution of emotions and social cognition to non-human entities. A possible relationship to the philosophy of anthropocentrism and its “threat to human distinctiveness” concept is discussed. © 2016 Elsevier B.V.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","43-50","","","160","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 42</p>","","","Adult; Female; Humans; Male; Young Adult; perception; artificial intelligence; User-Computer Interface; social cognition; Theory of Mind; Emotions; emotion; Cognition; cognition; Empathy; empathy; virtual reality; theory of mind; Social Perception; human; human experiment; adult; female; male; Article; normal human; young adult; human relation; Interpersonal Relations; controlled study; priority journal; character; computer interface; psychological theory; social acceptance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DEWNKKSA","journalArticle","2017","Conway, J.R.; Lee, D.; Ojaghi, M.; Catmur, C.; Bird, G.","Submentalizing or mentalizing in a level 1 perspective-taking task: A cloak and goggles test","Journal of Experimental Psychology: Human Perception and Performance","","00961523","10.1037/xhp0000319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001065631&doi=10.1037%2fxhp0000319&partnerID=40&md5=4574eab974dd54505c02084899d36262","It has been proposed that humans possess an automatic system to represent mental states ('implicit mentalizing'). The existence of an implicit mentalizing system has generated considerable debate however, centered on the ability of various experimental paradigms to demonstrate unambiguously such mentalizing. Evidence for implicit mentalizing has previously been provided by the 'dot perspective task,' where participants are slower to verify the number of dots they can see when an avatar can see a different number of dots. However, recent evidence challenged a mentalizing interpretation of this effect by showing it was unaltered when the avatar was replaced with an inanimate arrow stimulus. Here we present an extension of the dot perspective task using an invisibility cloaking device to render the dots invisible on certain trials. This paradigm is capable of providing unambiguous evidence of automatic mentalizing, but no such evidence was found. Two further well-powered experiments used opaque and transparent goggles to manipulate visibility but found no evidence of automatic mentalizing, nor of individual differences in empathy or perspective-taking predicting performance, contradicting previous studies using the same design. The results cast doubt on the existence of an implicit mentalizing system, suggesting that previous effects were due to domain-general processes. © 2016 The Author(s).","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","454-465","","3","43","","","","","","","","","","English","","","","","","","Publisher: American Psychological Association Inc.","<p>cited By 34</p>","","","Adult; Female; Humans; Male; Young Adult; Middle Aged; Theory of Mind; physiology; theory of mind; human; adult; female; male; young adult; adolescent; Adolescent; middle aged; vision; psychomotor performance; Psychomotor Performance; Visual Perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DW9AYDG5","conferencePaper","2017","Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.","A laughing-driven pupil response system for inducing empathy","SII 2016 - 2016 IEEE/SICE International Symposium on System Integration","978-1-5090-3329-4","","10.1109/SII.2016.7844051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015395679&doi=10.1109%2fSII.2016.7844051&partnerID=40&md5=79e71dbc5d0d655d939d8f50b2639752","Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy. © 2016 IEEE.","2017","2021-05-19 13:26:35","2021-05-19 13:26:35","","520-525","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 2016 IEEE/SICE International Symposium on System Integration, SII 2016 ; Conference Date: 13 December 2016 Through 15 December 2016; Conference Code:126401</p>","","","Human robot interaction; Media representation; Pupil response; Robot interactions; Affective response; Human interactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IT5439E","journalArticle","2017","De Carolis, B.; Ferilli, S.; Palestra, G.","Simulating empathic behavior in a social assistive robot","Multimedia Tools and Applications","","13807501","10.1007/s11042-016-3797-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988691125&doi=10.1007%2fs11042-016-3797-0&partnerID=40&md5=3d3264938f9865faf7b3dd27a9d15393","When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user’s affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot’s affective state and, consequently, the most appropriate empathic behavior. The robot’s empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot. © 2016, Springer Science+Business Media New York.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","5073-5094","","4","76","","","","","","","","","","English","","","","","","","Publisher: Springer New York LLC","<p>cited By 15</p>","","","Hardware; Affective Computing; Empathy; Robots; Affective state; Facial Expressions; Assistive robots; Ambient assisted living (AAL); Elderly users; Multimedia systems; Task-oriented","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCGBWBXG","journalArticle","2017","Chan, Z.C.Y.","Poetry writing and artistic ability in problem-based learning","International Journal on Disability and Human Development","","21911231","10.1515/ijdhd-2016-0003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb","Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","37-44","","1","16","","","","","","","","","","English","","","","","","","Publisher: Walter de Gruyter GmbH","<p>cited By 2</p>","","","writing; empathy; nursing; teaching; literature; creativity; human; clinical article; content analysis; follow up; Hong Kong; interview; long term memory; narrative; problem based learning; professional knowledge; stress management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBVJIDKV","conferencePaper","2017","Hervas, R.; Johnson, E.; Franca, C.G.L.D.L.; Bravo, J.; Mondejar, T.","A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars","Proceedings - 2016 15th International Conference on Ubiquitous Computing and Communications and 2016 8th International Symposium on Cyberspace and Security, IUCC-CSS 2016","978-1-5090-5566-1","","10.1109/IUCC-CSS.2016.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015234516&doi=10.1109%2fIUCC-CSS.2016.021&partnerID=40&md5=fdd98a86252b4919bd70a2d0688561f0","Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability. © 2016 IEEE.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","93-100","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of 15th International Conference on Ubiquitous Computing and Communications and 2016 8th International Symposium on Cyberspace and Security, IUCC-CSS 2016 ; Conference Date: 14 December 2016 Through 16 December 2016; Conference Code:126070</p>","","","Health; Serious games; Affective Computing; Computers; Learning algorithms; Learning systems; Physical health; Avatar interaction; Information use; Social communications; Ubiquitous computing; Down syndrome; Health systems; Intellectual disability; Real applications","","Georgalas N., Ray I., Jin Q., Garcia-Blas J., Carretero J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPRSZF8H","conferencePaper","2017","Lewandowska-Tomaszczyk, B.; Wilson, P.A.","Compassion, empathy and sympathy expression features in affective robotics","7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings","978-1-5090-2645-6","","10.1109/CogInfoCom.2016.7804526","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2","The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","65-70","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 10; Conference of 7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 ; Conference Date: 16 October 2016 Through 18 October 2016; Conference Code:125734</p>","","","Robotics; emotions; empathy; expressiveness; action tendencies; British English; compassion; empatia; GRID; responsiveness; sympathy; sympatia; valence; Corpus linguistics; False negatives; False positive; Polishing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RA7Z6V5N","journalArticle","2017","Johnson, E.; Hervás, R.; Gutiérrez-López-Franca, C.; Mondéjar, T.; Bravo, J.","Analyzing and Predicting Empathy in Neurotypical and Nonneurotypical Users with an Affective Avatar","Mobile Information Systems","","1574017X","10.1155/2017/7932529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021665183&doi=10.1155%2f2017%2f7932529&partnerID=40&md5=56f1d3d19d1da916c8444885ffcfd4a1","In recent times, diagnosing and treating different health issues have improved greatly with the help of technology, with an example being cognitive health issues. Despite this, there is still a difference between how the technology is working towards it and the actual potential that can be achieved. In this paper, we propose a mobile application with an affective avatar, encompassed in the area of serious games, which will obtain information related to the interactions performed by the users. There are a total of 50 users, of neurotypical and nonneurotypical backgrounds, with the latter being people with Down syndrome and intellectual disability. Based on collected data from the different users interacting with the avatar in a mobile device, we analyzed the results to obtain a ground truth about prototypic empathic interactions and feed those interactions to a learning algorithm to support the diagnosis process and therapy treatment of empathy and socialization issues. © 2017 Esperanza Johnson et al.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","","","","2017","","","","","","","","","","English","","","","","","","Publisher: Hindawi Limited","<p>cited By 2</p>","","","Serious games; Mobile devices; Mobile applications; Down syndrome; Intellectual disability; Ground truth; Health issues; Therapy treatment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HTTGGIZR","journalArticle","2017","Woo, J.; Botzheim, J.; Kubota, N.","Emotional empathy model for robot partners using recurrent spiking neural network model with Hebbian-LMS learning","Malaysian Journal of Computer Science","","01279084","10.22452/mjcs.vol30no4.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036526555&doi=10.22452%2fmjcs.vol30no4.1&partnerID=40&md5=7bf71955acddbdefa5deeff07d6d74dc","This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply ""Hebbian-LMS"" learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner ""iPhonoid-C"". Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","258-285","","4","30","","","","","","","","","","English","","","","","","","Publisher: Faculty of Computer Science and Information Technology","<p>cited By 8</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAEEMYL6","journalArticle","2017","May, A.D.; Lotfi, A.; Langensiepen, C.; Lee, K.; Acampora, G.","Human emotional understanding for empathetic companion robots","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-46562-3_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988564419&doi=10.1007%2f978-3-319-46562-3_18&partnerID=40&md5=9ef257c0045567a9e3e6ec41998bc780","Companion robots are becoming more common in home environments, as such a greater emphasis is required on analysis of human behaviour. An important aspect of human behaviour is emotion, both the ability to express and comprehend. While humans have developed excellent skills in inferring the emotional states of their counterparts via implicit cues such as facial expression and body language, this level of understanding is often neglected in Human Robot Interactions; furthermore, humans are able to empathetically respond to the emotions of others to create amore harmonious and person relationship. This paper is a preliminary proposal of a novel approach for facial emotional detection and appropriate empathetic responses, in conjunction with long term emotion mapping and prediction; the proposed system will be implemented on a social mobile robot, thus allowing a further level of behavioural comprehension to achieve a more human like encounter. The technique will be based on Fuzzy Cognitive Maps, using FACS Action Units as inputs, a high level facial descriptor layer and output of six emotions. © Springer International Publishing AG 2017.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","277-285","","","513","","","","","","","","","","English","","","","","","","ISBN: 9783319465616 Publisher: Springer Verlag","<p>cited By 3; Conference of 16th UK Workshop on Computational Intelligence, UKCI 2016 ; Conference Date: 7 September 2016 Through 9 September 2016; Conference Code:181569</p>","","","Artificial intelligence; Robots; Companion robot; Human robot interaction; Emotional state; Facial Expressions; Behavioral research; Body language; Social sciences; Human behaviours; Fuzzy inference; Action Unit; Computer keyboards; Fuzzy cognitive map; Home environment","","Gegov A., Angelov P., Jayne C., Shen Q.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8C3JWRQ","journalArticle","2017","Boella, L.","How to do the best without emotions?","Notizie di Politeia","","11282401","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031102019&partnerID=40&md5=02472ddee9b8e3ba675d6a7b498143df","From the richness of Harris' consideration of the main aspects of the contemporary debate - the nature of good, the question of the ""human"", post-human and of non-human animals, of freedom as being master of our lives, of Artificial Intelligence - I draw out the building block of the morality as ""trying to be good"". To be a good person implies insight, sympathy, empathy, understanding and knowledge to build clear ideas of what might conduce to the good.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","184-186","","127","33","","","","","","","","","","English","","","","","","","Publisher: Tipolito Subalpina","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7E8EWHWM","journalArticle","2017","Aljaroodi, H.M.; Adam, M.T.P.; Chiong, R.; Cornforth, D.J.; Minichiello, M.","Empathic avatars in stroke rehabilitation: A co-designed mhealth artifact for stroke survivors","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-59144-5_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020376567&doi=10.1007%2f978-3-319-59144-5_5&partnerID=40&md5=e05e96d7ef5e376b2f2f8da66f791986","Stroke is the second highest cause of death and disability worldwide. While rehabilitation programs are intended to support stroke survivors, and promote recovery after they leave the hospital, current rehabilitation programs typically provide only static written instructions and lack the ability to keep them engaged with the program. In this design science research paper, we present an mHealth artifact that builds on behavior change theory to increase stroke survivors’ engagement in rehabilitation programs. We employed a co-design methodology to identify design requirements for the stroke rehabilitation mHealth artifact, addressing stroke survivors’ needs and incorporating expertise of healthcare providers. Guided by these requirements, we developed design principles for the artifact pertaining to visual assets that are essential in immersing users in the design. We carried out a two-stage development process by having workshops and interviews with experts. Following this, a prototype was developed and evaluated in a series of workshops with multiple stakeholders. © Springer International Publishing AG 2017.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","73-89","","","10243 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319591438 Publisher: Springer Verlag","<p>cited By 5; Conference of 12th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2017 ; Conference Date: 30 May 2017 Through 1 June 2017; Conference Code:192279</p>","","","mHealth; Health care; Design; Multiple stakeholders; Co-design methodology; Co-designs; Design-science researches; Empathic avatars; Health care providers; Neuromuscular rehabilitation; Rehabilitation programs; Stroke rehabilitation","","Hevner A., Maedche A., vom Brocke J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AF4UVUD","conferencePaper","2017","Narayanan, S.; Bukvic, I.I.","Cinemacraft: Immersive live machinima as an empathetic musical storytelling platform","2017 ICMC/EMW - 43rd International Computer Music Conference and the 6th International Electronic Music Week","978-0-9845274-6-5","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040091347&partnerID=40&md5=597b32a63d29a48aeb9aa031548a605e","In the following paper we present Cinemacraft, a technologymediated immersive machinima platform for collaborative performance and musical human-computer interaction. To achieve this, Cinemacraft innovates upon a reverse-engineered version of Minecraft, offering a unique collection of live machinima production tools and a newly introduced Kinect HD module that allows for embodied interaction, including posture, arm movement, facial expressions, and a lip syncing based on captured voice input. The result is a malleable and accessible sensory fusion platform capable of delivering compelling live immersive and empathetic musical storytelling that through the use of low fidelity avatars also successfully sidesteps the uncanny valley. © 2016.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","384-389","","","","","","","","","","","Shanghai Conservatory of Music","","English","","","","","","","","<p>cited By 0; Conference of 43rd International Computer Music Conference, ICMC 2017 and the 6th International Electronic Music Week, EMW 2017 ; Conference Date: 15 October 2017 Through 20 October 2017; Conference Code:131926</p>","","","Uncanny valley; Facial Expressions; Human computer interaction; Low fidelities; Embodied interaction; Arm movements; Collaborative performance; Computer music; Production tools; Sensory fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TD7PTSNQ","journalArticle","2017","Chumkamon, S.; Hayashi, E.","Consciousnes-based emotion and behavior of pet robot with brain-inspired method","Information (Japan)","","13434500","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1","A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","615-629","","1","20","","","","","","","","","","English","","","","","","","Publisher: International Information Institute Ltd.","<p>cited By 0</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V72RVEC5","conferencePaper","2017","Silvey, P.E.","Leveling up: Strategies to achieve integrated cognitive architectures","AAAI Fall Symposium - Technical Report","978-1-57735-794-0","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044476959&partnerID=40&md5=09dc018b9aa3ed3c09f13c6428cf44b4","Human-level cognition (most uniquely characterized by our abilities to use language) should be seen as a superset of functional and behavioral capabilities shared by lower life-forms including animals and insects, and this perspective ought to principally guide our strategies for developing integrated cognitive architectures. Just as the study of biological model organisms has led to tremendous advances in our scientific knowledge of genetics and cellular function, the study of embodied cognition in simple agent-environment simulations can yield similar advances in Cognitive Science, Artificial Intelligence, and Robotics. By working first on the foundations of intelligent interaction with one's environment, and by focusing on core functions such as predictive and inductive learning, probabilistic goal-directed behavior compilation, and empathetic reasoning, we can better establish the grounding that the physical symbol system hypothesis assumes (Newell and Simon 1976), yet often without explicit demonstration of a mechanism to derive symbolic relations and semantics from raw sensory data. Logic and language are seen to emerge from our willingness to make discrete simplifying assumptions in a continuous and probabilistic world of experience, and developing a Standard Model of the Mind can help build much-needed bridges between historically nonaligned research communities. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","460-465","","","FS-17-01 - FS-17-05","","","","","","","","AI Access Foundation","","English","","","","","","","","<p>cited By 0; Conference of 2017 AAAI Fall Symposium ; Conference Date: 9 November 2017 Through 11 November 2017; Conference Code:134706</p>","","","Semantics; Artificial intelligence; Human robot interaction; Cognitive architectures; Intelligent robots; Cognitive systems; Research communities; Bioinformatics; Biological modeling; Environment simulation; Intelligent interactions; Military applications; Probabilistic goals; Public risks; Scientific knowledge; Simplifying assumptions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6FFXJCS","journalArticle","2017","Cho, H.-K.; Oh, J.; Lee, K.","A study on the potential roles of a robot peer in socio-emotional development of children","International Journal of Computational Vision and Robotics","","17529131","10.1504/IJCVR.2017.083447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b","This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","335-343","","3","7","","","","","","","","","","English","","","","","","","Publisher: Inderscience Publishers","<p>cited By 1</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXHF3ZMJ","journalArticle","2017","Wood, H.","Dynamic Syuzhets: Writing and Design Methods for Playable Stories","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-71027-3_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035121361&doi=10.1007%2f978-3-319-71027-3_3&partnerID=40&md5=03d42098fb334fd285b1d1f0ee7e3a53","The holodeck vision of the future of Interactive Digital Storytelling (IDS) assumes a world that reacts around players as story protagonists; but, we have seen how this approach faces challenges in negotiating the delivery of narrative affect and player agency within current technological and Artificial Intelligence (AI) realities. By approaching the field through creative writing practice, this paper argues that casting players as experience—rather than story—protagonists, has proved an effective alternate means of writing and designing for Playable Stories. Through close analysis of the growing Story Exploration Game genre and comparison with interactive theatre, four new terms—the dynamic syuzhet, authored fabula, fixed syuzhet and improvised fabula—are introduced to show how writing and designing for players as experience protagonists can negotiate the needs of narrative and player agency, provide means to combine mimetic and diegetic player experiences, pair self-directed and empathic engagement, and offer opportunities to use dramatic irony—a cornerstone of narrative drive in other storytelling forms that is unexploited in interactive storytelling. The study that formed the basis of this paper was driven by the question of how writers can develop practice within the current constraints of the form and informed the development of my own indie video game Underland. © 2017, Springer International Publishing AG.","2017","2021-05-19 13:26:36","2021-05-19 13:26:36","","24-37","","","10690 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319710266 Publisher: Springer Verlag","<p>cited By 1; Conference of 10th International Conference on Interactive Digital Storytelling, ICIDS 2017 ; Conference Date: 14 November 2017 Through 17 November 2017; Conference Code:205609</p>","","","Human computer interaction; Video game; Interactive computer graphics; Theaters; Immersive; Authored fabula; Creative writings; Diegetic; Dramatic irony; Experience protagonists; Experiential narratives; Fixed syuzhet; Improvised fabula; Interactive narrative; Interactive storytelling; Interactive theatre; Mimetic; Narratology; Playable stories; Player agency; Player roles; Players; Story Exploration Games","","Nunes N., Oakley I., Nisi V.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3VEZNKK2","journalArticle","2017","Smith, S.J.; Stone, B.T.; Ranatunga, T.; Nel, K.; Ramsoy, T.Z.; Berka, C.","Neurophysiological indices of human social interactions between humans and robots","Communications in Computer and Information Science","","18650929","10.1007/978-3-319-58750-9_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025174844&doi=10.1007%2f978-3-319-58750-9_36&partnerID=40&md5=a79ac8fdcd00acc223e0c6708767cf68","Technology continues to advance at exponential rates and we are exposed to a multitude of electronic interfaces in almost every aspect of our lives. In order to achieve seamless integration of both, human and technology, we must examine the objective and subjective responses to such interactions. The goal of this study was to examine neurophysiological responses to movement, communication, and usability with a robot assistant, in comparison to human assistant, in a real-world setting. OSHbot (robot assistants designed by Fellow Robots) were utilized as mobile store clerks to identify and locate merchandise in order to assist customers in finding items within a hardware store. By acquiring neurophysiological measures (electroencephalogram; EEG and electrocardiogram; ECG) of human perception and interaction with robots, we found evidence of Mirror Neuron System (MNS) elicitation and motor imagery processing, which is consistent with other studies examining human-robot interactions. Multiple analyses were conducted to assess differences between human-human interaction and human-robot interaction. Several EEG metrics were identified that were distinguishable based on interaction type; among these was the change observed across the Mu bandwidth (8–13 Hz). The variance in this EEG correlate has been related to empathetic state change. In order to explore differences in the interactions related to gender and age additional analyses were conducted to compare the effects of human-human interaction versus human-robot interaction with data stratified by gender and age. This analysis yielded significant differences across these categories between human-human interaction and human-robot interaction within EEG metrics. These preliminary data show promise for future research in the field of human-robot relations in contributing to the design and implementation of machines that not only deliver basic services but also create a social connection with humans. © Springer International Publishing AG 2017.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","251-262","","","713","","","","","","","","","","English","","","","","","","ISBN: 9783319587493 Publisher: Springer Verlag","<p>cited By 1; Conference of 19th International Conference on Human-Computer Interaction, HCI International 2017 ; Conference Date: 9 July 2017 Through 14 July 2017; Conference Code:194249</p>","","","Neurophysiology; Electroencephalography; Robots; Human robot interaction; Eye-tracking; Man machine systems; Machine design; Human-human interactions; Human computer interaction; Social interactions; Social sciences; Human social interactions; Electrocardiography; Design and implementations; Bandwidth; Electronic interface; Neurophysiological measures; Seamless integration","","C, Stephanidis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXFA3R2J","conferencePaper","2017","Martelaro, N.; Ju, W.","DJ Bot: Needfinding machines for improved music recommendations","AAAI Spring Symposium - Technical Report","978-1-57735-779-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028726782&partnerID=40&md5=d4d0bf5c9e0929a571855a0f22722c16","Modern-day music streaming services with huge music catalogs have the ability to track all of a user's interactions. Still, with all of this information on user behavior, music recommendation algorithms have little understanding of the meaningful choices that a listener makes when choosing music. To explore how to develop machine learning systems that can understand and empathize with people, we are working to merge user experience design methods with interactive technologies. We are exploring how designers can interact with people through an interactive music agent, DJ Bot, in order to elicit meaningful stories from listeners and to see how this information can inform music recommendation services. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","419-422","","","SS-17-01 - SS-17-08","","","","","","","","AI Access Foundation","","English","","","","","","","","<p>cited By 2; Conference of 2017 AAAI Spring Symposium ; Conference Date: 27 March 2017 Through 29 March 2017; Conference Code:129736</p>","","","Artificial intelligence; Learning systems; Computer aided design; Behavioral research; Interactive technology; Interactive music; Machine oriented languages; Music recommendation; Music streaming; User behaviors; User experience design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GV96CERC","journalArticle","2017","Pareto, L.","Robot as tutee","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-42975-5_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992630713&doi=10.1007%2f978-3-319-42975-5_24&partnerID=40&md5=e264311b65af2af8a876f39767155c2f","This paper explores the possible advantages of substituting teachable agents in a learning environment, with a humanoid robot as the non-human tutee. Teachable agents are used as an extension to educational games in order to leverage engagement, reflection and learning. The learning environment is engaging and shown to be effective for learning and promote self-efficacy in experimental studies in authentic classroom settings. Features beneficial for learning which are further enhanced by a robot compared to an agent are identified. These include embodiment of the robot; a social, empathic behaviour, better conversational abilities which together provide a better role model of an ideal learner for the student to identify with. © Springer International Publishing Switzerland 2017.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","271-277","","","457","","","","","","","","","","English","","","","","","","ISBN: 9783319429748 Publisher: Springer Verlag","<p>cited By 2; Conference of 7th International Conference on Robotics in Education, RiE 2016 ; Conference Date: 14 April 2016 Through 15 April 2016; Conference Code:184879</p>","","","Robotics; Education; Robots; Humanoid robot; Learning environments; Teaching; Anthropomorphic robots; Education computing; Computer aided instruction; Classroom settings; Educational game; Role model; Self efficacy; Teachable agents; Tutoring","","Balogh R., Koppensteiner G., Merdan M., Lepuschitz W.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PZWT5IU","journalArticle","2017","Fan, L.; Scheutz, M.; Lohani, M.; McCoy, M.; Stokes, C.","Do we need emotionally intelligent artificial agents? First results of human perceptions of emotional intelligence in humans compared to robots","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-67401-8_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029009078&doi=10.1007%2f978-3-319-67401-8_15&partnerID=40&md5=40847ef441d91c4b0c0d33b427b6059c","Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent’s emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them. © Springer International Publishing AG 2017.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","129-141","","","10498 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319674001 Publisher: Springer Verlag","<p>cited By 10; Conference of 17th International Conference on Intelligent Virtual Agents, IVA 2017 ; Conference Date: 27 August 2017 Through 30 August 2017; Conference Code:197079</p>","","","Robots; Emotional intelligence; Human robot interaction; Artificial agents; Machine design; Intelligent virtual agents; Social interactions; Non-verbal communications; Behavioral research; Intelligent robots; Human perception; Communication method","","O'Sullivan C., Leite I., Castellano G., Kopp S., Beskow J., Peters C.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YC62MZ6E","conferencePaper","2017","Siddique, F.B.; Kampman, O.; Yang, Y.; Dey, A.; Fung, P.","Zara returns: Improved personality induction and adaptation by an empathetic virtual agent","ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of System Demonstrations","978-1-945626-71-5","","10.18653/v1/P17-4021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052687243&doi=10.18653%2fv1%2fP17-4021&partnerID=40&md5=f0341b600ebcf2bba61e84de3bbd93b2","Virtual agents need to adapt their personality to the user in order to become more empathetic. To this end, we developed Zara the Supergirl, an interactive empathetic agent, using a modular approach. In this paper, we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks. From raw audio, an average F-score of 69.6 was obtained from real-time personality assessment using a Convolutional Neural Network (CNN) model. From text, we improved personality recognition results with a CNN model on top of pre-trained word embeddings and obtained an average F-score of 71.0. Results from our Human-Agent Interaction study confirmed our assumption that people have different agent personality preferences. We use insights from this study to adapt our agent to user personality. © 2017 Association for Computational Linguistics","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","121-126","","","","","","","","","","","Association for Computational Linguistics (ACL)","","English","","","","","","","","<p>cited By 7; Conference of 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017 ; Conference Date: 30 July 2017 Through 4 August 2017; Conference Code:132945</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZ9ZIVQG","journalArticle","2017","Shimada, T.; Sakurai, A.","Recognition of empathy seeking questions in one of the largest woman CQA in Japan","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-54472-4_60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018617990&doi=10.1007%2f978-3-319-54472-4_60&partnerID=40&md5=001e186fe5d53db5baeeab37adfd42ee","Many questions are posted on community websites in the world. Some of these questions are actually asked in order to receive empathy for the feelings of questioners, instead of getting specific answers to the questions asked. However, it is difficult to receive answers for these questions compared with questions that are asked for seeking responses other than for empathy. If such questions that are asked for the purpose of receiving empathy can get responses, it serves as an important factor to increase satisfaction of users. This paper reports on our attempt to improve response rate to the questions by classifying those questions that are asked for seeking empathy and those that are not by using machine learning and showing the questions classified as the ones seeking empathy to the prospective respondents who have been answered to these questions with higher rate. © Springer International Publishing AG 2017.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","641-650","","","10191 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319544717 Publisher: Springer Verlag","<p>cited By 0; Conference of 9th Asian Conference on Intelligent Information and Database Systems, ACIIDS 2017 ; Conference Date: 3 April 2017 Through 5 April 2017; Conference Code:190369</p>","","","Artificial intelligence; Community; Learning systems; Database systems; Response rate","","Tojo S., Trawinski B., Nguyen L.M., Nguyen N.T.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FYPEQ7KH","conferencePaper","2017","De Carolis, B.; Ferilli, S.; Palestra, G.; Redavid, D.","Emotion-recognition from speech-based interaction in AAL environment","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016315295&partnerID=40&md5=48d39fe986e3c8fb67cf9285e325457c","In Ambient Assisted Living environments assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. To this aim social assistive robots are being employed as a mediator interface and, in order to achieve a relation with the user, they should be endowed with the capability of recognizing the user affective state. Since a natural way to interact with a robot is speech, spoken user's input can be used to give to the robot the capability of recognizing the emotions and attitude of the user, thus providing more detail information about the user state. This paper focuses on this topic and proposes an approach based on the dimensional model of emotions in which the valence and arousal of user's spoken input are recognized. The experimental analysis shows the performance in terms of accuracy of the proposed approach on an Italian dataset. In order to show its application in the context of Ambient Assisted Living, an example is provided. © 2017, CEUR-WS. All rights reserved.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","92-104","","","1803","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 1; Conference of 2nd Italian Workshop on Artificial Intelligence for Ambient Assisted Living, AI*AAL.it 2016 ; Conference Date: 28 November 2016; Conference Code:126783</p>","","","Artificial intelligence; Robots; Speech recognition; Ambient assisted living; Affective state; Assistive robots; Deep neural networks; Assisted living; ITS applications; Ambient intelligence; Task-oriented; Emotion recognition from speech; Interface states; Dimensional model; Experimental analysis","","Bandini S., Cortellessa G., Palumbo F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6APE8V7A","conferencePaper","2017","Ramaswamy, N.; MacDonald, E.","Telepathic product design for water conservation","Proceedings of the International Conference on Engineering Design, ICED","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029740073&partnerID=40&md5=0f5e5840bdf2bc50fe33cc19d5ccde90","Can a product that reads the user's mind behave more efficiently and eventually train the user to conserve? Here, as a first step to answering this big question, we present a design method for telepathic products applied to the case study of a kitchen faucet. The case study is used to illustrate the different steps of the design method: (A) Build cognitive empathy and define cognitive styles; (B) Define design requirements, articulate variables that will control performance, understand limitations and design physical product; (C) Design the machine learning algorithm, inputs, and outputs; and (D) Integration and refinement. This work-in-progress report highlights the intricacies of applying adaptive machinelearning behavior to physical products performance in the ""real world"" rather than to a website or device such as a smart phone. Interesting findings include that automatic response, typically associated with websites and phones, is not possible with plumbing as water cannot be instantly at the right temperature; and that cognitive styles indeed manifest in dish washing observations, with distinctly different styles in terms of patience, temperature sensitivity, and laziness.","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","169-178","","","1","","","","","","","","Design Society","","English","","","","","","","ISSN: 22204334 Issue: DS87-1","<p>cited By 0; Conference of 21st International Conference on Engineering Design, ICED 2017 ; Conference Date: 21 August 2017 Through 25 August 2017; Conference Code:130265</p>","","","Ecodesign; Learning algorithms; Learning systems; Behavioral research; Product design; Automatic response; Cognitive styles; Control performance; Data visualization; Design method; Human behaviour in designs; Physical products; Smartphones; Telephone sets; Temperature sensitivity; User centered design; Water conservation; Websites; Work in progress","","Maier A.M., Van der Loos M., Skec S., Salustri F.A., Fadel G., Kim H., Kokkolaras M., Oehmen J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ALHSUEG","conferencePaper","2017","Gabriel, S.","Teaching human rights with video games?","Proceedings of the 11th European Conference on Games Based Learning, ECGBL 2017","978-1-911218-56-2","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036477671&partnerID=40&md5=e512018f6f44da07a412436d7d2a07c4","Serious games which deal with human rights topics have been on the rise for the last 15 years. Digital games show some unique properties that make them valuable for inducing social change. Some of the game elements that can be used to integrate values are as follows: Narration, which is one of the elements that is most obvious to players and is part of most of today's digital games, is a proper way of presenting human rights topics and can also include ideological messages. However, there are also other ways of creating empathy for certain groups as the example of Ayitii - The Cost of Life shows: If players feel responsible for the game characters, games can make players think about the topic presented. Being able to take meaningful decisions which influence the player's avatar, other non-playable characters, the narration or the game-world is a property of many recent games. Thus, ethical decisions are included in games and put players into the shoes of those who are oppressed or put in other situations where there is no easy way of deciding if something is right or wrong. Finally, the article also discusses if these serious games can affect players' real lives and change their way of thinking and attitudes. The serious game This War of Mine shows that some players think about their decisions and the topic of the game even after having stopped playing. However, there are also restrictions to transferring game contents into players' lives and induce social change. Quite often it is not enough just to play the game, teaching which must take place in a non-game context, is needed to make players aware of human rights (violations).","2017","2021-05-19 13:26:37","2021-05-19 13:26:37","","191-196","","","","","","","","","","","Academic Conferences and Publishing International Limited","","English","","","","","","","","<p>cited By 2; Conference of 11th European Conference on Games Based Learning, ECGBL 2017 ; Conference Date: 5 October 2017 Through 6 October 2017; Conference Code:131756</p>","","","Serious games; Empathy; Human computer interaction; Digital games; Video game; Computer games; Interactive computer graphics; Social aspects; Game contents; Game elements; Human rights; Social changes","","Pivec M., Grundler J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRKQ6UAD","conferencePaper","2016","Ranieri, C.M.; Romero, R.A.F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","Proceedings - 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016","978-1-5090-3656-1","","10.1109/LARS-SBR.2016.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010416838&doi=10.1109%2fLARS-SBR.2016.13&partnerID=40&md5=48a1a71aed354854f322eb1a82dcc7eb","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness. © 2016 IEEE.","2016","2021-05-19 13:26:37","2021-05-19 13:26:37","","31-36","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 4; Conference of 13th Latin American Robotics Symposium and 4th Brazilian Symposium on Robotics, LARS/SBR 2016 ; Conference Date: 8 October 2016 Through 12 October 2016; Conference Code:125443</p>","","","Robotics; Emotions; Affective Computing; Robots; Social robots; Mobile devices; Human robot interaction; Man machine systems; Human computer interaction; Emotional reactions; Android applications; Embodied virtual agents; Facial expressions analysis; Interaction strategy","","Cavalcante S.V., Tonidandel F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMLRNIGX","conferencePaper","2016","Li, C.; Jia, Q.; Feng, Y.","Human-robot interactoin design for robot-assisted intervention for children with autism based on E-S theory","Proceedings - 2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics, IHMSC 2016","978-1-5090-0768-4","","10.1109/IHMSC.2016.103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010383454&doi=10.1109%2fIHMSC.2016.103&partnerID=40&md5=05714d20ecede922ba1256697ed3443b","The paper presents a novel human-robot interaction (HRI) framework to assist intervention for children with autism, based on Empathizing-Systemizing (E-S) theory. E-S theory explains the social difficulties in autism as the result of deficits or delays in empathizing, while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing. In this paper, the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robot-assisted intervention, which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism. The design of HRI scenarios and tasks based on E-S theory makes the robot-assisted intervention more effective and efficient. © 2016 IEEE.","2016","2021-05-19 13:26:37","2021-05-19 13:26:37","","320-324","","","2","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of 8th International Conference on Intelligent Human-Machine Systems and Cybernetics, IHMSC 2016 ; Conference Date: 11 September 2016 Through 12 September 2016; Conference Code:125444</p>","","","Robots; Social robots; Human robot interaction; Cybernetics; Man machine systems; Machine design; Diseases; Human robot Interaction (HRI); Human robots; S-theory; Children with autisms; Autism therapies; Patient rehabilitation; Empathizing-systemizing (E-S) theory; Nonsocial behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJNIZQLQ","conferencePaper","2016","Sin, Y.M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.-I.; Miyake, Y.","Evaluation of a head motion synchronization system in the communicative process between human and robot","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan, SICE 2016","978-4-907764-50-0","","10.1109/SICE.2016.7749252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263059&doi=10.1109%2fSICE.2016.7749252&partnerID=40&md5=ee5466b2a448823dac918c1ff6b6ac0e","An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation. © 2016 The Society of Instrument and Control Engineers - SICE.","2016","2021-05-19 13:26:37","2021-05-19 13:26:37","","1514-1519","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 55th Annual Conference of the Society of Instrument and Control Engineers of Japan, SICE 2016 ; Conference Date: 20 September 2016 Through 23 September 2016; Conference Code:124992</p>","","","Developing countries; Surveys; Robots; Synchronization; Human robot interaction; Communication robot; Human computer interaction; Human-robot communication; Questionnaire surveys; Aging population; Head motion; Interactive modeling; Smooth interface; Synchronization systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BM3USEV5","journalArticle","2016","Mazzei, D.; De Maria, C.; Vozzi, G.","Touch sensor for social robots and interactive objects affective interaction","Sensors and Actuators, A: Physical","","09244247","10.1016/j.sna.2016.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992151545&doi=10.1016%2fj.sna.2016.10.006&partnerID=40&md5=8730338685c619c51456cb3ee6c5b179","The recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human–robot affective interaction. Most of these sensors, implemented as matrix of pressure sensors, are rigid, cannot be fabricated in complex shapes, cannot be subjected to large deformations, and usually allow to capture only the contact event, without any information about the interaction context. This paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns. The sensor is made of alternate layers of sensitive and insulating silicone: the soft nature of the sensor makes it adaptable to complex and deformable bodies. The main features from electrical signals are extracted with the principal component analysis, and a self-organising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture. The results open to interesting applications, which span from toy manufacturing, to human-robot interaction, and even to sport and biomedical equipment and applications. © 2016","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","92-99","","","251","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 7</p>","","","Robots; Human robot interaction; Principal component analysis; Tactile interaction; Human computer interaction; Complex networks; Affective interaction; Biomedical equipment; Contact sensors; Deformable bodies; Deformation; Electrical signal; Interaction context; Interactive objects; Self-Organising Neural Networks; Silicones; Touch sensors; Toy manufacture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKB5JN3G","conferencePaper","2016","Ishii, Y.; Watanabe, T.; Sejima, Y.","Development of an embodied avatar system using avatar-Shadow's color expressions with an interaction-activated communication model","HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2980487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994531607&doi=10.1145%2f2974804.2980487&partnerID=40&md5=fa666452f49b11f978504b10566a6478","In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color. Copyright © 2016 ACM.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","337-340","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 4th International Conference on Human Agent Interaction, HAI 2016 ; Conference Date: 4 October 2016 Through 7 October 2016; Conference Code:124110</p>","","","Virtual reality; Color; Avatar's shadow; Communication modeling; Embodied interaction; Heat conduction; Heat conduction equations; Heat transfer; Information theory; Interactive effect; Mediated Communication; Three dimensional effect; Virtual faces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBDLP2WV","conferencePaper","2016","Shinohara, Y.; Yoshizaki, M.; Hirota, A.; Kubo, K.; Takahashi, T.; Nishizaki, Y.; Nozawa, M.; Hayakawa, H.; Oka, N.","The optimum rate of mimicry in human-agent interaction","HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2980506","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504917&doi=10.1145%2f2974804.2980506&partnerID=40&md5=70b81e79d7d310421854ec9ba648e898","The importance of building rapport between a human and an agent is increasing with the burgeoning development of robot technology. Several recent studies have focused on the chameleon effect, using psychological concepts to investigate human-agent interaction. However, the validity of the chameleon effect in human-agent interaction is controversial. Few studies have explored the influence of individual cognitive ability and the rate of mimicry on the human-agent interaction. We explored the optimal rate of mimicry and the relationship between mimicry rate and individual empathic ability. We controlled the amount of agent mimicry and examined the effect on participants classified as high- and low-perspective takers. We found that, overall, participants preferred agents that mimicked their behavior 83% of the time. Moreover, high-, but not low-, perspective takers tended to be influenced by the mimicry rate. Copyright © 2016 ACM.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","367-370","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 1; Conference of 4th International Conference on Human Agent Interaction, HAI 2016 ; Conference Date: 4 October 2016 Through 7 October 2016; Conference Code:124110</p>","","","Perspective taking; Human agent interactions; Robot technology; Cognitive ability; Human-Agent-Interaction; Mimicry; nocv1; Optimum rate; The chameleon effect","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWU6RW8E","journalArticle","2016","Mattan, B.D.; Rotshtein, P.; Quinn, K.A.","Empathy and visual perspective-taking performance","Cognitive Neuroscience","","17588928","10.1080/17588928.2015.1085372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953718172&doi=10.1080%2f17588928.2015.1085372&partnerID=40&md5=527ce22966ad81cb1010584fee7295be","This study examined the extent to which visual perspective-taking performance is modulated by trait-level empathy. Participants completed a third-person visual perspective-taking task in which they judged the perspectives of two simultaneously presented avatars, designated “Self” and “Other.” Depending on the trial, these avatars either held the same view (i.e., congruent) or a different view (i.e., incongruent). Analyses focused on the relationship between empathy and two perspective-taking phenomena: Selection between competing perspectives (i.e., perspective-congruence effects) and prioritization of the Self avatar’s perspective. Empathy was related to improved overall performance on this task and a reduced cost of selecting between conflicting perspectives (i.e., smaller perspective-congruence effects). This effect was asymmetric, with empathy (i.e., empathic concern) levels predicting reduced interference from a conflicting perspective, especially when adopting the Self (vs. Other) avatar’s perspective. Taken together, these results highlight the importance of the self–other distinction and mental flexibility components of empathy. © 2016 Taylor & Francis.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","170-181","","1-4","7","","","","","","","","","","English","","","","","","","Publisher: Psychology Press Ltd","<p>cited By 15</p>","","","Adult; Female; Humans; Male; Young Adult; perception; physiology; Empathy; empathy; Social Perception; clinical trial; human; adult; female; male; young adult; vision; psychomotor performance; Psychomotor Performance; Visual Perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PQZVLU6","journalArticle","2016","Chumkamon, S.; Hayashi, E.; Koike, M.","Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot","Biologically Inspired Cognitive Architectures","","2212683X","10.1016/j.bica.2016.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992027508&doi=10.1016%2fj.bica.2016.09.004&partnerID=40&md5=648a687454e6dd807ff6eafa3fbbcddd","Companion or 'pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross-communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like 'emotion' and based on emotional intelligence (EI) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. © 2016 Elsevier B.V. All rights reserved.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","51-67","","","18","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 13</p>","","","Behavior; Robots; Artificial consciousness; Emotional intelligence; Companion robot; Human robot interaction; Human computer interaction; Intelligent robots; Natural interactions; Adaptive resonance theory; Biologically inspired; Cognitive systems; Emotional interactions; Topology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PIJYAF6S","journalArticle","2016","Wiśniewska, M.; Grudowski, P.","High-quality academic teachers in business school. The case of The University of Gdańsk, Poland","Total Quality Management and Business Excellence","","14783363","10.1080/14783363.2015.1064766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936966560&doi=10.1080%2f14783363.2015.1064766&partnerID=40&md5=0db7256a03085c4e979fe572a2f1f6ea","The Bologna process, the increasing number of higher education institutions, the mass education and the demographic problems make the quality of education and quality of the academic teachers a subject of wide public debate and concern. The aim of the paper is to identify the most preferred characteristics of a teacher working at a business school. The research problem was: What should a high-quality business school academic teacher be like? During the research, a six-stage qualitative survey design was proposed, and a letter questionnaire was applied as a free writing instrument and sent to second-year bachelor students of the Faculty of Management at The University of Gdańsk, Poland. To identify the most preferred characteristics, a content analysis and Pareto analysis were used. As a result, 32 characteristics were proposed and grouped into 5 categories, namely tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Based on this, several proposals and recommendations for the future were specified. The results obtained help not only to understand the needs of students, but also to prepare the most desired teaching environment in which deep learning outcomes are made possible for future managers in the context of modern economy. © 2015 Taylor & Francis.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","1158-1170","","9-10","27","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2BBMFNS","journalArticle","2016","López-Gil, J.-M.; Virgili-Gomá, J.; Gil, R.; García, R.","Method for improving EEG based emotion recognition by combining it with synchronized biometric and eye tracking technologies in a non-invasive and low cost way","Frontiers in Computational Neuroscience","","16625188","10.3389/fncom.2016.00085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983514538&doi=10.3389%2ffncom.2016.00085&partnerID=40&md5=eccb032d2d09f3fb6cc015458abac70d","Technical advances, particularly the integration of wearable and embedded sensors, facilitate tracking of physiological responses in a less intrusive way. Currently, there are many devices that allow gathering biometric measurements from human beings, such as EEG Headsets or Health Bracelets. The massive data sets generated by tracking of EEG and physiology may be used, among other things, to infer knowledge about human moods and emotions. Apart from direct biometric signal measurement, eye tracking systems are nowadays capable of determining the point of gaze of the users when interacting in ICT environments, which provides an added value research on many different areas, such as psychology or marketing. We present a process in which devices for eye tracking, biometric, and EEG signal measurements are synchronously used for studying both basic and complex emotions. We selected the least intrusive devices for different signal data collection given the study requirements and cost constraints, so users would behave in the most natural way possible. On the one hand, we have been able to determine basic emotions participants were experiencing by means of valence and arousal. On the other hand, a complex emotion such as empathy has also been detected. To validate the usefulness of this approach, a study involving forty-four people has been carried out, where they were exposed to a series of affective stimuli while their EEG activity, biometric signals, and eye position were synchronously recorded to detect self-regulation. The hypothesis of the work was that people who self-regulated would show significantly different results when analyzing their EEG data. Participants were divided into two groups depending on whether Electro Dermal Activity (EDA) data indicated they self-regulated or not. The comparison of the results obtained using different machine learning algorithms for emotion recognition shows that using EEG activity alone as a predictor for self-regulation does not allow properly determining whether a person in self-regulation its emotions while watching affective stimuli. However, adequately combining different data sources in a synchronous way to detect emotions makes it possible to overcome the limitations of single detection methods. © 2016 López-Gil, Virgili-Gomá, Gil and García.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","","","AUG","10","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 24</p>","","","Electroencephalography; machine learning; Emotions; Artificial intelligence; Empathy; empathy; Speech recognition; Physiology; Eye-tracking; eye tracking; arousal; human; human experiment; electroencephalogram; Learning algorithms; Learning systems; controlled study; stimulus; autoregulation; Biometric informations; Biometric measurements; Biometrics; Deregulation; dermis; exposure; eye position; Eye tracking systems; Eye tracking technologies; gaze; marketing; Physiological models; Physiological response; recognition; Signal detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRS2NCS4","journalArticle","2016","Roudposhti, K.K.; Nunes, U.; Dias, J.","Probabilistic social behavior analysis by exploring body motion-based patterns","IEEE Transactions on Pattern Analysis and Machine Intelligence","","01628828","10.1109/TPAMI.2015.2496209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978763318&doi=10.1109%2fTPAMI.2015.2496209&partnerID=40&md5=db01d33fa9bc27fd5f8ab2a7bcd42047","Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction. © 1979-2012 IEEE.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","1679-1691","","8","38","","","","","","","","","","English","","","","","","","Publisher: IEEE Computer Society","<p>cited By 11</p>","","","Humans; Movement; Algorithms; Models; Robots; Human robot interaction; Bayes Theorem; Motion; Social Behavior; Social signal processing; Signal processing; human; Man machine systems; social behavior; Behavioral research; algorithm; Bayesian networks; statistical model; Automated; automated pattern recognition; Bayes theorem; Bayesian approaches; Complex networks; Frequency domain analysis; Frequency domains; Human movement analysis; motion; movement (physiology); Network layers; Pattern Recognition; Social roles; Social sciences; Statistical","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49VFNAMF","conferencePaper","2016","Marcu, G.; Dowshen, N.; Saha, S.; Sarreal, R.R.; Andalibi, N.","TreatYoSelf: Empathy-driven behavioral intervention for marginalized youth living with HIV","PervasiveHealth: Pervasive Computing Technologies for Healthcare","978-1-63190-050-1","","10.4108/eai.16-5-2016.2263336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046951092&doi=10.4108%2feai.16-5-2016.2263336&partnerID=40&md5=9c69c52491175e22e9a5c12cd82ac0f2","Behavioral intervention technologies are well suited to addressing health behavior such as medication adherence, but only if successfully integrated into a user's daily life. Little is known about how to design such technologies to be adoptable, adaptable, useful, and feasible in everyday life. We report on the design process for TreatYoSelf, a smartphone application designed to improve medication adherence among youth living with HIV through reminders and positive reinforcement. Using participatory design, our aim was to understand factors related to adoption and acceptance of behavioral intervention technology as part of daily life. Two challenges of living with HIV led to an empathy-driven approach in our design process: (1) HIV is a stigmatized condition, which (2) disproportionately affects the marginalized populations of young African American men who have sex with men and transgender women. We discuss five empathy-driven design strategies: positive and nonjudgmental tone; minimal, avatar-based gamification; motivational and corny messages; nondisclosure through neutral signifiers; and social support through camaraderie. Our approach enabled us to identify and work through factors, often related to stigma and marginalization, which would lead to rejection of TreatYoSelf use in daily life. © 2016 EAI.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","","","","2016-May","","","","","","","","ICST Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering","","English","","","","","","","ISSN: 21531633","<p>cited By 12; Conference of 10th EAI International Conference on Pervasive Computing Technologies for Healthcare, PervasiveHealth 2016 ; Conference Date: 16 May 2016 Through 19 May 2016; Conference Code:138076</p>","","","mHealth; Behavior change; Ubiquitous computing; African American; Behavioral interventions; Design strategies; Ecological momentary intervention; Medication adherence; Participatory design; Smart-phone applications","","Favela J., Hoey J., Matic A., Fitzpatrick G., Weibel N.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T52CAD63","conferencePaper","2016","Liu, X.; London, K.","T.A.I: A tangible AI interface to enhance human-artificial intelligence (AI) communication beyond the screen","DIS 2016 - Proceedings of the 2016 ACM Conference on Designing Interactive Systems: Fuse","978-1-4503-4031-1","","10.1145/2901790.2901896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978646804&doi=10.1145%2f2901790.2901896&partnerID=40&md5=0872ed99d2fa2b941be3307017eb6085","Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","281-285","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 3; Conference of 11th ACM SIGCHI Conference on Designing Interactive Systems, DIS 2016 ; Conference Date: 4 June 2016 Through 8 June 2016; Conference Code:122031</p>","","","Virtual reality; Artificial intelligence; Emotional intelligence; Intelligent systems; Mobile devices; Human computer interaction; User study; Social agents; Affective communication; Digital communication systems; Digital communications; Hardware design; Interactive computer systems; Social connection; Tangible interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WAK3NBYG","journalArticle","2016","Erikson, H.; Salzmann-Erikson, M.","Future Challenges of Robotics and Artificial Intelligence in Nursing: What Can We Learn from Monsters in Popular Culture?","The Permanente journal","","15525775","10.7812/TPP/15-243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017068759&doi=10.7812%2fTPP%2f15-243&partnerID=40&md5=23d859741b5b97bbd0e82387e1fda49d","It is highly likely that artificial intelligence (AI) will be implemented in nursing robotics in various forms, both in medical and surgical robotic instruments, but also as different types of droids and humanoids, physical reinforcements, and also animal/pet robots. Exploring and discussing AI and robotics in nursing and health care before these tools become commonplace is of great importance. We propose that monsters in popular culture might be studied with the hope of learning about situations and relationships that generate empathic capacities in their monstrous existences. The aim of the article is to introduce the theoretical framework and assumptions behind this idea. Both robots and monsters are posthuman creations. The knowledge we present here gives ideas about how nursing science can address the postmodern, technologic, and global world to come. Monsters therefore serve as an entrance to explore technologic innovations such as AI. Analyzing when and why monsters step out of character can provide important insights into the conceptualization of caring and nursing as a science, which is important for discussing these empathic protocols, as well as more general insight into human knowledge. The relationship between caring, monsters, robotics, and AI is not as farfetched as it might seem at first glance.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","","","3","20","","","","","","","","","","English","","","","","","","","<p>cited By 13</p>","","","Humans; artificial intelligence; Robotics; Artificial Intelligence; robotics; human; Nursing Care; nursing care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DT8Y23YS","journalArticle","2016","Lawson, L.; Cane, S.","Do conservators dream of electric sheep? Replicas and replication","Studies in Conservation","","00393630","10.1080/00393630.2016.1181348","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988329847&doi=10.1080%2f00393630.2016.1181348&partnerID=40&md5=10144d954aca38ab318f4ec5ae973e82","The paper crosses the boundaries between different genres, drawing on key material and emphasising the philosophical challenges around decision-making and values in relation to replication and replicas. In 1968, Philip K. Dick wrote the book Do Androids Dream of Electric Sheep? which became the inspiration for the 1982 film Bladerunner. The book is set in Los Angeles in a post-apocalyptic future where mankind has left Earth, resulting in androids being created to develop new ‘off-world’ colonies. The book and film create a novel and interesting framework to discuss the subject of replicas and replication within contemporary conservation practice. Key themes are decay promoting replication, original versus replica, creating empathy in replication. The debate focuses on the case study of Naum Gabo's Construction in Space (Crystal) of 1937–39; which was the sculpture replicated in the most recent replication project at Tate, completed in July 2015. © 2016, © The International Institute for Conservation of Historic and Artistic Works 2016.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","109-113","","","61","","","","","","","","","","English","","","","","","","Publisher: Taylor and Francis Ltd.","<p>cited By 2</p>","","","Decision making; Empathy; Robots; Decay; Gabo; Original; Replica; Replicants; Philosophical aspects; Facsimile","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMRIN5BE","conferencePaper","2016","Fast, E.; Chen, B.; Bernstein, M.S.","Empath: Understanding topic signals in large-scale text","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-3362-7","","10.1145/2858036.2858535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015022494&doi=10.1145%2f2858036.2858535&partnerID=40&md5=c7f5be83a8cc1966392b34d936ba859e","Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like ""bleed"" and ""punch"" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r=0.906) with similar categories in LIWC.","2016","2021-05-19 13:26:38","2021-05-19 13:26:38","","4647-4657","","","","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 106; Conference of 34th Annual Conference on Human Factors in Computing Systems, CHI 2016 ; Conference Date: 7 May 2016 Through 12 May 2016; Conference Code:121621</p>","","","Social computing; Social media; Human computer interaction; Human engineering; Lexical categories; Computational social science; Fiction; Highly-correlated; Human language; Social sciences computing; Text analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H97BL5UK","conferencePaper","2016","Hall, L.; Hume, C.; Tazzyman, S.; Deshmukh, A.; Janarthanam, S.; Hastie, H.; Aylett, R.; Castellano, G.; Papadopoulos, F.; Jones, A.; Corrigan, L.J.; Paiva, A.; Oliveira, P.A.; Ribeiro, T.; Barendregt, W.; Serholt, S.; Kappas, A.","Map reading with an empathic robot tutor","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4673-8370-7","","10.1109/HRI.2016.7451859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964805945&doi=10.1109%2fHRI.2016.7451859&partnerID=40&md5=58ff42dc7dc58dc82b0100946189ea35","In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing mapreading tasks on a touch-screen device in this video. © 2016 IEEE.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","567","","","2016-April","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 6; Conference of 11th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2016 ; Conference Date: 7 March 2016 Through 10 March 2016; Conference Code:121147</p>","","","Education; Empathy; Robots; Human robot interaction; Students; Teaching; Man machine systems; Human computer interaction; Touch screens; Curricula; Maps; Educational settings; Reading skills; School students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WU8Y8B6U","conferencePaper","2016","Deshmukh, A.; Janarthanam, S.; Hastie, H.; Lim, M.Y.; Aylett, R.; Castellano, G.","How expressiveness of a robotic tutor is perceived by children in a learning environment","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4673-8370-7","","10.1109/HRI.2016.7451787","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964907051&doi=10.1109%2fHRI.2016.7451787&partnerID=40&md5=dda6422ecb74809d3fd5904a26e07c99","We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment. © 2016 IEEE.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","423-424","","","2016-April","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 10; Conference of 11th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2016 ; Conference Date: 7 March 2016 Through 10 March 2016; Conference Code:121147</p>","","","Robots; Human robot interaction; Learning environments; Man machine systems; Facial Expressions; Computer aided instruction; Expressive gestures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ST57X5BS","journalArticle","2016","Tordo, F.; Binkley, C.","Auto-empathy or the others-in-oneself's evolution: Definition and clinic of virtual [L'auto-empathie, ou le devenir de l'autrui-en-soi: Définition et clinique du virtuel]","Evolution Psychiatrique","","00143855","10.1016/j.evopsy.2014.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900883323&doi=10.1016%2fj.evopsy.2014.02.002&partnerID=40&md5=2772d143d98da8ff9a47bdfb519c12da","Objectives: The authors propose to explore a psychic phenomenon, the ""auto-empathy"", as implemented in the context of digital spaces and particularly in the situation of the player who embodies an avatar (a pixel figure) in a video game. Method: From the perspective of a theoretical opening both phenomenological and psychoanalytic, auto-empathy is the process in which, taking the position of the ""other-in-oneself"", we represent our subjective world - or the all states of our subjectivity (actions, emotions, thoughts) - by an empathic relationship with ourselves. The auto-empathy relationship is a process of distancing, and symbolic appropriation, in which we are divided into halves, implementing our innate ability to be both subject and object for ourselves. Results: The mediatization of auto-empathy in digital worlds can put ourselves instead of a figure that represents us - our avatar - so that our empathy is turned towards ourselves indirectly. This second time of empathy for a virtual figure of the self, called ""mediatized auto-empathy"" or ""virtual auto-empathy"", would contribute thirdly to the development of empathy for oneself. Finally, the development of empathy for others would be supported in a fourth time, by the attention the players are paying to each other in network games. Discussion: These four hypotheses, illustrated by clinical cases, open an interrogation concerning the frame of the psychoanalytical work. In the adolescent, the work of virtualisation, which consists in the creative anticipation of its subjective possibilities, seems regularly impeded. The mental duplicity is no longer in a position to operate a symbolizing distance between the real self and the virtual self, between the subjective self and the subjectivising self. The other-in-oneself is ineffective in proposing to the adolescent an empathic dialogue with oneself. Consequently, the autorepresentation flirts with the seizure, in particular in the subjective states of breaks. Nevertheless, the digital spaces could be indirect media of appropriation of subjective experiences for the teenager. Conclusion: Our reflections led us to think of auto-empathy as the realization of the other-in-oneself which allows us to represent our own subjective world. The auto-empathy mediatized by an avatar can thus be described as a representation by empathy of our subjective part that contains this character. From then on, the space of the video game appears as a space of subjectivation. © 2014 Elsevier Masson SAS.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","293-308","","2","81","","","","","","","","","","French","","","","","","","Publisher: Elsevier Masson SAS","<p>cited By 6</p>","","","empathy; virtual reality; adolescence; human; Article; auto empathy; psychoanalysis; self concept","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T72TY9EG","journalArticle","2016","Bennett, P.; Moore, M.; Wenham, J.","The PAUL Suit©: An experience of ageing","Clinical Teacher","","17434971","10.1111/tct.12410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962516324&doi=10.1111%2ftct.12410&partnerID=40&md5=b1c6d99b190d125ab4dbf1d3806b09d5","Background: An ageing population worldwide makes it increasingly important that health students understand issues that elderly people face and can provide empathic care to them. Context: This teaching department in an isolated rural setting developed an interprofessional learning session to assist health students to understand issues of functional loss and social isolation that can affect elderly people. Innovation: The Premature Ageing Unisex Leisure (PAUL) Suit© was developed as part of a 1-day learning session for undergraduate health students - including students of medicine, nursing and allied health - attending clinical placement in far-west New South Wales. The suit was developed locally and can be adjusted to simulate a wide range of functional losses in the wearer. Students undertake a range of daily tasks in the community while wearing the suit in the company of a student 'carer'. Over the past 4 years, approximately 140 students have participated in the simulation. Post-simulation evaluations report that students gain a greater understanding of some functional issues associated with ageing, and of the social isolation that can be associated with these. The experiential nature of the activity leads to some powerful insights. This activity is an innovative, experiential tool to deepen students understanding of issues related to ageing Implications: This activity is an innovative, experiential tool to deepen students understanding of issues relating to ageing. The interprofessional nature of the activity is an important factor in the success of the day, and produces a wide range of shared insights. The activity also enhances the partnerships between the university, the health service and the local community. Our experience supports the value of simulation in providing a deep learning opportunity in the area of ageing and disability. © 2016 John Wiley & Sons Ltd.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","107-111","","2","13","","","","","","","","","","English","","","","","","","Publisher: Blackwell Publishing Ltd","<p>cited By 8</p>","","","Humans; learning; Learning; education; psychology; Aging; human; health care personnel; Health Personnel; aging; Interprofessional Relations; Mobility Limitation; New South Wales; program evaluation; Program Evaluation; public relations; walking difficulty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GCSEP7U","conferencePaper","2016","Aylett, R.; Kappas, A.; Castellano, G.; Bull, S.; Barendregt, W.; Paiva, A.; Hall, L.","I know how that feels - An empathic robot tutor","eChallenges e-2015 Conference Proceedings","978-1-905824-53-3","","10.1109/eCHALLENGES.2015.7441088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966680793&doi=10.1109%2feCHALLENGES.2015.7441088&partnerID=40&md5=909e7470384b1199c96abcbcefbf3110","This paper discusses the design and implementation of an Empathic Robot Tutor, applied to topics in the school Geography curriculum, and using a multi-touch table. It explains the motivation and objectives, introduces the two application domains, Mapskills and Enercities2, and describes the technology that has been developed. It discusses a study using Mapskills on the impact of embodiment on their learning, and results arising from this. © 2015 IIMC.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of eChallenges e-2015 Conference ; Conference Date: 25 November 2015 Through 26 November 2015; Conference Code:121044</p>","","","Machine design; Curricula; Multi-touch tables; Technology transfer; Design and implementations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9T8QGBBN","conferencePaper","2016","Headleand, C.J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L.A.","Does the Perceived Identity of Non-player Characters Change How We Interact with Them?","Proceedings - 2015 International Conference on Cyberworlds, CW 2015","978-1-4673-9403-1","","10.1109/CW.2015.35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964255469&doi=10.1109%2fCW.2015.35&partnerID=40&md5=0e24ff4477d953ab395db33157d255bf","Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it. © 2015 IEEE.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","145-152","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 1; Conference of International Conference on Cyberworlds, CW 2015 ; Conference Date: 7 October 2015 Through 9 October 2015; Conference Code:119374</p>","","","Artificial intelligence; CASA; Identity; Internet; Intelligent agents; Non-player character; Computer games; Human agent interactions; Interactive computer graphics; Human identity; Human players; On-line games; Primary objective","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YPAUV33I","conferencePaper","2016","Chumkamon, S.; Masato, K.; Hayashi, E.","Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot","Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015","978-1-4799-8696-5","","10.1109/SMC.2015.45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964478149&doi=10.1109%2fSMC.2015.45&partnerID=40&md5=9f91bfb404d3b6db6083d78cea8a6634","This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA). © 2015 IEEE.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","185-190","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 2; Conference of IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015 ; Conference Date: 9 October 2015 Through 12 October 2015; Conference Code:119045</p>","","","Animals; Robots; Social robots; Artificial consciousness; Face recognition; Human robot interaction; Cybernetics; Facial Expressions; Social interactions; Human robots; Motivation; Facial expression recognition; Social sciences; Emotion modeling; Human communications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL9IRS3T","journalArticle","2016","Sorbello, R.; Chella, A.; Giardina, M.; Nishio, S.; Ishiguro, H.","An architecture for Telenoid robot as empathic conversational android companion for elderly people","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-08338-4_68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945974382&doi=10.1007%2f978-3-319-08338-4_68&partnerID=40&md5=284d20453f0caff779f01dbae2648464","In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user. © Springer International Publishing Switzerland 2016.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","939-953","","","302","","","","","","","","","","English","","","","","","","ISBN: 9783319083377 Publisher: Springer Verlag","<p>cited By 7; Conference of 13th International Conference on Intelligent Autonomous Systems, IAS 2014 ; Conference Date: 15 July 2014 Through 18 July 2014; Conference Code:140839</p>","","","Robotics; Robots; Human robot interaction; Humanoid robot; Telenoid; Anthropomorphic robots; Humanoid interaction; Behavioral research; Current limitation; Humanoid robotics; Interaction experiences; Life supports; Robotic architectures; Technology transfer","","Yamaguchi H., Menegatti E., Michael N., Berns K.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCGC37MG","conferencePaper","2016","Kido, T.; Swan, M.","Machine learning and personal genome informatics contribute to happiness sciences and wellbeing computing","AAAI Spring Symposium - Technical Report","978-1-57735-754-4","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979992294&partnerID=40&md5=cd065a6b014ca9e08b2e80e173a45c51","Two big recent revolutions: machine learning technologies; such as ""deep learning"" in Artificial Intelligence (AI), and personal genome informatics in biomedical science, provide us with new opportunities for understanding human happiness. Our ongoing important challenges are to discover our own truly meaningful personal happiness with the aid of AI and personal genome technologies. We have been developing a personal genome information agent entitled MyFinder, which supports searching for our inherited talents and maximizes our potential for a meaningful life. In the MyFinder project, we have provided a crowd-sourced DIY (Do it yourself) genomics research platform and conducted various ""citizen science"" projects in health and wellness. In this paper, we discuss how machine learning technologies and personal genome informatics might contribute to happiness sciences. We introduce the ""Social Intelligence Genomics and Empathy-Building Study"" and report the preliminary results of applying deep learning and six other machine learning algorithms for predicting social intelligence levels from nine SNPs genetic profiles. We discuss the possibilities and limitations of applying machine learning technologies for personal happiness trait prediction. We also discuss future AI challenges in the context of wellbeing computing. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","362-368","","","SS-16-01 - 07","","","","","","","","AI Access Foundation","","English","","","","","","","","<p>cited By 3; Conference of 2016 AAAI Spring Symposium ; Conference Date: 21 March 2016 Through 23 March 2016; Conference Code:122634</p>","","","Artificial intelligence; Learning algorithms; Learning systems; Engineering education; Biomedical science; Citizen science; Genes; Health and wellness; Information agents; Information science; Machine learning technology; Personal genomes; Research platforms; Social intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNDQ7YIU","journalArticle","2016","Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.","Machine learning and empathy: The Civil Rights CAPTCHA","Concurrency Computation","","15320626","10.1002/cpe.3632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958909683&doi=10.1002%2fcpe.3632&partnerID=40&md5=458756a37cac7783f5c8ceeed964ed3f","Human interactive proofs (HIPs) are a basic security measure on the Internet to avoid automatic attacks. There is an ongoing effort to find a HIP that is secure enough yet easy for humans. Recently, a new HIP has been designed aiming at higher security: the Civil Rights Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). It employs the empathy capacity of humans to further strengthen Securimage, a well-known text CAPTCHA. In this paper, we analyze it from a security perspective, finding fundamental design flaws. Using several well-known machine learning (ML) algorithms, we analyze to what extent these flaws affect its security. We discover that thanks to them, we can create a successful side-channel attack. This attack is able to correctly solve the HIP on 20.7% of occasions, much more than enough to consider it broken. Thus, we show that there is no need to solve the problem of optical character recognition nor empathy analysis for computers to break this particular HIP. ML can be successfully used to break a HIP that uses both with a side-channel attack. This security analysis can be applied to other HIPs. It will allow to test whether they are leaking too much information by unexpected ways, given non-evident design flaws. Copyright © 2015 John Wiley & Sons, Ltd.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","1310-1323","","4","28","","","","","","","","","","English","","","","","","","Publisher: John Wiley and Sons Ltd","<p>cited By 1</p>","","","Artificial intelligence; Learning systems; CAPTCHAs; Character recognition; Civil rights; Electronic mail filters; Fundamental design; Hot isostatic pressing; Human interactive proofs; Network security; Optical character recognition; Security analysis; Security measure; Side channel attack; Turing tests; Wordnet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CLPN3UV","journalArticle","2016","Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.","Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy","Paladyn","","20814836","10.1515/pjbr-2016-0005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88","An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","55-66","","1","7","","","","","","","","","","English","","","","","","","Publisher: De Gruyter Open Ltd","<p>cited By 13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6SFWTIV","journalArticle","2016","Musiall, M.","Magical thinking and empathy towards robots","Frontiers in Artificial Intelligence and Applications","","09226389","10.3233/978-1-61499-708-5-347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992603376&doi=10.3233%2f978-1-61499-708-5-347&partnerID=40&md5=d0fd98141be39c30e95ee0a8507671b6","This paper aims to understand why human beings develop empathetic attitudes towards robots. Whilst much research studies this issue from the perspective of the natural sciences, by referring to biological features of the human brain, it is also possible to investigate it from the perspective of the humanities by referring to humans' cultural features. After establishing animation as a necessary condition of empathy towards robots, the presentation delivers a hypothesis that magical thinking - typical for children, members of ""primitive"" societies and individuals with mental disorders - is involved in the empathetic relations with robots. Furthermore, arguments to defend and clarify this hypothesis are presented. © 2016 The authors and IOS Press. All rights reserved.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","347-356","","","290","","","","","","","","","","English","","","","","","","ISBN: 9781614997078 Publisher: IOS Press","<p>cited By 1; Conference of CFP Robophilosophy 2016/Research Network for Transdisciplinary Studies in Social Robotics, TRANSOR 2016 ; Conference Date: 17 October 2016 Through 21 October 2016; Conference Code:124134</p>","","","Robotics; Empathy; Robots; Animation; Human being; Biological features; Human brain; Magical thinking; Mental disorders; Research studies","","Andersen S.S., Norskov M., Seibt J., Norskov M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRXWPTYQ","journalArticle","2016","LeRouge, C.; Dickhut, K.; Lisetti, C.; Sangameswaran, S.; Malasanos, T.","Engaging adolescents in a computer-based weight management program: Avatars and virtual coaches could help","Journal of the American Medical Informatics Association","","10675027","10.1093/jamia/ocv078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959454549&doi=10.1093%2fjamia%2focv078&partnerID=40&md5=ba2d1369e0fb04e8aa874541e90a7f54","Objective This research focuses on the potential ability of animated avatars (a digital representation of the user) and virtual agents (a digital representation of a coach, buddy, or teacher) to deliver computer-based interventions for adolescents' chronic weight management. An exploration of the acceptance and desire of teens to interact with avatars and virtual agents for self-management and behavioral modification was undertaken. Materials and Methods The utilized approach was inspired by community-based participatory research. Data was collected from 2 phases: Phase 1) focus groups with teens, provider interviews, parent interviews; and Phase 2) mid-range prototype assessment by teens and providers. Results Data from all stakeholder groups expressed great interest in avatars and virtual agents assisting self-management efforts. Adolescents felt the avatars and virtual agents could: 1) reinforce guidance and support, 2) fit within their lifestyle, and 3) help set future goals, particularly after witnessing the effect of their current behavior(s) on the projected physical appearance (external and internal organs) of avatars. Teens wanted 2 virtual characters: A virtual agent to act as a coach or teacher and an avatar (extension of themselves) to serve as a ""buddy"" for empathic support and guidance and as a surrogate for rewards. Preferred modalities for use include both mobile devices to accommodate access and desktop to accommodate preferences for maximum screen real estate to support virtualization of functions that are more contemplative and complex (e.g., goal setting). Adolescents expressed a desire for limited co-user access, which they could regulate. Data revealed certain barriers and facilitators that could affect adoption and use. Discussion The current study extends the support of teens, parents, and providers for adding avatars or virtual agents to traditional computerbased interactions. Data supports the desire for a personal relationship with a virtual character in support of previous studies. The study provides a foundation for further work in the area of avatar-driven motivational interviewing. Conclusions This study provides evidence supporting the use of avatars and virtual agents, designed using participatory approaches, to be included in the continuum of care. Increased probability of engagement and long-term retention of overweight, obese adolescent users and suggests expanding current chronic care models toward more comprehensive, socio-technical representations. © The Author 2015.","2016","2021-05-19 13:26:39","2021-05-19 13:26:39","","19-28","","1","23","","","","","","","","","","English","","","","","","","Publisher: Oxford University Press","<p>cited By 29</p>","","","Humans; User-Computer Interface; computer; health behavior; human; Article; adolescent; Adolescent; information processing; procedures; video game; computer interface; Video Games; adolescent behavior; Adolescent Behavior; adolescent obesity; behavior modification; body weight management; computer program; Focus Groups; Health Behavior; lifestyle modification; managed care; participatory research; Pediatric Obesity; self care; Self Care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXUZPAZK","journalArticle","2016","Johnson, E.; Gutiérrez López de la Franca, C.; Hervás, R.; Mondéjar, T.; Bravo, J.","Analyzing human-avatar interaction with neurotypical and not neurotypical users","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-48746-5_54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999027877&doi=10.1007%2f978-3-319-48746-5_54&partnerID=40&md5=eff5763b7e292a0d02027a97a15c1736","Assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues. In this case, we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of Social Communications Disorders (SCD). The designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions, with those emotions changing according to the interactions that the user chooses to perform on the avatar. We have used Blender for the design of the emotions, which are happiness, sadness, surprise, fear and anger, plus a neutral emotion, while Unity was used to dictate the behavior of the avatar when the interactions were performed, which could be positive (caress), negative (poke) or neutral (wait). The avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users, as well as the difference between neurotypical and non-neurotypical users in terms of emotion recognition and chosen interactions. A ground truth has been established in terms of prototypic empathic interactions by the users. © Springer International Publishing AG 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","525-536","","","10069 LNCS","","","","","","","","","","English","","","","","","","ISBN: 9783319487458 Publisher: Springer Verlag","<p>cited By 1; Conference of 10th International Conference on Ubiquitous Computing and Ambient Intelligence, UCAmI 2016 ; Conference Date: 29 November 2016 Through 2 December 2016; Conference Code:186919</p>","","","Artificial intelligence; Affective Computing; Empathy; Affective avatar; Avatar interaction; Ambient intelligence; Social communications; Blending; Cognitive disability","","Caballero-Gil P., Burmester M., Garcia C.R., Quesada-Arencibia A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PK8IASCN","journalArticle","2016","Yamaguchi, T.; Inoue, K.; Yoshino, K.; Takanashi, K.; Ward, N.G.; Kawahara, T.","Generating a variety of backchannel forms based on linguistic and prosodic features for attentive listening agents","Transactions of the Japanese Society for Artificial Intelligence","","13460714","10.1527/tjsai.C-G31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982976968&doi=10.1527%2ftjsai.C-G31&partnerID=40&md5=5006cdc2ced5f0076a85cf5bff6ba48a","There is a growing interest in conversation agents and robots which conduct attentive listening. However, the current systems always generate the same or limited forms of backchannels every time, giving a monotonous impression. This study investigates the generation of a variety of backchannel forms appropriate for the dialogue context, using the corpus of counseling dialogue. At first, we annotate all acceptable backchannel form categories considering the permissible variation in backchannels. Second, we analyze how the morphological form of backchannels relates to linguistic features of the preceding utterance such as the utterance boundary type and the linguistic complexity. Based on this analysis, we conduct machine learning to predict backchannel form from the linguistic and prosodic features of the preceding context. This model outperformed a baseline which always outputs the same form of backchannels and another baseline which randomly generates backchannels. Finally, subjective evaluations by human listeners show that the proposed method generates backchannels more naturally and gives a feeling of understanding and empathy. © 2016, Transactions of the Japanese Society for Artificial Intelligence. All rights reserved.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","","","4","31","","","","","","","","","","Japanese","","","","","","","Publisher: Japanese Society for Artificial Intelligence","<p>cited By 0</p>","","","Linguistics; Artificial intelligence; Learning systems; Computational linguistics; Speech processing; Attentive listening; Back channels; Conversation agents; Linguistic complexity; Linguistic features; Morphological forms; Spoken dialogue system; Subjective evaluations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RBHVWBW","conferencePaper","2016","Jestice, R.","Walking in someone's virtual shoes: Virtual worlds as a tool for developing empathy","AMCIS 2016: Surfing the IT Innovation Wave - 22nd Americas Conference on Information Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987668886&partnerID=40&md5=fcf90cdfb9ac4debe4a88d5a5f25d8ff","Empathy is an important skill for leaders. It is proposed that virtual worlds can be used effectively as a tool in developing empathy, especially perspective taking. This emerging stream of research explores the use of virtual worlds and avatar manipulation as a means to evoke perspective taking in leadership students. It is proposed that due to the Proteus Effect, virtual world users will change their behavior in a role-play based on their avatar's appearance. Further, it is proposed that this change in behaviors will lead to more insight into the perspectives of different others in a similar real world situation.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","","","","","","","","","","","","Association for Information Systems","","English","","","","","","","","<p>cited By 0; Conference of 22nd Americas Conference on Information Systems: Surfing the IT Innovation Wave, AMCIS 2016 ; Conference Date: 11 August 2016 Through 14 August 2016; Conference Code:123256</p>","","","Virtual reality; Empathy; Virtual worlds; Perspective taking; Information systems; Interactive computer graphics; Role play; Leadership development; Real world situations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VD7QJ7W6","journalArticle","2016","Michael, P.","Avatar and Incarnation: Gita spirituality and ignatian spirituality at the crossroads","Gregorianum","","00174114","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976584150&partnerID=40&md5=6b67184810fdf9f4d9aa858abcca6107","In order to appreciate and dialogue between the core-experiences of Hinduism and Christianity, one must enter into their collective memories. A Christian who wishes to enter into a core-to-core dialogue with Hinduism must have two qualifications: a preliminary empathic apprehension of the real nature of the other religion's coreexperience, and an uninhibited willingness and readiness to enter into a communicatio in sacris with the Hindus. The notion of avatar in the Bhagavad Gita is the most central formulation of the relationship between God and human beings in Hinduism and hence the appropriate concept for entering into dialogue with the Incarnation of the Spiritual Exercises of Ignatius. In this article we first deal with the doctrine of avatar in the Bhagavad Gita and then discuss the doctrine of Incarnation in the Spiritual Exercises. In the last part of the article, we bring the Bhagavad Gita and the Spiritual Exercises together, comparing and contrasting them in the spirit of affirmation and focusing on the theme of dialogue between avatar and Incarnation. The writer through this article believes that the understanding and living of mystery can grow through dialogue by sharing the insights and riches of religious traditions of humankind.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","323-342","","2","97","","","","","","","","","","English","","","","","","","Publisher: Gregorian University Press","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EWZXWIF","conferencePaper","2016","Gibson, J.; Can, D.; Xiao, B.; Imel, Z.E.; Atkins, D.C.; Georgiou, P.; Narayanan, S.","A deep learning approach to modeling empathy in addiction counseling","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","10.21437/Interspeech.2016-554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994381542&doi=10.21437%2fInterspeech.2016-554&partnerID=40&md5=597e1b16131430e9c506dd9c234d9232","Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics. Copyright © 2016 ISCA.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","1447-1451","","","08-12-September-2016","","","","","","","","International Speech and Communication Association","","English","","","","","","","ISSN: 2308457X","<p>cited By 5; Conference of 17th Annual Conference of the International Speech Communication Association, INTERSPEECH 2016 ; Conference Date: 8 September 2016 Through 16 September 2016; Conference Code:124342</p>","","","Deep learning; Forecasting; Signal processing; Speech communication; Deep neural networks; Neural network model; Behavioral dynamics; Distributed computer systems; Goal-oriented; Local dynamics; Motivational interviews; Recurrent neural networks; Speech processing; Word embedding","","Morgan N., Metze F., Georgiou P., Morgan N., Narayanan S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHKRPFXW","journalArticle","2016","Ojha, S.; Williams, M.-A.","Ethically-guided emotional responses for social robots: Should I be angry?","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-47437-3_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992504048&doi=10.1007%2f978-3-319-47437-3_23&partnerID=40&md5=6347c3eacdf9f494772d383db27c9336","Emotions play a critical role in human-robot interaction. Human-robot interaction in social contexts will be more effective if robots can understand human emotions and express (display) emotions accordingly as a means to communicate their own internal state. In this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement. There have been recent advances in developing emotion for robots. However, despite the extensive research on robot emotion, it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation. A key question is - to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity? Realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people, we present a novel Ethical Emotion Generation System (EEGS) for the expression of the most acceptable emotions in social robots. © Springer International Publishing AG 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","233-242","","","9979 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319474366 Publisher: Springer Verlag","<p>cited By 8; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>","","","Electroencephalography; Robotics; Robots; Social robots; Human robot interaction; Emotional response; Man machine systems; Philosophical aspects; Computation theory; Computational model; Appraisal theory; Emotion expression; Emotion generation; Ethical emotion; Ethical judgements","","Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TUZKW9B","journalArticle","2016","Giambattista, A.; Teixeira, L.; Ayanoğlu, H.; Saraiva, M.; Duarte, E.","Expression of emotions by a service robot: A pilot study","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-40406-6_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977557359&doi=10.1007%2f978-3-319-40406-6_31&partnerID=40&md5=4e3540b931b764e55a11e0446d99c472","A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot’s facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children. © Springer International Publishing Switzerland 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","328-336","","","9748","","","","","","","","","","English","","","","","","","ISBN: 9783319404059 Publisher: Springer Verlag","<p>cited By 1; Conference of 5th International Conference on Design, User Experience, and Usability, DUXU 2016 Held as Part of 18th International Conference on Human-Computer Interaction, HCI International 2016 ; Conference Date: 17 July 2016 Through 22 July 2016; Conference Code:176959</p>","","","Virtual reality; Robots; Health care; Service robots; Human robot interaction; Mobile robots; Emotional design; User experience; Man machine systems; Machine design; Facial Expressions; Human robot Interaction (HRI); Human computer interaction; Emotional expressions; University students; Recognition of emotion","","A, Marcus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJQBLM9Z","journalArticle","2016","Biswas, M.; Murray, J.","The effects of cognitive biases in long-term human-robot interactions: Case studies using three cognitive biases on MARC the humanoid robot","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-47437-3_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992530101&doi=10.1007%2f978-3-319-47437-3_15&partnerID=40&md5=04c0c77ee6491b684750e79ae72cd6c4","The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant’s names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours. © Springer International Publishing AG 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","148-158","","","9979 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319474366 Publisher: Springer Verlag","<p>cited By 1; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>","","","Robotics; Robots; Human robot interaction; Humanoid robot; Long-term interaction; Man machine systems; Anthropomorphic robots; Human computer interaction; Case-studies; Cognitive bias; Robot-human interaction","","Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8BZ9MBL","journalArticle","2016","Bechade, L.; Duplessis, G.D.; Devillers, L.","Empirical study of humor support in social human-robot interaction","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-39862-4_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978870310&doi=10.1007%2f978-3-319-39862-4_28&partnerID=40&md5=1ef7ba186fefcb5c0b2d3249f892d26b","As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event’s context. © Springer International Publishing Switzerland 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","305-316","","","9749","","","","","","","","","","English","","","","","","","ISBN: 9783319398617 Publisher: Springer Verlag","<p>cited By 4; Conference of 18th International Conference on Human-Computer Interaction, HCI International 2016 ; Conference Date: 17 July 2016 Through 22 July 2016; Conference Code:177779</p>","","","Robots; Human robot interaction; Man machine systems; Human-human interactions; Social skills; Multi-modal; Empirical studies; Human computer interaction; Human response; Dialog systems; Social human-robot interactions; Verbal response","","Streitz N., Markopoulos P.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FNE3AL3A","conferencePaper","2016","Spaulding, S.; Gordon, G.; Breazeal, C.","Affect-aware student models for robot tutors","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","978-1-4503-4239-1","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014300978&partnerID=40&md5=ab570c486aa4727c54dfa49919643854","Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots. Copyright © 2016, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","864-872","","","","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","","English","","","","","","","ISSN: 15488403","<p>cited By 25; Conference of 15th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2016 ; Conference Date: 9 May 2016 Through 13 May 2016; Conference Code:126305</p>","","","Education; Affective Computing; Robots; Autonomous agents; Students; Teaching; Educational robots; Multi agent systems; Socially assistive robots; Educational experiences; Bayesian knowledge tracings; Child-robot interactions; Educational software; Inferential methods; Interactive stories","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRSPTAXF","journalArticle","2016","Cominelli, L.; Mazzei, D.; Carbonaro, N.; Garofalo, R.; Zaraki, A.; Tognetti, A.; de Rossi, D.","A preliminary framework for a social robot “sixth sense”","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-42417-0_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978901196&doi=10.1007%2f978-3-319-42417-0_6&partnerID=40&md5=f80fc266bb310648ba78530189c8d2c0","Building a social robot that is able to interact naturally with people is a challenging task that becomes even more ambitious if the robots’ interlocutors are children involved in crowded scenarios like a classroom or a museum. In such scenarios, the main concern is enabling the robot to track the subjects’ social and affective state modulating its behaviour on the basis of the engagement and the emotional state of its interlocutors. To reach this goal, the robot needs to gather visual and auditory data, but also to acquire physiological signals, which are fundamental for understating the interlocutors’ psycho-physiological state. Following this purpose, several Human-Robot Interaction (HRI) frameworks have been proposed in the last years, although most of them have been based on the use of wearable sensors. However, wearable equipments are not the best technology for acquisition in crowded multi-party environments for obvious reasons (e.g., all the subjects should be prepared before the experiment by wearing the acquisition devices). Furthermore, wearable sensors, also if designed to be minimally intrusive, add an extra factor to the HRI scenarios, introducing a bias in the measurements due to psychological stress. In order to overcome this limitations, in this work, we present an unobtrusive method to acquire both visual and physiological signals from multiple subjects involved in HRI. The system is able to integrate acquired data and associate them with unique subjects’ IDs. The implemented system has been tested with the FACE humanoid in order to assess integrated devices and algorithms technical features. Preliminary tests demonstrated that the developed system can be used for extending the FACE perception capabilities giving it a sort of sixth sense that will improve the robot empathic and behavioural capabilities. © Springer International Publishing Switzerland 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","58-70","","","9793","","","","","","","","","","English","","","","","","","ISBN: 9783319424163 Publisher: Springer Verlag","<p>cited By 2; Conference of 5th International Conference on Biomimetic and Biohybrid Systems, Living Machines 2016 ; Conference Date: 19 July 2016 Through 22 July 2016; Conference Code:178599</p>","","","Robotics; Affective Computing; Robots; Human robot interaction; Physiology; Social robotics; Wearable technology; Teaching; Man machine systems; Human robot Interaction (HRI); Human computer interaction; Behavioral research; Technology transfer; Biomimetics; Wearable sensors; Physiological signals; Behaviour monitoring; Psycho-physiological; Psychological stress; Synthetic tutor","","Lepora N.F., Prescott T.J., Mura A., Desmulliez M., Mangan M., Verschure P.F.M.J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5SEWSM5","journalArticle","2016","Fosch-Villaronga, E.; Barco, A.; Özcan, B.; Shukla, J.","An interdisciplinary approach to improving cognitive human-robot interaction - A novel emotion-based model","Frontiers in Artificial Intelligence and Applications","","09226389","10.3233/978-1-61499-708-5-195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992535797&doi=10.3233%2f978-1-61499-708-5-195&partnerID=40&md5=fbde25f94afad87e490fc66222668a0d","Socially Assistive Robotics (SAR) aims to provide robot-assisted therapy, for physical as well as cognitive rehabilitation. The paper analyzes two distinct use cases of cognitive rehabilitation therapies, one among involving children with Traumatic Brain Injury (TBI); and another one; second among involving individuals with Intellectual Disability (ID), and raises concerns regarding emotional adaptation, personalization, design, and ELS issues of humanrobot interaction in such cases. The paper's aim is to provide some guidance on how social robots should be designed in order to accommodate emotions in HRI as well as to respect the rights of the persons with disabilities. We argue that it is critically important to address the concerns highlighted in order to empower robots with empathetic behavior and to deliver effective cognitive rehabilitation therapies. © 2016 The authors and IOS Press. All rights reserved.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","195-205","","","290","","","","","","","","","","English","","","","","","","ISBN: 9781614997078 Publisher: IOS Press","<p>cited By 4; Conference of CFP Robophilosophy 2016/Research Network for Transdisciplinary Studies in Social Robotics, TRANSOR 2016 ; Conference Date: 17 October 2016 Through 21 October 2016; Conference Code:124134</p>","","","Brain; Robotics; Emotions; Robots; Social robots; Human robot interaction; Man machine systems; Machine design; Human robot Interaction (HRI); Patient rehabilitation; Cognitive human-robot interactions; ELS aspects; Persons with disabilities; Robot-assisted therapies; Socially assistive robotics (SAR)","","Andersen S.S., Norskov M., Seibt J., Norskov M.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D3UUMDKC","journalArticle","2016","Ruiz-Garcia, A.; Elshaw, M.; Altahhan, A.; Palade, V.","Emotion recognition using facial expression images for a robotic companion","Communications in Computer and Information Science","","18650929","10.1007/978-3-319-44188-7_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984851062&doi=10.1007%2f978-3-319-44188-7_6&partnerID=40&md5=c930ac12567269804e53520b4a4b93da","Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08%, whereas our MLP achieves 93.5%. These experiments serve as benchmark for our current research project in the area of social robotics. © Springer International Publishing Switzerland 2016.","2016","2021-05-19 13:26:40","2021-05-19 13:26:40","","79-93","","","629","","","","","","","","","","English","","","","","","","ISBN: 9783319441870 Publisher: Springer Verlag","<p>cited By 5; Conference of 17th International Conference on Engineering Applications of Neural Networks, EANN 2016 ; Conference Date: 2 September 2016 Through 5 September 2016; Conference Code:180339</p>","","","Neural networks; Robotics; Robots; Social robots; Emotion recognition; Face recognition; Speech recognition; Social robotics; Image classification; Support vector machines; Facial Expressions; Gabor filters; Accuracy rate; Facial expression classification; Image preprocessing; Multilayer perceptron network (MLP)","","Iliadis L., Jayne C.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4YRG259","conferencePaper","2016","Bertero, D.; Siddique, F.B.; Wu, C.-S.; Wan, Y.; Chan, R.H.Y.; Fung, P.","Real-time speech emotion and sentiment recognition for interactive dialogue systems","EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings","978-1-945626-25-8","","10.18653/v1/d16-1110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072837881&doi=10.18653%2fv1%2fd16-1110&partnerID=40&md5=cb47e47a58a6fe6643e7e847811cbdc0","In this paper, we describe our approach of enabling an interactive dialogue system to recognize user emotion and sentiment in real-time. These modules allow otherwise conventional dialogue systems to have “empathy” and answer to the user while being aware of their emotion and intent. Emotion recognition from speech previously consists of feature engineering and machine learning where the first stage causes delay in decoding time. We describe a CNN model to extract emotion from raw speech input without feature engineering. This approach even achieves an impressive average of 65.7% accuracy on six emotion categories, a 4.5% improvement when compared to the conventional feature based SVM classification. A separate, CNN-based sentiment analysis module recognizes sentiments from speech recognition results, with 82.5 F-measure on human-machine dialogues when trained with out-of-domain data. © 2016 Association for Computational Linguistics","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","1042-1047","","","","","","","","","","","Association for Computational Linguistics (ACL)","","English","","","","","","","","<p>cited By 28; Conference of 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016 ; Conference Date: 1 November 2016 Through 5 November 2016; Conference Code:150070</p>","","","Sentiment analysis; Speech recognition; Learning algorithms; Real time systems; Support vector machines; Human computer interaction; Speech processing; Dialogue systems; Emotion recognition from speech; Feature engineerings; Feature-based; Human-machine dialogue; Speech emotions; SVM classification; User emotions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FW7QEZY9","conferencePaper","2016","Kawahara, T.; Yamaguchi, T.; Inoue, K.; Takanashi, K.; Ward, N.","Prediction and generation of backchannel form for attentive listening systems","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","10.21437/Interspeech.2016-118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994351223&doi=10.21437%2fInterspeech.2016-118&partnerID=40&md5=0be540a15263f6c99286d45ff0b40cb6","In human-human dialogue, especially in attentive listening such as counseling, backchannels are important not only for smooth communication but also for establishing rapport. Despite several studies on when to backchannel, most of the current spoken dialogue systems generate the same pattern of backchannels, giving monotonous impressions to users. In this work, we investigate generation of a variety of backchannel forms according to the dialogue context. We first show the feasibility of choosing appropriate backchannel forms based on machine learning, and the synergy of using linguistic and prosodic features. For generation of backchannels, a framework based on a set of binary classifiers is adopted to effectively make a ""not-to-generate"" decision. The proposed model achieved better prediction accuracy than a baseline which always outputs the same backchannel form and another baseline which randomly generates backchannels. Finally, evaluations by human subjects demonstrate that the proposed method generates backchannels as naturally as human choices, giving impressions of understanding and empathy. Copyright © 2016 ISCA.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","2890-2894","","","08-12-September-2016","","","","","","","","International Speech and Communication Association","","English","","","","","","","ISSN: 2308457X","<p>cited By 17; Conference of 17th Annual Conference of the International Speech Communication Association, INTERSPEECH 2016 ; Conference Date: 8 September 2016 Through 16 September 2016; Conference Code:124342</p>","","","Artificial intelligence; Learning systems; Speech communication; Human subjects; Speech processing; Attentive listening; Back channels; Spoken dialogue system; Binary classifiers; Human dialogues; Prediction accuracy; Prosodic features","","Morgan N., Metze F., Georgiou P., Morgan N., Narayanan S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XAEAITMC","conferencePaper","2016","Ferreira, M.I.A.; Sequeira, J.S.","Designing a robotic interface for children: The MOnarCH robot example","Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016","978-981-314-912-0","","10.1142/9789813149137_0076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999663794&doi=10.1142%2f9789813149137_0076&partnerID=40&md5=7de84e5ccd68ae2c76e5f3801431a3f9","The development of an empathic link between oneself and the Other is a fundamental part of interpersonal relationships determining the establishment of effective social and affective links that are the grounding basis of successful communication and cooperation on which the cohesion of human societies depend and on which harmonious global personal development also stands. The design of efficient robotic interfaces for interaction with people, namely with children, depends on the development of expressive elements to be present in the appearance of robots and in the way they address and interact with people, i.e. on the definition of a set of socially behaviours identified as communication enhancers. The present paper reflects how the previous assumptions have determined the process that led to the construction of the MOnarCH robots and some of its design options. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","652-659","","","","","","","","","","","World Scientific Publishing Co. Pte Ltd","","English","","","","","","","","<p>cited By 1; Conference of 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016 ; Conference Date: 12 September 2016 Through 14 September 2016; Conference Code:185329</p>","","","Robotics; Communication; Mobile robots; Social robotics; Machine design; Human society; Economic and social effects; Interpersonal relationship; Children/robot interaction; Designing for interaction; Expressiveness; Personal development; Robotic interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDPPT77B","journalArticle","2016","Sejima, Y.; Egawa, S.; Sato, Y.; Watanabe, T.","A pupil response system using hemispherical displays for enhancing affective conveyance","Journal of Advanced Mechanical Design, Systems and Manufacturing","","18813054","10.1299/JAMDSM.2019JAMDSM0032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078309015&doi=10.1299%2fJAMDSM.2019JAMDSM0032&partnerID=40&md5=29a5562526052c2c6b4b3c50b9ee2dfb","In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker’s affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot’s eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance. © 2019 The Japan Society of Mechanical Engineers.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","","","4","10","","","","","","","","","","English","","","","","","","Publisher: Japan Society of Mechanical Engineers","<p>cited By 0</p>","","","Empathy; Human robot interaction; Media representation; Pupil response; Machine design; Speech communication; Affective engineering; Human Interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F39HVD4H","journalArticle","2016","Abbiati, M.; Baroffio, A.; Gerbase, M.W.","Personal profile of medical students selected through a knowledge-based exam only: Are we missing suitable students?","Medical Education Online","","10872981","10.3402/meo.v21.29705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007079343&doi=10.3402%2fmeo.v21.29705&partnerID=40&md5=f9afdbc35a30596a7a5ca8f19aee8413","Introduction: A consistent body of literature highlights the importance of a broader approach to select medical school candidates both assessing cognitive capacity and individual characteristics. However, selection in a great number of medical schools worldwide is still based on knowledge exams, a procedure that might neglect students with needed personal characteristics for future medical practice. We investigated whether the personal profile of students selected through a knowledge-based exam differed from those not selected. Methods: Students applying for medical school (N=311) completed questionnaires assessing motivations for becoming a doctor, learning approaches, personality traits, empathy, and coping styles. Selection was based on the results of MCQ tests. Principal component analysis was used to draw a profile of the students. Differences between selected and non-selected students were examined by Multivariate ANOVAs, and their impact on selection by logistic regression analysis. Results: Students demonstrating a profile of diligence with higher conscientiousness, deep learning approach, and task-focused coping were more frequently selected (p=0.01). Other personal characteristics such as motivation, sociability, and empathy did not significantly differ, comparing selected and non-selected students. Conclusion: Selection through a knowledge-based exam privileged diligent students. It did neither advantage nor preclude candidates with a more humane profile. © 2016 Milena Abbiati et al.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","","","1","21","","","","","","","","","","English","","","","","","","Publisher: Co-Action Publishing","<p>cited By 11</p>","","","Personality; Adult; Female; Humans; Male; Young Adult; learning; Learning; Education; Empathy; education; empathy; psychology; principal component analysis; motivation; Undergraduate; personality; medical education; Adaptation; Students; questionnaire; human; adult; female; major clinical study; male; young adult; controlled study; adolescent; Adolescent; procedures; Motivation; Psychological; Medical; medical school; medical student; Socioeconomic Factors; socioeconomics; College Admission Test; coping behavior; logistic regression analysis; School Admission Criteria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TE2M2A3N","conferencePaper","2016","Coeckelbergh, M.","Moving machines: Robots, empathy, and the performance of suffering","AISB Annual Convention 2016, AISB 2016","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041917924&partnerID=40&md5=4dcb71c2728f658225bedc448591eef2","","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","","","","","","","","","","","","The Society for the Study of Artificial Intelligence and the Simulation of Behaviour (AISB)","","English","","","","","","","","<p>cited By 0; Conference of 2016 Convention of the Society for the Study of Artificial Intelligence and Simulation of Behaviour, AISB 2016 ; Conference Date: 4 April 2016 Through 6 April 2016; Conference Code:127435</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KF6RP38P","conferencePaper","2016","Fung, P.; Dey, A.; Siddique, F.B.; Lin, R.; Yang, Y.; Yan, W.; Yin, R.C.H.","Zara: An empathetic interactive virtual agent","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994232510&partnerID=40&md5=2f53e4c08a96e5fc3df960ad4e028852","Zara, or 'Zara the Supergirl', is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented humanrobot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015. Copyright © 2016 ISCA.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","1176-1177","","","08-12-September-2016","","","","","","","","International Speech and Communication Association","","English","","","","","","","ISSN: 2308457X","<p>cited By 1; Conference of 17th Annual Conference of the International Speech Communication Association, INTERSPEECH 2016 ; Conference Date: 8 September 2016 Through 16 September 2016; Conference Code:124342</p>","","","Sentiment analysis; Virtual agent; Emotion recognition; Speech recognition; Human computer interaction; Speech communication; Speech processing; Empathy module; Human emotion recognition; Speech module; Virtual robots","","Morgan N., Metze F., Georgiou P., Morgan N., Narayanan S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6TNAXP8","journalArticle","2016","Shukla, J.; Barreda-Ángeles, M.; Oliver, J.; Puig, D.","MuDERI: Multimodal database for emotion recognition among intellectually disabled individuals","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-47437-3_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992523179&doi=10.1007%2f978-3-319-47437-3_26&partnerID=40&md5=5ecb6239283b3977469c0dc20359fa09","Social robots with empathic interaction is a crucial requirement towards deliverance of an effective cognitive stimulation among individuals with Intellectual Disability (ID) and has been challenged by absence of any particular database. Project REHABIBOTICS presents a first ever multimodal database of individuals with ID, recorded in a nearly real world settings for analysis of human affective states. MuDERI is an annotated multimodal database of audiovisual recordings, RGB-D videos and physiological signals of 12 participants in actual settings, which were recorded as participants were elicited using personalized real world objects and/or activities. The database is publicly available. © Springer International Publishing AG 2016.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","264-273","","","9979 LNAI","","","","","","","","","","English","","","","","","","ISBN: 9783319474366 Publisher: Springer Verlag","<p>cited By 4; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>","","","Robotics; Emotion recognition; Multimodal database; Assistive robotics; Intellectual disability; Database systems; Physiological signals; Robot-assisted therapies; Cognitive stimulations; Disabled individuals; Rating","","Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TJGWVGS","conferencePaper","2016","Fung, P.; Dey, A.; Bin Siddique, F.; Lin, R.; Yang, Y.; Bertero, D.; Yan, W.; Yin, R.C.H.; Wu, C.-S.","Zara: A virtual interactive dialogue system incorporating emotion, sentiment and personality recognition","COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations","978-4-87974-703-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048777533&partnerID=40&md5=fbcd4dcbaee2c6a3edb8e95be195275d","Zara, or 'Zara the Supergirl' is a virtual robot, that can exhibit empathy while interacting with an user, with the aid of its built in facial and emotion recognition, sentiment analysis, and speech module. At the end of the 5-10 minute conversation, Zara can give a personality analysis of the user based on all the user utterances. We have also implemented a real-time emotion recognition, using a CNN model that detects emotion from raw audio without feature extraction, and have achieved an average of 65.7% accuracy on six different emotion classes, which is an impressive 4.5% improvement from the conventional feature based SVM classification. Also, we have described a CNN based sentiment analysis module trained using out-of-domain data, that recognizes sentiment from the speech recognition transcript, which has a 74.8 F-measure when tested on human-machine dialogues. © COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","278-281","","","","","","","","","","","Association for Computational Linguistics, ACL Anthology","","English","","","","","","","","<p>cited By 4; Conference of 26th International Conference on Computational Linguistics, COLING 2016 ; Conference Date: 11 December 2016 Through 16 December 2016; Conference Code:136520</p>","","","Sentiment analysis; Emotion recognition; Speech recognition; Feature extraction; Personality recognition; Data mining; Human computer interaction; Computational linguistics; Classification (of information); Speech processing; Dialogue systems; Human-machine dialogue; SVM classification; Speech module; Virtual robots; Real-time emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5439KC95","conferencePaper","2016","Lok, B.","Training with virtual operating room teammates to influence team behaviors","Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016","978-1-5090-2299-1","","10.1109/CTS.2016.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016990802&doi=10.1109%2fCTS.2016.115&partnerID=40&md5=43b8f2a891be99dc9798e92fe575cfde","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care? In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room. We will examine the latest research into simulating healthcare teams with mixed reality humans. Mixed reality humans are virtual humans that can share the same physical space as the user. These virtual humans combine interactive graphics, natural language processing, artificial intelligence, human-computer interaction, and data mining to create in situ learning experiences. In these learning experiences, critical care personnel can work to improve teamwork with life-sized interactive virtual team-mates [1]. These learning experiences can also help implement best-practices to address address difficult teamwork concepts such as authority gradients, conflict negotiation, empathy and critical thinking [2][3]. Our research team (Samsun Lampotang, Anesthesia Department, University of Florida, Adam Wendling, Anesthesia Department, University of Florida, and Casey White, College of Medicine, University of Virginia) has developed VR hardware and software platforms to create compelling experiences for users to work on teams with mixed reality humans (MRHs). MRHs are virtual humans that can inhabit the user's physical space [4]. The MRH virtual team members can respond to the user's speech and actions and respond with natural speech and gestures. The virtual team members cannot physically interact with the environment. However, they can present realistic personalities and role-play the roles of operating room teammates, such as surgeons, anesthesiologists, nurses, and surgical technicians. The virtual team members combine the benefits of dynamic visuals of virtual humans with the physicality of mannequins (Figure 1). (Figure Presented) The virtual teammates are composed of comprise a minitower desktop for computation, networking, and rendering, a 40′ TV for display, and a Microsoft Kinect® (version 2) for tracking. All of these components are mounted onto a TV stand. Additionally, a Sennheiser DW-Pro 1 wireless headset is used for speech capture. ANDI's torso, arms, and head are rendered using a virtual human model from Autodesk's Character Generator. The virtual teammate's legs were physical and were composed of shoes and pants filled with stuffing. The physical props were used to integrate the virtual teammate into the user's space. A series of studies evaluated the social presence impact of ANDI design decisions and the current system configuration was shown to provide a virtual teammate with which participants reported a high sense of presence [5]. The virtual teammates' audio responses are pre-recorded by voice talent, and gestures are generated using motion capture and professionally key-framed animations. The virtual teammates can gaze at whoever is speaking, and intermittently glance at the other team members. They also blink and mimic idle motions when not speaking. We will examine results from studies evaluating the perception of virtual teammates, lessons learned in integrating such systems into hospital training, and areas for future research. © 2016 IEEE.","2016","2021-05-19 13:26:41","2021-05-19 13:26:41","","615-616","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 2016 International Conference on Collaboration Technologies and Systems, CTS 2016 ; Conference Date: 31 October 2016 Through 4 November 2016; Conference Code:126763</p>","","","Virtual reality; Health care; Data mining; Communication skills; E-learning; Computer graphics; Human computer interaction; NAtural language processing; Natural language processing systems; Nursing; Personnel training; Anesthesiology; Hardware and software; In situ processing; Intensive care units; Operating rooms; Rendering (computer graphics); System configurations; Team training; University of Florida; University of Virginia; Virtual humans","","Smari W.W., Natarian J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CRECPCW","conferencePaper","2015","Biswas, M.; Murray, J.C.","Towards an imperfect robot for long-term companionship: Case studies using cognitive biases","IEEE International Conference on Intelligent Robots and Systems","978-1-4799-9994-1","","10.1109/IROS.2015.7354228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958231490&doi=10.1109%2fIROS.2015.7354228&partnerID=40&md5=d2bfc1ff0b1555fb7f8aeaf6a2425e43","The research presented in this paper aims to find out what affect cognitive biases play in a robot's interactive behaviour for the goal of developing human-robot long-term companionship. It is expected that by utilising cognitive biases in a robot's interactive behaviours, making the robot cognitively imperfect, will affect how people relate to the robot thereby changing the process of long-term companionship. Previous research carried out in this area based on human-like cognitive characteristics in robots to create and maintain long-term relationship between robots and humans have yet to focus on developing human-like cognitive biases and as such is new to this application in robotics. To start working with cognitive biases 'misattribution' and 'empathic gap' have been selected which have been shown to be very common biases in humans and as such play a role on human-human interactions and long-term relationships. © 2015 IEEE.","2015","2021-05-19 13:26:41","2021-05-19 13:26:41","","5978-5983","","","2015-December","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","ISSN: 21530858","<p>cited By 8; Conference of IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2015 ; Conference Date: 28 September 2015 Through 2 October 2015; Conference Code:117884</p>","","","Robots; Human robot interaction; Human-human interactions; Human computer interaction; Human robots; Intelligent robots; Case-studies; Cognitive bias; Empathic Gap; Misattribution; Long-term relationships; Cognitive characteristics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86JQ62KL","conferencePaper","2015","Darling, K.; Nandy, P.; Breazeal, C.","Empathic concern and the effect of stories in human-robot interaction","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","978-1-4673-6704-2","","10.1109/ROMAN.2015.7333675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954066644&doi=10.1109%2fROMAN.2015.7333675&partnerID=40&md5=cdb1729f65a77b7680f2decb250845e0","People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses. © 2015 IEEE.","2015","2021-05-19 13:26:41","2021-05-19 13:26:41","","770-775","","","2015-November","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 39; Conference of 24th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2015 ; Conference Date: 31 August 2015 Through 4 September 2015; Conference Code:116986</p>","","","Robots; Human robot interaction; Man machine systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJM4GGV5","journalArticle","2015","Pablos, S.M.; García-Bermejo, J.G.; Zalama Casanova, E.; López, J.","Dynamic facial emotion recognition oriented to HCI applications","Interacting with Computers","","09535438","10.1093/iwc/iwt057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928327868&doi=10.1093%2fiwc%2fiwt057&partnerID=40&md5=1830d1e522ce7a76abd9ccd267476889","As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176-192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human-computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response. © 2013 The Author. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.","2015","2021-05-19 13:26:41","2021-05-19 13:26:41","","99-119","","2","27","","","","","","","","","","English","","","","","","","Publisher: Oxford University Press","<p>cited By 8</p>","","","Virtual reality; Computer vision; Gesture recognition; Face recognition; Facial Action Coding System; gestural input; intelligent avatars; Empirical studies; Human computer interaction; User interfaces; Ubiquitous computing; Active filters; Active Shape Models; Agent based; Differential equations; Dynamic information; Emotional recognition; Gabor filters; Graphical user interfaces; Image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2ET8QP8","conferencePaper","2015","Marti, P.; Iacono, I.","Social and empathic behaviours: Novel interfaces and interaction modalities","Proceedings - IEEE International Workshop on Robot and Human Interactive Communication","978-1-4673-6704-2","","10.1109/ROMAN.2015.7333634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954057498&doi=10.1109%2fROMAN.2015.7333634&partnerID=40&md5=a929da0458671f1cdcbee8e3dd2e67f3","This paper describes the results of a research conducted in the European project Accompany, whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home. The project developed a system consisting of a robotic companion, Care-O-bot, as part of a smart environment. An intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot. The paper is articulated in two parts. The first part illustrates the theory that inspired the development of a context-aware Graphical User Interface (GUI) used to interact with the robot. The GUI integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges. The second part focuses on the user evaluation, and reports the outcomes from three different tests. The results of the first two tests show a positive acceptance of the GUI by the older people. The final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot. © 2015 IEEE.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","217-222","","","2015-November","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 4; Conference of 24th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2015 ; Conference Date: 31 August 2015 Through 4 September 2015; Conference Code:116986</p>","","","Robotics; Robots; Perspective taking; User interfaces; Independent living; Graphical user interfaces; Acceptance tests; Context-Aware; European project; Graphical user interfaces (GUI); Intensive research; Smart environment; User evaluations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2BK7EPX9","conferencePaper","2015","Franco, G.A.M.","Evaluation of the emotional answer in HRI on a game situation","Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015","978-1-4503-3960-5","","10.1145/2824893.2824897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979647991&doi=10.1145%2f2824893.2824897&partnerID=40&md5=3c3eddadd8b9eb02473ab17a28a8c9ab","This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 7th Latin American Conference on Human Computer Interaction, CLIHC 2015 ; Conference Date: 18 November 2015 Through 21 November 2015; Conference Code:122512</p>","","","Empathy; Interaction design; Robots; Emocards; Human computer interaction; Emotional evaluation; Emotional reciprocity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVMKA8GT","journalArticle","2015","Suzuki, Y.; Galli, L.; Ikeda, A.; Itakura, S.; Kitazaki, M.","Measuring empathy for human and robot hand pain using electroencephalography","Scientific Reports","","20452322","10.1038/srep15924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946601210&doi=10.1038%2fsrep15924&partnerID=40&md5=7480591126ea8768b8ce1b5b5879fca1","This study provides the first physiological evidence of humans € ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","","","","5","","","","","","","","","","English","","","","","","","Publisher: Nature Publishing Group","<p>cited By 57</p>","","","Female; Humans; Male; Young Adult; electroencephalography; Electroencephalography; Robotics; physiology; Hand; pain; Empathy; empathy; robotics; psychology; Pain; human; female; male; young adult; pathophysiology; vision; procedures; Photic Stimulation; photostimulation; Visual Perception; analysis of variance; Analysis of Variance; Evoked Potentials; evoked response; hand; pain measurement; Pain Measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPGSQHZR","conferencePaper","2015","De Carolis, B.; Ferilli, S.; Palestra, G.; Carofiglio, V.","Modeling and simulating empathic behavior in social assistive robots","ACM International Conference Proceeding Series","978-1-4503-3684-0","","10.1145/2808435.2808445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979700862&doi=10.1145%2f2808435.2808445&partnerID=40&md5=cd533aacdb914fa907bc5e3ab8ae0e1d","Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living. © 2015 ACM.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","110-117","","","28","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 3; Conference of 11th Biannual Conference of the ACM SIGCHI Italian Chapter, CHItaly 2015 ; Conference Date: 28 September 2015 Through 30 September 2015; Conference Code:118273</p>","","","Affective Computing; Robots; Ambient assisted living; Emotional state; Affective state; Facial Expressions; Assistive robots; Computer applications; Computer programming; Assisted living; Modeling and simulating","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIQ7W4NV","conferencePaper","2015","Andersen, J.S.; Schoenau-Fog, H.","Using role-taking and behavioral mimicking in games to increase awareness on the bystander effect","ACADEMICMINDTREK 2015 - Proceedings of the 19th International Academic Mindtrek Conference","978-1-4503-3948-3","","10.1145/2818187.2818290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962875863&doi=10.1145%2f2818187.2818290&partnerID=40&md5=9bb92260b998ec261abfbb7a1ee9ae11","This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","69-72","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 0; Conference of 19th International Academic Mindtrek Conference, AcademicMindTrek 2015 ; Conference Date: 22 September 2015 Through 24 September 2015; Conference Code:119047</p>","","","Serious games; Interactive computer graphics; Game theory; Behavioral mimicking; Bystander effects; Proteus effect; Role playing; Role-taking; Simulations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CKWKPS5","conferencePaper","2015","Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.","Real-time sociometrics from audio-visual features for two-person dialogs","International Conference on Digital Signal Processing, DSP","978-1-4799-8058-1 978-1-4799-8058-1","","10.1109/ICDSP.2015.7251991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961315280&doi=10.1109%2fICDSP.2015.7251991&partnerID=40&md5=447bee82a1f60ad7b9676da82921a344","This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus. © 2015 IEEE.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","823-827","","","2015-September","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 6; Conference of IEEE International Conference on Digital Signal Processing, DSP 2015 ; Conference Date: 21 July 2015 Through 24 July 2015; Conference Code:118054</p>","","","Artificial intelligence; dialog; Signal processing; Learning algorithms; Real time; Learning systems; Audio-visual corpora; Audio-visual features; Audiovisual analysis; Digital signal processing; Face-to-face conversation; Leave-one-out cross validations; Sociometrics; Statistical methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGMP8DQJ","conferencePaper","2015","Mennesson, J.; Allaert, B.; Bilasco, I.M.; Van Der Aa, N.; Denis, A.; Cruz-Lara, S.","Faces and thoughts: An empathic dairy","2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015","978-1-4799-6026-2","","10.1109/FG.2015.7163170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944936778&doi=10.1109%2fFG.2015.7163170&partnerID=40&md5=404f347a45efe50821e18249ea214502","Many diary apps have been developed for an Android mobile device. Although most concentrate on securing the privacy and adding emoticons, only a few include automatic emotion measurements. This demo shows a new diary app including real-time multi-modal emotion measurements to capture the affective state of the user from the text provided and video images made. The emotion measurements from the Emotion from Face module, that analyzes images from the front camera [1], and the Emotion from Text module, that analyzes the text written by the user [2], are merged within the Emotion Fusion module to estimate the user's affective state more robustly. The app allows the user to have empathic feedback for each session. © 2015 IEEE.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 0; Conference of 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015 ; Conference Date: 4 May 2015 Through 8 May 2015; Conference Code:115630</p>","","","Gesture recognition; Face recognition; Mobile devices; Real time; Multi-modal; Affective state; Face module; Fusion modules; Video image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DXU7ETMF","journalArticle","2015","Sulpizio, V.; Committeri, G.; Metta, E.; Lambrey, S.; Berthoz, A.; Galati, G.","Visuospatial transformations and personality: evidence of a relationship between visuospatial perspective taking and self-reported emotional empathy","Experimental Brain Research","","00144819","10.1007/s00221-015-4280-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930869966&doi=10.1007%2fs00221-015-4280-2&partnerID=40&md5=a758a2763261e0854cd1aabac0e34968","In the visuospatial domain, perspective taking is the ability to imagine how a visual scene appears from an external observer’s viewpoint, and can be studied by asking subjects to encode object locations in a visual scene where another individual is present and then detecting their displacement when seeing the scene from the other’s viewpoint. In the current study, we explored the relationship between visuospatial perspective taking and self-report measures of the cognitive and emotional components of empathy in young adults. To this aim, we employed a priming paradigm, in which the presence of an avatar allowed to anticipate the next perceived perspective on the visual scene. We found that the emotional dimension of empathy was positively correlated with the behavioral advantage provided by the presence of the avatar, relative to unprimed perspective changes. These data suggest a link between the tendency to vicariously experience the others’ emotions and the ability to perform self–other spatial transformations. © 2015, Springer-Verlag Berlin Heidelberg.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","2091-2102","","7","233","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 8</p>","","","Personality; Adult; Female; Humans; Male; Young Adult; User-Computer Interface; Emotions; emotion; physiology; Space Perception; cognition; Empathy; empathy; behavior; personality; human; adult; female; male; Article; young adult; priority journal; self report; Self Report; Photic Stimulation; photostimulation; computer interface; analysis of variance; Analysis of Variance; correlational study; depth perception; personal experience; spatial memory; Spatial Memory; spatial memory test; statistics; Statistics as Topic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DSIX675Z","conferencePaper","2015","Jeong, S.; Dos Santos, K.; Graca, S.; O'Connell, B.; Anderson, L.; Stenquist, N.; Fitzpatrick, K.; Goodenough, H.; Logan, D.; Weinstock, P.; Breazeal, C.","Designing a socially assistive robot for pediatric care","Proceedings of IDC 2015: The 14th International Conference on Interaction Design and Children","978-1-4503-3590-4","","10.1145/2771839.2771923","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961960661&doi=10.1145%2f2771839.2771923&partnerID=40&md5=cebf2035b32662a1aaa414de3d031960","We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socioemotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs. © 2015 ACM.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","387-390","","","","","","","","","","","Association for Computing Machinery, Inc","","English","","","","","","","","<p>cited By 20; Conference of 14th International Conference on Interaction Design and Children, IDC 2015 ; Conference Date: 21 June 2015 Through 24 June 2015; Conference Code:116155</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I96YKBVV","journalArticle","2015","Han, J.; Jo, M.; Hyun, E.; So, H.-J.","Examining young children’s perception toward augmented reality-infused dramatic play","Educational Technology Research and Development","","10421629","10.1007/s11423-015-9374-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939948308&doi=10.1007%2fs11423-015-9374-9&partnerID=40&md5=8ca770924db1fe1a9950b09569d11ad1","Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children’s satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children’s perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5–6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children’s perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed. © 2015, Association for Educational Communications and Technology.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","455-474","","3","63","","","","","","","","","","English","","","","","","","Publisher: Springer New York LLC","<p>cited By 50</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4VLQR6Q","conferencePaper","2015","Encinas, E.","Cyrafour: How two human avatars communicate with each other","Conference on Human Factors in Computing Systems - Proceedings","978-1-4503-3146-3","","10.1145/2702613.2726962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954228084&doi=10.1145%2f2702613.2726962&partnerID=40&md5=e8f6949e117f019ec78ee6fa3660edf7","Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","109-114","","","18","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 1; Conference of 33rd Annual CHI Conference on Human Factors in Computing Systems, CHI EA 2015 ; Conference Date: 18 April 2015 Through 23 April 2015; Conference Code:116996</p>","","","Serious games; Robots; Telepresence; Embodied cognition; Machine design; Human computer interaction; Human engineering; Co-presence; Visual communication; Cloning; Cyranoids; Human avatars; Personal surrogates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZVIXTK6","journalArticle","2015","Jackson, P.L.; Michon, P.-E.; Geslin, E.; Carignan, M.; Beaudoin, D.","EEVEE: The Empathy-Enhancing Virtual Evolving Environment","Frontiers in Human Neuroscience","","16625161","10.3389/fnhum.2015.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933673349&doi=10.3389%2ffnhum.2015.00112&partnerID=40&md5=c41939d6689a9860f5a08ac3f7ec4c58","Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar’s behavior to the observer’s neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar’s face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders. © 2015 Jackson, Michon, Geslin, Carignan and Beaudoin.","2015","2021-05-19 13:26:42","2021-05-19 13:26:42","","","","MAR","9","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S. A.","<p>cited By 14</p>","","","pain; empathy; virtual reality; facial expression; human; human experiment; adult; female; male; Article; normal human; stimulus response; controlled study; information processing; anger; perceptive discrimination; disgust; emotionality; Empathy Enhancing Virtual Evolving Environment; image display; masking; mental task; process development; system analysis; task performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9S2QNNX","conferencePaper","2015","Encinas, E.; Mitchell, R.","Cyrafour: An experiential activity facilitating empathic distant communication among copresent individuals","ACM International Conference Proceeding Series","978-1-4503-3349-8","","10.1145/2735711.2735815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954181474&doi=10.1145%2f2735711.2735815&partnerID=40&md5=896eaa05e1644177282c941cfb9fa8f5","Distant communication relies mostly on a non-embodied representation of participants (e.g textual in chats, photographic in videoconference, auditory in telephony, etc) that lessens the sensory richness of conversational interactions. Cyrafour is a novel activity that explores the implications of using human avatars (cyranoids) for empathic interpersonal remote communication. An unscripted conversation between two individuals (the sources) is transmitted through radio waves and reproduced by two copresent subjects (the cyranoids) following certain conversational guidelines. In particular, the Sources were invited to discuss about a topic, play a conversation game and comment on an opinionated video. All Cyrafour sessions were video-taped and participants interviewed afterwards in order to support analysis and discussion. Cyrafour could be considered as a playful embodied identity game in which cyranoids are simultaneously together in and aside from a conversation generated elsewhere. This puzzling circumstance seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","165-166","","","11","","","","","","","","Association for Computing Machinery","","English","","","","","","","","<p>cited By 0; Conference of 6th Augmented Human International Conference, AH 2015 ; Conference Date: 9 March 2015 Through 11 March 2015; Conference Code:113936</p>","","","Serious games; Telepresence; Embodied cognition; Computer programming; Co-presence; Visual communication; Cyranoids; Human avatars","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZAWS66K","conferencePaper","2015","Ji, S.H.; You, S.J.; Cho, H.-K.","Design of Emotional Conversations with a Child for a Role Playing Robot","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-3318-4","","10.1145/2701973.2702009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969278892&doi=10.1145%2f2701973.2702009&partnerID=40&md5=22de8e058c04462574e4504c77cf3ddd","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot. © 2015 Authors.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","73-74","","","02-05-March-2015","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 2; Conference of 10th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2015 ; Conference Date: 2 March 2015 Through 5 March 2015; Conference Code:121433</p>","","","Robotics; Education; Robots; Human robot interaction; Humanoid robot; Man machine systems; Machine design; Anthropomorphic robots; Human intervention; Robot technology; Role playing; Emotional robots; Real time performance evaluation; Robotic systems; Role-playing game","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJPMPHUE","conferencePaper","2015","Jeong, S.; Gu, J.; Shin, D.-H.","I am Interested in What You are Saying: Role of Nonverbal Immediacy Cues in Listening","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-3318-4","","10.1145/2701973.2702040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969131750&doi=10.1145%2f2701973.2702040&partnerID=40&md5=430338bf874134357991c30484c63e40","Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot. © 2015 Authors.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","129-130","","","02-05-March-2015","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 1; Conference of 10th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2015 ; Conference Date: 2 March 2015 Through 5 March 2015; Conference Code:121433</p>","","","Robots; Human robot interaction; Human likeness; Nonverbal behavior; immediacy; nodding; posture; Inter-personal communications; Man machine systems; Human-human interactions; Human computer interaction; Behavioral research; Nonverbal immediacies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9PXXX4R","conferencePaper","2015","Mazzei, D.; Zaraki, A.; Lazzeri, N.; De Rossi, D.","Recognition and expression of emotions by a symbiotic android head","IEEE-RAS International Conference on Humanoid Robots","978-1-4799-7174-9","","10.1109/HUMANOIDS.2014.7041349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945179051&doi=10.1109%2fHUMANOIDS.2014.7041349&partnerID=40&md5=f47b54fd692ed1f07a9bef8e2a4b0f1c","The creation of social empathie communication channels between social robots and humans has started to become reality. Nowadays, the development of empathie and affective agents is giving to scientists another way to explore the social dimension of human beings. In this work, we introduce the FACE humanoid project that aims at creating a social and emotional android. FACE is an android head with an articulated neck mounted on a passive body. In order to enable FACE to perceive and express emotions, two dedicated engines have been developed. A sensory apparatus able to perceive the 'social world', and a facial expressions generation engine that allows the robot to express its synthetic emotions. The system has been also integrated with an attention-based gaze generation component that allows the robot to autonomously follow a conversation between its partners. The developed framework has been implemented and tested in several standard human-robot interaction settings. Results demonstrated the promising social capabilities of the robot to perceive and convey emotions to humans through the generation of emotional perceivable facial expressions and socially aligned behaviour. © 2014 IEEE.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","134-139","","","2015-February","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21640572","<p>cited By 3; Conference of 2014 14th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2014 ; Conference Date: 18 November 2014 Through 20 November 2014; Conference Code:112990</p>","","","Social robots; Human robot interaction; Anthropomorphic robots; Human being; Facial Expressions; Behavioral research; Express emotions; Engines; Social dimensions; Synthetic emotions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3AY8ULND","journalArticle","2015","Tisseron, S.; Tordo, F.; Baddoura, R.","Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0268-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924301513&doi=10.1007%2fs12369-014-0268-5&partnerID=40&md5=ae9ddda552ec58f57dc89db088c53239","The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","97-102","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 4</p>","","","Electrophysiology; Psychology; Social robots; Human robot interaction; Auto-empathy; Direct empathy; Intersubjective empathy; Reciprocal empathy; Agricultural robots; Man machine systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJ4TTFXM","journalArticle","2015","Damiano, L.; Dumouchel, P.; Lehmann, H.","Towards Human–Robot Affective Co-evolution Overcoming Oppositions in Constructing Emotions and Empathy","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0258-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924341694&doi=10.1007%2fs12369-014-0258-7&partnerID=40&md5=80851efee3b5a5866fe3182d7ca5c9b2","This article deals with contemporary research aimed at building emotional and empathic robots, and gives an overview of the field focusing on its main characteristics and ongoing transformations. It interprets the latter as precursors to a paradigmatic transition that could significantly change our social ecologies. This shift consists in abandoning the classical view of emotions as essentially individual states, and developing a relational view of emotions, which, as we argue, can create genuinely new emotional and empathic processes—dynamics of “human–robot” affective coordination supporting the development of mixed (human–robot) ecologies. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","7-18","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 19</p>","","","Social robots; Human robot interaction; Affective coordination; Naked vs. embodied mind; Agricultural robots; Artificial emotions; Co-evolution; Ecology; Field focusing; Relational views; Social ecologies; Synthetic methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRM4V7MG","journalArticle","2015","Mirnig, N.; Strasser, E.; Weiss, A.; Kühnlenz, B.; Wollherr, D.; Tscheligi, M.","Can You Read My Face?: A Methodological Variation for Assessing Facial Expressions of Robotic Heads","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0261-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924308183&doi=10.1007%2fs12369-014-0261-z&partnerID=40&md5=c7634d4e7d25e2feda063822ac3b47b8","Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants’ dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","63-76","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 6</p>","","","Robotics; Surveys; Social robots; Human robot interaction; Robot emotions; Agricultural robots; Anthropomorphic robots; Facial Expressions; Online surveys; Blending; Human faces; Online studies; Robotic head; Situational context; Two-step procedure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AUPVFQFD","journalArticle","2015","Lim, A.; Okuno, H.G.","A Recipe for Empathy: Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0262-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924287073&doi=10.1007%2fs12369-014-0262-y&partnerID=40&md5=0b55eb0be5c80bdacedbf176adf6fbd4","Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (“flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence. © 2014, Springer Science+Business Media Dordrecht.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","35-49","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 17</p>","","","Social robots; Emotional intelligence; Mirrors; Speech recognition; Developmental robotics; Agricultural robots; Educational robots; Multi-modal; Emergent behaviors; Intelligent robots; Emotional voices; Interaction robot; Mirror systems; Mirror-neuron system; Somatosensory cortex","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KX6LKKN2","journalArticle","2015","Asada, M.","Towards Artificial Empathy: How Can Artificial Empathy Follow the Developmental Pathway of Natural Empathy?","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0253-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924289838&doi=10.1007%2fs12369-014-0253-z&partnerID=40&md5=c0449e6915eb39b5a3612055fec7f938","The design of artificial empathy is one of the most essential issues in social robotics. This is because empathic interactions with ordinary people are needed to introduce robots into our society. Several attempts have been made for specific situations. However, such attempts have provided several limitations; thus, diminishing authenticity. The present article proposes “affective developmental robotics (hereafter, ADR),” which provides more authentic artificial empathy based on the concept of cognitive developmental robotics (hereafter, CDR). First, the evolution and development of empathy as revealed in neuroscience and biobehavioral studies are reviewed, moving from emotional contagion to envy and schadenfreude. These terms are then reconsidered from the ADR/CDR viewpoint, particularly along the developmental trajectory of self-other cognition. Next, a conceptual model of artificial empathy is proposed based on an ADR/CDR viewpoint and discussed with respect to several existing studies. Finally, a general discussion and proposals for addressing future issues are given. © 2014, The Author(s).","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","19-33","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 37</p>","","","Robotics; Social robots; Artificial empathy; Social robotics; Self/other cognition; Developmental robotics; Agricultural robots; Conceptual model; Ordinary people","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39U6RH6H","journalArticle","2015","Airenti, G.","The Cognitive Bases of Anthropomorphism: From Relatedness to Empathy","International Journal of Social Robotics","","18754791","10.1007/s12369-014-0263-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924336727&doi=10.1007%2fs12369-014-0263-x&partnerID=40&md5=7771b24f56c2451979b51997da835912","Humans may react very differently with respect to mechanical devices, including robots. They can interact with them with delight or retreat in aversion or fear. According to the famous model of the uncanny valley these opposite reactions depend on the degree of familiarity that different artifacts engender in humans. The aim of my work is trying to find out the cognitive bases of familiarity, analyzing the origin of anthropomorphic projection, namely human disposition to attribute anthropomorphic features - like intentions or feelings—to artifacts. I shall discuss two concepts: relatedness and empathy, and argue that relatedness is the precondition for empathy. The fact that it is possible to attribute anthropomorphic features virtually to any object shows that resemblance is not the point. Anthropomorphism is a kind of relation that humans establish with an artifact, and in order to comprehend this phenomenon we have to focus on the relational aspect. I shall argue that what we call anthropomorphism is an extension to nonhumans of forms of interactions typical of human communication, i.e. the attribution to an artifact of the position of interlocutor in a possible dialogue. It can be shown that attributing to an artifact the position of interlocutor in a dialogue implies dealing with it as if it were endowed of the features characterizing human mind, i.e. mental states and emotions. © 2015, Springer Science+Business Media Dordrecht.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","117-127","","1","7","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 25</p>","","","Communication; Empathy; Uncanny valley; Social robots; Anthropomorphism; Relatedness; Agricultural robots; Mental state; Human communications; Mechanical device; Theory of minds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQFXAGQZ","conferencePaper","2015","Seo, S.H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J.E.","Poor Thing! Would You Feel Sorry for a Simulated Robot?: A comparison of empathy toward a physical and a simulated robot","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2882-1","","10.1145/2696454.2696471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943526431&doi=10.1145%2f2696454.2696471&partnerID=40&md5=5ac18b53dc70b062ef9d8f67cfea37d1","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. © 2015 ACM.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","125-132","","","2015-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 52; Conference of 10th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2015 ; Conference Date: 2 March 2015 Through 5 March 2015; Conference Code:114310</p>","","","empathy; Robots; Human robot interaction; Man machine systems; Machine design; Human computer interaction; Physical robots; Growing bodies; High costs; Measuring instruments; Real robot; Simulated interactions; Simulated robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6N2JSV6","conferencePaper","2015","De Carolis, B.; Ferilli, S.; Palestra, G.; Carofiglio, V.","Towards an empathic social robot for ambient assisted living","CEUR Workshop Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928737527&partnerID=40&md5=b573ae7afac79bef8ae0c8f77bd8451d","In the context of Ambient Assisted Living, assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. This can be achieved, for instance, using a social assistive robot as interface towards the environment services. In the context of the NICA (Natural Interaction with a Caring Agent) project we developed the behavioral architecture of a social robot able to assist the user in the interaction with a smart home environment. In this paper we describe how this robot has been endowed with the capability of recognizing the user affective state from the combination of facial expressions and spoken utterances and to reason on in order to simulate an empathic behavior.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","19-34","","","1351","","","","","","","","CEUR-WS","","English","","","","","","","ISSN: 16130073","<p>cited By 8; Conference of 2nd International Workshop on Emotion and Sentiment in Social and Expressive Media, ESSEM 2015 ; Conference Date: 5 May 2015; Conference Code:112014</p>","","","Robots; Social robots; Autonomous agents; Intelligent buildings; Ambient assisted living; Affective state; Facial Expressions; Assistive robots; Multi agent systems; Automation; Natural interactions; Task-oriented; As interfaces","","Cambria E., Patti V., Rosso P., Bosco C., Damiano R.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34JPKPGJ","journalArticle","2015","Vallverdú, J.; Casacuberta, D.","Ethical and technical aspects of emotions to create empathy in medical machines","Intelligent Systems, Control and Automation: Science and Engineering","","22138986","10.1007/978-3-319-08108-3_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e","This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:43","2021-05-19 13:26:43","","341-362","","","74","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 5</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2M4Q7XAN","journalArticle","2015","Sili, M.; Bobeth, J.; Sandner, E.; Hanke, S.; Schwarz, S.; Mayer, C.","Talking faces in lab and field trials: A view on evaluation settings and user involvement results of avatar based user interaction techniques in three ambient assisted living projects","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-20892-3_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947268275&doi=10.1007%2f978-3-319-20892-3_14&partnerID=40&md5=d97a18c15ab9df182fd255f3173c2f46","In recent years, there has been an increasing interest in Ambient Assisted Living technology to support older adults. Research and industry are working jointly on reliable and suitable solutions to help older adults to remain healthy and safe while living independently. Appropriate interaction methods play an important role for the acceptance of such supporting systems. Today, solutions mainly rely on common and well-evaluated interaction techniques such as TV remotes or touch screens to enhance the usability. Projects presented in this work are based on the same interaction techniques, but additionally enrich the interaction experience with a real-time, empathic virtual assistance avatar. In this paper, we present evaluation settings and user involvement results acquired from three different Ambient Assisted Living projects focusing on avatar-based user interaction. Our results show that avatar-based interaction in the Ambient Assisted Living context is very well applicable, especially when combined with speech recognition. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","134-144","","","9193","","","","","","","","","","English","","","","","","","ISBN: 9783319208916 Publisher: Springer Verlag","<p>cited By 4; Conference of 1st International Conference on Human Aspects of IT for the Aged Population, ITAP 2015 Held as Part of 17th International Conference on Human-Computer Interaction, HCI International 2015 ; Conference Date: 2 August 2015 Through 7 August 2015; Conference Code:156739</p>","","","Speech recognition; Ambient assisted living; Avatar; Human computer interaction; Touch screens; Interaction experiences; Avatar-based interaction; Industrial research; Interaction methods; Interaction techniques; Multi-modality; User interaction","","Salvendy G., Zhou J., Salvendy G.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2335Q7IX","journalArticle","2015","Gil, P.; Rossi, C.; Coral, W.","Biophilic evolutionary buildings that restore the experience of animality in the city","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-22979-9_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947104679&doi=10.1007%2f978-3-319-22979-9_47&partnerID=40&md5=906ff7465fc2103a0556f85aed9a7a97","In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible –or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa¸cade that learns optimal configurations according to the perception of aggressiveness and calmness. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","465-472","","","9222","","","","","","","","","","English","","","","","","","ISBN: 9783319229782 Publisher: Springer Verlag","<p>cited By 1; Conference of 4th International Conference on Biomimetic and Biohybrid Systems, Living Machines 2015 ; Conference Date: 28 July 2015 Through 31 July 2015; Conference Code:123139</p>","","","Artificial intelligence; Animals; Biomimicry; Biophilia; Evolutionary robotics; Intelligent buildings; Wellbeing; Embodied evolution; Behavioral research; Biomimetics","","Verschure P.F.M.J., Mura A., Wilson S.P., Prescott T.J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZFDDZE3","journalArticle","2015","Ceschi, A.; Scalco, A.; Dickert, S.; Sartori, R.","Compassion and prosocial behavior. Is it possible to simulate them virtually?","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-19629-9_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946410442&doi=10.1007%2f978-3-319-19629-9_23&partnerID=40&md5=1d820a863bf587f7f0f85fe86d00561e","In the field of artificial intelligence, a question dealing with computer and cognitive science is arising and becoming more and more crucial: Can we design agents so sophisticated that they are capable of mimicking emotional behaviors in general as well as specific emotions like compassion or empathy? Despite the production of different computational models, their integration with cognitive and psychological theories remains a central problem. Reasons are both methodological and theoretical. Primarily, it is difficult to quantify the impact of such factors as individual differences, inclinations and personality traits. In addition, Agent-Based Models (ABMs) often use linear dynamics, even in describing emotions, without considering the basis of psychophysics. Bearing in mind this and focusing on compassion as a particular emotion, the paper aims to present a “Decalogue” for those interested in designing agents capable of mimicking human emotional behaviors. In the paper, compassion will be translated as prosocial behavior. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","207-214","","","372","","","","","","","","","","English","","","","","","","ISBN: 9783319196282 Publisher: Springer Verlag","<p>cited By 7; Conference of International Conference on Practical Applications of Agents and Multi-Agent Systems, PAAMS 2015 ; Conference Date: 3 June 2015 Through 4 June 2015; Conference Code:154079</p>","","","Artificial intelligence; Psychophysics; Psychophysiology; Autonomous agents; Compassion; Prosocial Behavior; Personality traits; Individual Differences; Computation theory; Intelligent agents; Behavioral research; Computational model; Multi agent systems; Emotional behavior; Computational methods; Psychological theory","","Campbell A., Alonso-Betanzos A., Mathieu P., Fernandez-Caballero A., Jimenez-Lopez M.D., Bajo J., Hernandez J.Z., Moreno M.N., Julian V., Botti V.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGGYWLZP","journalArticle","2015","Ahn, T.-B.; Kang, E.-S.","Evaluation study of a human-sized bipedal humanoid robot through a public demonstration in a science museum","Journal of Institute of Control, Robotics and Systems","","19765622","10.5302/J.ICROS.2015.15.0109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941275810&doi=10.5302%2fJ.ICROS.2015.15.0109&partnerID=40&md5=4fa5bf50debed289c455d163e9699f20","Although human-sized bipedal humanoid robots have been developed as the ideal form of human-friendly robots, studies of humanoid robots from the user perspective and of actual interaction between humanoid robots and the public in daily environments are few. This paper presents a long-term public demonstration that encouraged interaction between a humanoid robot and unspecified individuals. We have collected a significant amount of subjective evaluation data from the public by performing a storytelling demonstration that enhanced people's empathy towards the robot. The evaluation model consists of the robot's human friendliness, which involves its impression on humans, interaction with humans, and imitation of human motions and the robot's human appearance which involves gender, age, height, and body type. This study shows that there is no significant difference in human-friendliness between gender groups (male and female), while there is a significant difference between age groups (children and adults). In human appearance, it appears that there is no significant difference between either gender groups or age groups, except for the case of the robot's height. © ICROS 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","849-857","","9","21","","","","","","","","","","English","","","","","","","Publisher: Institute of Control, Robotics and Systems","<p>cited By 0</p>","","","Robots; Human robot interaction; Humanoid robot; Anthropomorphic robots; User study; Subjective evaluations; Demonstrations; Evaluation modeling; Evaluation study; Human-Friendly Robots; Science museum; User perspectives","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHXPQEUB","journalArticle","2015","Vircikova, M.; Magyar, G.; Sincak, P.","The affective loop: A tool for autonomous and adaptive emotional human-robot interaction","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-16841-8_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942582493&doi=10.1007%2f978-3-319-16841-8_23&partnerID=40&md5=5224d167331f07059c553018a92b6858","The paper presents an affective model for social robotics, where the robot is capable of behavior adaptation, in accordance with the needs and preferences of a particular user. The proposed approach differs from other studies in human-robot interaction as these usually have been using the ‘Wizard of Oz’ technique, where a person remotely operates a robot. On the other side, simulated robots are not able of personalized behaviors and behave according to the preprogrammed set of rules. We provide a tool to personalize affective artificial behaviors in cooperative human—robot scenarios, where human emotion recognition, appropriate robotic behavior selection and expression of robotic emotions play a key role. The preliminary experiments show that the personalized affective robotic behavior can achieve better results in a scenario in which a robot motivates children in learning. We believe that human—robot interfaces which mimic how humans interact with one another in an empathic way could ultimately lead to robots being accepted in the wider domain. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","247-254","","","345","","","","","","","","","","English","","","","","","","ISBN: 9783319168401 Publisher: Springer Verlag","<p>cited By 3; Conference of 3rd International Conference on Robot Intelligence Technology and Applications, RiTA 2014 ; Conference Date: 6 November 2014 Through 8 November 2014; Conference Code:142319</p>","","","Robotics; Robots; Social robots; Human robot interaction; Man machine systems; Robot interactions; Behavioral research; Intelligent robots; Human emotion recognition; Personalizations; Robotic behavior; Behavior adaptations; Robotic emotions; Subjective computing","","Yang W., Jo J., Myung H., Kim J.-H., Sincak P.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5WQ35XXE","journalArticle","2015","Fuente, L.A.; Ierardi, H.; Pilling, M.; Crook, N.T.","Influence of upper body pose mirroring in human-robot interaction","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-25554-5_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983598081&doi=10.1007%2f978-3-319-25554-5_22&partnerID=40&md5=3f7276e6bca1a0a0ba38bb00b597daee","This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people’s perception of their conversation with it. A set of twelve questions about the participants’ university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","214-223","","","9388 LNCS","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 7; Conference of 7th International Conference on Social Robotics, ICSR 2015 ; Conference Date: 26 October 2015 Through 30 October 2015; Conference Code:154559</p>","","","Robotics; Empathy; Robots; Anthropomorphism; Human robot interaction; Rapport; Man machine systems; Behavioral research; Experimental evaluation; Body pose; Human social interactions; Human upper body; Upper bodies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TV5RMR52","journalArticle","2015","Hernández-Castro, C.J.; Barrero, D.F.; R-Moreno, M.D.","A machine learning attack against the civil rights CAPTCHA","Studies in Computational Intelligence","","1860949X","10.1007/978-3-319-10422-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921532152&doi=10.1007%2f978-3-319-10422-5_26&partnerID=40&md5=c429dffc0b1e39cc4456d096362e8de0","Human Interactive Proofs (HIPs) are a basic security measure on the Internet to avoid several types of automatic attacks. Recently, a new HIP has been designed to increase security: the Civil Rights CAPTCHA. It employs the empathy capacity of humans to further strengthen the security of a well known OCR CAPTCHA, Securimage. In this paper, we analyse it from a security perspective, pointing out its design flaws. Then, we create a successful side-channel attack, leveraging some well-known machine learning algorithms. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","239-248","","","570","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTKE7YUI","journalArticle","2015","Lazzeri, N.; Mazzei, D.; Greco, A.; Rotesi, A.; Lanatà, A.; De Rossi, D.E.","Can a humanoid face be expressive? A psychophysiological investigation","Frontiers in Bioengineering and Biotechnology","","22964185","10.3389/fbioe.2015.00064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029136651&doi=10.3389%2ffbioe.2015.00064&partnerID=40&md5=a53e545ed9f44fd77c91883d8c6b8aab","Non-verbal signals expressed through body language play a crucial role in multi-modal human communication during social relations. Indeed, in all cultures, facial expressions are the most universal and direct signs to express innate emotional cues. A human face conveys important information in social interactions and helps us to better understand our social partners and establish empathic links. Latest researches show that humanoid and social robots are becoming increasingly similar to humans, both esthetically and expressively. However, their visual expressiveness is a crucial issue that must be improved to make these robots more realistic and intuitively perceivable by humans as not different from them. This study concerns the capability of a humanoid robot to exhibit emotions through facial expressions. More specifically, emotional signs performed by a humanoid robot have been compared with corresponding human facial expressions in terms of recognition rate and response time. The set of stimuli included standardized human expressions taken from an Ekman-based database and the same facial expressions performed by the robot. Furthermore, participants' psychophysiological responses have been explored to investigate whether there could be differences induced by interpreting robot or human emotional stimuli. Preliminary results show a trend to better recognize expressions performed by the robot than 2D photos or 3D models. Moreover, no significant differences in the subjects' psychophysiological state have been found during the discrimination of facial expressions performed by the robot in comparison with the same task performed with 2D photos and 3D models. © 2015 Lazzeri, Mazzei, Greco, Rotesi, Lanatà and De Rossi.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","","","MAY","3","","","","","","","","","","English","","","","","","","Publisher: Frontiers Media S.A.","<p>cited By 21</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6V7CP88","conferencePaper","2015","Koltick, N.","Autonomous botanist: The poetic potentials of a new robotic species","ACADIA 2015 - Computational Ecologies: Design in the Anthropocene: Proceedings of the 35th Annual Conference of the Association for Computer Aided Design in Architecture","978-0-692-53726-8","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051989770&partnerID=40&md5=d2e2f91d070c255ab324f046a72147b0","This project begins by asking questions about ethics and empathy towards robots, and contemplates the future of their behavior in ways not informed by pragmatics or economy. What if a robot had a hobby? How do robots make aesthetic decisions? What is a robot’s point of view? It seeks to shift perception of robotic agency and allow the audience to embody the robotic gardeners’ vision, behavior and influence its aesthetics. By amplifying perceptual differences between humans and robots and we allow for both tangible and virtual embodiment experiences from multiple scales and perspectives. This compelling design speculation seeks to deploy a variety of interactive computational techniques, exploring novel forms and behaviors in order to engage deeper philosophical issues surrounding aesthetics, non-human agencies, and the role of the synthetic in the future. © 2015 ACADIA. All rights reserved.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","","","","2015-October","","","","","","","","ACADIA","","English","","","","","","","","<p>cited By 1; Conference of 35th Annual Conference of the Association for Computer Aided Design in Architecture - Computational Ecologies: Design in the Anthropocene, ACADIA 2015 ; Conference Date: 19 October 2015 Through 25 October 2015; Conference Code:136176</p>","","","Robotics; Computer architecture; Virtual reality; Robots; Philosophical aspects; Computer aided design; Ecology; Compelling designs; Computational technique; Human agency; Multiple scale; Perceptual difference","","Perry C., Combs L.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A89B4BEA","journalArticle","2015","Virčíkova, M.; Sinčák, P.","Teach your robot how you want it to express emotions: On the personalized affective human-humanoid interaction","Advances in Intelligent Systems and Computing","","21945357","10.1007/978-3-319-10783-7_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032118207&doi=10.1007%2f978-3-319-10783-7_9&partnerID=40&md5=22af8b608d901d438a4c1910a06c47ef","We believe that in order for robots to interact naturally with humans, they should be able to express affective behavior. This paper deals with the development of an affective model for social robotics in which the resulting robotic expressions adapt according to the human subjective preferences. We have developed a method which can be used by non-technical individuals to design the affective models of humanoid robots. Our vision of the future research is that the proposed personalization will be treated, from user’s perspective, as an empathic response of the machine. We see the major contribution of this unique approach especially in long-term human-robot relationships and it could ultimately lead to robots being accepted in a wider domain. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","81-92","","","316","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 0</p>","","","Robotics; Computer vision; Robots; Human robot interaction; Social robotics; Humanoid robot; Machine design; Anthropomorphic robots; Humanoid interaction; Human robots; Economic and social effects; Affective behaviors; Personalizations; Express emotions; Affective model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37AYGS5R","journalArticle","2015","Nunn, L.M.; Bolt, S.C.","Wearing a Rainbow Bumper Sticker: Experiential Learning on Homophobia, Heteronormativity, and Heterosexual Privilege","Journal of LGBT Youth","","19361653","10.1080/19361653.2015.1045963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938493116&doi=10.1080%2f19361653.2015.1045963&partnerID=40&md5=d869be1d87d7e9b1c33aabdb34d9d90f","College campuses are known to be heteronormative environments that often foster heterosexism and homophobia. There is a broad call for lesbian, gay, bisexual, transgender, and queer (LGBTQ) awareness-building curricula as one avenue for positive change in campus climates. This study interrogates the effects of an experiential learning activity where students were tasked with wearing a rainbow bumper sticker on their person for 24 hours. The aim was to inspire deep learning through self-reflection on experiences of discomfort. Students positively rated the activity for helping them recognize how homophobia influences conformity to heterosexual norms; recognize heterosexual privilege; and empathize with others who hold nonnormative sexual identities. © 2015, Copyright © Taylor & Francis Group, LLC.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","276-301","","3","12","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 4</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2K4TBVD","conferencePaper","2015","Yoshida, N.; Nakataniy, Y.; Yonezawa, T.","Breathing expression for intimate communication corresponding to the physical distance and contact between human and robot","EAI International Conference on Bio-inspired Information and Communications Technologies (BICT)","","","10.4108/eai.3-12-2015.2262419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052166553&doi=10.4108%2feai.3-12-2015.2262419&partnerID=40&md5=9713dbd5e5ed533a7a82dfbe30666dfd","In this paper, we propose living-being-like breathing expressions concurrent with both aspiration and utterances using a stuffed-Toy robot in order to enable intimate interactions. The focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two. From the factor analysis of the impression for the word ıntimacy"" and the distance between the robot and the participants, it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility. © 2016 ICST.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","","","","","","","","","","","","","","English","","","","","","","ISSN: 24116777","<p>cited By 0; Conference of 9th EAI International Conference on Bio-Inspired Information and Communications Technologies, BICT 2015 ; Conference Date: 3 December 2015 Through 5 December 2015; Conference Code:130982</p>","","","Robots; Close distance; Stuffed toy robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4D5QPFQN","journalArticle","2015","Baron, N.S.","Shall We Talk? Conversing With Humans and Robots","Information Society","","01972243","10.1080/01972243.2015.1020211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929321457&doi=10.1080%2f01972243.2015.1020211&partnerID=40&md5=b1bc07bd4cd52d72f27a1fbf83e05eb2","While social robots are the creation of human beings, it is not obvious what kinds of conversation people desire to have with computer-based devices. Progressive improvements in speech recognition, natural language parsing, and physical embodiment are making it technologically possible for social robots to engage with humans in essentially the full range of conversational modes that we do with one another. However, when we examine the variety of possible (human) linguistic functions, we discover reasons people may not wish for total verisimilitude when interacting linguistically with robots. Informational and empathetic functions are likely to be more welcomed than those involving social control or critique. © 2015, Published with license by Taylor & Francis.","2015","2021-05-19 13:26:44","2021-05-19 13:26:44","","257-264","","3","31","","","","","","","","","","English","","","","","","","Publisher: Routledge","<p>cited By 9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45YP6PEI","conferencePaper","2015","Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani Sherman, T.","Design and Evaluation of a Peripheral Robotic Conversation Companion","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2882-1","","10.1145/2696454.2696495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943575630&doi=10.1145%2f2696454.2696495&partnerID=40&md5=25d296afd2bb48f4924a435a5cdb57c8","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy. © 2015 ACM.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","3-10","","","2015-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 60; Conference of 10th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2015 ; Conference Date: 2 March 2015 Through 5 March 2015; Conference Code:114310</p>","","","Robotics; empathy; Robots; Behavior change; Design; Human robot interaction; ambient kinetic tangibles; Man machine systems; Machine design; Human-human interactions; Human computer interaction; Behavioral research; Hardware and software; Autonomous behaviors; Design and evaluations; Natural communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRP3ZC4C","conferencePaper","2015","Hood, D.; Lemaignan, S.; Dillenbourg, P.","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2882-1","","10.1145/2696454.2696479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943550932&doi=10.1145%2f2696454.2696479&partnerID=40&md5=c5d573890e88b608b9382205e80c22f5","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education. © 2015 ACM.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","83-90","","","2015-March","","","","","","","","IEEE Computer Society","","English","","","","","","","ISSN: 21672148","<p>cited By 83; Conference of 10th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2015 ; Conference Date: 2 March 2015 Through 5 March 2015; Conference Code:114310</p>","","","Robotics; Education; Robots; Human robot interaction; Principal component analysis; Humanoid robot; Man machine systems; Anthropomorphic robots; Education computing; In-Situ Study; Learning by teaching; Meta cognitions; Optimal parameter; Primary schools; Robotic partners; Statistical shape model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XBSRQ649","journalArticle","2015","Patel, H.; MacDorman, K.F.","Sending an avatar to do a human’s job: Compliance with authority persists despite the uncanny valley","Presence: Teleoperators and Virtual Environments","","10547460","10.1162/PRES_a_00212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929302303&doi=10.1162%2fPRES_a_00212&partnerID=40&md5=19d56358034d04dcd1491d273a47bb96","Just as physical appearance affects social influence in human communication, it may also affect the processing of advice conveyed through avatars, computer-animated characters, and other human-like interfaces. Although the most persuasive computer interfaces are often the most human-like, they have been predicted to incur the greatest risk of falling into the uncanny valley, the loss of empathy attributed to characters that appear eerily human. Previous studies compared interfaces on the left side of the uncanny valley, namely, those with low human likeness. To examine interfaces with higher human realism, a between-groups factorial experiment was conducted through the internet with 426 midwestern U.S. undergraduates. This experiment presented a hypothetical ethical dilemma followed by the advice of an authority figure. The authority was manipulated in three ways: depiction (digitally recorded or computer animated), motion quality (smooth or jerky), and advice (disclose or refrain from disclosing sensitive information). Of these, only the advice changed opinion about the ethical dilemma, even though the animated depiction was significantly eerier than the human depiction. These results indicate that compliance with an authority persists even when using an uncannily realistic computeranimated double. © 2015 by the Massachusetts Institute of Technology.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","1-23","","1","24","","","","","","","","","","English","","","","","","","Publisher: MIT Press Journals","<p>cited By 8</p>","","","Uncanny valley; Human likeness; Philosophical aspects; Economic and social effects; Social influence; Human communications; Animated characters; Ethical dilemma; Factorial experiment; Landforms; Sensitive informations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZRZABQZ","conferencePaper","2015","Deshmukh, A.; Jones, A.; Janarthanam, S.; Hastie, H.; Ribeiro, T.; Aylett, R.; Paiva, A.; Castellano, G.","An empathic robotic tutor in a map application (demonstration)","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","978-1-4503-3771-7","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944706470&partnerID=40&md5=931736e18e4be9ce33fc1b3b2d82a9d8","In this demonstration, we describe a scenario developed in the EMOTE project [2]. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain we demonstrate here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We demonstrate this scenario with a NAO robot interacting with the students whilst performing map-reading tasks in the form of a game on a touch-screen device. Copyright © 2015, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","1923-1924","","","3","","","","","","","","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)","","English","","","","","","","ISSN: 15488403","<p>cited By 5; Conference of 14th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2015 ; Conference Date: 4 May 2015 Through 8 May 2015; Conference Code:115712</p>","","","Robotics; Education; Empathy; Robots; Autonomous agents; Human robot interaction; Students; Teaching; Human computer interaction; Touch screens; Multi agent systems; Curricula; Maps; Educational settings; Reading skills; School students","","Bordini R.H., Weiss G., Yolum P., Elkind E.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMX4BTPP","journalArticle","2015","Alves-Oliveira, P.; Ribeiro, T.; Petisca, S.; Di Tullio, E.; Melo, F.S.; Paiva, A.","An empathic robotic tutor for school classrooms: Considering expectation and satisfaction of children as end-users","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-25554-5_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983652228&doi=10.1007%2f978-3-319-25554-5_3&partnerID=40&md5=c631496d31e146123d02e432cf3c2fac","Before interacting with a futuristic technology such as a robot, there is a lot of space for the creation of a whole set of expectations towards that interaction. Once that interaction happens, users can be left with a hand full of satisfaction, dissatisfaction, or even a mix of both. To study the possible role of experience as a mediator between expectation and satisfaction, we developed a scale for HRI that measures expectations and satisfaction of the users. Afterwards, we conducted a study with end-users interacting with a social robot. The robot is being developed to be an empathic robotic tutor to be used in real schools, with input from primary end-users (children). Children’s expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed. The results can be fed back to the system developers on how well it is being designed for such a target population, and what factors regarding their expectation and satisfaction have shifted after the experience of interaction. By delivering on the children’s expectations, we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational environment. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","21-30","","","9388 LNCS","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 9; Conference of 7th International Conference on Social Robotics, ICSR 2015 ; Conference Date: 26 October 2015 Through 30 October 2015; Conference Code:154559</p>","","","Robotics; Robots; Social robots; Human robot interaction; Teaching; Machine design; Human computer interaction; Natural interactions; User centered design; End users; Educational environment; Expectation; Satisfaction; System developers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJH8CQ72","conferencePaper","2015","Rasool, Z.; Masuyama, N.; Islam, M.N.; Loo, C.K.","Empathic interaction using the computational emotion model","Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015","978-1-4799-7560-0","","10.1109/SSCI.2015.26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964955492&doi=10.1109%2fSSCI.2015.26&partnerID=40&md5=a46376a05176a93e601b99827119b808","This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-Arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors. © 2015 IEEE.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","109-116","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 3; Conference of IEEE Symposium Series on Computational Intelligence, SSCI 2015 ; Conference Date: 8 December 2015 Through 10 December 2015; Conference Code:119063</p>","","","Artificial intelligence; Robots; Face recognition; Human robot interaction; Emotional models; Machine design; Facial Expressions; Human computer interaction; Computation theory; Behavioral research; Facial expression recognition; Curricula; Emotion modeling; Fuzzy logic; Scaling model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVUNBKRF","journalArticle","2015","Garza, A.A.; Lemus Zuñiga, L.G.; del Rosario Baltazar, M.; Marquez, B.Y.; Ramírez, C.L.; Romero, K.","Intelligent social agent for the development of social relations based on primary emotions","Smart Innovation, Systems and Technologies","","21903018","10.1007/978-3-319-19728-9_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947904053&doi=10.1007%2f978-3-319-19728-9_28&partnerID=40&md5=e146418f66b057d4a871dfc2954a655e","This article shows the experimentation with emotions in a scenario with a specific task, where the main goal is to see the behavior of emotions to the task given to them that based on the level of empathy that exists between these emotions, all this work is done within a Social Multi-Agent System, in which it is intended that two or more robots can present a profile of personality and emotion for the search of empathy between them to make a team. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","337-344","","","38","","","","","","","","","","English","","","","","","","ISBN: 9783319197272 Publisher: Springer Science and Business Media Deutschland GmbH","<p>cited By 0; Conference of 9th KES International Conference on Agent and Multi-Agent Systems-Technologies and Applications, KES-AMSTA 2015 ; Conference Date: 17 June 2015 Through 19 June 2015; Conference Code:157669</p>","","","Intelligent agents; Multi agent systems; Intelligent social agents; Social relations; Specific tasks","","Jain L.C., Howlett R.J., Jezic G.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5YNRV86","journalArticle","2015","Jones, A.; Küster, D.; Basedow, C.A.; Alves-Oliveira, P.; Serholt, S.; Hastie, H.; Corrigan, L.J.; Barendregt, W.; Kappas, A.; Paiva, A.; Castellano, G.","Empathic robotic tutors for personalised learning: A multidisciplinary approach","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-25554-5_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983637850&doi=10.1007%2f978-3-319-25554-5_29&partnerID=40&md5=aa4ed613a5062f248613250f8d7a581f","Within any learning process, the formation of a socio emotional relationship between learner and teacher is paramount to facilitating a good learning experience. The ability to form this relationship may come naturally to an attentive teacher; but how do we endow an unemotional robot with this ability? In this paper, we extend upon insights from the literature to include tools from user-centered design (UCD) and analyses of human-human interaction (HHI) as the basis of a multidisciplinary approach in the development of an empathic robotic tutor. We discuss the lessons learned in respect to design principles with the aim of personalised learning with empathic robotic tutors. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","285-295","","","9388 LNCS","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 21; Conference of 7th International Conference on Social Robotics, ICSR 2015 ; Conference Date: 26 October 2015 Through 30 October 2015; Conference Code:154559</p>","","","Robotics; Robots; Human robot interaction; Teaching; Human-human interactions; Learning systems; Human computer interaction; Learning experiences; User centered design; Design Principles; Learning process; Multi-disciplinary approach; Personalisation; Personalised learning; User Centered Design(UCD)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BHD6A6U","journalArticle","2015","Armitage, A.","The Dark Side: The Poetics of Toxic Leadership","Advances in Developing Human Resources","","15234223","10.1177/1523422315587905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937032486&doi=10.1177%2f1523422315587905&partnerID=40&md5=a0b0a2351d3520e851174389365d1a30","The Problem Morgan explored in her book What Poetry Brings to Business the deep but unexpected connections between business and poetry. She demonstrated how the creative energy, emotional power, and communicative complexity of poetry relate directly to the practical needs for innovation and problem solving that face business managers, and how poetry can unpack complexity, together with the ability to empathize with, and better understand the thoughts and feelings of others. This, it can be argued, not only aids the creative process of individuals, but it can also help facilitate the entrepreneurial culture of an organization, develop imaginative solutions, and help better understand chaotic environments. However, despite Morgan’s welcomed addition, it still remains that there is still a dearth of literature of the use of poetry concerning toxic leadership practices. The Solution According to Roebuck, reflexive practice can be described as a process of inquiry that facilities appreciation and understanding of contextualized views, deeper learning experiences, the development of ideas, and the conditions for actual change. Therefore, if organizations are not to objectify the creativity of those who aspire to be organizational leaders, then leadership development programs have to give voice to those who own organizational problems and their solution. Examples of organizational poetry will be presented to show how it can be used to unlock personal experiences and relationships within the context of working life. It will be argued that if stories are to represent reality as lived by those who report them, then poetry provides an alternative method of enquiry to inform contemporary leadership practices. The Stakeholders Poetry empowers individuals to internalize stories that carefully attend to context and settings to offer fresh perspectives on established truths, thus providing a way to explore hidden worlds that might often go unsaid in the milieu of normal conversation. As such, this article is aimed at those who need to develop an alternative paradigm for leadership and Human Resource Development (HRD) educational programs and want to adopt a more open dialogical approach to human relations within classroom settings and practice. © 2015, © The Author(s) 2015.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","376-390","","3","17","","","","","","","","","","English","","","","","","","Publisher: SAGE Publications Inc.","<p>cited By 2</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7BZK4XC","journalArticle","2015","Pettinati, M.J.; Arkin, R.C.","Towards a robot computational model to preserve dignity in stigmatizing patient-caregiver relationships","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","03029743","10.1007/978-3-319-25554-5_53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983551906&doi=10.1007%2f978-3-319-25554-5_53&partnerID=40&md5=101e69f850eee5fb87938dd20f24c8b8","Parkinson’s disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patientcaregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity. © Springer International Publishing Switzerland 2015.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","532-542","","","9388 LNCS","","","","","","","","","","English","","","","","","","Publisher: Springer Verlag","<p>cited By 3; Conference of 7th International Conference on Social Robotics, ICSR 2015 ; Conference Date: 26 October 2015 Through 30 October 2015; Conference Code:154559</p>","","","Robotics; Computation theory; Computational model; Robotic agents; Computational methods; Nonverbal channels; Nonverbal cues; Norm violation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LYXK3QA8","conferencePaper","2015","Pieroni, M.; Rizzello, L.; Rosini, N.; Fantoni, G.; De Rossi, D.; Mazzei, D.","Affective Internet of Things: Mimicking human-like personality in designing smart-objects","IEEE World Forum on Internet of Things, WF-IoT 2015 - Proceedings","978-1-5090-0365-5","","10.1109/WF-IoT.2015.7389088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964556250&doi=10.1109%2fWF-IoT.2015.7389088&partnerID=40&md5=8a13b6d0e0a3f31879eb1dbd9bcdce78","The paper wants to introduce the concept of Affective Internet of Things (AIoT) where smart objects are empowered with affective capability in terms of abstraction of their emotional state. Moreover each smart object can be associated with a specific 'personality'. This approach, already used in the field of social robotics, mainly exploits robots' appearance (i.e. anthropomorphism or zoomorphism). The research aims at extending such a paradigm to everyday-life objects in order to 'warm-up' the empathic connections that humans generally establish with 'cold' gadgets and devices. A new framework for the Affective IoT has been developed: EMPATI (EMPATI Mimics Personalities on Affective Things on Internet). It provides models and functions to simulate different personality for affective objects living in both virtual and real world. Finally, a set of experiments has been conceived to assess the key aspects of the framework in terms of capability to simulate emotional responses depending on the object interaction with the environment and the affective stimuli. © 2015 IEEE.","2015","2021-05-19 13:26:45","2021-05-19 13:26:45","","400-405","","","","","","","","","","","Institute of Electrical and Electronics Engineers Inc.","","English","","","","","","","","<p>cited By 6; Conference of 2nd IEEE World Forum on Internet of Things, WF-IoT 2015 ; Conference Date: 14 December 2015 Through 16 December 2015; Conference Code:119271</p>","","","Robotics; Internet; Social robotics; Emotional state; Emotional response; Human computer interaction; Human like; Internet of things; Real-world; affective object; Object interactions; Smart objects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZRDDV2I","journalArticle","2015","Santos-Lang, C.C.","Moral ecology approaches to machine ethics","Intelligent Systems, Control and Automation: Science and Engineering","","22138986","10.1007/978-3-319-08108-3_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921383640&doi=10.1007%2f978-3-319-08108-3_8&partnerID=40&md5=a85fa6ea1a4880edfbb476c3505fd3d9","Wallach and Allen’s seminal book, Moral Machines: Teaching Robots Right from Wrong, categorized theories of machine ethics by the types of algorithms each employs (e.g., top-down vs. bottom-up), ultimately concluding that a hybrid approach would be necessary. Humans are hybrids individually: our brains are wired to adapt our evaluative approach to our circumstances. For example, stressors can inhibit the action of oxytocin in the brain, thus forcing a nurse who usually acts from subjective empathy to defer to objective rules instead. In contrast, ecosystem approaches to ethics promote hybridization across, rather than within, individuals; the nurse being empowered to specialize in personalized care because other workers specialize in standardization, and profitability. Various philosophers have argued, or laid the framework to argue, that such specialization can be advantageous to teams and societies. Rather than mass-produce identical machines to emulate the best individual human, perhaps we should build diverse teams of machines to emulate the best human teams. © Springer International Publishing Switzerland 2015","2015","2021-05-19 13:26:46","2021-05-19 13:26:46","","111-127","","","74","","","","","","","","","","English","","","","","","","Publisher: Kluwer Academic Publishers","<p>cited By 3</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSPPRRFW","journalArticle","2015","Nijholt, A.","Designing Humor for Playable Cities","Procedia Manufacturing","","23519789","10.1016/j.promfg.2015.07.358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009957570&doi=10.1016%2fj.promfg.2015.07.358&partnerID=40&md5=f471888187c5afeb3635554f745fa9c3","Smartness, made possible by intelligent sensors and actuators, is invading our home, office and public environments. This smartness monitors, anticipates and supports our activities, increasing efficiency of our activities. Smartness is usually associated with efficiency, but it also allows environments, virtual humans and social robots to display emotions, empathy and provide environments to introduce and support humorous events. We review examples of playful and humorous street furniture in ‘playable’ cities and projects that allow residents and visitors to interact with objects and environments in playful and humorous ways. We add observations on humor theory, in particular observations that deal with physical, visual and multimodal humor. Our emphasis is on introducing incongruities and on exploring different forms of incongruities in order to introduce humorous situations. Inventories of incongruities are explored. These inventories have been obtained from observing humor in everyday situations, in comedies, in movies, and in TV commercials. Shortcomings of these inventories from the point of view of multimodal and interaction humor are discussed and some preliminary views on additional approaches are provided. © 2015 The Authors","2015","2021-05-19 13:26:46","2021-05-19 13:26:46","","2175-2182","","","3","","","","","","","","","","English","","","","","","","Publisher: Elsevier B.V.","<p>cited By 6</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
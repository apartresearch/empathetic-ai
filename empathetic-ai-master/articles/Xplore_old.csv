"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"YDFW3MYM","conferencePaper","2019","Peterson, J.; Cohen, C.; Harrison, P.; Novak, J.; Tossell, C.; Phillips, E.","Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming","2019 Systems and Information Engineering Design Symposium (SIEDS)","","","10.1109/SIEDS.2019.8735613","","The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.","2019-04","2021-04-19 15:42:26","2021-04-19 15:42:26","","1-6","","","","","","","","","","","","","","","","","","","","","","","","Atmospheric measurements; Battery charge measurement; Human-machine teaming; Human-robot interaction; Military aircraft; Particle measurements; Robots; Stress; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUXSYBNB","conferencePaper","2017","Burns, H. D.; Lesseig, K.","Empathy in middle school engineering design process","2017 IEEE Frontiers in Education Conference (FIE)","","","10.1109/FIE.2017.8190669","","This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.","2017-10","2021-04-19 15:42:26","2021-04-19 15:42:26","","1-4","","","","","","","","","","","","","","","","","","","","","","","","5G mobile communication; after-school science club; Computer bugs; design process; empathy; engineering; middle school","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CI6HUZU","journalArticle","2015","Pablos, S. M.; García-Bermejo, J. G.; ZalamaCasanova, E.; López, J.","Dynamic Facial Emotion Recognition Oriented to HCI Applications","Interacting with Computers","","1873-7951","10.1093/iwc/iwt057","","As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176–192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human–computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response.","2015-03","2021-04-19 15:42:27","2021-04-19 15:42:27","","99-119","","2","27","","","","","","","","","","","","","","","","","","","","","agent-based interaction; computer vision; empirical studies in ubiquitous and mobile computing; gestural input; graphical user interfaces; intelligent avatars","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJ22GSZQ","conferencePaper","2018","Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri","Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","10.1109/ICAITI.2018.8686759","","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.","2018-09","2021-04-19 15:42:27","2021-04-19 15:42:27","","208-212","","","","","","","","","","","","","","","","","","","","","","","","Android; Asperger syndrome; Mobile Robot; Rank Wilcoxon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IV2TTBML","conferencePaper","2019","Carranza, K. A. L. R.; Manalili, J.; Bugtai, N. T.; Baldovino, R. G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","10.1109/RITAPP.2019.8932852","","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.","2019-11","2021-04-19 15:42:27","2021-04-19 15:42:27","","160-163","","","","","","","","","","","","","","","","","","","","","","","","affective computing; Affective computing; Chatbot; Cognitive science; Computer science; deep learning; Deep learning; emotionally aware technology; facial expression detection; Psychology; Robots; scripted chatbot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QTFIH36","conferencePaper","2015","Darling, K.; Nandy, P.; Breazeal, C.","Empathic concern and the effect of stories in human-robot interaction","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2015.7333675","","People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.","2015-08","2021-04-19 15:42:27","2021-04-19 15:42:27","","770-775","","","","","","","","","","","","","","","","","","","","","","","","Atmospheric measurements; Human-robot interaction; Indexes; Media; Particle measurements; Robots; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWRW94MQ","conferencePaper","2015","Seo, S. H.; Geiskkovitch, D.; Nakane, M.; King, C.; Young, J. E.","Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. Categories and Subject Descriptors H.5.2 [User Interfaces]: evaluation/methodology General Terms Experimentation and Human Factors.","2015-03","2021-04-19 15:42:27","2021-04-19 15:42:27","","125-132","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Computational modeling; empathy; Human-robot interaction; Instruments; Programming; Psychology; robot embodiment; Robots; simulated interaction; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDHMLXLB","conferencePaper","2019","Mallol-Ragolta, A.; Schmitt, M.; Baird, A.; Cummins, N.; Schuller, B.","Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition","2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019)","","","10.1109/FG.2019.8756517","","The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.","2019-05","2021-04-19 15:42:27","2021-04-19 15:42:27","","1-5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TFWKTI7","conferencePaper","2018","Mollahosseini, A.; Abdollahi, H.; Mahoor, M. H.","Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525777","","Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.","2018-08","2021-04-19 15:42:28","2021-04-19 15:42:28","","783-789","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Face recognition; Mirrors; Observers; Robots; Speech recognition; Task analysis; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRW6I6E6","conferencePaper","2018","James, J.; Watson, C. I.; MacDonald, B.","Artificial Empathy in Social Robots: An analysis of Emotions in Speech","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525652","","Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.","2018-08","2021-04-19 15:42:28","2021-04-19 15:42:28","","632-637","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Anthropomorphism; Human-robot interaction; Medical services; Robot sensing systems; Standards; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVIR9Z92","conferencePaper","2016","Egawa, S.; Sejima, Y.; Sato, Y.; Watanabe, T.","A laughing-driven pupil response system for inducing empathy","2016 IEEE/SICE International Symposium on System Integration (SII)","","","10.1109/SII.2016.7844051","","Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.","2016-12","2021-04-19 15:42:28","2021-04-19 15:42:28","","520-525","","","","","","","","","","","","","","","","","","","","ISSN: 2474-2325","","","","Computer science; Mathematical model; Robots; Solid modeling; Speech; Three-dimensional displays; Timing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6BZLUWJ","conferencePaper","2020","Corretjer, M. G.; Ros, R.; Martin, F.; Miralles, D.","The Maze of Realizing Empathy with Social Robots","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223466","","Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.","2020-08","2021-04-19 15:42:28","2021-04-19 15:42:28","","1334-1339","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E9G5TVWF","conferencePaper","2015","Hoffman, G.; Zuckerman, O.; Hirschberger, G.; Luria, M.; Shani-Sherman, T.","Design and Evaluation of a Peripheral Robotic Conversation Companion","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote nonaggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to-human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.","2015-03","2021-04-19 15:42:28","2021-04-19 15:42:28","","3-10","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Ambient kinetic tangibles; Animation; Behavior change; Design; Empathy; Human-robot interaction; Kinetic theory; Monitoring; Robot sensing systems; Robotic companions; Shape; Smartphone robots.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8WLVAA3","conferencePaper","2019","Sripian, P.; Kurono, Y.; Yoshida, R.; Sugaya, M.","Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals","2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN46459.2019.8956353","","Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.","2019-10","2021-04-19 15:42:28","2021-04-19 15:42:28","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NE33KM72","conferencePaper","2016","Sin, Y. M.; Robin; Liang, Q.; Tani, K.; Ogawa, K.; Miyake, Y.","Evaluation of a head motion synchronization system in the communicative process between human and robot","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","","","10.1109/SICE.2016.7749252","","An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.","2016-09","2021-04-19 15:42:28","2021-04-19 15:42:28","","1514-1519","","","","","","","","","","","","","","","","","","","","","","","","Acceleration; Accelerometers; Aging; Head motion synchronization; human-robot interaction; Human-robot interaction; mutual entrainment; Robots; Senior citizens; Synchronization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"575B2ZDG","conferencePaper","2020","Sönmez, E. B.; Köse, H.; Barkana, D. E.","Towards a New Computational Affective System for Personal Assistive Robots","2020 28th Signal Processing and Communications Applications Conference (SIU)","","","10.1109/SIU49456.2020.9302238","","The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively.","2020-10","2021-04-19 15:42:28","2021-04-19 15:42:28","","1-4","","","","","","","","","","","","","","","","","","","","ISSN: 2165-0608","","","","affective computing; Computational modeling; emotion recognition; Face recognition; Faces; facial expression; Feature extraction; Mood; Robots; Three-dimensional displays; virtual human","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63HD845Y","conferencePaper","2018","Wen, J.; Stewart, A.; Billinghurst, M.; Tossell, C.","Band of Brothers and Bolts: Caring About Your Robot Teammate","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8594324","","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.","2018-10","2021-04-19 15:42:29","2021-04-19 15:42:29","","1853-1858","","","","","","","","","","","","","","","","","","","","ISSN: 2153-0866","","","","Atmospheric measurements; Bonding; Computer bugs; Particle measurements; Robots; Time measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7AWQYY9","conferencePaper","2019","Vertesi, J.","Seeing Like a Rover: Team Work and Human-Robot Relations","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673224","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019-03","2021-04-19 15:42:29","2021-04-19 15:42:29","","152-152","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Human-Robot Interaction; Teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPK9PV6F","conferencePaper","2020","Ye, S.; Feigh, K.; Howard, A.","Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223437","","Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.","2020-08","2021-04-19 15:42:29","2021-04-19 15:42:29","","1186-1189","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXAVZJL3","conferencePaper","2019","Charrier, L.; Rieger, A.; Galdeano, A.; Cordier, A.; Lefort, M.; Hassas, S.","The RoPE Scale: a Measure of How Empathic a Robot is Perceived","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673082","","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.","2019-03","2021-04-19 15:42:29","2021-04-19 15:42:29","","656-657","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Human-Robot Interaction; Indexes; Measurement; Perceived Empathy; Psychology; Psychometrics; Robot sensing systems; Social Robots; Software reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YULK9SNW","conferencePaper","2020","Cinieri, S.; Kapralos, B.; Uribe-Quevedo, A.; Lamberti, F.","Eye Tracking and Speech Driven Human-Avatar Emotion-Based Communication","2020 IEEE 8th International Conference on Serious Games and Applications for Health (SeGAH)","","","10.1109/SeGAH49190.2020.9201874","","Feelings, emotions, and empathy play an important role in many daily activities including verbal and non-verbal communication. Their automatic recognition and interpretation is important in a variety of applications requiring communication skills that are difficult to reproduce in computer-simulated environments, including those involving human-avatar interactions. Our recent work has begun investigating the development of intelligent avatars capable of detecting user (human) emotions to allow for realistic human-avatar interactions within medical-based virtual simulations and serious games. In this paper, we present a system that couples eye tracking and dialogue interpretation to allow for intelligent and realistic human-avatar communication. Although formal testing is required, preliminary results are promising, showing the potential of the system.","2020-08","2021-04-19 15:42:29","2021-04-19 15:42:29","","1-5","","","","","","","","","","","","","","","","","","","","ISSN: 2573-3060","","","","Avatars; Emotion; eye tracking; Games; Gaze tracking; human-avatar interaction; intelligent avatar; Medical diagnostic imaging; Medical services; mood; Speech recognition; Virtual environments; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"56JSUW3F","conferencePaper","2018","Raffe, W. L.; Garcia, J. A.","Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly","2018 IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH)","","","10.1109/SeGAH.2018.8401371","","This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations.","2018-05","2021-04-19 15:42:29","2021-04-19 15:42:29","","1-7","","","","","","","","","","","","","","","","","","","","ISSN: 2573-3060","","","","Avatars; Games; Senior citizens; Tracking; Training; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZP845LXS","conferencePaper","2016","Ranieri, C. M.; Romero, R. A. F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","10.1109/LARS-SBR.2016.13","","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.","2016-10","2021-04-19 15:42:29","2021-04-19 15:42:29","","31-36","","","","","","","","","","","","","","","","","","","","","","","","Affective computing; Emotions; Mobile devices; Robots; Social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSZFRFUU","conferencePaper","2015","Chumkamon, S.; Masato, K.; Hayashi, E.","Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot","2015 IEEE International Conference on Systems, Man, and Cybernetics","","","10.1109/SMC.2015.45","","This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).","2015-10","2021-04-19 15:42:29","2021-04-19 15:42:29","","185-190","","","","","","","","","","","","","","","","","","","","","","","","Animals; CBA; Face; Facial Expression Recognition; Human-Robot Interactio; Manipulators; Mathematical model; Neurotransmitters; Shape; Social Robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLK2UP55","conferencePaper","2020","Mitsuno, S.; Yoshikawa, Y.; Ishiguro, H.","Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223442","","In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.","2020-08","2021-04-19 15:42:30","2021-04-19 15:42:30","","653-658","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKR75NY5","conferencePaper","2019","Sanoubari, E.; Seo, S. H.; Garcha, D.; Young, J. E.; Loureiro-Rodríguez, V.","Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673326","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019-03","2021-04-19 15:42:30","2021-04-19 15:42:30","","382-391","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Cultural differences; culture; Ethics; Global communication; in the wild; Mood; persuasive robots; Robots; Shape; social robots; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSJM4Z5W","conferencePaper","2020","Nehra, V.; Nagpal, R.; Sehgal, R.","Collective Intelligence: When, Where and Why","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","10.1109/Confluence47617.2020.9058000","","The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.","2020-01","2021-04-19 15:42:30","2021-04-19 15:42:30","","805-810","","","","","","","","","","","","","","","","","","","","","","","","Aggregates; Artificial Intellegence; Collective intelligence; Collective Intelligence; Organizations; Particle swarm optimization; Social network services; Standards organizations; Swarm Intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVFI9RHP","conferencePaper","2020","Dixit, R.; Chinnam, R. B.; Singh, H.","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","2020 IEEE Aerospace Conference","","","10.1109/AERO47225.2020.9172612","","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.","2020-03","2021-04-19 15:42:30","2021-04-19 15:42:30","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 1095-323X","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6M65WH8","conferencePaper","2018","Churamani, N.; Barros, P.; Strahl, E.; Wermter, S.","Learning Empathy-Driven Emotion Expressions using Affective Modulations","2018 International Joint Conference on Neural Networks (IJCNN)","","","10.1109/IJCNN.2018.8489158","","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.","2018-07","2021-04-19 15:42:30","2021-04-19 15:42:30","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 2161-4407","","","","Adaptation models; Convolution; Emotion recognition; Mood; Neurons; Robot sensing systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WIDU6WAI","conferencePaper","2018","Kühnlenz, B.; Kühnlenz, K.; Busse, F.; Förtsch, P.; Wolf, M.","Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525515","","Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.","2018-08","2021-04-19 15:42:31","2021-04-19 15:42:31","","275-281","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Anthropomorphism; Color; Communication channels; Mood; Robots; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUF5M834","conferencePaper","2018","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.; Kutics, A.","Counseling Robot Implementation and Evaluation","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2018.00297","","A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called ""unazuki"" in Japanese, a kind of nodding to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared.","2018-10","2021-04-19 15:42:31","2021-04-19 15:42:31","","1716-1722","","","","","","","","","","","","","","","","","","","","ISSN: 2577-1655","","","","Counseling; Dialog Promotion; Dictionaries; Employee welfare; Natural languages; Nodding; Ontologies; Reflection; Robot; Robot sensing systems; unazuki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBY54WBN","conferencePaper","2017","Anshar, M.; Williams, M.","Evolving artificial pain from fault detection through pattern data analysis","2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)","","","10.1109/RCAR.2017.8311945","","Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.","2017-07","2021-04-19 15:42:31","2021-04-19 15:42:31","","694-699","","","","","","","","","","","","","","","","","","","","","","","","Data analysis; Machinery; Pain; Planning; Robot sensing systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIAZ8PYH","conferencePaper","2018","Iranzo, R. M. G.; Padilla-Zea, N.; Paderewski-Rodríguez, P.; González-González, C. S.","Empathy and virtual agents for learning applications in symbiotic systems","2018 IEEE Global Engineering Education Conference (EDUCON)","","","10.1109/EDUCON.2018.8363298","","Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges.","2018-04","2021-04-19 15:42:31","2021-04-19 15:42:31","","694-697","","","","","","","","","","","","","","","","","","","","ISSN: 2165-9567","","","","Biometrics (access control); bot; empathy; ethics; Ethics; Guidelines; Observers; Privacy; robot; Robots; Symbiosis; symbiotic agents; transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMWVXBWY","conferencePaper","2015","Hood, D.; Lemaignan, S.; Dillenbourg, P.","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.By leveraging simulated handwriting on a synchronised tablet display, a NAo humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models.Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015-03","2021-04-19 15:42:31","2021-04-19 15:42:31","","83-90","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Education; Humanoid robots; Mathematical model; Principal component analysis; Shape; Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHAGN6KA","conferencePaper","2017","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Design of Counseling Robot for Production by 3D Printer","2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS)","","","10.1109/SITIS.2017.20","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling.","2017-12","2021-04-19 15:42:32","2021-04-19 15:42:32","","56-62","","","","","","","","","","","","","","","","","","","","","","","","Cognition; Counseling; Dialog Promotion; Emotion recognition; Employee welfare; Nodding; Problem-solving; Psychology; Reflection; Robot; Robots; unazuki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRWB7IZN","conferencePaper","2019","Chiu, K. C.","Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation","2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","","","10.1109/IEEM44572.2019.8978876","","This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence.","2019-12","2021-04-19 15:42:32","2021-04-19 15:42:32","","1516-1520","","","","","","","","","","","","","","","","","","","","ISSN: 2157-362X","","","","Artificial Intelligence; Dream Consultation; Knowledge Management; Semantic Analytics; Text Mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"829WIVQ8","conferencePaper","2020","Wang, Z.","Future Challenges in the Next Generation of Voice User Interface","2020 International Conference on Computing and Data Science (CDS)","","","10.1109/CDS49703.2020.00045","","With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI.","2020-08","2021-04-19 15:42:32","2021-04-19 15:42:32","","191-193","","","","","","","","","","","","","","","","","","","","","","","","accessibility; artificial intelligence; Data science; user interface; voice user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4TA4KYB","conferencePaper","2019","Costantini, S.; Gasperis, G. De; Migliarini, P.","Multi-agent System Engineering for Emphatic Human-Robot Interaction","2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","","","10.1109/AIKE.2019.00015","","Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy.","2019-06","2021-04-19 15:42:32","2021-04-19 15:42:32","","36-42","","","","","","","","","","","","","","","","","","","","","","","","affect; communication; emotions; empathy; Face; Face recognition; human robot interaction; logic; Multi-agent systems; perception; Robot kinematics; Skin; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W7FZW362","conferencePaper","2018","Tuyen, N. T. Viet; Jeong, S.; Chong, N. Y.","Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8593974","","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.","2018-10","2021-04-19 15:42:32","2021-04-19 15:42:32","","2008-2013","","","","","","","","","","","","","","","","","","","","ISSN: 2153-0866","","","","Collision avoidance; Neurons; Robot kinematics; Self-organizing feature maps; Training; Trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSL555HV","conferencePaper","2018","Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.","Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression","2018 15th International Conference on Ubiquitous Robots (UR)","","","10.1109/URAI.2018.8441767","","Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.","2018-06","2021-04-19 15:42:32","2021-04-19 15:42:32","","377-382","","","","","","","","","","","","","","","","","","","","","","","","Cultural differences; Human-robot interaction; Neurons; Psychology; Robots; Self-organizing feature maps; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVWGX4UR","conferencePaper","2019","Das, A. K.; Ashrafi, A.; Ahmmad, M.","Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","10.1109/CCOMS.2019.8821655","","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.","2019-02","2021-04-19 15:42:32","2021-04-19 15:42:32","","36-40","","","","","","","","","","","","","","","","","","","","","","","","Case; Decision making; Forecasting; Human Guided; Judge; Judicial System; Law; Machine intelligence; Machine learning algorithms; Machine learning Framework; Predict Punishment; Predictive models; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHJ8QZUI","conferencePaper","2019","Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.","2019-12","2021-04-19 15:42:32","2021-04-19 15:42:32","","1564-1571","","","","","","","","","","","","","","","","","","","","","","","","Big Data; Cloud computing; deep learning; Distributed processing; Electromagnetic interference; Erbium; mental illness; online empathy.; Social computing; social media; social network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YK2TJRIV","conferencePaper","2017","Tuyen, N. T. V.; Jeong, S.; Chong, N. Y.","Learning human behavior for emotional body expression in socially assistive robotics","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","","","10.1109/URAI.2017.7992882","","Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots.","2017-06","2021-04-19 15:42:33","2021-04-19 15:42:33","","45-50","","","","","","","","","","","","","","","","","","","","","","","","clustering; emotional body expression; human-robot interaction; Human-robot interaction; imitation learning; Kernel; Neurons; Psychology; Robots; Skeleton; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBFDZ9L4","conferencePaper","2017","Kurashige, K.; Tsuruta, S.; Sakurai, E.; Sakurai, Y.; Knauf, R.; Damiani, E.","Context respectful counseling agent integrated with robot nodding for dialog promotion","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2017.8122833","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling.","2017-10","2021-04-19 15:42:33","2021-04-19 15:42:33","","1540-1545","","","","","","","","","","","","","","","","","","","","","","","","Cognition; Counseling; Dialog Promotion; Dictionaries; Employee welfare; Nodding; Ontologies; Problem-solving; Reflection; Robot; Robots; unazuki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7L7FJI4E","journalArticle","2016","Roudposhti, K. K.; Nunes, U.; Dias, J.","Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns","IEEE Transactions on Pattern Analysis and Machine Intelligence","","1939-3539","10.1109/TPAMI.2015.2496209","","Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.","2016-08","2021-04-19 15:42:33","2021-04-19 15:42:33","","1679-1691","","8","38","","","","","","","","","","","","","","","","","","","","","Analytical models; Bayes methods; Bayesian approach; Feature extraction; frequency domain; Histograms; human movement analysis; Human-robot interaction; Shape; social role; Social signal processing; Three-dimensional displays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RIFT6C9","conferencePaper","2015","Rasool, Z.; Masuyama, N.; Islam, M. N.; Loo, C. K.","Empathic Interaction Using the Computational Emotion Model","2015 IEEE Symposium Series on Computational Intelligence","","","10.1109/SSCI.2015.26","","This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.","2015-12","2021-04-19 15:42:33","2021-04-19 15:42:33","","109-116","","","","","","","","","","","","","","","","","","","","","","","","Clustering algorithms; Computational modeling; Face; Face recognition; Mood; Robots; Shape","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JUNJ5KU","conferencePaper","2016","Hervás, R.; Johnson, E.; Franca, C. Gutierrez López de la; Bravo, J.; Mondéjar, T.","A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars","2016 15th International Conference on Ubiquitous Computing and Communications and 2016 International Symposium on Cyberspace and Security (IUCC-CSS)","","","10.1109/IUCC-CSS.2016.021","","Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability.","2016-12","2021-04-19 15:42:33","2021-04-19 15:42:33","","93-100","","","","","","","","","","","","","","","","","","","","","","","","Affective Computing; Avatars; Cognitive Health; Emotion recognition; Games; Human-Avatar Interaction; Machine Learning; Object recognition; Proposals; Psychology; Social Communication Disorders; Taxonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MSPLTPH","conferencePaper","2015","Headleand, C. J.; Jackson, J.; Priday, L.; Teahan, W.; Cenydd, L. A.","Does the Perceived Identity of Non-player Characters Change How We Interact with Them?","2015 International Conference on Cyberworlds (CW)","","","10.1109/CW.2015.35","","Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it.","2015-10","2021-04-19 15:42:33","2021-04-19 15:42:33","","145-152","","","","","","","","","","","","","","","","","","","","","","","","Artificial intelligence; Ash; Avatars; CASA; Computers; Games; Games AI; Human Agent Interaction; Identity; NPC; Robots; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRLA4Z6D","conferencePaper","2017","Restrepo, E. G. y; Boticario, J. G.","Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","","","10.1109/ICE.2017.8280067","","This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society.","2017-06","2021-04-19 15:42:33","2021-04-19 15:42:33","","1552-1558","","","","","","","","","","","","","","","","","","","","","","","","Accessibility; Afective computing; Artificial Intelligence; Assistive technology; Cultural differences; Diversity; Economics; Education; Empathy; Gesture recognition; Intelligent systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MJFXETK","conferencePaper","2015","Tahir, Y.; Chakraborty, D.; Maszczyk, T.; Dauwels, S.; Dauwels, J.; Thalmann, N.; Thalmann, D.","Real-time sociometrics from audio-visual features for two-person dialogs","2015 IEEE International Conference on Digital Signal Processing (DSP)","","","10.1109/ICDSP.2015.7251991","","This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.","2015-07","2021-04-19 15:42:33","2021-04-19 15:42:33","","823-827","","","","","","","","","","","","","","","","","","","","ISSN: 2165-3577","","","","Accuracy; audiovisual analysis; Conferences; dialog; Feature extraction; machine learning; real-time; Real-time systems; Signal processing; sociometrics; Speech; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7WPIWMB","conferencePaper","2020","Filho, L. A. D. Lusquino; Oliveira, L. F. R.; Carneiro, H. C. C.; Guarisa, G. P.; Filho, A. L.; França, F. M. G.; Lima, P. M. V.","A weightless regression system for predicting multi-modal empathy","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","","","10.1109/FG47880.2020.00086","","This work takes into account the benefits of machine learning in order to estimate the valence of emotions on the OMG Empathy dataset, considering the information obtained from face expressions and dialogue of interlocutors. RegressionWiSARD and ClusRegressionWiSARD n-tuple regressors and its ensembles were employed to this end. The best performance achieved among all the combinations of weightless neural models considered (evaluated using the CCC metric) was 0.25 in validation set of the Personalized Track.","2020-11","2021-04-19 15:42:34","2021-04-19 15:42:34","","657-661","","","","","","","","","","","","","","","","","","","","","","","","Bagging; Computational modeling; empathy prediction; Mel frequency cepstral coefficient; Predictive models; Random access memory; regression wisard; Training; Videos; weightless artificial neural network; wisard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4PJHXCC","conferencePaper","2020","Perusquía-Hernández, M.; Balda, M. C.; Jáuregui, D. A. Gómez; Paez-Granados, D.; Dollack, F.; Salazar, J. V.","Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User’s Physiological Affective States","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223598","","Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.","2020-08","2021-04-19 15:42:34","2021-04-19 15:42:34","","1328-1333","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","embodiment; empathy and intersubjectivity; haptic feedback; Haptic interfaces; Heart rate; human-machine interaction; Physiology; Robot sensing systems; Robots; Vibrations; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C3D34AHD","journalArticle","2020","Rafique, M.; Hassan, M. A.; Jaleel, A.; Khalid, H.; Bano, G.","A Computation Model for Learning Programming and Emotional Intelligence","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3015533","","Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.","2020","2021-04-19 15:42:34","2021-04-19 15:42:34","","149616-149629","","","8","","","","","","","","","","","","","","","","","","","","","basic programming; Computational modeling; Education; Emotional intelligence; Programming profession; Robots; robots based learning; screen-free interface; Sequential analysis; Tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
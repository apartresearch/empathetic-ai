"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"LF77RFTT","conferencePaper","2018","James, Jesin; Watson, Catherine Inez; MacDonald, Bruce","Artificial Empathy in Social Robots: An analysis of Emotions in Speech","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525652","","Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.","2018-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","632-637","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Task analysis; Medical services; Human-robot interaction; Robot sensing systems; Anthropomorphism; Standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IUU84GN","conferencePaper","2019","Peterson, Jordan; Cohen, Chase; Harrison, Paige; Novak, Jonathan; Tossell, Chad; Phillips, Elizabeth","Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming","2019 Systems and Information Engineering Design Symposium (SIEDS)","","","10.1109/SIEDS.2019.8735613","","The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.","2019-04","2021-05-19 12:41:47","2021-05-19 12:41:47","","1-6","","","","","","","","","","","","","","","","","","","","","","","","Stress; Task analysis; Human-robot interaction; Robots; Atmospheric measurements; Particle measurements; Battery charge measurement; Human-machine teaming; Military aircraft","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4NB53SJ","conferencePaper","2020","Simons, Ama; Doyle, Thomas; Musson, David; Reilly, James","Impact of Physiological Sensor Variance on Machine Learning Algorithms","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC42975.2020.9282912","","Machine learning based acute stress detection systems use physiological sensor data to objectively predict acute stress. However, machine learning algorithms developed for stress detection do not consider how machine learning algorithm performance may be affected based on a change(s) in the deployment environment. In this study, the deployment environment changes that are investigated are sensor type and sensor placement. Electrodermal activity (EDA) and skin temperature (TEMP) data from two different sensors, the RespiBAN Professional (RespiBAN) and the Empatica E4 are used to train three different machine learning models. The RespiBAN records the EDA data from the rectus abdominis and records the skin TEMP data from the sternum. The Empatica E4 sensor records both EDA and skin TEMP data from the wrist. Three different support vector machine (SVM) models were trained to classify no-stress versus stress states using EDA and skin TEMP data. The first model was trained using data from the RespiBAN wearable sensor (SVM-R), the second model was trained using data from the Empatica E4 sensor (SVM-E) and third model was trained using data from both sensors (SVM-RE). The accuracy of SVM-R on a test set recorded by the RespiBAN sensor was 100%. The accuracy of SVM-E on a test set recorded by the Empatica E4 sensor was 99%. The accuracy of SVM-RE on a test set recorded by both the RespiBAN and Empatica E4 sensor was 82%. The accuracy of the SVM-R on a test set recorded by the Empatica E4 was 64%. These results suggest that research and development cannot be hardware or placement agnostic with wearable sensing data. Sensor type and placement must be taken into consideration when reporting performance metrics of physiological based stress detection machine learning algorithms.","2020-10","2021-05-19 12:41:47","2021-05-19 12:41:47","","241-247","","","","","","","","","","","","","","","","","","","","ISSN: 2577-1655","","","","Stress; Machine learning; Data models; Machine learning algorithms; Skin; Physiology; support vector machine; Support vector machines; stress detection; wearable physiological sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8VDFW2Y","conferencePaper","2015","Darling, Kate; Nandy, Palash; Breazeal, Cynthia","Empathic concern and the effect of stories in human-robot interaction","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2015.7333675","","People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.","2015-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","770-775","","","","","","","","","","","","","","","","","","","","","","","","Media; Human-robot interaction; Robots; Atmospheric measurements; Indexes; Particle measurements; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FNNDRVXI","conferencePaper","2017","Burns, Henriette D.; Lesseig, Kristin","Empathy in middle school engineering design process","2017 IEEE Frontiers in Education Conference (FIE)","","","10.1109/FIE.2017.8190669","","This work-in-progress studies empathy in middle-school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy-based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.","2017-10","2021-05-19 12:41:47","2021-05-19 12:41:47","","1-4","","","","","","","","","","","","","","","","","","","","","","","","empathy; design process; 5G mobile communication; after-school science club; Computer bugs; engineering; middle school","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VYKSHQE5","conferencePaper","2015","Rasool, Zeeshan; Masuyama, Naoki; Islam, Md. Nazrul; Loo, Chu Kiong","Empathic Interaction Using the Computational Emotion Model","2015 IEEE Symposium Series on Computational Intelligence","","","10.1109/SSCI.2015.26","","This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.","2015-12","2021-05-19 12:41:47","2021-05-19 12:41:47","","109-116","","","","","","","","","","","","","","","","","","","","","","","","Computational modeling; Robots; Face; Face recognition; Shape; Mood; Clustering algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6R5YVFG","conferencePaper","2018","Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H","Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525777","","Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.","2018-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","783-789","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Task analysis; Robots; Videos; Face recognition; Mirrors; Observers; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUDECYJY","conferencePaper","2015","Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.","Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI. Categories and Subject Descriptors H.5.2 [User Interfaces]: evaluation/methodology General Terms Experimentation and Human Factors.","2015-03","2021-05-19 12:41:47","2021-05-19 12:41:47","","125-132","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Computational modeling; Programming; Psychology; empathy; Human-robot interaction; Robots; Videos; Instruments; robot embodiment; simulated interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WII43CUQ","journalArticle","2015","Pablos, Samuel Marcos; García-Bermejo, Jaime Gómez; ZalamaCasanova, Eduardo; López, Joaquín","Dynamic Facial Emotion Recognition Oriented to HCI Applications","Interacting with Computers","","1873-7951","10.1093/iwc/iwt057","","As part of a multimodal animated avatar previously presented in Marcos-Pablos et al. ((2010) A realistic, virtual head for human-computer interaction. Interact. Comput., 22, 176–192, ISSN 0953-5438), in this paper we describe a method for dynamic recognition of displayed facial emotions on low-resolution streaming images. First, we address the detection of action units (AUs) of the facial action coding system using active shape models and Gabor filters. Normalized outputs of the AU recognition step are then used as inputs for a neural network that consists of an habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations, thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates. To assess the suitability of the developed emotional recognition system for human–computer interaction applications, it has been successfully integrated in the architecture of an avatar and we have conducted a preliminary experiment on empathy. The experiment showed promising results, as the avatar that made use of the emotional recognition system obtained a clear increase in the positivity of the rating when compared with the same avatar with no emotional response.","2015-03","2021-05-19 12:41:47","2021-05-19 12:41:47","","99-119","","2","27","","","","","","","","","","","","","","","","","","","","","agent-based interaction; computer vision; empirical studies in ubiquitous and mobile computing; gestural input; graphical user interfaces; intelligent avatars","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UBPMUAWD","conferencePaper","2018","Febtriko, Anip; Rahayuningsih, Tri; Septiani, Dinda; Trisnawati, Liza; Arisandi, Diki; Sukri","Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome","2018 International Conference on Applied Information Technology and Innovation (ICAITI)","","","10.1109/ICAITI.2018.8686759","","Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.","2018-09","2021-05-19 12:41:47","2021-05-19 12:41:47","","208-212","","","","","","","","","","","","","","","","","","","","","","","","Mobile Robot; Android; Asperger syndrome; Rank Wilcoxon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NL59LW89","conferencePaper","2019","Mallol-Ragolta, Adria; Schmitt, Maximilian; Baird, Alice; Cummins, Nicholas; Schuller, Björn","Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition","2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019)","","","10.1109/FG.2019.8756517","","The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual (OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient (CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.","2019-05","2021-05-19 12:41:47","2021-05-19 12:41:47","","1-5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLFGTANF","conferencePaper","2019","Carranza, Karmelo Antonio Lazaro R.; Manalili, Joshua; Bugtai, Nilo T.; Baldovino, Renann G.","Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots","2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)","","","10.1109/RITAPP.2019.8932852","","Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.","2019-11","2021-05-19 12:41:47","2021-05-19 12:41:47","","160-163","","","","","","","","","","","","","","","","","","","","","","","","Deep learning; Psychology; deep learning; Cognitive science; Affective computing; affective computing; Robots; Chatbot; Computer science; emotionally aware technology; facial expression detection; scripted chatbot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPJL5VQ6","conferencePaper","2019","DiPaola, Steve; Yalçin, Özge Nilay","A multi-layer artificial intelligence and sensing based affective conversational embodied agent","2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)","","","10.1109/ACIIW.2019.8925291","","Building natural and conversational virtual humans is a task of formidable complexity. We believe that, especially when building agents that affectively interact with biological humans in real-time, a cognitive science-based, multilayered sensing and artificial intelligence (AI) systems approach is needed. For this demo, we show a working version (through human interaction with it) our modular system of natural, conversation 3D virtual human using AI or sensing layers. These including sensing the human user via facial emotion recognition, voice stress, semantic meaning of the words, eye gaze, heart rate, and galvanic skin response. These inputs are combined with AI sensing and recognition of the environment using deep learning natural language captioning or dense captioning. These are all processed by our AI avatar system allowing for an affective and empathetic conversation using an NLP topic-based dialogue capable of using facial expressions, gestures, breath, eye gaze and voice language-based two-way back and forth conversations with a sensed human. Our lab has been building these systems in stages over the years.","2019-09","2021-05-19 12:41:47","2021-05-19 12:41:47","","91-92","","","","","","","","","","","","","","","","","","","","","","","","artificial intelligence; Machine learning; deep learning; biosensing; affective computing; conversational agent; Emotion recognition; Real-time systems; Biosensors; embodied agent; embodied character agents; sensing systems; Streaming media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Y5P7N66","conferencePaper","2019","Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amélie; Lefort, Mathieu; Hassas, Salima","The RoPE Scale: a Measure of How Empathic a Robot is Perceived","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673082","","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.","2019-03","2021-05-19 12:41:47","2021-05-19 12:41:47","","656-657","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Psychology; Psychometrics; Indexes; Robot sensing systems; Human-Robot Interaction; Measurement; Perceived Empathy; Social Robots; Software reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZSJNBWH","conferencePaper","2016","Egawa, Shoichi; Sejima, Yoshihiro; Sato, Yoichiro; Watanabe, Tomio","A laughing-driven pupil response system for inducing empathy","2016 IEEE/SICE International Symposium on System Integration (SII)","","","10.1109/SII.2016.7844051","","Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.","2016-12","2021-05-19 12:41:47","2021-05-19 12:41:47","","520-525","","","","","","","","","","","","","","","","","","","","ISSN: 2474-2325","","","","Timing; Robots; Computer science; Mathematical model; Solid modeling; Speech; Three-dimensional displays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJMPUZ59","conferencePaper","2020","Rossi, Silvia; Dell’Aquila, Elena; Russo, Davide; Maggi, Gianpaolo","Increasing Engagement with Chameleon Robots in Bartending Services","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223488","","As the field of service robotics has been rapidly growing, it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way. This is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users' experience. In this paper, we address the question of whether a specific behavioral style of a barman-robot, acted through para-verbal and non-verbal behaviors, can affect users' engagement and the creation of positive emotions. To that end, we endowed a barman-robot taking drink orders from human customers, with an empathic behavioral style. This aims at triggering to alignment process by mimicking the conversation partner's behavior. This behavioral style is compared to an entertaining style, aiming at creating a positive relationship with the users, and a neutral style for control. Results suggest that when participants experienced more positive emotions, the robot was perceived as safer, so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement. Indeed, when the empathic robot modulates its behavior according to the user's one, this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in public-service contexts.","2020-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","464-469","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFQJQQFB","conferencePaper","2015","Marti, Patrizia; Iacono, Iolanda","Social and empathic behaviours: Novel interfaces and interaction modalities","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2015.7333634","","This paper describes the results of a research conducted in the European project Accompany, whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home. The project developed a system consisting of a robotic companion, Care-O-bot, as part of a smart environment. An intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot. The paper is articulated in two parts. The first part illustrates the theory that inspired the development of a context-aware Graphical User Interface (GUI) used to interact with the robot. The GUI integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges. The second part focuses on the user evaluation, and reports the outcomes from three different tests. The results of the first two tests show a positive acceptance of the GUI by the older people. The final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot.","2015-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","217-222","","","","","","","","","","","","","","","","","","","","","","","","Context; Cognitive science; Senior citizens; Robot sensing systems; Observers; Graphical user interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48NXMLHI","conferencePaper","2018","Wen, James; Stewart, Amanda; Billinghurst, Mark; Tossell, Chad","Band of Brothers and Bolts: Caring About Your Robot Teammate","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8594324","","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.","2018-10","2021-05-19 12:41:47","2021-05-19 12:41:47","","1853-1858","","","","","","","","","","","","","","","","","","","","ISSN: 2153-0866","","","","Robots; Atmospheric measurements; Particle measurements; Computer bugs; Bonding; Time measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EM72BAK","conferencePaper","2019","Ghandeharioun, Asma; McDuff, Daniel; Czerwinski, Mary; Rowan, Kael","Towards Understanding Emotional Intelligence for Behavior Change Chatbots","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","","","10.1109/ACII.2019.8925433","","A natural conversational interface that allows longitudinal symptom tracking would be extremely valuable in health/wellness applications. However, the task of designing emotionally-aware agents for behavior change is still poorly understood. In this paper, we present the design and evaluation of an emotion-aware chatbot that conducts experience sampling in an empathetic manner. We evaluate it through a human-subject experiment with N=39 participants over the course of a week. Our results show that extraverts preferred the emotion-aware chatbot significantly more than introverts. Also, participants reported a higher percentage of positive mood reports when interacting with the empathetic bot. Finally, we provide guidelines for the design of emotion-aware chatbots for potential use in mHealth contexts.","2019-09","2021-05-19 12:41:47","2021-05-19 12:41:47","","8-14","","","","","","","","","","","","","","","","","","","","ISSN: 2156-8111","","","","Stress; Visualization; Statistics; emotional intelligence; affective computing; mental health; Games; Mood; Mobile applications; agent; experience sampling; Sociology; System analysis and design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WNDLHYI","conferencePaper","2020","Corretjer, Marialejandra García; Ros, Raquel; Martin, Fernando; Miralles, David","The Maze of Realizing Empathy with Social Robots","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223466","","Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.","2020-08","2021-05-19 12:41:47","2021-05-19 12:41:47","","1334-1339","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ARCRM3E","conferencePaper","2015","Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani-Sherman, Tal","Design and Evaluation of a Peripheral Robotic Conversation Companion","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote nonaggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to-human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.","2015-03","2021-05-19 12:41:47","2021-05-19 12:41:47","","3-10","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Monitoring; Empathy; Human-robot interaction; Robot sensing systems; Ambient kinetic tangibles; Animation; Behavior change; Design; Kinetic theory; Robotic companions; Shape; Smartphone robots.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z6TU8JY3","conferencePaper","2016","Li, Chaochao; Jia, Qingxuan; Feng, Yongli","Human-Robot Interactoin Design for Robot-Assisted Intervention for Children with Autism Based on E-S Theory","2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","","","10.1109/IHMSC.2016.103","","The paper presents a novel human-robot interaction (HRI) framework to assist intervention for children with autism, based on Empathizing-Systemizing (E-S) theory. E-S theory explains the social difficulties in autism as the result of deficits or delays in empathizing, while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing. In this paper, the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robot-assisted intervention, which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism. The design of HRI scenarios and tasks based on E-S theory makes the robot-assisted intervention more effective and efficient.","2016-08","2021-05-19 12:41:48","2021-05-19 12:41:48","","320-324","","","02","","","","","","","","","","","","","","","","","","","","","social robot; Human-robot interaction; Emotion recognition; Robot sensing systems; Autism; autism therapy; Human Robot Interaction (HRI); Empathizing-Systemizing (E-S) theory; Load modeling; Systematics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYYAD6IM","journalArticle","2020","Cuzzocrea, Alfredo; Pilato, Giovanni","A composite framework for supporting user emotion detection based on intelligent taxonomy handling","Logic Journal of the IGPL","","1368-9894","10.1093/jigpal/jzaa047","","One of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her. The first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper. The system can analyze the Twitter ID of the new acquaintance, trying to detect the IAB (Interactive Advertising Bureau) Tier 1 categories that possibly can let arise in him/her a joyful feeling. Furthermore, it can retrieve news about that category and report them to the user, hopefully increasing his/her curiosity towards the system, improving the naturalness of the interaction. Moreover, the system is capable of querying Wikipedia in order to clarify any doubts that may arise in the user. A sample of a possible interaction is reported at the end of the paper.","2020-01","2021-05-19 12:41:48","2021-05-19 12:41:48","","207-219","","1","29","","","","","","","","","","","","","","","","","","","","","human–robot interaction; affective AI; Taxonomies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2P34R59","conferencePaper","2019","Sripian, Peeraya; Kurono, Yuya; Yoshida, Reiji; Sugaya, Midori","Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals","2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN46459.2019.8956353","","Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.","2019-10","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIZAUKKD","conferencePaper","2016","Sin, Yap Miao; Robin; Liang, Qiao; Tani, Koyu; Ogawa, Ken-ichiro; Miyake, Yoshihiro","Evaluation of a head motion synchronization system in the communicative process between human and robot","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","","","10.1109/SICE.2016.7749252","","An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.","2016-09","2021-05-19 12:41:48","2021-05-19 12:41:48","","1514-1519","","","","","","","","","","","","","","","","","","","","","","","","human-robot interaction; Human-robot interaction; Robots; Senior citizens; Acceleration; Accelerometers; Aging; Head motion synchronization; mutual entrainment; Synchronization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3CN3J9Y","conferencePaper","2020","Sönmez, Elena Battini; Köse, Hatice; Barkana, Duygun Erol","Towards a New Computational Affective System for Personal Assistive Robots","2020 28th Signal Processing and Communications Applications Conference (SIU)","","","10.1109/SIU49456.2020.9302238","","The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively.","2020-10","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-4","","","","","","","","","","","","","","","","","","","","ISSN: 2165-0608","","","","Computational modeling; emotion recognition; affective computing; virtual human; Robots; facial expression; Face recognition; Three-dimensional displays; Faces; Feature extraction; Mood","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSUVQHIF","conferencePaper","2016","Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra","How expressiveness of a robotic tutor is perceived by children in a learning environment","2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2016.7451787","","We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.","2016-03","2021-05-19 12:41:48","2021-05-19 12:41:48","","423-424","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Psychology; Human-robot interaction; Robots; Computer science; Instruments; Europe; Information technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2LLCJ3I","conferencePaper","2019","Vertesi, Janet","Seeing Like a Rover: Team Work and Human-Robot Relations","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673224","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go - in search and rescue operations, ocean voyages, or even into space - they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology. This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' “eyes” on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team. Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019-03","2021-05-19 12:41:48","2021-05-19 12:41:48","","152-152","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Teamwork; Human-Robot Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSIBWFZS","conferencePaper","2020","Ye, Sean; Feigh, Karen; Howard, Ayanna","Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223437","","Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.","2020-08","2021-05-19 12:41:48","2021-05-19 12:41:48","","1186-1189","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V79LYH7B","conferencePaper","2020","Cinieri, Saverio; Kapralos, Bill; Uribe-Quevedo, Alvaro; Lamberti, Fabrizio","Eye Tracking and Speech Driven Human-Avatar Emotion-Based Communication","2020 IEEE 8th International Conference on Serious Games and Applications for Health (SeGAH)","","","10.1109/SeGAH49190.2020.9201874","","Feelings, emotions, and empathy play an important role in many daily activities including verbal and non-verbal communication. Their automatic recognition and interpretation is important in a variety of applications requiring communication skills that are difficult to reproduce in computer-simulated environments, including those involving human-avatar interactions. Our recent work has begun investigating the development of intelligent avatars capable of detecting user (human) emotions to allow for realistic human-avatar interactions within medical-based virtual simulations and serious games. In this paper, we present a system that couples eye tracking and dialogue interpretation to allow for intelligent and realistic human-avatar communication. Although formal testing is required, preliminary results are promising, showing the potential of the system.","2020-08","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-5","","","","","","","","","","","","","","","","","","","","ISSN: 2573-3060","","","","Emotion; Medical diagnostic imaging; Medical services; virtual reality; Avatars; Games; Speech recognition; mood; eye tracking; human-avatar interaction; Gaze tracking; intelligent avatar; Virtual environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBFM73MP","conferencePaper","2018","Raffe, William L.; Garcia, Jaime A.","Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly","2018 IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH)","","","10.1109/SeGAH.2018.8401371","","This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations.","2018-05","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-7","","","","","","","","","","","","","","","","","","","","ISSN: 2573-3060","","","","Visualization; Training; Senior citizens; Avatars; Games; Tracking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V73PW8LP","conferencePaper","2016","Ranieri, Caetano Mazzoni; Romero, Roseli A.F.","An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction","2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR)","","","10.1109/LARS-SBR.2016.13","","Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.","2016-10","2021-05-19 12:41:48","2021-05-19 12:41:48","","31-36","","","","","","","","","","","","","","","","","","","","","","","","Emotions; Affective computing; Robots; Social robots; Mobile devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5EJY63E","conferencePaper","2015","Chumkamon, Sakmongkon; Masato, Koike; Hayashi, Eiji","Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot","2015 IEEE International Conference on Systems, Man, and Cybernetics","","","10.1109/SMC.2015.45","","This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).","2015-10","2021-05-19 12:41:48","2021-05-19 12:41:48","","185-190","","","","","","","","","","","","","","","","","","","","","","","","Animals; Face; Mathematical model; Shape; CBA; Facial Expression Recognition; Human-Robot Interactio; Manipulators; Neurotransmitters; Social Robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6WZJZHQM","conferencePaper","2019","Chai, Yibo; Wu, Fengyang; Sun, Rui; Zhang, Zhongliang; Bao, Jie; Ma, Runxin; Peng, Qizhou; Wu, Danqin; Wan, Yexing; Li, Keyu","Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)","","","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230","","Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.","2019-12","2021-05-19 12:41:48","2021-05-19 12:41:48","","1564-1571","","","","","","","","","","","","","","","","","","","","","","","","Big Data; social media; deep learning; Cloud computing; Distributed processing; Electromagnetic interference; Erbium; mental illness; Social computing; online empathy.; social network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NU8PALC6","conferencePaper","2020","Mitsuno, Seiya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi","Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223442","","In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.","2020-08","2021-05-19 12:41:48","2021-05-19 12:41:48","","653-658","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJSLLDKB","conferencePaper","2019","Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica","Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673326","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019-03","2021-05-19 12:41:48","2021-05-19 12:41:48","","382-391","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Ethics; Task analysis; culture; social robots; Robots; Cultural differences; Shape; Mood; Global communication; in the wild; persuasive robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTZNSE3B","conferencePaper","2018","Ota, Kenshi; Jimenez, Felix; Yoshikawa, Tomohiro; Furuhashi, Takeshi","Sympathy-Expression Method for Educational-Support Robots Based on Writing Times","2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","","","10.1109/FUZZ-IEEE.2018.8491635","","In recent years, educational-support robots that can assist human learners have been attracting the attention of researchers. However, learners feel that these robots have monotonous behaviors, making collaborative learning with the robot a boring experience. To solve this problem, a previous study proposed using the sympathy-expression method in which the robot expresses its own emotions autonomously on the basis of the answer time. However, we propose the notion that the writing time should also be considered. The writing time is defined as the time taken by the learners to answer the questions. When learners wrote a lot, the answer time became long and the robot (in the previous method) used to express emotions of sleep. To empathize with the learners, it is important for the robot to express emotions of arousal. Therefore, in this paper, we propose the sympathy-expression method, which expresses emotions based on the writing time.","2018-07","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-6","","","","","","","","","","","","","","","","","","","","","","","","Education; Robots; Conferences; Time measurement; Writing; Learning systems; Fuzzy logic; background subtraction; educational-support robots; SD method; sympathy expression method","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDNFCKQS","conferencePaper","2019","Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher","Mutual Reinforcement Learning with Robot Trainers","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2019.8673284","","The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.","2019-03","2021-05-19 12:41:48","2021-05-19 12:41:48","","572-573","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Cognition; Task analysis; Reinforcement learning; Cognitive science; Adaptation models; Human-robot interaction; Robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZ53TJ23","conferencePaper","2020","Nehra, Vanshika; Nagpal, Renuka; Sehgal, Rajni","Collective Intelligence: When, Where and Why","2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","10.1109/Confluence47617.2020.9058000","","The term “Collective” is just not restricted to the human beings but can also be referred to the organisms such as flock of birds, swarm of bees, colony of bats etc. In computer environments, the term may also refer to groups of virtual artificially intelligent agents. Most generally it can applicable to the workings of the entire planet or universe as smart organization whose intelligence is supplied and manifested through the entities within it. Collective Intelligence is a no new terms infact it's been used from several decades now but what's new is the emergence of computer technology which makes it a new and one of the most promising application of it used in a variety of field. Machine learning and Artificial Intelligence are making an enormous buzz around the world. The plenty of utilizations in Artificial Intelligence have changed the substance of innovation. This paper would give an overview of the promising future aspects and researches in the field of Collective Intelligence in brief. We need to concentrate on the elements that guide collective intelligence if we really want to optimize our groups for excellent cooperation. We need to concentrate on personality characteristics that are not so simple to follow, yet they are critical to the long-term achievement of organizations, such as intellect, consciousness, compassion, empathy, and regard. In this paper along with the definition of the Collective Intelligence, it would be measured, compared with individual intelligence and its applications are studied in brief.","2020-01","2021-05-19 12:41:48","2021-05-19 12:41:48","","805-810","","","","","","","","","","","","","","","","","","","","","","","","Collective Intelligence; Aggregates; Artificial Intellegence; Collective intelligence; Organizations; Particle swarm optimization; Social network services; Standards organizations; Swarm Intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XVUFQLF","conferencePaper","2020","Dixit, Rahul; Chinnam, Ratne Babu; Singh, Harpreet","Artificial Intelligence and Machine Learning in Sparse/Inaccurate Data Situations","2020 IEEE Aerospace Conference","","","10.1109/AERO47225.2020.9172612","","Machine Learning (ML) and other artificial Intelligence (AI) techniques have been developed for real-time decision making, and are gaining traction in data-rich situations. However, these techniques are less proven in sparse-data environments, and at present are more the subject of research than application. Typical implementations of ML and AI require a cross-disciplinary decision engine that, once “trained,” can cognitively respond to changes in input. The key to successful training is to a) have a defined decision-basis (answer-key), and/or b) facilitate sufficient learning, both of which require ample data (observability) and ample time for the machine to develop a logical outcome. Much research has been focused on developing decision algorithms using various logical formulations, dimensionality reductions, neural techniques, and learning reinforcements for tasks that traditionally require human intelligence. What is missing in most current research streams are implementations of ML and AI for decisions that are fundamentally rooted in human intuition and empathy, e.g., situations in which the decision requires a holistic view and the outcome is based on a qualitative judgement based on context and fact. This paper is intended to benefit a wide range of readers considering Artificial Intelligence, from the merely curious to “techies” from other disciplines to experienced practitioners and researchers. Using a qualitative/ characteristics base perspective of data and AI, we examine defense industry procurement, operational, tactical, and strategic decision scenarios, then identify where AI can currently promote better informed decisions and which arenas need would benefit by letting AI technology and sophistication evolve further.","2020-03","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 1095-323X","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMJ6XBIE","conferencePaper","2015","Biswas, M.; Murray, J.C.","Towards an imperfect robot for long-term companionship: case studies using cognitive biases","2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2015.7354228","","The research presented in this paper aims to find out what affect cognitive biases play in a robot's interactive behaviour for the goal of developing human-robot long-term companionship. It is expected that by utilising cognitive biases in a robot's interactive behaviours, making the robot cognitively imperfect, will affect how people relate to the robot thereby changing the process of long-term companionship. Previous research carried out in this area based on human-like cognitive characteristics in robots to create and maintain long-term relationship between robots and humans have yet to focus on developing human-like cognitive biases and as such is new to this application in robotics. To start working with cognitive biases `misattribution' and `empathic gap' have been selected which have been shown to be very common biases in humans and as such play a role on human-human interactions and long-term relationships.","2015-09","2021-05-19 12:41:48","2021-05-19 12:41:48","","5978-5983","","","","","","","","","","","","","","","","","","","","","","","","Human-robot interaction; Service robots; Atmospheric measurements; Anthropomorphism; Human-Robot Interaction; Speech; Cognitive Bias; Correlation; Empathic Gap; Human-Robot Long-term Companionship; Imperfect Robots; Misattribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7QDWCM9","conferencePaper","2018","Churamani, Nikhil; Barros, Pablo; Strahl, Erik; Wermter, Stefan","Learning Empathy-Driven Emotion Expressions using Affective Modulations","2018 International Joint Conference on Neural Networks (IJCNN)","","","10.1109/IJCNN.2018.8489158","","Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.","2018-07","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-8","","","","","","","","","","","","","","","","","","","","ISSN: 2161-4407","","","","Neurons; Adaptation models; Emotion recognition; Robot sensing systems; Mood; Convolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNXDM9N4","conferencePaper","2018","Kühnlenz, Barbara; Kühnlenz, Kolja; Busse, Fabian; Förtsch, Pascal; Wolf, Maximilian","Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/ROMAN.2018.8525515","","Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.","2018-08","2021-05-19 12:41:48","2021-05-19 12:41:48","","275-281","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Task analysis; Robots; Anthropomorphism; Mood; Color; Communication channels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZ5S93HH","conferencePaper","2018","Carranza, Karmelo Antonio R.; Day, Nicole Jillian B.; Lin, Lawrence Matthew S.; Ponce, Albert R.; Reyes, Wilbur Rex O.; Abad, Alexander C.; Baldovino, Renann G.","Akibot: A Telepresence Robot for Medical Teleconsultation","2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)","","","10.1109/HNICEM.2018.8666283","","One problem in the healthcare industry in the Philippines is the maldistribution of doctors. This greatly affects the accessibility of patients to proper healthcare. As a matter of fact, in 2015, 59.2% of deaths in the Philippines are attributed as deaths unattended by a doctor. Although there are current government programs, which aim to solve this problem, the use of telepresence systems can be another viable solution as doctors can still provide quality healthcare services even when located in a remote area. One limitation of medical telepresence robots is the lack of medical features. For this reason, the developed telepresence system includes a telepresence robot called Akibot with integrated medical devices such as otoscope, stethoscope, and ultrasound probe. Akibot is a highly maneuverable remotely controlled telepresence robot designed for general practice medical consultation between doctors and a patient on a remote area. Akibot has an empathic exterior with 4.6 out of 5 rating on its perceived quality of appearance and is equipped with modular medical devices and highly customizable screen, tested on an Android and Windows OS.","2018-11","2021-05-19 12:41:48","2021-05-19 12:41:48","","1-4","","","","","","","","","","","","","","","","","","","","","","","","Medical diagnostic imaging; Medical services; DC motors; Telepresence; Delays; general practice medical consultation; human-centered robot design; Robot control; teleconsultation; telepresence robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLVXYKX4","conferencePaper","2018","Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea","Counseling Robot Implementation and Evaluation","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2018.00297","","A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called ""unazuki"" in Japanese, a kind of nodding to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared.","2018-10","2021-05-19 12:41:48","2021-05-19 12:41:48","","1716-1722","","","","","","","","","","","","","","","","","","","","ISSN: 2577-1655","","","","Robot sensing systems; Robot; Counseling; Dialog Promotion; Dictionaries; Employee welfare; Natural languages; Nodding; Ontologies; Reflection; unazuki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RUAWPIJA","conferencePaper","2017","Anshar, Muh; Williams, Mary-Anne","Evolving artificial pain from fault detection through pattern data analysis","2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)","","","10.1109/RCAR.2017.8311945","","Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.","2017-07","2021-05-19 12:41:48","2021-05-19 12:41:48","","694-699","","","","","","","","","","","","","","","","","","","","","","","","Pain; Robot sensing systems; Data analysis; Machinery; Planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZN5SS4F","conferencePaper","2018","Iranzo, Rosa M. Gil; Padilla-Zea, Natalia; Paderewski-Rodríguez, Patricia; González-González, Carina S.","Empathy and virtual agents for learning applications in symbiotic systems","2018 IEEE Global Engineering Education Conference (EDUCON)","","","10.1109/EDUCON.2018.8363298","","Transparency and ethics are the key issues to improve in the future generations of bots and robots. Communication between users and bots or robots must be clear and transparent to be audited. Empathy will be a valuable asset in a symbiotic domain (user/bot, bot/bot, bot/robot, robot/robot, user/robot). We expose some guidelines to UX designers to cope to new paradigms in HCI communication challenges.","2018-04","2021-05-19 12:41:49","2021-05-19 12:41:49","","694-697","","","","","","","","","","","","","","","","","","","","ISSN: 2165-9567","","","","Ethics; ethics; empathy; Robots; robot; Observers; Biometrics (access control); bot; Guidelines; Privacy; Symbiosis; symbiotic agents; transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4D7K75W","conferencePaper","2021","Abraham, Geo; Nithya, M.","Multi-Functional Personal Assistant Robot Using Raspberry Pi and Coral Accelerator","2021 5th International Conference on Computing Methodologies and Communication (ICCMC)","","","10.1109/ICCMC51019.2021.9418299","","In the present day scenario, a human-like personal assistant robot would ease man’s life with his day-to-day activities and aid him to make up for the lost time spent in inefficient means of calculations and other dependencies. This research work stirs plans to develop a personal assistant robot that has following features. The robot can perceive normal objects that are seen in day-to-day lives and can pass on the information as voice messages which can significantly help old and outwardly impeded individuals. It can read out text messages from an image which again can significantly help old and outwardly impeded individuals. It acts as an empathy robot by perceiving facial feelings and is programmed to play some music according to the detected emotion of the user. It also can find out whether the user is wearing a mask and if not can give an alert voice message. Lastly, it can also has Amazon Alexa speech assistant technology.","2021-04","2021-05-19 12:41:49","2021-05-19 12:41:49","","638-643","","","","","","","","","","","","","","","","","","","","","","","","Object recognition; Emotion Recognition; Robots; Acceleration; CNN; coral USB accelerator; Mask Detection; Personal assistant Robot; Raspberry Pi; Universal Serial Bus; Virtual assistants","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI7ZW4WB","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","","","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.By leveraging simulated handwriting on a synchronised tablet display, a NAo humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models.Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015-03","2021-05-19 12:41:49","2021-05-19 12:41:49","","83-90","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2121","","","","Education; Humanoid robots; Mathematical model; Shape; Principal component analysis; Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UM925LX","conferencePaper","2017","Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto","Design of Counseling Robot for Production by 3D Printer","2017 13th International Conference on Signal-Image Technology Internet-Based Systems (SITIS)","","","10.1109/SITIS.2017.20","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called “unazuki” in Japanese, a kind of “nodding” to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a “unazuki” or “dialog promotion nodding” robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such “unazuki”, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce our newly developed robot that behaves human-like by an appropriate nodding behavior. The main motivation for developing a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffers from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is often very important that the agent behaves as much as possible human-like. Finally, we present the experimental evaluation results that proves such nodding is effective in counseling.","2017-12","2021-05-19 12:41:49","2021-05-19 12:41:49","","56-62","","","","","","","","","","","","","","","","","","","","","","","","Psychology; Cognition; Robots; Emotion recognition; Robot; Counseling; Dialog Promotion; Employee welfare; Nodding; Reflection; unazuki; Problem-solving","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRTPYWQI","conferencePaper","2015","Mennesson, José; Allaert, Benjamin; Bilasco, Ioan Marius; van der Aa, Nico; Denis, Alexandre; Cruz-Lara, Samuel","Faces and thoughts: An empathic dairy","2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)","","","10.1109/FG.2015.7163170","","Many diary apps have been developed for an Android mobile device. Although most concentrate on securing the privacy and adding emoticons, only a few include automatic emotion measurements. This demo shows a new diary app including real-time multi-modal emotion measurements to capture the affective state of the user from the text provided and video images made. The emotion measurements from the Emotion from Face module, that analyzes images from the front camera [1], and the Emotion from Text module, that analyzes the text written by the user [2], are merged within the Emotion Fusion module to estimate the user's affective state more robustly. The app allows the user to have empathic feedback for each session.","2015-05","2021-05-19 12:41:49","2021-05-19 12:41:49","","1-1","","","1","","","","","","","","","","","","","","","","","","","","","Computer architecture; Sentiment analysis; Conferences; Real-time systems; Information technology; Smart phones","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH4E4QR9","conferencePaper","2019","Ghandeharioun, Asma; McDuff, Daniel; Czerwinski, Mary; Rowan, Kael","EMMA: An Emotion-Aware Wellbeing Chatbot","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","","","10.1109/ACII.2019.8925455","","The delivery of mental health interventions via ubiquitous devices has shown much promise. A conversational chatbot is a promising oracle for delivering appropriate just-in-time interventions. However, designing emotionally-aware agents, specially in this context, is under-explored. Furthermore, the feasibility of automating the delivery of just-in-time mHealth interventions via such an agent has not been fully studied. In this paper, we present the design and evaluation of EMMA (EMotion-Aware mHealth Agent) through a two-week long human-subject experiment with N=39 participants. EMMA provides emotionally appropriate micro-activities in an empathetic manner. We show that the system can be extended to detect a user's mood purely from smartphone sensor data. Our results show that our personalized machine learning model was perceived as likable via self-reports of emotion from users. Finally, we provide a set of guidelines for the design of emotion-aware bots for mHealth.","2019-09","2021-05-19 12:41:49","2021-05-19 12:41:49","","1-7","","","","","","","","","","","","","","","","","","","","ISSN: 2156-8111","","","","Stress; Medical treatment; Machine learning; Affective computing; emotional intelligence; affective computing; mental health; Mood; Intelligent agents; Mobile applications; agent; Sociology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FURM7PEJ","conferencePaper","2016","Hall, Lynne; Hume, Colette; Tazzyman, Sarah; Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Aylett, Ruth; Castellano, Ginevra; Papadopoulos, Fotis; Jones, Aidan; Corrigan, Lee J.; Paiva, Ana; Oliveira, Patrícia Alves; Ribeiro, Tiago; Barendregt, Wolmet; Serholt, Sofia; Kappas, Arvid","Map reading with an empathic robot tutor","2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","","","10.1109/HRI.2016.7451859","","In this video submission, we describe a scenario developed in the EMOTE project. The overall goal of the EMOTE project is to develop an empathic robot tutor for 11-13 year old school students in an educational setting. The pedagogical domain here is to assist students in learning and testing their map-reading skills typically learned as part of the geography curriculum in schools. We show this scenario with a NAO robot interacting with the students whilst performing map-reading tasks on a touch-screen device in this video.","2016-03","2021-05-19 12:41:49","2021-05-19 12:41:49","","567-567","","","","","","","","","","","","","","","","","","","","ISSN: 2167-2148","","","","Context; Psychology; empathy; Computers; Robots; robot-child interaction; robotic tutor; Art; Jacobian matrices; Systems engineering and theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6TMBYLT","conferencePaper","2019","Chiu, K. C.","Use Text Mining to Abstract Affective Words in the Dream Log to Assist Dream Consultation","2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)","","","10.1109/IEEM44572.2019.8978876","","This study analyzes affective expression in dream log by text mining, guide participants focusing on the affective words in their dream log to release their emotions. This study provided a new method for exploring the correlation between dream and stress in psychology research area, and improved the application of knowledge management by text mining for dream log. The results show that teacher or counselor can improve their consultation by feeling empathy with the affective words in the dream log those emotions be ignored in previously consultation but picked from dream log by artificial intelligence.","2019-12","2021-05-19 12:41:49","2021-05-19 12:41:49","","1516-1520","","","","","","","","","","","","","","","","","","","","ISSN: 2157-362X","","","","Artificial Intelligence; Dream Consultation; Knowledge Management; Text Mining; Semantic Analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63L3EL3K","conferencePaper","2020","Wang, Zicheng","Future Challenges in the Next Generation of Voice User Interface","2020 International Conference on Computing and Data Science (CDS)","","","10.1109/CDS49703.2020.00045","","With the development of artificial intelligence technology, artificial interactions come up for providing powerful assistance to our lives. Among them, voice user interface (VUI) plays important roles in assisting the disabled and complex interaction scenarios. This paper mainly introduces the key elements and core technics in VUI. Also, future challenges will be discussed from the perspective of empathy, ethics, and accessibility. This paper serves as a summary for future study in VUI.","2020-08","2021-05-19 12:41:49","2021-05-19 12:41:49","","191-193","","","","","","","","","","","","","","","","","","","","","","","","artificial intelligence; accessibility; Data science; user interface; voice user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7QJ24SG","conferencePaper","2019","Barbieri, Francesco; Guizzo, Eric; Lucchesi, Federico; Maffei, Giovanni; del Prado Martín, Fermín Moscoso; Weyde, Tillman","Towards a Multimodal Time-Based Empathy Prediction System","2019 14th IEEE International Conference on Automatic Face Gesture Recognition (FG 2019)","","","10.1109/FG.2019.8756532","","We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community.","2019-05","2021-05-19 12:41:49","2021-05-19 12:41:49","","1-5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMX6TPZI","conferencePaper","2019","Costantini, Stefania; De Gasperis, Giovanni; Migliarini, Patrizio","Multi-agent System Engineering for Emphatic Human-Robot Interaction","2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","","","10.1109/AIKE.2019.00015","","Human-robot interactions have to take into account the natural multi-modal bidirectional communication model that is common among humans. The model does not rely just on speech and verbal exchange, but it shall include emotional exchange through different channels: face muscles, body posture, voice modulation, skin responses, odors, etc. While some aspects are feasible yet far from being adopted by daily robotic interaction with humans, the other ones can exploit current level of technology so as to be included in common, although complex, human-robot communication use cases. In order to cope in synergic but efficient and modular way with the various emphatic communication aspects, we propose to employ intelligent agents and multi-agent system. Such multi-agent system comprises a controller sub-system aboard the robot, which is coordinated by logical agents that can incorporate perceptive modules which generates state predicates, reason about them, plan, and deliver emotionally intelligent action while interacting with human beings, emulating as much as possible human empathy.","2019-06","2021-05-19 12:41:49","2021-05-19 12:41:49","","36-42","","","","","","","","","","","","","","","","","","","","","","","","perception; emotions; communication; empathy; affect; Face; Face recognition; Speech recognition; Robot kinematics; human robot interaction; logic; Multi-agent systems; Skin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SIATJEC","conferencePaper","2018","Viet Tuyen, Nguyen Tan; Jeong, Sungmoon; Chong, Nak Young","Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","","10.1109/IROS.2018.8593974","","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.","2018-10","2021-05-19 12:41:49","2021-05-19 12:41:49","","2008-2013","","","","","","","","","","","","","","","","","","","","ISSN: 2153-0866","","","","Neurons; Training; Robot kinematics; Collision avoidance; Self-organizing feature maps; Trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69QVI7HE","conferencePaper","2018","Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young","Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression","2018 15th International Conference on Ubiquitous Robots (UR)","","","10.1109/URAI.2018.8441767","","Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.","2018-06","2021-05-19 12:41:49","2021-05-19 12:41:49","","377-382","","","","","","","","","","","","","","","","","","","","","","","","Neurons; Psychology; Training; Human-robot interaction; Robots; Cultural differences; Self-organizing feature maps","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36HL7VI9","conferencePaper","2019","Das, Amit Kumar; Ashrafi, Aziza; Ahmmad, Muktadir","Joint Cognition of Both Human and Machine for Predicting Criminal Punishment in Judicial System","2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)","","","10.1109/CCOMS.2019.8821655","","Thousands of research have been taking place to develop advanced Artificial Intelligence System which can't only perform faster but also predict better than human. But a human has some qualities which can never be gained by a machine like creativity, empathy, sensing, and critical thinking. By aggregating the best sides of both, a novel paradigm for the judicial system can be anticipated. For this purpose, we prepare a dataset both from an online survey (n=103) and interviews conducted in Bangladesh on cases related to `Women and Children Repression Prevention Act, 2000'. We apply several machine learning algorithms to make a machine that can predict punishment like a judge and calculate both the test accuracy and the predictive power of the models to observe which algorithm performs better and stable than the others. Even human can guide machine for judging a delinquent.","2019-02","2021-05-19 12:41:49","2021-05-19 12:41:49","","36-40","","","","","","","","","","","","","","","","","","","","","","","","Task analysis; Decision making; Law; Case; Human Guided; Judge; Judicial System; Machine learning Framework; Predict Punishment; Forecasting; Machine intelligence; Machine learning algorithms; Predictive models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GNPW45HQ","conferencePaper","2016","Shamsuddin, Syamimi; Ahmad, Intan Fatihah; Zulkifli, Winal Zikril; Hwee, Lim Thiam; Yussof, Hanafiah","Preliminary study on the use of therapeutic seal robot for patients with depression","2016 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS)","","","10.1109/IRIS.2016.8066065","","Depression is a serious mental health challenge. If left untreated, it could lead to other critical symptoms, even suicide. In Malaysia, the prevalence is estimated between 8-10% of the population but it is often under-recognized and undertreated. This study is the first one in Malaysia to propose an animal robot to provide mental support to patients with depression. The main objective of this paper is to introduce PARO the seal robot as a remedy to reduce the need for psychotropic drugs during depression therapy at a rehabilitation center. Patients with depression requires repetitive conditioning and motivation. A robotic animal is a proposed solution to provide constant mental support and induce warm and empathetic feelings from the patients. Comparing assessment scores of pre and post robotic therapy shall shed light on the suitability of PARO to help patients with depression.","2016-12","2021-05-19 12:41:49","2021-05-19 12:41:49","","52-56","","","","","","","","","","","","","","","","","","","","","","","","Medical treatment; Animals; depression; rehabilitation; human-robot interaction; Senior citizens; Robot sensing systems; Dementia; PARO; robotic therapy; Seals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5C74TCGY","conferencePaper","2017","Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young","Learning human behavior for emotional body expression in socially assistive robotics","2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","","","10.1109/URAI.2017.7992882","","Generating emotional body expressions for socially assistive robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, we propose a new model of emotional body expression for the robot inspired by social and emotional development of infant from their parents. An infant is often influenced by social referencing, meaning that they perceive their parents' interpretation about emotional situations to form their own interpretation. Similar to the infant development case, robots can be designed to generate representative emotional behaviors using self-organized neural networks trained with various emotional behavior samples from human partners. We demonstrate the validity of our emotional behavior expression through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots.","2017-06","2021-05-19 12:41:49","2021-05-19 12:41:49","","45-50","","","","","","","","","","","","","","","","","","","","","","","","Neurons; Psychology; Training; human-robot interaction; Human-robot interaction; Robots; clustering; emotional body expression; imitation learning; Kernel; Skeleton","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PP59DJLJ","conferencePaper","2017","Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto","Context respectful counseling agent integrated with robot nodding for dialog promotion","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","","","10.1109/SMC.2017.8122833","","Nowadays, a lot of IT personnel have psychological distress. Meanwhile, counselors to help them are lack in number. To solve the problem, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent). CRECA listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent can be enhanced using a body language called ""unazuki"" in Japanese, a kind of ""nodding"" to greatly promote dialogue, often accompanying ""un-un"" (meaning ""exactly"") of Japanese onomatopoeia. This body language is expected to significantly help represent empathy or entire approval. In this paper, the agent is integrated with such a ""unazuki"" or ""dialog promotion nodding"" robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize such ""unazuki"", the robot nods twice at each end of dialog sentence input by clients. The experimental evaluation proves such nodding is effective in counseling.","2017-10","2021-05-19 12:41:49","2021-05-19 12:41:49","","1540-1545","","","","","","","","","","","","","","","","","","","","","","","","Cognition; Robots; Robot; Counseling; Dialog Promotion; Dictionaries; Employee welfare; Nodding; Ontologies; Reflection; unazuki; Problem-solving","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUWTEXQ9","journalArticle","2016","Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge","Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns","IEEE Transactions on Pattern Analysis and Machine Intelligence","","1939-3539","10.1109/TPAMI.2015.2496209","","Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading).The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.","2016-08","2021-05-19 12:41:49","2021-05-19 12:41:49","","1679-1691","","8","38","","","","","","","","","","","","","","","","","","","","","Human-robot interaction; Three-dimensional displays; Shape; Feature extraction; Analytical models; Bayes methods; Bayesian approach; frequency domain; Histograms; human movement analysis; social role; Social signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6CKE67X2","conferencePaper","2016","Hervás, Ramón; Johnson, Esperanza; Gutierrez López de la Franca, Carlos; Bravo, José; Mondéjar, Tania","A Learning System to Support Social and Empathy Disorders Diagnosis through Affective Avatars","2016 15th International Conference on Ubiquitous Computing and Communications and 2016 International Symposium on Cyberspace and Security (IUCC-CSS)","","","10.1109/IUCC-CSS.2016.021","","Nowadays diagnosis and treatment of cognitive and physical health issues can be empowered through the use of information technologies. However, there is a significant gap between the potential of those technologies and the real application. One example is the use of serious games with health proposals, a trending research area still not implanted in health systems. This paper proposes the use of serious games, particularly an interactive and affective avatar-based application to support the diagnosis and treatment of empathy and socialization issues, in an autonomous way through the implementation of a learning algorithm based on the ground truth obtained from the evaluation with real users, including normotypical users, users with Down syndrome and users with intellectual disability.","2016-12","2021-05-19 12:41:49","2021-05-19 12:41:49","","93-100","","","","","","","","","","","","","","","","","","","","","","","","Object recognition; Psychology; Affective Computing; Machine Learning; Avatars; Games; Emotion recognition; Cognitive Health; Human-Avatar Interaction; Social Communication Disorders; Proposals; Taxonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2VS755N","conferencePaper","2015","Headleand, Christopher J.; Jackson, James; Priday, Lee; Teahan, William; Cenydd, Llyr Ap","Does the Perceived Identity of Non-player Characters Change How We Interact with Them?","2015 International Conference on Cyberworlds (CW)","","","10.1109/CW.2015.35","","Although there have been studies demonstrating that users will respond favorably to synthetic companions and team-mates in computer games, there has been little research into how a player's behavior may change when a known non-player character (NPC) assumes a human identity or persona. This is a common scenario in modern computer games, where players interact with NPCs assuming the guise of human characters. To explore this question, an online game was developed in which a human player had a primary objective of surviving against increasingly difficult waves of enemies. As a secondary objective, the player was tasked with protecting an unarmed NPC companion which assumed either a human, or non-human identity, but with identical underlying Artificial Intelligence. The intention was to explore whether the human player would be more or less protective of a synthetic companion simply due to the identity assumed. The results of the study demonstrate that player's behavior does change based on identity, and clearly indicates that the player was more protective of the companion assuming a human identity. Furthermore, the results show that this phenomenon extends beyond simple human and non-human identities, and that the specific persona, or gender of the NPC may influence the player's empathy towards it.","2015-10","2021-05-19 12:41:49","2021-05-19 12:41:49","","145-152","","","","","","","","","","","","","","","","","","","","","","","","Visualization; Artificial intelligence; Computers; Robots; Ash; Avatars; CASA; Games; Games AI; Human Agent Interaction; Identity; NPC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BK522QD","conferencePaper","2017","y Restrepo, Emmanuelle Gutiérrez; Boticario, Jesús G.","Responsive and responsible higher education through advanced technology Accessibility, empathy and diversity the keys of our future","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","","","10.1109/ICE.2017.8280067","","This paper explores the unexpected but fundamental relationship among the strategy defined for the Educational and Professional Development and Support Centres, results from the ACACIA European project, and the future of artificial intelligence. The purpose of this analysis is reducing their respective bias and improving their acuity. The lack of empathy detected by several studies among current young population along with non-inclusive design tendencies of current and upcoming intelligent systems give rise to a problem that we must tackle as soon as possible if we want to achieve a more inclusive society.","2017-06","2021-05-19 12:41:49","2021-05-19 12:41:49","","1552-1558","","","","","","","","","","","","","","","","","","","","","","","","Education; Artificial Intelligence; Empathy; Accessibility; Diversity; Afective computing; Assistive technology; Cultural differences; Economics; Gesture recognition; Intelligent systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4D8L7N55","conferencePaper","2019","Lopez-Martinez, Daniel; El-Haouij, Neska; Picard, Rosalind","Detection of Real-World Driving-Induced Affective State Using Physiological Signals and Multi-View Multi-Task Machine Learning","2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)","","","10.1109/ACIIW.2019.8925190","","Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance.","2019-09","2021-05-19 12:41:49","2021-05-19 12:41:49","","356-361","","","","","","","","","","","","","","","","","","","","","","","","Stress; Machine learning; Feature extraction; Heart rate; Physiology; Affective State; Databases; Multi-task Multi-view Machine Learning; Physiological data; Real-world driving; Vehicles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C4MFDJYD","conferencePaper","2020","Carper, Ben; McGowan, Dillon; Miller, Samantha; Nelson, Joe; Palombi, Leah; Romeo, Lina; Spigelman, Kayla; Doryab, Afsaneh","Modeling Biological Rhythms to Predict Mental and Physical Readiness","2020 Systems and Information Engineering Design Symposium (SIEDS)","","","10.1109/SIEDS49339.2020.9106683","","The human body is composed of various biological clocks that impact physical and mental health functioning. Modeling biological rhythms provides the means to understand the effect of internal and external factors on human mental and physical performance. So far, biological rhythms have mostly been studied in controlled laboratory settings thus limiting the long term study and modeling of these rhythms. This paper presents the results of our exploratory study of modeling human rhythms with longitudinal physiological data collected from consumer devices in the wild. We used data from four people continuously wearing Empatica (E4) wristbands and Oura smart rings for approximately four months to build models of human rhythms. We then used those model parameters in a machine learning approach to predict mental and physical readiness. Our results showed that most models built with a combination of sensors and rhythmic features obtained a prediction accuracy above the baseline measure of 66% (Max accuracy = 82.7%). These results provide insights into the feasibility of using consumer devices to model biological rhythms and use them to assess human and performance and health.","2020-04","2021-05-19 12:41:49","2021-05-19 12:41:49","","1-6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9M4KU7HU","conferencePaper","2019","Zsom, A.; LaFrance, W.C.; Blum, A.S.; Li, P.; Wahed, L.A.; Shaikh, M.A.; Sharma, G.; Ranieri, R.; Zhang, L.; Tsekhan, S.; Hamid, T.; Levin, J.; Truccolo, W.","Ictal autonomic activity recorded via wearable-sensors plus machine learning can discriminate epileptic and psychogenic nonepileptic seizures","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","","","10.1109/EMBC.2019.8857552","","Differentiating epileptic seizures (ES) and psychogenic nonepileptic seizures (PNES) is commonly based on electroencephalogram and concurrent video recordings (vEEG). Here, we demonstrate that these two types of seizures can be discriminated based on signals related to autonomic nervous system activity recorded via wearable sensors. We used Empatica E4 Wristband sensors worn on both arms in vEEG confirmed seizures, and machine learning methods to train classifiers, specifically, extreme gradient boosting (XGBoost). Classification performance achieved a predictive accuracy of 78 ± 1.5% on previously unseen data for whether a seizure was epileptic or psychogenic, which is 6 standard deviations above the baseline of 68% accuracy. Our dataset contained altogether 35 seizures from 18 patients out of which 8 patients had 13 convulsive seizures. Prediction of seizure type was based on simple features derived from the segments of autonomic activity measurements (electrodermal activity, body temperature, blood volume pulse, and heart rate) and forearm acceleration. Features related to heart rate and electrodermal activity were ranked as the top predictors in XGBoost classifiers. We found that patients with PNES had a higher ictal heart rate and electrodermal activity than patients with ES. In contrast to existing published studies of mainly convulsive seizures, our classifier focuses on autonomic signals to differentiate convulsive or nonconvulsive semiology ES from PNES. Our results show that autonomic activity recorded via wearable sensors provides promising signals for detection and discrimination of psychogenic and epileptic seizures, but more work is necessary to improve the predictive power of the model.","2019-07","2021-05-19 12:41:49","2021-05-19 12:41:49","","3502-3506","","","","","","","","","","","","","","","","","","","","ISSN: 1558-4615","","","","Machine learning; Standards; Histograms; Heart rate; Sensors; Temperature measurement; Wrist","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54K7NNSR","conferencePaper","2019","Montesinos, Victoriano; Dell’Agnola, Fabio; Arza, Adriana; Aminifar, Amir; Atienza, David","Multi-Modal Acute Stress Recognition Using Off-the-Shelf Wearable Devices","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","","","10.1109/EMBC.2019.8857130","","Monitoring stress and, in general, emotions has attracted a lot of attention over the past few decades. Stress monitoring has many applications, including high-risk missions and surgical procedures as well as mental/emotional health monitoring. In this paper, we evaluate the possibility of stress and emotion monitoring using off-the-shelf wearable sensors. To this aim, we propose a multi-modal machine-learning technique for acute stress episodes detection, by fusing the information careered in several biosignals and wearable sensors. Furthermore, we investigate the contribution of each wearable sensor in stress detection and demonstrate the possibility of acute stress recognition using wearable devices. In particular, we acquire the physiological signals using the Shimmer3 ECG Unit and the Empatica E4 wristband. Our experimental evaluation shows that it is possible to detect acute stress episodes with an accuracy of 84.13%, for an unseen test set, using multi-modal machinelearning and sensor-fusion techniques.","2019-07","2021-05-19 12:41:49","2021-05-19 12:41:49","","2196-2201","","","","","","","","","","","","","","","","","","","","ISSN: 1558-4615","","","","Stress; Monitoring; Feature extraction; Biomarkers; Biomedical monitoring; Electrocardiography; Wearable sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FU4PMBJL","conferencePaper","2021","Prabha, Anju; Yadav, Jyoti; Rani, Asha; Singh, Vijander","Non-invasive Diabetes Mellitus Detection System using Machine Learning Techniques","2021 11th International Conference on Cloud Computing, Data Science Engineering (Confluence)","","","10.1109/Confluence51648.2021.9377138","","This work presents an automated diabetes mellitus detection system (DMDS), based on wrist photoplethysmography (PPG) signal and physiological parameters. The PPG signal with an average duration of 2.5 minutes is obtained using the handle Empatica E4 Wristband from 217 patients. The mel frequency cepstral coefficients (MFCC) features are extracted from 5 second segments of the PPG signal. The extracted features and physiological parameters constitute the input for machine learning (ML) systems. K-nearest neighbors (KNN) and Support Vector machine (SVM) algorithms are used for classification. 83.87% and 84.49% classification accuracy is achieved with KNN and radial basis function (RBF) Kernel SVM based DMDS respectively. Further principal component analysis is used on the input feature set to the SVM classifier which provides 7.79% improvement in the performance. The performance of the developed systems is also analysed using entropy triangle. Results reveal the effectiveness of proposed DMDS for non-invasive DM detection. The designed wrist band identifies the diabetic and pre-diabetic cases in real time on the basis of short duration PPG signal and physiological parameters.","2021-01","2021-05-19 12:41:49","2021-05-19 12:41:49","","948-953","","","","","","","","","","","","","","","","","","","","","","","","Machine learning; Feature extraction; Physiology; Mel frequency cepstral coefficient; SVM; Diabetes; Support vector machines; Diabetes Mellitus; Wrist; Entropy Triangle; KNN; MFCC; PCA; Physical Parameters; PPG Signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXPD5EJ4","conferencePaper","2020","Girardi, Daniela; Ferrari, Alessio; Novielli, Nicole; Spoletini, Paola; Fucci, Davide; Huichapa, Thaide","The Way it Makes you Feel Predicting Users’ Engagement during Interviews with Biofeedback and Supervised Learning","2020 IEEE 28th International Requirements Engineering Conference (RE)","","","10.1109/RE48521.2020.00016","","Capturing users' engagement is crucial for gathering feedback about the features of a software product. In a market-driven context, current approaches to collect and analyze users' feedback are based on techniques leveraging information extracted from product reviews and social media. These approaches are hardly applicable in bespoke software development, or in contexts in which one needs to gather information from specific users. In such cases, companies need to resort to face-to-face interviews to get feedback on their products. In this paper, we propose to utilize biofeedback to complement interviews with information about the engagement of the user on the discussed features and topics. We evaluate our approach by interviewing users while gathering their biometric data using an Empatica E4 wristband. Our results show that we can predict users' engagement by training supervised machine learning algorithms on the biometric data. The results of our work can be used to facilitate the prioritization of product features and to guide the interview based on users' engagement.","2020-08","2021-05-19 12:41:50","2021-05-19 12:41:50","","32-43","","","","","","","","","","","","","","","","","","","","ISSN: 2332-6441","","","","Software; Sentiment analysis; Task analysis; Feature extraction; Interviews; Heart rate; Biological control systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQUYFE4N","conferencePaper","2015","Tahir, Yasir; Chakraborty, Debsubhra; Maszczyk, Tomasz; Dauwels, Shoko; Dauwels, Justin; Thalmann, Nadia; Thalmann, Daniel","Real-time sociometrics from audio-visual features for two-person dialogs","2015 IEEE International Conference on Digital Signal Processing (DSP)","","","10.1109/ICDSP.2015.7251991","","This paper proposes a real time sociometric system to analyze social behavior from audio-visual recordings of two-person face-to-face conversations in English. The novelty of the proposed system lies in this automatic inference of ten social indicators in real time. The system comprises of a Microsoft kinect device that captures RGB and depth data to compute visual cues and microphones to capture speech cues from an on-going conversation. With these non-verbal cues as features, machine learning algorithms are implemented in the system to extract multiple indicators of social behavior including empathy, confusion and politeness. The system is trained and tested on two carefully annotated corpora that consist of two person dialogs. Based on leave-one-out cross-validation test, the accuracy range of developed algorithms to infer social behaviors is 50% - 86% for audio corpus, and 62% - 92% for audio-visual corpus.","2015-07","2021-05-19 12:41:50","2021-05-19 12:41:50","","823-827","","","","","","","","","","","","","","","","","","","","ISSN: 2165-3577","","","","machine learning; Visualization; Conferences; Speech; Feature extraction; Accuracy; audiovisual analysis; dialog; real-time; Real-time systems; Signal processing; sociometrics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZW9YJBP","conferencePaper","2020","Lusquino Filho, Leopoldo A. D.; Oliveira, Luiz F. R.; Carneiro, Hugo C. C.; Guarisa, Gabriel P.; Filho, Aluízio Lima; França, Felipe M. G.; Lima, Priscila M. V.","A weightless regression system for predicting multi-modal empathy","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","","","10.1109/FG47880.2020.00086","","This work takes into account the benefits of machine learning in order to estimate the valence of emotions on the OMG Empathy dataset, considering the information obtained from face expressions and dialogue of interlocutors. RegressionWiSARD and ClusRegressionWiSARD n-tuple regressors and its ensembles were employed to this end. The best performance achieved among all the combinations of weightless neural models considered (evaluated using the CCC metric) was 0.25 in validation set of the Personalized Track.","2020-11","2021-05-19 12:41:50","2021-05-19 12:41:50","","657-661","","","","","","","","","","","","","","","","","","","","","","","","Computational modeling; Training; Predictive models; Videos; Bagging; empathy prediction; Mel frequency cepstral coefficient; Random access memory; regression wisard; weightless artificial neural network; wisard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JW2DBLLP","conferencePaper","2019","Franzius, Mathias","Towards Beauty: Robot Following Aesthetics Gradients","2019 19th International Conference on Advanced Robotics (ICAR)","","","10.1109/ICAR46387.2019.8981647","","Increasing numbers of devices are equipped with cameras generating large amounts of images. State of the art technologies allow to automatically identify relevant and aesthetically pleasing images after they were stored. Here, we demonstrate a robot that estimates the gradient of image aesthetics in its environment and actively navigates towards the maximum. Aesthetics navigation is integrated into a modified robotic lawnmower, switching online between tasks based on estimated aesthetics scores. This behavior generates higher aesthetics scores than offline selection of images captured during standard behavior. The proposed system extends robotic behavior from the purely functional towards a cooperative and empathic level.","2019-12","2021-05-19 12:41:50","2021-05-19 12:41:50","","55-60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UIGSGQ5R","conferencePaper","2020","Perusquía-Hernández, Monica; Balda, Marisabel Cuberos; Gómez Jáuregui, David Antonio; Paez-Granados, Diego; Dollack, Felix; Salazar, Jose Victorio","Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User’s Physiological Affective States","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","","","10.1109/RO-MAN47096.2020.9223598","","Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self- tracking results might cause the opposite effect. Subtle self- tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.","2020-08","2021-05-19 12:41:50","2021-05-19 12:41:50","","1328-1333","","","","","","","","","","","","","","","","","","","","ISSN: 1944-9437","","","","Visualization; Robots; embodiment; Robot sensing systems; empathy and intersubjectivity; haptic feedback; Haptic interfaces; Heart rate; human-machine interaction; Physiology; Vibrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRRT9ANY","journalArticle","2019","Haynes, Alice; Simons, Melanie F.; Helps, Tim; Nakamura, Yuichi; Rossiter, Jonathan","A Wearable Skin-Stretching Tactile Interface for Human–Robot and Human–Human Communication","IEEE Robotics and Automation Letters","","2377-3766","10.1109/LRA.2019.2896933","","Currently, the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user. While this can be very effective, vibration as a physical stimulation is limited in modality and is uncommon in the natural world. In many cases, for human-robot and human- human interaction, a more natural, affective tactile interaction is needed to provide comfortable and varied stimuli. In this letter, we present the super-cutaneous wearable electrical empathic stimulator (SCWEES), a tactile device that gently stretches and squeezes the surface of the skin. Our hypothesis is that this device can create a pleasant, unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts. We describe the design of the SCWEES, a lightweight 3D-printed semi-flexible structure that attaches to the skin at two points and actuates via two shape-memory alloy coil actuators. We evaluate the SCWEES through a range of human interaction experiments: stimulation strength and pleasantness, contraction and extension, and the conveyance of non-disruptive notifications. Quantitative and qualitative results show that the SCWEES generates a pleasant sensation, can convey useful information in human-machine interactions, and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task.","2019-04","2021-05-19 12:41:50","2021-05-19 12:41:50","","1641-1646","","2","4","","","","","","","","","","","","","","","","","","","","","Robot sensing systems; Actuators; Skin; Haptic interfaces; Vibrations; affective tactile stimulation; Force; haptics and haptic interfaces; social human-robot interaction; soft robot applications; Wearable robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4IZ3XS3F","conferencePaper","2015","Aylett, Ruth; Kappas, Arvid; Castellano, Ginevra; Bull, Susan; Barendregt, Wolmet; Paiva, Ana; Hall, Lynne","I know how that feels — An empathic robot tutor","eChallenges e-2015 Conference","","","10.1109/eCHALLENGES.2015.7441088","","This paper discusses the design and implementation of an Empathic Robot Tutor, applied to topics in the school Geography curriculum, and using a multi-touch table. It explains the motivation and objectives, introduces the two application domains, Mapskills and Enercities2, and describes the technology that has been developed. It discusses a study using Mapskills on the impact of embodiment on their learning, and results arising from this.","2015-11","2021-05-19 12:41:50","2021-05-19 12:41:50","","1-9","","","","","","","","","","","","","","","","","","","","ISSN: 2166-1677","","","","Computational modeling; Electronic mail; Games; Robot sensing systems; Bonding; Facsimile","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QSHSIZF","conferencePaper","2017","Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile","Stacked deep convolutional auto-encoders for emotion recognition from facial expressions","2017 International Joint Conference on Neural Networks (IJCNN)","","","10.1109/IJCNN.2017.7966040","","Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system.","2017-05","2021-05-19 12:41:50","2021-05-19 12:41:50","","1586-1593","","","","","","","","","","","","","","","","","","","","ISSN: 2161-4407","","","","Training; Robots; Emotion recognition; Feature extraction; Convolution; Kernel; Convergence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CSFIRD3","journalArticle","2020","Rafique, Memoona; Hassan, Muhammad Awais; Jaleel, Abdul; Khalid, Hina; Bano, Gulshan","A Computation Model for Learning Programming and Emotional Intelligence","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3015533","","Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.","2020","2021-05-19 12:41:50","2021-05-19 12:41:50","","149616-149629","","","8","","","","","","","","","","","","","","","","","","","","","Computational modeling; Education; Robots; Emotional intelligence; basic programming; Programming profession; robots based learning; screen-free interface; Sequential analysis; Tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZSEAFU8","conferencePaper","2017","Stock, Ruth Maria","User responses to social robots - experimental insights and psychophysiological measures","2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)","","","10.1109/PERCOMW.2017.7917582","","Summary form only given. Companies in China, Japan and USA started introducing social robots at the customer interface in various industries, such as hospitality services, retailing, and health care services. In contrast to production robots, social robots are humanoid and communicate with speech and gestures with the primary purpose to interact with humans. While the prevalence of social robots is increasing, knowledge about the user acceptance of these robots is scarce. Based on an experimental series, potential stressors as well as emotional and behavioral user responses to the interaction with a social robot are examined. The experimental setting was a hotel reception, in which participants had to interact with the social robot (i.e., the humanoid robot Pepper) in the role of a hotel guest. Participants' psychological responses to the social robot were assessed via self-assessments of the participants. Beyond these standard measures, external raters evaluated the participants' responses by evaluating their facial expressions and gestures on the basis of the video recordings of the experimental procedure. Furthermore, a non-intrusive wearable device, Empatica E4, was used to measure physiological data, in particular heart rate (HR), heart rate variability (HRV) and electrodermal activity (EDA). Results show that participants were able to clearly recognize robotic emotions and behaviors. Furthermore, we could reveal similar patterns within a human-robot-interaction as compared to human-human-interactions.","2017-03","2021-05-19 12:41:50","2021-05-19 12:41:50","","326-326","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
Key;Item Type;Publication Year;Author;Title;Publication Title;ISBN;ISSN;DOI;Url;Abstract Note;Date;Date Added;Date Modified;Access Date;Pages;Num Pages;Issue;Volume;Number Of Volumes;Journal Abbreviation;Short Title;Series;Series Number;Series Text;Series Title;Publisher;Place;Language;Rights;Type;Archive;Archive Location;Library Catalog;Call Number;Extra;Notes;File Attachments;Link Attachments;Manual Tags;Automatic Tags;Editor;Series Editor;Translator;Contributor;Attorney Agent;Book Author;Cast Member;Commenter;Composer;Cosponsor;Counsel;Interviewer;Producer;Recipient;Reviewed Author;Scriptwriter;Words By;Guest;Number;Edition;Running Time;Scale;Medium;Artwork Size;Filing Date;Application Number;Assignee;Issuing Authority;Country;Meeting Name;Conference Name;Court;References;Reporter;Legal Status;Priority Numbers;Programming Language;Version;System;Code;Code Number;Section;Session;Committee;History;Legislative Body;Title Duplicate;TA Keyword
3RR4P2S4;journalArticle;2021;"Cuzzocrea, Alfredo; Pilato, Giovanni";A composite framework for supporting user emotion detection based on intelligent taxonomy handling;LOGIC JOURNAL OF THE IGPL;NA;1367-0751;10.1093/jigpal/jzaa047;NA;One of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her. The first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper. The system can analyze the Twitter ID of the new acquaintance, trying to detect the IAB (Interactive Advertising Bureau) Tier 1 categories that possibly can let arise in him/her a joyful feeling. Furthermore, it can retrieve news about that category and report them to the user, hopefully increasing his/her curiosity towards the system, improving the naturalness of the interaction. Moreover, the system is capable of querying Wikipedia in order to clarify any doubts that may arise in the user. A sample of a possible interaction is reported at the end of the paper.;2021-04;2021-05-19T13:29:52Z;2021-05-19T13:29:52Z;NA;207-219;NA;2;29;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article;NA;NA;NA;NA;"human-robot interaction; affective AI; Taxonomies";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;acompositeframeworkforsupportinguseremotiondetectionbasedonintelligenttaxonomyhandling;a composite framework for supporting user emotion detection based on intelligent taxonomy handling one of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her the first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper the system can analyze the twitter id of the new acquaintance trying to detect the iab interactive advertising bureau tier 1 categories that possibly can let arise in himher a joyful feeling furthermore it can retrieve news about that category and report them to the user hopefully increasing hisher curiosity towards the system improving the naturalness of the interaction moreover the system is capable of querying wikipedia in order to clarify any doubts that may arise in the user a sample of a possible interaction is reported at the end of the paper
62YLIVK7;journalArticle;2021;"Pozharliev, Rumen; De Angelis, Matteo; Rossi, Dario; Romani, Simona; Verbeke, Willem; Cherubino, Patrizia";Attachment styles moderate customer responses to frontline service robots: Evidence from affective, attitudinal, and behavioral measures;PSYCHOLOGY & MARKETING;NA;0742-6046;10.1002/mar.21475;NA;Despite the growing application of interactive technologies like service robots in customer service, there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees. Moreover, it is unclear whether all customers respond to the interaction with frontline service robots in the same way. Our research looks at how individual differences in social behaviors, specifically in customers' attachment styles, influence three types of customer responses: affective responses (experienced pleasantness), attitudinal responses (perceived empathy, satisfaction), and behavioral responses (word-of-mouth). Three experimental studies reveal that customers with low (vs. high) scores on anxious attachment style (AAS) measures respond more negatively to frontline service robot (compared to a frontline human agent). We investigate alternative explanations for these findings, such as robots' level of anthropomorphism and we show that human-likeness features such as voice type and level of human-like physical appearance, cannot explain our findings. Our results indicate that for low-AAS customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots, leading to possible implications on customer segmentation, targeting, and marketing communication.;2021-05;2021-05-19T13:29:53Z;2021-05-19T13:29:53Z;NA;881-895;NA;5;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"empathy; service robots; anthropomorphism; attachment styles; social response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;attachmentstylesmoderatecustomerresponsestofrontlineservicerobotsevidencefromaffectiveattitudinalandbehavioralmeasures;attachment styles moderate customer responses to frontline service robots evidence from affective attitudinal and behavioral measures despite the growing application of interactive technologies like service robots in customer service there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees moreover it is unclear whether all customers respond to the interaction with frontline service robots in the same way our research looks at how individual differences in social behaviors specifically in customers attachment styles influence three types of customer responses affective responses experienced pleasantness attitudinal responses perceived empathy satisfaction and behavioral responses wordofmouth three experimental studies reveal that customers with low vs high scores on anxious attachment style aas measures respond more negatively to frontline service robot compared to a frontline human agent we investigate alternative explanations for these findings such as robots level of anthropomorphism and we show that humanlikeness features such as voice type and level of humanlike physical appearance cannot explain our findings our results indicate that for lowaas customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots leading to possible implications on customer segmentation targeting and marketing communication
NYC4J548;journalArticle;2021;"Riddoch, Katie A.; Cross, Emily S.";“Hit the Robot on the Head With This Mallet” - Making a Case for Including More Open Questions in HRI Research;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2021.603510;NA;Researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents, as opposed to objects. One such approach involves asking participants to inflict `harm' on a robot. Researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying, and propose that relatively long periods of hesitation might reflect empathy for the robot, and perhaps even attribution of human-like qualities, such as agency and sentience. In a recent experiment, we adapted the so-called `hesitance to hit' paradigm, in which participants were instructed to hit a humanoid robot on the head with a mallet. After standing up to do so (signaling intent to hit the robot), participants were stopped, and then took part in a semi-structured interview to probe their thoughts and feelings during the period of hesitation. Thematic analysis of the responses indicate that hesitation not only reflects perceived socialness, but also other factors including (but not limited to) concerns about cost, mallet disbelief, processing of the task instruction, and the influence of authority. The open-ended, free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism, perceived power imbalances, and feelings of connection toward the robot. In addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots, we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics.;2021-02-25;2021-05-19T13:29:53Z;2021-05-19T13:29:53Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; social robotics; qualitative research; human- robot interaction; prosocial behaviour; social perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;hittherobotontheheadwiththismalletmakingacaseforincludingmoreopenquestionsinhriresearch;hit the robot on the head with this mallet  making a case for including more open questions in hri research researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents as opposed to objects one such approach involves asking participants to inflict harm on a robot researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying and propose that relatively long periods of hesitation might reflect empathy for the robot and perhaps even attribution of humanlike qualities such as agency and sentience in a recent experiment we adapted the socalled hesitance to hit paradigm in which participants were instructed to hit a humanoid robot on the head with a mallet after standing up to do so signaling intent to hit the robot participants were stopped and then took part in a semistructured interview to probe their thoughts and feelings during the period of hesitation thematic analysis of the responses indicate that hesitation not only reflects perceived socialness but also other factors including but not limited to concerns about cost mallet disbelief processing of the task instruction and the influence of authority the openended free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism perceived power imbalances and feelings of connection toward the robot in addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics
SCEACN3G;journalArticle;2021;"Babel, Franziska; Kraus, Johannes M.; Baumann, Martin";Development and Testing of Psychological Conflict Resolution Strategies for Assertive Robots to Resolve Human-Robot Goal Conflict;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.591448;NA;"As service robots become increasingly autonomous and follow their own task-related goals, human-robot conflicts seem inevitable, especially in shared spaces. Goal conflicts can arise from simple trajectory planning to complex task prioritization. For successful human-robot goal-conflict resolution, humans and robots need to negotiate their goals and priorities. For this, the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user. In this paper, conflict resolution strategies for service robots (public cleaning robot, home assistant robot) are developed by transferring psychological concepts (e.g., negotiation, cooperation) to HRI. Altogether, fifteen strategies were grouped by the expected affective outcome (positive, neutral, negative). In two online experiments, the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts (public: n(1) = 61; private: n(2) = 93). To obtain a comparative value, the strategies were also applied by a human. As additional outcomes trust, fear, arousal, and valence, as well as perceived politeness of the agent were assessed. The positive/neutral strategies were found to be more acceptable and effective than negative strategies. Some negative strategies (i.e., threat, command) even led to reactance and fear. Some strategies were only positively evaluated and effective for certain agents (human or robot) or only acceptable in one of the two application contexts (i.e., approach, empathy). Influences on strategy acceptance and compliance in the public context could be found: acceptance was predicted by politeness and trust. Compliance was predicted by interpersonal power. Taken together, psychological conflict resolution strategies can be applied in HRI to enhance robot task effectiveness. If applied robot-specifically and context-sensitively they are accepted by the user. The contribution of this paper is twofold: conflict resolution strategies based on Human Factors and Social Psychology are introduced and empirically evaluated in two online studies for two application contexts. Influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed.";2021-01-26;2021-05-19T13:29:54Z;2021-05-19T13:29:54Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"trust; persuasive robots; acceptance; HRI strategies; robot assertiveness; user compliance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;developmentandtestingofpsychologicalconflictresolutionstrategiesforassertiverobotstoresolvehumanrobotgoalconflict;development and testing of psychological conflict resolution strategies for assertive robots to resolve humanrobot goal conflict as service robots become increasingly autonomous and follow their own taskrelated goals humanrobot conflicts seem inevitable especially in shared spaces goal conflicts can arise from simple trajectory planning to complex task prioritization for successful humanrobot goalconflict resolution humans and robots need to negotiate their goals and priorities for this the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user in this paper conflict resolution strategies for service robots public cleaning robot home assistant robot are developed by transferring psychological concepts eg negotiation cooperation to hri altogether fifteen strategies were grouped by the expected affective outcome positive neutral negative in two online experiments the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts public n1  61 private n2  93 to obtain a comparative value the strategies were also applied by a human as additional outcomes trust fear arousal and valence as well as perceived politeness of the agent were assessed the positiveneutral strategies were found to be more acceptable and effective than negative strategies some negative strategies ie threat command even led to reactance and fear some strategies were only positively evaluated and effective for certain agents human or robot or only acceptable in one of the two application contexts ie approach empathy influences on strategy acceptance and compliance in the public context could be found acceptance was predicted by politeness and trust compliance was predicted by interpersonal power taken together psychological conflict resolution strategies can be applied in hri to enhance robot task effectiveness if applied robotspecifically and contextsensitively they are accepted by the user the contribution of this paper is twofold conflict resolution strategies based on human factors and social psychology are introduced and empirically evaluated in two online studies for two application contexts influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed
XJNCCCZQ;journalArticle;2021;"Chang, Wenwen; Wang, Hong; Yan, Guanghui; Lu, Zhiguo; Liu, Chong; Hua, Chengcheng";EEG based functional connectivity analysis of human pain empathy towards humans and robots;NEUROPSYCHOLOGIA;NA;0028-3932;10.1016/j.neuropsychologia.2020.107695;NA;Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots.;2021-01-22;2021-05-19T13:29:54Z;2021-05-19T13:29:54Z;NA;NA;NA;NA;151;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"EEG; Functional connectivity; Empathy; Human-robot interaction; Empathy index; Mutual information";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;eegbasedfunctionalconnectivityanalysisofhumanpainempathytowardshumansandrobots;eeg based functional connectivity analysis of human pain empathy towards humans and robots humans can show emotional reactions toward humanoid robots such as empathy previous neuroimaging studies have indicated that neural responses of empathy for others pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans however the wholebrain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown in the present study the functional connectivity was investigated for erps recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and nonpainful situations functional brain networks for both early and late empathy responses were constructed and a new parameter empathy index ei was proposed to represent the empathy ability of humans quantitatively we found that the mutual dependences between early erp components was significantly decreased but for the late components there were no significant changes the mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components but not for late components the connectivity weights for early components were larger than late components ei value shows significant difference between painful and nonpainful stimuli indicating it is a good indicator to represent the empathy of humans this study enriches our understanding of the neurological mechanisms implicated in human empathy and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots
9SWDV3ZD;journalArticle;NA;"Ho, Jeffrey C. F.; Ng, Ryan";Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion;BEHAVIOUR & INFORMATION TECHNOLOGY;NA;0144-929X;10.1080/0144929X.2020.1864018;NA;This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters - NPCs in a prosocial VR game - influences players' in-game empathy towards NPCs and game immersion. Participants first experienced either a robot's perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants' game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players' weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed.;NA;2021-05-19T13:29:56Z;2021-05-19T13:29:56Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article; Early Access";NA;NA;NA;NA;"empathy; virtual reality; digital games; Perspective taking; prosocial games";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;perspectivetakingofnonplayercharactersinprosocialvirtualrealitygameseffectsonclosenessempathyandgameimmersion;perspectivetaking of nonplayer characters in prosocial virtual reality games effects on closeness empathy and game immersion this study explores the effects of the perspectivetaking of nonplayer characters npcs on enhancing game immersion in prosocial virtual reality vr games prosocial games are games focusing on helping others game researchers have been keen to investigate factors that influence the immersive experience in digital games previous studies show that vr allows people to take the perspective of others inducing empathy and prosocial behaviour in the real world in this labbased study we explore whether and how taking the perspective of other game characters  npcs in a prosocial vr game  influences players ingame empathy towards npcs and game immersion participants first experienced either a robots perspective of being destroyed by fire in vr or read a text description about the same event then they participated a prosocial vr game in which they saved robots the findings show that perspectivetaking experiences indirectly enhance participants game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player this indirect effect is moderated by players weekly exposure to video games these results suggest that vrbased perspectivetaking of npcs can indirectly enhance gameplay experiences in prosocial vr games theoretical and game design implications are discussed
LDQ5LCHS;journalArticle;2020;"Ionta, Silvio; Costantini, Marcello; Ferretti, Antonio; Galati, Gaspare; Romani, Gian Luca; Aglioti, Salvatore M.";Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain;CORTEX;NA;0010-9452;10.1016/j.cortex.2020.09.028;NA;Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by lowand high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively. (C) 2020 The Author(s). Published by Elsevier Ltd.;2020-12;2021-05-19T13:29:56Z;2021-05-19T13:29:56Z;NA;295-308;NA;NA;133;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE Publisher: ELSEVIER MASSON, CORP OFF Type: Article;NA;NA;NA;NA;"fMRI; Empathy; Pain; Affective; Sensorimotor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;visualsimilarityandpsychologicalclosenessareneurallydissociableinthebrainresponsetovicariouspain;visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain personal and vicarious experience of pain activate partially overlapping brain networks this brain activity is further modulated by lowand highorder factors eg the perceived intensity of the models pain and the models similarity with the onlooker respectively we investigated which specific aspect of similarity modulates such empathic reactivity focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models to this aim we recorded fmri data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand a baby human hand a puppy dog paw and an anthropomorphic robotic hand the interaction between type of vicarious experience pain touch and nature of model adult baby dog robot showed that the right supramarginal gyrus rsmg was selectively active for visual similarity more active during vicarious pain for the adult and baby models while the anterior cingulate cortex acc was more sensitive to psychological closeness specifically linked to vicarious pain for the baby model these findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain respectively c 2020 the authors published by elsevier ltd
URG73Y5L;journalArticle;2020;"Konijn, Elly A.; Hoorn, Johan F.";Differential Facial Articulacy in Robots and Humans Elicit Different Levels of Responsiveness, Empathy, and Projected Feelings;ROBOTICS;NA;NA;10.3390/robotics9040092;NA;"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot's face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot's face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) x 2 (treatment: affectionate vs. maltreated). Participants (N = 265; M-age = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of `because I feel, I believe it's real,' despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of `it is just a robot' fades into the background and appears not relevant anymore.";2020-12;2021-05-19T13:29:57Z;2021-05-19T13:29:57Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; social robots; facial expression; experiment; human-robot communication; user response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;differentialfacialarticulacyinrobotsandhumanselicitdifferentlevelsofresponsivenessempathyandprojectedfeelings;differential facial articulacy in robots and humans elicit different levels of responsiveness empathy and projected feelings lifelike humanoid robots are on the rise aiming at communicative purposes that resemble humanlike conversation in human social interaction the facial expression serves important communicative functions we examined whether a robots face is similarly important in humanrobot communication based on emotion research and neuropsychological insights on the parallel processing of emotions we argue that greater plasticity in the robots face elicits higher affective responsivity more closely resembling humantohuman responsiveness than a more static face we conducted a betweensubjects experiment of 3 facial plasticity human vs facially flexible robot vs facially static robot x 2 treatment affectionate vs maltreated participants n  265 mage  315 were measured for their emotional responsiveness empathy and attribution of feelings to the robot results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns significantly different intensities of feelings and attributions eg pain upon maltreatment followed facial articulacy theoretical implications for underlying processes in humanrobot communication are discussed we theorize that precedence of emotion and affect over cognitive reflection which are processed in parallel triggers the experience of because i feel i believe its real despite being aware of communicating with a robot by evoking emotional responsiveness the cognitive awareness of it is just a robot fades into the background and appears not relevant anymore
VM3URQDR;journalArticle;2020;"Bagheri, Elahe; Esteban, Pablo G.; Cao, Hoang-Long; De Beir, Albert; Lefeber, Dirk; Vanderborght, Bram";An Autonomous Cognitive Empathy Model Responsive to Users' Facial Emotion Expressions;ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS;NA;2160-6455;10.1145/3341198;NA;Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.;2020-11;2021-05-19T13:29:58Z;2021-05-19T13:29:58Z;NA;NA;NA;3, SI;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"Empathy; social robots; human robot interaction; adaptive interaction; facial emotion detection; non-verbal behavior";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anautonomouscognitiveempathymodelresponsivetousersfacialemotionexpressions;an autonomous cognitive empathy model responsive to users facial emotion expressions successful social robot services depend on how robots can interact with users the effective service can be obtained through smooth engaged and humanoid interactions in which robots react properly to a users affective state this article proposes a novel automatic cognitive empathy model acem for humanoid robots to achieve longer and more engaged humanrobot interactions hri by considering humans emotions and replying to them appropriately the proposed model continuously detects the affective states of a user based on facial expressions and generates desired either parallel or reactive empathic behaviors that are already adapted to the users personality users affective states are detected using a stacked autoencoder network that is trained and tested on the ravdess dataset the overall proposed empathic model is verified throughout an experiment where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis the results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot
97Z9FJDE;journalArticle;2020;"Giannopulu, Irini; Etournaud, Aude; Terada, Kazunori; Velonaki, Mari; Watanabe, Tomio";Ordered interpersonal synchronisation in ASD children via robots;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-020-74438-6;NA;Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.;2020-10-15;2021-05-19T13:29:59Z;2021-05-19T13:29:59Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY Publisher: NATURE RESEARCH Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;orderedinterpersonalsynchronisationinasdchildrenviarobots;ordered interpersonal synchronisation in asd children via robots children with autistic spectrum disorders asd experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity robotic interventions have been explored for use with asd children worldwide revealing that robots encourage onetoone social and emotional interactions however associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in french and japanese asd children when they interact with a human or a robot under analogous experimental conditions using the paradigm of actorperceiver where the child was the actor and the robot or the human the perceiver we recorded the autonomic heart rate activation and reported emotional feelings of asd children in both countries japanese and french asd children showed different interpersonal synchronisation when they interacted with the human perceiver even though the human was the same in both countries however they exhibited similar interpersonal synchronisation when the perceiver was the robot the findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in asd children and that both french and japanese asd children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping
29DPG2CR;journalArticle;NA;"Bagheri, Elahe; Roesler, Oliver; Cao, Hoang-Long; Vanderborght, Bram";A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00683-4;NA;Robots that express human's social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better.;NA;2021-05-19T13:30:00Z;2021-05-19T13:30:00Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Personality; Reinforcement learning; Empathy; Human-robot interaction; Social robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;areinforcementlearningbasedcognitiveempathyframeworkforsocialrobots;a reinforcement learning based cognitive empathy framework for social robots robots that express humans social norms like empathy are perceived as more friendly understanding and caring however appropriate humanlike empathic behaviors cannot be defined in advance instead they must be learned through daily interaction with humans in different situations additionally to learn and apply the correct behaviors robots must be able to perceive and understand the affective states of humans this study presents a framework to enable cognitive empathy in social robots which uses facial emotion recognition to perceive and understand the affective states of human users the perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states the proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot pepper the results show that by applying empathic behaviors selected by the employed learning model the robot is able to provide participants comfort and confidence and help them enjoy and feel better
QMPZ8IGA;journalArticle;2021;"Kuester, Dennis; Swiderska, Aleksandra";Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes;INTERNATIONAL JOURNAL OF PSYCHOLOGY;NA;0020-7594;10.1002/ijop.12715;NA;According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.;2021-06;2021-05-19T13:30:00Z;2021-05-19T13:30:00Z;NA;454-465;NA;3;56;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND Publisher: JOHN WILEY & SONS LTD Type: Article;NA;NA;NA;NA;"Robots; Benevolent intentions; Dehumanisation; Mind perception; Moral typecasting theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;seeingthemindofrobotsharmaugmentsmindperceptionbutbenevolentintentionsreducedehumanisationofartificialentitiesinvisualvignettes;seeing the mind of robots harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes according to moral typecasting theory good and evildoers agents interact with the recipients of their actions patients in a moral dyad when this dyad is completed mind attribution towards intentionally harmed liminal minds is enhanced however from a dehumanisation view malevolent actions may instead result in a denial of humanness to contrast both accounts a visual vignette experiment n  253 depicted either malevolent or benevolent intentions towards robotic or human avatars additionally we examined the role of harmsalience by showing patients as either harmed or still unharmed the results revealed significantly increased mind attribution towards visibly harmed patients mediated by perceived pain and expressed empathy benevolent and malevolent intentions were evaluated respectively as morally right or wrong but their impact on the patient was diminished for the robotic avatar contrary to dehumanisation predictions our manipulation of intentions failed to affect mind perception nonetheless benevolent intentions reduced dehumanisation of the patients moreover when pain and empathy were statistically controlled the effect of intentions on mind perception was mediated by dehumanisation these findings suggest that perceived intentions might only be indirectly tied to mind perception and that their role may be better understood when additionally accounting for empathy and dehumanisation
C4NJ4JAH;journalArticle;NA;"James, Jesin; Balamurali, B. T.; Watson, Catherine I.; MacDonald, Bruce";Empathetic Speech Synthesis and Testing for Healthcare Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-020-00691-4;NA;One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot's voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people's acceptance of social robots.;NA;2021-05-19T13:30:01Z;2021-05-19T13:30:01Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access";NA;NA;NA;NA;"Social robots; Artificial empathy; Emotional speech synthesis; Healthcare; Prosody modelling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empatheticspeechsynthesisandtestingforhealthcarerobots;empathetic speech synthesis and testing for healthcare robots one of the major factors that affect the acceptance of robots in humanrobot interaction applications is the type of voice with which they interact with humans the robots voice can be used to express empathy which is an affective response of the robot to the human user in this study the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications a pilot study using an empathetic voice spoken by a voice actor was conducted only prosody in speech is used to express empathy here without any visual cues also the emotions needed for an empathetic voice are identified it was found that the emotions needed are not only the stronger primary emotions but also the nuanced secondary emotions these emotions are then synthesised using prosody modelling a second study replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well this paper reports the modelling and synthesises of an empathetic voice and experimentally shows that people prefer empathetic voice for healthcare robots the results can be further used to develop empathetic social robots that can improve peoples acceptance of social robots
KMDAUZEC;journalArticle;2020;"Casas-Bocanegra, Diego; Gomez-Vargas, Daniel; Pinto-Bernal, Maria J.; Maldonado, Juan; Munera, Marcela; Villa-Moreno, Adriana; Stoelen, Martin F.; Belpaeme, Tony; Cifuentes, Carlos A.";An Open-Source Social Robot Based on Compliant Soft Robotics for Therapy with Children with ASD;ACTUATORS;NA;NA;10.3390/act9030091;NA;Therapy with robotic tools is a promising way to help improve verbal and nonverbal communication in children. The robotic tools are able to increase aspects such as eye contact and the ability to follow instructions and to empathize with others. This work presents the design methodology, development, and experimental validation of a novel social robot based on CompliAnt SofT Robotics called the CASTOR robot, which intends to be used as an open-source platform for the long-term therapy of children with autism spectrum disorder (CwASD). CASTOR integrates the concepts of soft actuators and compliant mechanisms to create a replicable robotic platform aimed at real therapy scenarios involving physical interaction between the children and the robot. The validation shows promising results in terms of robustness and the safety of the user and robot. Likewise, mechanical tests assess the robot's response to blocking conditions for two critical modules (i.e., neck and arm) in interaction scenarios. Future works should focus on the validation of the robot's effectiveness in the therapy of CwASD.;2020-09;2021-05-19T13:30:01Z;2021-05-19T13:30:01Z;NA;NA;NA;3;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"robot design; autism therapy; autism spectrum disorder; compliant mechanisms; physical interaction; series elastic actuators; social assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anopensourcesocialrobotbasedoncompliantsoftroboticsfortherapywithchildrenwithasd;an opensource social robot based on compliant soft robotics for therapy with children with asd therapy with robotic tools is a promising way to help improve verbal and nonverbal communication in children the robotic tools are able to increase aspects such as eye contact and the ability to follow instructions and to empathize with others this work presents the design methodology development and experimental validation of a novel social robot based on compliant soft robotics called the castor robot which intends to be used as an opensource platform for the longterm therapy of children with autism spectrum disorder cwasd castor integrates the concepts of soft actuators and compliant mechanisms to create a replicable robotic platform aimed at real therapy scenarios involving physical interaction between the children and the robot the validation shows promising results in terms of robustness and the safety of the user and robot likewise mechanical tests assess the robots response to blocking conditions for two critical modules ie neck and arm in interaction scenarios future works should focus on the validation of the robots effectiveness in the therapy of cwasd
CDILTHJ9;journalArticle;2020;"Sumitani, Mizuho; Osumi, Michihiro; Abe, Hiroaki; Azuma, Kenji; Tsuchida, Rikuhei; Sumitani, Masahiko";A Robot Has a Mind of Its Own Because We Intuitively Share It;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app10186531;NA;People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we `share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent).;2020-09;2021-05-19T13:30:02Z;2021-05-19T13:30:02Z;NA;NA;NA;18;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"pain; empathy; affective mind; facial expression; robot (virtual agent)";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;arobothasamindofitsownbecauseweintuitivelyshareit;a robot has a mind of its own because we intuitively share it people perceive the mind in two dimensions intellectual and affective advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions conversely it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions we investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds ie painful unhappy and neutral the cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions subjects were asked to rate the pain intensity from the respective facial expressions changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities only when watching the painful expression of a virtual agent did the cold pain detection threshold increase significantly by directly evaluating intuitive pain responses when observing facial expressions of a virtual agent we found that we share empathic neural responses which can be intuitively emerge according to observed pain intensity with a robot a virtual agent
84YRC76D;journalArticle;2020;"Pepito, Joseph Andrew; Ito, Hirokazu; Betriana, Feni; Tanioka, Tetsuya; Locsin, Rozzano C.";Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations;NURSING PHILOSOPHY;NA;1466-7681;10.1111/nup.12318;NA;"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.";2020-10;2021-05-19T13:30:02Z;2021-05-19T13:30:02Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; affective developmental robotics; artificial empathy; humanoid nurse robots; intelligent humanoid robots; nursing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;intelligenthumanoidrobotsexpressingartificialhumanlikeempathyinnursingsituations;intelligent humanoid robots expressing artificial humanlike empathy in nursing situations intelligent humanoid robots ihrs are becoming likely to be integrated into nursing practice however a proper integration of ihrs requires a detailed description and explanation of their essential capabilities particularly regarding their competencies in replicating and portraying emotive functions such as empathy existing humanoid robots can exhibit rudimentary forms of empathy as these machines slowly become commonplace in healthcare settings they will be expected to express empathy as a natural function rather than merely to portray artificial empathy as a replication of human empathy this article works with a twofold purpose firstly to consider the impact of artificial empathy in nursing and secondly to describe the influence of affective developmental robotics adr in anticipation of the empathic behaviour presented by artificial humanoid robots the adr has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy this will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry a discussion of ihrs demonstrating artificial empathy is critical to nursing practice today particularly in healthcare settings dense with technology
US8G9LRZ;journalArticle;2020;"Stokes, Felicia; Palmer, Amitabha";Artificial Intelligence and Robotics in Nursing: Ethics of Caring as a Guide to Dividing Tasks Between AI and Humans;NURSING PHILOSOPHY;NA;1466-7681;10.1111/nup.12306;NA;Nurses have traditionally been regarded as clinicians that deliver compassionate, safe, and empathetic health care (Nurses again outpace other professions for honesty & ethics, 2018). Caring is a fundamental characteristic, expectation, and moral obligation of the nursing and caregiving professions (Nursing: Scope and standards of practice, American Nurses Association, Silver Spring, MD, 2015). Along with caring, nurses are expected to undertake ever-expanding duties and complex tasks. In part because of the growing physical, intellectual and emotional demandingness, of nursing as well as technological advances, artificial intelligence (AI) and AI care robots are rapidly changing the healthcare landscape. As technology becomes more advanced, efficient, and economical, opportunities and pressure to introduce AI into nursing care will only increase. In the first part of the article, we review recent and existing applications of AI in nursing and speculate on future use. Second, situate our project within the recent literature on the ethics of nursing and AI. Third, we explore three dominant theories of caring and the two paradigmatic expressions of caring (touch and presence) and conclude that AI-at least for the foreseeable future-is incapable of caring in the sense central to nursing and caregiving ethics. We conclude that for AI to be implemented ethically, it cannot transgress the core values of nursing, usurp aspects of caring that can only meaningfully be carried out by human beings, and it must support, open, or improve opportunities for nurses to provide the uniquely human aspects of care.;2020-10;2021-05-19T13:30:03Z;2021-05-19T13:30:03Z;NA;NA;NA;4;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article;NA;NA;NA;NA;"artificial intelligence; ethics; nursing; robotics; ethics of caring";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;artificialintelligenceandroboticsinnursingethicsofcaringasaguidetodividingtasksbetweenaiandhumans;artificial intelligence and robotics in nursing ethics of caring as a guide to dividing tasks between ai and humans nurses have traditionally been regarded as clinicians that deliver compassionate safe and empathetic health care nurses again outpace other professions for honesty  ethics 2018 caring is a fundamental characteristic expectation and moral obligation of the nursing and caregiving professions nursing scope and standards of practice american nurses association silver spring md 2015 along with caring nurses are expected to undertake everexpanding duties and complex tasks in part because of the growing physical intellectual and emotional demandingness of nursing as well as technological advances artificial intelligence ai and ai care robots are rapidly changing the healthcare landscape as technology becomes more advanced efficient and economical opportunities and pressure to introduce ai into nursing care will only increase in the first part of the article we review recent and existing applications of ai in nursing and speculate on future use second situate our project within the recent literature on the ethics of nursing and ai third we explore three dominant theories of caring and the two paradigmatic expressions of caring touch and presence and conclude that aiat least for the foreseeable futureis incapable of caring in the sense central to nursing and caregiving ethics we conclude that for ai to be implemented ethically it cannot transgress the core values of nursing usurp aspects of caring that can only meaningfully be carried out by human beings and it must support open or improve opportunities for nurses to provide the uniquely human aspects of care
ZLLD8J62;journalArticle;2020;"Rossi, Silvia; Conti, Daniela; Garramone, Federica; Santangelo, Gabriella; Staffa, Mariacarla; Varrasi, Simone; Di Nuovo, Alessandro";The Role of Personality Factors and Empathy in the Acceptance and Performance of a Social Robot for Psychometric Evaluations;ROBOTICS;NA;NA;10.3390/robotics9020039;NA;Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the “openness to experience”, on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests.;2020-06;2021-05-19T13:30:04Z;2021-05-19T13:30:04Z;NA;NA;NA;2;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"empathy; human friendly cognitive robotics; personality factors; psychometric evaluation; social assistive robots; technology acceptance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theroleofpersonalityfactorsandempathyintheacceptanceandperformanceofasocialrobotforpsychometricevaluations;the role of personality factors and empathy in the acceptance and performance of a social robot for psychometric evaluations research and development in socially assistive robotics have produced several novel applications in the care of senior people however some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users intellectual capacity to fully exploit the application of a social robot as a psychometric tool it is necessary to account for the users factors that might influence the interaction with a robot and the evaluation of user cognitive performance to this end we invited senior participants to use a prototype of a robotled cognitive test and analyzed the influence of personality traits and users empathy on the cognitive performance and technology acceptance results show a positive influence of a personality trait the openness to experience on the humanrobot interaction and that other factors such as anxiety trust and intention to use are influencing technology acceptance and correlate the evaluation by psychometric tests
S99XEAV3;journalArticle;2020;"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin";Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots;TOURISM MANAGEMENT;NA;0261-5177;10.1016/j.tourman.2019.104042;NA;Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.;2020-06;2021-05-19T13:30:04Z;2021-05-19T13:30:04Z;NA;NA;NA;NA;78;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article;NA;NA;NA;NA;"Artificial intelligence; Human-robot interaction; Hospitality services; Intention to use robots; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;leveraginghumanrobotinteractioninhospitalityservicesincorporatingtheroleofperceivedvalueempathyandinformationsharingintovisitorsintentionstousesocialrobots;leveraging humanrobot interaction in hospitality services incorporating the role of perceived value empathy and information sharing into visitors intentions to use social robots social robots have become pervasive in the tourism and hospitality service environments the empirical understanding of the drivers of visitors intentions to use robots in such services has become an urgent necessity for their sustainable deployment certainly using social androids within hospitality services requires organisations attentive commitment to value creation and fulfilling service quality expectations in this paper via structural equation modelling sem and semistructured interviews with managers we conceptualise and empirically test visitors intentions to use social robots in hospitality services with data collected in singapores hospitality settings we found visitors intentions to use social robots stem from the effects of technology acceptance variables service quality dimensions leading to perceived value and two further dimensions from human robot interaction hri empathy and information sharing analysis of these dimensions importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robotdelivered services in tourism and hospitality strategies
CD4R6IUH;journalArticle;2020;"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung";The Design and Implementation of XiaoIce, an Empathetic Social Chatbot;COMPUTATIONAL LINGUISTICS;NA;0891-2017;10.1162/coli_a_00368;NA;This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human-machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.;2020-03;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;53-93;NA;1;46;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA Publisher: MIT PRESS Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;thedesignandimplementationofxiaoiceanempatheticsocialchatbot;the design and implementation of xiaoice an empathetic social chatbot this article describes the development of microsoft xiaoice the most popular social chatbot in the world xiaoice is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication affection and social belonging we take into account both intelligent quotient and emotional quotient in system design cast humanmachine social chat as decisionmaking over markov decision processes and optimize xiaoice for longterm user engagement measured in expected conversationturns per session cps we detail the system architecture and key components including dialogue manager core chat skills and an empathetic computing module we show how xiaoice dynamically recognizes human feelings and states understands user intent and responds to user needs throughout long conversations since the release in 2014 xiaoice has communicated with over 660 million active users and succeeded in establishing longterm relationships with many of them analysis of largescale online logs shows that xiaoice has achieved an average cps of 23 which is significantly higher than that of other chatbots and even human conversations
ZT2NC7TU;journalArticle;2020;McBride, Neil;Robot Enhanced Therapy for Autistic Children: An Ethical Analysis;IEEE TECHNOLOGY AND SOCIETY MAGAZINE;NA;0278-0097;10.1109/MTS.2020.2967493;NA;The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in IEEE Technology and Society Magazine, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions.;2020-03;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;51-60;NA;1;39;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Medical treatment; Ethics; Robot sensing systems; Autism; Pediatrics; Social implications of technology";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotenhancedtherapyforautisticchildrenanethicalanalysis;robot enhanced therapy for autistic children an ethical analysis the use of social robots has been proposed for the delivery of therapy to autistic children the aim of such projects of which the dream project is an example is to replace therapists by robots operating in sensory environments that enable them to detect and respond to feedback from the child this article considers the ethical concerns of autonomy community transparency identity value and empathy to evaluate the ethics of such deployment of robots in doing so it provides a response to the richardson et al article in ieee technology and society magazine mar 2018 20 this article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned the use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed rather than on the basis of the technology itself particularly important is the roboticists empathy with the user of the robot and gaining an understanding of the individual child the paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the childs regulation of emotions
GWM22WQW;journalArticle;2020;"Bjorling, Elin A.; Thomas, Kyle; Rose, Emma J.; Cakmak, Maya";Exploring Teens as Robot Operators, Users and Witnesses in the Wild;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2020.00005;NA;As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.;2020-02-21;2021-05-19T13:30:07Z;2021-05-19T13:30:07Z;NA;NA;NA;NA;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"empathy; social robots; mental health; adolescence; human-centered design; participatory; Wizard of Oz";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;exploringteensasrobotoperatorsusersandwitnessesinthewild;exploring teens as robot operators users and witnesses in the wild as social robots continue to show promise as assistive technologies the exploration of appropriate and impactful robot behaviors is key to their eventual success teens are a unique population given their vulnerability to stress leading to both mental and physical illness much of teen stress stems from school making the school environment an ideal location for a stress reducing technology the goal of this mixedmethods study was to understand teens operation of and responsiveness to a robot only capable of movement compared to a robot only capable of speech stemming from a humancentered approach we introduce a participatory wizard of oz pwoz interaction method that engaged teens as operators users and witnesses in a uniquely transparent interaction in this paper we illustrate the use of the pwoz interaction method as well as how it helps identify engaging robot interactions using this technique we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions we analyzed the teens interactions with both the verbal and nonverbal robots and identified strong themes of 1 authenticity 2 empathy 3 emotional engagement and 4 imperfection creates connection finally we reflect on the benefits and limitations of the pwoz method and our study to identify next steps toward the design and development of our social robot
LWWYWHSC;journalArticle;2020;"Anders, Silke; Beck, Christian; Domin, Martin; Lotze, Martin";Empathic responses to unknown others are modulated by shared behavioural traits;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-020-57711-6;NA;How empathically people respond to a stranger's pain or pleasure does not only depend on the situational context, individual traits and intentions, but also on interindividual factors. Here we ask whether empathic responses towards unknown others are modulated by behavioural similarity as a potential marker of genetic relatedness. Participants watched two supposed human players who were modelled as having a strong (player LP) or weak (player NLP) tendency to lead in social situations executing penalty shots in a virtual reality robot soccer game. As predicted, empathic response were modulated by shared behavioural traits: participants whose tendency to lead was more similar to player LP's tendency to lead experienced more reward, and showed stronger neural activity in reward-related brain regions, when they saw player LP score a goal, and participants whose tendency to lead was more similar to player NLP's tendency to lead showed stronger empathic responses when they saw player NLP score a goal. These findings highlight the potentially evolutionary grounded role of phenotypic similarity for neural processes underlying human social perception.;2020-02-06;2021-05-19T13:30:08Z;2021-05-19T13:30:08Z;NA;NA;NA;1;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicresponsestounknownothersaremodulatedbysharedbehaviouraltraits;empathic responses to unknown others are modulated by shared behavioural traits how empathically people respond to a strangers pain or pleasure does not only depend on the situational context individual traits and intentions but also on interindividual factors here we ask whether empathic responses towards unknown others are modulated by behavioural similarity as a potential marker of genetic relatedness participants watched two supposed human players who were modelled as having a strong player lp or weak player nlp tendency to lead in social situations executing penalty shots in a virtual reality robot soccer game as predicted empathic response were modulated by shared behavioural traits participants whose tendency to lead was more similar to player lps tendency to lead experienced more reward and showed stronger neural activity in rewardrelated brain regions when they saw player lp score a goal and participants whose tendency to lead was more similar to player nlps tendency to lead showed stronger empathic responses when they saw player nlp score a goal these findings highlight the potentially evolutionary grounded role of phenotypic similarity for neural processes underlying human social perception
DZAXM7UT;conferencePaper;2020;"Rossi, Silvia; Dell'Aquila, Elena; Russo, Davide; Maggi, Gianpaolo";Increasing Engagement with Chameleon Robots in Bartending Services;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;As the field of service robotics has been rapidly growing, it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way. This is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users' experience. In this paper, we address the question of whether a specific behavioral style of a barman-robot, acted through para-verbal and non-verbal behaviors, can affect users' engagement and the creation of positive emotions. To that end, we endowed a barman-robot taking drink orders from human customers, with an empathic behavioral style. This aims at triggering to alignment process by mimicking the conversation partner's behavior. This behavioral style is compared to an entertaining style, aiming at creating a positive relationship with the users, and a neutral style for control. Results suggest that when participants experienced more positive emotions, the robot was perceived as safer, so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement. Indeed, when the empathic robot modulates its behavior according to the user's one, this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in public-service contexts.;2020;2021-05-19T13:30:12Z;2021-05-19T13:30:12Z;NA;464-469;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;increasingengagementwithchameleonrobotsinbartendingservices;increasing engagement with chameleon robots in bartending services as the field of service robotics has been rapidly growing it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way this is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users experience in this paper we address the question of whether a specific behavioral style of a barmanrobot acted through paraverbal and nonverbal behaviors can affect users engagement and the creation of positive emotions to that end we endowed a barmanrobot taking drink orders from human customers with an empathic behavioral style this aims at triggering to alignment process by mimicking the conversation partners behavior this behavioral style is compared to an entertaining style aiming at creating a positive relationship with the users and a neutral style for control results suggest that when participants experienced more positive emotions the robot was perceived as safer so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement indeed when the empathic robot modulates its behavior according to the users one this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in publicservice contexts
G8AYUJ4K;conferencePaper;2020;"Mitsuno, Seiya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.;2020;2021-05-19T13:30:12Z;2021-05-19T13:30:12Z;NA;653-658;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotonrobotgossipingtoimprovesenseofhumanrobotconversation;robotonrobot gossiping to improve sense of humanrobot conversation in recent years a substantial amount of research has been aimed at realizing a social robot that can maintain longterm user interest one approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users however privacy problems may occur owing to private information of the user being mentioned we propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping this dialogue strategy can improve the sense of conversation which results in increased interest while avoiding the privacy issue we examined our proposal by conducting a conversation experiment evaluated by subject impressions the results demonstrated that the proposed method could help the robot to obtain higher evaluations in particular the perceived mind was improved in the likert scale evaluation whereas the robot empathy and intention to use were improved in the binary comparison evaluation our dialogue strategy may contribute to understanding the factors regarding the sense of conversation thereby adding value to the field of humanrobot interaction
BH8DME83;conferencePaper;2020;"Ye, Sean; Feigh, Karen; Howard, Ayanna";Learning in Motion: Dynamic Interactions for Increased Trust in Human-Robot Interaction Games;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Embodiment of actions and tasks has typically been analyzed from the robot's perspective where the robot's embodiment helps develop and maintain trust. However, we ask a similar question looking at the interaction from the human perspective. Embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation. To understand how human embodiment can help develop and increase trust in human-robot interactions, we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot. Participants either performed the dance motion or utilized a touch screen during the interaction. The results showed that participants' trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device.;2020;2021-05-19T13:30:13Z;2021-05-19T13:30:13Z;NA;1186-1189;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;learninginmotiondynamicinteractionsforincreasedtrustinhumanrobotinteractiongames;learning in motion dynamic interactions for increased trust in humanrobot interaction games embodiment of actions and tasks has typically been analyzed from the robots perspective where the robots embodiment helps develop and maintain trust however we ask a similar question looking at the interaction from the human perspective embodied cognition has been shown in the cognitive science literature to produce increased social empathy and cooperation to understand how human embodiment can help develop and increase trust in humanrobot interactions we created conducted a study where participants were tasked with memorizing greek letters associated with dance motions with the help of a humanoid robot participants either performed the dance motion or utilized a touch screen during the interaction the results showed that participants trust in the robot increased at a higher rate during human embodiment of motions as opposed to utilizing a touch screen device
JYDVDUAF;conferencePaper;2020;"Perusquia-Hernandez, Monica; Balda, Marisabel Cuberos; Jauregui, David Antonio Gomez; Paez-Granados, Diego; Dollack, Felix; Salazar, Jose Victorio";Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self-tracking results might cause the opposite effect. Subtle self-tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.;2020;2021-05-19T13:30:13Z;2021-05-19T13:30:13Z;NA;1328-1333;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;"embodiment; empathy and intersubjectivity; haptic feedback; human-machine interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotmirroringpromotingempathywithanartificialagentbyreflectingtheusersphysiologicalaffectivestates;robot mirroring promoting empathy with an artificial agent by reflecting the users physiological affective states selftracking aims to increase awareness decrease undesired behaviors and ultimately lead towards a healthier lifestyle however inappropriate communication of selftracking results might cause the opposite effect subtle selftracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self hence we propose a wearable pet that reflects the users affective states through visual and haptic feedback by eliciting empathy and fostering helping behaviors towards it users would indirectly help themselves a wearable prototype was built and three user studies performed to evaluate the appropriateness of the proposed affective representations visual representations using facial and body cues were clear for valence and less clear for arousal haptic interoceptive patterns emulating heartrate levels matched the desired feedback urgency levels with a saturation frequency the integrated visuohaptic representations matched to participants own affective experience from the results we derived three design guidelines for future robot mirroring wearable systems physical embodiment interoceptive feedback and customization
DGKJPQ4Z;conferencePaper;2020;"Garcia Corretjer, Marialejandra; Ros, Raquel; Martin, Fernando; Miralles, David";The Maze of Realizing Empathy with Social Robots;2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72816-075-7;NA;NA;NA;Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.;2020;2021-05-19T13:30:14Z;2021-05-19T13:30:14Z;NA;1334-1339;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper";<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;themazeofrealizingempathywithsocialrobots;the maze of realizing empathy with social robots current trends envisage an evolution of collaboration engagement and relationship between humans and devices intelligent agents and robots in our everyday life some of the key elements under study are affective states motivation trust care and empathy this paper introduces an empathy testbed that serves as a case study for an existing empathy model the model describes the steps that need to occur in the process to provoke meaning in empathy as well as the variables and elements that contextualise those steps based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze a set of exploratory trials are carried out to gather insights on how users perceive the proposed testbed around attachment and trust which are basic elements for the realisation of empathy
BQF6P7UL;conferencePaper;2020;"Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vazquez, Marynel";Prompting Prosocial Human Interventions in Response to Robot Mistreatment;PROCEEDINGS OF THE 2020 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI `20);978-1-4503-6746-2;NA;10.1145/3319502.3374781;NA;Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.;2020;2021-05-19T13:30:15Z;2021-05-19T13:30:15Z;NA;211-220;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; SIGAI; IEEE Robot & Automat Soc; ACM Digital Lib; FN Robot; ARM; Cambridge Consultants; Furhat Robot; Halodi; Toyota Res Inst; Cambridge Univ Press; EXG Wear; Frontiers Robot & AI; Honda Res Inst; IDLab; MDPI Robot; MIT Press Europe; Promobot; Semio ISSN: 2167-2121 Type: Proceedings Paper";<p>ACM/IEEE International Conference on Human-Robot Interaction (HRI), Cambridge, ENGLAND, MAR 23-26, 2020</p>;NA;NA;NA;"Human-robot interaction; prosocial behavior; robot abuse";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;promptingprosocialhumaninterventionsinresponsetorobotmistreatment;prompting prosocial human interventions in response to robot mistreatment inspired by the benefits of human prosocial behavior we explore whether prosocial behavior can be extended to a humanrobot interaction hri context more specifically we study whether robots can induce prosocial behavior in humans through a 1x2 betweensubjects user study n  30 in which a confederate abused a robot through this study we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot our findings demonstrate possible effects of group social influence through emotional cues by robots in humanrobot interaction they reveal a need for further research regarding human prosocial behavior within hri
FYHNFM95;conferencePaper;2020;"Sani-Bozkurt, Sunagul; Bozkus-Genc, Gulden";NEW TREND ON ASD: CAN SOCIAL ROBOT BE A USEFUL TOOL IN JOINT ATTENTION FOR ASD?;14TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT CONFERENCE (INTED2020);978-84-09-17939-8;NA;NA;NA;Children with Autism Spectrum Disorder (ASD) suffer from a characteristic impairment in the ability to interpret social cues and often fail to use social gaze in empathetic and joint-attention tasks. The behavior of tracking an adult's eye movements, which appears in typically developing children in about 6th month, is considered as the beginning point of the ability to respond to joint attention. Studies show that children with ASD exhibit less joint attention skill and they fail in looking at the direction others are looking at and pointing at and in following the direction others are looking at, pointing at when they are compared to typically developing children and other children with developmental retardation. It is reported in some studies that the behaviors of responding to others' joint attention and initiation to joint attention are taught separately, and in other studies, both joint attention abilities are taught together. Nowadays, robot applications have appeared as a new approach in ASD implementations as a result of technological and scientific developments. Various social robots have been produced with an aim to increase the motivation of those with ASD by decreasing the stress level in complicated situations in the social setting and by enabling them to learn in simpler, predictable, and controlled settings. Besides, recently, social robots have increasingly been used in teaching joint attention abilities. In this study, it was aimed to give information about joint attention and types of robots, explain the characteristics of social robots, and put forward the current trends related to social robots by examining the studies conducted on the use of social robots for teaching joint attention abilities to children with ASD. Social robots could be a promising method for ASD treatment. There are remarkably different results regarding the robot applications in teaching the joint attention abilities to children with ASD. Therefore, it is not definitively known to which extent robot therapy contributes to the student's joint attention improvement. While efficiency research is frequently conducted in the studies in which robots have been used for teaching joint attention abilities to children with ASD, although rarely, comparative studies have also been conducted in recent years. Positive results are mentioned in this efficiency research, whereas there are also controversial results. In comparative studies, it is noteworthy that the human being and robot applications were compared in only one study. As a result, robots are thought to provide a significant support for the development of joint attention interactions such as attracting the attention of children, helping them participate in activities, building a bond for social interaction, motivating them, providing natural stimuli and bringing about different emotional expressions although there are different results about robot applications in the development of the joint attention abilities of children with ASD. In the related literature, it is also suggested to work with larger and different sample groups in order to generalize the existing study results since it is observed that the dimension of generalization is not addressed. Further studies in which robots play an active role compared to therapists can be carried out.;2020;2021-05-19T13:30:16Z;2021-05-19T13:30:16Z;NA;2090-2097;NA;NA;NA;NA;NA;NA;INTED Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1079 Type: Proceedings Paper;<p>14th International Technology, Education and Development Conference (INTED), Valencia, SPAIN, MAR 02-04, 2020</p>;NA;NA;NA;"robots; social robot; joint attention; Autism spectrum disorder";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;newtrendonasdcansocialrobotbeausefultoolinjointattentionforasd;new trend on asd can social robot be a useful tool in joint attention for asd children with autism spectrum disorder asd suffer from a characteristic impairment in the ability to interpret social cues and often fail to use social gaze in empathetic and jointattention tasks the behavior of tracking an adults eye movements which appears in typically developing children in about 6th month is considered as the beginning point of the ability to respond to joint attention studies show that children with asd exhibit less joint attention skill and they fail in looking at the direction others are looking at and pointing at and in following the direction others are looking at pointing at when they are compared to typically developing children and other children with developmental retardation it is reported in some studies that the behaviors of responding to others joint attention and initiation to joint attention are taught separately and in other studies both joint attention abilities are taught together nowadays robot applications have appeared as a new approach in asd implementations as a result of technological and scientific developments various social robots have been produced with an aim to increase the motivation of those with asd by decreasing the stress level in complicated situations in the social setting and by enabling them to learn in simpler predictable and controlled settings besides recently social robots have increasingly been used in teaching joint attention abilities in this study it was aimed to give information about joint attention and types of robots explain the characteristics of social robots and put forward the current trends related to social robots by examining the studies conducted on the use of social robots for teaching joint attention abilities to children with asd social robots could be a promising method for asd treatment there are remarkably different results regarding the robot applications in teaching the joint attention abilities to children with asd therefore it is not definitively known to which extent robot therapy contributes to the students joint attention improvement while efficiency research is frequently conducted in the studies in which robots have been used for teaching joint attention abilities to children with asd although rarely comparative studies have also been conducted in recent years positive results are mentioned in this efficiency research whereas there are also controversial results in comparative studies it is noteworthy that the human being and robot applications were compared in only one study as a result robots are thought to provide a significant support for the development of joint attention interactions such as attracting the attention of children helping them participate in activities building a bond for social interaction motivating them providing natural stimuli and bringing about different emotional expressions although there are different results about robot applications in the development of the joint attention abilities of children with asd in the related literature it is also suggested to work with larger and different sample groups in order to generalize the existing study results since it is observed that the dimension of generalization is not addressed further studies in which robots play an active role compared to therapists can be carried out
2TZC78CD;journalArticle;2020;"Rafique, Memoona; Hassan, Muhammad Awais; Jaleel, Abdul; Khalid, Hina; Bano, Gulshan";A Computation Model for Learning Programming and Emotional Intelligence;IEEE ACCESS;NA;2169-3536;10.1109/ACCESS.2020.3015533;NA;Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.;2020;2021-05-19T13:30:16Z;2021-05-19T13:30:16Z;NA;149616-149629;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"Computational modeling; Education; Robots; Emotional intelligence; basic programming; Programming profession; robots based learning; screen-free interface; Sequential analysis; Tools";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;acomputationmodelforlearningprogrammingandemotionalintelligence;a computation model for learning programming and emotional intelligence introducing coding in early education improves the logical and computational thinking in kids however cognitive skills are not sufficient for a successful life understanding and managing the emotions of oneself is another crucial factor in success the current state of the art teaching methods educates the kids about programming and emotional intelligence independently in our opinion it is advantageous to teach kids emotional intelligence along with the programming concepts however the literature lacks the studies that make students emotionally aware while teaching them programming this research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kids emotional intelligence can be enhanced while teaching them cognitive skills we proposed a computational model that teaches programming and emotional intelligence side by side to students the model provides a curriculum and related tools for evaluations five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model these students were divided into five groups a b c d and e each having a mean age of 4 5 6 7 and 8 years respectively students performed multiple adaptive scenarios of pathfinding that were based on selfawareness socialawareness sharing and empathy emotions students provide the programming instructions such as sequencing conditional statements and looping to a robot the children have successfully improved in both fundamental programming constructs and emotional intelligence skills the research also successfully reduced screen time problem by providing a screenfree student interface
66CX8XIS;journalArticle;2019;"Carlson, Zachary; Lemmon, Louise; Higgins, MacCallister; Frank, David; Shahrezaie, Roya Salek; Feil-Seifer, David";Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-019-00599-8;NA;"Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable.";2019-12;2021-05-19T13:30:19Z;2021-05-19T13:30:19Z;NA;727-739;NA;5;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Perception; Human-robot interaction; Human-robot cooperation; Mistreatment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;perceivedmistreatmentandemotionalcapabilityfollowingaggressivetreatmentofrobotsandcomputers;perceived mistreatment and emotional capability following aggressive treatment of robots and computers robots and computers are increasingly being used in scenarios where they interact socially with people how people react to these agents is telling about the perceived empathy of such agents mistreatment of robots or computers by coworkers might provoke such telling reactions this study examines perceived mistreatment directed towards a robot in comparison to a computer this will provide some understanding of how people feel about robots in collaborative social settings we conducted a two by two betweensubjects study with 80 participants participants worked cooperatively with either a robot or a computer agent an experiment confederate would either act aggressively or neutrally towards the agent we hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer and so would observe more mistreatment with a robot the final results supported our hypotheses the participants observed greater mistreatment for the robot but not the computer also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable
K9QCI43Y;journalArticle;2019;"Johanson, Deborah L.; Ahn, Ho Seok; MacDonald, Bruce A.; Ahn, Byeong Kyu; Lim, JongYoon; Hwang, Euijun; Sutherland, Craig J.; Broadbent, Elizabeth";The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction: Randomized Controlled Trial;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/13667;NA;Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings.;2019-10-04;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;10;21;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"engagement; social interaction; robotics; health care robotics; social intelligence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theeffectofrobotattentionalbehaviorsonuserperceptionsandbehaviorsinasimulatedhealthcareinteractionrandomizedcontrolledtrial;the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction randomized controlled trial background for robots to be effectively used in health applications they need to display appropriate social behaviors a fundamental requirement in all social interactions is the ability to engage maintain and demonstrate attention attentional behaviors include leaning forward selfdisclosure and changes in voice pitch objective this study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction methods a parallel randomized controlled trial with a 111 allocation ration was conducted we randomized participants to 1 of 4 experimental conditions before engaging in a scripted facetoface interaction with a fully automated medical receptionist robot experimental conditions included a selfdisclosure condition voice pitch change condition forward lean condition and neutral condition participants completed paperbased postinteraction measures relating to engagement perceived robot attention and perceived robot empathy we video recorded interactions and coded for participant attentional behaviors results a total of 181 participants were recruited from the university of auckland participants who interacted with the robot in the forward lean and selfdisclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions p03 participants in the forward lean selfdisclosure and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition p001 participants in the forward lean and selfdisclosure conditions spent significantly more time looking at the robot than participants in the neutral condition p001 significantly more participants in the selfdisclosure condition laughed during the interaction p01 whereas significantly more participants in the forward lean condition leant toward the robot during the interaction p001 conclusions the use of selfdisclosure and forward lean by a health care robot can increase human engagement and attentional behaviors voice pitch changes did not increase attention or engagement the small effects with regard to participant perceptions are potentially because of the limitations in selfreport measures or a lack of comparison for most participants who had never interacted with a robot before further research could explore the use of selfdisclosure and forward lean using a withinsubjects design and in real health care settings
F74D6R55;journalArticle;2019;"Tatsukawa, Kyohei; Takahashi, Hideyuki; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Android Pretending to Have Similar Traits of Imagination as Humans Evokes Stronger Perceived Capacity to Feel;FRONTIERS IN ROBOTICS AND AI;NA;2296-9144;10.3389/frobt.2019.00088;NA;"The perception of robots as mindful enriches how humans relate to them. Given that congruence in perceived representations of the world enable humans to experience commonality in mental states (a shared reality), we propose that congruence between humans, and robots will encourage humans to attribute humanlike mental capacities to robots. To investigate this, we assessed the mental perceptions of a robot in a visual imagination task using Gray et al. mind perception scale, which evaluates experience (capacity to feel), and agency (capacity to plan and do). For each ambiguous picture in the designed task, humans, and a robot imagined an animal. The task was performed under six conditions (2 x 3: Lead/Follow for Low/Medium/High). In the Lead condition, the robot records its perceived animal first; in the Follow condition, the robot records after the human participant. The experiment had three different degrees of congruence: Low (0%), Medium (60%), and High (100%). The results showed that perceived experiences were higher in the Lead condition, suggesting that the robot is perceived to be empathetic. It is probable that the Follow condition was perceived as mimicry rather than shared reality. Therefore, the order of response may have played an important role in commonality in mental states. No differences were observed in the perceived agency across all conditions. These results suggest that the order of response affects how humans perceive the minds of robots. Additionally, we assessed a post-task questionnaire to evaluate the interpersonal closeness that the humans felt toward the android. The main effect was observed in the degrees of congruence. This result is in line with those of previous studies that report relationships across sharing of similarities and friendliness.";2019-09-18;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"mind perception; robot; interpersonal closeness; shared reality; visual imagination";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;androidpretendingtohavesimilartraitsofimaginationashumansevokesstrongerperceivedcapacitytofeel;android pretending to have similar traits of imagination as humans evokes stronger perceived capacity to feel the perception of robots as mindful enriches how humans relate to them given that congruence in perceived representations of the world enable humans to experience commonality in mental states a shared reality we propose that congruence between humans and robots will encourage humans to attribute humanlike mental capacities to robots to investigate this we assessed the mental perceptions of a robot in a visual imagination task using gray et al mind perception scale which evaluates experience capacity to feel and agency capacity to plan and do for each ambiguous picture in the designed task humans and a robot imagined an animal the task was performed under six conditions 2 x 3 leadfollow for lowmediumhigh in the lead condition the robot records its perceived animal first in the follow condition the robot records after the human participant the experiment had three different degrees of congruence low 0 medium 60 and high 100 the results showed that perceived experiences were higher in the lead condition suggesting that the robot is perceived to be empathetic it is probable that the follow condition was perceived as mimicry rather than shared reality therefore the order of response may have played an important role in commonality in mental states no differences were observed in the perceived agency across all conditions these results suggest that the order of response affects how humans perceive the minds of robots additionally we assessed a posttask questionnaire to evaluate the interpersonal closeness that the humans felt toward the android the main effect was observed in the degrees of congruence this result is in line with those of previous studies that report relationships across sharing of similarities and friendliness
VU4ADQQD;journalArticle;2019;"Nishio, Toshiaki; Yoshikawa, Yuichiro; Ogawa, Kohei; Ishiguro, Hiroshi";Development of an Effective Information Media Using Two Android Robots;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app9173442;NA;Conversational robots have been used to convey information to people in the real world. Android robots, which have a human-like appearance, are expected to be able to convey not only objective information but also subjective information, such as a robot's feelings. Meanwhile, as an approach to realize attractive conversation, multi-party conversation by multiple robots was the focus of this study. By collaborating among several robots, the robots provide information while maintaining the naturalness of conversation. However, the effectiveness of interaction with people has not been surveyed using this method. In this paper, to develop more efficient media to convey information, we propose a scenario-based, semi-passive conversation system using two androids. To verify its effectiveness, we conducted a subjective experiment comparing it to a system that does not include any interaction with people, and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids. The experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids.;2019-09-01;2021-05-19T13:30:20Z;2021-05-19T13:30:20Z;NA;NA;NA;17;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"human robot interaction; android robot; multiple conversation robots; passive social conversation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;developmentofaneffectiveinformationmediausingtwoandroidrobots;development of an effective information media using two android robots conversational robots have been used to convey information to people in the real world android robots which have a humanlike appearance are expected to be able to convey not only objective information but also subjective information such as a robots feelings meanwhile as an approach to realize attractive conversation multiparty conversation by multiple robots was the focus of this study by collaborating among several robots the robots provide information while maintaining the naturalness of conversation however the effectiveness of interaction with people has not been surveyed using this method in this paper to develop more efficient media to convey information we propose a scenariobased semipassive conversation system using two androids to verify its effectiveness we conducted a subjective experiment comparing it to a system that does not include any interaction with people and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids the experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids
4GFTW38Q;journalArticle;2019;"Tsiourti, Christiana; Weiss, Astrid; Wac, Katarzyna; Vincze, Markus";Multimodal Integration of Emotional Signals from Voice, Body, and Context: Effects of (In)Congruence on Emotion Recognition and Attitudes Towards Robots;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-019-00524-z;NA;Humanoid social robots have an increasingly prominent place in today's world. Their acceptance in social and emotional human-robot interaction (HRI) scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users. In this article, we incorporate recent findings from psychology, neuroscience, human-computer interaction, and HRI, to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots, with a particular emphasis on the effects of incongruence. In a social HRI laboratory experiment, we investigated contextual incongruence (i.e., the conflict situation where a robot's reaction is incongrous with the socio-emotional context of the interaction) and cross-modal incongruence (i.e., the conflict situation where an observer receives incongruous emotional information across the auditory (vocal prosody) and visual (whole-body expressions) modalities). Results showed that both contextual incongruence and cross-modal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot. This, in turn, gives the impression that the robot is unintelligent or unable to express “empathic” behaviour and leads to profoundly harmful effects on likability and believability. Our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way. We offer recommendations regarding design choices and discuss future research areas in the direction of multimodal HRI.;2019-08;2021-05-19T13:30:21Z;2021-05-19T13:30:21Z;NA;555-573;NA;4;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Robot emotions; Body language; Believability; Multi-modal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;multimodalintegrationofemotionalsignalsfromvoicebodyandcontexteffectsofincongruenceonemotionrecognitionandattitudestowardsrobots;multimodal integration of emotional signals from voice body and context effects of incongruence on emotion recognition and attitudes towards robots humanoid social robots have an increasingly prominent place in todays world their acceptance in social and emotional humanrobot interaction hri scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users in this article we incorporate recent findings from psychology neuroscience humancomputer interaction and hri to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots with a particular emphasis on the effects of incongruence in a social hri laboratory experiment we investigated contextual incongruence ie the conflict situation where a robots reaction is incongrous with the socioemotional context of the interaction and crossmodal incongruence ie the conflict situation where an observer receives incongruous emotional information across the auditory vocal prosody and visual wholebody expressions modalities results showed that both contextual incongruence and crossmodal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot this in turn gives the impression that the robot is unintelligent or unable to express empathic behaviour and leads to profoundly harmful effects on likability and believability our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way we offer recommendations regarding design choices and discuss future research areas in the direction of multimodal hri
HFHGYGD7;journalArticle;2019;"Gong, Chao; Lin, Fuhong; Zhou, Xianwei; Lu, Xing";Amygdala-Inspired Affective Computing: to Realize Personalized Intracranial Emotions with Accurately Observed External Emotions;CHINA COMMUNICATIONS;NA;1673-5447;NA;NA;Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected.;2019-08;2021-05-19T13:30:22Z;2021-05-19T13:30:22Z;NA;115-129;NA;8;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article;NA;NA;NA;NA;"emotion recognition; affective computing; external emotions; intracranial emotions; personalized machines";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;amygdalainspiredaffectivecomputingtorealizepersonalizedintracranialemotionswithaccuratelyobservedexternalemotions;amygdalainspired affective computing to realize personalized intracranial emotions with accurately observed external emotions artificial intelligence technology has revolutionized every industry and trade in recent years however its own development is encountering bottlenecks that it is unable to implement empathy with human emotions so affective computing is getting more attention from researchers in this paper we propose an amygdalainspired affective computing framework to realize the recognition of all kinds of human personalized emotions similar to the amygdala the instantaneous emergency emotion is first computed more quickly in a lowredundancy convolutional neural network compressed by pruning and weight sharing with hashing trick then the realtime process emotion is identified more accurately by the memory level neural networks which is good at handling timerelated signals finally the intracranial emotion is recognized in personalized hidden markov models we demonstrate on facial expression of emotion dataset and the recognition accuracy of external emotions including the emergency emotion and the process emotion reached 8572 and the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected
ZKT6LFHT;journalArticle;2019;"Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farne, A.; Dominey, P. F.; Pavani, F.";Embodiment into a robot increases its acceptability;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/s41598-019-46528-7;NA;Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects' head movements. As a result, participants saw themselves as a robot. When participant' and robot's head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots' humanoid's appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.;2019-07-12;2021-05-19T13:30:22Z;2021-05-19T13:30:22Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;embodimentintoarobotincreasesitsacceptability;embodiment into a robot increases its acceptability recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes closeness empathy racial biases here we use a simple neuroscienceinspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot participants wore a head mounted display tracking their head movements and displaying the 3d visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects head movements as a result participants saw themselves as a robot when participant and robots head movements were correlated participants felt that they were incorporated into the robot with a sense of agency critically the robot they embodied was judged more likeable and socially closer remarkably we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity was independent of robots humanoids appearance these findings not only reveal the ease of bodyswapping via visualmotor synchrony into robots that do not share any clear human resemblance but they may also pave a new way to make our future robotic helpers socially acceptable
THM8SBPE;journalArticle;2019;"Pham, Hai Van; Asadi, Farzin; Abut, Nurettin; Kandilli, Ismet";Hybrid Spiral STC-Hedge Algebras Model in Knowledge Reasonings for Robot Coverage Path Planning and Its Applications;APPLIED SCIENCES-BASEL;NA;NA;10.3390/app9091909;NA;Robotics is a highly developed field in industry, and there is a large research effort in terms of humanoid robotics, including the development of multi-functional empathetic robots as human companions. An important function of a robot is to find an optimal coverage path planning, with obstacle avoidance in dynamic environments for cleaning and monitoring robotics. This paper proposes a novel approach to enable robotic path planning. The proposed approach combines robot reasoning with knowledge reasoning techniques, hedge algebra, and the Spiral Spanning Tree Coverage (STC) algorithm, for a cleaning and monitoring robot with optimal decisions. This approach is used to apply knowledge inference and hedge algebra with the Spiral STC algorithm to enable autonomous robot control in the optimal coverage path planning, with minimum obstacle avoidance. The results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot. Experimental results are compared with current methods under the same conditions. The proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates. Experiments are done with real robots for cleaning in dynamic environments.;2019-05-01;2021-05-19T13:30:25Z;2021-05-19T13:30:25Z;NA;NA;NA;9;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"hedge algebra; robot coverage path planning; robot knowledge reasonings; simulation of a robot; spiral spanning tree coverage";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;hybridspiralstchedgealgebrasmodelinknowledgereasoningsforrobotcoveragepathplanninganditsapplications;hybrid spiral stchedge algebras model in knowledge reasonings for robot coverage path planning and its applications robotics is a highly developed field in industry and there is a large research effort in terms of humanoid robotics including the development of multifunctional empathetic robots as human companions an important function of a robot is to find an optimal coverage path planning with obstacle avoidance in dynamic environments for cleaning and monitoring robotics this paper proposes a novel approach to enable robotic path planning the proposed approach combines robot reasoning with knowledge reasoning techniques hedge algebra and the spiral spanning tree coverage stc algorithm for a cleaning and monitoring robot with optimal decisions this approach is used to apply knowledge inference and hedge algebra with the spiral stc algorithm to enable autonomous robot control in the optimal coverage path planning with minimum obstacle avoidance the results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot experimental results are compared with current methods under the same conditions the proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates experiments are done with real robots for cleaning in dynamic environments
MNSWJU25;journalArticle;2019;"Cross, Emily S.; Riddoch, Katie A.; Pratts, Jaydan; Titone, Simon; Chaudhury, Bishakha; Hortensius, Ruud";A neurocognitive investigation of the impact of socializing with a robot on empathy for pain;PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES;NA;0962-8436;10.1098/rstb.2018.0034;NA;To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue `From social brains to social robots: applying neurocognitive insights to human-robot interaction'.;2019-04-29;2021-05-19T13:30:25Z;2021-05-19T13:30:25Z;NA;NA;NA;1771;374;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND Publisher: ROYAL SOC Type: Article;NA;NA;NA;NA;"fMRI; social cognition; empathy; human-robot interaction; social robotics; experience-dependent plasticity";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;aneurocognitiveinvestigationoftheimpactofsocializingwitharobotonempathyforpain;a neurocognitive investigation of the impact of socializing with a robot on empathy for pain to what extent can humans form social relationships with robots in the present study we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy a core component of social relationships towards robots twentysix individuals underwent identical fmri sessions before and after being issued a social robot to take home and interact with over the course of a week while undergoing fmri participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation repetition suppression of activity in the pain network a collection of brain regions associated with empathy and emotional responding was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure in contrast to our hypothesis functional regionofinterest analyses revealed no change in neural overlap for agents after the socializing intervention similarly no increase in activation when observing a robot experiencing pain emerged postsocializing wholebrain analysis showed that before the socializing intervention superior parietal and early visual regions are sensitive to novel agents while after socializing medial temporal regions show agent sensitivity a region of the inferior parietal lobule was sensitive to novel emotions but only during the presocializing scan session together these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot as measured by behavioural or brain responses we discuss the extent to which longterm socialization with robots might shape social cognitive processes and ultimately our relationships with these machines this article is part of the theme issue from social brains to social robots applying neurocognitive insights to humanrobot interaction
FY7J55HR;journalArticle;2019;"Haynes, Alice; Simons, Melanie F.; Helps, Tim; Nakamura, Yuichi; Rossiter, Jonathan";A Wearable Skin-Stretching Tactile Interface for Human-Robot and Human-Human Communication;IEEE ROBOTICS AND AUTOMATION LETTERS;NA;2377-3766;10.1109/LRA.2019.2896933;NA;Currently, the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user. While this can be very effective, vibration as a physical stimulation is limited in modality and is uncommon in the natural world. In many cases, for human-robot and human-human interaction, a more natural, affective tactile interaction is needed to provide comfortable and varied stimuli. In this letter, we present the super-cutaneous wearable electrical empathic stimulator (SCWEES), a tactile device that gently stretches and squeezes the surface of the skin. Our hypothesis is that this device can create a pleasant, unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts. We describe the design of the SCWEES, a lightweight 3D-printed semi-flexible structure that attaches to the skin at two points and actuates via two shape-memory alloy coil actuators. We evaluate the SCWEES through a range of human interaction experiments: stimulation strength and pleasantness, contraction and extension, and the conveyance of non-disruptive notifications. Quantitative and qualitative results show that the SCWEES generates a pleasant sensation, can convey useful information in human-machine interactions, and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task.;2019-04;2021-05-19T13:30:26Z;2021-05-19T13:30:26Z;NA;1641-1646;NA;2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article;NA;NA;NA;NA;"affective tactile stimulation; haptics and haptic interfaces; social human-robot interaction; soft robot applications; Wearable robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;awearableskinstretchingtactileinterfaceforhumanrobotandhumanhumancommunication;a wearable skinstretching tactile interface for humanrobot and humanhuman communication currently the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user while this can be very effective vibration as a physical stimulation is limited in modality and is uncommon in the natural world in many cases for humanrobot and humanhuman interaction a more natural affective tactile interaction is needed to provide comfortable and varied stimuli in this letter we present the supercutaneous wearable electrical empathic stimulator scwees a tactile device that gently stretches and squeezes the surface of the skin our hypothesis is that this device can create a pleasant unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts we describe the design of the scwees a lightweight 3dprinted semiflexible structure that attaches to the skin at two points and actuates via two shapememory alloy coil actuators we evaluate the scwees through a range of human interaction experiments stimulation strength and pleasantness contraction and extension and the conveyance of nondisruptive notifications quantitative and qualitative results show that the scwees generates a pleasant sensation can convey useful information in humanmachine interactions and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task
Q9G6VRUI;journalArticle;2019;"Alves-Oliveira, Patricia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana";Empathic Robot for Group Learning: A Field Study;ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION;NA;NA;10.1145/3300188;NA;"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.";2019-03;2021-05-19T13:30:26Z;2021-05-19T13:30:26Z;NA;NA;NA;1;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article;NA;NA;NA;NA;"education; empathy; human-robot interaction; collaborative learning; group learning; learning gains; Social robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicrobotforgrouplearningafieldstudy;empathic robot for group learning a field study this work explores a group learning scenario with an autonomous empathic robot we address two research questions 1 can an autonomous robot designed with empathic competencies foster collaborative learning in a group context 2 can an empathic robot sustain positive educational outcomes in longterm collaborative learning interactions with groups of students to answer these questions we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development two studies were conducted the first study compares learning outcomes in children across three conditions learning with an empathic robot learning with a robot without empathic capabilities and learning without a robot the results show that the autonomous robot with empathy fosters meaningful discussions about sustainability which is a learning outcome in sustainability education the second study features groups of students who interact with the robot in a school classroom for 2 months the longterm educational interaction did not seem to provide significant learning gains although there was a change in gameactions to achieve more sustainability during gameplay this result reflects the need to perform more longterm research in the field of educational robots for group learning
NSEBSJ26;conferencePaper;2019;"Qureshi, Shahnawaz; Hagelback, Johan; Iqbal, Syed Muhammad Zeeshan; Javaid, Hamad; Lindley, Craig A.";Evaluation of Classifiers for Emotion Detection While Performing Physical and Visual Tasks: Tower of Hanoi and IAPS;IN℡LIGENT SYSTEMS AND APPLICATIONS, VOL 1;978-3-030-01054-6 978-3-030-01053-9;NA;10.1007/978-3-030-01054-6_25;NA;With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT.;2019;2021-05-19T13:30:27Z;2021-05-19T13:30:27Z;NA;347-363;NA;NA;868;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>Intelligent Systems Conference (IntelliSys), London, ENGLAND, SEP 06-07, 2018</p>;NA;NA;NA;"Electroencephalography (EEG); Artificial Neural Networks (ANN); Bayesian Network (BNT); Cognitive psychology; Human Computer Interaction (HCI); K-Nearest Neighbor (KNN); Regression Tree (RT); Support Vector Machine (SVM); Tower of Hanoi (ToH)";Arai, K and Kapoor, S and Bhatia, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;evaluationofclassifiersforemotiondetectionwhileperformingphysicalandvisualtaskstowerofhanoiandiaps;evaluation of classifiers for emotion detection while performing physical and visual tasks tower of hanoi and iaps with the advancement in robot technology smart humanrobot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities if a robot can identify emotions and intentions of a human interacting with it interactions with humans can potentially become more natural and effective however mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots electroencephalography eeg can be used for recording signals revealing emotions and motivations from a human brain this study aimed to evaluate different machine learning techniques to classify eeg data associated with specific affectiveemotional states for experimental purposes we used visual iaps and physical tower of hanoi tasks to record human emotional states in the form of eeg data the obtained eeg data processed formatted and evaluated using various machine learning techniques to find out which method can most accurately classify eeg data according to associated affectiveemotional states the experiment confirms the choice of a method for improving the accuracy of results according to the results support vector machine was the first and regression tree was the second best method for classifying eeg data associated with specific affectiveemotional states with accuracies up to 7000 and 6000 respectively in both tasks svm was better in performance than rt
5TFI9Z5Y;conferencePaper;2019;"Esfandbod, Alireza; Rokhi, Zeynab; Taheri, Alireza; Alemi, Minoo; Meghdari, Ali";Human-Robot Interaction based on Facial Expression Imitation;2019 7TH INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM 2019);978-1-72816-604-9;NA;NA;NA;Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database, which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants' viewpoints on the imitation capability of the robot of 4.1 out of 5.;2019;2021-05-19T13:30:27Z;2021-05-19T13:30:27Z;NA;69-73;NA;NA;NA;NA;NA;NA;RSI International Conference on Robotics and Mechatronics ICRoM;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Iran ISSN: 2377-679X Type: Proceedings Paper";<p>7th International Conference on Robotics and Mechatronics (ICRoM), Sharif Univ Technol, Tehran, IRAN, NOV 20-21, 2019</p>;NA;NA;NA;"Human Robot Interaction; Social Robots; Facial Expression Recognition; Convolutional Neural Network; Imitation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;humanrobotinteractionbasedonfacialexpressionimitation;humanrobot interaction based on facial expression imitation mimicry during facetoface interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner in this paper we propose a facial expression imitation system that utilizes a convolutional neural network cnn the model was trained by means of the ck database which is a popular benchmark in facial expression recognition then we implemented the proposed system on a robotic platform and investigated the methods performance via 20 recruited participants we observed a high mean score of the participants viewpoints on the imitation capability of the robot of 41 out of 5
732L9J28;conferencePaper;2019;"Bechade, Lucile; Dubuisson-Duplessis, Guillaume; Pittaro, Gabrielle; Garcia, Melanie; Devillers, Laurence";Towards Metrics of Evaluation of Pepper Robot as a Social Companion for the Elderly;ADVANCED SOCIAL INTERACTION WITH AGENTS;978-3-319-92108-2 978-3-319-92107-5;NA;10.1007/978-3-319-92108-2_11;NA;For the design of socially acceptable robots, field studies in Human-Robot Interaction are necessary. Constructing dialogue benchmarks can have a meaning only if researchers take into account the evaluation of robot, human, and their interaction. This paper describes a study aiming at finding an objective evaluation procedure of the dialogue with a social robot. The goal is to build an empathic robot (JOKER project) and it focuses on elderly people, the end-users expected by ROMEO2 project. The authors carried out three experimental sessions. The first time, the robot was NAO, and it was with a Wizard of Oz (emotions were entered manually by experimenters as inputs to the program). The other times, the robot was Pepper, and it was totally autonomous (automatic detection of emotions and decision according to). Each interaction involved various scenarios dealing with emotion recognition, humor, negotiation and cultural quiz. The paper details the system functioning, the scenarios and the evaluation of the experiments.;2019;2021-05-19T13:30:29Z;2021-05-19T13:30:29Z;NA;89-101;NA;NA;510;NA;NA;NA;Lecture Notes in Electrical Engineering;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1876-1100 Type: Proceedings Paper;<p>8th International Workshop on Spoken Dialogue Systems (IWSDS), Farmington, PA, JUN 06-09, 2017</p>;NA;NA;NA;"Human-Robot Interaction; Evaluation; Data collection; Metrics; Elderly end-users";Eskenazi, M and Devillers, L and Mariani, J;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsmetricsofevaluationofpepperrobotasasocialcompanionfortheelderly;towards metrics of evaluation of pepper robot as a social companion for the elderly for the design of socially acceptable robots field studies in humanrobot interaction are necessary constructing dialogue benchmarks can have a meaning only if researchers take into account the evaluation of robot human and their interaction this paper describes a study aiming at finding an objective evaluation procedure of the dialogue with a social robot the goal is to build an empathic robot joker project and it focuses on elderly people the endusers expected by romeo2 project the authors carried out three experimental sessions the first time the robot was nao and it was with a wizard of oz emotions were entered manually by experimenters as inputs to the program the other times the robot was pepper and it was totally autonomous automatic detection of emotions and decision according to each interaction involved various scenarios dealing with emotion recognition humor negotiation and cultural quiz the paper details the system functioning the scenarios and the evaluation of the experiments
BIJL9QCM;conferencePaper;2019;"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana";EmotoTent: Reducing School Violence through Embodied Empathy Games;PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019);978-1-4503-6690-8;NA;10.1145/3311927.3326596;NA;"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (Al), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic Al agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.";2019;2021-05-19T13:30:29Z;2021-05-19T13:30:29Z;NA;755-760;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Boise State Univ; Stem Act Ctr; St Lukes; Osmo; Langan Barber Fdn; Discovery Ctr Idaho; StemFinity; NSF; Boise Type: Proceedings Paper";<p>18th Annual ACM Interaction Design and Children (IDC), Boise, ID, JUN 12-15, 2019</p>;NA;NA;NA;"biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emototentreducingschoolviolencethroughembodiedempathygames;emototent reducing school violence through embodied empathy games emototent is an interactive socioemotional learning system developed in response to escalating levels of violence inequality and marginalization in schools seen in the early 21st century the system is inspired by advances in biosensing wearables tattoo displays brain sensors robotic agents artificial intelligence al gestural interaction and 3d holographic displays by 2030 technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning emotionbased humancomputer interaction affective biosensing empathetic al agents and 3d interactive holographic environments we envision emototent as a modular emotion sensing holodeck in the emototent program children learn and practice emotion regulation and empathy with peers pets and a robotic dog agent in ways that are experiential embodied and playful we propose emototent as a core element of a k6 socioemotional learning curriculum designed to improve school culture through the enhancement of childrens ability to regulate emotions and interact with human and nonhuman species with empathy and compassion enhancing these qualities has been shown to lead to reductions in violence and bullying racism gender inequality and other forms of marginalization we predict that the emototent socioemotional learning program will improve school cultures and create a foundation for childrens lifelong wellbeing
KMGRY635;conferencePaper;2019;"Sripian, Peeraya; Kurono, Yuya; Yoshida, Reiji; Sugaya, Midori";Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals;2019 28TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-72812-622-7;NA;NA;NA;Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.;2019;2021-05-19T13:30:31Z;2021-05-19T13:30:31Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 1944-9445 Type: Proceedings Paper;<p>28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), New Delhi, INDIA, OCT 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;studyofempathyonrobotexpressionbasedonemotionestimatedfromfacialexpressionandbiologicalsignals;study of empathy on robot expression based on emotion estimated from facial expression and biological signals empathy the ability to share the others feeling is one of the effective elements in promoting mutual reliability and construction of a good relationship in order to create empathy between humanrobot a robot must be able to estimate the emotion of human and reflect the same emotion on its expression in general emotion can be estimated based on observable expressions such as facial expression or unobservable expressions such as biological signals although there are many methods for measuring emotion from both facial expression and biological signals few studies have been done on the comparison of estimated emotion in this paper we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot using our proposed emotion estimation system we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion
UIV4LEMU;conferencePaper;2019;"Carranza, Karmelo Antonio Lazaro R.; Manalili, Joshua; Bugtai, Nilo T.; Baldovino, Renann G.";Expression Tracking with OpenCV Deep Learning for a Development of Emotionally Aware Chatbots;2019 7TH INTERNATIONAL CONFERENCE ON ROBOT IN℡LIGENCE TECHNOLOGY AND APPLICATIONS (RITA);978-1-72813-118-4;NA;NA;NA;Affective computing explores the development of systems and devices that can perceive, translate, process, and reproduce human emotion. It is an interdisciplinary field which includes computer science, psychology and cognitive science. An inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots. This paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a post-therapy session survey chatbot which responds depending on two inputs, interactant's response and facial expression. The developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot. Facial expression tracking for happy, neutral, and hurt had 66.7%, 16.7%, and 56.7% tracking accuracy, respectively. Moreover, the developed program was tested to track expressions simultaneously per second. It can track 17 expressions with stationary subject and 14 expressions with non-stationary subject in a span of 30 seconds.;2019;2021-05-19T13:30:32Z;2021-05-19T13:30:32Z;NA;160-163;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computat Intelligence Soc; MIR MSREP; Smilegate; WCG; Inst Control Robot & Syst; Daejeon Int Marketing Enterprise; Korea Tourism Org Type: Proceedings Paper";<p>7th International Conference on Robot Intelligence Technology and Applications (RiTA), KAIST, Daejeon, SOUTH KOREA, NOV 01-03, 2019</p>;NA;NA;NA;"deep learning; affective computing; emotionally aware technology; facial expression detection; scripted chatbot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;expressiontrackingwithopencvdeeplearningforadevelopmentofemotionallyawarechatbots;expression tracking with opencv deep learning for a development of emotionally aware chatbots affective computing explores the development of systems and devices that can perceive translate process and reproduce human emotion it is an interdisciplinary field which includes computer science psychology and cognitive science an inspiration for the research is the ability to simulate empathy when communicating with computers or in the future robots this paper explored the potential of facial expression tracking with deep learning to make chatbots more emotionally aware through developing a posttherapy session survey chatbot which responds depending on two inputs interactants response and facial expression the developed chatbot summarizes emotional state of the user during the survey through percentages of the tracked facial expressions throughout the conversation with the chatbot facial expression tracking for happy neutral and hurt had 667 167 and 567 tracking accuracy respectively moreover the developed program was tested to track expressions simultaneously per second it can track 17 expressions with stationary subject and 14 expressions with nonstationary subject in a span of 30 seconds
R7BIDUWZ;conferencePaper;2019;"Barbieri, Francesco; Guizzo, Eric; Lucchesi, Federico; Maffei, Giovanni; del Prado Martin, Fermin Moscoso; Weyde, Tillman";Towards a Multimodal Time-Based Empathy Prediction System;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community(1);2019;2021-05-19T13:30:34Z;2021-05-19T13:30:34Z;NA;716-720;NA;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsamultimodaltimebasedempathypredictionsystem;towards a multimodal timebased empathy prediction system we describe our system for empathic emotion recognition it is based on deep learning on multiple modalities in a late fusion architecture we describe the modules of our system and discuss the evaluation results our code is also available for the research community1
YD94XTA9;conferencePaper;2019;"Mallol-Ragolta, Adria; Schmitt, Maximilian; Baird, Alice; Cummins, Nicholas; Schuller, Bjoern";Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition;2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019);978-1-72810-089-0;NA;NA;NA;The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual ( OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient ( CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.;2019;2021-05-19T13:30:35Z;2021-05-19T13:30:35Z;NA;721-725;NA;NA;NA;NA;NA;NA;IEEE International Conference on Automatic Face and Gesture Recognition and Workshops;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper";<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;performanceanalysisofunimodalandmultimodalmodelsinvalencebasedempathyrecognition;performance analysis of unimodal and multimodal models in valencebased empathy recognition the human ability to empathise is a core aspect of successful interpersonal relationships in this regard humanrobot interaction can be improved through the automatic perception of empathy among other human attributes allowing robots to affectively adapt their actions to interactants feelings in any given situation this paper presents our contribution to the generalised track of the oneminute gradual  omg empathy prediction challenge by describing our approach to predict a listeners valence during semiscripted actorlistener interactions we extract visual and acoustic features from the interactions and feed them into a bidirectional long shortterm memory network to capture the timedependencies of the valencebased empathy during the interactions generalised and personalised unimodal and multimodal valencebased empathy models are then trained to assess the impact of each modality on the system performance furthermore we analyse if intrasubject dependencies on empathy perception affect the system performance we assess the models by computing the concordance correlation coefficient  ccc between the predicted and selfannotated valence scores the results support the suitability of employing multimodal data to recognise participants valencebased empathy during the interactions and highlight the subjectdependency of empathy in particular we obtained our best result with a personalised multimodal model which achieved a ccc of 011 on the test set
WJKWQ3AA;conferencePaper;2019;"Peterson, Jordan; Cohen, Chase; Harrison, Paige; Novak, Jonathan; Tossell, Chad; Phillips, Elizabeth";Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming;2019 SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS);978-1-72810-998-5;NA;NA;NA;The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.;2019;2021-05-19T13:30:36Z;2021-05-19T13:30:36Z;NA;170-175;NA;NA;NA;NA;NA;NA;IEEE Systems and Information Engineering Design Symposium;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2639-7439 Type: Proceedings Paper;<p>Systems and Information Engineering Design Symposium (SIEDS), Univ Virginia, Charlottesville, VA, APR 26, 2019</p>;NA;NA;NA;"Human-robot interaction; Human-machine teaming";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;idealwarriorandrobotrelationsstressandempathysroleinhumanrobotteaming;ideal warrior and robot relations stress and empathys role in humanrobot teaming the battlefield of the future will look very different than the battlefields of the past automated technologies are finding themselves more and more integrated into every aspect of the fight as technology continues to advance the united states military must consider what a humanmachine team will look like and how an optimal relationship between the two assets can be formed especially under the stressful conditions that often characterize military contexts for a humanmachine team in a military context to work at maximum efficiency an ideal level of empathy towards an automated teammate must be obtained the goal of this study is to determine the effect stress can have on an individuals empathetic reaction toward a pepper robot twentyeight participants interacted with a pepper robot either under stress or not empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with pepper even though doing so would harm the robot although not conclusive the results suggest an interaction between participant gender and stress on empathy toward the pepper robot women showed more empathy toward pepper under higher levels of stress than lower levels of stress however the opposite was true for men men showed less empathy toward pepper under higher levels of stress the results of this study could help to inform military training and robot design
G5KVAUD3;conferencePaper;2019;"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie";Development of a Cloud-based Computational Framework for an Empathetic Robot;PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019);978-1-4503-6287-0;NA;10.1145/3313991.3314018;NA;This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.;2019;2021-05-19T13:30:38Z;2021-05-19T13:30:38Z;NA;102-108;NA;NA;NA;NA;NA;NA;International Conference on Computer and Automation Engineering;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2154-4352 Type: Proceedings Paper;<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>;NA;NA;NA;"deep learning; robot; cloud control; emotion classification; intent perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;developmentofacloudbasedcomputationalframeworkforanempatheticrobot;development of a cloudbased computational framework for an empathetic robot this article presents the development and preliminary evaluation of an empathy controlled robot such a robot is one step forward towards industry 50 as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator an inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs the paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost power consumption and computational burden of the system we propose that tasks requiring realtime and safety critical control are processed using dedicated onboard computers whereas functionality dedicated to system optimization machine learning and customization are handled through use a cloudbased platform in this paper key components of the architecture are defined and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operators voice is presented
NXKR7845;journalArticle;2019;"Sejima, Yoshihiro; Egawa, Shoichi; Sato, Yoichiro; Watanabe, Tomio";A pupil response system using hemispherical displays for enhancing affective conveyance;JOURNAL OF ADVANCED MECHANICAL DESIGN SYSTEMS AND MANUFACTURING;NA;1881-3054;10.1299/jamdsm.2019jamdsm0032;NA;In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker's affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot's eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance.;2019;2021-05-19T13:30:40Z;2021-05-19T13:30:40Z;NA;NA;NA;2;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: SHINANOMACHI-RENGAKAN BLDG., SHINANOMACHI 35, SHINJUKU-KU, TOKYO, 160-0016, JAPAN Publisher: JAPAN SOC MECHANICAL ENGINEERS Type: Article;NA;NA;NA;NA;"Empathy; Human interface; Human-robot interaction design; Kansei and affective engineering; Media representation; Pupil response";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;apupilresponsesystemusinghemisphericaldisplaysforenhancingaffectiveconveyance;a pupil response system using hemispherical displays for enhancing affective conveyance in human interaction and communication not only verbal messages but also nonverbal behaviors such as facial expressions body movements gazes and pupil responses play an important role in expressions of talkers affect these expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy we focused on the pupil response which is closely related to human affect and developed an embodied communication system in which an interactive cg character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input in addition it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system in this paper in order to realize the smooth interaction between human and robot we developed a pupil response system using hemispherical displays for enhancing affective conveyance this system looks like robots eyeballs and expresses vivid pupil response by speech input we carried out a sensory evaluation experiment under the condition that the developed system speaks the results demonstrated that the system effectively enhances affective conveyance
GI7VYRXG;conferencePaper;2019;"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodriguez, Veronica";Good Robot Design or Machiavellian? An in-the-wild robot leveraging minimal knowledge of passersby's culture;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people ( changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?;2019;2021-05-19T13:30:42Z;2021-05-19T13:30:42Z;NA;382-391;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"culture; social robots; in the wild; persuasive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;goodrobotdesignormachiavelliananinthewildrobotleveragingminimalknowledgeofpassersbysculture;good robot design or machiavellian an inthewild robot leveraging minimal knowledge of passersbys culture social robots are being designed to use humanlike communication techniques including body language social signals and empathy to work effectively with people just as between people some robots learn about people and adapt to them in this paper we present one such robot design we developed sam a robot that learns minimal information about a persons background and adapts to this background our inthewild study found that people helped sam for significantly longer when it adapted to match their background while initially we saw this as a success in reconsidering our study we started seeing a different angle our robot effectively deceived people  changed its story and text based on some knowledge of their background to get more work from them there was little direct benefit to the person from this adaptation yet the robot stood to gain free labor we would like to pose the question to the community is this simply good robot design or is our robot being manipulative where does the ethical line lay between a robot leveraging social techniques to improve interaction and the more negative framing of a robot or algorithm taking advantage of people how can we decide what is good here and what is less desirable
ECLNJPCS;conferencePaper;2019;"Roy, Sayanti; Kieson, Emily; Abramson, Charles; Crick, Christopher";Mutual Reinforcement Learning with Robot Trainers;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;The researchers in this study have developed a novel approach using mutual reinforcement learning (MRL) where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback. This shared model not only has a collective impact but improves human cognition and helps in building a successful human-robot relationship. In our current work, we compared our learned reinforcement model with a baseline non-reinforcement and random approach in a robotics domain to identify the significance and impact of MRL. MRL contributed to improved skill transfer, and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners.;2019;2021-05-19T13:30:42Z;2021-05-19T13:30:42Z;NA;572-573;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;mutualreinforcementlearningwithrobottrainers;mutual reinforcement learning with robot trainers the researchers in this study have developed a novel approach using mutual reinforcement learning mrl where both the robot and human act as empathetic individuals who function as reinforcement learning agents for each other to achieve a particular task over continuous communication and feedback this shared model not only has a collective impact but improves human cognition and helps in building a successful humanrobot relationship in our current work we compared our learned reinforcement model with a baseline nonreinforcement and random approach in a robotics domain to identify the significance and impact of mrl mrl contributed to improved skill transfer and the robot was able successfully to predict which reinforcement behaviors would be most valuable to its human partners
HAVMQZSX;conferencePaper;2019;"Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amelie; Lefort, Mathieu; Hassas, Salima";The RoPE Scale: a Measure of How Empathic a Robot is Perceived;HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-5386-8555-6;NA;NA;NA;To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.;2019;2021-05-19T13:30:43Z;2021-05-19T13:30:43Z;NA;656-657;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper";<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>;NA;NA;NA;"Psychometrics; Human-Robot Interaction; Perceived Empathy; Social Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theropescaleameasureofhowempathicarobotisperceived;the rope scale a measure of how empathic a robot is perceived to be accepted in our everyday life and to be valuable interaction partners robots should be able to display emotional and empathic behaviors that is why there has been a great focus on developing empathy in robots in recent years however there is no consensus on how to measure how much a robot is considered to be empathic in this context we decided to construct a questionnaire which specifically measures the perception of a robots empathy in humanrobot interaction hri therefore we conducted pretests to generate items these were validated by experts and will be further validated in an experimental setting
5DZHGQ9C;conferencePaper;2019;"Jarvela, Simo; Salminen, Mikko; Ruonala, Antti; Timonen, Janne; Mannermaa, Kristiina; Ravaja, Niklas; Jacucci, Giulio";DYNECOM: Augmenting Empathy in VR with Dyadic Synchrony Neurofeedback;PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES;978-0-9981331-2-6;NA;NA;NA;In a novel experimental setting, we augmented a variation of traditional compassion meditation with our custom built VR environment for multiple concurrent users. The system incorporates respiration and brainwave based biofeedback that enables responsiveness to the shared physiological states of the users. The presence of another user's avatar in the shared virtual space supported low level social interactions and provided active targets for evoked compassion. We enhanced interoception and the deep empathetic processes involved in compassion meditation with real time visualizations of breathing rates and the level of approach motivation assessed from EEG frontal asymmetry, and the dyadic synchrony of those signals between the two users. We found how the different biofeedback types increased both the amount of physiological synchrony between the users and their self-reported empathy, illustrating how dyadic synchrony biofeedback can expand the possibilities of biofeedback in affective computing and VR solutions for health and wellness.;2019;2021-05-19T13:30:45Z;2021-05-19T13:30:45Z;NA;4212-4220;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;HICSS;Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>;NA;NA;NA;NA;Bui, TX;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;dynecomaugmentingempathyinvrwithdyadicsynchronyneurofeedback;dynecom augmenting empathy in vr with dyadic synchrony neurofeedback in a novel experimental setting we augmented a variation of traditional compassion meditation with our custom built vr environment for multiple concurrent users the system incorporates respiration and brainwave based biofeedback that enables responsiveness to the shared physiological states of the users the presence of another users avatar in the shared virtual space supported low level social interactions and provided active targets for evoked compassion we enhanced interoception and the deep empathetic processes involved in compassion meditation with real time visualizations of breathing rates and the level of approach motivation assessed from eeg frontal asymmetry and the dyadic synchrony of those signals between the two users we found how the different biofeedback types increased both the amount of physiological synchrony between the users and their selfreported empathy illustrating how dyadic synchrony biofeedback can expand the possibilities of biofeedback in affective computing and vr solutions for health and wellness
Z7XQI2UC;conferencePaper;2019;"Homburg, Nadine; Merkle, Moritz";A Cross-Country Comparison of Attitudes toward Humanoid Robots in Germany, the US, and India;PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES;978-0-9981331-2-6;NA;NA;NA;So far, researchers know very little about what people actually expect from humanoid robots during a human-robot interaction. Therefore, this study surveyed 610 non-experts from Germany (133), the US (174), and India (303) and asked them to rate the following attributes regarding humanoid robots: empathy, expertise, reliability, and trust. This paper develops hypotheses, connecting robot attributes to the four cultural dimensions suggested by Hofstede individualism, masculinity versus femininity, power distance, and uncertainty avoidance. The results show, that India rates all the attributes the highest, and that Germany and the US rate all aspects rather similarly with the largest difference regarding reliability.;2019;2021-05-19T13:30:46Z;2021-05-19T13:30:46Z;NA;4773-4782;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;HICSS;Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>;NA;NA;NA;NA;Bui, TX;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;acrosscountrycomparisonofattitudestowardhumanoidrobotsingermanytheusandindia;a crosscountry comparison of attitudes toward humanoid robots in germany the us and india so far researchers know very little about what people actually expect from humanoid robots during a humanrobot interaction therefore this study surveyed 610 nonexperts from germany 133 the us 174 and india 303 and asked them to rate the following attributes regarding humanoid robots empathy expertise reliability and trust this paper develops hypotheses connecting robot attributes to the four cultural dimensions suggested by hofstede individualism masculinity versus femininity power distance and uncertainty avoidance the results show that india rates all the attributes the highest and that germany and the us rate all aspects rather similarly with the largest difference regarding reliability
SETK48M2;journalArticle;2018;"Swiderska, Aleksandra; Kuester, Dennis";Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots;PERCEPTION;NA;0301-0066;10.1177/0301006618809919;NA;Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.;2018-12;2021-05-19T13:30:47Z;2021-05-19T13:30:47Z;NA;1139-1152;NA;12;47;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article;NA;NA;NA;NA;"pain; robots; empathy; mind perception; anthropomorphism; harm";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;avatarsinpainvisibleharmenhancesmindperceptioninhumansandrobots;avatars in pain visible harm enhances mind perception in humans and robots previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind their attributions of mind to that entity increased currently we investigated if the presence of a facial wound enhanced the perception of mental capacities experience and agency in response to images of robotic and humanlike avatars compared with unharmed avatars the results revealed that harmed versions of both robotic and humanlike avatars were imbued with mind to a higher degree irrespective of the baseline level of mind attributed to their unharmed counterparts perceptions of capacity for pain mediated attributions of experience while both pain and empathy mediated attributions of abilities linked to agency the findings suggest that harm even when it appears to have been inflicted unintentionally may augment mind perception for robotic as well as for nearly human entities at least as long as it is perceived to elicit pain
TYI7IRQG;journalArticle;2018;"Giannopulu, Irini; Terada, Kazunori; Watanabe, Tomio";Emotional Empathy as a Mechanism of Synchronisation in Child-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2018.01852;NA;Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation.;2018-10-16;2021-05-19T13:30:48Z;2021-05-19T13:30:48Z;NA;NA;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"child; emotional empathy; heart rate; interactor robot; synchronisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionalempathyasamechanismofsynchronisationinchildrobotinteraction;emotional empathy as a mechanism of synchronisation in childrobot interaction simulating emotional experience emotional empathy is the fundamental ingredient of interpersonal communication in the speakerlistener scenario the speaker is always a child the listener is a human or a toy robot two groups of neurotypical children aged 6 years on average composed the population one japanese n  20 and one french n  20 revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot the results might signify that emotional empathy requires the implication of an automatic identification in this sense emotional empathy might be considered a broad idiosyncrasy a kind of synchronisation offering the mind a peculiar form of communication our findings seem to be consistent with the assumption that childrens brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation
5KQ3DUK9;journalArticle;2018;"Yalcin, Ozge Nilay; DiPaola, Steve";A computational model of empathy for interactive agents;BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES;NA;2212-683X;10.1016/j.bica.2018.07.010;NA;Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018-10;2021-05-19T13:30:48Z;2021-05-19T13:30:48Z;NA;20-25;NA;NA;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Conversational agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;acomputationalmodelofempathyforinteractiveagents;a computational model of empathy for interactive agents empathy has been defined in the scientific literature as the capacity to relate anothers emotional state and assigned to a broad spectrum of cognitive and behavioral abilities advances in neuroscience psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy recently cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents which can provide means to test these models and hypotheses a computational model of empathy not only would help to advance the technological artifacts to be more socially compatible but also understand the empathy mechanisms test theories and address the ethics and morality problems the artificial intelligence ai community is facing today in this paper we will review the empathy research from various fields gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents
YAER6HZX;journalArticle;2018;"Ghosh, Dipanjan; Olewnik, Andrew; Lewis, Kemper";Application of autoencoders in cyber-empathic design;DESIGN SCIENCE;NA;2053-4701;10.1017/dsj.2018.11;NA;A critical task in product design is mapping information from the consumer space to the design space. This process is largely dependent on the designer to identify and relate psychological and consumer level factors to engineered product attributes. In this way, current methodologies lack provision to test a designer's cognitive reasoning and may introduce bias through the mapping process. Prior work on Cyber-Empathic Design (CED) supports this mapping by relating user-product interaction data from embedded sensors to psychological constructs. To understand consumer perceptions, a network of psychological constructs is developed using Structural Equation Modeling for parameter estimation and hypothesis testing, making the framework falsifiable in nature. The focus of this technical brief is toward automating CED through unsupervised deep learning to extract features from raw data. Additionally, Partial Least Square Structural Equation Modeling is used with extracted sensor features as inputs. To demonstrate the effectiveness of the approach a case study involving sensor-integrated shoes compares three models - a survey-only model (no sensor data), the existing CED approach with manually extracted sensor features, and the proposed deep learning based CED approach. The deep learning based approach results in improved model fit.;2018-07-30;2021-05-19T13:30:50Z;2021-05-19T13:30:50Z;NA;NA;NA;NA;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA Publisher: CAMBRIDGE UNIV PRESS Type: Article;NA;NA;NA;NA;"machine learning; sensors; empathic design; product design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;applicationofautoencodersincyberempathicdesign;application of autoencoders in cyberempathic design a critical task in product design is mapping information from the consumer space to the design space this process is largely dependent on the designer to identify and relate psychological and consumer level factors to engineered product attributes in this way current methodologies lack provision to test a designers cognitive reasoning and may introduce bias through the mapping process prior work on cyberempathic design ced supports this mapping by relating userproduct interaction data from embedded sensors to psychological constructs to understand consumer perceptions a network of psychological constructs is developed using structural equation modeling for parameter estimation and hypothesis testing making the framework falsifiable in nature the focus of this technical brief is toward automating ced through unsupervised deep learning to extract features from raw data additionally partial least square structural equation modeling is used with extracted sensor features as inputs to demonstrate the effectiveness of the approach a case study involving sensorintegrated shoes compares three models  a surveyonly model no sensor data the existing ced approach with manually extracted sensor features and the proposed deep learning based ced approach the deep learning based approach results in improved model fit
TAQNSX56;journalArticle;2018;"Martens, Amanda L.; Grover, Cathy A.; Saucier, Donald A.; Morrison, Breanna A.";An examination of gender differences versus similarities in a virtual world;COMPUTERS IN HUMAN BEHAVIOR;NA;0747-5632;10.1016/j.chb.2018.03.012;NA;"We derived competing hypotheses from the gender similarities perspective versus the gender differences perspective to examine participants' behavior in an online virtual world in which we manipulated participants' gender. To manipulate participants' gender in the virtual environment, we randomly assigned them to one of three avatars (female, male, or robot). Using a screen recording device, we measured the percentage of time participants spent interacting with empathizing (e.g., options for shopping, telephone) and systemizing (e.g., weapons, options for building) objects in a virtual reality house that we constructed to reflect evidence put forth by the differences perspective. Because we derived competing hypotheses we expected to find support for either the similarities perspective or the differences perspective; however, our results suggested support for both. Consistent with the differences perspective hypotheses, participants paid attention to objects in the environment that were consistent with the social representation of their own gender. However, our results were consistent with the similarities perspective hypotheses, such that the avatars' gender also played a role in the percentage of time participants spent interacting with empathizing and systemizing objects. Therefore, we conclude that observable differences between men and women are the consequence of both biological and social forces, and research should focus on the interaction between the two as etiologies and explanations for sex and gender differences and similarities. (C) 2018 Elsevier Ltd. All rights reserved.";2018-07;2021-05-19T13:30:51Z;2021-05-19T13:30:51Z;NA;404-409;NA;NA;84;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article;NA;NA;NA;NA;"Virtual reality; Gender differences; Gender similarities";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anexaminationofgenderdifferencesversussimilaritiesinavirtualworld;an examination of gender differences versus similarities in a virtual world we derived competing hypotheses from the gender similarities perspective versus the gender differences perspective to examine participants behavior in an online virtual world in which we manipulated participants gender to manipulate participants gender in the virtual environment we randomly assigned them to one of three avatars female male or robot using a screen recording device we measured the percentage of time participants spent interacting with empathizing eg options for shopping telephone and systemizing eg weapons options for building objects in a virtual reality house that we constructed to reflect evidence put forth by the differences perspective because we derived competing hypotheses we expected to find support for either the similarities perspective or the differences perspective however our results suggested support for both consistent with the differences perspective hypotheses participants paid attention to objects in the environment that were consistent with the social representation of their own gender however our results were consistent with the similarities perspective hypotheses such that the avatars gender also played a role in the percentage of time participants spent interacting with empathizing and systemizing objects therefore we conclude that observable differences between men and women are the consequence of both biological and social forces and research should focus on the interaction between the two as etiologies and explanations for sex and gender differences and similarities c 2018 elsevier ltd all rights reserved
LLJWU6DU;journalArticle;2018;"Costa, Sandra; Brunete, Alberto; Bae, Byung-Chull; Mavridis, Nikolaos";Emotional Storytelling Using Virtual and Robotic Agents;INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS;NA;0219-8436;10.1142/S0219843618500068;NA;In order to create effective storytelling agents three fundamental questions must be answered: first, is a physically embodied agent preferable to a virtual agent or a voice-only narration? Second, does a human voice have an advantage over a synthesised voice? Third, how should the emotional trajectory of the different characters in a story be related to a storyteller's facial expressions during storytelling time, and how does this correlate with the apparent emotions on the faces of the listeners? The results of two specially designed studies indicate that the physically embodied robot produces more attention to the listener as compared to a virtual embodiment, that a human voice is preferable over the current state of the art of text-to-speech, and that there is a complex yet interesting relation between the emotion lines of the story, the facial expressions of the narrating agent, and the emotions of the listener, and that the empathising of the listener is evident through its facial expressions. This work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximise their effectiveness.;2018-06;2021-05-19T13:30:52Z;2021-05-19T13:30:52Z;NA;NA;NA;3;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type: Article;NA;NA;NA;NA;"facial expression analysis; non-verbal communication; Storytelling; emotional affective response; eye blink analysis; posture analysis; robot and virtual agents";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionalstorytellingusingvirtualandroboticagents;emotional storytelling using virtual and robotic agents in order to create effective storytelling agents three fundamental questions must be answered first is a physically embodied agent preferable to a virtual agent or a voiceonly narration second does a human voice have an advantage over a synthesised voice third how should the emotional trajectory of the different characters in a story be related to a storytellers facial expressions during storytelling time and how does this correlate with the apparent emotions on the faces of the listeners the results of two specially designed studies indicate that the physically embodied robot produces more attention to the listener as compared to a virtual embodiment that a human voice is preferable over the current state of the art of texttospeech and that there is a complex yet interesting relation between the emotion lines of the story the facial expressions of the narrating agent and the emotions of the listener and that the empathising of the listener is evident through its facial expressions this work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximise their effectiveness
STDTV8ND;journalArticle;2018;"da Silva, Joana Galvao Gomes; Kavanagh, David J.; Belpaeme, Tony; Taylor, Lloyd; Beeson, Konna; Andrade, Jackie";Experiences of a Motivational Interview Delivered by a Robot: Qualitative Study;JOURNAL OF MEDICAL INTERNET RESEARCH;NA;1438-8871;10.2196/jmir.7737;NA;Background: Motivational interviewing is an effective intervention for supporting behavior change but traditionally depends on face-to-face dialogue with a human counselor. This study addressed a key challenge for the goal of developing social robotic motivational interviewers: creating an interview protocol, within the constraints of current artificial intelligence, which participants will find engaging and helpful. Objective: The aim of this study was to explore participants' qualitative experiences of a motivational interview delivered by a social robot, including their evaluation of usability of the robot during the interaction and its impact on their motivation. Methods: NAO robots are humanoid, child-sized social robots. We programmed a NAO robot with Choregraphe software to deliver a scripted motivational interview focused on increasing physical activity. The interview was designed to be comprehensible even without an empathetic response from the robot. Robot breathing and face-tracking functions were used to give an impression of attentiveness. A total of 20 participants took part in the robot-delivered motivational interview and evaluated it after 1 week by responding to a series of written open-ended questions. Each participant was left alone to speak aloud with the robot, advancing through a series of questions by tapping the robot's head sensor. Evaluations were content-analyzed utilizing Boyatzis' steps: (1) sampling and design, (2) developing themes and codes, and (3) validating and applying the codes. Results: Themes focused on interaction with the robot, motivation, change in physical activity, and overall evaluation of the intervention. Participants found the instructions clear and the navigation easy to use. Most enjoyed the interaction but also found it was restricted by the lack of individualized response from the robot. Many positively appraised the nonjudgmental aspect of the interview and how it gave space to articulate their motivation for change. Some participants felt that the intervention increased their physical activity levels. Conclusions: Social robots can achieve a fundamental objective of motivational interviewing, encouraging participants to articulate their goals and dilemmas aloud. Because they are perceived as nonjudgmental, robots may have advantages over more humanoid avatars for delivering virtual support for behavioral change.;2018-05;2021-05-19T13:30:53Z;2021-05-19T13:30:53Z;NA;NA;NA;5;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"qualitative research; robotics; motivational interviewing; motivation; counseling; computer-assisted therapy; exercise; person-centered therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;experiencesofamotivationalinterviewdeliveredbyarobotqualitativestudy;experiences of a motivational interview delivered by a robot qualitative study background motivational interviewing is an effective intervention for supporting behavior change but traditionally depends on facetoface dialogue with a human counselor this study addressed a key challenge for the goal of developing social robotic motivational interviewers creating an interview protocol within the constraints of current artificial intelligence which participants will find engaging and helpful objective the aim of this study was to explore participants qualitative experiences of a motivational interview delivered by a social robot including their evaluation of usability of the robot during the interaction and its impact on their motivation methods nao robots are humanoid childsized social robots we programmed a nao robot with choregraphe software to deliver a scripted motivational interview focused on increasing physical activity the interview was designed to be comprehensible even without an empathetic response from the robot robot breathing and facetracking functions were used to give an impression of attentiveness a total of 20 participants took part in the robotdelivered motivational interview and evaluated it after 1 week by responding to a series of written openended questions each participant was left alone to speak aloud with the robot advancing through a series of questions by tapping the robots head sensor evaluations were contentanalyzed utilizing boyatzis steps 1 sampling and design 2 developing themes and codes and 3 validating and applying the codes results themes focused on interaction with the robot motivation change in physical activity and overall evaluation of the intervention participants found the instructions clear and the navigation easy to use most enjoyed the interaction but also found it was restricted by the lack of individualized response from the robot many positively appraised the nonjudgmental aspect of the interview and how it gave space to articulate their motivation for change some participants felt that the intervention increased their physical activity levels conclusions social robots can achieve a fundamental objective of motivational interviewing encouraging participants to articulate their goals and dilemmas aloud because they are perceived as nonjudgmental robots may have advantages over more humanoid avatars for delivering virtual support for behavioral change
6N6RRVGR;journalArticle;2018;"Lazzeri, Nicole; Mazzei, Daniele; Cominelli, Lorenzo; Cisternino, Antonio; De Rossi, Danilo Emilio";Designing the Mind of a Social Robot;APPLIED SCIENCES-BASEL;NA;2076-3417;10.3390/app8020302;NA;Humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with human-inspired capabilities and traits. In the last few decades, this has become a reality with enormous advances in hardware performance, computer graphics, robotics technology, and artificial intelligence. New interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social, empathetic and affective capabilities. This paper presents the design, implementation, and test of a human-inspired cognitive architecture for social robots. State-of-the-art design approaches and methods are thoroughly analyzed and discussed, cases where the developed system has been successfully used are reported. The tests demonstrated the system's ability to endow a social humanoid robot with human social behaviors and with in-silico robotic emotions.;2018-02;2021-05-19T13:30:55Z;2021-05-19T13:30:55Z;NA;NA;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article;NA;NA;NA;NA;"social cognition; social robot; cognitive architecture; humanoid; human-inspired robot; robot mind";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designingthemindofasocialrobot;designing the mind of a social robot humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with humaninspired capabilities and traits in the last few decades this has become a reality with enormous advances in hardware performance computer graphics robotics technology and artificial intelligence new interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social empathetic and affective capabilities this paper presents the design implementation and test of a humaninspired cognitive architecture for social robots stateoftheart design approaches and methods are thoroughly analyzed and discussed cases where the developed system has been successfully used are reported the tests demonstrated the systems ability to endow a social humanoid robot with human social behaviors and with insilico robotic emotions
XTBIYGDM;conferencePaper;2018;"Kuehnlenz, Barbara; Busse, Fabian; Foertsch, Pascal; Wolf, Maximilian; Kuehnlenz, Kolja";Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.;2018;2021-05-19T13:30:56Z;2021-05-19T13:30:56Z;NA;275-281;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;effectofexplicitemotionaladaptationonprosocialbehaviorofhumanstowardsrobotsdependsonpriorrobotexperience;effect of explicit emotional adaptation on prosocial behavior of humans towards robots depends on prior robot experience emotional adaptation increases prosocial behavior of humans towards robotic interaction partners social cues are an important factor in this context this work investigates if emotional adaptation still works under absence of humanlike facial action units a humanrobot dialog scenario is chosen using nao pretending to work for a supermarket and involving humans providing object names to the robot for training purposes in a user study two conditions are implemented with or without explicit emotional adaptation of nao to the human user in a betweensubjects design evaluations of user experience and acceptance are conducted based on evaluated measures of humanrobot interaction hri the results of the user study reveal a significant increase of helpfulness number of named objects anthropomorphism and empathy in the explicit emotional adaptation condition even without social cues of facial action units but only in case of prior robot contact of the test persons otherwise an opposite effect is found these findings suggest that reduction of these social cues can be overcome by robot experience prior to the interaction task eg realizable by an additional bonding phase confirming the importance of such from previous work additionally an interaction with academic background of the participants is found
87NM3XKJ;conferencePaper;2018;"James, Jesin; Watson, Catherine Inez; MacDonald, Bruce";Artificial Empathy in Social Robots: An analysis of Emotions in Speech;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.;2018;2021-05-19T13:30:57Z;2021-05-19T13:30:57Z;NA;632-637;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;artificialempathyinsocialrobotsananalysisofemotionsinspeech;artificial empathy in social robots an analysis of emotions in speech artificial speech developed using speech synthesizers has been used as the voice for robots in human robot interaction hri as humans anthropomorphize robots an empathetically interacting robot is expected to increase the level of acceptance of social robots here a human perception experiment evaluates whether human subjects perceive empathy in robot speech for this experiment empathy is expressed only by adding appropriate emotions to the words in speech also humans preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed the results show that humans are able to perceive empathy and emotions in robot speech and prefer it over the standard robotic voice it is important for the emotions in empathetic speech to be consistent with the language content of what is being said and with the human users emotional state analyzing emotions in empathetic speech using valencearousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots
7AKIUZGJ;conferencePaper;2018;"Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H.";Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots;2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018);978-1-5386-7980-7;NA;NA;NA;Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.;2018;2021-05-19T13:30:58Z;2021-05-19T13:30:58Z;NA;783-789;NA;NA;NA;NA;NA;NA;IEEE RO-MAN;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper";<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>;NA;NA;NA;NA;Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;studyingeffectsofincorporatingautomatedaffectperceptionwithspokendialoginsocialrobots;studying effects of incorporating automated affect perception with spoken dialog in social robots social robots are becoming an integrated part of our daily lives with the goal of understanding humans social intentions and feelings a capability which is often referred to as empathy despite significant progress towards the development of empathic social agents current social robots have yet to reach the full emotional and social capabilities this paper presents our recent effort on incorporating an automated facial expression recognition fer system based on deep neural networks into the spoken dialog of a social robot ryan to extend and enrich its capabilities beyond spoken dialog and integrate the users affect state into the robots responses in order to evaluate whether this incorporation can improve social capabilities of ryan we conducted a series of humanrobotinteraction hri experiments in these experiments the subjects watched some videos and ryan engaged them in a conversation driven by users facial expressions perceived by the robot we measured the accuracy of the automated fer system on the robot when interacting with different human subjects as well as three socialinteractive aspects namely task engagement empathy and likability of the robot the results of our hri study indicate that the subjects rated empathy and likability of the affectaware ryan significantly higher than nonempathic the control condition ryan interestingly we found that the accuracy of the fer system is not a limiting factor as subjects rated the affectaware agent equipped with a low accuracy fer system as empathic and likable as when facial expression was recognized by a human observer
KLHQ5SFV;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor";He who hesitates is lost (...in thoughts over a robot);PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18);978-1-4503-5420-2;NA;10.1145/3183654.3183703;NA;In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.;2018;2021-05-19T13:30:58Z;2021-05-19T13:30:58Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Amer Psychol Assoc Type: Proceedings Paper;<p>Technology, Mind, and Society Conference (TechMindSociety), Washington, DC, APR 05-07, 2018</p>;NA;NA;NA;"Robotics; Empathy; Anthropomorphism; Human Machine Team; User Study";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;hewhohesitatesislostinthoughtsoverarobot;he who hesitates is lost in thoughts over a robot in a team the strong bonds that can form between teammates are often seen as critical for reaching peak performance this perspective may need to be reconsidered however if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions as relationships extend over long periods of time sustained empathic behavior towards robots would be of interest in order to measure user actions that may vary over time and are affected by empathy towards a robot teammate we created the teammate simulation system our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time the results of our study can have strong implications for the overall performance of human machine teams
NFFQ2IH2;conferencePaper;2018;"Carranza, Karmelo Antonio R.; Day, Nicole Jillian B.; Lin, Lawrence Matthew S.; Ponce, Albert R.; Reyes, Wilbur Rex O.; Abad, Alexander C.; Baldovino, Renann G.";Akibot: A Telepresence Robot for Medical Teleconsultation;2018 IEEE 10TH INTERNATIONAL CONFERENCE ON HUMANOID, NANOTECHNOLOGY, INFORMATION TECHNOLOGY, COMMUNICATION AND CONTROL, ENVIRONMENT AND MANAGEMENT (HNICEM);978-1-5386-7767-4;NA;NA;NA;One problem in the healthcare industry in the Philippines is the maldistribution of doctors. This greatly affects the accessibility of patients to proper healthcare. As a matter of fact, in 2015, 59.2% of deaths in the Philippines are attributed as deaths unattended by a doctor. Although there are current government programs, which aim to solve this problem, the use of telepresence systems can be another viable solution as doctors can still provide quality healthcare services even when located in a remote area. One limitation of medical telepresence robots is the lack of medical features. For this reason, the developed telepresence system includes a telepresence robot called Akibot with integrated medical devices such as otoscope, stethoscope, and ultrasound probe. Akibot is a highly maneuverable remotely controlled telepresence robot designed for general practice medical consultation between doctors and a patient on a remote area. Akibot has an empathic exterior with 4.6 out of 5 rating on its perceived quality of appearance and is equipped with modular medical devices and highly customizable screen, tested on an Android and Windows OS.;2018;2021-05-19T13:31:00Z;2021-05-19T13:31:00Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Conference on Humanoid Nanotechnology Information Technology Communication and Control Environment and Management;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Backup Publisher: IEEE ISSN: 2475-7152 Type: Proceedings Paper;<p>10th IEEE International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM), Baguio City, PHILIPPINES, NOV 29-DEC 02, 2018</p>;NA;NA;NA;"general practice medical consultation; human-centered robot design; teleconsultation; telepresence robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;akibotatelepresencerobotformedicalteleconsultation;akibot a telepresence robot for medical teleconsultation one problem in the healthcare industry in the philippines is the maldistribution of doctors this greatly affects the accessibility of patients to proper healthcare as a matter of fact in 2015 592 of deaths in the philippines are attributed as deaths unattended by a doctor although there are current government programs which aim to solve this problem the use of telepresence systems can be another viable solution as doctors can still provide quality healthcare services even when located in a remote area one limitation of medical telepresence robots is the lack of medical features for this reason the developed telepresence system includes a telepresence robot called akibot with integrated medical devices such as otoscope stethoscope and ultrasound probe akibot is a highly maneuverable remotely controlled telepresence robot designed for general practice medical consultation between doctors and a patient on a remote area akibot has an empathic exterior with 46 out of 5 rating on its perceived quality of appearance and is equipped with modular medical devices and highly customizable screen tested on an android and windows os
XPTHFDNH;conferencePaper;2018;"Tan, Xiang Zhi; Vazquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron";Inducing Bystander Interventions During Robot Abuse with Social Mechanisms;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171247;NA;We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant's performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.;2018;2021-05-19T13:31:02Z;2021-05-19T13:31:02Z;NA;169-177;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"robots; empathy; Human-robot interaction; abuse; bullying; peer intervention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;inducingbystanderinterventionsduringrobotabusewithsocialmechanisms;inducing bystander interventions during robot abuse with social mechanisms we explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse we designed a betweensubjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically the robot was either empathetic towards the participants performance in the task or indifferent when the robot was mistreated it ignored the abuse shut down in response to it or reacted emotionally we found that the majority of the participants intervened to help the robot after it was abused interventions happened for a wide range of reasons interestingly the empathetic robot increased the proportion of participants that selfreported intervening in comparison to the indifferent robot but more participants moved the robot as a response to abuse in the latter case the participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all
ITV5YQLP;conferencePaper;2018;"Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana";Group-based Emotions in Teams of Humans and Robots;HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION;978-1-4503-4953-6;NA;10.1145/3171221.3171252;NA;Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.;2018;2021-05-19T13:31:03Z;2021-05-19T13:31:03Z;NA;261-269;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"emotion; trust; group effects; Human-robot teamwork; identification; inter-group interactions; self-categorisation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;groupbasedemotionsinteamsofhumansandrobots;groupbased emotions in teams of humans and robots providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others furthermore the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion namely groupbased emotions this paper contributes with the first model on groupbased emotions in social robotic partners we defined a model of groupbased emotions for social robots that allowed us to create two distinct robotic characters that express either individual or groupbased emotions this paper also contributes with a user study where two autonomous robots embedded the previous characters and formed two humanrobot teams to play a competitive game our results showed that participants perceived the robot that expresses groupbased emotions as more likeable and attributed higher levels of group identification and group trust towards their teams when compared to the robotic partner that expresses individualbased emotions
YRVIY56X;conferencePaper;2018;"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea";Counseling Robot Implementation and Evaluation;2018 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC);978-1-5386-6650-0;NA;10.1109/SMC.2018.00297;NA;A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called “unazuki” in Japanese, a kind of nodding to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared according several subjective feelings by the evaluation subjects.;2018;2021-05-19T13:31:04Z;2021-05-19T13:31:04Z;NA;1716-1722;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Sci Council Japan ISSN: 1062-922X Type: Proceedings Paper";"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE Syst Man &amp; Cybernet Soc, Miyazaki, JAPAN, OCT 07-10, 2018</p>";NA;NA;NA;"Robot; Counseling; Dialog Promotion; Nodding; unazuki";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;counselingrobotimplementationandevaluation;counseling robot implementation and evaluation a lot of it personnel have psychological distress and counselors to help them are lack in number therefore we proposed a counseling agent ca called creca context respectful counseling agent which listens to clients and promotes their reflection context respectfully namely in a context preserving way this agent is now enhanced using a body language called unazuki in japanese a kind of nodding to greatly promote dialogue often accompanying unun meaning exactly of japanese onomatopoeia this body language significantly helps represent empathy or entire approval our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients further reflection to realize it the robot nods twice at each end of dialog sentence input by clients here we introduce a robot that behaves humanlike by an appropriate nodding behavior the motivation for such a more humanlike robot was the extension of application fields from it workers counselling to people who suffer from more social problems such as financial debt or anxiety of victory or defeat for such applications it is important that the agent behaves as much as possible humanlike here we present an enhanced experimental evaluation the quantitative evaluation is based on the utterance amounts of a test group of individuals these amount with and without the nodding feature are compared additionally the robots with and without nodding are compared according several subjective feelings by the evaluation subjects
5ETBULZB;conferencePaper;2018;"Wen, James; Stewart, Amanda; Billinghurst, Mark; Tossell, Chad";Band of Brothers and Bolts: Caring About Your Robot Teammate;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.;2018;2021-05-19T13:31:05Z;2021-05-19T13:31:05Z;NA;1853-1858;NA;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;bandofbrothersandboltscaringaboutyourrobotteammate;band of brothers and bolts caring about your robot teammate it has been observed that a robot shown as suffering is enough to cause an empathic response from a person whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern we report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion our findings suggest that induced empathy can in fact have a significant impact on a persons behavior to the extent that the ability to fulfill a mission may be affected
TBPV8EEU;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction;2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS);978-1-5386-8094-0;NA;NA;NA;Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.;2018;2021-05-19T13:31:05Z;2021-05-19T13:31:05Z;NA;2008-2013;NA;NA;NA;NA;NA;NA;IEEE International Conference on Intelligent Robots and Systems;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper";<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>;NA;NA;NA;NA;Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionalbodilyexpressionsforculturallycompetentrobotsthroughlongtermhumanrobotinteraction;emotional bodily expressions for culturally competent robots through long term humanrobot interaction generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multiculture society in this paper we propose an incremental learning model for selecting the users representative or habitual emotional behaviors which place emphasis on individual users cultural traits identified through long term interaction furthermore a transformation model is proposed to convert the obtained emotional behaviors into a specific robots motion space to validate the proposed approach the models were evaluated by two example scenarios of interaction the experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users and to generate its emotional bodily expressions it was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator
V8G24QHE;conferencePaper;2018;"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young";Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression;2018 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS (UR);978-1-5386-6334-9;NA;NA;NA;Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.;2018;2021-05-19T13:31:13Z;2021-05-19T13:31:13Z;NA;377-382;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>15th International Conference on Ubiquitous Robots (UR), Honolulu, HI, JUN 26-30, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;incrementallearningofhumanemotionalbehaviorforsocialrobotemotionalbodyexpression;incremental learning of human emotional behavior for social robot emotional body expression generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in humanrobot interaction in this paper an enhanced model of robot emotional body expression is proposed which places emphasis on the individual users cultural traits similar to our previous paper this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background social referencing occurs when infants perceive their parents facial expressions and vocal tones of emotional situations to form their own interpretation on the other hand this model replaces the batch learning selforganizing map with the dynamic cell structure incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts we demonstrate the validity of our incremental learning model through a public human action dataset which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual users culture
ZJGUULA6;conferencePaper;2018;"Kohori, Tomoko; Hirayama, Shiho; Hara, Takenori; Muramatsu, Michiko; Naganuma, Hiroyuki; Yamano, Masayuki; Ichikawa, Kazuko; Matsumoto, Hiroko; Uchiyama, Hiroko";Development and Evaluation of an Interactive Therapy Robot;ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY, ACE 2017;978-3-319-76270-8 978-3-319-76269-2;NA;10.1007/978-3-319-76270-8_6;NA;Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes.;2018;2021-05-19T13:31:17Z;2021-05-19T13:31:17Z;NA;66-83;NA;NA;10714;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Multimodal Technologies & Interact Journal ISSN: 0302-9743 Type: Proceedings Paper;<p>14th International Conference on Advances in Computer Entertainment Technology (ACE), London, ENGLAND, DEC 14-16, 2017</p>;NA;NA;NA;"Healing elements Therapeutic robots designed to communicate with humans; Therapeutic effect";Cheok, AD and Inami, M and Romao, T;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;developmentandevaluationofaninteractivetherapyrobot;development and evaluation of an interactive therapy robot interactions with animals can enhance emotions and improve mood by engendering feelings of healing relaxation comfort and reduced stress unfortunately many people cannot live with animals because of allergies infection risk or risk of damage to rental housing to address these problems some research groups have investigated robotbased psychotherapy however the important healing elements for therapy robots were not identified therefore we conducted an internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented we assumed that a healing mood could be induced based on the interactive functions and appearance to verify this hypothesis we developed and evaluated a new interactive therapy robot next we conducted interviews with individuals who interacted with a prototype therapy robot the interviews revealed that the appearance of the robot was critical to engendering feelings of healing comfort and empathy in addition the size softness and comfort of the interactive therapy robot contributed to people feeling affection towards it we also confirmed the importance of the robot appearing to listen to those who interacted with it our results should be useful for designing companion robots for therapy purposes
JLWCRTQG;journalArticle;2018;"Barakova, E. I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.";Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot;CONNECTION SCIENCE;NA;0954-0091;10.1080/09540091.2017.1350938;NA;In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game - the game with the robot was seen as more challenging and the robot - as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world.;2018;2021-05-19T13:31:19Z;2021-05-19T13:31:19Z;NA;81-98;NA;1, SI;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article;NA;NA;NA;NA;"combining social and game strategy; Economic game strategies for robots; engagement robot/computer; long-term relations with robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;sociallygroundedgamestrategyenhancesbondingandperceivedsmartnessofahumanoidrobot;socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot in search for better technological solutions for education we adapted a principle from economic game theory namely that giving a help will promote collaboration and eventually longterm relations between a robot and a child this principle has been shown to be effective in games between humans and between humans and computer agents we compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer we found that by combining the social and game strategy the children average age of 83 years had more empathy and social engagement with the robot since the children did not want to necessarily win against it this finding is promising for using social strategies for the creation of longterm relations between robots and children and making educational tasks more engaging an additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game  the game with the robot was seen as more challenging and the robot  as a smarter opponent this finding might be due to the higher perceived or expected intelligence from the robot or because of the higher complexity of seeing patterns in threedimensional world
52IU7ENA;conferencePaper;2018;"Churamani, Nikhil; Banos, Pablo; Strahl, Erik; Wermter, Stefan";Learning Empathy-Driven Emotion Expressions using Affective Modulations;2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6014-6;NA;NA;NA;Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.;2018;2021-05-19T13:31:20Z;2021-05-19T13:31:20Z;NA;NA;NA;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;ISSN: 2161-4393 Type: Proceedings Paper;<p>International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, BRAZIL, JUL 08-13, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;learningempathydrivenemotionexpressionsusingaffectivemodulations;learning empathydriven emotion expressions using affective modulations humanrobot interaction hri studies particularly the ones designed around social robots use emotions as important building blocks for interaction design in order to provide a natural interaction experience these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction these internal emotions act as motivation for learning to respond to the user in different situations using the physical capabilities of the robot this paper proposes a deep hybrid neural model for multimodal affect recognition analysis and behaviour modelling in social robots the model uses growing selforganising network models to encode intrinsic affective states for the robot these intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the neuroinspired companion nico robot enabling the robot to express empathy towards the users
AYQILR9M;conferencePaper;2018;"Bjorling, Elin A.; Rose, Emma; Ren, Rachel";Teen-Robot Interaction A Pilot Study of Engagement with a Low-fidelity Prototype;COMPANION OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'18);978-1-4503-5615-2;NA;10.1145/3173386.3177068;NA;Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies.;2018;2021-05-19T13:31:21Z;2021-05-19T13:31:21Z;NA;69-70;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"engagement; prototype; Teen-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;teenrobotinteractionapilotstudyofengagementwithalowfidelityprototype;teenrobot interaction a pilot study of engagement with a lowfidelity prototype todays teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots although humanrobot interaction has been explored in children adults and seniors examination of teenrobot interaction has been minimal using humancentered design our team is developing a social robot to gather stress and mood data from teens in a public high school as part of our preliminary design stage we conducted a interaction pilot study in the wild to explore and capture teens initial interactions with a lowfidelity social robot prototype we observed strong engagement and expressions of empathy from teens during our qualitative interaction studies
HKFU97W9;conferencePaper;2018;"Kang, Dahyun; Kim, SunKyoung; Kwak, Sonya S.";The Effects of Physical Contact in the Functional Intimate Distance on Users' Acceptance toward Robots;COMPANION OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'18);978-1-4503-5615-2;NA;10.1145/3173386.3177023;NA;We investigated the effects of physical contact of robots on the users' acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand.;2018;2021-05-19T13:31:21Z;2021-05-19T13:31:21Z;NA;143-144;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theeffectsofphysicalcontactinthefunctionalintimatedistanceonusersacceptancetowardrobots;the effects of physical contact in the functional intimate distance on users acceptance toward robots we investigated the effects of physical contact of robots on the users acceptance in the functional intimate distance we conducted a two robot interaction types interaction with physical contact vs interaction with a tool withinparticipants experiment n18 this study was a videobased observation study according to the experimental results the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone on the other hand the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patients temperature with a thermometer instead of its hand
KJMCM8ZL;conferencePaper;2018;"Lehmann, Hagen; Broz, Frank";Contagious Yawning in Human-Robot Interaction;COMPANION OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'18);978-1-4503-5615-2;NA;10.1145/3173386.3177063;NA;This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data.;2018;2021-05-19T13:31:21Z;2021-05-19T13:31:21Z;NA;173-174;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper";<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>;NA;NA;NA;"Empathy; Human-Robot Interaction; Behavior Contagion; Yawning";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;contagiousyawninginhumanrobotinteraction;contagious yawning in humanrobot interaction this late breaking report introduces an approach to measure yawning contagion between robots and humans understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in hri we will give an overview of an experiment which used an emys robot for the presentation of the yawning stimulus we will present the results of our preliminary analysis of the collected data
BXXQ2R7B;conferencePaper;2018;"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi";Towards Empathetic Human-Robot Interactions;COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II;978-3-319-75487-1 978-3-319-75486-4;NA;10.1007/978-3-319-75487-1_14;NA;Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.;2018;2021-05-19T13:31:21Z;2021-05-19T13:31:21Z;NA;173-193;NA;NA;9624;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Issue: II Type: Proceedings Paper;<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>;NA;NA;NA;NA;Gelbukh, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsempathetichumanrobotinteractions;towards empathetic humanrobot interactions since the late 1990s when speech companies began providing their customerservice software in the market people have gotten used to speaking to machines as people interact more often with voice and gesture controlled machines they expect the machines to recognize different emotions and understand other high level communication features such as humor sarcasm and intention in order to make such communication possible the machines need an empathy module in them which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot although research on empathetic robots is still in the primary stage current methods involve using signal processing techniques sentiment analysis and machine learning algorithms to make robots that can understand human emotion other aspects of humanrobot interaction include facial expression and gesture recognition as well as robot movement to convey emotion and intent we propose zara the supergirl as a prototype system of empathetic robots it is a softwarebased virtual android with an animated cartoon character to present itself on the screen she will get smarter and more empathetic by having machine learning algorithms and gathering more data and learning from it in this paper we present our work so far in the areas of deep learning of emotion and sentiment recognition as well as humor recognition we hope to explore the future direction of android development and how it can help improve peoples lives
LJFIZGR3;conferencePaper;2018;"Macianskiene, Nemira; Bijeikiene, Vilma";APPLICATION OF FORMATIVE ASSESSMENT FOR THE ENHANCED FOREIGN LANGUAGE LEARNING;EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES;978-84-09-02709-5;NA;NA;NA;"Education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking, problem-solving, global empathy, tolerance, intercultural awareness as well as team-work and collaboration. Formative assessment (FA) has emerged to be one of the efficient tools in the development of the above-mentioned competences and thus a topical issue in today's education. A number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills, student responsibility, active self-regulated learning, viewing learning as a goal rather than an outcome (Anderson, M., 2016; Brookhart, 2009; Chappuis, J., 2016; Fisher & Frey, 2014; [13]). The present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education. It aims at investigating how the application of formative assessment assists in fostering deep learning, student-centered approach, collaborative and tension free environment, active learning in small groups, enhanced dynamic exchange of feedback between teachers and students as well as self-assessment and peer-assessment both in traditional classroom as well as in virtual learning environment. It also explores the impact of formative assessment upon student lifelong learning skill development. Methodologically, the study is based on an opinion survey, reflection and class observation performed with 181 university students and 21 language teachers. The study has revealed that formative assessment adds significant value to the learning and teaching of languages. It settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality, cooperative learning, connection-building among all members of the learning and teaching process including students and teachers. It has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further in-depth research.";2018;2021-05-19T13:31:22Z;2021-05-19T13:31:22Z;NA;10084-10091;NA;NA;NA;NA;NA;NA;EDULEARN Proceedings;NA;NA;NA;IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT;LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN;English;NA;NA;NA;NA;NA;NA;ISSN: 2340-1117 Type: Proceedings Paper;<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>;NA;NA;NA;"foreign language learning and teaching; Formative assessment; student-centered approach; tertiary education";Chova, LG and Martinez, AL and Torres, IC;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;applicationofformativeassessmentfortheenhancedforeignlanguagelearning;application of formative assessment for the enhanced foreign language learning education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking problemsolving global empathy tolerance intercultural awareness as well as teamwork and collaboration formative assessment fa has emerged to be one of the efficient tools in the development of the abovementioned competences and thus a topical issue in todays education a number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills student responsibility active selfregulated learning viewing learning as a goal rather than an outcome anderson m 2016 brookhart 2009 chappuis j 2016 fisher  frey 2014 13 the present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education it aims at investigating how the application of formative assessment assists in fostering deep learning studentcentered approach collaborative and tension free environment active learning in small groups enhanced dynamic exchange of feedback between teachers and students as well as selfassessment and peerassessment both in traditional classroom as well as in virtual learning environment it also explores the impact of formative assessment upon student lifelong learning skill development methodologically the study is based on an opinion survey reflection and class observation performed with 181 university students and 21 language teachers the study has revealed that formative assessment adds significant value to the learning and teaching of languages it settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality cooperative learning connectionbuilding among all members of the learning and teaching process including students and teachers it has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further indepth research
VFLS6D9H;conferencePaper;2018;"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama";Touch Your Heart: A Tone-aware Chatbot for Customer Care on Social Media;PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018);978-1-4503-5620-6;NA;10.1145/3173574.3173989;NA;Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone -aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.;2018;2021-05-19T13:31:23Z;2021-05-19T13:31:23Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>CHI Conference on Human Factors in Computing Systems (CHI), Montreal, CANADA, APR 21-26, 2018</p>;NA;NA;NA;"Chatbot; Deep Learning; Social Media; Customer Care";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;touchyourheartatoneawarechatbotforcustomercareonsocialmedia;touch your heart a toneaware chatbot for customer care on social media chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years however current work on chatbot for customer care ignores a key to impact user experience  tones in this work we create a novel toneaware chatbot that generates toned responses to user requests on social media we first conduct a formative research in which the effects of tones are studied significant and various influences of different tones on user experience are uncovered in the study with the knowledge of effects of tones we design a deep learning based chatbot that takes tone information into account we train our system on over 15 million real customer care conversations collected from twitter the evaluation reveals that our tone aware chatbot generates as appropriate responses to user requests as human agents more importantly our chatbot is perceived to be even more empathetic than human agents
KYUUCPFM;journalArticle;2018;"Vallverdu, Jordi; Nishida, Toyoaki; Ohmoto, Yoshisama; Moran, Stuart; Lazare, Sarah";Fake Empathy and Human-Robot Interaction (HRI): A Preliminary Study;INTERNATIONAL JOURNAL OF TECHNOLOGY AND HUMAN INTERACTION;NA;1548-3908;10.4018/IJTHI.2018010103;NA;Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call `fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different `humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi-angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment.;2018-03;2021-05-19T13:31:23Z;2021-05-19T13:31:23Z;NA;44-59;NA;1;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type: Article;NA;NA;NA;NA;"Emotions; Empathy; Robots; Human-Robot Interaction; Fake; HRI; WOZ";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;fakeempathyandhumanrobotinteractionhriapreliminarystudy;fake empathy and humanrobot interaction hri a preliminary study empathy is a basic emotion trigger for human beings especially while regulating social relationships and behaviour the main challenge of this paper is study whether peoples empathic reactions towards robots change depending on previous information given to human about the robot before the interaction the use of false data about robot skills creates different levels of what we call fake empathy this study performs an experiment in woz environment in which different subjects n17 interacting with the same robot while they believe that the robot is a different robot up to three versions each robot scenario provides a different humanoid description and out hypothesis is that the more humanlike looks the robot the more empathically can be the human responses results were obtained from questionnaires and multiangle video recordings positive results reinforce the strength of our hypothesis although we recommend a new and bigger and then more robust experiment
LCQIVA68;journalArticle;2017;"Chikaraishi, Takenobu; Yoshikawa, Yuichiro; Ogawa, Kohei; Hirata, Oriza; Ishiguro, Hiroshi";Creation and Staging of Android Theatre “Sayonara” towards Developing Highly Human-Like Robots;FUTURE INTERNET;NA;1999-5903;10.3390/fi9040075;NA;Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.;2017-12;2021-05-19T13:31:24Z;2021-05-19T13:31:24Z;NA;NA;NA;4;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI AG Type: Article;NA;NA;NA;NA;"social robots; android theatre; contemporary colloquial theatre theory; robot theatre";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;creationandstagingofandroidtheatresayonaratowardsdevelopinghighlyhumanlikerobots;creation and staging of android theatre sayonara towards developing highly humanlike robots even after longterm exposures androids with a strikingly humanlike appearance evoke unnatural feelings the behavior that would induce humanlike feelings after long exposures is difficult to determine and it often depends on the cultural background of the observers therefore in this study we generate an acting performance system for the android in which an android and a human interact in a stage play in the real world we adopt the theatrical theory called contemporary colloquial theatre theory to give the android natural behaviors so that audiences can comfortably observe it even after longminute exposure a stage play is created and shown in various locations and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a selfevaluating questionnaire overall analysis indicates that the audience had positive feelings in terms of attractiveness towards the android on the stage even after 20 min of exposure the singularly high acceptance of the android by japanese audiences seems to be correlated with a high animism tendency rather than to empathy we also discuss how the stage play approach is limited and could be extended to contribute to realization of humanrobot interaction in the real world
MAM7KB5E;journalArticle;2017;"Borenstein, Jason; Arkin, Ronald C.";Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior;AI & SOCIETY;NA;0951-5666;10.1007/s00146-016-0684-1;NA;"An under-examined aspect of human-robot interaction that warrants further exploration is whether robots should be permitted to influence a user's behavior for that person's own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user's behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user's empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be.";2017-11;2021-05-19T13:31:24Z;2021-05-19T13:31:24Z;NA;499-507;NA;4;32;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Charity; Companion robots; Design ethics; Nudges; Robot ethics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;nudgingforgoodrobotsandtheethicalappropriatenessofnurturingempathyandcharitablebehavior;nudging for good robots and the ethical appropriateness of nurturing empathy and charitable behavior an underexamined aspect of humanrobot interaction that warrants further exploration is whether robots should be permitted to influence a users behavior for that persons own good yet an even more controversial practice could be on the horizon which is allowing a robot to nudge a users behavior for the good of society in this article we examine the feasibility of creating companion robots that would seek to nurture a users empathy toward other human beings as more and more computing devices subtly and overtly influence human behavior it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway our primary focus is on whether a companion robot could encourage humans to perform charitable acts this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be
X6ELKEYM;journalArticle;2017;"Wiese, Eva; Metta, Giorgio; Wykowska, Agnieszka";Robots As Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.01663;NA;Robots are increasingly envisaged as our future cohabitants. However, while considerable progress has been made in recent years in terms of their technological realization, the ability of robots to interact with humans in an intuitive and social way is still quite limited. An important challenge for social robotics is to determine how to design robots that can perceive the user's needs, feelings, and intentions, and adapt to users over a broad range of cognitive abilities. It is conceivable that if robots were able to adequately demonstrate these skills, humans would eventually accept them as social companions. We argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motion/eye-tracking, electroencephalography, or functional near-infrared spectroscopy embedded in interactive human-robot paradigms. This approach requires understanding how humans interact with each other, how they perform tasks together and how they develop feelings of social connection over time, and using these insights to formulate design principles that make social robots attuned to the workings of the human brain. In this review, we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in social-cognitive processing. We first review literature related to social-cognitive processes and mechanisms involved in human-human interactions, and highlight the importance of perceiving others as intentional agents to activate these social brain areas. We then discuss how attribution of intentionality can positively affect human-robot interaction by (a) fostering feelings of social connection, empathy and prosociality, and by (b) enhancing performance on joint human-robot tasks. Lastly, we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous, and discuss challenges associated with designing social robots that are inspired by neuroscientific principles.;2017-10-04;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Review;NA;NA;NA;NA;"social neuroscience; human-robot interaction; social robotics; mind perception; attribution of intentionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotsasintentionalagentsusingneuroscientificmethodstomakerobotsappearmoresocial;robots as intentional agents using neuroscientific methods to make robots appear more social robots are increasingly envisaged as our future cohabitants however while considerable progress has been made in recent years in terms of their technological realization the ability of robots to interact with humans in an intuitive and social way is still quite limited an important challenge for social robotics is to determine how to design robots that can perceive the users needs feelings and intentions and adapt to users over a broad range of cognitive abilities it is conceivable that if robots were able to adequately demonstrate these skills humans would eventually accept them as social companions we argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motioneyetracking electroencephalography or functional nearinfrared spectroscopy embedded in interactive humanrobot paradigms this approach requires understanding how humans interact with each other how they perform tasks together and how they develop feelings of social connection over time and using these insights to formulate design principles that make social robots attuned to the workings of the human brain in this review we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in socialcognitive processing we first review literature related to socialcognitive processes and mechanisms involved in humanhuman interactions and highlight the importance of perceiving others as intentional agents to activate these social brain areas we then discuss how attribution of intentionality can positively affect humanrobot interaction by a fostering feelings of social connection empathy and prosociality and by b enhancing performance on joint humanrobot tasks lastly we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous and discuss challenges associated with designing social robots that are inspired by neuroscientific principles
E23N7EYG;journalArticle;2017;"Liu, Xin; Xie, Lun; Wang, Zhiliang";Empathizing with Emotional Robot Based on Cognition Reappraisal;CHINA COMMUNICATIONS;NA;1673-5447;NA;NA;This paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive person's expressions. It integrates a guiding cognitive reappraisal strategy into the HMM (Hidden Markov Model) emotional interactive model for empathizing between robot and person. The emotion is considered as a source in the 3D space (Arousal, Valence, and Stance). State transition and emotion intensity can be quantitatively analyzed in the continuous space. This cognition-emotion interactive model have been verified by the expression and behavior robot. Empathizing is the main distinguishing feature of our work, and it is realized by the emotional regulation which operated in a continuous 3D emotional space enabling a wide range of intermediate emotions. The experiment results provide evidence with acceptability, accuracy, richness, fluency, interestingness, friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the human-robot interaction (HRI).;2017-09;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;100-113;NA;9;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article;NA;NA;NA;NA;"human-robot interaction; emotional robot; active field emotion space; emotional regulation; guiding cognitive reappraisal";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathizingwithemotionalrobotbasedoncognitionreappraisal;empathizing with emotional robot based on cognition reappraisal this paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive persons expressions it integrates a guiding cognitive reappraisal strategy into the hmm hidden markov model emotional interactive model for empathizing between robot and person the emotion is considered as a source in the 3d space arousal valence and stance state transition and emotion intensity can be quantitatively analyzed in the continuous space this cognitionemotion interactive model have been verified by the expression and behavior robot empathizing is the main distinguishing feature of our work and it is realized by the emotional regulation which operated in a continuous 3d emotional space enabling a wide range of intermediate emotions the experiment results provide evidence with acceptability accuracy richness fluency interestingness friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the humanrobot interaction hri
WJWXG4MW;journalArticle;2017;"Abubshait, Abdulaziz; Wiese, Eva";You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human-Robot Interaction;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.01393;NA;Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed.;2017-08-23;2021-05-19T13:31:25Z;2021-05-19T13:31:25Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"intentionality; social cognition; human-robot interaction; social robotics; mind perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;youlookhumanbutactlikeamachineagentappearanceandbehaviormodulatedifferentaspectsofhumanrobotinteraction;you look human but act like a machine agent appearance and behavior modulate different aspects of humanrobot interaction gaze following occurs automatically in social interactions but the degree to which gaze is followed depends on whether an agent is perceived to have a mind making its behavior socially more relevant for the interaction mind perception also modulates the attitudes we have toward others and determines the degree of empathy prosociality and morality invested in social interactions seeing mind in others is not exclusive to human agents but mind can also be ascribed to nonhuman agents like robots as long as their appearance andor behavior allows them to be perceived as intentional beings previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents and positively affect attitudes and performance in humanrobot interaction what has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in humanrobot interaction we examine this question by manipulating agent appearance human vs robot and behavior reliable vs random within the same paradigm and examine how congruent humanreliable vs robotrandom versus incongruent humanrandom vs robotreliable combinations of these triggers affect performance ie gaze following and attitudes ie agent ratings in humanrobot interaction the results show that both appearance and behavior affect humanrobot interaction but that the two triggers seem to operate in isolation with appearance more strongly impacting attitudes and behavior more strongly affecting performance the implications of these findings for humanrobot interaction are discussed
4ZEIILSG;journalArticle;2017;"Rouaix, Natacha; Retru-Chavastel, Laure; Rigaud, Anne-Sophie; Monnet, Clotilde; Lenoir, Hermine; Pino, Maribel";Affective and Engagement Issues in the Conception and Assessment of a Robot-Assisted Psychomotor Therapy for Persons with Dementia;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2017.00950;NA;"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a “control software” for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient-therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction.";2017-06-30;2021-05-19T13:31:26Z;2021-05-19T13:31:26Z;NA;NA;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"engagement; social robots; control software; dementia; geriatrics; psychomotor therapy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;affectiveandengagementissuesintheconceptionandassessmentofarobotassistedpsychomotortherapyforpersonswithdementia;affective and engagement issues in the conception and assessment of a robotassisted psychomotor therapy for persons with dementia the interest in robotassisted therapies rat for dementia care has grown steadily in recent years however rat using humanoid robots is still a novel practice for which the adhesion mechanisms indications and benefits remain unclear also little is known about how the robots behavioral and affective style might promote engagement of persons with dementia pwd in rat the present study sought to investigate the use of a humanoid robot in a psychomotor therapy for pwd we examined the robots potential to engage participants in the intervention and its effect on their emotional state a brief psychomotor therapy program involving the robot as the therapists assistant was created for this purpose a corpus of social and physical behaviors for the robot and a control software for customizing the program and operating the robot were also designed particular attention was given to components of the rat that could promote participants engagement robots interaction style personalization of contents in the pilot assessment of the intervention nine pwd 7 women and 2 men m age  86 yo hospitalized in a geriatrics unit participated in four individual therapy sessions one classic therapy ct session patienttherapist and three rat sessions patienttherapistrobot outcome criteria for the evaluation of the intervention included participants engagement emotional state and wellbeing satisfaction of the intervention appreciation of the robot and empathyrelated behaviors in humanrobot interaction hri results showed a high constructive engagement in both ct and rat sessions more positive emotional responses in participants were observed in rat compared to ct rat sessions were better appreciated than ct sessions the use of a social robot as a mediating tool appeared to promote the involvement of pwd in the therapeutic intervention increasing their immediate wellbeing and satisfaction
6R7K2F3R;journalArticle;2017;"Slomian, Justine; Emonts, Patrick; Vigneron, Lara; Acconcia, Alessandro; Reginster, Jean-Yves; Oumourgh, Mina; Bruyere, Olivier";Meeting the Needs of Mothers During the Postpartum Period: Using Co-Creation Workshops to Find Technological Solutions;JMIR RESEARCH PROTOCOLS;NA;1929-0748;10.2196/resprot.6831;NA;Background: The postnatal period is associated with many new needs for mothers. Objective: The aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth. Methods: Two co-creation workshops were undertaken with parents and professionals. The aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth. The aim of the second workshop was to create solutions in response to the criteria selected during the first workshop. Results: Parents and health professionals want solutions that include empathy (ie, to help fight against the feelings of abnormality and loneliness), that help mothers in daily life, that are personalized and adapted to different situations, that are educational, and that assures some continuity in their contact with health professionals. In practice, we found that parents and professionals think the solution should be accessible to everyone and available at all times. To address these criteria, technology experts proposed different solutions, such as a forum dedicated to the postpartum period that is supervised by professionals, a centralized website, a system of videoconferencing, an online exchange group, a “gift voucher” system, a virtual reality app, or a companion robot. Conclusions: The human component seems to be very important during the postnatal period. Nevertheless, technology could be a great ally in helping mothers during the postpartum period. Technology can help reliably inform parents and may also give them the right tools to find supportive people. However, these technologies should be tested in clinical trials.;2017-05;2021-05-19T13:31:26Z;2021-05-19T13:31:26Z;NA;NA;NA;5;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article;NA;NA;NA;NA;"co-creating workshop; co-creation; mothers' needs; postpartum needs; technological solutions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;meetingtheneedsofmothersduringthepostpartumperiodusingcocreationworkshopstofindtechnologicalsolutions;meeting the needs of mothers during the postpartum period using cocreation workshops to find technological solutions background the postnatal period is associated with many new needs for mothers objective the aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth methods two cocreation workshops were undertaken with parents and professionals the aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth the aim of the second workshop was to create solutions in response to the criteria selected during the first workshop results parents and health professionals want solutions that include empathy ie to help fight against the feelings of abnormality and loneliness that help mothers in daily life that are personalized and adapted to different situations that are educational and that assures some continuity in their contact with health professionals in practice we found that parents and professionals think the solution should be accessible to everyone and available at all times to address these criteria technology experts proposed different solutions such as a forum dedicated to the postpartum period that is supervised by professionals a centralized website a system of videoconferencing an online exchange group a gift voucher system a virtual reality app or a companion robot conclusions the human component seems to be very important during the postnatal period nevertheless technology could be a great ally in helping mothers during the postpartum period technology can help reliably inform parents and may also give them the right tools to find supportive people however these technologies should be tested in clinical trials
JZ9LYPQR;journalArticle;2017;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe";Simulating empathic behavior in a social assistive robot;MULTIMEDIA TOOLS AND APPLICATIONS;NA;1380-7501;10.1007/s11042-016-3797-0;NA;When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user's affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot's affective state and, consequently, the most appropriate empathic behavior. The robot's empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.;2017-02;2021-05-19T13:31:27Z;2021-05-19T13:31:27Z;NA;5073-5094;NA;4;76;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Empathy; Affective computing; Social assistive robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;simulatingempathicbehaviorinasocialassistiverobot;simulating empathic behavior in a social assistive robot when used as an interface in the context of ambient assisted living aal a social robot should not just provide a taskoriented support it should also try to establish a social empathic relation with the user to this aim it is crucial to endow the robot with the capability of recognizing the users affective state and reason on it for triggering the most appropriate communicative behavior in this paper we describe how such an affective reasoning has been implemented in the nao robot for simulating empathic behaviors in the context of aal in particular the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions the recognized emotion allows triggering the robots affective state and consequently the most appropriate empathic behavior the robots empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot
8387VVLJ;conferencePaper;2017;"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama";A New Chatbot for Customer Service on Social Media;PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17);978-1-4503-4655-9;NA;10.1145/3025453.3025496;NA;"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.";2017;2021-05-19T13:31:28Z;2021-05-19T13:31:28Z;NA;3506-3510;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper";<p>ACM SIGCHI Conference on Human Factors in Computing Systems (CHI), Denver, CO, MAY 06-11, 2017</p>;NA;NA;NA;"social media; deep learning; Chatbot; customer service";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anewchatbotforcustomerserviceonsocialmedia;a new chatbot for customer service on social media users are rapidly turning to social media to request and receive customer service however a majority of these requests were not addressed timely or even not addressed at all to overcome the problem we create a new conversational system to automatically generate responses for users requests on social media our system is integrated with stateoftheart deep learning techniques and is trained by nearly 1m twitter conversations between users and agents from over 60 brands the evaluation reveals that over 40 of the requests are emotional and the system is about as good as human agents in showing empathy to help users cope with emotional situations results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric
ZB69PL3Q;conferencePaper;2017;"Anshar, Muh; Williams, Mary-Anne";Evolving Artificial Pain from Fault Detection through Pattern Data Analysis;2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR);978-1-5386-2035-9;NA;NA;NA;Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.;2017;2021-05-19T13:31:30Z;2021-05-19T13:31:30Z;NA;694-699;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Inst Elect & Elect Engineers; Inst Elect & Elect Engineers Robot & Automat Soc; Harbin Inst Technol; Beijing Inst Technol; Univ Nevada; Univ Electro Commun Tokyo; Chinese Univ Hong Kong; Chinese Acad Sci Type: Proceedings Paper";<p>IEEE International Conference on Real-time Computing and Robotics (RCAR), Okinawa, JAPAN, JUL 14-18, 2017</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;evolvingartificialpainfromfaultdetectionthroughpatterndataanalysis;evolving artificial pain from fault detection through pattern data analysis fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications as the breath of robots applications requiring human interaction grow it is important for robots to acquire sophisticated social skills such as empathy towards pain however it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects this paper introduces the concept of pain based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain faults provide the stimulus and defines a classified magnitude value which constitutes artificial pain generation comprised of synthetic pain classes our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain the robot is also capable of alerting humans whenever a task will generate artificial pain or whenever humans fails to acknowledge the alert the robot can take a considerable preventive actions through joint stiffness adjustment
JMYQ9JDF;conferencePaper;2017;"Burns, Henriette D.; Lesseig, Kristin";Empathy in Middle School Engineering Design Process;2017 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE);978-1-5090-5920-1;NA;NA;NA;This work-in-progress studies empathy in middle school engineering design pedagogy. A model of empathy in engineering as a core skill, as a practice orientation and a professional way of being that can be taught in university programs has been proposed [1]. Does an emotional intelligence model of empathy need to be taught earlier than at the university level? The engineering design process has been included in the science standards for k-12 schools since 2013[2]. One of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum. The design process typically includes the steps of defining the engineering problem, developing solutions and optimizing the design. Although the word “empathy” is not used, these problems are defined from an empathetic perspective as “situations people want to change” of “social and global significance.” However, the standards do not discuss how to define a problem or how to teach empathy. In the winter of 2016 a study was conducted to evaluate the influence of empathy based lessons on girls' interest in science, technology, engineering and mathematics (STEM). Some information is known about empathy in lessons. Girls may be more interested if lessons are altered to include an element of caring [3]. Other studies indicate children's empathy increases with type of media provided in lesson (computer versus robot) [4]. The study in this article was a qualitative case study of 50 children, grades 6, 7, and 8, boys and girls in an after-school 4-H Science Club. The lessons were conducted once per week. The lessons were previously conducted in an all-girls after-school STEM program with similar available inexpensive materials. Both schools had similar demographics. The students and coordinators(instructors) were observed, pre- and post-surveys were conducted, and interviews of both students and coordinators were audio and/or video-taped. Although responses varied by lesson, initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design.;2017;2021-05-19T13:31:31Z;2021-05-19T13:31:31Z;NA;NA;NA;NA;NA;NA;NA;NA;Frontiers in Education Conference;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE ASEE; IEEE Comp Soc; Indian ISSN: 0190-5848 Type: Proceedings Paper";<p>IEEE Frontiers in Education Conference (FIE), Indianapolis, IN, OCT 18-21, 2017</p>;NA;NA;NA;"empathy; design process; after-school science club; engineering; middle school";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathyinmiddleschoolengineeringdesignprocess;empathy in middle school engineering design process this workinprogress studies empathy in middle school engineering design pedagogy a model of empathy in engineering as a core skill as a practice orientation and a professional way of being that can be taught in university programs has been proposed 1 does an emotional intelligence model of empathy need to be taught earlier than at the university level the engineering design process has been included in the science standards for k12 schools since 20132 one of the purposes of this inclusion is the ability to reach a diverse population of students by applying real world problems in their curriculum the design process typically includes the steps of defining the engineering problem developing solutions and optimizing the design although the word empathy is not used these problems are defined from an empathetic perspective as situations people want to change of social and global significance however the standards do not discuss how to define a problem or how to teach empathy in the winter of 2016 a study was conducted to evaluate the influence of empathy based lessons on girls interest in science technology engineering and mathematics stem some information is known about empathy in lessons girls may be more interested if lessons are altered to include an element of caring 3 other studies indicate childrens empathy increases with type of media provided in lesson computer versus robot 4 the study in this article was a qualitative case study of 50 children grades 6 7 and 8 boys and girls in an afterschool 4h science club the lessons were conducted once per week the lessons were previously conducted in an allgirls afterschool stem program with similar available inexpensive materials both schools had similar demographics the students and coordinatorsinstructors were observed pre and postsurveys were conducted and interviews of both students and coordinators were audio andor videotaped although responses varied by lesson initial results indicate many students and coordinators did not understand the meaning of empathy situated in engineering design
NKSK8KC5;conferencePaper;2017;"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile";Stacked Deep Convolutional Auto-Encoders for Emotion Recognition from Facial Expressions;2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN);978-1-5090-6182-2;NA;NA;NA;Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system.;2017;2021-05-19T13:31:32Z;2021-05-19T13:31:32Z;NA;1586-1593;NA;NA;NA;NA;NA;NA;IEEE International Joint Conference on Neural Networks (IJCNN);NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Neurol Network Soc; IEEE Computat Intelligence Soc; Intel; BMI; Budapest Semester Cognit Sci ISSN: 2161-4393 Type: Proceedings Paper";<p>International Joint Conference on Neural Networks (IJCNN), Anchorage, AK, MAY 14-19, 2017</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;stackeddeepconvolutionalautoencodersforemotionrecognitionfromfacialexpressions;stacked deep convolutional autoencoders for emotion recognition from facial expressions emotion recognition is critical for everyday living and is essential for meaningful interaction if we are to progress towards human and machine interaction that is engaging the human user the machine should be able to recognize the emotional state of the user deep convolutional neural networks cnn have proven to be efficient in emotion recognition problems the good degree of performance achieved by these classifiers can be attributed to their ability to selflearn a downsampled feature vector that retains spatial information through filter kernels in convolutional layers given the view that random initialization of weights can lead to convergence to nonoptimal local minima in this paper we explore the impact of training the initial weights in an unsupervised manner we study the effect of pretraining a deep cnn as a stacked convolutional autoencoder scae in a greedy layerwise unsupervised fashion for emotion recognition using facial expression images when trained with randomly initialized weights our cnn emotion recognition model achieves a performance rate of 9116 on the karolinska directed emotional faces kdef dataset in contrast when each layer of the model including the hidden layer is pretrained as an autoencoder the performance increases to 9252 pretraining our cnn as a scae also reduces training time marginally the emotion recognition model developed in this work will form the basis of a realtime empathic robot system
ZX5F45B5;journalArticle;2017;"Woo, Jinseok; Botzheim, Janos; Kubota, Naoyuki";EMOTIONAL EMPATHY MODEL FOR ROBOT PARTNERS USING RECURRENT SPIKING NEURAL NETWORK MODEL WITH HEBBIAN-LMS LEARNING;MALAYSIAN JOURNAL OF COMPUTER SCIENCE;NA;0127-9084;NA;NA;This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply “Hebbian-LMS” learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner “iPhonoid-C”. Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.;2017;2021-05-19T13:31:32Z;2021-05-19T13:31:32Z;NA;258-285;NA;4;30;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA Publisher: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH Type: Article;NA;NA;NA;NA;"Conversation System; Emotional Empathy Model; Hebbian-LMS Learning; Recurrent Spiking Neural Network; Robot Partner";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionalempathymodelforrobotpartnersusingrecurrentspikingneuralnetworkmodelwithhebbianlmslearning;emotional empathy model for robot partners using recurrent spiking neural network model with hebbianlms learning this paper discusses the development of an emotion model for robot partner system in our previous studies we have focused only on the robots emotional state however the emotional state of the other party is also an important factor for smooth conversation in human society therefore the robot partner has two emotional structures for human empathy and robot emotion first human empathy uses a perceptual based emotion model to know the humans emotional state based on the sensory information next we propose a recurrent simple spike response model to improve the robots emotional model and we apply hebbianlms learning to modify the weights in the spiking neural network the robots emotional state is calculated by using the humans emotional information internal and external information the robot partner can use the emotional results to control the facial and gesture expression the utterance style is also changed by the robots emotional state as a result the robot partner can interact emotionally and naturally with human first we explain the related works and the development of the robot partner iphonoidc next we define the architecture of the emotional model to realize emotional empathy towards human then we discuss the algorithms and the methods for developing the emotional model finally we show experimental results of the proposed method and discuss the effectiveness of the proposed structure
8DFICJ9C;conferencePaper;2017;Pareto, Lena;Robot as Tutee;ROBOTICS IN EDUCATION: RESEARCH AND PRACTICES FOR ROBOTICS IN STEM EDUCATION;978-3-319-42975-5 978-3-319-42974-8;NA;10.1007/978-3-319-42975-5_24;NA;"This paper explores the possible advantages of substituting teachable agents in a learning environment, with a humanoid robot as the non-human tutee. Teachable agents are used as an extension to educational games in order to leverage engagement, reflection and learning. The learning environment is engaging and shown to be effective for learning and promote self-efficacy in experimental studies in authentic classroom settings. Features beneficial for learning which are further enhanced by a robot compared to an agent are identified. These include embodiment of the robot; a social, empathic behaviour, better conversational abilities which together provide a better role model of an ideal learner for the student to identify with.";2017;2021-05-19T13:31:34Z;2021-05-19T13:31:34Z;NA;271-277;NA;NA;457;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>7th International Conference on Robotics in Education (RiE), Vienna, AUSTRIA, APR 14-15, 2016</p>;NA;NA;NA;"Robotics; Tutoring; Robot tutee; Role-model learner; Teachable agent";Merdan, M and Lepuschitz, W and Koppensteiner, G and Balogh, R;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotastutee;robot as tutee this paper explores the possible advantages of substituting teachable agents in a learning environment with a humanoid robot as the nonhuman tutee teachable agents are used as an extension to educational games in order to leverage engagement reflection and learning the learning environment is engaging and shown to be effective for learning and promote selfefficacy in experimental studies in authentic classroom settings features beneficial for learning which are further enhanced by a robot compared to an agent are identified these include embodiment of the robot a social empathic behaviour better conversational abilities which together provide a better role model of an ideal learner for the student to identify with
75L8CF64;conferencePaper;2017;"Fan, Lisa; Scheutz, Matthias; Lohani, Monika; Mccoy, Marissa; Stokes, Charlene";Do We Need Emotionally Intelligent Artificial Agents? First Results of Human Perceptions of Emotional Intelligence in Humans Compared to Robots;IN℡LIGENT VIRTUAL AGENTS, IVA 2017;978-3-319-67401-8 978-3-319-67400-1;NA;10.1007/978-3-319-67401-8_15;NA;Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent's emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them.;2017;2021-05-19T13:31:37Z;2021-05-19T13:31:37Z;NA;129-141;NA;NA;10498;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;Backup Publisher: KTH Royal Inst Technol ISSN: 0302-9743 Type: Proceedings Paper;"<p>17th International Conference on Intelligent Virtual Agents (IVA), Swedish Natl Museum Sci &amp; Technol, Stockholm, SWEDEN, AUG 27-30, 2017</p>";NA;NA;NA;"emotional intelligence; Human-robot interaction; empathetic robot";Beskow, J and Peters, C and Castellano, G and OSullivan, C and Leite, I and Kopp, S;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;doweneedemotionallyintelligentartificialagentsfirstresultsofhumanperceptionsofemotionalintelligenceinhumanscomparedtorobots;do we need emotionally intelligent artificial agents first results of human perceptions of emotional intelligence in humans compared to robots humans are very apt at reading emotional signals in other humans and even artificial agents which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions for artificial agents without emotional intelligence might generate behavior that is misinterpreted unexpected and confusing to humans violating human expectations and possibly causing emotional harm surprisingly there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions here we present the first study in the perception of emotional intelligence ei in robots vs humans the objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments study participants were shown a scene in which either a robot or a human behaved with either high or low empathy and then they were asked to evaluate the agents emotional intelligence and trustworthiness the results showed that participants could consistently distinguish the high ei condition from the low ei condition regardless of the variations in which communication methods were observed and that whether the agent was a robot or human had no effect on the perception we also found that relative to low ei high ei conditions led to greater trust in the agent which implies that we must design robots to be emotionally intelligent if we wish for users to trust them
E9AA9F36;conferencePaper;2017;"Bin Siddique, Farhad; Kampman, Onno; Yang, Yang; Dey, Anik; Fung, Pascale";Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent;PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS;978-1-945626-71-5;NA;10.18653/v1/P17-4021;NA;Virtual agents need to adapt their personality to the user in order to become more empathetic. To this end, we developed Zara the Supergirl, an interactive empathetic agent, using a modular approach. In this paper, we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks. From raw audio, an average F-score of 69.6 was obtained from real-time personality assessment using a Convolutional Neural Network (CNN) model. From text, we improved personality recognition results with a CNN model on top of pre-trained word embeddings and obtained an average F-score of 71.0. Results from our Human-Agent Interaction study confirmed our assumption that people have different agent personality preferences. We use insights from this study to adapt our agent to user personality.;2017;2021-05-19T13:31:38Z;2021-05-19T13:31:38Z;NA;121-126;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTATIONAL LINGUISTICS-ACL;209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Alibaba Grp; Amazon; Apple; Baidu; Bloomberg; Facebook; Google; Samsung; Tencent; eBay; Elsevier; IBM Res; KPMG; Maluuba; Microsoft; Naver Line; NEC; Recruit Inst Technol; SAP; Adobe; Bosch; CVTE; Duolingo; Huawei; Nuance; Oracle; Sogou; Grammarly; Toutiao; Yandex Type: Proceedings Paper";<p>55th Annual Meeting of the Association-for-Computational-Linguistics (ACL), Vancouver, CANADA, JUL 30-AUG 04, 2017</p>;NA;NA;NA;NA;Bansal, M and Ji, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;zarareturnsimprovedpersonalityinductionandadaptationbyanempatheticvirtualagent;zara returns improved personality induction and adaptation by an empathetic virtual agent virtual agents need to adapt their personality to the user in order to become more empathetic to this end we developed zara the supergirl an interactive empathetic agent using a modular approach in this paper we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks from raw audio an average fscore of 696 was obtained from realtime personality assessment using a convolutional neural network cnn model from text we improved personality recognition results with a cnn model on top of pretrained word embeddings and obtained an average fscore of 710 results from our humanagent interaction study confirmed our assumption that people have different agent personality preferences we use insights from this study to adapt our agent to user personality
PAFNX8SK;journalArticle;2016;"Mazzei, Daniele; De Maria, Carmelo; Vozzi, Giovanni";Touch sensor for social robots and interactive objects affective interaction;SENSORS AND ACTUATORS A-PHYSICAL;NA;0924-4247;10.1016/j.sna.2016.10.006;NA;The recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human robot affective interaction. Most of these sensors, implemented as matrix of pressure sensors, are rigid, cannot be fabricated in complex shapes, cannot be subjected to large deformations, and usually allow to capture only the contact event, without any information about the interaction context. This paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns. The sensor is made of alternate layers of sensitive and insulating silicone: the soft nature of the sensor makes it adaptable to complex and deformable bodies. The main features from electrical signals are extracted with the principal component analysis, and a self-organising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture. The results open to interesting applications, which span from toy manufacturing, to human-robot interaction, and even to sport and biomedical equipment and applications. (C) 2016 Elsevier B.V. All rights reserved.;2016-11-01;2021-05-19T13:31:40Z;2021-05-19T13:31:40Z;NA;92-99;NA;NA;251;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 564, 1001 LAUSANNE, SWITZERLAND Publisher: ELSEVIER SCIENCE SA Type: Article;NA;NA;NA;NA;"Affective robotics; Flexible silicone sensor; Tactile interaction; Touch sensor";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;touchsensorforsocialrobotsandinteractiveobjectsaffectiveinteraction;touch sensor for social robots and interactive objects affective interaction the recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human robot affective interaction most of these sensors implemented as matrix of pressure sensors are rigid cannot be fabricated in complex shapes cannot be subjected to large deformations and usually allow to capture only the contact event without any information about the interaction context this paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns the sensor is made of alternate layers of sensitive and insulating silicone the soft nature of the sensor makes it adaptable to complex and deformable bodies the main features from electrical signals are extracted with the principal component analysis and a selforganising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture the results open to interesting applications which span from toy manufacturing to humanrobot interaction and even to sport and biomedical equipment and applications c 2016 elsevier bv all rights reserved
G2CYVWUK;journalArticle;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji; Masato, Koike";Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot;BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES;NA;2212-683X;10.1016/j.bica.2016.09.004;NA;"Companion or `pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like `emotion' and based on emotional intelligence (El) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. (C) 2016 Elsevier B.V. All rights reserved.";2016-10;2021-05-19T13:31:40Z;2021-05-19T13:31:40Z;NA;51-67;NA;NA;18;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article;NA;NA;NA;NA;"Behavior; Human-robot interaction; Emotional intelligence; Companion robot; Consciousness based architecture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;intelligentemotionandbehaviorbasedontopologicalconsciousnessandadaptiveresonancetheoryinacompanionrobot;intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot companion or pet robots can be expected to be an important part of a future in which robots contribute to our lives in many ways an understanding of emotional interactions would be essential to such robots behavior to improve the cognitive and behavior systems of such robots we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation including a biologically inspired emotion system a fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot this paper focuses on three points in the development of our proposed framework 1 the organization of the behavior including insidestate emotion regarding the phylogenetic consciousnessbased architecture 2 a method whereby the robot can have empathy toward its human users expressions of emotion and 3 a method that enables the robot to select a facial expression in response to the human user providing instant humanlike emotion and based on emotional intelligence el that uses a biologically inspired topological online method to express for example encouragement or being delighted we also demonstrate the performance of the artificial consciousness based on the complexity level and a robots social expressions that are designed to enhance the users affinity with the robot c 2016 elsevier bv all rights reserved
Y2K9XBWS;journalArticle;2016;"Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge";Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns;IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE IN℡LIGENCE;NA;0162-8828;10.1109/TPAMI.2015.2496209;NA;Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading). The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.;2016-08;2021-05-19T13:31:42Z;2021-05-19T13:31:42Z;NA;1679-1691;NA;8, SI;38;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA Publisher: IEEE COMPUTER SOC Type: Article;NA;NA;NA;NA;"Bayesian approach; frequency domain; human movement analysis; social role; Social signal processing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;probabilisticsocialbehavioranalysisbyexploringbodymotionbasedpatterns;probabilistic social behavior analysis by exploring body motionbased patterns understanding human behavior through nonverbalbased features is interesting in several applications such as surveillance ambient assisted living and humanrobot interaction in this article in order to analyze human behaviors in social context we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation the novelty of this method is that we analyze body motionbased features in frequency domain to estimate different human social patterns interpersonal behaviors ibs and a social role sr to analyze the dynamics and interrelations of peoples body motions a human movement descriptor is used to extract discriminative features and a multilayer dynamic bayesian network dbn technique is proposed to model the existent dependencies laban movement analysis lma is a wellknown human movement descriptor which provides efficient midlevel information of human body motions the midlevel information is useful to extract the complex interdependencies the dbn technique is tested in different scenarios to model the mentioned complex dependencies the study is applied for obtaining four ibs interest indicator empathy and emphasis to estimate one sr leading the obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in humanrobot interaction
YN73ZWQM;conferencePaper;2016;"Fung, Pascale; Dey, Anik; Bin Siddique, Farhad; Lin, Ruixi; Yang, Yang; Yan, Wan; Yin, Ricky Chan Ho";Zara: An Empathetic Interactive Virtual Agent;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;NA;NA;Zara, or `Zara the Supergirl', is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented human robot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015.;2016;2021-05-19T13:31:43Z;2021-05-19T13:31:43Z;NA;1176-1177;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"emotion recognition; human-computer interaction; speech recognition; empathy module";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;zaraanempatheticinteractivevirtualagent;zara an empathetic interactive virtual agent zara or zara the supergirl is a virtual robot that can show empathy while interacting with an user and at the end of a 510 minute conversation it can give a personality analysis based on the user responses it can display and share emotions with the aid of its built in sentiment analysis facial and emotion recognition and speech module being the first of its kind it has successfully integrated an empathetic system along with the human emotion recognition and sharing into an augmented human robot interaction system zara was also displayed at the world economic forum held at dalian in september 2015
UM9PVKJ8;conferencePaper;2016;"Gibson, James; Can, Dogan; Xiao, Bo; Imel, Zac E.; Atkins, David C.; Georgiou, Panayiotis; Narayanan, Shrikanth";A Deep Learning Approach to Modeling Empathy in Addiction Counseling;17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES;978-1-5108-3313-5;NA;10.21437/Interspeech.2016-554;NA;Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics.;2016;2021-05-19T13:31:44Z;2021-05-19T13:31:44Z;NA;1447-1451;NA;NA;NA;NA;NA;NA;Interspeech;NA;NA;NA;ISCA-INT SPEECH COMMUNICATION ASSOC;C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper";<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>;NA;NA;NA;"behavioral signal processing; motivational interviews; recurrent neural networks; word embedding";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;adeeplearningapproachtomodelingempathyinaddictioncounseling;a deep learning approach to modeling empathy in addiction counseling motivational interviewing is a goaloriented psychotherapy employed in cases such as addiction that aims to help clients explore and resolve their ambivalence about their problem in motivational interviewing it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes in this paper we propose a deep neural network dnn system for predicting counselors session level empathy ratings from transcripts of the interactions first we train a recurrent neural network mapping the text of each speaker turn to a set of taskspecific behavioral acts that represent local dynamics of the clientcounselor interaction subsequently this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating we show that this method outperforms training the dnn endtoend in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics
R266D7YW;conferencePaper;2016;"Egawa, Shoichi; Sejima, Yoshihiro; Sato, Yoichiro; Watanabe, Tomio";A Laughing-driven Pupil Response System for Inducing Empathy;2016 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII);978-1-5090-3329-4;NA;NA;NA;Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.;2016;2021-05-19T13:31:45Z;2021-05-19T13:31:45Z;NA;520-525;NA;NA;NA;NA;NA;NA;IEEE/SICE International Symposium on System Integration;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; SICE; SICE Syst Integrat Div; IEEE Robot & Automat Soc; IEEE ind Elect Soc; Hokkaido Univ, Grad Sch Informat Sci & Technol ISSN: 2474-2317 Type: Proceedings Paper";<p>IEEE/SICE International Symposium on System Integration (SII), Sapporo, JAPAN, DEC 13-15, 2016</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;alaughingdrivenpupilresponsesystemforinducingempathy;a laughingdriven pupil response system for inducing empathy laughing response plays an important role in supporting human interaction and communication and enhances empathy by sharing laughter each other therefore in order to develop communication systems which enhance empathy it is desired to design the media representation using the pupil response which is related to affective response such as pleasureunpleasure in this paper we aim to enhance empathy during human and robot interaction and communication and develop a pupil response system for inducing empathy by laughing response using hemispherical display in addition we evaluate the pupil response with the laughing response by using the developed system the results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy
K8SX755Z;conferencePaper;2016;"Chumkamon, Sakmongkon; Hayashi, Eiji";Social Expression of Pet Robot Based on Artificial Consciousness and Biologically Inspired Online Topological Method;PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON ARTIFICIAL LIFE AND ROBOTICS (ICAROB 2016);978-4-9908350-1-9;NA;NA;NA;The social robot becomes important to the future world of pervasive computing, where the robot currently facilitates our life. The social behavior and natural action of the robot is one of the most needed function for emerging future realistic human-like robot. Our paper proposes the artificial topological consciousness based on a pet robot using the artificial neurotransmitter and motivation. Since, the significant is cross-creature communication to friendly companionship. This system focuses on three points. The first, the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can socially perform its expression to human using biologically inspired topological on-line method for encouragement or being delighted by its own emotion and the human expression. We believe the artificial consciousness based on complexity level and the robot social expression enhance the user affinity by the experiment.;2016;2021-05-19T13:31:46Z;2021-05-19T13:31:46Z;NA;204-207;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ALIFE ROBOTICS CO, LTD;HIG HANDADAI, OITA, 870-1112, JAPAN;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ALife Robot Corp Ltd; Int Conf Artificial Life & Robot, Int Steering Comm; IEEE Fukuoka Sect; IEEE Robot & Automat Soc; Chinese Assoc Artificial Intelligence Type: Proceedings Paper";<p>International Conference on Artificial Life and Robotics (ICAROB), Okinawa, JAPAN, JAN 29-31, 2016</p>;NA;NA;NA;"Consciousness-Based Architecture; Cross-Creature Communication; EQ";Jia, Y and Ito, T and Lee, JJ and Sugisaka, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;socialexpressionofpetrobotbasedonartificialconsciousnessandbiologicallyinspiredonlinetopologicalmethod;social expression of pet robot based on artificial consciousness and biologically inspired online topological method the social robot becomes important to the future world of pervasive computing where the robot currently facilitates our life the social behavior and natural action of the robot is one of the most needed function for emerging future realistic humanlike robot our paper proposes the artificial topological consciousness based on a pet robot using the artificial neurotransmitter and motivation since the significant is crosscreature communication to friendly companionship this system focuses on three points the first the organization of the behavior and emotion model regarding the phylogenetic the second the method of the robot that can have empathy with user expression the third how the robot can socially perform its expression to human using biologically inspired topological online method for encouragement or being delighted by its own emotion and the human expression we believe the artificial consciousness based on complexity level and the robot social expression enhance the user affinity by the experiment
EMJS4LPV;conferencePaper;2016;"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile";Emotion Recognition Using Facial Expression Images for a Robotic Companion;ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2016;978-3-319-44188-7 978-3-319-44187-0;NA;10.1007/978-3-319-44188-7_6;NA;Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5%. These experiments serve as benchmark for our current research project in the area of social robotics.;2016;2021-05-19T13:31:47Z;2021-05-19T13:31:47Z;NA;79-93;NA;NA;629;NA;NA;NA;Communications in Computer and Information Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 1865-0929 Type: Proceedings Paper;<p>17th International Conference on Engineering Applications of Neural Networks (EANN), Robert Gordon Univ, Aberdeen, SCOTLAND, SEP 02-05, 2016</p>;NA;NA;NA;"Neural networks; Social robots; Emotion recognition; Gabor filter; Image classification; Support Vector Machine";Jayne, C and Iliadis, L;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionrecognitionusingfacialexpressionimagesforaroboticcompanion;emotion recognition using facial expression images for a robotic companion social robots are gradually becoming part of society however social robots lack the ability to adequately interact with users in a natural manner and are in need of more humanlike abilities in this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the kdef database a fundamental first step towards the development of an empathic social robot we compare the performance of support vector machines svm and a multilayer perceptron network mlp on facial expression classification we employ gabor filters as an image preprocessing step before classification our svm model achieves an accuracy rate of 9708  whereas our mlp achieves 935 these experiments serve as benchmark for our current research project in the area of social robotics
AUDACTUN;conferencePaper;2016;"Johnson, Esperanza; Lopez de la Franca, Carlos Gutierrez; Hervas, Ramon; Mondejar, Tania; Bravo, Jose";Analyzing Human-Avatar Interaction with Neurotypical and not Neurotypical Users;UBIQUITOUS COMPUTING AND AMBIENT IN℡LIGENCE, UCAMI 2016, PT I;978-3-319-48746-5 978-3-319-48745-8;NA;10.1007/978-3-319-48746-5_54;NA;Assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues. In this case, we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of Social Communications Disorders (SCD). The designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions, with those emotions changing according to the interactions that the user chooses to perform on the avatar. We have used Blender for the design of the emotions, which are happiness, sadness, surprise, fear and anger, plus a neutral emotion, while Unity was used to dictate the behavior of the avatar when the interactions were performed, which could be positive (caress), negative (poke) or neutral (wait). The avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users, as well as the difference between neurotypical and non-neurotypical users in terms of emotion recognition and chosen interactions. A ground truth has been established in terms of prototypic empathic interactions by the users.;2016;2021-05-19T13:31:47Z;2021-05-19T13:31:47Z;NA;525-536;NA;NA;10069;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Univ Las Palmas Gran Canaria; MAmI Res Grp ISSN: 0302-9743 Type: Proceedings Paper";<p>10th International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI), San Bartolome de Tirajana, SPAIN, NOV 29-DEC 02, 2016</p>;NA;NA;NA;"Empathy; Affective computing; Affective avatar; Cognitive disabilities; Human-avatar interaction; Social communication disorder";Garcia, CR and CaballeroGil, P and Burmester, M and QuesadaArencibia, A;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;analyzinghumanavatarinteractionwithneurotypicalandnotneurotypicalusers;analyzing humanavatar interaction with neurotypical and not neurotypical users assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues in this case we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of social communications disorders scd the designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions with those emotions changing according to the interactions that the user chooses to perform on the avatar we have used blender for the design of the emotions which are happiness sadness surprise fear and anger plus a neutral emotion while unity was used to dictate the behavior of the avatar when the interactions were performed which could be positive caress negative poke or neutral wait the avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users as well as the difference between neurotypical and nonneurotypical users in terms of emotion recognition and chosen interactions a ground truth has been established in terms of prototypic empathic interactions by the users
89993U4Z;conferencePaper;2016;"Sin, Yap Miao Robin; Liang, Qiao; Tani, Koyu; Ogawa, Ken-ichiro; Miyake, Yoshihiro";Evaluation of a Head Motion Synchronization System in the Communicative Process Between Human and Robot;2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE);978-4-907764-50-0;NA;NA;NA;An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.;2016;2021-05-19T13:31:48Z;2021-05-19T13:31:48Z;NA;1514-1519;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;Type: Proceedings Paper;<p>55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE), Tsukuba, JAPAN, SEP 20-23, 2016</p>;NA;NA;NA;"human-robot interaction; Head motion synchronization; mutual entrainment";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;evaluationofaheadmotionsynchronizationsysteminthecommunicativeprocessbetweenhumanandrobot;evaluation of a head motion synchronization system in the communicative process between human and robot an aging population is worldwide social problem which affects many developed and developing countries in this regard many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia however these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered in this research therefore we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot this system was evaluated by conducting oneway facetoface humanrobot communication experiments with young native japanese speakers under three conditions namely unreactive reactive and interactive conditions head motion synchrony analysis revealed a leaderfollower relationship for the reactive model and a mutual entrainment of head motion for the interactive model also questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions in addition the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition hence these indicate that empathy was shared through mutual entrainment of head motion which could provide a smooth interface in humanrobot communication this system would be extended to elderly adults as an assistive system for the elderlys rehabilitation
CBRCN438;conferencePaper;2016;"Li, Chaochao; Jia, Qingxuan; Feng, Yongli";Human-Robot Interactoin Design for Robot-Assisted Intervention for Children with Autism Based on E-S Theory;2016 8TH INTERNATIONAL CONFERENCE ON IN℡LIGENT HUMAN-MACHINE SYSTEMS AND CYBERNETICS (IHMSC), VOL. 2;978-1-5090-0768-4;NA;10.1109/IHMSC.2016.103;NA;The paper presents a novel human-robot interaction (HRI) framework to assist intervention for children with autism, based on Empathizing-Systemizing (E-S) theory. E-S theory explains the social difficulties in autism as the result of deficits or delays in empathizing, while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing. In this paper, the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robot-assisted intervention, which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism. The design of HRI scenarios and tasks based on E-S theory makes the robot-assisted intervention more effective and efficient.;2016;2021-05-19T13:31:49Z;2021-05-19T13:31:49Z;NA;320-324;NA;NA;NA;NA;NA;NA;International Conference on Intelligent Human-Machine Systems and Cybernetics;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; Univ Bristol; Japan Adv Inst Sci & Technol; Beihang Univ ISSN: 2157-8982 Type: Proceedings Paper";<p>8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), Zhejiang Univ, Hangzhou, PEOPLES R CHINA, SEP 11-12, 2016</p>;NA;NA;NA;"social robot; autism therapy; Human Robot Interaction (HRI); Empathizing-Systemizing (E-S) theory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;humanrobotinteractoindesignforrobotassistedinterventionforchildrenwithautismbasedonestheory;humanrobot interactoin design for robotassisted intervention for children with autism based on es theory the paper presents a novel humanrobot interaction hri framework to assist intervention for children with autism based on empathizingsystemizing es theory es theory explains the social difficulties in autism as the result of deficits or delays in empathizing while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing in this paper the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robotassisted intervention which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism the design of hri scenarios and tasks based on es theory makes the robotassisted intervention more effective and efficient
BHM2MTQK;conferencePaper;2016;"Ranieri, Caetano M.; Romero, Roseli A. F.";An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction;PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016;978-1-5090-3656-1;NA;10.1109/LARS-SBR.2016.13;NA;Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.;2016;2021-05-19T13:31:49Z;2021-05-19T13:31:49Z;NA;31-36;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Brazilian Comp Soc; Centro Estudos Sistemas Avancados Recife; Centro Informatica UFPE; ROBOLIURE; VIRTUS IMPAVIDA; Inst Inovacao; Robolivre; CAPES; Inst SENAI Inovacao; Conselho Nacl Desenvolvimento Cientifico Tecnologico; Fundacao Amparo Ciencia Tecnologia Estado Pernambuco; IEEE Robot & Automat Soc Chapter Brazil; IEEE Latin Amer Robot Council Type: Proceedings Paper";<p>13th Latin American Robotics Symposium / 4th Brazilian Robotics Symposium (LARS/SBR), Recife, BRAZIL, OCT 08-12, 2016</p>;NA;NA;NA;NA;Cavalcante, SV and Tonidandel, F;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anemotionbasedinteractionstrategytoimprovehumanrobotinteraction;an emotionbased interaction strategy to improve humanrobot interaction emotion and empathy are key subjects on humanrobot interaction especially regarding social robots several studies have investigated emotional reactions of humans toward robots while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction this paper presents an emotionaware interaction strategy applied to an embodied virtual agent implemented as an android application the system assigns two distinct paradigms to the virtual character according to the users emotion inferred through facial expressions analysis within subject user experiments have been performed in order to evaluate if the proposed strategy improves empathy and pleasantness
L5YPJQYX;conferencePaper;2016;"Fosch-Villaronga, Eduard; Barco, Alex; Ozcan, Beste; Shukla, Jainendra";An Interdisciplinary Approach to Improving Cognitive Human-Robot Interaction - A Novel Emotion-Based Model;WHAT SOCIAL ROBOTS CAN AND SHOULD DO;978-1-61499-708-5 978-1-61499-707-8;NA;10.3233/978-1-61499-708-5-195;NA;"Socially Assistive Robotics (SAR) aims to provide robot-assisted therapy, for physical as well as cognitive rehabilitation. The paper analyzes two distinct use cases of cognitive rehabilitation therapies, one among involving children with Traumatic Brain Injury (TBI); and another one; second among involving individuals with Intellectual Disability (ID), and raises concerns regarding emotional adaptation, personalization, design, and ELS issues of human-robot interaction in such cases. The paper's aim is to provide some guidance on how social robots should be designed in order to accommodate emotions in HRI as well as to respect the rights of the persons with disabilities. We argue that it is critically important to address the concerns highlighted in order to empower robots with empathetic behavior and to deliver effective cognitive rehabilitation therapies.";2016;2021-05-19T13:31:50Z;2021-05-19T13:31:50Z;NA;195-205;NA;NA;290;NA;NA;NA;Frontiers in Artificial Intelligence and Applications;NA;NA;NA;IOS PRESS;NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Aarhus Univ, Sch Culture & Soc, Res Unit Robophilosophy; Res Network Transdisciplinary Studies Social Robot; Danish Res Council Humanities ISSN: 0922-6389 Type: Proceedings Paper";<p>Conference on Robot Philosophy / TRANSOR Conference on What Social Robots Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016</p>;NA;NA;NA;"emotions; social robots; ELS aspects; human-robot interaction (HRI); social robot design";Seibt, J and Norskov, M and Andersen, SS;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;aninterdisciplinaryapproachtoimprovingcognitivehumanrobotinteractionanovelemotionbasedmodel;an interdisciplinary approach to improving cognitive humanrobot interaction  a novel emotionbased model socially assistive robotics sar aims to provide robotassisted therapy for physical as well as cognitive rehabilitation the paper analyzes two distinct use cases of cognitive rehabilitation therapies one among involving children with traumatic brain injury tbi and another one second among involving individuals with intellectual disability id and raises concerns regarding emotional adaptation personalization design and els issues of humanrobot interaction in such cases the papers aim is to provide some guidance on how social robots should be designed in order to accommodate emotions in hri as well as to respect the rights of the persons with disabilities we argue that it is critically important to address the concerns highlighted in order to empower robots with empathetic behavior and to deliver effective cognitive rehabilitation therapies
UGZQ39RA;conferencePaper;2016;"Deshmukh, Amol; Janarthanam, Srinivasan; Hastie, Helen; Lim, Mei Yii; Aylett, Ruth; Castellano, Ginevra";How Expressiveness of a Robotic Tutor is Perceived by Children in a Learning Environment;ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16);978-1-4673-8369-1;NA;NA;NA;We present a study investigating the expressiveness of two different types of robots in a tutoring task. The robots used were i) the EMYS robot, with facial expression capabilities, and ii) the NAO robot, without facial expressions but able to perform expressive gestures. Preliminary results show that the NAO robot was perceived to be more friendly, pleasant and empathic than the EMYS robot as a tutor in a learning environment.;2016;2021-05-19T13:31:51Z;2021-05-19T13:31:51Z;NA;423-424;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: ACM; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; HFES; AAAI; ACM SIGART ISSN: 2167-2121 Type: Proceedings Paper";<p>11th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Christchurch, NEW ZEALAND, MAR 07-10, 2016</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;howexpressivenessofarobotictutorisperceivedbychildreninalearningenvironment;how expressiveness of a robotic tutor is perceived by children in a learning environment we present a study investigating the expressiveness of two different types of robots in a tutoring task the robots used were i the emys robot with facial expression capabilities and ii the nao robot without facial expressions but able to perform expressive gestures preliminary results show that the nao robot was perceived to be more friendly pleasant and empathic than the emys robot as a tutor in a learning environment
Q8HZ8X6P;conferencePaper;2016;"Bechade, Lucile; Duplessis, Guillaume Dubuisson; Devillers, Laurence";Empirical Study of Humor Support in Social Human-Robot Interaction;DISTRIBUTED, AMBIENT AND PERVASIVE INTERACTIONS, (DAPI 2016);978-3-319-39862-4 978-3-319-39861-7;NA;10.1007/978-3-319-39862-4_28;NA;As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event's context.;2016;2021-05-19T13:31:53Z;2021-05-19T13:31:53Z;NA;305-316;NA;NA;9749;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INT PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>4th International Conference on Distributed, Ambient and Pervasive Interactions (DAPI) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;NA;Streitz, N and Markopoulos, P;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empiricalstudyofhumorsupportinsocialhumanrobotinteraction;empirical study of humor support in social humanrobot interaction as part of the joker project which provides a multimodal dialog system with social skills including humor and empathy this paper explores idea concerning the human verbal responses to a joking robot humor support is defined as the conversational strategies used in reaction to humor utterances this paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus we assume that using humor in humanrobot interaction sets up a positive atmosphere in which participants are willing to contribute this study relies on 49 humanrobot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses the human humor responses elicited through canned jokes and conversational humor were annotated three main categories of human responses were found 1 providing no support 2 recognizing the attempt of humor and 3 contributing with more humor the findings indicate that as in humanhuman interaction strategies of humor support are strongly dependent of the humorous events context
UII28LK6;conferencePaper;2016;"Biswas, Mriganka; Murray, John";The Effects of Cognitive Biases in Long-Term Human-Robot Interactions: Case Studies Using Three Cognitive Biases on MARC the Humanoid Robot;SOCIAL ROBOTICS, (ICSR 2016);978-3-319-47437-3 978-3-319-47436-6;NA;10.1007/978-3-319-47437-3_15;NA;The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant's names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours.;2016;2021-05-19T13:31:53Z;2021-05-19T13:31:53Z;NA;148-158;NA;NA;9979;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper";<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>;NA;NA;NA;"Human-robot interaction; Cognitive bias in robot; Human-robot long-term interactions; Imperfect robot";Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theeffectsofcognitivebiasesinlongtermhumanrobotinteractionscasestudiesusingthreecognitivebiasesonmarcthehumanoidrobot;the effects of cognitive biases in longterm humanrobot interactions case studies using three cognitive biases on marc the humanoid robot the research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing longterm companionship between a robot and human in this paper we discuss how cognitive biases such as misattribution empathy gap and dunningkruger effects can play a role in robothuman interaction with the aim of improving longterm companionship one of the robots used in this study called marc see fig 1 was given a series of biased behaviours such as forgetting participants names denying its own faults for failures unable to understand what a participant is saying etc such fallible behaviours were compared to a nonbiased baseline behaviour in the current paper we present a comparison of two case studies using these biases and a nonbiased algorithm it is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between robots and humans the results of the current experiments show that the participants initially warmed to the robot with the biased behaviours
57ZQF6HC;conferencePaper;2016;"Ojha, Suman; Williams, Mary-Anne";Ethically-Guided Emotional Responses for Social Robots: Should I Be Angry?;SOCIAL ROBOTICS, (ICSR 2016);978-3-319-47437-3 978-3-319-47436-6;NA;10.1007/978-3-319-47437-3_23;NA;Emotions play a critical role in human-robot interaction. Human-robot interaction in social contexts will be more effective if robots can understand human emotions and express (display) emotions accordingly as a means to communicate their own internal state. In this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement. There have been recent advances in developing emotion for robots. However, despite the extensive research on robot emotion, it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation. A key question is - to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity? Realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people, we present a novel Ethical Emotion Generation System (EEGS) for the expression of the most acceptable emotions in social robots.;2016;2021-05-19T13:31:54Z;2021-05-19T13:31:54Z;NA;233-242;NA;NA;9979;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper";<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>;NA;NA;NA;"Social robots; Appraisal theory; Ethical emotion; Appraisal compensation; EEGS";Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ethicallyguidedemotionalresponsesforsocialrobotsshouldibeangry;ethicallyguided emotional responses for social robots should i be angry emotions play a critical role in humanrobot interaction humanrobot interaction in social contexts will be more effective if robots can understand human emotions and express display emotions accordingly as a means to communicate their own internal state in this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement there have been recent advances in developing emotion for robots however despite the extensive research on robot emotion it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation a key question is  to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people we present a novel ethical emotion generation system eegs for the expression of the most acceptable emotions in social robots
XPC9DEAH;conferencePaper;2016;"Giambattista, Angela; Teixeira, Luis; Ayanoglu, Hande; Saraiva, Magda; Duarte, Emilia";Expression of Emotions by a Service Robot: A Pilot Study;DESIGN, USER EXPERIENCE, AND USABILITY: TECHNOLOGICAL CONTEXTS, PT III;978-3-319-40406-6 978-3-319-40405-9;NA;10.1007/978-3-319-40406-6_31;NA;A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot's facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children.;2016;2021-05-19T13:31:55Z;2021-05-19T13:31:55Z;NA;328-336;NA;NA;9748;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>5th International Conference on Design, User Experience, and Usability (DUXU) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>;NA;NA;NA;"Service robot; Human robot interaction; Healthcare; Emotional design; User experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;expressionofemotionsbyaservicerobotapilotstudy;expression of emotions by a service robot a pilot study a successful humanrobot interaction hri depends on the empathy that the robot has the capability of instantiating on the user namely through the expression of emotions in this pilot study we examined the recognition of emotions being expressed by a service robot in a virtual environment ve by university students the ve was a corridor neutral in terms of context of use the robots facial expressions body movements and displacement were manipulated to express eight basic emotions results showed that participants had difficulties in recognizing the emotions 33 of success also results suggested that the participants established empathy with the robot further work is needed to improve the emotional expression of this robot which aims to interact with hospitalized children
CB5P8G8Q;conferencePaper;2016;"Sorbello, Rosario; Chella, Antonio; Giardina, Marcello; Nishio, Shuichi; Ishiguro, Hiroshi";An Architecture for Telenoid Robot as Empathic Conversational Android Companion for Elderly People;IN℡LIGENT AUTONOMOUS SYSTEMS 13;978-3-319-08338-4 978-3-319-08337-7;NA;10.1007/978-3-319-08338-4_68;NA;In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic human-android interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user.;2016;2021-05-19T13:31:56Z;2021-05-19T13:31:56Z;NA;939-953;NA;NA;302;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;Backup Publisher: Univ Padova ISSN: 2194-5357 Type: Proceedings Paper;<p>13th International Conference on Intelligent Autonomous Systems (IAS), Centro Congressi Padova, Padova, ITALY, JUL 15-18, 2014</p>;NA;NA;NA;"Humanoid robot; Humanoid robot interaction; Life support empathic robot; Telenoid";Menegatti, E and Michael, N and Berns, K and Yamaguchi, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anarchitecturefortelenoidrobotasempathicconversationalandroidcompanionforelderlypeople;an architecture for telenoid robot as empathic conversational android companion for elderly people in humanhumanoid interaction hhi empathy is the crucial key in order to overcome the current limitations of social robots in facts a principal defining characteristic of human social behaviour is empathy the present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction we start from the hypothesis that the robots in order to become personal companions need to know how to empathic interact with human beings to validate our research we have used the proposed system with the minimalistic humanoid robot telenoid we have conducted humanrobot interactions test with elderly people with no prior interaction experience with robot during the experiment elderly persons engaged a stimulated conversation with the humanoid robot our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings the experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user
49YLLKTT;conferencePaper;2016;"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia";Affect-Aware Student Models for Robot Tutors;AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS;978-1-4503-4239-1;NA;NA;NA;Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.;2016;2021-05-19T13:32:01Z;2021-05-19T13:32:01Z;NA;864-872;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Int Fdn Autonomous Agents & Multiagent Syst; Natl Sci Fdn; Artificial Intelligence Journal; Springer; Unicen; Sumitomo Elect; Living Analyt Res Ctr; Panasonic R & D Ctr Singapore; Assoc Comp Machinery Special Interest Grp Artificial Intelligence; Assoc Comp Machinery Type: Proceedings Paper";<p>15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Singapore, SINGAPORE, MAY 09-10, 2016</p>;NA;NA;NA;"affective computing; child-robot interaction; socially assistive robots; educational robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;affectawarestudentmodelsforrobottutors;affectaware student models for robot tutors computational tutoring systems such as educational software or interactive robots have the potential for great societal benefit such systems track and assess students knowledge via inferential methods such as the popular bayesian knowledge tracing bkt algorithm however these methods do not typically draw on the affective signals that human teachers use to assess knowledge such as indications of discomfort engagement or frustration in this paper we present a novel extension to the bkt model that uses affective data derived autonomously from video records of children playing an interactive storytelling game with a robot to infer student knowledge of reading skills we find that compared to a control group of children who played the game with only a tablet children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction we then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models these results suggest that physically embodied affectaware robot tutors can provide more effective and empathic educational experiences for children and advance both algorithmic and humancentered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive educational robots
YHZG6FR2;conferencePaper;2016;"Cominelli, Lorenzo; Mazzei, Daniele; Carbonaro, Nicola; Garofalo, Roberto; Zaraki, Abolfazl; Tognetti, Alessandro; De Rossi, Danilo";A Preliminary Framework for a Social Robot “Sixth Sense”;BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2016;978-3-319-42417-0 978-3-319-42416-3;NA;10.1007/978-3-319-42417-0_6;NA;Building a social robot that is able to interact naturally with people is a challenging task that becomes even more ambitious if the robots' interlocutors are children involved in crowded scenarios like a classroom or a museum. In such scenarios, the main concern is enabling the robot to track the subjects' social and affective state modulating its behaviour on the basis of the engagement and the emotional state of its interlocutors. To reach this goal, the robot needs to gather visual and auditory data, but also to acquire physiological signals, which are fundamental for understating the interlocutors' psycho-physiological state. Following this purpose, several Human-Robot Interaction (HRI) frameworks have been proposed in the last years, although most of them have been based on the use of wearable sensors. However, wearable equipments are not the best technology for acquisition in crowded multi-party environments for obvious reasons (e.g., all the subjects should be prepared before the experiment by wearing the acquisition devices). Furthermore, wearable sensors, also if designed to be minimally intrusive, add an extra factor to the HRI scenarios, introducing a bias in the measurements due to psychological stress. In order to overcome this limitations, in this work, we present an unobtrusive method to acquire both visual and physiological signals from multiple subjects involved in HRI. The system is able to integrate acquired data and associate them with unique subjects' IDs. The implemented system has been tested with the FACE humanoid in order to assess integrated devices and algorithms technical features. Preliminary tests demonstrated that the developed system can be used for extending the FACE perception capabilities giving it a sort of sixth sense that will improve the robot empathic and behavioural capabilities.;2016;2021-05-19T13:32:02Z;2021-05-19T13:32:02Z;NA;58-70;NA;NA;9793;NA;NA;NA;Lecture Notes in Computer Science;NA;NA;NA;SPRINGER INTERNATIONAL PUBLISHING AG;GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Future Emerging Technologies, European Unions Framework 7 Program; Heriot Watt Univ ISSN: 0302-9743 Type: Proceedings Paper";<p>5th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Edinburgh, SCOTLAND, JUL 19-22, 2016</p>;NA;NA;NA;"Affective computing; Human-Robot Interaction; Social robotics; Behaviour monitoring; Synthetic tutor";Lepora, NF and Mura, A and Mangan, M and Verschure, PFMJ and Desmulliez, M and Prescott, TJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;apreliminaryframeworkforasocialrobotsixthsense;a preliminary framework for a social robot sixth sense building a social robot that is able to interact naturally with people is a challenging task that becomes even more ambitious if the robots interlocutors are children involved in crowded scenarios like a classroom or a museum in such scenarios the main concern is enabling the robot to track the subjects social and affective state modulating its behaviour on the basis of the engagement and the emotional state of its interlocutors to reach this goal the robot needs to gather visual and auditory data but also to acquire physiological signals which are fundamental for understating the interlocutors psychophysiological state following this purpose several humanrobot interaction hri frameworks have been proposed in the last years although most of them have been based on the use of wearable sensors however wearable equipments are not the best technology for acquisition in crowded multiparty environments for obvious reasons eg all the subjects should be prepared before the experiment by wearing the acquisition devices furthermore wearable sensors also if designed to be minimally intrusive add an extra factor to the hri scenarios introducing a bias in the measurements due to psychological stress in order to overcome this limitations in this work we present an unobtrusive method to acquire both visual and physiological signals from multiple subjects involved in hri the system is able to integrate acquired data and associate them with unique subjects ids the implemented system has been tested with the face humanoid in order to assess integrated devices and algorithms technical features preliminary tests demonstrated that the developed system can be used for extending the face perception capabilities giving it a sort of sixth sense that will improve the robot empathic and behavioural capabilities
T7WVJQZ3;journalArticle;2015;"Suzuki, Yutaka; Galli, Lisa; Ikeda, Ayaka; Itakura, Shoji; Kitazaki, Michiteru";Measuring empathy for human and robot hand pain using electroencephalography;SCIENTIFIC REPORTS;NA;2045-2322;10.1038/srep15924;NA;This study provides the first physiological evidence of humans' ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.;2015-11-03;2021-05-19T13:32:04Z;2021-05-19T13:32:04Z;NA;NA;NA;NA;5;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;measuringempathyforhumanandrobothandpainusingelectroencephalography;measuring empathy for human and robot hand pain using electroencephalography this study provides the first physiological evidence of humans ability to empathize with robot pain and highlights the difference in empathy for humans and robots we performed electroencephalography in 15 healthy adults who observed either human or robothand pictures in painful or nonpainful situations such as a finger cut by a knife we found that the descending phase of the p3 component was larger for the painful stimuli than the nonpainful stimuli regardless of whether the hand belonged to a human or robot in contrast the ascending phase of the p3 component at the frontalcentral electrodes was increased by painful human stimuli but not painful robot stimuli though the interaction of anova was not significant but marginal these results suggest that we empathize with humanoid robots in late topdown processing similarly to human others however the beginning of the topdown process of empathy is weaker for robots than for humans
SIIXSLNX;journalArticle;2015;"Han, Jeonghye; Jo, Miheon; Hyun, Eunja; So, Hyo-jeong";Examining young children's perception toward augmented reality-infused dramatic play;ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT;NA;1042-1629;10.1007/s11423-015-9374-9;NA;Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children's satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children's perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5-6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children's perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed.;2015-06;2021-05-19T13:32:05Z;2021-05-19T13:32:05Z;NA;455-474;NA;3;63;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Augmented reality; Dramatic play; Educational robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;examiningyoungchildrensperceptiontowardaugmentedrealityinfuseddramaticplay;examining young childrens perception toward augmented realityinfused dramatic play amid the increasing interest in applying augmented reality ar in educational settings this study explores the design and enactment of an arinfused robot system to enhance childrens satisfaction and sensory engagement with dramatic play activities in particular we conducted an exploratory study to empirically examine childrens perceptions toward the computer and robotmediated ar systems designed to make dramatic play activities interactive and participatory a multidisciplinary expert group consisting of early childhood education experts preschool teachers ar specialists and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play the experiment was conducted in a kindergarten setting in korea with 81 children aged 56 years old the participants were placed either in the computermediated ar condition n  40 or the robotmediated ar condition n  41 we administered an instrument to measure childrens perceived levels of the following variables a satisfaction ie interest in dramatic play  userfriendliness b sensory immersion ie selfengagement environmentengagement  interactionengagement and c media recognition ie collaboration with media media function  empathy with media data analysis indicates that children in the robotmediated condition showed significantly higher perceptions than those in the computermediated condition regarding the following aspects interest in dramatic play satisfaction interactive engagement sensory immersion and empathy with media media recognition furthermore it was found that the youngeraged children and girls in particular perceived arinfused dramatic play more positively than the olderaged children and boys respectively the contribution of this study is to provide empirical evidence about the affordances of robots and arbased learning systems for young children this remains a relatively unexplored area of research in the field of learning technologies implications of the current study and future research directions are also discussed
3A6EMT4M;journalArticle;2015;"de Borst, Aline W.; de Gelder, Beatrice";Is it the real deal? Perception of virtual characters versus humans: an affective cognitive neuroscience perspective;FRONTIERS IN PSYCHOLOGY;NA;1664-1078;10.3389/fpsyg.2015.00576;NA;Recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film, avatars, or androids. These stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control. While avatars and androids are well suited to study human cognition, they should not be equated to human stimuli. For example, the uncanny valley hypothesis theorizes that artificial agents with high human-likeness may evoke feelings of eeriness in the human observer. Here we review if, when, and how the perception of human-like avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies. First, we discuss how the appearance of virtual characters affects perception. When stimuli are morphed across categories from non-human to human, the most ambiguous stimuli, rather than the most human-like stimuli, show prolonged classification times and increased eeriness. Human-like to human stimuli show a positive linear relationship with familiarity. Secondly, we show that expressions of emotions in human-like avatars can be perceived similarly to human emotions, with corresponding behavioral, physiological and neuronal activations, with exception of physical dissimilarities. Subsequently, we consider if and when one perceives differences in action representation by artificial agents versus humans. Motor resonance and predictive coding models may account for empirical findings, such as an interference effect on action for observed human-like, natural moving characters. However, the expansion of these models to explain more complex behavior, such as empathy, still needs to be investigated in more detail. Finally, we broaden our outlook to social interaction, where virtual reality stimuli can be utilized to imitate complex social situations.;2015-05-12;2021-05-19T13:32:06Z;2021-05-19T13:32:06Z;NA;NA;NA;NA;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Review;NA;NA;NA;NA;"fMRI; virtual reality; social interaction; uncanny valley; action perception; emotion perception; naturalistic stimuli; virtual characters";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;isittherealdealperceptionofvirtualcharactersversushumansanaffectivecognitiveneuroscienceperspective;is it the real deal perception of virtual characters versus humans an affective cognitive neuroscience perspective recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film avatars or androids these stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control while avatars and androids are well suited to study human cognition they should not be equated to human stimuli for example the uncanny valley hypothesis theorizes that artificial agents with high humanlikeness may evoke feelings of eeriness in the human observer here we review if when and how the perception of humanlike avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies first we discuss how the appearance of virtual characters affects perception when stimuli are morphed across categories from nonhuman to human the most ambiguous stimuli rather than the most humanlike stimuli show prolonged classification times and increased eeriness humanlike to human stimuli show a positive linear relationship with familiarity secondly we show that expressions of emotions in humanlike avatars can be perceived similarly to human emotions with corresponding behavioral physiological and neuronal activations with exception of physical dissimilarities subsequently we consider if and when one perceives differences in action representation by artificial agents versus humans motor resonance and predictive coding models may account for empirical findings such as an interference effect on action for observed humanlike natural moving characters however the expansion of these models to explain more complex behavior such as empathy still needs to be investigated in more detail finally we broaden our outlook to social interaction where virtual reality stimuli can be utilized to imitate complex social situations
SY9974KU;journalArticle;2015;"Mirnig, Nicole; Strasser, Ewald; Weiss, Astrid; Kuehnlenz, Barbara; Wollherr, Dirk; Tscheligi, Manfred";Can You Read My Face? A Methodological Variation for Assessing Facial Expressions of Robotic Heads;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0261-z;NA;Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants' dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach.;2015-02;2021-05-19T13:32:08Z;2021-05-19T13:32:08Z;NA;63-76;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Human-robot interaction; Social robots; Facial expressions; Robot emotions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;canyoureadmyfaceamethodologicalvariationforassessingfacialexpressionsofroboticheads;can you read my face a methodological variation for assessing facial expressions of robotic heads our paper reports about an online study on robot facial expressions on the one hand we performed this study to assess the quality of the current facial expressions of two robot heads on the other hand we aimed at developing a simple easytouse methodological variation to evaluate facial expressions of robotic heads short movie clips of two different robot heads showing a happy sad surprised and neutral facial expression were compiled into an online survey to examine how people interpret these expressions additionally we added a control condition with a human face showing the same four emotions the results showed that the facial expressions could be recognized well for both heads even the blender emotion surprised was recognized although it resulted in positive and negative connotations these results underline the importance of the situational context to correctly interpret emotional facial expressions besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads the more humanlike designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animallike features in terms of the validation procedure we could provide evidence for a feasible twostep procedure by assessing the participants dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion in subsequence robot facial expressions can be validated with a closedquestion approach
VJYRYEWZ;journalArticle;2015;"Tisseron, Serge; Tordo, Frederic; Baddoura, Ritta";Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0268-5;NA;The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.;2015-02;2021-05-19T13:32:09Z;2021-05-19T13:32:09Z;NA;97-102;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Psychology; Human-robot interaction; Auto-empathy; Direct empathy; Empathy with robots; Intersubjective empathy; Reciprocal empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;testingempathywithrobotsamodelinfourdimensionsandsixteenitems;testing empathy with robots a model in four dimensions and sixteen items the fourdimensional model of empathy presented in this paper addresses humanhuman humanavatar and humanrobot interaction and aims at better understanding the specificities of the empathy that humans might develop towards robots its first dimension is autoempathy and refers to an empathetic relationship with oneself how can a human directing a robot expand the various components of empathy he feels for himself to this robot the second is direct empathy what does a human attribute to a robot in terms of thoughts emotions action potentials or even altruism on the model of what he imagines and attributes to himself the third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me feel or guess my emotions and thoughts anticipate my actions and wear me assistance if necessary finally the fourth dimension intersubjective empathy is about thinking and imagining that a robot can inform me of things  emotions thoughts that i am likely to experience that i do not know about myself each of these four dimensions includes four different components 1 action empathy of action 2 emotion emotional empathy 3 cognition cognitive empathy and 4 assistance empathy of assistance this theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving humanhuman and humanrobot interaction
UTAMVD4W;journalArticle;2015;"Lim, Angelica; Okuno, Hiroshi G.";A Recipe for Empathy Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese;INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS;NA;1875-4791;10.1007/s12369-014-0262-y;NA;Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (”flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence.;2015-02;2021-05-19T13:32:10Z;2021-05-19T13:32:10Z;NA;35-49;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article;NA;NA;NA;NA;"Developmental robotics; Emotional contagion based on SIRE model; MEI robot; Robot empathy";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;arecipeforempathyintegratingthemirrorsysteminsulasomatosensorycortexandmotherese;a recipe for empathy integrating the mirror system insula somatosensory cortex and motherese could a robot feel authentic empathy what exactly is empathy and why do most humans have it we present a model which suggests that empathy is an emergent behavior with four main elements a mirror neuron system somatosensory cortices an insula and infantdirected baby talk or motherese to test our hypothesis we implemented a robot called mei multimodal emotional intelligence with these functions and allowed it to interact with human caregivers using comfort and approval motherese the first kinds of vocalizations heard by infants at 3 and 6 months of age the robot synchronized in realtime to the humans through voice and movement dynamics while training statistical models associated with its low level gut feeling flourishing or distress based on battery or temperature experiments show that the postinteraction robot associates novel happy voices with physical flourishing 90  of the time sad voices with distress 84  of the time our results also show that a robot trained with infantdirected attention bids can recognize adult fear voices importantly this is the first emotion system to recognize adult emotional voices after training only with motherese suggesting that this specific parental behavior may help build emotional intelligence
6TR84DP7;conferencePaper;2015;"Chumkamon, Sakmongkon; Masato, Koike; Hayashi, Eiji";Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot;2015 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2015): BIG DATA ANALYTICS FOR HUMAN-CENTRIC SYSTEMS;978-1-4799-8696-5;NA;10.1109/SMC.2015.45;NA;This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).;2015;2021-05-19T13:32:12Z;2021-05-19T13:32:12Z;NA;185-190;NA;NA;NA;NA;NA;NA;IEEE International Conference on Systems Man and Cybernetics Conference Proceedings;NA;NA;NA;IEEE COMPUTER SOC;10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Comp Soc; IEEE Syst Man & Cybernet Soc; Hong Kong Polytechn Univ; K C Wong Fdn ISSN: 1062-922X Type: Proceedings Paper";<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), City Univ Hong Kong, Hong Kong, PEOPLES R CHINA, OCT 09-12, 2015</p>;NA;NA;NA;"CBA; Facial Expression Recognition; Human-Robot Interactio; Social Robot; component";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;facialexpressionofsocialinteractionbasedonemotionalmotivationofanimalrobot;facial expression of social interaction based on emotional motivation of animal robot this paper aims to develop the research based on a pet robot and its artificial consciousness we propose the animal behavior and emotion using the artificial neurotransmitter and motivation this research still implements the communication between human and a pet robot respecting to a social cognitive and interaction thus the development of crosscreature communication is crucial for friendly companionship this system focuses on three points the first that is the organization of the behavior and emotion model regarding the phylogenesis the second is the method of the robot that can have empathy with user expression the third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression this paper eventually presents the performance and the experiment that the robot using crossperception and crossexpression between animal robot and social interaction of human communication based on the consciousness based architecture cba
HFHU22DB;conferencePaper;2015;"Vircikova, Maria; Magyar, Gergely; Sincak, Peter";The Affective Loop: A Tool for Autonomous and Adaptive Emotional Human-Robot Interaction;ROBOT IN℡LIGENCE TECHNOLOGY ANDAPPLICATIONS 3;978-3-319-16841-8 978-3-319-16840-1;NA;10.1007/978-3-319-16841-8_23;NA;The paper presents an affective model for social robotics, where the robot is capable of behavior adaptation, in accordance with the needs and preferences of a particular user. The proposed approach differs from other studies in human-robot interaction as these usually have been using the `Wizard of Oz' technique, where a person remotely operates a robot. On the other side, simulated robots are not able of personalized behaviors and behave according to the preprogrammed set of rules. We provide a tool to personalize affective artificial behaviors in cooperative human-robot scenarios, where human emotion recognition, appropriate robotic behavior selection and expression of robotic emotions play a key role. The preliminary experiments show that the personalized affective robotic behavior can achieve better results in a scenario in which a robot motivates children in learning. We believe that human-robot interfaces which mimic how humans interact with one another in an empathic way could ultimately lead to robots being accepted in the wider domain.;2015;2021-05-19T13:32:12Z;2021-05-19T13:32:12Z;NA;247-254;NA;NA;345;NA;NA;NA;Advances in Intelligent Systems and Computing;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 2194-5357 Type: Proceedings Paper;<p>3rd International Conference on Robot Intelligence Technology and Applications, Beijing, PEOPLES R CHINA, NOV 06-08, 2014</p>;NA;NA;NA;"Social Robots; Affective Robotics; Personalization; Social Human-Robot Interaction; Subjective Computing";Kim, JH and Yang, W and Jo, J and Sincak, P and Myung, H;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theaffectiveloopatoolforautonomousandadaptiveemotionalhumanrobotinteraction;the affective loop a tool for autonomous and adaptive emotional humanrobot interaction the paper presents an affective model for social robotics where the robot is capable of behavior adaptation in accordance with the needs and preferences of a particular user the proposed approach differs from other studies in humanrobot interaction as these usually have been using the wizard of oz technique where a person remotely operates a robot on the other side simulated robots are not able of personalized behaviors and behave according to the preprogrammed set of rules we provide a tool to personalize affective artificial behaviors in cooperative humanrobot scenarios where human emotion recognition appropriate robotic behavior selection and expression of robotic emotions play a key role the preliminary experiments show that the personalized affective robotic behavior can achieve better results in a scenario in which a robot motivates children in learning we believe that humanrobot interfaces which mimic how humans interact with one another in an empathic way could ultimately lead to robots being accepted in the wider domain
SQY3D5XK;conferencePaper;2015;"Rasool, Zeeshan; Masuyama, Naoki; Islam, Md. Nazrul; Loo, Chu Kiong";Empathic Interaction using the Computational Emotion Model;2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL IN℡LIGENCE (IEEE SSCI);978-1-4799-7560-0;NA;10.1109/SSCI.2015.26;NA;"This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model; whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.";2015;2021-05-19T13:32:13Z;2021-05-19T13:32:13Z;NA;109-116;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; IEEE Computational Intelligence Soc; IEEE BigData Type: Proceedings Paper";<p>IEEE Symposium Series Computational Intelligence, Cape Town, SOUTH AFRICA, DEC 07-10, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicinteractionusingthecomputationalemotionmodel;empathic interaction using the computational emotion model this paper describes the empathy oriented humanrobot interaction model it is projected to design the model capable of different empathic responses parallel and reactive during the course of interaction with the user depending upon the personality and mood factors of the robot the proposed model encompasses three main stages ie perception empathic appraisal and empathic expression perception refers to capturing users emotion state via facial expression recognition empathic appraisal is based on the computational emotional model for generating its internal emotions mood state and empathic responses the internal emotions are defined using psychological studies and generated on 2d pleasurearousal scaling model whereas fuzzy logic is used to calculate the intensity of the each emotion a virtual facial expression simulator is applied for expression of resultant empathic emotions preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors
CJ88GZ8Z;conferencePaper;2015;"Marti, Patrizia; Iacono, Iolanda";Social and empathic behaviours: novel interfaces and interaction modalities;2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-4673-6704-2;NA;NA;NA;This paper describes the results of a research conducted in the European project Accompany, whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home. The project developed a system consisting of a robotic companion, Care-O-bot, as part of a smart environment. An intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot. The paper is articulated in two parts. The first part illustrates the theory that inspired the development of a context-aware Graphical User Interface (GUI) used to interact with the robot. The GUI integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges. The second part focuses on the user evaluation, and reports the outcomes from three different tests. The results of the first two tests show a positive acceptance of the GUI by the older people. The final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot.;2015;2021-05-19T13:32:14Z;2021-05-19T13:32:14Z;NA;217-222;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper";<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;socialandempathicbehavioursnovelinterfacesandinteractionmodalities;social and empathic behaviours novel interfaces and interaction modalities this paper describes the results of a research conducted in the european project accompany whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home the project developed a system consisting of a robotic companion careobot as part of a smart environment an intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot the paper is articulated in two parts the first part illustrates the theory that inspired the development of a contextaware graphical user interface gui used to interact with the robot the gui integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges the second part focuses on the user evaluation and reports the outcomes from three different tests the results of the first two tests show a positive acceptance of the gui by the older people the final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot
Y86HVEAP;conferencePaper;2015;"Darling, Kate; Nandy, Palash; Breazeal, Cynthia";Empathic concern and the effect of stories in human-robot interaction;2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN);978-1-4673-6704-2;NA;NA;NA;People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.;2015;2021-05-19T13:32:15Z;2021-05-19T13:32:15Z;NA;770-775;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE;345 E 47TH ST, NEW YORK, NY 10017 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper";<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicconcernandtheeffectofstoriesinhumanrobotinteraction;empathic concern and the effect of stories in humanrobot interaction people have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in humanrobot interaction our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it we measure the effects of lifelike movement and stories on peoples hesitation to strike the robot and we evaluate the relationship between hesitation and peoples trait empathy our results show that people with a certain type of high trait empathy empathic concern hesitate to strike the robots we also find that high empathic concern and hesitation are more strongly related for robots with stories this suggests that high trait empathy increases peoples hesitation to strike a robot and that stories may positively influence their empathic responses
8KLULTCA;conferencePaper;2015;"Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani-Sherman, Tal";Design and Evaluation of a Peripheral Robotic Conversation Companion;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696495;NA;We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.;2015;2021-05-19T13:32:18Z;2021-05-19T13:32:18Z;NA;3-10;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"Empathy; Human-robot interaction; Ambient kinetic tangibles; Behavior change; Design; Robotic companions; Smartphone robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designandevaluationofaperipheralroboticconversationcompanion;design and evaluation of a peripheral robotic conversation companion we present the design implementation and evaluation of a peripheral empathyevoking robotic conversation companion kip1 the robots function is to increase peoples awareness to the effect of their behavior towards others potentially leading to behavior change specifically kip1 is designed to promote nonaggressive conversation between people it monitors the conversations nonverbal aspects and maintains an emotional model of its reaction to the conversation if the conversation seems calm kip1 responds by a gesture designed to communicate curious interest if the conversation seems aggressive kip1 responds by a gesture designed to communicate fear we describe the design process of kip1 guided by the principles of peripheral and evocative we detail its hardware and software systems and a study evaluating the effects of the robots autonomous behavior on couples conversations we find support for our design goals a conversation companion reacting to the conversation led to more gaze attention but not more verbal distraction compared to a robot that moves but does not react to the conversation this suggests that robotic devices could be designed as companions to humanhuman interaction without compromising the natural communication flow between people participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them this points to the robots potential to elicit peoples empathy
6V2GZMJ6;conferencePaper;2015;"Hood, Deanna; Lemaignan, Severin; Dillenbourg, Pierre";When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696479;NA;This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced bene fits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.;2015;2021-05-19T13:32:19Z;2021-05-19T13:32:19Z;NA;83-90;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;whenchildrenteacharobottowriteanautonomousteachablehumanoidwhichusessimulatedhandwriting;when children teach a robot to write an autonomous teachable humanoid which uses simulated handwriting this article presents a novel robotic partner which children can teach handwriting the system relies on the learning by teaching paradigm to build an interaction so as to stimulate metacognition empathy and increased selfesteem in the child user we hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student but could also present the opportunity for children to experience physicallyinduced bene fits encountered during humanled handwriting interventions such as motor mimicry by leveraging simulated handwriting on a synchronised tablet display anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner statistical shape models derived from principal component analysis of a dataset of adultwritten letter trajectories allow the robot to draw purposefully deformed letters by incorporating feedback from user demonstrations the system is then able to learn the optimal parameters for the appropriate shape models preliminary in situ studies have been conducted with primary school classes to obtain insight into childrens use of the novel system children aged 68 successfully engaged with the robot and improved its writing to a level which they were satisfied with the validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education
7MHVEEY2;conferencePaper;2015;"Alves-Oliveira, Patricia; Ribeiro, Tiago; Petisca, Sofia; di Tullio, Eugenio; Melo, Francisco S.; Paiva, Ana";An Empathic Robotic Tutor for School Classrooms: Considering Expectation and Satisfaction of Children as End-Users;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_3;NA;Before interacting with a futuristic technology such as a robot, there is a lot of space for the creation of a whole set of expectations towards that interaction. Once that interaction happens, users can be left with a hand full of satisfaction, dissatisfaction, or even a mix of both. To study the possible role of experience as a mediator between expectation and satisfaction, we developed a scale for HRI that measures expectations and satisfaction of the users. Afterwards, we conducted a study with end-users interacting with a social robot. The robot is being developed to be an empathic robotic tutor to be used in real schools, with input from primary end-users (children). Children's expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed. The results can be fed back to the system developers on how well it is being designed for such a target population, and what factors regarding their expectation and satisfaction have shifted after the experience of interaction. By delivering on the children's expectations, we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational environment.;2015;2021-05-19T13:32:20Z;2021-05-19T13:32:20Z;NA;21-30;NA;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;"Human-Robot Interaction; Expectation; Satisfaction; Robotic tutor; User-centered design";Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;anempathicrobotictutorforschoolclassroomsconsideringexpectationandsatisfactionofchildrenasendusers;an empathic robotic tutor for school classrooms considering expectation and satisfaction of children as endusers before interacting with a futuristic technology such as a robot there is a lot of space for the creation of a whole set of expectations towards that interaction once that interaction happens users can be left with a hand full of satisfaction dissatisfaction or even a mix of both to study the possible role of experience as a mediator between expectation and satisfaction we developed a scale for hri that measures expectations and satisfaction of the users afterwards we conducted a study with endusers interacting with a social robot the robot is being developed to be an empathic robotic tutor to be used in real schools with input from primary endusers children childrens expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed the results can be fed back to the system developers on how well it is being designed for such a target population and what factors regarding their expectation and satisfaction have shifted after the experience of interaction by delivering on the childrens expectations we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational environment
CXHJV6YN;conferencePaper;2015;"Fuente, Luis A.; Ierardi, Hannah; Pilling, Michael; Crook, Nigel T.";Influence of Upper Body Pose Mirroring in Human-Robot Interaction;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_22;NA;This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people's perception of their conversation with it. A set of twelve questions about the participants' university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots.;2015;2021-05-19T13:32:21Z;2021-05-19T13:32:21Z;NA;214-223;NA;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;"Empathy; Anthropomorphism; Body-pose mirroring; Rapport";Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;influenceofupperbodyposemirroringinhumanrobotinteraction;influence of upper body pose mirroring in humanrobot interaction this paper explores the effect of upper body pose mirroring in humanrobot interaction a group of participants is used to evaluate how imitation by a robot affects peoples perception of their conversation with it a set of twelve questions about the participants university experience serves as a backbone for the dialogue structure in our experimental evaluation the robot reacts in one of three ways to the human upper body pose ignoring it displaying its own upper body pose and mirroring it the manner in which the robot behaviour influences human appraisal is analysed using the standard godspeed questionnaire our results show that robot body mirroringnonmirroring influences the perceived humanness of the robot the results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots
YKFRAJ9A;conferencePaper;2015;"Pettinati, Michael J.; Arkin, Ronald C.";Towards a Robot Computational Model to Preserve Dignity in Stigmatizing Patient-Caregiver Relationships;SOCIAL ROBOTICS (ICSR 2015);978-3-319-25554-5 978-3-319-25553-8;NA;10.1007/978-3-319-25554-5_53;NA;Parkinson's disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patient-caregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity.;2015;2021-05-19T13:32:24Z;2021-05-19T13:32:24Z;NA;532-542;NA;NA;9388;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;ISSN: 0302-9743 Type: Proceedings Paper;<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>;NA;NA;NA;NA;Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsarobotcomputationalmodeltopreservedignityinstigmatizingpatientcaregiverrelationships;towards a robot computational model to preserve dignity in stigmatizing patientcaregiver relationships parkinsons disease pd patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels our approach to uphold pd patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patientcaregiver interaction this paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during empathetic opportunities in their interaction a pd patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver when this difference falls outside of acceptable set bounds norms the robotic agent will act using subtle nonverbal cues to guide the relationship back within these bounds preserving patient dignity
2TMLMG5P;conferencePaper;2015;"Gil, Pablo; Rossi, Claudio; Coral, William";Biophilic Evolutionary Buildings that Restore the Experience of Animality in the City;BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2015;978-3-319-22979-9 978-3-319-22978-2;NA;10.1007/978-3-319-22979-9_47;NA;In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible - or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa, cade that learns optimal configurations according to the perception of aggressiveness and calmness.;2015;2021-05-19T13:32:25Z;2021-05-19T13:32:25Z;NA;465-472;NA;NA;9222;NA;NA;NA;Lecture Notes in Artificial Intelligence;NA;NA;NA;SPRINGER-VERLAG BERLIN;HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Univ Sheffield; Univ Pompeu Fabra Barcelona; Inst Catalana Recerca Estudis Avancats ISSN: 0302-9743 Type: Proceedings Paper";<p>4th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Barcelona, SPAIN, JUL 28-31, 2015</p>;NA;NA;NA;"Biomimicry; Biophilia; Evolutionary robotics; Intelligent buildings; Wellbeing; Embodied evolution";Wilson, SP and Verschure, PFMJ and Mura, A and Prescott, TJ;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;biophilicevolutionarybuildingsthatrestoretheexperienceofanimalityinthecity;biophilic evolutionary buildings that restore the experience of animality in the city in this paper we present our work on the training of robotised architectural components of intelligent buildings focusing on how architectural components can learn to behave animalistically according to the judgment of human users our work aims at recovering the lost contact with animals in the urban context taking advantage of biophilic empathy the parameters governing the robotised elements we propose are mainly qualitative emotions and aesthetical perception which cannot easily be described by mathematical parameters additionally due to their complexity it is often impossible  or at least impractical to hardcode suitable controllers for such structures thus we propose the use of artificial intelligence learning techniques concretely evolutionary algorithms to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors this idea is tested on an intelligent fa cade that learns optimal configurations according to the perception of aggressiveness and calmness
9BHCNVES;journalArticle;2015;"Lazzeri, Nicole; Mazzei, Daniele; Greco, Alberto; Rotesi, Annalisa; Lanata, Antonio; De Rossi, Danilo Emilio";Can a humanoid face be expressive? A psychophysiological investigation;FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY;NA;2296-4185;10.3389/fbioe.2015.00064;NA;Non-verbal signals expressed through body language play a crucial role in multi-modal human communication during social relations. Indeed, in all cultures, facial expressions are the most universal and direct signs to express innate emotional cues. A human face conveys important information in social interactions and helps us to better understand our social partners and establish empathic links. Latest researches show that humanoid and social robots are becoming increasingly similar to humans, both esthetically and expressively. However, their visual expressiveness is a crucial issue that must be improved to make these robots more realistic and intuitively perceivable by humans as not different from them. This study concerns the capability of a humanoid robot to exhibit emotions through facial expressions. More specifically, emotional signs performed by a humanoid robot have been compared with corresponding human facial expressions in terms of recognition rate and response time. The set of stimuli included standardized human expressions taken from an Ekman-based database and the same facial expressions performed by the robot. Furthermore, participants' psychophysiological responses have been explored to investigate whether there could be differences induced by interpreting robot or human emotional stimuli. Preliminary results show a trend to better recognize expressions performed by the robot than 2D photos or 3D models. Moreover, no significant differences in the subjects' psychophysiological state have been found during the discrimination of facial expressions performed by the robot in comparison with the same task performed with 2D photos and 3D models.;2015;2021-05-19T13:32:28Z;2021-05-19T13:32:28Z;NA;NA;NA;NA;3;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article;NA;NA;NA;NA;"affective computing; social robots; facial expressions; humanoid robot; emotion perception; expression recognition; psychophysiological signals";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;canahumanoidfacebeexpressiveapsychophysiologicalinvestigation;can a humanoid face be expressive a psychophysiological investigation nonverbal signals expressed through body language play a crucial role in multimodal human communication during social relations indeed in all cultures facial expressions are the most universal and direct signs to express innate emotional cues a human face conveys important information in social interactions and helps us to better understand our social partners and establish empathic links latest researches show that humanoid and social robots are becoming increasingly similar to humans both esthetically and expressively however their visual expressiveness is a crucial issue that must be improved to make these robots more realistic and intuitively perceivable by humans as not different from them this study concerns the capability of a humanoid robot to exhibit emotions through facial expressions more specifically emotional signs performed by a humanoid robot have been compared with corresponding human facial expressions in terms of recognition rate and response time the set of stimuli included standardized human expressions taken from an ekmanbased database and the same facial expressions performed by the robot furthermore participants psychophysiological responses have been explored to investigate whether there could be differences induced by interpreting robot or human emotional stimuli preliminary results show a trend to better recognize expressions performed by the robot than 2d photos or 3d models moreover no significant differences in the subjects psychophysiological state have been found during the discrimination of facial expressions performed by the robot in comparison with the same task performed with 2d photos and 3d models
FVWMZN9I;conferencePaper;2015;"Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.";Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot;PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15);978-1-4503-2882-1;NA;10.1145/2696454.2696471;NA;"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.";2015;2021-05-19T13:32:28Z;2021-05-19T13:32:28Z;NA;125-132;NA;NA;NA;NA;NA;NA;ACM IEEE International Conference on Human-Robot Interaction;NA;NA;NA;ASSOC COMPUTING MACHINERY;1515 BROADWAY, NEW YORK, NY 10036-9998 USA;English;NA;NA;NA;NA;NA;NA;"Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper";<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>;NA;NA;NA;"empathy; Human-robot interaction; robot embodiment; simulated interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;poorthingwouldyoufeelsorryforasimulatedrobotacomparisonofempathytowardaphysicalandasimulatedrobot;poor thing would you feel sorry for a simulated robot a comparison of empathy toward a physical and a simulated robot in designing and evaluating humanrobot interactions and interfaces researchers often use a simulated robot due to the high cost of robots and time required to program them however it is important to consider how interaction with a simulated robot differs from a real robot that is do simulated robots provide authentic interaction we contribute to a growing body of work that explores this question and maps out simulatedversusreal differences by explicitly investigating empathy how people empathize with a physical or simulated robot when something bad happens to it our results suggest that people may empathize more with a physical robot than a simulated one a finding that has important implications on the generalizability and applicability of simulated hri work empathy is particularly relevant to social hri and is integral to for example companion and care robots our contribution additionally includes an original and reproducible hri experimental design to induce empathy toward robots in laboratory settings and an experimentally validated empathymeasuring instrument from psychology for use with hri
5G8RIWWW;journalArticle;2021;"Pelau, Corina; Dabija, Dan Cristian; Ene, Irina";what makes an ai device human-like? the role of interaction quality, empathy and perceived psychological anthropomorphic characteristics on the acceptance of artificial intelligence in the service industry;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2021.106855;https://www.sciencedirect.com/science/article/pii/S0747563221001783;intelligent ai devices have become a common presence in the business landscape, offering a wide range of services, from the medical sector to the hospitality industry. from an organizational perspective, ai devices have several advantages, by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more cost-efficient. however, in order to maintain the high standards of a brand, they have to be accepted by consumers and deliver socially adequate performance. therefore, it is important to determine the characteristics of ai devices which make them accepted and trusted by consumers. based on the computers as social actors (casa) theory, we have researched on the role of psychological anthropomorphic characteristics, perceived empathy, and interaction quality in the acceptance of ai devices in the service industry. the results show that anthropomorphic characteristics alone do not influence acceptance and trust towards ai devices. however, both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance. a human-like ai device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer. this result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and ai devices.;2021;2021-05-19T13:19:57Z;2021-05-19T13:19:57Z;NA;106855;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"artificial intelligence; robots; human-computer interaction; anthropomorphism; AI device; computers as social actors; consumer behaviour; human-AI interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;whatmakesanaidevicehumanliketheroleofinteractionqualityempathyandperceivedpsychologicalanthropomorphiccharacteristicsontheacceptanceofartificialintelligenceintheserviceindustry;what makes an ai device humanlike the role of interaction quality empathy and perceived psychological anthropomorphic characteristics on the acceptance of artificial intelligence in the service industry intelligent ai devices have become a common presence in the business landscape offering a wide range of services from the medical sector to the hospitality industry from an organizational perspective ai devices have several advantages by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more costefficient however in order to maintain the high standards of a brand they have to be accepted by consumers and deliver socially adequate performance therefore it is important to determine the characteristics of ai devices which make them accepted and trusted by consumers based on the computers as social actors casa theory we have researched on the role of psychological anthropomorphic characteristics perceived empathy and interaction quality in the acceptance of ai devices in the service industry the results show that anthropomorphic characteristics alone do not influence acceptance and trust towards ai devices however both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance a humanlike ai device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer this result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and ai devices
366NWT4A;journalArticle;2018;Heyes, Cecilia;empathy is not in our genes;Neuroscience & Biobehavioral Reviews;NA;0149-7634;https://doi.org/10.1016/j.neubiorev.2018.11.001;https://www.sciencedirect.com/science/article/pii/S0149763418308194;in academic and public life empathy is seen as a fundamental force of morality – a psychological phenomenon, rooted in biology, with profound effects in law, policy, and international relations. but the roots of empathy are not as firm as we like to think. the matching mechanism that distinguishes empathy from compassion, envy, schadenfreude, and sadism is a product of learning. here i present a dual system model that distinguishes empathy1, an automatic process that catches the feelings of others, from empathy2, controlled processes that interpret those feelings. research with animals, infants, adults and robots suggests that the mechanism of empathy1, emotional contagion, is constructed in the course of development through social interaction. learned matching implies that empathy is both agile and fragile. it can be enhanced and redirected by novel experience, and broken by social change.;2018;2021-05-19T13:19:57Z;2021-05-19T13:19:57Z;NA;499-507;NA;NA;95;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Affective empathy; Mirror neurons; Emotional contagion; Affect mirroring; Associative learning; Empathic understanding; Learned Matching; Self-stimulation; Synchronous emotion";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathyisnotinourgenes;empathy is not in our genes in academic and public life empathy is seen as a fundamental force of morality  a psychological phenomenon rooted in biology with profound effects in law policy and international relations but the roots of empathy are not as firm as we like to think the matching mechanism that distinguishes empathy from compassion envy schadenfreude and sadism is a product of learning here i present a dual system model that distinguishes empathy1 an automatic process that catches the feelings of others from empathy2 controlled processes that interpret those feelings research with animals infants adults and robots suggests that the mechanism of empathy1 emotional contagion is constructed in the course of development through social interaction learned matching implies that empathy is both agile and fragile it can be enhanced and redirected by novel experience and broken by social change
ILKWRYCM;journalArticle;2015;"Balint, Tibor S.; Hall, Ashley";humanly space objects—perception and connection with the observer;Acta Astronautica;NA;0094-5765;https://doi.org/10.1016/j.actaastro.2015.01.010;https://www.sciencedirect.com/science/article/pii/S0094576515000144;expanding humanity into space is an inevitable step in our quest to explore our world. yet space exploration is costly, and the awaiting environment challenges us with extreme cold, heat, vacuum and radiation, unlike anything encountered on earth. thus, the few pioneers who experience it needed to be well protected throughout their spaceflight. the resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life. such connections may occur via sensory inputs, namely vision, touch, sound, smell, and taste. this then follows the process of sensing, interpreting, and recognizing familiar patterns, or learning from new experiences. the desire to connect could even transfer to observed objects, if their movements and characteristics trigger the appropriate desires from the observer. when ordered in a familiar way, for example visual stimuli from lights and movements of an object, it may create a perceived real bond with an observer, and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable. these behavior patterns can be designed into an object and performed autonomously in front of an observer, in our case an astronaut. the experience may introduce multiple responses, including communication, connection, empathy, order, and disorder. while emotions are clearly evoked in the observer and may seem one sided, in effect the object itself provides a decoupled bond, connectivity and communication between the observer and the artist-designer of the object. in this paper we will discuss examples from the field of arts and other domains, including robotics, where human perception through object interaction was explored, and investigate the starting point for new innovative design concepts and future prototype designs, that extend these experiences beyond the boundaries of earth, while taking advantage of remoteness and the zero gravity environment. through a form of emotional connection and design, these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a co-located observer in spaceflight. we conclude that beyond providing creative expressions for humanly contacts, these experiences may also provide further insights into human perception in spaceflight, and could be tested on the international space station, and serve as a stepping-stone towards use on long-duration spaceflight to mars.;2015;2021-05-19T13:19:58Z;2021-05-19T13:19:58Z;NA;129-144;NA;NA;110;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;<p>Dynamics and Control of Space Systems</p>;NA;NA;"Perception; Cognition; Affordances; Design; Art; Cybernetics; Tacit-knowledge";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;humanlyspaceobjectsperceptionandconnectionwiththeobserver;humanly space objectsperception and connection with the observer expanding humanity into space is an inevitable step in our quest to explore our world yet space exploration is costly and the awaiting environment challenges us with extreme cold heat vacuum and radiation unlike anything encountered on earth thus the few pioneers who experience it needed to be well protected throughout their spaceflight the resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life such connections may occur via sensory inputs namely vision touch sound smell and taste this then follows the process of sensing interpreting and recognizing familiar patterns or learning from new experiences the desire to connect could even transfer to observed objects if their movements and characteristics trigger the appropriate desires from the observer when ordered in a familiar way for example visual stimuli from lights and movements of an object it may create a perceived real bond with an observer and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable these behavior patterns can be designed into an object and performed autonomously in front of an observer in our case an astronaut the experience may introduce multiple responses including communication connection empathy order and disorder while emotions are clearly evoked in the observer and may seem one sided in effect the object itself provides a decoupled bond connectivity and communication between the observer and the artistdesigner of the object in this paper we will discuss examples from the field of arts and other domains including robotics where human perception through object interaction was explored and investigate the starting point for new innovative design concepts and future prototype designs that extend these experiences beyond the boundaries of earth while taking advantage of remoteness and the zero gravity environment through a form of emotional connection and design these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a colocated observer in spaceflight we conclude that beyond providing creative expressions for humanly contacts these experiences may also provide further insights into human perception in spaceflight and could be tested on the international space station and serve as a steppingstone towards use on longduration spaceflight to mars
LGYTD4GC;conferencePaper;2020;"Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio";DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI;Proceedings of the International Conference on Advanced Visual Interfaces;978-1-4503-7535-1;NA;10.1145/3399715.3399820;https://doi.org/10.1145/3399715.3399820;Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.;2020;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;NA;NA;NA;NA;NA;NA;NA;AVI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Salerno, Italy;NA;NA;NA;"Computer Vision; Deep Learning; User Emotions; User Experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;delexadeeplearningemotiveexperienceinvestigatingempathichci;delex a deep learning emotive experience investigating empathic hci recent advances in machine learning have unveiled interesting possibilities for realtime investigating about user characteristics and expressions like but not limited to age sex body posture emotions and moods these new opportunities lay the foundations for new hci tools for interactive applications that adopt user emotions as a communication channelthis paper presents an emotion controlled user experience that changes according to user feelings and emotions analysed at runtime aiming at obtaining a preliminary evaluation of the proposed ecosystem a controlled experiment has been performed in an engineering and software development company where 60 people have been involved as volunteers the subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in virtual environments the results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters
MJMNC7X8;conferencePaper;2020;"Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena";Empathic Chatbot Response for Medical Assistance;Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents;978-1-4503-7586-3;NA;10.1145/3383652.3423864;https://doi.org/10.1145/3383652.3423864;Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).;2020;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;NA;NA;NA;NA;NA;NA;NA;IVA '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, Scotland, UK;NA;NA;NA;"empathy; conversational agent; emotion detection; healthcare computing; pattern matching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicchatbotresponseformedicalassistance;empathic chatbot response for medical assistance is it helpful for a medical physical health chatbot to show empathy how can a chatbot show empathy only based on shortterm text conversations we have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation one chatbot was adviceonly and asked only the necessary questions for the diagnosis without responding to the users emotions another chatbot capable of showing empathy responded in a more supportive manner by analyzing the users emotions and generating appropriate responses with a high empathic accuracy using the rope scale questionnaire for empathy perception in a humanrobot interaction our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants n12
5C99JYP7;conferencePaper;2021;"Burns, Rachael Bevill; Seifi, Hasti; Lee, Hyosang; Kuchenbecker, Katherine J.";A Haptic Empathetic Robot Animal for Children with Autism;Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-8290-8;NA;10.1145/3434074.3446352;https://doi.org/10.1145/3434074.3446352;Children with autism and their families could greatly benefit from increased support resources. While robots are already being introduced into autism therapy and care, we propose that these robots could better understand the child's needs and provide enriched interaction if they utilize touch. We present our plans, both completed and ongoing, for a touch-perceiving robot companion for children with autism. We established and validated touch-perception requirements for an ideal robot companion through interviews with 11 autism specialists. Currently, we are evaluating custom fabric-based tactile sensors that enable the robot to detect and identify various touch communication gestures. Finally, our robot companion will react to the child's touches through an emotion response system that will be customizable by a therapist or caretaker.;2021;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;583–585;NA;NA;NA;NA;NA;NA;HRI '21 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boulder, CO, USA;NA;NA;NA;"socially assistive robotics; robot-assisted therapy; tactile sensors";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ahapticempatheticrobotanimalforchildrenwithautism;a haptic empathetic robot animal for children with autism children with autism and their families could greatly benefit from increased support resources while robots are already being introduced into autism therapy and care we propose that these robots could better understand the childs needs and provide enriched interaction if they utilize touch we present our plans both completed and ongoing for a touchperceiving robot companion for children with autism we established and validated touchperception requirements for an ideal robot companion through interviews with 11 autism specialists currently we are evaluating custom fabricbased tactile sensors that enable the robot to detect and identify various touch communication gestures finally our robot companion will react to the childs touches through an emotion response system that will be customizable by a therapist or caretaker
CNJGJPUS;conferencePaper;2019;"Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji";The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot;Proceedings of the 7th International Conference on Human-Agent Interaction;978-1-4503-6922-0;NA;10.1145/3349537.3351891;https://doi.org/10.1145/3349537.3351891;We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.;2019;2021-05-19T12:52:09Z;2021-05-19T12:52:09Z;NA;51–58;NA;NA;NA;NA;NA;NA;HAI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Kyoto, Japan;NA;NA;NA;"empathy; human-robot interaction; animism; robots' perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theroleofanimismtendenciesandempathyinadultevaluationsofrobot;the role of animism tendencies and empathy in adult evaluations of robot we investigated whether japanese adults beliefs about friendship and morality toward robots differing in appearance ie humanoid doglike and eggshaped related to their animism tendencies and empathy university students responded to questionnaires regarding three animism tendencies ie general animism or a tendency to believe souls or gods in nonliving things aliveness animism or a tendency to consider nonliving things as live entities and agentic animisms or a tendency to attribute biological artifactual psychological perceptual and naming properties and empathy we found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors aliveness animism as well as a tendency to attribute perceptual and name properties toward robots might be necessary for an individual to believe that robots could be social agents participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong selforiented emotional reactivity whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility we discuss implications of these results and reasons why people feel that robots have a mind or consciousness
6JC7UN9R;conferencePaper;2015;"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe; Carofiglio, Valeria";Modeling and Simulating Empathic Behavior in Social Assistive Robots;Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter;978-1-4503-3684-0;NA;10.1145/2808435.2808445;https://doi.org/10.1145/2808435.2808445;Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living.;2015;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;110–117;NA;NA;NA;NA;NA;NA;CHItaly 2015;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Rome, Italy;NA;NA;NA;"Affective Computing; Social Assistive Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;modelingandsimulatingempathicbehaviorinsocialassistiverobots;modeling and simulating empathic behavior in social assistive robots several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain in our opinion to plan their response and interact successfully with people it is crucial to recognize human emotions to this aim features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user the information gained from these different sources may be fused in order to endow the robot with the capability to reason on the users affective state in this paper we describe how this capability has been implemented in the nao robot and how this allows simulating empathic behaviors in the context of ambient assisted living
WRWUFXT6;journalArticle;2015;Leite, Iolanda;Long-Term Interactions with Empathic Social Robots;AI Matters;NA;NA;10.1145/2735392.2735397;https://doi.org/10.1145/2735392.2735397;We investigated the effects of an adaptive empathic model in repeated interactions between users and social robots. The proposed model includes an online learning decision-making mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state.;2015-03;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;13–15;NA;3;1;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;longterminteractionswithempathicsocialrobots;longterm interactions with empathic social robots we investigated the effects of an adaptive empathic model in repeated interactions between users and social robots the proposed model includes an online learning decisionmaking mechanism that allows the robot to select the most appropriate supportive behaviors based on the impact that similar behaviors had in keeping the user in a positive affective state
TMB9JQ9T;conferencePaper;2020;"Patro, Jasabanta; Rathore, Pushpendra Singh";A Sociolinguistic Route to the Characterization and Detection of the Credibility of Events on Twitter;Proceedings of the 31st ACM Conference on Hypertext and Social Media;978-1-4503-7098-1;NA;10.1145/3372923.3404795;https://doi.org/10.1145/3372923.3404795;Although Twitter constitutes as one of the primary sources of real-time news with users acting as the sensors updating the content from all across the globe, yet the spread of rumours via Twitter is becoming an increasingly alarming issue and is known to have caused significant damage already. We propose a credibility analysis approach based on the linguistic structure of the tweets. We not only characterize the Twitter events but also predict their perceived credibility of them by a novel deep learning architecture. We use the huge CREDBANK data to conduct our experiments. Some of our exciting findings are that standard LIWC categories like 'negate', 'discrep', 'cogmech', 'swear' and the Empath categories like 'hate', 'poor', 'government', 'worship' and 'swearing-terms' correlate negatively with the credibility of events. While some of our results resonate with the earlier literature others represent novel insights of the fake and legitimate twitter events. Using the above observations and the current deep learning architecture we predict the credibility of an event (a four-class classification problem in our case) with an accuracy of 0.54 that improves the best-known state-of-the-art (current accuracy 0.43) by 26%. A fascinating observation is that even by looking at the first few tweets of an event, it is possible to make the prediction almost as accurate as in the case where the entire volume of tweets is observed.;2020;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;241–250;NA;NA;NA;NA;NA;NA;HT '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Virtual Event, USA;NA;NA;NA;"credibility detection; event credibility; sociolinguistic approach";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;asociolinguisticroutetothecharacterizationanddetectionofthecredibilityofeventsontwitter;a sociolinguistic route to the characterization and detection of the credibility of events on twitter although twitter constitutes as one of the primary sources of realtime news with users acting as the sensors updating the content from all across the globe yet the spread of rumours via twitter is becoming an increasingly alarming issue and is known to have caused significant damage already we propose a credibility analysis approach based on the linguistic structure of the tweets we not only characterize the twitter events but also predict their perceived credibility of them by a novel deep learning architecture we use the huge credbank data to conduct our experiments some of our exciting findings are that standard liwc categories like negate discrep cogmech swear and the empath categories like hate poor government worship and swearingterms correlate negatively with the credibility of events while some of our results resonate with the earlier literature others represent novel insights of the fake and legitimate twitter events using the above observations and the current deep learning architecture we predict the credibility of an event a fourclass classification problem in our case with an accuracy of 054 that improves the bestknown stateoftheart current accuracy 043 by 26 a fascinating observation is that even by looking at the first few tweets of an event it is possible to make the prediction almost as accurate as in the case where the entire volume of tweets is observed
P49Z2K6Q;conferencePaper;2019;Aubergé, Véronique;The Socio-Affective Robot: Aimed to Understand Human Links?;Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop;978-1-4503-6913-8;NA;10.1145/3347320.3357687;https://doi.org/10.1145/3347320.3357687;"Is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence, revealing some crucial aspects of social and cultural human processing? Among the smart objects, the social robot cannot be distinguished by precise and well defined technical or morphological cues. Even though no serious and discriminative attributes can be given by any science knowledge – even the movement attribute, and the ""autonomous” cognitive attribute are not clearly defined – in order to understand how an object becomes, perceptively, a subject (social robot), it is a fact that the automatons and the talking artefacts are now named robot, which is particularly attractive for general public, for scientists and engineers. However, is it a socio-cultural desire or a technical need to add the augmentation of the social space to the ""augmented self” (self body and self environment abilities)?In this talk we will explore some social space perturbations in ecological conditions, such as elderly people suffering from isolation and interacting with a robot that can emit solely non-verbal speech primitives. Long term interactions were collected and analysed using the concepts of the Dynamic Affective Network for Social Entities (D.A.N.S.E.) theory. We will try to show that non-verbal speech primitives, organised in the D.A.N.S.E.'s ""glue” paradigm, permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance, but also to explore in particular an empathic dimension. Through a Living Lab method, evaluation of these hypotheses and building of an empathic socio-affective HRI were conducted together, within strong ethical constraints. In particular the development of frail robots for frail people will be proposed as possible ethical perspective.";2019;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;1;NA;NA;NA;NA;NA;NA;AVEC '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Nice, France;NA;NA;NA;"engagement; frail person; hri; living lab; social robot; socio-affective speech";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;thesocioaffectiverobotaimedtounderstandhumanlinks;the socioaffective robot aimed to understand human links is the social robot a product of artificial intelligence or is it a perception product by our natural intelligence revealing some crucial aspects of social and cultural human processing among the smart objects the social robot cannot be distinguished by precise and well defined technical or morphological cues even though no serious and discriminative attributes can be given by any science knowledge  even the movement attribute and the autonomous cognitive attribute are not clearly defined  in order to understand how an object becomes perceptively a subject social robot it is a fact that the automatons and the talking artefacts are now named robot which is particularly attractive for general public for scientists and engineers however is it a sociocultural desire or a technical need to add the augmentation of the social space to the augmented self self body and self environment abilitiesin this talk we will explore some social space perturbations in ecological conditions such as elderly people suffering from isolation and interacting with a robot that can emit solely nonverbal speech primitives long term interactions were collected and analysed using the concepts of the dynamic affective network for social entities danse theory we will try to show that nonverbal speech primitives organised in the danses glue paradigm permit to predict the relations with the robot perceived by elderly as oriented inside or outside dominance but also to explore in particular an empathic dimension through a living lab method evaluation of these hypotheses and building of an empathic socioaffective hri were conducted together within strong ethical constraints in particular the development of frail robots for frail people will be proposed as possible ethical perspective
YBVRBUUI;conferencePaper;2019;Zhou, Michelle X.;"Getting Virtually Personal: Making Responsible and Empathetic ""Her"" for Everyone";Proceedings of the 24th International Conference on Intelligent User Interfaces;978-1-4503-6272-6;NA;10.1145/3301275.3308445;https://doi.org/10.1145/3301275.3308445;Have you watched the movie Her? Have you ever wondered or wished to have your own AI companion just like Samantha, who could understand you better than you know about yourself, and could tell you what you really are, whom your best partner may be, and which career path would be best for you? In this talk, I will present a computational framework for building responsible and empathetic Artificial Intelligent (AI) agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real world.Starting with a live demo of showing how an AI interviewer chats with a user to automatically derive his/her personality characteristics and provide personalized recommendations, I will highlight the technical advances of the framework in two aspects. First, I will present a computational, evidence-based approach to Big 5 personality inference, which enables an AI agent to deeply understand a user's unique characteristics by analyzing the user's chat text on the fly. Second, I will describe a topic-based conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agent.I will describe the initial applications of our AI agents in the real world, from talent selection to student teaming to user experience research. Finally, I will discuss the wider implications of our work on building hyper-personalized systems and their impact on our lives.;2019;2021-05-19T12:52:10Z;2021-05-19T12:52:10Z;NA;i;NA;NA;NA;NA;NA;NA;IUI '19;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Marina del Ray, California;NA;NA;NA;"computational psychology; AI interviewer; chatbot; conversational agent; empathetic AI; hyper-personalization; personality inference; responsible AI";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;gettingvirtuallypersonalmakingresponsibleandempatheticherforeveryone;getting virtually personal making responsible and empathetic her for everyone have you watched the movie her have you ever wondered or wished to have your own ai companion just like samantha who could understand you better than you know about yourself and could tell you what you really are whom your best partner may be and which career path would be best for you in this talk i will present a computational framework for building responsible and empathetic artificial intelligent ai agents who can deeply understand their users as unique individuals and responsibly guide their behavior in both virtual and real worldstarting with a live demo of showing how an ai interviewer chats with a user to automatically derive hisher personality characteristics and provide personalized recommendations i will highlight the technical advances of the framework in two aspects first i will present a computational evidencebased approach to big 5 personality inference which enables an ai agent to deeply understand a users unique characteristics by analyzing the users chat text on the fly second i will describe a topicbased conversation engine that couples deep learning with rules to support a natural conversation and rapid customization of a conversational agenti will describe the initial applications of our ai agents in the real world from talent selection to student teaming to user experience research finally i will discuss the wider implications of our work on building hyperpersonalized systems and their impact on our lives
FVLZ42QE;journalArticle;2020;"McDonald, Nora; Pan, Shimei";Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact;Proc. ACM Hum.-Comput. Interact.;NA;NA;10.1145/3415218;https://doi.org/10.1145/3415218;Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.;2020-10;2021-05-19T12:52:11Z;2021-05-19T12:52:11Z;NA;NA;NA;CSCW2;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: New York, NY, USA Publisher: Association for Computing Machinery;NA;NA;NA;"artificial intelligence; ethics; algorithm bias; education; intersectionality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;intersectionalaiastudyofhowinformationsciencestudentsthinkaboutethicsandtheirimpact;intersectional ai a study of how information science students think about ethics and their impact recent literature has demonstrated the limited and in some instances waning role of ethical training in computing classes in the us the capacity for artificial intelligence ai to be inequitable or harmful is well documented yet its an issue that continues to lack apparent urgency or effective mitigation the question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing ai particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restrictionfrom risk assessment and bail assignment in criminal justice to public benefits distribution and access to housing and other critical resources that enable security and success within society the us is a mecca of information and computer science is and cs learning for asian students whose experiences as minorities renders them familiar with and vulnerable to the societal bias that feeds ai bias our goal was to better understand how students who are being educated to design ai systems think about these issues and in particular their sensitivity to intersectional considerations that heighten risk for vulnerable groups in this paper we report on findings from qualitative interviews with 20 graduate students 11 from an ai class and 9 from a data mining class we find that students are not predisposed to think deeply about the implications of ai design for the privacy and wellbeing of others unless explicitly encouraged to do so when they do their thinking is focused through the lens of personal identity and experience but their reflections tend to center on bias an intrinsic feature of design rather than on fairness an outcome that requires them to imagine the consequences of ai while they are in fact equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities many need help to do this empathy work notably the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias and the interaction with context our findings suggest that experience with identitybased vulnerability promotes more analytically complex thinking about ai lending further support to the argument that identityrelated ethics should be integrated into is and cs curriculums rather than positioned as a standalone course
MQTYRXW6;conferencePaper;2015;Encinas, Enrique;Cyrafour: How Two Human Avatars Communicate With Each Other;Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems;978-1-4503-3146-3;NA;10.1145/2702613.2726962;https://doi.org/10.1145/2702613.2726962;Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.;2015;2021-05-19T12:52:11Z;2021-05-19T12:52:11Z;NA;109–114;NA;NA;NA;NA;NA;NA;CHI EA '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Seoul, Republic of Korea;NA;NA;NA;"embodied cognition; serious games; copresence; cyranoids; human avatars; personal surrogates; telepresence";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;cyrafourhowtwohumanavatarscommunicatewitheachother;cyrafour how two human avatars communicate with each other human avatars or physical surrogates are becoming increasingly present in leisure artistic and business activities that seek to augment the sensory richness available to telepresent participants while a number of studies have focused on how human avatars relate to other humans little attention has been paid to the particularities of human avatar to human avatar interaction this paper examines characteristic features of such interaction through cyrafour a playful embodied identity game in which two human avatars clone various conversations generated elsewhere such cloning or speech shadowing seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised this project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces
AKSF7SZ8;conferencePaper;2016;"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne";I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor;"Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems";978-1-4503-4239-1;NA;NA;NA;We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.;2016;2021-05-19T12:52:55Z;2021-05-19T12:52:55Z;NA;931–939;NA;NA;NA;NA;NA;NA;AAMAS '16;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"empathy; human-agent interaction; human-robot interaction; memory";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;irememberyouinteractionwithmemoryforanempathicvirtualrobotictutor;i remember you interaction with memory for an empathic virtual robotic tutor we present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor the domain is a virtual robotic tutor who is guiding and helping learners through a mobile treasure hunt exercise that tests their map reading skills the contribution described in this paper is the discovery that incorporating memory through utterances that recall events from previous interactions significantly increases the learners ability to perform a pedagogical task however the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory in addition there was a significant drop in perceived empathy this work has a large potential influence in the field of interaction design for agents as one cannot blindly add in humanlike features such as memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability
PQI958GE;conferencePaper;2016;"Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka";Sharing Emotion Described as Text on the Internet by Changing Self-Physiological Perception;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2974825;https://doi.org/10.1145/2974804.2974825;"Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.";2016;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;145–153;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Biopolis, Singapore;NA;NA;NA;"emotion; theory of mind; a sense of ownership; online communication; physiological perception; self-perception";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;sharingemotiondescribedastextontheinternetbychangingselfphysiologicalperception;sharing emotion described as text on the internet by changing selfphysiological perception agents like human such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information meanwhile as in the case of internet bot it is still difficult to communiate the emotion described as text let alone empathizing due to degradation of information online the current study proposes a method for experiencing emotion on the internet by reproducing a mechanism of evoking emotion this method evokes a number of emotions described on the web by changing of selfphysiological perception with sensory stimuli to investigate the feasibility of our method we made a system named communious mouse this system rewrites the perception of selfskin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion the current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system
5MAHCZAT;conferencePaper;2021;"Urakami, Jacqueline; Sutthithatip, Sujitra";Building a Collaborative Relationship between Human and Robot through Verbal and Non-Verbal Interaction;Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-8290-8;NA;10.1145/3434074.3447171;https://doi.org/10.1145/3434074.3447171;Interpersonal communication and relationship building promote successful collaborations. This study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partner.Participants interacted with two robots that differed in their nonverbal and verbal expressiveness. The interactive robot actively engaged the participant in a conversation before, during and after a collaborative task whereas the non-interactive robot remained passive. The robots' nonverbal and verbal interactions increased participants' perception of the robot as a social actor and strengthened bonding and relationship building between human and robot. The results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact, the robot is attributed a certain personality, and the robot is perceived as being alive.Our study could not show that an interactive robot receives more help by the collaboration partner. Future research should investigate additional factors that facilitate helpful behavior among humans, such as similarity, attributional judgement and empathy.;2021;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;257–261;NA;NA;NA;NA;NA;NA;HRI '21 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boulder, CO, USA;NA;NA;NA;"social presence; helping; human robot collaboration; relationship building";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;buildingacollaborativerelationshipbetweenhumanandrobotthroughverbalandnonverbalinteraction;building a collaborative relationship between human and robot through verbal and nonverbal interaction interpersonal communication and relationship building promote successful collaborations this study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partnerparticipants interacted with two robots that differed in their nonverbal and verbal expressiveness the interactive robot actively engaged the participant in a conversation before during and after a collaborative task whereas the noninteractive robot remained passive the robots nonverbal and verbal interactions increased participants perception of the robot as a social actor and strengthened bonding and relationship building between human and robot the results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact the robot is attributed a certain personality and the robot is perceived as being aliveour study could not show that an interactive robot receives more help by the collaboration partner future research should investigate additional factors that facilitate helpful behavior among humans such as similarity attributional judgement and empathy
WLRPP9DB;conferencePaper;2015;"Jeong, Sooyeon; Santos, Kristopher Dos; Graca, Suzanne; O'Connell, Brianna; Anderson, Laurel; Stenquist, Nicole; Fitzpatrick, Katie; Goodenough, Honey; Logan, Deirdre; Weinstock, Peter; Breazeal, Cynthia";Designing a Socially Assistive Robot for Pediatric Care;Proceedings of the 14th International Conference on Interaction Design and Children;978-1-4503-3590-4;NA;10.1145/2771839.2771923;https://doi.org/10.1145/2771839.2771923;We present the design of the Huggable robot that can playfully interact with children and provide socio-emotional support for them in pediatric care context. Our design takes into consideration that many young patients are nervous, intimidated, and are socio-emotionally vulnerable at hospitals. The Huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions. It uses a smart phone device for its computational power and internal sensors. The robot's haptic sensors perceive physical touch and can use the information in meaningful ways. The modular arm component allows easy sensor replacement and increases the usability of the Huggable robot for various pediatric care services. From a preliminary pilot user study with two healthy and two ill children, all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children. We learned various types of physical touch occurred during the child-robot interaction, and will continue to develop more intelligent haptic sensory system for the Huggable robot to better assist and support child patients' socio-emotional needs.;2015;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;387–390;NA;NA;NA;NA;NA;NA;IDC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boston, Massachusetts;NA;NA;NA;"child-robot interaction; healthcare robotics; pediatric care; robot design; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designingasociallyassistiverobotforpediatriccare;designing a socially assistive robot for pediatric care we present the design of the huggable robot that can playfully interact with children and provide socioemotional support for them in pediatric care context our design takes into consideration that many young patients are nervous intimidated and are socioemotionally vulnerable at hospitals the huggable robot has a childish and furry look be perceived friendly and can perform swift and smooth motions it uses a smart phone device for its computational power and internal sensors the robots haptic sensors perceive physical touch and can use the information in meaningful ways the modular arm component allows easy sensor replacement and increases the usability of the huggable robot for various pediatric care services from a preliminary pilot user study with two healthy and two ill children all participants enjoyed playing with the robot but the two children with medical conditions showed caring and empathetic behaviors than the two health children we learned various types of physical touch occurred during the childrobot interaction and will continue to develop more intelligent haptic sensory system for the huggable robot to better assist and support child patients socioemotional needs
CEQQ4RCH;conferencePaper;2015;"Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung";Design of Emotional Conversations with a Child for a Role Playing Robot;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702009;https://doi.org/10.1145/2701973.2702009;The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.;2015;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;73–74;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"emotional role playing robot; human intervention device; human-robot-interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designofemotionalconversationswithachildforaroleplayingrobot;design of emotional conversations with a child for a role playing robot the children who suffer from psychological and emotional disorder are unaccustomed to cooperation shared meaning sympathy empathy and magnanimity in recent several attempts has been tried at increasing childrens social skills by emotional roleplaying game with robots because the robotic system can offer dynamic adaptive and autonomous interaction for learning of imitation skills with realtime performance evaluation and feedback but there are limits in robot technologies especially it is very difficult to understand the childrens word and take suitable behaviors for the childrens intents therefore we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper for the purpose we design a humanrobotinteraction software and a special human intervention device hid and finally we implement our suggested method with a commercial humanoid robot
CUJ77IIN;conferencePaper;2018;"Kang, Dahyun; Kim, SunKyoung; Kwak, Sonya S.";The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots;Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-5615-2;NA;10.1145/3173386.3177023;https://doi.org/10.1145/3173386.3177023;We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand.;2018;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;143–144;NA;NA;NA;NA;NA;NA;HRI '18;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Chicago, IL, USA;NA;NA;NA;"empathy; human-robot interaction; functional intimacy; knowledgeableness; physical contact; safety; sociability; social distance";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theeffectsofthephysicalcontactinthefunctionalintimatedistanceonusersacceptancetowardrobots;the effects of the physical contact in the functional intimate distance on users acceptance toward robots we investigated the effects of physical contact of robots on the users acceptance in the functional intimate distance we conducted a two robot interaction types interaction with physical contact vs interaction with a tool withinparticipants experiment n18 this study was a videobased observation study according to the experimental results the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone on the other hand the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patients temperature with a thermometer instead of its hand
7L4WANDM;conferencePaper;2020;"Kim, Jinwook; Baek, Kyungwon; Jang, Jinkyu";Petbe: Projecting a Real Being onto a Social Robot Using Contextual Data for a Pet Monitoring Method;Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-7057-8;NA;10.1145/3371382.3378236;https://doi.org/10.1145/3371382.3378236;The demand for pet monitoring devices is growing due to the increasing number of one-person households raising pets. However, current monitoring methods using video camera entail various problems, which may lead to discontinued usage. To overcome this problem, we propose Petbe, a social robot that projects your own pet using a context-aware approach based on BLE beacons and Raspberry Pis. The corresponding smartphone application provides various robot status updates (robot head) and movements (robot body). With the development of Petbe, we conducted an exploratory study to verify the advancement of the above issues on monitoring user's own pets with the following factors: privacy concern, companionship, awareness, connectivity, and satisfaction. The outcomes indicate that Petbe helps to reduce privacy concerns and build companionship through empathetic interaction.;2020;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;290–292;NA;NA;NA;NA;NA;NA;HRI '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Cambridge, United Kingdom;NA;NA;NA;"social robot; context aware; pet monitoring; projection";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;petbeprojectingarealbeingontoasocialrobotusingcontextualdataforapetmonitoringmethod;petbe projecting a real being onto a social robot using contextual data for a pet monitoring method the demand for pet monitoring devices is growing due to the increasing number of oneperson households raising pets however current monitoring methods using video camera entail various problems which may lead to discontinued usage to overcome this problem we propose petbe a social robot that projects your own pet using a contextaware approach based on ble beacons and raspberry pis the corresponding smartphone application provides various robot status updates robot head and movements robot body with the development of petbe we conducted an exploratory study to verify the advancement of the above issues on monitoring users own pets with the following factors privacy concern companionship awareness connectivity and satisfaction the outcomes indicate that petbe helps to reduce privacy concerns and build companionship through empathetic interaction
UNJC4X4P;conferencePaper;2015;Franco, Gloria Adriana Mendoza;Evaluation of the Emotional Answer in HRI on a Game Situation;Proceedings of the Latin American Conference on Human Computer Interaction;978-1-4503-3960-5;NA;10.1145/2824893.2824897;https://doi.org/10.1145/2824893.2824897;This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.;2015;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;NA;NA;NA;NA;NA;NA;NA;CLIHC '15;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Córdoba, Argentina;NA;NA;NA;"empathy; interaction design; HRI; Emocards; emotional evaluation; emotional reciprocity; lottery application";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;evaluationoftheemotionalanswerinhrionagamesituation;evaluation of the emotional answer in hri on a game situation this project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot a lottery game application has been developed for playing with the robot nao and through an experimental scenario the empathy towards a robot has been demonstrated as a result the emocards are presented as a promising assessment method for the emotional answer of the users
BBQGR6GS;conferencePaper;2015;"Jeong, Seongmi; Gu, Jihyang; Shin, Dong-Hee";I Am Interested in What You Are Saying: Role of Nonverbal Immediacy Cues in Listening;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702040;https://doi.org/10.1145/2701973.2702040;Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot.;2015;2021-05-19T12:52:56Z;2021-05-19T12:52:56Z;NA;129–130;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"hri; immediacy; nodding; nonverbal behavior; posture";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;iaminterestedinwhatyouaresayingroleofnonverbalimmediacycuesinlistening;i am interested in what you are saying role of nonverbal immediacy cues in listening immediacy plays a key role in interpersonal communication some of immediate behaviors in humanhuman interaction i e gaze and nodding have received much attention in hri however others i e body posture dont this study investigates whether robots posture lean forward vs upright and nodding manner small and fast vs large and slow can affect perception of the robot the current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes including perceived empathy humanlikeness and likability of the robot
UFDLZAS9;conferencePaper;2020;"Pollmann, Kathrin; Ziegler, Daniel";Personal Quizmaster: A Pattern Approach to Personalized Interaction Experiences with the MiRo Robot;Proceedings of the Conference on Mensch Und Computer;978-1-4503-7540-5;NA;10.1145/3404983.3410414;https://doi.org/10.1145/3404983.3410414;In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes.;2020;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;485–489;NA;NA;NA;NA;NA;NA;MuC '20;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Magdeburg, Germany;NA;NA;NA;"social robot; behavioral patterns; multimodal behavioral expressions; personalized human-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;personalquizmasterapatternapproachtopersonalizedinteractionexperienceswiththemirorobot;personal quizmaster a pattern approach to personalized interaction experiences with the miro robot in humanrobot interaction personalization has been proposed as a strategy to increase acceptance for social robots the present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual users characteristics and needs to demonstrate this approach we designed a quiz game application for the miro robot the robot acts as the quizmaster and shows different behaviors coachlikeempathic vs challengingprovocative depending on the type of user who is playing the game communityfocused vs competitionfocused player we describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game the result is a wizardofoz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes
JPKDHXJZ;conferencePaper;2021;"Chirapornchai, Chatchai; Bremner, Paul; Daly, Joseph E.";Helper's High with a Robot Pet;Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;978-1-4503-8290-8;NA;10.1145/3434074.3447165;https://doi.org/10.1145/3434074.3447165;Helper's high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement. This study investigates if a robot pet can, like a real pet, induce helpers high in people interacting with it. A Vector robot was programmed to express the need for daily exercise and attention, and participants were instructed how to help the robot meet those needs. Our within subjects design had two conditions: with and without emotional behaviour modifiers to the robot's behaviour. Our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants, which would create a stronger helper's high effect than purely functional need expression behaviours. We present a long-term (4 day) remote study design that not only facilitates the kind of interactions needed for helper's high, but abides by government guidelines on Covid-19 safety (under which a laboratory study is not possible). Preliminary results suggest that Vector was able to improve the mood of some participants, and mood changes tend to be greater when Vector expressed behaviours with emotional components. Our post-study interview data suggests that individual differences in living environment and mood impacting external factors, affected Vector's efficacy in mood influencing.;2021;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;229–233;NA;NA;NA;NA;NA;NA;HRI '21 Companion;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Boulder, CO, USA;NA;NA;NA;"empathy; helper's high; mood improvement; robot pet; vector";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;helpershighwitharobotpet;helpers high with a robot pet helpers high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement this study investigates if a robot pet can like a real pet induce helpers high in people interacting with it a vector robot was programmed to express the need for daily exercise and attention and participants were instructed how to help the robot meet those needs our within subjects design had two conditions with and without emotional behaviour modifiers to the robots behaviour our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants which would create a stronger helpers high effect than purely functional need expression behaviours we present a longterm 4 day remote study design that not only facilitates the kind of interactions needed for helpers high but abides by government guidelines on covid19 safety under which a laboratory study is not possible preliminary results suggest that vector was able to improve the mood of some participants and mood changes tend to be greater when vector expressed behaviours with emotional components our poststudy interview data suggests that individual differences in living environment and mood impacting external factors affected vectors efficacy in mood influencing
BFCKYF8N;conferencePaper;2018;"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia";A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.;2018;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;1658–1666;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"social robot; human-robot interaction; intelligent tutoring systems; gaussian processl; speech-based systems; student modeling";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;asocialrobotsystemformodelingchildrenswordpronunciationsociallyinteractiveagentstrack;a social robot system for modeling childrens word pronunciation socially interactive agents track autonomous educational social robots can be used to help promote literacy skills in young children such robots which emulate the emotive perceptual and empathic abilities of human teachers are capable of replicating some of the benefits of oneonone tutoring from human teachers in part by leveraging individual students behavior and task performance data to infer sophisticated models of their knowledge these student models are then used to provide personalized educational experiences by for example determining the optimal sequencing of curricular material in this paper we introduce an integrated system for autonomously analyzing and assessing childrens speech and pronunciation in the context of an interactive word game between a social robot and a child we present a novel game environment and its computational formulation an integrated pipeline for capturing and analyzing childrens speech in realtime and an autonomous robot that models childrens word pronunciation via gaussian process regression gpr augmented with an active learning protocol that informs the robots behavior we show that the system is capable of autonomously assessing childrens pronunciation ability with ground truth determined by a postexperiment evaluation by human raters we also compare phoneme and wordlevel gpr models and discuss tradeoffs of each approach in modeling childrens pronunciation finally we describe and analyze a pipeline for automatic analysis of childrens speech and pronunciation including an evaluation of speechace as a tool for future development of autonomous speechbased language tutors
JS25ETMC;conferencePaper;2015;"Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre";The CoWriter Project: Teaching a Robot How to Write;Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts;978-1-4503-3318-4;NA;10.1145/2701973.2702091;https://doi.org/10.1145/2701973.2702091;"This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.";2015;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;269;NA;NA;NA;NA;NA;NA;HRI'15 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Portland, Oregon, USA;NA;NA;NA;"education; human-robot interaction; learning by teaching";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;thecowriterprojectteachingarobothowtowrite;the cowriter project teaching a robot how to write this video that accompanies the paper when children teach a robot to write an autonomous teachable humanoid which uses simulated handwriting by the same authors and presented as well during this conference presents the first results of the epfl cowriter project the project aims at building a robotic partner which children can teach handwriting the system allows for the learning by teaching paradigm to be employed in the interaction so as to stimulate metacognition empathy and increased selfesteem in the child user it is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student but could also present the opportunity for children to experience physicallyinduced benefits encountered during humanled handwriting interventions such as motor mimicry
EFWZLJVA;conferencePaper;2016;"Shinohara, Yumiko; Kubo, Katsuhiro; Nozawa, Momoyo; Yoshizaki, Misa; Takahashi, Tomomi; Hayakawa, Hirofumi; Hirota, Atsushi; Nishizaki, Yukiko; Oka, Natsuki";The Optimum Rate of Mimicry in Human-Agent Interaction;Proceedings of the Fourth International Conference on Human Agent Interaction;978-1-4503-4508-8;NA;10.1145/2974804.2980506;https://doi.org/10.1145/2974804.2980506;The importance of building rapport between a human and an agent is increasing with the burgeoning development of robot technology. Several recent studies have focused on the chameleon effect, using psychological concepts to investigate human-agent interaction. However, the validity of the chameleon effect in human-agent interaction is controversial. Few studies have explored the influence of individual cognitive ability and the rate of mimicry on the human-agent interaction. We explored the optimal rate of mimicry and the relationship between mimicry rate and individual empathic ability. We controlled the amount of agent mimicry and examined the effect on participants classified as high- and low-perspective takers. We found that, overall, participants preferred agents that mimicked their behavior 83% of the time. Moreover, high-, but not low-, perspective takers tended to be influenced by the mimicry rate.;2016;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;367–370;NA;NA;NA;NA;NA;NA;HAI '16;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Biopolis, Singapore;NA;NA;NA;"human-agent interaction; perspective taking; mimicry; impression of robot; the chameleon effect";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theoptimumrateofmimicryinhumanagentinteraction;the optimum rate of mimicry in humanagent interaction the importance of building rapport between a human and an agent is increasing with the burgeoning development of robot technology several recent studies have focused on the chameleon effect using psychological concepts to investigate humanagent interaction however the validity of the chameleon effect in humanagent interaction is controversial few studies have explored the influence of individual cognitive ability and the rate of mimicry on the humanagent interaction we explored the optimal rate of mimicry and the relationship between mimicry rate and individual empathic ability we controlled the amount of agent mimicry and examined the effect on participants classified as high and lowperspective takers we found that overall participants preferred agents that mimicked their behavior 83 of the time moreover high but not low perspective takers tended to be influenced by the mimicry rate
ZRZ235JD;conferencePaper;2018;Spaulding, Samuel;Personalized Robot Tutors That Learn from Multimodal Data;Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems;NA;NA;NA;NA;As the cost of sensors decreases and ability to model and learn from multi-modal data increases, researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning. These robots are designed to emulate the emotive, perceptual, and empathic abilities of human teachers, and are capable of replicating some of the benefits of one-on-one tutoring from human teachers. My thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech, facial expressions, and task performance to build rich models of the user's knowledge and preferences. These student models are then used to provide personalized educational experiences, such as optimal curricular sequencing, or leaning preferences for educational style. In this abstract, we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks.;2018;2021-05-19T12:52:57Z;2021-05-19T12:52:57Z;NA;1781–1783;NA;NA;NA;NA;NA;NA;AAMAS '18;NA;NA;NA;International Foundation for Autonomous Agents and Multiagent Systems;Richland, SC;NA;NA;NA;NA;NA;NA;NA;event-place: Stockholm, Sweden;NA;NA;NA;"human-robot interaction; social robotics; multimodal interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;personalizedrobottutorsthatlearnfrommultimodaldata;personalized robot tutors that learn from multimodal data as the cost of sensors decreases and ability to model and learn from multimodal data increases researchers are exploring how to use the unique qualities of physically embodied robots to help engage students and promote learning these robots are designed to emulate the emotive perceptual and empathic abilities of human teachers and are capable of replicating some of the benefits of oneonone tutoring from human teachers my thesis research focuses on developing methods for robots to analyze and integrate multimodal data including speech facial expressions and task performance to build rich models of the users knowledge and preferences these student models are then used to provide personalized educational experiences such as optimal curricular sequencing or leaning preferences for educational style in this abstract we summarize past projects in this area and discuss applications such as learning from affective signals and model transfer across tasks
C5Y6JTSN;conferencePaper;2021;"Herdel, Viviane; Kuzminykh, Anastasia; Hildebrandt, Andrea; Cauchard, Jessica R.";Drone in Love: Emotional Perception of Facial Expressions on Flying Robots;Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;978-1-4503-8096-6;NA;10.1145/3411764.3445495;https://doi.org/10.1145/3411764.3445495;Drones are rapidly populating human spaces, yet little is known about how these flying robots are perceived and understood by humans. Recent works suggested that their acceptance is predicated upon their sociability. This paper explores the use of facial expressions to represent emotions on social drones. We leveraged design practices from ground robotics and created a set of rendered robotic faces that convey basic emotions. We evaluated individuals’ response to these emotional facial expressions on drones in two empirical studies (N = 98, N = 98). Our results demonstrate that individuals accurately recognize five drone emotional expressions, as well as make sense of intensities within emotion categories. We describe how participants were emotionally affected by the drone, showed empathy towards it, and created narratives to interpret its emotions. As a consequence, we formulate design recommendations for social drones and discuss methodological insights on the use of static versus dynamic stimuli in affective robotics studies.;2021;2021-05-19T12:53:15Z;2021-05-19T12:53:15Z;NA;NA;NA;NA;NA;NA;NA;NA;CHI '21;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Yokohama, Japan;NA;NA;NA;"Affective Computing; Emotion Recognition; Anthropomorphism; Robot; Facial Expressions; Human-Drone Interaction; UAV.";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;droneinloveemotionalperceptionoffacialexpressionsonflyingrobots;drone in love emotional perception of facial expressions on flying robots drones are rapidly populating human spaces yet little is known about how these flying robots are perceived and understood by humans recent works suggested that their acceptance is predicated upon their sociability this paper explores the use of facial expressions to represent emotions on social drones we leveraged design practices from ground robotics and created a set of rendered robotic faces that convey basic emotions we evaluated individuals response to these emotional facial expressions on drones in two empirical studies n  98 n  98 our results demonstrate that individuals accurately recognize five drone emotional expressions as well as make sense of intensities within emotion categories we describe how participants were emotionally affected by the drone showed empathy towards it and created narratives to interpret its emotions as a consequence we formulate design recommendations for social drones and discuss methodological insights on the use of static versus dynamic stimuli in affective robotics studies
YIIBZ78F;conferencePaper;2019;"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania";Ballbit Adventure: A Physical Game for a Collaborative Racing;Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;978-1-4503-6871-1;NA;10.1145/3341215.3356982;https://doi.org/10.1145/3341215.3356982;Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.;2019;2021-05-19T12:53:16Z;2021-05-19T12:53:16Z;NA;97–103;NA;NA;NA;NA;NA;NA;CHI PLAY '19 Extended Abstracts;NA;NA;NA;Association for Computing Machinery;New York, NY, USA;NA;NA;NA;NA;NA;NA;NA;event-place: Barcelona, Spain;NA;NA;NA;"cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ballbitadventureaphysicalgameforacollaborativeracing;ballbit adventure a physical game for a collaborative racing playtime accounts for one of the most critical learning periods for children as they learn how to interact and socialize with their playmates in this paper we present a new kind of cooperationbased physical game called ballbit adventure our game provides a collaborative environment for children to communicate cooperate and empathize through solving challenges in an interactive maze each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line through the format of a physical racing game ballbit adventure hopes to show the value of facetoface play experience to counterbalance the disconnected online interactions that children have with video games
UBPMUAWD;conferencePaper;2018;"Febtriko, Anip; Rahayuningsih, Tri; Septiani, Dinda; Trisnawati, Liza; Arisandi, Diki; Sukri";Effectiveness Of Android-Based Mobile Robots For Children Asperger Syndrome;2018 International Conference on Applied Information Technology and Innovation (ICAITI);NA;NA;10.1109/ICAITI.2018.8686759;NA;Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.;2018-09;2021-05-19T12:41:47Z;2021-05-19T12:41:47Z;NA;208-212;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Mobile Robot; Android; Asperger syndrome; Rank Wilcoxon";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;effectivenessofandroidbasedmobilerobotsforchildrenaspergersyndrome;effectiveness of androidbased mobile robots for children asperger syndrome autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest one type of autism is asperger syndrome is a personal qualitative weakness in communicating and social interaction just like any other autistic child with aspergers syndrome it is very difficult to understand emotions limitations in expressing and understanding emotions cause children with aspergers syndrome to retreat socially like aloof indifferent less interested in others lack empathy think in one direction and think hard therefore it is necessary to apply play therapy for children with asperger syndrome disorder by using android mobilebased robot as a robot control tool wheelshaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot research using pre experimental design the population in sampling is 15 children children with aspergers syndrome take the 6 12 year age example at special school for pekanbaru children data collection to assess the outcome of play therapy using mobile robot the data collected were analyzed by descriptive analysis and rank wilcoxon test the main purpose of this study is the influence or effectiveness of the use of androidbased mobile robots as a control tool against aspergers syndrome disorder in children in independent schools pekanbaru to communicate and interact socially
SPJL5VQ6;conferencePaper;2019;"DiPaola, Steve; Yalçin, Özge Nilay";A multi-layer artificial intelligence and sensing based affective conversational embodied agent;2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW);NA;NA;10.1109/ACIIW.2019.8925291;NA;Building natural and conversational virtual humans is a task of formidable complexity. We believe that, especially when building agents that affectively interact with biological humans in real-time, a cognitive science-based, multilayered sensing and artificial intelligence (AI) systems approach is needed. For this demo, we show a working version (through human interaction with it) our modular system of natural, conversation 3D virtual human using AI or sensing layers. These including sensing the human user via facial emotion recognition, voice stress, semantic meaning of the words, eye gaze, heart rate, and galvanic skin response. These inputs are combined with AI sensing and recognition of the environment using deep learning natural language captioning or dense captioning. These are all processed by our AI avatar system allowing for an affective and empathetic conversation using an NLP topic-based dialogue capable of using facial expressions, gestures, breath, eye gaze and voice language-based two-way back and forth conversations with a sensed human. Our lab has been building these systems in stages over the years.;2019-09;2021-05-19T12:41:47Z;2021-05-19T12:41:47Z;NA;91-92;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"artificial intelligence; Machine learning; deep learning; biosensing; affective computing; conversational agent; Emotion recognition; Real-time systems; Biosensors; embodied agent; embodied character agents; sensing systems; Streaming media";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;amultilayerartificialintelligenceandsensingbasedaffectiveconversationalembodiedagent;a multilayer artificial intelligence and sensing based affective conversational embodied agent building natural and conversational virtual humans is a task of formidable complexity we believe that especially when building agents that affectively interact with biological humans in realtime a cognitive sciencebased multilayered sensing and artificial intelligence ai systems approach is needed for this demo we show a working version through human interaction with it our modular system of natural conversation 3d virtual human using ai or sensing layers these including sensing the human user via facial emotion recognition voice stress semantic meaning of the words eye gaze heart rate and galvanic skin response these inputs are combined with ai sensing and recognition of the environment using deep learning natural language captioning or dense captioning these are all processed by our ai avatar system allowing for an affective and empathetic conversation using an nlp topicbased dialogue capable of using facial expressions gestures breath eye gaze and voice languagebased twoway back and forth conversations with a sensed human our lab has been building these systems in stages over the years
W3CN3J9Y;conferencePaper;2020;"Sönmez, Elena Battini; Köse, Hatice; Barkana, Duygun Erol";Towards a New Computational Affective System for Personal Assistive Robots;2020 28th Signal Processing and Communications Applications Conference (SIU);NA;NA;10.1109/SIU49456.2020.9302238;NA;The need of social interaction between human and robot is extensively highlighted in recent studies involving social robots. Language, emotions, postures, and gestures are commonly used to increase the quality of human-computer interaction. In this study, we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during human-computer interaction. Human-like empathy is considered as an emergent behavior based on social interaction with humans, gut feelings, mirroring system, and association between external stimuli and emotions in the developmental robotics theory. Our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agent/robot. Furthermore, our study demonstrates a model of the changes of the affective state of the robot from one emotion to another, in synchronization with the emotions expressed by its human partner. The robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training. The simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively.;2020-10;2021-05-19T12:41:48Z;2021-05-19T12:41:48Z;NA;1-4;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ISSN: 2165-0608;NA;NA;NA;"Computational modeling; emotion recognition; affective computing; virtual human; Robots; facial expression; Face recognition; Three-dimensional displays; Faces; Feature extraction; Mood";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsanewcomputationalaffectivesystemforpersonalassistiverobots;towards a new computational affective system for personal assistive robots the need of social interaction between human and robot is extensively highlighted in recent studies involving social robots language emotions postures and gestures are commonly used to increase the quality of humancomputer interaction in this study we focus on the design of a cognitive architecture to model the emotions and the dynamics of them to implement artificial empathy during humancomputer interaction humanlike empathy is considered as an emergent behavior based on social interaction with humans gut feelings mirroring system and association between external stimuli and emotions in the developmental robotics theory our study uses developmental robotics theory and it presents a simulation of the internal emotional states of an agentrobot furthermore our study demonstrates a model of the changes of the affective state of the robot from one emotion to another in synchronization with the emotions expressed by its human partner the robot can adjust its inner state and mood in harmony to the emotional state of the human partner after training the simulations are performed and the proposed computational affective system is evaluated by the human participants subjectively
6WZJZHQM;conferencePaper;2019;"Chai, Yibo; Wu, Fengyang; Sun, Rui; Zhang, Zhongliang; Bao, Jie; Ma, Runxin; Peng, Qizhou; Wu, Danqin; Wan, Yexing; Li, Keyu";Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective;2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom);NA;NA;10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230;NA;Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.;2019-12;2021-05-19T12:41:48Z;2021-05-19T12:41:48Z;NA;1564-1571;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Big Data; social media; deep learning; Cloud computing; Distributed processing; Electromagnetic interference; Erbium; mental illness; Social computing; online empathy.; social network";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;predictingfuturealleviationofmentalillnessinsocialmediaanempathybasedsocialnetworkperspective;predicting future alleviation of mental illness in social media an empathybased social network perspective numerous studies have shown that users posts on social media can explicitly or implicitly reflect various human psychological characteristics through mining these data predictive models can be built to forecast and analyze potential mental illness which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments however most existing approaches face severe information loss and ignore the time dynamics of user behaviour to fill the research gaps we use timeaware social networks to combine various information sources in social media posts also machine learning detectors are trained to automatically identify empathic interactions filter out irrelevant information and construct empathybased networks finally we devise a hybrid deep learning algorithm to learn embeddings from the dynamic featurerich networks and predict future alleviation of mental illness compared with strong baselines our approach achieves the bestperforming results with efficient computation speed
4D8L7N55;conferencePaper;2019;"Lopez-Martinez, Daniel; El-Haouij, Neska; Picard, Rosalind";Detection of Real-World Driving-Induced Affective State Using Physiological Signals and Multi-View Multi-Task Machine Learning;2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW);NA;NA;10.1109/ACIIW.2019.8925190;NA;Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance.;2019-09;2021-05-19T12:41:49Z;2021-05-19T12:41:49Z;NA;356-361;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Stress; Machine learning; Feature extraction; Heart rate; Physiology; Affective State; Databases; Multi-task Multi-view Machine Learning; Physiological data; Real-world driving; Vehicles";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;detectionofrealworlddrivinginducedaffectivestateusingphysiologicalsignalsandmultiviewmultitaskmachinelearning;detection of realworld drivinginduced affective state using physiological signals and multiview multitask machine learning affective states have a critical role in driving performance and safety they can degrade driver situation awareness and negatively impact cognitive processes severely diminishing road safety therefore detecting and assessing drivers affective states is crucial in order to help improve the driving experience and increase safety comfort and wellbeing recent advances in affective computing have enabled the detection of such states this may lead to empathic automotive user interfaces that account for the drivers emotional state and influence the driver in order to improve safety in this work we propose a multiview multitask machine learning method for the detection of drivers affective states using physiological signals the proposed approach is able to account for interdrive variability in physiological responses while enabling interpretability of the learned models a factor that is especially important in systems deployed in the real world we evaluate the models on three different datasets containing realworld driving experiences our results indicate that accounting for drivespecific differences significantly improves model performance
GZSEAFU8;conferencePaper;2017;Stock, Ruth Maria;User responses to social robots - experimental insights and psychophysiological measures;2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops);NA;NA;10.1109/PERCOMW.2017.7917582;NA;Summary form only given. Companies in China, Japan and USA started introducing social robots at the customer interface in various industries, such as hospitality services, retailing, and health care services. In contrast to production robots, social robots are humanoid and communicate with speech and gestures with the primary purpose to interact with humans. While the prevalence of social robots is increasing, knowledge about the user acceptance of these robots is scarce. Based on an experimental series, potential stressors as well as emotional and behavioral user responses to the interaction with a social robot are examined. The experimental setting was a hotel reception, in which participants had to interact with the social robot (i.e., the humanoid robot Pepper) in the role of a hotel guest. Participants' psychological responses to the social robot were assessed via self-assessments of the participants. Beyond these standard measures, external raters evaluated the participants' responses by evaluating their facial expressions and gestures on the basis of the video recordings of the experimental procedure. Furthermore, a non-intrusive wearable device, Empatica E4, was used to measure physiological data, in particular heart rate (HR), heart rate variability (HRV) and electrodermal activity (EDA). Results show that participants were able to clearly recognize robotic emotions and behaviors. Furthermore, we could reveal similar patterns within a human-robot-interaction as compared to human-human-interactions.;2017-03;2021-05-19T12:41:50Z;2021-05-19T12:41:50Z;NA;326-326;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;userresponsestosocialrobotsexperimentalinsightsandpsychophysiologicalmeasures;user responses to social robots  experimental insights and psychophysiological measures summary form only given companies in china japan and usa started introducing social robots at the customer interface in various industries such as hospitality services retailing and health care services in contrast to production robots social robots are humanoid and communicate with speech and gestures with the primary purpose to interact with humans while the prevalence of social robots is increasing knowledge about the user acceptance of these robots is scarce based on an experimental series potential stressors as well as emotional and behavioral user responses to the interaction with a social robot are examined the experimental setting was a hotel reception in which participants had to interact with the social robot ie the humanoid robot pepper in the role of a hotel guest participants psychological responses to the social robot were assessed via selfassessments of the participants beyond these standard measures external raters evaluated the participants responses by evaluating their facial expressions and gestures on the basis of the video recordings of the experimental procedure furthermore a nonintrusive wearable device empatica e4 was used to measure physiological data in particular heart rate hr heart rate variability hrv and electrodermal activity eda results show that participants were able to clearly recognize robotic emotions and behaviors furthermore we could reveal similar patterns within a humanrobotinteraction as compared to humanhumaninteractions
3G25GYJA;journalArticle;2021;"Cominelli L; Feri F; Garofalo R; Giannetti C; Meléndez-Jiménez MA; Greco A; Nardelli M; Scilingo EP; Kirchkamp O";Promises and trust in human-robot interaction.;Scientific reports;NA;NA;NA;NA;Understanding human trust in machine partners has become imperative due to the widespread use of intelligent machines in a variety of applications and contexts. The aim of this paper is to investigate whether human-beings trust a social robot-i.e. a human-like robot that embodies emotional states, empathy, and non-verbal communication-differently than other types of agents. To do so, we adapt the well-known economic trust-game proposed by Charness and Dufwenberg (2006) to assess whether receiving a promise from a robot increases human-trust in it. We find that receiving a promise from the robot increases the trust of the human in it, but only for individuals who perceive the robot very similar to a human-being. Importantly, we observe a similar pattern in choices when we replace the humanoid counterpart with a real human but not when it is replaced by a computer-box. Additionally, we investigate participants' psychophysiological reaction in terms of cardiovascular and electrodermal activity. Our results highlight an increased psychophysiological arousal when the game is played with the social robot compared to the computer-box. Taken all together, these results strongly support the development of technologies enhancing the humanity of robots.;2021;2021-06-05T11:16:49Z;2021-06-05T11:16:49Z;NA;NA;NA;1;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 9025257044;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;promisesandtrustinhumanrobotinteraction;promises and trust in humanrobot interaction understanding human trust in machine partners has become imperative due to the widespread use of intelligent machines in a variety of applications and contexts the aim of this paper is to investigate whether humanbeings trust a social robotie a humanlike robot that embodies emotional states empathy and nonverbal communicationdifferently than other types of agents to do so we adapt the wellknown economic trustgame proposed by charness and dufwenberg 2006 to assess whether receiving a promise from a robot increases humantrust in it we find that receiving a promise from the robot increases the trust of the human in it but only for individuals who perceive the robot very similar to a humanbeing importantly we observe a similar pattern in choices when we replace the humanoid counterpart with a real human but not when it is replaced by a computerbox additionally we investigate participants psychophysiological reaction in terms of cardiovascular and electrodermal activity our results highlight an increased psychophysiological arousal when the game is played with the social robot compared to the computerbox taken all together these results strongly support the development of technologies enhancing the humanity of robots
VG6JXBH7;journalArticle;2020;"Sakurai, Eriko; Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea; Frati, Fulvio";Embodiment matters: toward culture-specific robotized counselling;J Reliable Intell Environ Journal of Reliable Intelligent Environments;NA;2199-4668;NA;NA;Abstract: In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures.;2020;2021-06-05T11:21:26Z;2021-06-05T11:21:26Z;NA;129-139;NA;3;6;NA;NA;Embodiment matters;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8644462671;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;embodimentmatterstowardculturespecificrobotizedcounselling;embodiment matters toward culturespecific robotized counselling abstract in this paper we propose adding the traditional japanese nodding behavior to the repertoire of social movements to be used in the context of humanrobot interaction our approach is motivated by the notion that in many cultures trustbuilding can be boosted by small body gestures we discuss the integration of a robot capable of such movements within creca our contextrespectful counseling agent the frequent nodding called unazuki in japan often accompanying the unun sound meaning i agree of japanese onomatopoeia underlines empathy and embodies unconditioned approval we argue that unazuki creates more empathy and promotes longer conversation between the robotic counsellor and people we set up an experiment involving ten subjects to verify these effects our quantitative evaluation is based on the classic metrics of utterance adapted to support the japanese language interactions featuring unazuki showed higher value of this metrics moreover subjects assessed the counselling robots trustworthiness and kindness as very high likert scale 55 versus 345 showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions with unambiguous evidence that embodiment can have a positive impact that warrants further exploration the 3d printable design of our robot supports creating culturespecific libraries of social movements adapting the gestural repertoire to different human cultures
ZYFH2W49;journalArticle;2015;NA;Towards the synthetic self: making othersperceive me as an other;Paladyn: Journal of Behavioral Robotics;NA;2081-4836;NA;NA;Future applications of robotic technologies willinvolve interactions with non-expert humans as machineswill assume the role of companions, teachers or healthcareassistants. In all those tasks social behavior is a key abilitythat needs to be systematically investigated and modelledat the lowest level, as even a minor inconsistency of therobot’s behavior can greatly affect the way humans willperceive it and react to it. Here we propose an integratedarchitecture for generating a socially competent robot.Wevalidate our architecture using a humanoid robot, demonstratingthat gaze, eye contact and utilitarian emotionsplay an essential role in the psychological validity or socialsalience of Human-Robot Interaction (HRI). We showthat this social salience affects both the empathic bondingbetween the human and a humanoid robot and, to acertain extent, the attribution of a Theory of Mind (ToM).More specifically, we investigate whether these social cuesaffect other utilitarian aspects of the interaction such asknowledge transfer within a teaching context.;2015;2021-06-05T11:27:37Z;2021-06-05T11:27:37Z;NA;NA;NA;NA;6;NA;NA;Towards the synthetic self;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 7181678012;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsthesyntheticselfmakingothersperceivemeasanother;towards the synthetic self making othersperceive me as an other future applications of robotic technologies willinvolve interactions with nonexpert humans as machineswill assume the role of companions teachers or healthcareassistants in all those tasks social behavior is a key abilitythat needs to be systematically investigated and modelledat the lowest level as even a minor inconsistency of therobots behavior can greatly affect the way humans willperceive it and react to it here we propose an integratedarchitecture for generating a socially competent robotwevalidate our architecture using a humanoid robot demonstratingthat gaze eye contact and utilitarian emotionsplay an essential role in the psychological validity or socialsalience of humanrobot interaction hri we showthat this social salience affects both the empathic bondingbetween the human and a humanoid robot and to acertain extent the attribution of a theory of mind tommore specifically we investigate whether these social cuesaffect other utilitarian aspects of the interaction such asknowledge transfer within a teaching context
9NEMTAEA;journalArticle;2021;NA;Vocal Synchrony of Robots Boosts Positive Affective Empathy;Applied Sciences;NA;2076-3417;NA;NA;Robots that can talk with humans play increasingly important roles in society. However, current conversation robots remain unskilled at eliciting empathic feelings in humans. To address this problem, we used a robot that speaks in a voice synchronized with human vocal prosody. We conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization. We assessed seven subjective responses related to affective empathy (e.g., emotional connection) and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level. The subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the de-synchronizing condition. The physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization. These findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses.;2021;2021-06-05T11:32:03Z;2021-06-05T11:32:03Z;NA;NA;NA;2502;11;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8974746860;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;vocalsynchronyofrobotsboostspositiveaffectiveempathy;vocal synchrony of robots boosts positive affective empathy robots that can talk with humans play increasingly important roles in society however current conversation robots remain unskilled at eliciting empathic feelings in humans to address this problem we used a robot that speaks in a voice synchronized with human vocal prosody we conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization we assessed seven subjective responses related to affective empathy eg emotional connection and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level the subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the desynchronizing condition the physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization these findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses
HPV4W3WS;journalArticle;2019;NA;Affective Embodied Agents and Their Effect on Decision Making;Proceedings;NA;2504-3900;NA;NA;Embodied agents, such as avatars and social robots, are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor. This influences how users perceive these technologies and how they interact with them. We report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being. Twenty-one individuals were asked to play the ultimatum game, playing the role of a responder against another person, a computer, an avatar and a robot for a total of 32 games (8 per condition). We hypothesize that affective expressions by avatars and robots influence the emotional state of the users, leading them to irrational behavior by rejecting unfair proposals. We monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder. Our results show that most fair offers were accepted while most unfair offers were rejected. However, participants rejected more very unfair offers made by people and computers than by the avatars or robots.;2019;2021-06-05T11:34:10Z;2021-06-05T11:34:10Z;NA;NA;NA;1;31;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8464672719;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;affectiveembodiedagentsandtheireffectondecisionmaking;affective embodied agents and their effect on decision making embodied agents such as avatars and social robots are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor this influences how users perceive these technologies and how they interact with them we report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being twentyone individuals were asked to play the ultimatum game playing the role of a responder against another person a computer an avatar and a robot for a total of 32 games 8 per condition we hypothesize that affective expressions by avatars and robots influence the emotional state of the users leading them to irrational behavior by rejecting unfair proposals we monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder our results show that most fair offers were accepted while most unfair offers were rejected however participants rejected more very unfair offers made by people and computers than by the avatars or robots
HWDTYRT7;journalArticle;2017;"Richard Stillman II; Richard Stillman II";Public professionalism in an era of radical transformations: its meaning, challenges, and training;Revista de Administração Pública;NA;0034-7612;NA;NA;"ArticlePublic professionalism in an era of radical transformations: its meaning, challenges, and trainingProfesionalismo público en una era de transformaciones radicales: su significado, desafíos y entrenamientoRichard Stillman II1  2  1University of Colorado / EUA2Public Administration Review/ EUAPublic professionalism lives within a schizophrenic world today. On one hand more people aspire to be professionals than ever before. As the late Everett Hughes, perhaps the most eminent scholar of this topic, once wrote, “professions are more numerous than ever before. Professional people are a larger portion of the labor force. The professional attitude or mood is likewise more widespread; professional status more sought after.” Everywhere in advanced and developing nations public professionals and professionalism are triumphant in contributing to the GDP growth to shaping and implementing most if not all areas of public policy. In 2017 27% of the full-time American Federal Workforce are classed as professionals, 37% as administrators, and 27% as technical personnel such as 5,521 economists, 35,529 nurses, 20,115 electronics engineers, 17,118 attorneys, and 242 museum curators. Thus over a one-third of federal employees are classed as “professional-technical (a figure which would be much higher if contract employees were included). So widespread is professionalization that long ago, Frederick Mosher termed government as “the professional state”; or Don Price referred to it as “the scientific estate” or Zbigniew Brzezinski called it “the technocratic society”. Whatever it is labelled, public professionals unquestionably make modern government tick and contemporary society run. Yet, in 2017 western nations are reeling from widespread, determined populist revolts against unelected officials. Voter cries against public professionals and their pervasive influence over shaping public policy are loud and frequent. The Brexit vote last year in England sought independence from those unseen, unelected EU officials in Brussels. Donald Trump’s presidential inauguration this year can be attributed significantly to the fact he was “an outsider” who had never been an elected politician, nor even served in any public position, even the military (the first such president ever in U.S. History). His campaign targets were established institutions such as Nato, the Paris Climate Accords, Affordable Health Care, the CIA, and more recently the FBI Director. France, Italy, the Netherlands, and others have witnessed the rise and power of similar populist leaders with wide-ranging agendas to cut government and/or radically reform it. In short, recently the electorate everywhere seem to want to “apply a stick to the backsides” and “bloody the noses” of experts! Ideally rid the world of them!This lecture will attempt to address the challenges of professionals who work in this Janus-Faced, contradictory world that both enthusiastically embraces and forcefully rejects them by examining first, what is public professionalism today? How do we define the term nowadays? What are its major foundational values?Second, what are the key political-sociological-economic trends influencing the activities and shaping actions of public professionals? Their sources and impacts? And how are these forces reshaping the work professionals perform as well as those foundational values that served in the past to create and sustain public professionalism?Finally, given these new realities of radical transformations confronting public professionals world-wide in the second decade of the 21st century, how best can teachers educate those aiming for careers as public professionals as well as advance the skills and expertise of “old hands” who are already in the public service? How can “it” be best taught, given the immense challenges governments everywhere confront?Before going further, it is important to spell out the premises behind my lecture. They are six-fold, relatively clear-cut, and simple:Government decisions and official behavior immensely impact every nation and the world as a whole by influencing society’s development, its economic prosperity, and legitimacy of democracy;The great bulk of public sector decisions, indeed THE key decisions, are determined by public professionals who are largely unelected and tenured;The quality and kinds of decisions and actions these public professionals make depend upon their skills, orientation, outlooks, and values;These professional qualities depend heavily upon their backgrounds, training, education, career development, as well as their current involvement in whatever professional associations or groups they belong;Government is composed of many professions-physicians, lawyers, engineers, etc.-and so it never can hope to become just one professional body, but rather public sector professionalization realistically involves advancing the degree of their individual influence on decision-making as well as inculcating professional values throughout many groups working in the public sector; andThe activities and challenges facing public professionals as well as the advancement of professionalism within each nation are not identical but share many of the same attributes world-wide today.Since “public professional” and “public professionalism” are frequently referred to, it is first essential to define what we are talking about here. These terms are slippery, even ambiguous and open to many interpretations and ways of thinking. Oxford English Dictionary, for example, tells us its earliest meaning derived from “professing” or someone who “professes” to know more about a subject and is better qualified to do a job as a result. “The occupation which one professes to be skilled in and to follow […] A vocation in which professional knowledge of some branch of learning is used in its application to the affairs of others, and in the practice of the art based upon it.” Originally the term “professional” was confined to the traditional callings of divinity, law, medicine, and the military. Today it applies to a far wider, more pervasive, and ever growing groups-some employed exclusively by government such as foreign service officers, city managers, police, military, and urban planners and others employed across the public, nonprofit, and private sectors who enormously influence public sector choices such as lawyers, engineers, scientists, physicians, and economists. And this does not even begin to encompass the newly emerging professions such as cyber-security and emergency disaster personnel or other many specializations and sub-specializations. Given the ever-growing numbers of specialized occupations, can these recent job categories be labelled as professionals? It is not easy to tell nor offer up clear-cut definitions. While there is no commonly agreed up meaning today of public professionals and/or professionalization of the public service, Frederick Mosher’s definition is useful, both precise and flexible enough to fit common-day understanding:[…] a more or less specialized and purposeful field of human activity which require some specialized education or training (though it may be acquired on the job), which offers a career of life work, and enjoys a relatively high status. It normally aspires to social, not selfish, purpose. Usually, but not always, it requires a degree or certification, and credential of some kind. Often its members join in a professional organization, local, state, or national, which enunciates standards and ethics of professional performance sometimes with the powers of enforcement.Note the three value components of Mosher’s definition that serve as the foundational norms of public professionals past and present: applied expertise, corporate identity, and ethical responsibility.First, and above all, public professionalism is based upon expertise. Knowledge, theoretically based but pragmatically applied to shaping directly or indirectly human affairs, serve as origins and ongoing rationale of every professional’s existence. The modern military profession grew out the creation of the formation of the nation-state in the 15th and 16th centuries that demanded trained expertise in what Harold Lasswell once characterized as “the management of violence”. The American City Manager Profession was a mundane result of what to do about potholes in city streets thanks to the newly invented automobile at the dawn of the 20th century. Staunton, Virginia hired the first city manager in 1909, Charles Ashburner, a trained civil engineer, to deal with that pothole problem. Similarly, contemporary responses to specific empirical necessities of coping with cloud computing, applying new crime-fighting CSI techniques, dealing with a sudden outbreak of a heretofore unknown medical disease, or combating the threats of Isis are likewise the cause of the origins and growth of new professions. An urbanized, industrialized, globalized, and information-driven world spawns professionalization at a rapid rate, far more rapid than ever before. Not too long ago, someone went to “an ear, nose, and throat doctor” to treat ailments related to those body parts, but nowadays a myriad of specialists subdivide work in that single area with strange unpronounceable titles such as otolaryngologists, pulmonologists, gastroenterologists, allergists, and much more. Specialization is driven by speedier accumulation of scientific knowledge that requires a subdivision of labor but it also stems from self-interest, i.e. specialized expertise is generally considered higher status and receives higher pay. But whatever the cause of narrowing specialization, according to a recent empirical study by Lotte Anderson and Lene Peterson, professionalism is negatively correlated with compassion, defined as being emotionally (empathically) based motivation to do good for others by improving public service delivery. Rather professional norms of applied expertise are the determining factor for effective service delivery performance to clients rather than the application of more humanly compassion or user friendly approaches. In short, the degree of specialized applied and theoretical knowledge and the firmness and consistence of its application remain the cornerstone of “best practices” of professionals everywhere.Second, a corporate identity forges development and expansion of professions. It also gives structure and purpose to their existence, sets boundaries for the scope and substance of any professional activity, and establishes lines of who belongs inside its ranks and who does not. It further defines and creates “professional elites” who govern and control internal “hidden hierarchies”, in the words of Corinne Gibbs. State Bar Associations or Medical Societies for traditional fields like Law and Medicine or the International City/County Managers’ Association and Society of Civil Engineers for newer careers in local public management and civil engineers provide such corporate structures in America and define the best educational practices, entrance routes, credentialing requirements, continuing training options, codes of conduct, and methods of enforcement. They serve as advocates for a profession by advancing its cause through publicity campaigns with many varieties of internet, lobbying, and hard-copy literature and disseminate knowledge through regular meetings and serious journal publications. As a recent study by Mirko Noordegraaf underscores, professionalism is developed and nurtured via “connectedness” which is advanced in three ways: between professional actions and practices, between segments and groups, and between workplaces and other spaces. Above all, professionals resist political intrusion into their work. Ironically professionals of all stripes often express hostility to anything smacking of “the political” although public professionals by definition work for government and must be ultimately responsive to elected officials. Likewise, they are keen to maintain their independence from other professional groups. Fierce rivalries inside government are frequent between neighboring professions like the repeated conflicts among army, navy, air force personnel. Often invisible to the public and little studied by scholars, these professional associations and their elites exert powerful influences over shaping modern-day professional identities and the public actions they take.Finally, ethical responsibility undergirds as every profession’s ultimate raison d’etre. Professions are rooted in moral purposes of serving others beyond selfish interests. Such moral aims are more often than not codified in written statements, explicit codes of conduct, frequently combined with enforceable mechanisms to ensure their compliance. These may be framed in ancient Hippocratic Oath of Doctors to do no harm or more recent public professional codes of ethics of the Government Finance Officers Association or the American Society for Public Administration that spell out complicated professional, moral, legal standards of conduct for association members. Though realistically the transmission of ethical norms throughout professional ranks is not a product of written documents or codes of ethics but through informal communications of what is acceptable behavior or not. Especially the role models of elites serve to set standards for “best practices”, norms of good behavior, essential training, “ideal career tracks”, and what defines success or not within the field. Conferences, in-house journals, informal discussions inculcate ethical values informally throughout the membership. As James Svara wrote recently, the essence of the articulated ethical values for public professions should stress serving “the public with respect, concern, courtesy, and responsiveness, recognizing that service to the public is beyond service to oneself.” Effective enforcement prods strong, ongoing reminders that violations have significant career consequences-both in the short term and long run. The challenges of ensuring effective ethical enforcement within every profession remain some of the most difficult, complex, and enduring issues they confront.So how are the socio-economic-political trends of today reshaping these professional foundational values for tomorrow? What are the challenges professions face world-wide in recent years? Are the core values upon which public professions were created and grew being strengthen? Or, in decline? My thesis: the traditional three values-applied expertise, corporate identity, and ethical responsibility-upon which public professionals originated and are sustained nowadays are being transformed profoundly across the planet by a series of influential, even contradictory forces. Here are several that appear prominently world-wide, serving shape and reshape the framing values of public professionalism:Populist Revolt vs. the Necessity for Expertise in the Public Sector: As was indicated at the beginning of this lecture, western democracies in recent years experienced strong reactions to unelected officials of all stripes and elected many committed to cutting or eliminating such individuals, but at the same time the demand for more government services remains unabated. How to reconcile these opposites which simultaneously reject and sustain effective government as well as the core values of neutral, objective expertise at the heart of public professionalism?Social Media vs. Sustained Expertise: In 2007 Apple launched it iPhone; late 2006 Facebook opened its doors; Google came out with the Android operating system in 2007; Amazon introduced Kindle in 2007; and Airbnb started in 2007. Thanks to social media the last decade witnessed a fundamental reshaping of individual behavior, work, commerce, finance, education, government, the economy, and yes, public professionalism. Social media asks everyone to be immediately involved, offering immediate answers to complex issues, plus making rapidly shifting demands on public officials. Yes, social media is more democratic because it allows everyone to be involved almost instantaneously, but simultaneously social media fosters “presentism” that drives out long-term thought and action. So how can public professionals who value-indeed require--long term, neutral, applied, objective expertise for problem solving cope with social media? How can they nurture applied expertise that involves thoughtful reflection and careful decision-making among those “who know best”? Given the massive data available-more information than accumulated by humans up to 2003-what is the right sort of data to identify, collect, and utilize vs. ignore and disregard? How do we know the real impact of social media on public professionals?The Pseudo-Event vs. the Real Event: Many years ago Daniel Boorstin referred to a media created event that was unreal or fake as “a pseudo-event”. The rise of social media has accelerated what now is called “fake news”. Often pseudo-events create reality that happens and has serious consequences, such as suicides, staged riots, or shootings. Yet, professionalism rests upon honest information, verifiable facts, as well as objective analysis. Sorting out truth from fiction has always been challenging for public professionals, but the expansion of social media during the last decade only exacerbates an already devilish dilemma. How can professionals discern fact from fiction today and respond appropriately in an increasingly social media saturated world?The Drive to Specialize vs. Integrated Professional Policy-Making: As was emphasized before, the drive to specialize and sub-specialize and so on is apparent within the professional ranks as new issues and new information demand new varieties of expertise. The result is what some term, “stovepipes” throughout government or little clusters of experts who talk to themselves rather than those outside their specialization, beyond their immediate agency, or wider general public. Hence, the right hand often is unaware of what the left hand is doing. Competition among professional groups such as within the defense department-army, air force, navy-further inhibits collaboration. Yet, effective public policy making requires integration across many professional fields to succeed. No professional group can go it alone in any policy-making arena. Thus the dilemma: how to foster integration and collaboration across increasingly narrow specialized and competitive professional ranks?Proliferation of Temporary Contractors vs. In-House Professionals: The recent devastating leaks in American Intelligence have all been the result of temporary contract employees such as Edward Snowden. Increased use of contractors is often justified politically for keeping costs down and cutting government employees. That is good political rhetoric, but there is little evidence to support such rationales. Instead, in the words of Hugh Heclo, we have become a “government of strangers”. As a result, there is potential for a serious erosion of a professional corporate identity due to the lack of commonly shared professional norms plus effective ethical enforcement mechanisms. Hence, the key question: how can professionalization of government as a whole advance when it is seriously challenged from within due to the rise of temporary contract workers (which in national security and law enforcement cases can jeopardize human life as well)?Global Interconnectedness vs. Local Accountability: As mentioned before, professional groups are rooted in state and community level associations such as the State Bar Association or State Medical Societies for entrance exams, credentialing, ethics enforcement, and much more. Yet, increasingly professional work spans the global or at least are interconnected beyond the borders of any single nation. Again, problem-solving demands wider international cooperation and collaboration to succeed in almost every field today from environmental protection to military intervention. Hence, how to insure that public professionals, educated and credentialed within a local jurisdiction, are prepared to see “the big picture” and work effectively with colleagues across national boundaries?Increased Ethical Responsibilities vs. Limited Ethical Training: Not very long ago, it was assumed if you studied public administration, you WERE ETHICAL! Hence, MPA programs until recently were largely devoted to training students in the “bread and butter” topics of training for the 3Es-economy, efficiency, effectiveness-via classes in organization and management, budgeting and finance, human resources management, etc. Few teachers paid much attention to ethics and the subject was largely absent from public administration curricula. While more is being done in classrooms to incorporate ethical training as well as establishing codes of conduct that are enforced by professional associations, the rapid escalation of ethical responsibilities and demands upon public officials continues to grow at a staggering rate. From first-line employee to top department head in government, ethical dilemmas are profound and pervasive. So the central, if not THE CENTRAL CHALLENGE, confronting the field today is: how to develop ethical awareness among professionals in order to make and to apply ethically sound choices for resolving problems they confront?Specialist vs. Generalist Public Service Education: Universities remain conveyor belts for advancing expertise, credentialing, and educating public professionals. Until relatively recently it was easy to name the top public administration schools, the top scholars in the field, an agreed upon means of academic preparation, and recognize a common curriculum for training throughout the field. A generalist orientation largely prepared students for a variety of public sector careers. While today university training beyond the BS or BA degree is generally accepted as the appropriate route to professional careers in government, the choice of schools, curricula, and specializations are staggering in the USA. Generalist degrees have largely declined or disappeared in favor of highly narrow subject matter such as defense policy making, emergency management training, law enforcement administration, budgeting and financial management, or human resources management. Once many of these were designated as sub-fields of a generalist MPA degree but now are offered as stand-alone graduate degrees. But does specialized training adequately prepare students for government work that requires understanding “the big picture”, how to integrate the parts, and then make them operate altogether as a “whole ball of wax”? At what point does increasing professional specialization become counterproductive to achieving “the public interest”?A Clear Dichotomy vs. An Integrated Political/Professional Team: Since the rise of democracy with elected officials and growth of bureaucracies with appointed public professions, the dilemma has always been how to “mesh” the two distinctively different realms of the political and administrative into an effective collaborative team to serve the public interest, especially since both have profoundly different incentive structures, agendas, outlooks, and purposes. The issue is as old as public administration itself; indeed, it was a major concern of Woodrow Wilson’s first essay written in America on the subject, The study of administration (1887), i.e. how to ensure responsible government in light of the creation of a new civil service system? How to make certain professionals are accountable to the public? The topic remains front and center to the public sector world-wide today, namely how can elected officials hold appointed public professionals accountable while at the same time how can professionals offer the best neutral, objective, independent advice and service to elected representatives? Everywhere in the world nowadays this issue of “marrying” political and professional is not only challenging but decides ultimately the fate of many, if not all, key public policy debates.Certainly other current world-wide trends impacting public professionalism could be added to this list, such as citizen participation, union representation in government, and career mobility. But I tried to emphasize those most recent, most critical, and with the greatest potential global impacts on the public sector. Granted, many of my examples and citations were drawn from the USA. So my perspectives and this discussion may well be somewhat limited, parochial, and even biased. I certainly know little about Brazilian public administration and the specific challenges your public service confronts, but I suspect many of the trends outlined above are effecting your nation and its public sector in equally profound, pervasive, and often unknown ways. Especially for those seminal public profession values of applied expertise, corporate identity, and ethical responsibility, my hunch is that individually and collectively these aforementioned forces serve to fragment, diffuse, even negate many aspects of foundational professional values in Brazil as well as everywhere abroad. Thus my central argument for advancing public service education is aimed to revitalize, reinvigorate, and rejuvenate those core values that created and developed public professionalism as we now know it and are under attack in many quarters. Why? Again, as emphasized in the stated premises to this lecture, government decisions and official behavior have immense impact on any nation and the world-social, political, economic-hence, it is the education of public professionals that is critical to shaping public choices and actions. Effective government and a just modern society cannot work without a professionalized public service. If Carl Friedrich once wrote that “bureaucracy is the core of modern government”, certainly “public professionals” are the core of that core.So what are the best routes for advancing public professionalism in the second decade of the 21st century and beyond? Again, I must claim ignorance about Brazil’s public service and its particular contemporary challenges. Though permit me to discuss general educational strategies in light of the nine forgoing global trends and speculate about routes that can significantly serve to strengthen and advance those three foundational professional values. Here I will sum up this talk--not by outlining specific remedies or educational programs and curricula, not arguing for part-time vs. full time alternatives, not in-house vs. university training, not online vs. in classroom face-to-face teaching-but rather by speculating on general educational strategies aimed at broadly strengthening the three seminal foundational values of public professionalism.First, by fostering greater constitutional understanding: Here I am not suggesting more legal training in the specifics of constitutional law. Rather I refer to the broader Aristotelian sense of comprehending the basic purposes, meaning, and influence on public professionals of framing legal documents for every nation. In the case of the United States Constitution, such instruction would not ask students to learn the specifics of the 6 thousand word framing document but rather to comprehend its intellectual origins in the late 18th century and why that era and the men involved fashioned a very unique founding arrangement; its central aims as embodied in its preamble that lay out possibilities, limits, and roles of today’s public sector; its general structure that shapes the current actions and constraints on modern American Government; as well as its 27 amendments since 1789 and evolving interpretations over time that influence public sector activities today. By linking greater constitutional understanding to contemporary public professional education can rejuvenate and invigorate basic ethical values that undergird all professional decision-making activities.Second, by encouraging deeper appreciation of professional history and the lives of professional leaders: Professionals live within a stream of history that runs deep and wide and decisively influences their modern corporate identities of who they are, what they do, and how they operate in the modern-day world. History can tremendously enrich professional careers, inspire their work, by knowledge of their past development, key founders, their accomplishments and, yes, failures. It can broaden their way of thinking about problems; offer examples of not just how-to-do-something, but how-to-do-it-well; what works best or not; as well as approaches and strategies that succeed-or fail. Such education would include reading about the lives of the great professional leaders: why they entered the field, how they learned their professional skills, what they learned about, experienced in their apprenticeships that fostered their career development, how they rose to prominence within the professional ranks, what inspired their deep commitment to this line of work, role models that aided their advancement, and decisions they made that made them historically famous-or infamous as professional leaders. Much of professional education requires hard work and sheer perspiration. History and biography offers invaluable inspiration for those who aspire to top leadership ranks as well as those “old hands” already in charge.Third, by grasping lessons of administrative cases: The world of government does not present its practitioners with simple questions or neat solutions. Especially as they move up in every organizational hierarchy, administrative issues become more and more complex. Professionals in government do not wake up in the morning and say, “Today I will deal with a budget issue”; “tomorrow I will address policy of such and such an area” and “the next day hiring a new employee will be my agenda”. Nothing is so neat and tidy in government. Rather, everything is usually interconnected, events come upon desks unpredictably, and choices are more often than not neither right nor wrong, but mixed with a lot grey uncertainty, without full information, and considerable questions as to the results and outcomes to be achieved. Here is where administrative cases are a necessary pedagogical tool. Unlike medical school or law school cases with often clear-cut right and wrong answers, the best administrative cases are open to many interpretations and force students to see the ambiguity and complexity of so much of what real-life government decision-making is all about. The best administrative cases encourage students to appreciate and navigate such cloudy operational environments as well as learn how successful policy-making and implementation of policy involves working across agency, departmental, and unit lines, using multiple administrative skills of budgeting and finance, human resources, planning, and so on in order to achieve results. In short, cases focusing upon gaining collaborative management skills, seeing “the big picture” beyond the limited intellectual horizons of most professional training, are vital for advancing professionalization in all parts of modern government.Finally, by studying the future: The old adage that we should study the future because that is where we spend the rest of our lives is certainly true or contains an important truth for those who work in the public sector. For better or worse-or better AND worse-virtually all government activities involve shaping the future. It may concern big choices of peace or war, or simply entail plugging numbers into a line-item budget or hiring a new employee. Such big choices or mundane tasks in the public service help to decide what tomorrow will become. The destinies of societies everywhere are the hands of public professionals who are employed throughout government, deciding on the social challenges we face, what they are, and how to confront them by making choices big and small. Though few would debate the value of knowing about the future, the question is how? Or, how to educate professionals in futuristic learning? Certainly the rise of “big data” and its world-wide immense influence on business and government planning and decision-making is apparent and fact of modern life. Thus learning to gather, comprehend, and analyze large data, separating the essential from non-essential, fact from fiction, unlocking the relevant information related to the questions at hand in order to glean future trends is invaluable for predicting the future. But other less grand routes to glimpsing the future can be found by learning how to conduct focus groups, sample expert opinion, or gather reference material from a wide variety of document sources. While certainly no one-best-way exists to properly examine where we are headed tomorrow, the most striking aspect of professional education to date is how little involves thinking about the future. Part of the problem is the popular association of futuristic studies with tea-leaf reading and casting horoscopes, activities not enthusiastically embraced by university academics-so far. But there are numerous more reputable technological-scientific methods worth at least somehow, someway incorporating into our professional training programs which include: trend extrapolation, genius forecasting, Delphic exercises, simulation, scenario building, cross-impact matrix development and much more that can help us predict and plan for tomorrow. Perhaps we cannot see the future with precision or a degree of accuracy we wish, but some guidance is better than nothing to point the way forward in order assist professionals to plan better today. Simply because we do not know how to educate for “it” or so far there is no agreed upon proper training methodology are no excuses for not trying-given that the stakes are so high for professionals working in government, indeed more generally for society’s prosperity and survival.Received: June 21, 2017; Accepted: October 26, 2017Richard Stillman II - Professor of Public Administration at University of Colorado / EUA and Former Editor-in-chief at Public Administration Review / EUA. E-mail: Richard.Stillman@ucdenver.edu. This is an open-access article distributed under the terms of the Creative Commons Attribution License";2017;2021-06-05T11:35:50Z;2021-06-05T11:35:50Z;NA;917-926;NA;6;51;NA;NA;Public professionalism in an era of radical transformations;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;Open WorldCat;NA;OCLC: 8522323859;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;publicprofessionalisminaneraofradicaltransformationsitsmeaningchallengesandtraining;public professionalism in an era of radical transformations its meaning challenges and training articlepublic professionalism in an era of radical transformations its meaning challenges and trainingprofesionalismo público en una era de transformaciones radicales su significado desafíos y entrenamientorichard stillman ii1  2  1university of colorado  eua2public administration review euapublic professionalism lives within a schizophrenic world today on one hand more people aspire to be professionals than ever before as the late everett hughes perhaps the most eminent scholar of this topic once wrote professions are more numerous than ever before professional people are a larger portion of the labor force the professional attitude or mood is likewise more widespread professional status more sought after everywhere in advanced and developing nations public professionals and professionalism are triumphant in contributing to the gdp growth to shaping and implementing most if not all areas of public policy in 2017 27 of the fulltime american federal workforce are classed as professionals 37 as administrators and 27 as technical personnel such as 5521 economists 35529 nurses 20115 electronics engineers 17118 attorneys and 242 museum curators thus over a onethird of federal employees are classed as professionaltechnical a figure which would be much higher if contract employees were included so widespread is professionalization that long ago frederick mosher termed government as the professional state or don price referred to it as the scientific estate or zbigniew brzezinski called it the technocratic society whatever it is labelled public professionals unquestionably make modern government tick and contemporary society run yet in 2017 western nations are reeling from widespread determined populist revolts against unelected officials voter cries against public professionals and their pervasive influence over shaping public policy are loud and frequent the brexit vote last year in england sought independence from those unseen unelected eu officials in brussels donald trumps presidential inauguration this year can be attributed significantly to the fact he was an outsider who had never been an elected politician nor even served in any public position even the military the first such president ever in us history his campaign targets were established institutions such as nato the paris climate accords affordable health care the cia and more recently the fbi director france italy the netherlands and others have witnessed the rise and power of similar populist leaders with wideranging agendas to cut government andor radically reform it in short recently the electorate everywhere seem to want to apply a stick to the backsides and bloody the noses of experts ideally rid the world of themthis lecture will attempt to address the challenges of professionals who work in this janusfaced contradictory world that both enthusiastically embraces and forcefully rejects them by examining first what is public professionalism today how do we define the term nowadays what are its major foundational valuessecond what are the key politicalsociologicaleconomic trends influencing the activities and shaping actions of public professionals their sources and impacts and how are these forces reshaping the work professionals perform as well as those foundational values that served in the past to create and sustain public professionalismfinally given these new realities of radical transformations confronting public professionals worldwide in the second decade of the 21st century how best can teachers educate those aiming for careers as public professionals as well as advance the skills and expertise of old hands who are already in the public service how can it be best taught given the immense challenges governments everywhere confrontbefore going further it is important to spell out the premises behind my lecture they are sixfold relatively clearcut and simplegovernment decisions and official behavior immensely impact every nation and the world as a whole by influencing societys development its economic prosperity and legitimacy of democracythe great bulk of public sector decisions indeed the key decisions are determined by public professionals who are largely unelected and tenuredthe quality and kinds of decisions and actions these public professionals make depend upon their skills orientation outlooks and valuesthese professional qualities depend heavily upon their backgrounds training education career development as well as their current involvement in whatever professional associations or groups they belonggovernment is composed of many professionsphysicians lawyers engineers etcand so it never can hope to become just one professional body but rather public sector professionalization realistically involves advancing the degree of their individual influence on decisionmaking as well as inculcating professional values throughout many groups working in the public sector andthe activities and challenges facing public professionals as well as the advancement of professionalism within each nation are not identical but share many of the same attributes worldwide todaysince public professional and public professionalism are frequently referred to it is first essential to define what we are talking about here these terms are slippery even ambiguous and open to many interpretations and ways of thinking oxford english dictionary for example tells us its earliest meaning derived from professing or someone who professes to know more about a subject and is better qualified to do a job as a result the occupation which one professes to be skilled in and to follow  a vocation in which professional knowledge of some branch of learning is used in its application to the affairs of others and in the practice of the art based upon it originally the term professional was confined to the traditional callings of divinity law medicine and the military today it applies to a far wider more pervasive and ever growing groupssome employed exclusively by government such as foreign service officers city managers police military and urban planners and others employed across the public nonprofit and private sectors who enormously influence public sector choices such as lawyers engineers scientists physicians and economists and this does not even begin to encompass the newly emerging professions such as cybersecurity and emergency disaster personnel or other many specializations and subspecializations given the evergrowing numbers of specialized occupations can these recent job categories be labelled as professionals it is not easy to tell nor offer up clearcut definitions while there is no commonly agreed up meaning today of public professionals andor professionalization of the public service frederick moshers definition is useful both precise and flexible enough to fit commonday understanding a more or less specialized and purposeful field of human activity which require some specialized education or training though it may be acquired on the job which offers a career of life work and enjoys a relatively high status it normally aspires to social not selfish purpose usually but not always it requires a degree or certification and credential of some kind often its members join in a professional organization local state or national which enunciates standards and ethics of professional performance sometimes with the powers of enforcementnote the three value components of moshers definition that serve as the foundational norms of public professionals past and present applied expertise corporate identity and ethical responsibilityfirst and above all public professionalism is based upon expertise knowledge theoretically based but pragmatically applied to shaping directly or indirectly human affairs serve as origins and ongoing rationale of every professionals existence the modern military profession grew out the creation of the formation of the nationstate in the 15th and 16th centuries that demanded trained expertise in what harold lasswell once characterized as the management of violence the american city manager profession was a mundane result of what to do about potholes in city streets thanks to the newly invented automobile at the dawn of the 20th century staunton virginia hired the first city manager in 1909 charles ashburner a trained civil engineer to deal with that pothole problem similarly contemporary responses to specific empirical necessities of coping with cloud computing applying new crimefighting csi techniques dealing with a sudden outbreak of a heretofore unknown medical disease or combating the threats of isis are likewise the cause of the origins and growth of new professions an urbanized industrialized globalized and informationdriven world spawns professionalization at a rapid rate far more rapid than ever before not too long ago someone went to an ear nose and throat doctor to treat ailments related to those body parts but nowadays a myriad of specialists subdivide work in that single area with strange unpronounceable titles such as otolaryngologists pulmonologists gastroenterologists allergists and much more specialization is driven by speedier accumulation of scientific knowledge that requires a subdivision of labor but it also stems from selfinterest ie specialized expertise is generally considered higher status and receives higher pay but whatever the cause of narrowing specialization according to a recent empirical study by lotte anderson and lene peterson professionalism is negatively correlated with compassion defined as being emotionally empathically based motivation to do good for others by improving public service delivery rather professional norms of applied expertise are the determining factor for effective service delivery performance to clients rather than the application of more humanly compassion or user friendly approaches in short the degree of specialized applied and theoretical knowledge and the firmness and consistence of its application remain the cornerstone of best practices of professionals everywheresecond a corporate identity forges development and expansion of professions it also gives structure and purpose to their existence sets boundaries for the scope and substance of any professional activity and establishes lines of who belongs inside its ranks and who does not it further defines and creates professional elites who govern and control internal hidden hierarchies in the words of corinne gibbs state bar associations or medical societies for traditional fields like law and medicine or the international citycounty managers association and society of civil engineers for newer careers in local public management and civil engineers provide such corporate structures in america and define the best educational practices entrance routes credentialing requirements continuing training options codes of conduct and methods of enforcement they serve as advocates for a profession by advancing its cause through publicity campaigns with many varieties of internet lobbying and hardcopy literature and disseminate knowledge through regular meetings and serious journal publications as a recent study by mirko noordegraaf underscores professionalism is developed and nurtured via connectedness which is advanced in three ways between professional actions and practices between segments and groups and between workplaces and other spaces above all professionals resist political intrusion into their work ironically professionals of all stripes often express hostility to anything smacking of the political although public professionals by definition work for government and must be ultimately responsive to elected officials likewise they are keen to maintain their independence from other professional groups fierce rivalries inside government are frequent between neighboring professions like the repeated conflicts among army navy air force personnel often invisible to the public and little studied by scholars these professional associations and their elites exert powerful influences over shaping modernday professional identities and the public actions they takefinally ethical responsibility undergirds as every professions ultimate raison detre professions are rooted in moral purposes of serving others beyond selfish interests such moral aims are more often than not codified in written statements explicit codes of conduct frequently combined with enforceable mechanisms to ensure their compliance these may be framed in ancient hippocratic oath of doctors to do no harm or more recent public professional codes of ethics of the government finance officers association or the american society for public administration that spell out complicated professional moral legal standards of conduct for association members though realistically the transmission of ethical norms throughout professional ranks is not a product of written documents or codes of ethics but through informal communications of what is acceptable behavior or not especially the role models of elites serve to set standards for best practices norms of good behavior essential training ideal career tracks and what defines success or not within the field conferences inhouse journals informal discussions inculcate ethical values informally throughout the membership as james svara wrote recently the essence of the articulated ethical values for public professions should stress serving the public with respect concern courtesy and responsiveness recognizing that service to the public is beyond service to oneself effective enforcement prods strong ongoing reminders that violations have significant career consequencesboth in the short term and long run the challenges of ensuring effective ethical enforcement within every profession remain some of the most difficult complex and enduring issues they confrontso how are the socioeconomicpolitical trends of today reshaping these professional foundational values for tomorrow what are the challenges professions face worldwide in recent years are the core values upon which public professions were created and grew being strengthen or in decline my thesis the traditional three valuesapplied expertise corporate identity and ethical responsibilityupon which public professionals originated and are sustained nowadays are being transformed profoundly across the planet by a series of influential even contradictory forces here are several that appear prominently worldwide serving shape and reshape the framing values of public professionalismpopulist revolt vs the necessity for expertise in the public sector as was indicated at the beginning of this lecture western democracies in recent years experienced strong reactions to unelected officials of all stripes and elected many committed to cutting or eliminating such individuals but at the same time the demand for more government services remains unabated how to reconcile these opposites which simultaneously reject and sustain effective government as well as the core values of neutral objective expertise at the heart of public professionalismsocial media vs sustained expertise in 2007 apple launched it iphone late 2006 facebook opened its doors google came out with the android operating system in 2007 amazon introduced kindle in 2007 and airbnb started in 2007 thanks to social media the last decade witnessed a fundamental reshaping of individual behavior work commerce finance education government the economy and yes public professionalism social media asks everyone to be immediately involved offering immediate answers to complex issues plus making rapidly shifting demands on public officials yes social media is more democratic because it allows everyone to be involved almost instantaneously but simultaneously social media fosters presentism that drives out longterm thought and action so how can public professionals who valueindeed requirelong term neutral applied objective expertise for problem solving cope with social media how can they nurture applied expertise that involves thoughtful reflection and careful decisionmaking among those who know best given the massive data availablemore information than accumulated by humans up to 2003what is the right sort of data to identify collect and utilize vs ignore and disregard how do we know the real impact of social media on public professionalsthe pseudoevent vs the real event many years ago daniel boorstin referred to a media created event that was unreal or fake as a pseudoevent the rise of social media has accelerated what now is called fake news often pseudoevents create reality that happens and has serious consequences such as suicides staged riots or shootings yet professionalism rests upon honest information verifiable facts as well as objective analysis sorting out truth from fiction has always been challenging for public professionals but the expansion of social media during the last decade only exacerbates an already devilish dilemma how can professionals discern fact from fiction today and respond appropriately in an increasingly social media saturated worldthe drive to specialize vs integrated professional policymaking as was emphasized before the drive to specialize and subspecialize and so on is apparent within the professional ranks as new issues and new information demand new varieties of expertise the result is what some term stovepipes throughout government or little clusters of experts who talk to themselves rather than those outside their specialization beyond their immediate agency or wider general public hence the right hand often is unaware of what the left hand is doing competition among professional groups such as within the defense departmentarmy air force navyfurther inhibits collaboration yet effective public policy making requires integration across many professional fields to succeed no professional group can go it alone in any policymaking arena thus the dilemma how to foster integration and collaboration across increasingly narrow specialized and competitive professional ranksproliferation of temporary contractors vs inhouse professionals the recent devastating leaks in american intelligence have all been the result of temporary contract employees such as edward snowden increased use of contractors is often justified politically for keeping costs down and cutting government employees that is good political rhetoric but there is little evidence to support such rationales instead in the words of hugh heclo we have become a government of strangers as a result there is potential for a serious erosion of a professional corporate identity due to the lack of commonly shared professional norms plus effective ethical enforcement mechanisms hence the key question how can professionalization of government as a whole advance when it is seriously challenged from within due to the rise of temporary contract workers which in national security and law enforcement cases can jeopardize human life as wellglobal interconnectedness vs local accountability as mentioned before professional groups are rooted in state and community level associations such as the state bar association or state medical societies for entrance exams credentialing ethics enforcement and much more yet increasingly professional work spans the global or at least are interconnected beyond the borders of any single nation again problemsolving demands wider international cooperation and collaboration to succeed in almost every field today from environmental protection to military intervention hence how to insure that public professionals educated and credentialed within a local jurisdiction are prepared to see the big picture and work effectively with colleagues across national boundariesincreased ethical responsibilities vs limited ethical training not very long ago it was assumed if you studied public administration you were ethical hence mpa programs until recently were largely devoted to training students in the bread and butter topics of training for the 3eseconomy efficiency effectivenessvia classes in organization and management budgeting and finance human resources management etc few teachers paid much attention to ethics and the subject was largely absent from public administration curricula while more is being done in classrooms to incorporate ethical training as well as establishing codes of conduct that are enforced by professional associations the rapid escalation of ethical responsibilities and demands upon public officials continues to grow at a staggering rate from firstline employee to top department head in government ethical dilemmas are profound and pervasive so the central if not the central challenge confronting the field today is how to develop ethical awareness among professionals in order to make and to apply ethically sound choices for resolving problems they confrontspecialist vs generalist public service education universities remain conveyor belts for advancing expertise credentialing and educating public professionals until relatively recently it was easy to name the top public administration schools the top scholars in the field an agreed upon means of academic preparation and recognize a common curriculum for training throughout the field a generalist orientation largely prepared students for a variety of public sector careers while today university training beyond the bs or ba degree is generally accepted as the appropriate route to professional careers in government the choice of schools curricula and specializations are staggering in the usa generalist degrees have largely declined or disappeared in favor of highly narrow subject matter such as defense policy making emergency management training law enforcement administration budgeting and financial management or human resources management once many of these were designated as subfields of a generalist mpa degree but now are offered as standalone graduate degrees but does specialized training adequately prepare students for government work that requires understanding the big picture how to integrate the parts and then make them operate altogether as a whole ball of wax at what point does increasing professional specialization become counterproductive to achieving the public interesta clear dichotomy vs an integrated politicalprofessional team since the rise of democracy with elected officials and growth of bureaucracies with appointed public professions the dilemma has always been how to mesh the two distinctively different realms of the political and administrative into an effective collaborative team to serve the public interest especially since both have profoundly different incentive structures agendas outlooks and purposes the issue is as old as public administration itself indeed it was a major concern of woodrow wilsons first essay written in america on the subject the study of administration 1887 ie how to ensure responsible government in light of the creation of a new civil service system how to make certain professionals are accountable to the public the topic remains front and center to the public sector worldwide today namely how can elected officials hold appointed public professionals accountable while at the same time how can professionals offer the best neutral objective independent advice and service to elected representatives everywhere in the world nowadays this issue of marrying political and professional is not only challenging but decides ultimately the fate of many if not all key public policy debatescertainly other current worldwide trends impacting public professionalism could be added to this list such as citizen participation union representation in government and career mobility but i tried to emphasize those most recent most critical and with the greatest potential global impacts on the public sector granted many of my examples and citations were drawn from the usa so my perspectives and this discussion may well be somewhat limited parochial and even biased i certainly know little about brazilian public administration and the specific challenges your public service confronts but i suspect many of the trends outlined above are effecting your nation and its public sector in equally profound pervasive and often unknown ways especially for those seminal public profession values of applied expertise corporate identity and ethical responsibility my hunch is that individually and collectively these aforementioned forces serve to fragment diffuse even negate many aspects of foundational professional values in brazil as well as everywhere abroad thus my central argument for advancing public service education is aimed to revitalize reinvigorate and rejuvenate those core values that created and developed public professionalism as we now know it and are under attack in many quarters why again as emphasized in the stated premises to this lecture government decisions and official behavior have immense impact on any nation and the worldsocial political economichence it is the education of public professionals that is critical to shaping public choices and actions effective government and a just modern society cannot work without a professionalized public service if carl friedrich once wrote that bureaucracy is the core of modern government certainly public professionals are the core of that coreso what are the best routes for advancing public professionalism in the second decade of the 21st century and beyond again i must claim ignorance about brazils public service and its particular contemporary challenges though permit me to discuss general educational strategies in light of the nine forgoing global trends and speculate about routes that can significantly serve to strengthen and advance those three foundational professional values here i will sum up this talknot by outlining specific remedies or educational programs and curricula not arguing for parttime vs full time alternatives not inhouse vs university training not online vs in classroom facetoface teachingbut rather by speculating on general educational strategies aimed at broadly strengthening the three seminal foundational values of public professionalismfirst by fostering greater constitutional understanding here i am not suggesting more legal training in the specifics of constitutional law rather i refer to the broader aristotelian sense of comprehending the basic purposes meaning and influence on public professionals of framing legal documents for every nation in the case of the united states constitution such instruction would not ask students to learn the specifics of the 6 thousand word framing document but rather to comprehend its intellectual origins in the late 18th century and why that era and the men involved fashioned a very unique founding arrangement its central aims as embodied in its preamble that lay out possibilities limits and roles of todays public sector its general structure that shapes the current actions and constraints on modern american government as well as its 27 amendments since 1789 and evolving interpretations over time that influence public sector activities today by linking greater constitutional understanding to contemporary public professional education can rejuvenate and invigorate basic ethical values that undergird all professional decisionmaking activitiessecond by encouraging deeper appreciation of professional history and the lives of professional leaders professionals live within a stream of history that runs deep and wide and decisively influences their modern corporate identities of who they are what they do and how they operate in the modernday world history can tremendously enrich professional careers inspire their work by knowledge of their past development key founders their accomplishments and yes failures it can broaden their way of thinking about problems offer examples of not just howtodosomething but howtodoitwell what works best or not as well as approaches and strategies that succeedor fail such education would include reading about the lives of the great professional leaders why they entered the field how they learned their professional skills what they learned about experienced in their apprenticeships that fostered their career development how they rose to prominence within the professional ranks what inspired their deep commitment to this line of work role models that aided their advancement and decisions they made that made them historically famousor infamous as professional leaders much of professional education requires hard work and sheer perspiration history and biography offers invaluable inspiration for those who aspire to top leadership ranks as well as those old hands already in chargethird by grasping lessons of administrative cases the world of government does not present its practitioners with simple questions or neat solutions especially as they move up in every organizational hierarchy administrative issues become more and more complex professionals in government do not wake up in the morning and say today i will deal with a budget issue tomorrow i will address policy of such and such an area and the next day hiring a new employee will be my agenda nothing is so neat and tidy in government rather everything is usually interconnected events come upon desks unpredictably and choices are more often than not neither right nor wrong but mixed with a lot grey uncertainty without full information and considerable questions as to the results and outcomes to be achieved here is where administrative cases are a necessary pedagogical tool unlike medical school or law school cases with often clearcut right and wrong answers the best administrative cases are open to many interpretations and force students to see the ambiguity and complexity of so much of what reallife government decisionmaking is all about the best administrative cases encourage students to appreciate and navigate such cloudy operational environments as well as learn how successful policymaking and implementation of policy involves working across agency departmental and unit lines using multiple administrative skills of budgeting and finance human resources planning and so on in order to achieve results in short cases focusing upon gaining collaborative management skills seeing the big picture beyond the limited intellectual horizons of most professional training are vital for advancing professionalization in all parts of modern governmentfinally by studying the future the old adage that we should study the future because that is where we spend the rest of our lives is certainly true or contains an important truth for those who work in the public sector for better or worseor better and worsevirtually all government activities involve shaping the future it may concern big choices of peace or war or simply entail plugging numbers into a lineitem budget or hiring a new employee such big choices or mundane tasks in the public service help to decide what tomorrow will become the destinies of societies everywhere are the hands of public professionals who are employed throughout government deciding on the social challenges we face what they are and how to confront them by making choices big and small though few would debate the value of knowing about the future the question is how or how to educate professionals in futuristic learning certainly the rise of big data and its worldwide immense influence on business and government planning and decisionmaking is apparent and fact of modern life thus learning to gather comprehend and analyze large data separating the essential from nonessential fact from fiction unlocking the relevant information related to the questions at hand in order to glean future trends is invaluable for predicting the future but other less grand routes to glimpsing the future can be found by learning how to conduct focus groups sample expert opinion or gather reference material from a wide variety of document sources while certainly no onebestway exists to properly examine where we are headed tomorrow the most striking aspect of professional education to date is how little involves thinking about the future part of the problem is the popular association of futuristic studies with tealeaf reading and casting horoscopes activities not enthusiastically embraced by university academicsso far but there are numerous more reputable technologicalscientific methods worth at least somehow someway incorporating into our professional training programs which include trend extrapolation genius forecasting delphic exercises simulation scenario building crossimpact matrix development and much more that can help us predict and plan for tomorrow perhaps we cannot see the future with precision or a degree of accuracy we wish but some guidance is better than nothing to point the way forward in order assist professionals to plan better today simply because we do not know how to educate for it or so far there is no agreed upon proper training methodology are no excuses for not tryinggiven that the stakes are so high for professionals working in government indeed more generally for societys prosperity and survivalreceived june 21 2017 accepted october 26 2017richard stillman ii  professor of public administration at university of colorado  eua and former editorinchief at public administration review  eua email richardstillmanucdenveredu this is an openaccess article distributed under the terms of the creative commons attribution license
TSCR3ZQP;journalArticle;2021;Balle, S.N.;Empathic responses and moral status for social robots: an argument in favor of robot patienthood based on K. E. Løgstrup;AI and Society;NA;09515666;10.1007/s00146-021-01211-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104950822&doi=10.1007%2fs00146-021-01211-2&partnerID=40&md5=3787db2c2f40a90ea3212ba2a25225a5;"Empirical research on human–robot interaction (HRI) has demonstrated how humans tend to react to social robots with empathic responses and moral behavior. How should we ethically evaluate such responses to robots? Are people wrong to treat non-sentient artefacts as moral patients since this rests on anthropomorphism and ‘over-identification’ (Bryson and Kime, Proc Twenty-Second Int Jt Conf Artif Intell Barc Catalonia Spain 16–22:1641–1646, 2011)—or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood, such that social robots become our ‘Others’ (Gunkel, Robot rights, MIT Press, London, 2018; Coeckelbergh, Kairos J Philos Sci 20:141–158, 2018)?. In this research paper, I weave extant HRI studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots, on which the ethical evaluation of moral behavior toward them is dependent. Patienthood for robots has standardly been thought to obtain on some intrinsic ground, such as being sentient, conscious, or having interest. But since these attempts neglect moral experience and are curbed by epistemic difficulties, I take inspiration from Coeckelbergh and Gunkel’s ‘relational approach’ to explore an alternative way of accounting for robot patienthood based on extrinsic premises. Based on the ethics of Danish theologian K. E. Løgstrup (1905–1981) I argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjects—even if they emerge from social interaction afforded by robots we have anthropomorphized. I ultimately develop an argument in defense of treating robots as moral patients. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.";2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media Deutschland GmbH;<p>cited By 0</p>;NA;NA;"Social robots; Philosophical aspects; Robot interactions; Social interactions; Human subjects; Catalonia; Empirical research; Research papers";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicresponsesandmoralstatusforsocialrobotsanargumentinfavorofrobotpatienthoodbasedonkeløgstrup;empathic responses and moral status for social robots an argument in favor of robot patienthood based on k e løgstrup empirical research on humanrobot interaction hri has demonstrated how humans tend to react to social robots with empathic responses and moral behavior how should we ethically evaluate such responses to robots are people wrong to treat nonsentient artefacts as moral patients since this rests on anthropomorphism and overidentification bryson and kime proc twentysecond int jt conf artif intell barc catalonia spain 162216411646 2011or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood such that social robots become our others gunkel robot rights mit press london 2018 coeckelbergh kairos j philos sci 20141158 2018 in this research paper i weave extant hri studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots on which the ethical evaluation of moral behavior toward them is dependent patienthood for robots has standardly been thought to obtain on some intrinsic ground such as being sentient conscious or having interest but since these attempts neglect moral experience and are curbed by epistemic difficulties i take inspiration from coeckelbergh and gunkels relational approach to explore an alternative way of accounting for robot patienthood based on extrinsic premises based on the ethics of danish theologian k e løgstrup 19051981 i argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjectseven if they emerge from social interaction afforded by robots we have anthropomorphized i ultimately develop an argument in defense of treating robots as moral patients  2021 the authors under exclusive licence to springerverlag london ltd part of springer nature
63PFUFUA;journalArticle;2021;Pashevich, E.;Can communication with social robots influence how children develop empathy? Best-evidence synthesis;AI and Society;NA;09515666;10.1007/s00146-021-01214-z;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105417711&doi=10.1007%2fs00146-021-01214-z&partnerID=40&md5=3450c898fc3bbd8515987bb1735a8566;Social robots are gradually entering children’s lives in a period when children learn about social relationships and exercise prosocial behaviors with parents, peers, and teachers. Designed for long-term emotional engagement and to take the roles of friends, teachers, and babysitters, such robots have the potential to influence how children develop empathy. This article presents a review of the literature (2010–2020) in the fields of human–robot interaction (HRI), psychology, neuropsychology, and roboethics, discussing the potential impact of communication with social robots on children’s social and emotional development. The critical analysis of evidence behind these discussions shows that, although robots theoretically have high chances of influencing the development of empathy in children, depending on their design, intensity, and context of use, there is no certainty about the kind of effect they might have. Most of the analyzed studies, which showed the ability of robots to improve empathy levels in children, were not longitudinal, while the studies observing and arguing for the negative effect of robots on children’s empathy were either purely theoretical or dependent on the specific design of the robot and the situation. Therefore, there is a need for studies investigating the effects on children’s social and emotional development of long-term regular and consistent communication with robots of various designs and in different situations. © 2021, The Author(s).;2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media Deutschland GmbH;<p>cited By 0</p>;NA;NA;"Social robots; Machine design; Robot interactions; Social relationships; Economic and social effects; CAN communications; Context of use; Critical analysis; Emotional engagements; Neuropsychology; Potential impacts";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;cancommunicationwithsocialrobotsinfluencehowchildrendevelopempathybestevidencesynthesis;can communication with social robots influence how children develop empathy bestevidence synthesis social robots are gradually entering childrens lives in a period when children learn about social relationships and exercise prosocial behaviors with parents peers and teachers designed for longterm emotional engagement and to take the roles of friends teachers and babysitters such robots have the potential to influence how children develop empathy this article presents a review of the literature 20102020 in the fields of humanrobot interaction hri psychology neuropsychology and roboethics discussing the potential impact of communication with social robots on childrens social and emotional development the critical analysis of evidence behind these discussions shows that although robots theoretically have high chances of influencing the development of empathy in children depending on their design intensity and context of use there is no certainty about the kind of effect they might have most of the analyzed studies which showed the ability of robots to improve empathy levels in children were not longitudinal while the studies observing and arguing for the negative effect of robots on childrens empathy were either purely theoretical or dependent on the specific design of the robot and the situation therefore there is a need for studies investigating the effects on childrens social and emotional development of longterm regular and consistent communication with robots of various designs and in different situations  2021 the authors
8H37WPQZ;journalArticle;2021;"Vargas Martin, M.; Pérez Valle, E.; Horsburgh, S.";Artificial Empathy for Clinical Companion Robots with Privacy-By-Design;Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST;NA;18678211;10.1007/978-3-030-70569-5_23;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104418757&doi=10.1007%2f978-3-030-70569-5_23&partnerID=40&md5=d3890f65cafff1ceba3086b0fd4212bf;We present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families. Our approach removes the need for Cloud-based automatic speech recognition systems to address healthcare privacy expectations. Furthermore, we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation. Our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.;2021;2021-05-19T13:26:06Z;2021-05-19T13:26:06Z;NA;351-361;NA;NA;362 LNICST;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030705688 Publisher: Springer Science and Business Media Deutschland GmbH;"<p>cited By 0; Conference of 9th EAI International Conference on Wireless Mobile Communication and Healthcare, MobiHealth 2020 ; Conference Date: 19 November 2020 Through 19 November 2020; Conference Code:255799</p>";NA;NA;"Mental health; Health care; Companion robot; Speech recognition; Human robot interaction; Humanoid robot; Machine design; Robot interactions; Anthropomorphic robots; Facial Expressions; Privacy by design; Automatic speech recognition system; Cloud-based; Mobile telecommunication systems";NA;Ye J., Yordanova K., O'Grady M.J., Civitarese G.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;artificialempathyforclinicalcompanionrobotswithprivacybydesign;artificial empathy for clinical companion robots with privacybydesign we present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families our approach removes the need for cloudbased automatic speech recognition systems to address healthcare privacy expectations furthermore we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions  2021 icst institute for computer sciences social informatics and telecommunications engineering
SRBA6GP4;conferencePaper;2021;"Zafar, Z.; Ashok, A.; Berns, K.";Personality traits assessment using p.A.D. Emotional space in human-robot interaction;VISIGRAPP 2021 - Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications;978-989-758-488-6;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974518&partnerID=40&md5=579d9d515e2e418c556711a934135b57;"Cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings. Humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish human-human interaction. Similarly, assessment of human personality is highly critical in realizing natural and intelligent human-robot interaction. Numerous personality traits assessment systems have been reported in the literature; however, most of them target the big five personality traits. From only visual information, this work proposes to use pleasure, arousal, and dominance emotional space for the assessment of personality traits based on the work of Mehrabian. To validate the system, three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot. Experimental results show that the system can assess human personality traits with 84% accuracy in real-time and, hence, it can adapt its behavior according to the perceived personality of the interaction partner. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.";2021;2021-05-19T13:26:07Z;2021-05-19T13:26:07Z;NA;111-118;NA;NA;2;NA;NA;NA;NA;NA;NA;NA;SciTePress;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2021 ; Conference Date: 8 February 2021 Through 10 February 2021; Conference Code:167535</p>";NA;NA;"Computer vision; Social robots; Social robotics; Humanoid robot; Personality traits; Man machine systems; Anthropomorphic robots; Assessment system; Computer graphics; Human being; Human-human interactions; Real time; Visual information";NA;Paljic A., Bouatouch K., Peck T., Braz J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;personalitytraitsassessmentusingpademotionalspaceinhumanrobotinteraction;personality traits assessment using pad emotional space in humanrobot interaction cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish humanhuman interaction similarly assessment of human personality is highly critical in realizing natural and intelligent humanrobot interaction numerous personality traits assessment systems have been reported in the literature however most of them target the big five personality traits from only visual information this work proposes to use pleasure arousal and dominance emotional space for the assessment of personality traits based on the work of mehrabian to validate the system three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot experimental results show that the system can assess human personality traits with 84 accuracy in realtime and hence it can adapt its behavior according to the perceived personality of the interaction partner copyright  2021 by scitepress  science and technology publications lda all rights reserved
R6B668TQ;journalArticle;2021;"Erel, H.; Trayman, D.; Levy, C.; Manor, A.; Mikulincer, M.; Zuckerman, O.";Enhancing Emotional Support: The Effect of a Robotic Object on Human–Human Support Quality;International Journal of Social Robotics;NA;18754791;10.1007/s12369-021-00779-5;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105378198&doi=10.1007%2fs12369-021-00779-5&partnerID=40&md5=31fccb98f281cb4956d06a3377775de0;Emotional support in the context of psychological caregiving is an important aspect of human–human interaction that can significantly increase well-being. In this study, we tested if non-verbal gestures of a non-humanoid robot can increase emotional support in a human–human interaction. Sixty-four participants were invited in pairs to take turns in disclosing a personal problem and responding in a supportive manner. In the experimental condition, the robotic object performed emphatic gestures, modeled according to the behavior of a trained therapist. In the baseline condition, the robotic object performed up-and-down gestures, without directing attention towards the participants. Findings show that the robot’s empathy-related gestures significantly improved the emotional support quality provided by one participant to another, as indicated by both subjective and objective measures. The non-humanoid robot was perceived as peripheral to the natural human–human interaction and influenced participants’ behavior without interfering. We conclude that non-humanoid gestures of a robotic object can enhance the quality of emotional support in intimate human–human interaction. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.;2021;2021-05-19T13:26:07Z;2021-05-19T13:26:07Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Science and Business Media B.V.;<p>cited By 0</p>;NA;NA;"Robotics; Social robots; Humanoid robot; Agricultural robots; Anthropomorphic robots; Human interactions; Base-line conditions; Emotional supports; Experimental conditions; Human support; Subjective and objective measures; Well being";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;enhancingemotionalsupporttheeffectofaroboticobjectonhumanhumansupportquality;enhancing emotional support the effect of a robotic object on humanhuman support quality emotional support in the context of psychological caregiving is an important aspect of humanhuman interaction that can significantly increase wellbeing in this study we tested if nonverbal gestures of a nonhumanoid robot can increase emotional support in a humanhuman interaction sixtyfour participants were invited in pairs to take turns in disclosing a personal problem and responding in a supportive manner in the experimental condition the robotic object performed emphatic gestures modeled according to the behavior of a trained therapist in the baseline condition the robotic object performed upanddown gestures without directing attention towards the participants findings show that the robots empathyrelated gestures significantly improved the emotional support quality provided by one participant to another as indicated by both subjective and objective measures the nonhumanoid robot was perceived as peripheral to the natural humanhuman interaction and influenced participants behavior without interfering we conclude that nonhumanoid gestures of a robotic object can enhance the quality of emotional support in intimate humanhuman interaction  2021 the authors under exclusive licence to springer nature bv
Z4EBSUD4;journalArticle;2020;Wales, J.J.;Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots;Frontiers in Artificial Intelligence and Applications;NA;09226389;10.3233/FAIA200906;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65;According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.;2020;2021-05-19T13:26:08Z;2021-05-19T13:26:08Z;NA;114-124;NA;NA;335;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9781643681542 Publisher: IOS Press BV;"<p>cited By 0; Conference of 4th Conference on Robophilosophy 2020: Culturally Sustainable Social Robotics ; Conference Date: 18 August 2020 Through 21 August 2020; Conference Code:165874</p>";NA;NA;"Robotics; Social robots; Philosophical aspects; Training data; Augustine; Bodily movement; Consumer products; Educational robots; Instrumentalization; Personal robot; Users' satisfactions";NA;Norskov M., Quick O.S., Seibt J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathyandinstrumentalizationlateancientculturalcritiqueandthechallengeofapparentlypersonalrobots;empathy and instrumentalization late ancient cultural critique and the challenge of apparently personal robots according to a tradition that we hold variously today the relational person lives most personally in affective and cognitive empathy whereby we enter subjective communion with another person near future social ais including social robots will give us this experience without possessing any subjectivity of their own they will also be consumer products designed to be subservient instruments of their users satisfaction this would seem inevitable yet we cannot live as personal when caught between instrumentalizing apparent persons slaveholding or numbly dismissing the apparent personalities of our instruments mild sociopathy this paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century north african philosopher and theologian augustine of hippo who is among those essential in giving us our understanding of relational persons augustines semiotics deeply intertwined with our affective life suggest that if we are to own persuasive social robots humanely we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails text messages books and bodily movements will have provided the training data for the behavior of nearfuture social ais so doing we may see simulation as simulation albeit persuasive while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation if we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy we will suborn the sign to ourselves undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons  2020 the authors and ios press all rights reserved
WWZZQQSJ;journalArticle;2020;"Xiao, G.; Tu, G.; Zheng, L.; Zhou, T.; Li, X.; Ahmed, S.H.; Jiang, D.";Multi-modality Sentiment Analysis in Social Internet of Things based on Hierarchical Attentions and CSATTCN with MBM Network;IEEE Internet of Things Journal;NA;23274662;10.1109/JIOT.2020.3015381;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099552559&doi=10.1109%2fJIOT.2020.3015381&partnerID=40&md5=00cb27c2be4c5b7cab3cc2add96681ec;Multi-modality sentiment analysis in the social internet of things is a developing field, which is basic to empathetic mechanisms, affective computing, and artificial intelligence. Current works in this domain do not explicitly consider the influence of contextual information fusion based on correlation coefficient and memory network with branch structure for sentiment analysis. Unlike present works, this paper presents a Hierarchical Self-attention Fusion (H-SATF) model for capturing contextual information better among utterances, a Contextual Self-attention Temporal Convolutional Network (CSAT-TCN) for the sentiment recognition in social internet of things, and a Multi Branches Memory (MBM) network that stores self-speaker and inter-speaker sentimental states into global memories. For the MOSI datasets, the hybrid H-SATF-CSAT-TCN-MBM model outperforms the state-of-art networks and shows 0.31 9.93% improvement. IEEE;2020;2021-05-19T13:26:16Z;2021-05-19T13:26:16Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Institute of Electrical and Electronics Engineers Inc.;<p>cited By 5</p>;NA;NA;"Sentiment analysis; Affective Computing; Internet of things; Convolutional neural networks; Correlation coefficient; ART networks; Arts computing; Branch structure; Contextual information; Convolutional networks; Memory network; Multi modality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;multimodalitysentimentanalysisinsocialinternetofthingsbasedonhierarchicalattentionsandcsattcnwithmbmnetwork;multimodality sentiment analysis in social internet of things based on hierarchical attentions and csattcn with mbm network multimodality sentiment analysis in the social internet of things is a developing field which is basic to empathetic mechanisms affective computing and artificial intelligence current works in this domain do not explicitly consider the influence of contextual information fusion based on correlation coefficient and memory network with branch structure for sentiment analysis unlike present works this paper presents a hierarchical selfattention fusion hsatf model for capturing contextual information better among utterances a contextual selfattention temporal convolutional network csattcn for the sentiment recognition in social internet of things and a multi branches memory mbm network that stores selfspeaker and interspeaker sentimental states into global memories for the mosi datasets the hybrid hsatfcsattcnmbm model outperforms the stateofart networks and shows 031 993 improvement ieee
NK9PK8ZM;journalArticle;2020;"Hickton, L.; Lewis, M.; Cañamero, L.";Expression of Grounded Affect: How Much Emotion Can Arousal Convey?;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-63486-5_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231;In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:17Z;2021-05-19T13:26:17Z;NA;234-248;NA;NA;12228 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030634858 Publisher: Springer Science and Business Media Deutschland GmbH;"<p>cited By 0; Conference of 21th Annual Conference on Towards Autonomous Robotics, TAROS 20120 ; Conference Date: 16 September 2020 Through 16 September 2020; Conference Code:252749</p>";NA;NA;"Robotics; Social robots; Humanoid robot; Anthropomorphic robots; Affective state; Control robots; Exploratory studies; Hexapod robots; Simple modeling";NA;Mohammad A., Russo M., Dong X.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;expressionofgroundedaffecthowmuchemotioncanarousalconvey;expression of grounded affect how much emotion can arousal convey in this paper we consider how nonhumanoid robots can communicate their affective state via bodily forms of communication kinesics and the extent to which this influences how humans respond to them we propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study n  9 during which participants were interviewed after watching expressive and nonexpressive hexapod robots perform different scenes a summary of these interviews is presented and a number of emerging themes are identified and discussed whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion  2020 springer nature switzerland ag
Q28YISCM;journalArticle;2020;"Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.";Emotion Synchronization Method for Robot Facial Expression;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-49062-1_44;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20;Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:17Z;2021-05-19T13:26:17Z;NA;644-653;NA;NA;12182 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030490614 Publisher: Springer;"<p>cited By 0; Conference of Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242229</p>";NA;NA;"Robots; Synchronization; Communication robot; Emotion estimation; Facial Expressions; Human computer interaction; Human robots; Biological signals; Human emotion; Subjective impressions; Synchronization method";NA;M, Kurosu;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionsynchronizationmethodforrobotfacialexpression;emotion synchronization method for robot facial expression nowadays communication robots are becoming popular since they are actively used in both commercially and personally increasing empathy between humanrobot can effectively enhance the positive impression empathy can be created by syncing human emotion with the robot expression emotion estimation can be done by analyzing controllable expressions like facial expression or uncontrollable expression like biological signals in this work we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal in order to find out which of the proposed methods yield the best impression subjective impression rating is used in the experiment from the result of the impression evaluation we found that the robots facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal  2020 springer nature switzerland ag
N7E9HMBI;journalArticle;2020;"Sejima, Y.; Sato, Y.; Watanabe, T.";Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-030-20441-9_11;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b;Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.;2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;95-102;NA;NA;952;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030204402 Publisher: Springer Verlag;"<p>cited By 0; Conference of AHFE International Conference on Affective and Pleasurable Design, 2019 ; Conference Date: 24 July 2019 Through 28 July 2019; Conference Code:226989</p>";NA;NA;"Empathy; Human robot interaction; Pupil response; Man machine systems; Non-verbal communications; Body contacts; Emotional expressions; Face to face; Measurement device; Pet Robots";NA;S, Fukuda;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;developmentofapupilresponsesystemwithempathyexpressioninfacetofacebodycontact;development of a pupil response system with empathy expression in facetoface body contact pupil response is closely related to human affects and emotions focusing on the pupil response in human robot interaction we developed a pupil response interface using hemisphere displays for enhancing affective expression this interface can generate pupil response like human by speech input and enhance affective expression in this study for the basic research of forming an intimate communication between human and petrobot we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device based on the analysis we developed an advanced pupil response system for enhancing intimacy this system generates the empathy expression when the talker touches any surface of hemisphere displays the effectiveness of the system was confirmed experimentally  2020 springer nature switzerland ag
Z2PWQV5Y;conferencePaper;2020;"Firdaus, M.; Ekbal, A.; Bhattacharyya, P.";Incorporating politeness across languages in customer care responses: Towards building a multi-lingual empathetic dialogue agent;LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings;979-10-95546-34-4;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096584871&partnerID=40&md5=7e8e8d8f2bef5ac7638ad3b967c8b7f7;Customer satisfaction is an essential aspect of customer care systems. It is imperative for such systems to be polite while handling the customer requests or demands. In this paper, we present a large multi-lingual conversational dataset for English and Hindi. We choose data from Twitter having both generic and courteous responses between customer care agents and aggrieved users. We also propose strong baselines that can induce courteous behaviour in generic customer care response in a multi-lingual scenario. We build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agent's responses. Our system is competent in generating responses in different languages (here, English and Hindi) depending on the customer's preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention. Experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system. Qualitative and quantitative analysis show that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction. © European Language Resources Association (ELRA), licensed under CC-BY-NC;2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;4172-4182;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;European Language Resources Association (ELRA);NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>";NA;NA;"Deep learning; Linguistics; Customer satisfaction; Sales; Customer care; Customer care systems; Information shared; Large dataset; Learning frameworks; Qualitative and quantitative analysis";NA;Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;incorporatingpolitenessacrosslanguagesincustomercareresponsestowardsbuildingamultilingualempatheticdialogueagent;incorporating politeness across languages in customer care responses towards building a multilingual empathetic dialogue agent customer satisfaction is an essential aspect of customer care systems it is imperative for such systems to be polite while handling the customer requests or demands in this paper we present a large multilingual conversational dataset for english and hindi we choose data from twitter having both generic and courteous responses between customer care agents and aggrieved users we also propose strong baselines that can induce courteous behaviour in generic customer care response in a multilingual scenario we build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agents responses our system is competent in generating responses in different languages here english and hindi depending on the customers preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system qualitative and quantitative analysis show that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction  european language resources association elra licensed under ccbync
E6WFDILN;journalArticle;2020;"Chung, S.-E.; Ryoo, H.-Y.";Gesture design attribute and level value of social robot: A user experience based study;Journal of System and Management Sciences;NA;18166075;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3;"This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.";2020;2021-05-19T13:26:18Z;2021-05-19T13:26:18Z;NA;108-121;NA;2;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Success Culture Press;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;gesturedesignattributeandlevelvalueofsocialrobotauserexperiencebasedstudy;gesture design attribute and level value of social robot a user experience based study this study was to verify the attributes of the social robots gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes to do so the attributes and the level value standards for the gesture interfaces key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies for the emotional gesture attributes the level values were categorized as pleasure at low arousal pleasure at high arousal displeasure at low arousal and displeasure at high arousal among the communicative expression gesture attributes the level values were categorized as idling conversation induction and concentration and empathy lastly the derived attributes and the level values for the emotional gesture and communicative gesture have been integrated with the ones for the functionalsemantic gesture derived on the previous studies they have been presented as the robots gesture interface design factors available in the aspect of the user experience  2020 success culture press all rights reserved
66NMRVTN;journalArticle;2019;"Sena, J.R.; Cabatuan, M.";Deep learning-based facial expression recognition and analysis for filipino gamers;International Journal of Recent Technology and Engineering;NA;22773878;10.35940/ijrte.B1027.078219;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286;This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.;2019;2021-05-19T13:26:22Z;2021-05-19T13:26:22Z;NA;1822-1827;NA;2;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Blue Eyes Intelligence Engineering and Sciences Publication;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;deeplearningbasedfacialexpressionrecognitionandanalysisforfilipinogamers;deep learningbased facial expression recognition and analysis for filipino gamers this paper presents a computer vision based emotion recognition system for the identification of six basic emotions among filipino gamers using deep learning techniques in particular the proposed system utilized deep learning through the inception network and longshort term memory lstm the researchers gathered a database for filipino facial expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data the system was able to produce a maximum categorical validation accuracy of9983 and a test accuracy of9940 for the six basic emotions using the filipino database the crossdatabase analysis results using the wellknown cohnkanade database showed that the proposed inceptionlstm system has accuracy on a par with the current existing systems the results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept  beiesp
2IG7HJYR;journalArticle;2019;"Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.";Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects;Lecture Notes in Electrical Engineering;NA;18761100;10.1007/978-3-030-04672-9_7;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f;The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:25Z;2021-05-19T13:26:25Z;NA;101-113;NA;NA;540;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030046712 Publisher: Springer Verlag;"<p>cited By 0; Conference of 8th Italian Forum on Ambient Assisted Living, ForitAAL 2017 ; Conference Date: 12 June 2017 Through 15 June 2017; Conference Code:223489</p>";NA;NA;"Robotics; Animals; Empathy; Robots; Social robotics; Human-object continuum; Living-nonliving continuum; Social distance; Assisted living";NA;Casiddu N., Monteriu A., Porfirione C., Cavallo F.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;degreesofempathyhumansempathytowardhumansanimalsrobotsandobjects;degrees of empathy humans empathy toward humans animals robots and objects the aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans animals robots and objects the present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately our research questions are does the continuum represented by this set of elements elicit empathy is it possible to observe a linear decrease of empathy according to different features of the selected elements more broadly does empathy as a construct resist in front of the diversification of the element eliciting it results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated they felt more sad sorry aroused and out of control for animals than for humans but showed little to no empathy for objects interestingly robots that looked more humanlike evoked emotions similar to those evoked by humans while robots that looked more animallike evoked emotions halfway between those evoked by humans and objects implications are discussed  2019 springer nature switzerland ag
5T8D4UEI;journalArticle;2019;"Parviainen, J.; van Aerschot, L.; Särkikoski, T.; Pekkarinen, S.; Melkas, H.; Hennala, L.";Motions with emotions? A phenomenological approach to understanding the simulated aliveness of a robot body;Techne: Research in Philosophy and Technology;NA;10918264;10.5840/techne20191126106;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081323649&doi=10.5840%2ftechne20191126106&partnerID=40&md5=378eb5e3022a3bfccf7c5f223679272b;This article examines how the interactive capabilities of companion robots, particularly their materiality and animate movements, appeal to human users and generate an image of aliveness. Building on Husserl's phenomenological notion of a 'double body' and theories of emotions as affective responses, we develop a new understanding of the robots' simulated aliveness. Analyzing empirical findings of a field study on the use of the robot Zora in care homes for older people, we suggest that the aliveness of companion robots is the result of a combination of four aspects: 1) material ingredients, 2) morphology, 3) animate movements guided by software programs and human operators as in Wizard of Oz-settings and 4) anthropomorphising narratives created by their users to support the robot's performance. We suggest that narratives on affective states, such as, sleepiness or becoming frightened attached to the robot trigger users' empathic feelings, caring and tenderness toward the robot. © 2019 Philosophy Documentation Center. All rights reserved.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;318-341;NA;3;23;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Philosophy Documentation Center;<p>cited By 10</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;motionswithemotionsaphenomenologicalapproachtounderstandingthesimulatedalivenessofarobotbody;motions with emotions a phenomenological approach to understanding the simulated aliveness of a robot body this article examines how the interactive capabilities of companion robots particularly their materiality and animate movements appeal to human users and generate an image of aliveness building on husserls phenomenological notion of a double body and theories of emotions as affective responses we develop a new understanding of the robots simulated aliveness analyzing empirical findings of a field study on the use of the robot zora in care homes for older people we suggest that the aliveness of companion robots is the result of a combination of four aspects 1 material ingredients 2 morphology 3 animate movements guided by software programs and human operators as in wizard of ozsettings and 4 anthropomorphising narratives created by their users to support the robots performance we suggest that narratives on affective states such as sleepiness or becoming frightened attached to the robot trigger users empathic feelings caring and tenderness toward the robot  2019 philosophy documentation center all rights reserved
G2XV38T9;journalArticle;2019;"Zhang, Y.; Qi, S.";User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-22335-9_24;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825;With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;350-366;NA;NA;11588 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030223342 Publisher: Springer Verlag;"<p>cited By 2; Conference of 6th International Conference on HCI in Business, Government, and Organizations, HCIBGO 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228649</p>";NA;NA;"Robotics; Surveys; Decision making; Robots; User experience; Hospitality; Service quality management; Human computer interaction; User interfaces; Consumer behavior; Decision making process; Hotels; Quality of service; Quantitative research; Regression analysis; Research objectives; Service expectations; User classification; Wages";NA;Nah F.F.-H., Siau K.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;userexperiencestudytheserviceexpectationofhotelgueststotheutilizationofaibasedservicerobotinfullservicehotels;user experience study the service expectation of hotel guests to the utilization of aibased service robot in fullservice hotels with the dramatic development of ai technology the concept of robotic hotel is entering the publics awareness although ai application brings in high efficiency low labor cost and novelty practical operation of robotic hotels still faces with challenges this quantitative research aims at understanding the current user expectation level of ai robotic hotel and robot appliance based on that it tries to make the user classification by demographic behavioral and attitude factors by using the refined servqual model it gathers the expectation from five dimensions involving tangibles reliability responsiveness assurance and empathy these research objectives were realized by using surveydesigned questionnaires and distributed by a snowball sampling method conducted in beijing after validity and reliability test data collected from the field were analyzed by a variety of inspections it is found that education attitude and income level have a significant effect on the expectation to stay in the robotic hotel which provided the basis of market position for robotic hotel operators through regression analysis the model was established to identify what factors played an important part and how they worked it is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels this thesis drew up several conclusions which would help industry players including hoteliers ai robot suppliers better understand details of the user group in their decisionmaking process as well as academic side to formulate a tailored model to evaluate the interaction between ai robots and hotel guests  2019 springer nature switzerland ag
6VLJCLM4;conferencePaper;2019;"Arriaga, O.; Valdenegro-Toro, M.; Plöger, P.G.";Real-time convolutional neural networks for emotion and gender classification;ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning;978-2-87587-065-0;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2;Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.;2019;2021-05-19T13:26:26Z;2021-05-19T13:26:26Z;NA;221-226;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ESANN (i6doc.com);NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 6; Conference of 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2019 ; Conference Date: 24 April 2019 Through 26 April 2019; Conference Code:149793</p>";NA;NA;"Neural networks; Machine learning; Convolutional neural network; Convolution; Real time; Computation time; Facial feature; Gender classification; Gender recognition; Open source license; Open systems; Real time evaluation";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;realtimeconvolutionalneuralnetworksforemotionandgenderclassification;realtime convolutional neural networks for emotion and gender classification emotion and gender recognition from facial features are important properties of human empathy robots should also have these capabilities for this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters enabling realtime evaluation on a constrained platform we report accuracies of 96 in the imdb gender dataset and 66 in the fer2013 emotion dataset while requiring a computation time of less than 0008 seconds on a core i7 cpu all our code demos and pretrained architectures have been released under an opensource license in our repository at httpsgithubcomoarriagaface classification  2019 esann i6doccom all rights reserved
X9SLPHH8;journalArticle;2019;"Matsuyama, Y.; Asahi, Y.";High Sensitivity Layer Feature Analysis in Food Market;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-22649-7_19;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335;It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.;2019;2021-05-19T13:26:27Z;2021-05-19T13:26:27Z;NA;232-243;NA;NA;11570 LNCS;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030226480 Publisher: Springer Verlag;"<p>cited By 1; Conference of Thematic Area on Human Interface and the Management of Information, HIMI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228569</p>";NA;NA;"Deep learning; Intelligent systems; Testing; Decision tree analysis; Innovation theory; Test marketing; Human computer interaction; Commerce; Conducting tests; Decision theory; Decision trees; Feature analysis; Generalized models; High sensitivity; Image analysis; Market researches; Sales; Text processing";NA;Yamamoto S., Mori H.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;highsensitivitylayerfeatureanalysisinfoodmarket;high sensitivity layer feature analysis in food market it is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market however if you actually drop it you will need a lot of money this study we pay attention to innovation theory in japan the study reported a long sales period however the study didnt report a short sales period therefore we report of a short sales period especially food this study we call high sensitivity layer the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers we think that those that collect a lot of empathy in the high sensitivity layer are diffusive in the innovators and the early adopters and grab the characteristics of highly sensitive consumers who gather many empathies i think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer we prepare a generalized model with a deep learning model and report features of highly sensitive consumers visually and numerically clearly using decision tree analysis from that model from the analysis results attached more images and the older the better it got a report that empathizes with sensitive consumers when conducting test marketing it is predicted that highsensitivity consumers will be able to obtain preferable results by targeting people with this characteristic also it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer in the future i would like to further accurate classification by text mining of posted characters and analysis of posted images  2019 springer nature switzerland ag
IQN3B54D;conferencePaper;2019;"Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.";Digital empathy secures Frankenstein’s monster;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210;People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.;2019;2021-05-19T13:26:27Z;2021-05-19T13:26:27Z;NA;335-349;NA;NA;2348;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 4; Conference of 5th Collaborative European Research Conference, CERC 2019 ; Conference Date: 29 March 2019 Through 30 March 2019; Conference Code:147497</p>";NA;NA;"Speech recognition; Diagnosis; Computation theory; Computer games; Computational model; Image recognition; Asian games; Expert systems; General practitioners; Large datasets; Medical imaging; Robotic surgery; Surgery; Surgical operation";NA;Walsh P., Low R., Burkhardt D., Bleimann U., Regier S., Stengel I., Humm B.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;digitalempathysecuresfrankensteinsmonster;digital empathy secures frankensteins monster peoples worries about robot and ai software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like mary shelleys frankenstein monster the term frankenalgorithms has been used furthermore there are concerns about driverless cars automated general practitioner doctors gps and robotic surgeons legal expert systems and particularly autonomous military drones digital empathy grows when people and computers place themselves in each others shoes some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them however in recent times computers have outperformed people beating world champions at the asian game of go 2017 jeopardy 2011 and chess 1997 mastering precision in medical surgical operations star and diagnosis watson and in specific speech and image recognition tasks computers have also composed music aiva generated art aaron stories quill and poetry google ai in terms of calling for more digital empathy between machines and people we refer here to theories computational models algorithms and systems for detecting representing and responding to peoples emotions and sentiment in speech and images but also for peoples goals plans beliefs and intentions in reciprocation people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made keeping in mind that they are not as prone as people to becoming tired we conclude that if digital souls are programmed with digital empathy and people have more empathy with them by doing unto them as we would have them do unto us this will help to secure shelleys monster  2019 ceurws all rights reserved
3NJTM4KV;conferencePaper;2018;"Hieida, C.; Horii, T.; Nagai, T.";Emotion Differentiation based on Decision-Making in Emotion Model;RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication;978-1-5386-7980-7;NA;10.1109/ROMAN.2018.8525579;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058082859&doi=10.1109%2fROMAN.2018.8525579&partnerID=40&md5=a8b97edffc128454fce9f7f211968e30;Having emotions is essential for robots in order for them to understand and sympathize with people's feelings. In addition, it may allow robots to be accepted in human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions is proposed based on various neurological and psychological findings related to empathic communication between humans and robots. Subsequently, a decision-making mechanism based on affects using convolutional long short-term memory and deep deterministic policy gradient is examined. We set a 'facial expression' task simulating mother-child interactions and verified emotion differentiation during the task. © 2018 IEEE.;2018;2021-05-19T13:26:28Z;2021-05-19T13:26:28Z;NA;659-665;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 1; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>";NA;NA;"Decision making; Robots; Human society; Facial Expressions; Behavioral research; Emotion modeling; Decision-making mechanisms; Policy gradient";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotiondifferentiationbasedondecisionmakinginemotionmodel;emotion differentiation based on decisionmaking in emotion model having emotions is essential for robots in order for them to understand and sympathize with peoples feelings in addition it may allow robots to be accepted in human society the role of emotions in decisionmaking is another important perspective in this paper a model of emotions is proposed based on various neurological and psychological findings related to empathic communication between humans and robots subsequently a decisionmaking mechanism based on affects using convolutional long shortterm memory and deep deterministic policy gradient is examined we set a facial expression task simulating motherchild interactions and verified emotion differentiation during the task  2018 ieee
IVJTPPUI;journalArticle;2018;"Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.";Approaches for generating empathy: A systematic mapping;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-319-54978-1_89;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f;Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.;2018;2021-05-19T13:26:31Z;2021-05-19T13:26:31Z;NA;715-722;NA;NA;558;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319549774 Publisher: Springer Verlag;"<p>cited By 5; Conference of 14th International Conference on Information Technology - New Generations, ITNG 2017 ; Conference Date: 10 April 2017 Through 12 April 2017; Conference Code:195369</p>";NA;NA;"Robotics; Virtual reality; Empathy; Human robot interaction; Customer satisfaction; Rapport; Secondary study; Teaching; Human computer interaction; Social interactions; Mapping; Computer games; Computer supported cooperative work; Computer aided instruction; Collaborative learning environment; Collaborative systems; Customer relationships; Public relations; Systematic mapping studies";NA;S, Latifi;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;approachesforgeneratingempathyasystematicmapping;approaches for generating empathy a systematic mapping empathy plays an important role in social interactions such an effective teachinglearning process in a teacherstudent relationship and companyclient or employeecustomer relationship to retain potential clients and provide them with greater satisfaction increasingly people are using technology to support their interactions especially when the interlocutors are geographically distant from one another this has a negative impact on the empathic capacity of individuals in the computer science there are different approaches techniques and mechanisms to promote empathy in social or humancomputer interactions therefore this article presents a systematic mapping to identify and systematize the approaches techniques and mechanisms used in computing to promote empathy as a result we have identified existing approaches eg collaborative learning environment virtual and robotics agents and collaborativeaffective games to promote empathy the main areas involved eg humancomputer interaction artificial intelligence robotics and collaborative systems the top researchers and their affiliations who are potential contributors to future research and finally the growth status of this line of research  springer international publishing ag 2018
UGMA3339;journalArticle;2018;"Kwon, O.; Kim, J.; Jin, Y.; Lee, N.";Impact of human-robot interaction on user satisfaction with humanoid-based healthcare;International Journal of Engineering and Technology(UAE);NA;2227524X;10.14419/ijet.v7i2.12.11038;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911;Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.;2018;2021-05-19T13:26:32Z;2021-05-19T13:26:32Z;NA;68-75;NA;2;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Science Publishing Corporation Inc;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;impactofhumanrobotinteractiononusersatisfactionwithhumanoidbasedhealthcare;impact of humanrobot interaction on user satisfaction with humanoidbased healthcare backgroundobjectives the advent of selfservice technology sst egkiosks and automatic response system has made it possible for service providersto make use of nonfacetoface channels to meet usersneeds and decrease userscosts and time on the other hand however more complex technology andor services inhibit users satisfaction andconsequentlythe intention to adopt sst because such sst can instill fear in users nevertheless at present patients and other people who are interested in their own health and wellbeing are paying great attention to healthcare robots as a form of sstandconsequently it has become crucial to investigate how these healthcare robots can positively influence users satisfaction with them hence this study aims to empirically investigate the factors that affect users satisfaction with healthcare robots especially in regard to humanrobot interaction hri methodsstatistical analysis we focused on the theory of heterophily and applied a series of factors identified in previous robotadoption studiesuniquely this study focuses on users heterophily with healthcare robots examining heterophily through three fundamental elements empathy professionalism and personality which we considered to be suitable fordetermining user satisfaction with hribased communicationto prove the validity of our hypotheses we conducted an empirical testthat involved participants receiving a short health assessment from a robot findings the findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot the higher the level of user satisfaction with the humanoidstyle healthcare service further our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction improvementsapplications first to increase user satisfactionrobots must be provided with the ability to somehow recognizea users personality and adjust their own accordingly before beginning the robotbased healthcare service secondly users behavior patterns should be analyzed by the healthcare robot overall our study empirically shows the importance of ensuring thatprofessionalism is present in healthcaredomainrelated hri  2018 ohbyung kwon atal
VI8PE6FJ;journalArticle;2018;"Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.";Smiles of children with ASD may facilitate helping behaviors to the robot;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-030-05204-1_6;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5;Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.;2018;2021-05-19T13:26:32Z;2021-05-19T13:26:32Z;NA;55-64;NA;NA;11357 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783030052034 Publisher: Springer Verlag;"<p>cited By 0; Conference of 10th International Conference on Social Robotics, ICSR 2018 ; Conference Date: 28 November 2018 Through 30 November 2018; Conference Code:221569</p>";NA;NA;"Robotics; Robots; Helping behavior; Smile; Diseases; Autism spectrum disorders; Children with autisms; Positive correlations; Social communications";NA;Broadbent E., Wagner A.R., Ge S.S., Salichs M.A., Castro-Gonzalez A., He H., Cabibihan J.-J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;smilesofchildrenwithasdmayfacilitatehelpingbehaviorstotherobot;smiles of children with asd may facilitate helping behaviors to the robot helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy in this study we examined the potentials of using a robot as a recipient of help and helping behaviors to a robot also we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood the results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles it implies that smiles may facilitate helping behaviors to the robot this preliminary research indicates the potentials of robotassisted interventions to facilitate and increase helping behaviors of children with autism spectrum disorder asd  2018 springer nature switzerland ag
VCGBWBXG;journalArticle;2017;Chan, Z.C.Y.;Poetry writing and artistic ability in problem-based learning;International Journal on Disability and Human Development;NA;21911231;10.1515/ijdhd-2016-0003;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb;Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;37-44;NA;1;16;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Walter de Gruyter GmbH;<p>cited By 2</p>;NA;NA;"writing; empathy; nursing; teaching; literature; creativity; human; clinical article; content analysis; follow up; Hong Kong; interview; long term memory; narrative; problem based learning; professional knowledge; stress management";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;poetrywritingandartisticabilityinproblembasedlearning;poetry writing and artistic ability in problembased learning problembased learning pbl is a teaching and learning approach that is widely used in healthcare education it has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues medical education and their relationship with patients the rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose suggesting that important and detailed information could be better memorised through poetic text to report on how poetry writing and reciting was used in a pbl class in nursing to enhance the students artistic ability and on the students perspectives on artistry in their learning this paper presented a part of results of a main educational study where data were collected through lesson observations reflective notes and a followup interview a total of 17 hong kong students were encouraged to collaborate in groups and write english poems based on a clinical case a content analysis was conducted on their reflective notes and narratives were extracted from an interview although the students learned about cooperation creativity thinking stress management how to make lively presentations deep learning longterm memory and professional knowledge they expressed that the above were indirectly related to artistry scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students artistic ability so as to let them learn about empathy and understand patients sufferings and illness experiences  2017 walter de gruyter gmbh berlinboston
GPRSZF8H;conferencePaper;2017;"Lewandowska-Tomaszczyk, B.; Wilson, P.A.";Compassion, empathy and sympathy expression features in affective robotics;7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings;978-1-5090-2645-6;NA;10.1109/CogInfoCom.2016.7804526;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2;"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.";2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;65-70;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 10; Conference of 7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 ; Conference Date: 16 October 2016 Through 18 October 2016; Conference Code:125734</p>";NA;NA;"Robotics; emotions; empathy; expressiveness; action tendencies; British English; compassion; empatia; GRID; responsiveness; sympathy; sympatia; valence; Corpus linguistics; False negatives; False positive; Polishing";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;compassionempathyandsympathyexpressionfeaturesinaffectiverobotics;compassion empathy and sympathy expression features in affective robotics the present paper identifies differences in the expression features of compassion sympathy and empathy in british english and polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures the results showed that english compassion is characterised by more positive valence and more of a desire to act than polish współczucie polish empatia is also characterised by a more negative valence than english empathy which has a wider range of application when used in positive contexts english sympathy corresponds to polish sympatia however it also acquires elements of negative valence in english the results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culturespecific emotion models the more explicit patterns of responsiveness british english for the compassion model in our case is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents  2016 ieee
TD7PTSNQ;journalArticle;2017;"Chumkamon, S.; Hayashi, E.";Consciousnes-based emotion and behavior of pet robot with brain-inspired method;Information (Japan);NA;13434500;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1;A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;615-629;NA;1;20;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: International Information Institute Ltd.;<p>cited By 0</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;consciousnesbasedemotionandbehaviorofpetrobotwithbraininspiredmethod;consciousnesbased emotion and behavior of pet robot with braininspired method a personal robot becomes important to the future world where the robot facilitates our lives and be a friend the understanding of emotional interaction is essential in the social behavior including a natural behavior that is the needed functions for creature behaviorlike robots our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion since the significant factor of a companionable robot is the crosscommunication system without conflict this paper then focuses on three points the first is the organization of the behavior and emotion model regarding the phylogenetic the second the method of the robot that can have empathy with user expression the third how the robot can perform the expression to the human with emotional intelligence using a biologically inspired topological online method for encouragement or being delighted we additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment  2017 international information institute
V72RVEC5;conferencePaper;2017;Silvey, P.E.;Leveling up: Strategies to achieve integrated cognitive architectures;AAAI Fall Symposium - Technical Report;978-1-57735-794-0;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044476959&partnerID=40&md5=09dc018b9aa3ed3c09f13c6428cf44b4;Human-level cognition (most uniquely characterized by our abilities to use language) should be seen as a superset of functional and behavioral capabilities shared by lower life-forms including animals and insects, and this perspective ought to principally guide our strategies for developing integrated cognitive architectures. Just as the study of biological model organisms has led to tremendous advances in our scientific knowledge of genetics and cellular function, the study of embodied cognition in simple agent-environment simulations can yield similar advances in Cognitive Science, Artificial Intelligence, and Robotics. By working first on the foundations of intelligent interaction with one's environment, and by focusing on core functions such as predictive and inductive learning, probabilistic goal-directed behavior compilation, and empathetic reasoning, we can better establish the grounding that the physical symbol system hypothesis assumes (Newell and Simon 1976), yet often without explicit demonstration of a mechanism to derive symbolic relations and semantics from raw sensory data. Logic and language are seen to emerge from our willingness to make discrete simplifying assumptions in a continuous and probabilistic world of experience, and developing a Standard Model of the Mind can help build much-needed bridges between historically nonaligned research communities. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;460-465;NA;NA;FS-17-01 - FS-17-05;NA;NA;NA;NA;NA;NA;NA;AI Access Foundation;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 0; Conference of 2017 AAAI Fall Symposium ; Conference Date: 9 November 2017 Through 11 November 2017; Conference Code:134706</p>";NA;NA;"Semantics; Artificial intelligence; Human robot interaction; Cognitive architectures; Intelligent robots; Cognitive systems; Research communities; Bioinformatics; Biological modeling; Environment simulation; Intelligent interactions; Military applications; Probabilistic goals; Public risks; Scientific knowledge; Simplifying assumptions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;levelingupstrategiestoachieveintegratedcognitivearchitectures;leveling up strategies to achieve integrated cognitive architectures humanlevel cognition most uniquely characterized by our abilities to use language should be seen as a superset of functional and behavioral capabilities shared by lower lifeforms including animals and insects and this perspective ought to principally guide our strategies for developing integrated cognitive architectures just as the study of biological model organisms has led to tremendous advances in our scientific knowledge of genetics and cellular function the study of embodied cognition in simple agentenvironment simulations can yield similar advances in cognitive science artificial intelligence and robotics by working first on the foundations of intelligent interaction with ones environment and by focusing on core functions such as predictive and inductive learning probabilistic goaldirected behavior compilation and empathetic reasoning we can better establish the grounding that the physical symbol system hypothesis assumes newell and simon 1976 yet often without explicit demonstration of a mechanism to derive symbolic relations and semantics from raw sensory data logic and language are seen to emerge from our willingness to make discrete simplifying assumptions in a continuous and probabilistic world of experience and developing a standard model of the mind can help build muchneeded bridges between historically nonaligned research communities copyright  2017 association for the advancement of artificial intelligence wwwaaaiorg all rights reserved
U6FFXJCS;journalArticle;2017;"Cho, H.-K.; Oh, J.; Lee, K.";A study on the potential roles of a robot peer in socio-emotional development of children;International Journal of Computational Vision and Robotics;NA;17529131;10.1504/IJCVR.2017.083447;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b;This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.;2017;2021-05-19T13:26:36Z;2021-05-19T13:26:36Z;NA;335-343;NA;3;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Inderscience Publishers;<p>cited By 1</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;astudyonthepotentialrolesofarobotpeerinsocioemotionaldevelopmentofchildren;a study on the potential roles of a robot peer in socioemotional development of children this paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided the environment consists of a socially assistive robot an auxiliary display and a mobile device for teachers intervention the robot and the display are employed as mediators to give adequate affective feedbacks to children which might not be possible among very young peers the intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children we intended to increase childrens engagement on the activities and enhance their empathy while interacting with a friendlike robot than they do with an adult teacher to verify the feasibility of the proposed design we implemented an activity on emotional regulation strategies and performed a brief user study the results clearly show that the participants prefer sociable mode of robot operation to still mode operation copyright  2017 inderscience enterprises ltd
3VEZNKK2;journalArticle;2017;"Smith, S.J.; Stone, B.T.; Ranatunga, T.; Nel, K.; Ramsoy, T.Z.; Berka, C.";Neurophysiological indices of human social interactions between humans and robots;Communications in Computer and Information Science;NA;18650929;10.1007/978-3-319-58750-9_36;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025174844&doi=10.1007%2f978-3-319-58750-9_36&partnerID=40&md5=a79ac8fdcd00acc223e0c6708767cf68;"Technology continues to advance at exponential rates and we are exposed to a multitude of electronic interfaces in almost every aspect of our lives. In order to achieve seamless integration of both, human and technology, we must examine the objective and subjective responses to such interactions. The goal of this study was to examine neurophysiological responses to movement, communication, and usability with a robot assistant, in comparison to human assistant, in a real-world setting. OSHbot (robot assistants designed by Fellow Robots) were utilized as mobile store clerks to identify and locate merchandise in order to assist customers in finding items within a hardware store. By acquiring neurophysiological measures (electroencephalogram; EEG and electrocardiogram; ECG) of human perception and interaction with robots, we found evidence of Mirror Neuron System (MNS) elicitation and motor imagery processing, which is consistent with other studies examining human-robot interactions. Multiple analyses were conducted to assess differences between human-human interaction and human-robot interaction. Several EEG metrics were identified that were distinguishable based on interaction type; among these was the change observed across the Mu bandwidth (8–13 Hz). The variance in this EEG correlate has been related to empathetic state change. In order to explore differences in the interactions related to gender and age additional analyses were conducted to compare the effects of human-human interaction versus human-robot interaction with data stratified by gender and age. This analysis yielded significant differences across these categories between human-human interaction and human-robot interaction within EEG metrics. These preliminary data show promise for future research in the field of human-robot relations in contributing to the design and implementation of machines that not only deliver basic services but also create a social connection with humans. © Springer International Publishing AG 2017.";2017;2021-05-19T13:26:37Z;2021-05-19T13:26:37Z;NA;251-262;NA;NA;713;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319587493 Publisher: Springer Verlag;"<p>cited By 1; Conference of 19th International Conference on Human-Computer Interaction, HCI International 2017 ; Conference Date: 9 July 2017 Through 14 July 2017; Conference Code:194249</p>";NA;NA;"Neurophysiology; Electroencephalography; Robots; Human robot interaction; Eye-tracking; Man machine systems; Machine design; Human-human interactions; Human computer interaction; Social interactions; Social sciences; Human social interactions; Electrocardiography; Design and implementations; Bandwidth; Electronic interface; Neurophysiological measures; Seamless integration";NA;C, Stephanidis;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;neurophysiologicalindicesofhumansocialinteractionsbetweenhumansandrobots;neurophysiological indices of human social interactions between humans and robots technology continues to advance at exponential rates and we are exposed to a multitude of electronic interfaces in almost every aspect of our lives in order to achieve seamless integration of both human and technology we must examine the objective and subjective responses to such interactions the goal of this study was to examine neurophysiological responses to movement communication and usability with a robot assistant in comparison to human assistant in a realworld setting oshbot robot assistants designed by fellow robots were utilized as mobile store clerks to identify and locate merchandise in order to assist customers in finding items within a hardware store by acquiring neurophysiological measures electroencephalogram eeg and electrocardiogram ecg of human perception and interaction with robots we found evidence of mirror neuron system mns elicitation and motor imagery processing which is consistent with other studies examining humanrobot interactions multiple analyses were conducted to assess differences between humanhuman interaction and humanrobot interaction several eeg metrics were identified that were distinguishable based on interaction type among these was the change observed across the mu bandwidth 813 hz the variance in this eeg correlate has been related to empathetic state change in order to explore differences in the interactions related to gender and age additional analyses were conducted to compare the effects of humanhuman interaction versus humanrobot interaction with data stratified by gender and age this analysis yielded significant differences across these categories between humanhuman interaction and humanrobot interaction within eeg metrics these preliminary data show promise for future research in the field of humanrobot relations in contributing to the design and implementation of machines that not only deliver basic services but also create a social connection with humans  springer international publishing ag 2017
FYPEQ7KH;conferencePaper;2017;"De Carolis, B.; Ferilli, S.; Palestra, G.; Redavid, D.";Emotion-recognition from speech-based interaction in AAL environment;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016315295&partnerID=40&md5=48d39fe986e3c8fb67cf9285e325457c;In Ambient Assisted Living environments assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. To this aim social assistive robots are being employed as a mediator interface and, in order to achieve a relation with the user, they should be endowed with the capability of recognizing the user affective state. Since a natural way to interact with a robot is speech, spoken user's input can be used to give to the robot the capability of recognizing the emotions and attitude of the user, thus providing more detail information about the user state. This paper focuses on this topic and proposes an approach based on the dimensional model of emotions in which the valence and arousal of user's spoken input are recognized. The experimental analysis shows the performance in terms of accuracy of the proposed approach on an Italian dataset. In order to show its application in the context of Ambient Assisted Living, an example is provided. © 2017, CEUR-WS. All rights reserved.;2017;2021-05-19T13:26:37Z;2021-05-19T13:26:37Z;NA;92-104;NA;NA;1803;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 1; Conference of 2nd Italian Workshop on Artificial Intelligence for Ambient Assisted Living, AI*AAL.it 2016 ; Conference Date: 28 November 2016; Conference Code:126783</p>";NA;NA;"Artificial intelligence; Robots; Speech recognition; Ambient assisted living; Affective state; Assistive robots; Deep neural networks; Assisted living; ITS applications; Ambient intelligence; Task-oriented; Emotion recognition from speech; Interface states; Dimensional model; Experimental analysis";NA;Bandini S., Cortellessa G., Palumbo F.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotionrecognitionfromspeechbasedinteractioninaalenvironment;emotionrecognition from speechbased interaction in aal environment in ambient assisted living environments assistance and care are delegated to the intelligence embedded in the environment that in our opinion should provide not only a taskoriented support but also an interface able to establish a social empathic relation with the user to this aim social assistive robots are being employed as a mediator interface and in order to achieve a relation with the user they should be endowed with the capability of recognizing the user affective state since a natural way to interact with a robot is speech spoken users input can be used to give to the robot the capability of recognizing the emotions and attitude of the user thus providing more detail information about the user state this paper focuses on this topic and proposes an approach based on the dimensional model of emotions in which the valence and arousal of users spoken input are recognized the experimental analysis shows the performance in terms of accuracy of the proposed approach on an italian dataset in order to show its application in the context of ambient assisted living an example is provided  2017 ceurws all rights reserved
T72TY9EG;journalArticle;2016;"Bennett, P.; Moore, M.; Wenham, J.";The PAUL Suit©: An experience of ageing;Clinical Teacher;NA;17434971;10.1111/tct.12410;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962516324&doi=10.1111%2ftct.12410&partnerID=40&md5=b1c6d99b190d125ab4dbf1d3806b09d5;Background: An ageing population worldwide makes it increasingly important that health students understand issues that elderly people face and can provide empathic care to them. Context: This teaching department in an isolated rural setting developed an interprofessional learning session to assist health students to understand issues of functional loss and social isolation that can affect elderly people. Innovation: The Premature Ageing Unisex Leisure (PAUL) Suit© was developed as part of a 1-day learning session for undergraduate health students - including students of medicine, nursing and allied health - attending clinical placement in far-west New South Wales. The suit was developed locally and can be adjusted to simulate a wide range of functional losses in the wearer. Students undertake a range of daily tasks in the community while wearing the suit in the company of a student 'carer'. Over the past 4 years, approximately 140 students have participated in the simulation. Post-simulation evaluations report that students gain a greater understanding of some functional issues associated with ageing, and of the social isolation that can be associated with these. The experiential nature of the activity leads to some powerful insights. This activity is an innovative, experiential tool to deepen students understanding of issues related to ageing Implications: This activity is an innovative, experiential tool to deepen students understanding of issues relating to ageing. The interprofessional nature of the activity is an important factor in the success of the day, and produces a wide range of shared insights. The activity also enhances the partnerships between the university, the health service and the local community. Our experience supports the value of simulation in providing a deep learning opportunity in the area of ageing and disability. © 2016 John Wiley & Sons Ltd.;2016;2021-05-19T13:26:39Z;2021-05-19T13:26:39Z;NA;107-111;NA;2;13;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Blackwell Publishing Ltd;<p>cited By 8</p>;NA;NA;"Humans; learning; Learning; education; psychology; Aging; human; health care personnel; Health Personnel; aging; Interprofessional Relations; Mobility Limitation; New South Wales; program evaluation; Program Evaluation; public relations; walking difficulty";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;thepaulsuitanexperienceofageing;the paul suit an experience of ageing background an ageing population worldwide makes it increasingly important that health students understand issues that elderly people face and can provide empathic care to them context this teaching department in an isolated rural setting developed an interprofessional learning session to assist health students to understand issues of functional loss and social isolation that can affect elderly people innovation the premature ageing unisex leisure paul suit was developed as part of a 1day learning session for undergraduate health students  including students of medicine nursing and allied health  attending clinical placement in farwest new south wales the suit was developed locally and can be adjusted to simulate a wide range of functional losses in the wearer students undertake a range of daily tasks in the community while wearing the suit in the company of a student carer over the past 4 years approximately 140 students have participated in the simulation postsimulation evaluations report that students gain a greater understanding of some functional issues associated with ageing and of the social isolation that can be associated with these the experiential nature of the activity leads to some powerful insights this activity is an innovative experiential tool to deepen students understanding of issues related to ageing implications this activity is an innovative experiential tool to deepen students understanding of issues relating to ageing the interprofessional nature of the activity is an important factor in the success of the day and produces a wide range of shared insights the activity also enhances the partnerships between the university the health service and the local community our experience supports the value of simulation in providing a deep learning opportunity in the area of ageing and disability  2016 john wiley  sons ltd
8CLPN3UV;journalArticle;2016;"Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.";Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy;Paladyn;NA;20814836;10.1515/pjbr-2016-0005;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88;An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.;2016;2021-05-19T13:26:39Z;2021-05-19T13:26:39Z;NA;55-66;NA;1;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: De Gruyter Open Ltd;<p>cited By 13</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;appearanceofarobotaffectstheimpactofitsbehaviouronperceivedtrustworthinessandempathy;appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy an increasing number of companion robots have started reaching the public in the recent years these robots vary in their appearance and behavior since these two factors can have an impact on lasting humanrobot relationships it is important to understand their effect for companion robots we have conducted an experiment that evaluated the impact of a robots appearance and its behaviour in repeated interactions on its perceived empathy trustworthiness and anxiety experienced by a human the results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot moreover negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot in addition we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots moreover a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partners message in order to reduce her anxiety  2016 jakub złotowski et al published by de gruyter open
XAEAITMC;conferencePaper;2016;"Ferreira, M.I.A.; Sequeira, J.S.";Designing a robotic interface for children: The MOnarCH robot example;Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016;978-981-314-912-0;NA;10.1142/9789813149137_0076;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999663794&doi=10.1142%2f9789813149137_0076&partnerID=40&md5=7de84e5ccd68ae2c76e5f3801431a3f9;The development of an empathic link between oneself and the Other is a fundamental part of interpersonal relationships determining the establishment of effective social and affective links that are the grounding basis of successful communication and cooperation on which the cohesion of human societies depend and on which harmonious global personal development also stands. The design of efficient robotic interfaces for interaction with people, namely with children, depends on the development of expressive elements to be present in the appearance of robots and in the way they address and interact with people, i.e. on the definition of a set of socially behaviours identified as communication enhancers. The present paper reflects how the previous assumptions have determined the process that led to the construction of the MOnarCH robots and some of its design options. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.;2016;2021-05-19T13:26:41Z;2021-05-19T13:26:41Z;NA;652-659;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;World Scientific Publishing Co. Pte Ltd;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 1; Conference of 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016 ; Conference Date: 12 September 2016 Through 14 September 2016; Conference Code:185329</p>";NA;NA;"Robotics; Communication; Mobile robots; Social robotics; Machine design; Human society; Economic and social effects; Interpersonal relationship; Children/robot interaction; Designing for interaction; Expressiveness; Personal development; Robotic interface";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designingaroboticinterfaceforchildrenthemonarchrobotexample;designing a robotic interface for children the monarch robot example the development of an empathic link between oneself and the other is a fundamental part of interpersonal relationships determining the establishment of effective social and affective links that are the grounding basis of successful communication and cooperation on which the cohesion of human societies depend and on which harmonious global personal development also stands the design of efficient robotic interfaces for interaction with people namely with children depends on the development of expressive elements to be present in the appearance of robots and in the way they address and interact with people ie on the definition of a set of socially behaviours identified as communication enhancers the present paper reflects how the previous assumptions have determined the process that led to the construction of the monarch robots and some of its design options  2016 world scientific publishing co pte ltd all rights reserved
F6TNAXP8;journalArticle;2016;"Shukla, J.; Barreda-Ángeles, M.; Oliver, J.; Puig, D.";MuDERI: Multimodal database for emotion recognition among intellectually disabled individuals;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);NA;03029743;10.1007/978-3-319-47437-3_26;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992523179&doi=10.1007%2f978-3-319-47437-3_26&partnerID=40&md5=5ecb6239283b3977469c0dc20359fa09;Social robots with empathic interaction is a crucial requirement towards deliverance of an effective cognitive stimulation among individuals with Intellectual Disability (ID) and has been challenged by absence of any particular database. Project REHABIBOTICS presents a first ever multimodal database of individuals with ID, recorded in a nearly real world settings for analysis of human affective states. MuDERI is an annotated multimodal database of audiovisual recordings, RGB-D videos and physiological signals of 12 participants in actual settings, which were recorded as participants were elicited using personalized real world objects and/or activities. The database is publicly available. © Springer International Publishing AG 2016.;2016;2021-05-19T13:26:41Z;2021-05-19T13:26:41Z;NA;264-273;NA;NA;9979 LNAI;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISBN: 9783319474366 Publisher: Springer Verlag;"<p>cited By 4; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>";NA;NA;"Robotics; Emotion recognition; Multimodal database; Assistive robotics; Intellectual disability; Database systems; Physiological signals; Robot-assisted therapies; Cognitive stimulations; Disabled individuals; Rating";NA;Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;muderimultimodaldatabaseforemotionrecognitionamongintellectuallydisabledindividuals;muderi multimodal database for emotion recognition among intellectually disabled individuals social robots with empathic interaction is a crucial requirement towards deliverance of an effective cognitive stimulation among individuals with intellectual disability id and has been challenged by absence of any particular database project rehabibotics presents a first ever multimodal database of individuals with id recorded in a nearly real world settings for analysis of human affective states muderi is an annotated multimodal database of audiovisual recordings rgbd videos and physiological signals of 12 participants in actual settings which were recorded as participants were elicited using personalized real world objects andor activities the database is publicly available  springer international publishing ag 2016
4TJGWVGS;conferencePaper;2016;"Fung, P.; Dey, A.; Bin Siddique, F.; Lin, R.; Yang, Y.; Bertero, D.; Yan, W.; Yin, R.C.H.; Wu, C.-S.";Zara: A virtual interactive dialogue system incorporating emotion, sentiment and personality recognition;COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations;978-4-87974-703-7;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048777533&partnerID=40&md5=fbcd4dcbaee2c6a3edb8e95be195275d;Zara, or 'Zara the Supergirl' is a virtual robot, that can exhibit empathy while interacting with an user, with the aid of its built in facial and emotion recognition, sentiment analysis, and speech module. At the end of the 5-10 minute conversation, Zara can give a personality analysis of the user based on all the user utterances. We have also implemented a real-time emotion recognition, using a CNN model that detects emotion from raw audio without feature extraction, and have achieved an average of 65.7% accuracy on six different emotion classes, which is an impressive 4.5% improvement from the conventional feature based SVM classification. Also, we have described a CNN based sentiment analysis module trained using out-of-domain data, that recognizes sentiment from the speech recognition transcript, which has a 74.8 F-measure when tested on human-machine dialogues. © COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: System Demonstrations.;2016;2021-05-19T13:26:41Z;2021-05-19T13:26:41Z;NA;278-281;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Association for Computational Linguistics, ACL Anthology;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 4; Conference of 26th International Conference on Computational Linguistics, COLING 2016 ; Conference Date: 11 December 2016 Through 16 December 2016; Conference Code:136520</p>";NA;NA;"Sentiment analysis; Emotion recognition; Speech recognition; Feature extraction; Personality recognition; Data mining; Human computer interaction; Computational linguistics; Classification (of information); Speech processing; Dialogue systems; Human-machine dialogue; SVM classification; Speech module; Virtual robots; Real-time emotion recognition";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;zaraavirtualinteractivedialoguesystemincorporatingemotionsentimentandpersonalityrecognition;zara a virtual interactive dialogue system incorporating emotion sentiment and personality recognition zara or zara the supergirl is a virtual robot that can exhibit empathy while interacting with an user with the aid of its built in facial and emotion recognition sentiment analysis and speech module at the end of the 510 minute conversation zara can give a personality analysis of the user based on all the user utterances we have also implemented a realtime emotion recognition using a cnn model that detects emotion from raw audio without feature extraction and have achieved an average of 657 accuracy on six different emotion classes which is an impressive 45 improvement from the conventional feature based svm classification also we have described a cnn based sentiment analysis module trained using outofdomain data that recognizes sentiment from the speech recognition transcript which has a 748 fmeasure when tested on humanmachine dialogues  coling 2016  26th international conference on computational linguistics proceedings of coling 2016 system demonstrations
W9PXXX4R;conferencePaper;2015;"Mazzei, D.; Zaraki, A.; Lazzeri, N.; De Rossi, D.";Recognition and expression of emotions by a symbiotic android head;IEEE-RAS International Conference on Humanoid Robots;978-1-4799-7174-9;NA;10.1109/HUMANOIDS.2014.7041349;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945179051&doi=10.1109%2fHUMANOIDS.2014.7041349&partnerID=40&md5=f47b54fd692ed1f07a9bef8e2a4b0f1c;The creation of social empathie communication channels between social robots and humans has started to become reality. Nowadays, the development of empathie and affective agents is giving to scientists another way to explore the social dimension of human beings. In this work, we introduce the FACE humanoid project that aims at creating a social and emotional android. FACE is an android head with an articulated neck mounted on a passive body. In order to enable FACE to perceive and express emotions, two dedicated engines have been developed. A sensory apparatus able to perceive the 'social world', and a facial expressions generation engine that allows the robot to express its synthetic emotions. The system has been also integrated with an attention-based gaze generation component that allows the robot to autonomously follow a conversation between its partners. The developed framework has been implemented and tested in several standard human-robot interaction settings. Results demonstrated the promising social capabilities of the robot to perceive and convey emotions to humans through the generation of emotional perceivable facial expressions and socially aligned behaviour. © 2014 IEEE.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;134-139;NA;NA;2015-February;NA;NA;NA;NA;NA;NA;NA;IEEE Computer Society;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 21640572;"<p>cited By 3; Conference of 2014 14th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2014 ; Conference Date: 18 November 2014 Through 20 November 2014; Conference Code:112990</p>";NA;NA;"Social robots; Human robot interaction; Anthropomorphic robots; Human being; Facial Expressions; Behavioral research; Express emotions; Engines; Social dimensions; Synthetic emotions";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;recognitionandexpressionofemotionsbyasymbioticandroidhead;recognition and expression of emotions by a symbiotic android head the creation of social empathie communication channels between social robots and humans has started to become reality nowadays the development of empathie and affective agents is giving to scientists another way to explore the social dimension of human beings in this work we introduce the face humanoid project that aims at creating a social and emotional android face is an android head with an articulated neck mounted on a passive body in order to enable face to perceive and express emotions two dedicated engines have been developed a sensory apparatus able to perceive the social world and a facial expressions generation engine that allows the robot to express its synthetic emotions the system has been also integrated with an attentionbased gaze generation component that allows the robot to autonomously follow a conversation between its partners the developed framework has been implemented and tested in several standard humanrobot interaction settings results demonstrated the promising social capabilities of the robot to perceive and convey emotions to humans through the generation of emotional perceivable facial expressions and socially aligned behaviour  2014 ieee
S6N2JSV6;conferencePaper;2015;"De Carolis, B.; Ferilli, S.; Palestra, G.; Carofiglio, V.";Towards an empathic social robot for ambient assisted living;CEUR Workshop Proceedings;NA;NA;NA;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928737527&partnerID=40&md5=b573ae7afac79bef8ae0c8f77bd8451d;In the context of Ambient Assisted Living, assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. This can be achieved, for instance, using a social assistive robot as interface towards the environment services. In the context of the NICA (Natural Interaction with a Caring Agent) project we developed the behavioral architecture of a social robot able to assist the user in the interaction with a smart home environment. In this paper we describe how this robot has been endowed with the capability of recognizing the user affective state from the combination of facial expressions and spoken utterances and to reason on in order to simulate an empathic behavior.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;19-34;NA;NA;1351;NA;NA;NA;NA;NA;NA;NA;CEUR-WS;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 16130073;"<p>cited By 8; Conference of 2nd International Workshop on Emotion and Sentiment in Social and Expressive Media, ESSEM 2015 ; Conference Date: 5 May 2015; Conference Code:112014</p>";NA;NA;"Robots; Social robots; Autonomous agents; Intelligent buildings; Ambient assisted living; Affective state; Facial Expressions; Assistive robots; Multi agent systems; Automation; Natural interactions; Task-oriented; As interfaces";NA;Cambria E., Patti V., Rosso P., Bosco C., Damiano R.;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsanempathicsocialrobotforambientassistedliving;towards an empathic social robot for ambient assisted living in the context of ambient assisted living assistance and care are delegated to the intelligence embedded in the environment that in our opinion should provide not only a taskoriented support but also an interface able to establish a social empathic relation with the user this can be achieved for instance using a social assistive robot as interface towards the environment services in the context of the nica natural interaction with a caring agent project we developed the behavioral architecture of a social robot able to assist the user in the interaction with a smart home environment in this paper we describe how this robot has been endowed with the capability of recognizing the user affective state from the combination of facial expressions and spoken utterances and to reason on in order to simulate an empathic behavior
34JPKPGJ;journalArticle;2015;"Vallverdú, J.; Casacuberta, D.";Ethical and technical aspects of emotions to create empathy in medical machines;Intelligent Systems, Control and Automation: Science and Engineering;NA;22138986;10.1007/978-3-319-08108-3_20;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e;This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.;2015;2021-05-19T13:26:43Z;2021-05-19T13:26:43Z;NA;341-362;NA;NA;74;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Kluwer Academic Publishers;<p>cited By 5</p>;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ethicalandtechnicalaspectsofemotionstocreateempathyinmedicalmachines;ethical and technical aspects of emotions to create empathy in medical machines this chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions artificial emotions is still an emergent field in artificial intelligence so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions we argue that empathy is the key emotion in healthcare contexts we discuss what empathy is and how it can be modeled to include it in a medical machine we consider types of medical machines telemedicine care robots and mobile apps and describe the main machines that are in use and offer some predictions about what the near future may bring the main ethical problems we consider in machine medical ethics are privacy violations due to online patient databases how to deal with error and responsibility concerning machine decisions and actions social inequality as a result of people being removed from an ehealthcare system and how to build trust between machines patients and medical professionals  springer international publishing switzerland 2015
A89B4BEA;journalArticle;2015;"Virčíkova, M.; Sinčák, P.";Teach your robot how you want it to express emotions: On the personalized affective human-humanoid interaction;Advances in Intelligent Systems and Computing;NA;21945357;10.1007/978-3-319-10783-7_9;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032118207&doi=10.1007%2f978-3-319-10783-7_9&partnerID=40&md5=22af8b608d901d438a4c1910a06c47ef;We believe that in order for robots to interact naturally with humans, they should be able to express affective behavior. This paper deals with the development of an affective model for social robotics in which the resulting robotic expressions adapt according to the human subjective preferences. We have developed a method which can be used by non-technical individuals to design the affective models of humanoid robots. Our vision of the future research is that the proposed personalization will be treated, from user’s perspective, as an empathic response of the machine. We see the major contribution of this unique approach especially in long-term human-robot relationships and it could ultimately lead to robots being accepted in a wider domain. © Springer International Publishing Switzerland 2015.;2015;2021-05-19T13:26:44Z;2021-05-19T13:26:44Z;NA;81-92;NA;NA;316;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Publisher: Springer Verlag;<p>cited By 0</p>;NA;NA;"Robotics; Computer vision; Robots; Human robot interaction; Social robotics; Humanoid robot; Machine design; Anthropomorphic robots; Humanoid interaction; Human robots; Economic and social effects; Affective behaviors; Personalizations; Express emotions; Affective model";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;teachyourrobothowyouwantittoexpressemotionsonthepersonalizedaffectivehumanhumanoidinteraction;teach your robot how you want it to express emotions on the personalized affective humanhumanoid interaction we believe that in order for robots to interact naturally with humans they should be able to express affective behavior this paper deals with the development of an affective model for social robotics in which the resulting robotic expressions adapt according to the human subjective preferences we have developed a method which can be used by nontechnical individuals to design the affective models of humanoid robots our vision of the future research is that the proposed personalization will be treated from users perspective as an empathic response of the machine we see the major contribution of this unique approach especially in longterm humanrobot relationships and it could ultimately lead to robots being accepted in a wider domain  springer international publishing switzerland 2015
G2K4TBVD;conferencePaper;2015;"Yoshida, N.; Nakataniy, Y.; Yonezawa, T.";Breathing expression for intimate communication corresponding to the physical distance and contact between human and robot;EAI International Conference on Bio-inspired Information and Communications Technologies (BICT);NA;NA;10.4108/eai.3-12-2015.2262419;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052166553&doi=10.4108%2feai.3-12-2015.2262419&partnerID=40&md5=9713dbd5e5ed533a7a82dfbe30666dfd;"In this paper, we propose living-being-like breathing expressions concurrent with both aspiration and utterances using a stuffed-Toy robot in order to enable intimate interactions. The focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two. From the factor analysis of the impression for the word ıntimacy"" and the distance between the robot and the participants, it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility. © 2016 ICST.";2015;2021-05-19T13:26:44Z;2021-05-19T13:26:44Z;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;ISSN: 24116777;"<p>cited By 0; Conference of 9th EAI International Conference on Bio-Inspired Information and Communications Technologies, BICT 2015 ; Conference Date: 3 December 2015 Through 5 December 2015; Conference Code:130982</p>";NA;NA;"Robots; Close distance; Stuffed toy robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;breathingexpressionforintimatecommunicationcorrespondingtothephysicaldistanceandcontactbetweenhumanandrobot;breathing expression for intimate communication corresponding to the physical distance and contact between human and robot in this paper we propose livingbeinglike breathing expressions concurrent with both aspiration and utterances using a stuffedtoy robot in order to enable intimate interactions the focus of the research is the impression of the intimacy between the robot and the user corresponding to the physical distance of the two from the factor analysis of the impression for the word ıntimacy and the distance between the robot and the participants it is conjectured that the physical intimacy showed strong effects in terms of both warm empathy and tranquility  2016 icst
LYXK3QA8;conferencePaper;2015;"Pieroni, M.; Rizzello, L.; Rosini, N.; Fantoni, G.; De Rossi, D.; Mazzei, D.";Affective Internet of Things: Mimicking human-like personality in designing smart-objects;IEEE World Forum on Internet of Things, WF-IoT 2015 - Proceedings;978-1-5090-0365-5;NA;10.1109/WF-IoT.2015.7389088;https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964556250&doi=10.1109%2fWF-IoT.2015.7389088&partnerID=40&md5=8a13b6d0e0a3f31879eb1dbd9bcdce78;The paper wants to introduce the concept of Affective Internet of Things (AIoT) where smart objects are empowered with affective capability in terms of abstraction of their emotional state. Moreover each smart object can be associated with a specific 'personality'. This approach, already used in the field of social robotics, mainly exploits robots' appearance (i.e. anthropomorphism or zoomorphism). The research aims at extending such a paradigm to everyday-life objects in order to 'warm-up' the empathic connections that humans generally establish with 'cold' gadgets and devices. A new framework for the Affective IoT has been developed: EMPATI (EMPATI Mimics Personalities on Affective Things on Internet). It provides models and functions to simulate different personality for affective objects living in both virtual and real world. Finally, a set of experiments has been conceived to assess the key aspects of the framework in terms of capability to simulate emotional responses depending on the object interaction with the environment and the affective stimuli. © 2015 IEEE.;2015;2021-05-19T13:26:45Z;2021-05-19T13:26:45Z;NA;400-405;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Institute of Electrical and Electronics Engineers Inc.;NA;English;NA;NA;NA;NA;NA;NA;NA;"<p>cited By 6; Conference of 2nd IEEE World Forum on Internet of Things, WF-IoT 2015 ; Conference Date: 14 December 2015 Through 16 December 2015; Conference Code:119271</p>";NA;NA;"Robotics; Internet; Social robotics; Emotional state; Emotional response; Human computer interaction; Human like; Internet of things; Real-world; affective object; Object interactions; Smart objects";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;affectiveinternetofthingsmimickinghumanlikepersonalityindesigningsmartobjects;affective internet of things mimicking humanlike personality in designing smartobjects the paper wants to introduce the concept of affective internet of things aiot where smart objects are empowered with affective capability in terms of abstraction of their emotional state moreover each smart object can be associated with a specific personality this approach already used in the field of social robotics mainly exploits robots appearance ie anthropomorphism or zoomorphism the research aims at extending such a paradigm to everydaylife objects in order to warmup the empathic connections that humans generally establish with cold gadgets and devices a new framework for the affective iot has been developed empati empati mimics personalities on affective things on internet it provides models and functions to simulate different personality for affective objects living in both virtual and real world finally a set of experiments has been conceived to assess the key aspects of the framework in terms of capability to simulate emotional responses depending on the object interaction with the environment and the affective stimuli  2015 ieee
MLEEMK4E;conferencePaper;2021;"Park, Ung; Kim, Minsoo; Jang, Youngeun; Lee, GiJae; Kim, KangGeon; Kim, Ig-Jae; Choi, Jongsuk";Robot Facial Expression Framework for Enhancing Empathy in Human-Robot Interaction;"2021 30th IEEE International Conference on Robot &amp; Human Interactive Communication (RO-MAN)";NA;NA;10.1109/RO-MAN50785.2021.9515533;https://doi.org/10.1109/RO-MAN50785.2021.9515533;"A social robot interacts with humans based on social intelligence, for which related applications are being developed across diverse fields to be increasingly integrated in modern society. In this regard, social intelligence and interaction are the keywords of a social robot. Social intelligence refers to the ability to control interactions or thoughts and feelings of relationships with other people; primal empathy, which is the ability to empathize by perceiving emotional signals, among the components of social intelligence was applied to the robot in this study. We proposed that the empathic ability of a social robot can be improved if the social robot can create facial expressions based on the emotional state of a user. Moreover, we suggested a framework of facial expressions for robots. These facial expressions can be repeatedly used in various social robot platforms to achieve such a strategy.";2021;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;832–838;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Vancouver, BC, Canada;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;robotfacialexpressionframeworkforenhancingempathyinhumanrobotinteraction;robot facial expression framework for enhancing empathy in humanrobot interaction a social robot interacts with humans based on social intelligence for which related applications are being developed across diverse fields to be increasingly integrated in modern society in this regard social intelligence and interaction are the keywords of a social robot social intelligence refers to the ability to control interactions or thoughts and feelings of relationships with other people primal empathy which is the ability to empathize by perceiving emotional signals among the components of social intelligence was applied to the robot in this study we proposed that the empathic ability of a social robot can be improved if the social robot can create facial expressions based on the emotional state of a user moreover we suggested a framework of facial expressions for robots these facial expressions can be repeatedly used in various social robot platforms to achieve such a strategy
4Z7J38Q6;conferencePaper;2021;"Bejarano, Alexandra; Lomax, Olivia; Scherschel, Peyton; Williams, Tom";Designing for Perceived Robot Empathy for Children in Long-Term Care;Social Robotics: 13th International Conference, ICSR 2021, Singapore, Singapore, November 10–13, 2021, Proceedings;978-3-030-90524-8;NA;10.1007/978-3-030-90525-5_65;https://doi.org/10.1007/978-3-030-90525-5_65;"We describe a mixed-methods approach toward the design and evaluation of social robots that can offer emotional support for children in long-term care environments. Based on the results of a needfinding interview with a local expert, our specific aim was to design a robot that would be perceived as empathetic. An online human-subject study (n&nbsp;=&nbsp;26) provided preliminary support for a hypothesis that this design goal could be achieved by designing robots to maintain the flow of conversation and ask related followup questions to further understand interlocutors’ feelings.";2021;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;743–748;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Springer-Verlag;Berlin, Heidelberg;NA;NA;NA;NA;NA;NA;NA;event-place: Singapore, Singapore;NA;NA;NA;"Child-robot interaction; Empathy; Social robot design";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;designingforperceivedrobotempathyforchildreninlongtermcare;designing for perceived robot empathy for children in longterm care we describe a mixedmethods approach toward the design and evaluation of social robots that can offer emotional support for children in longterm care environments based on the results of a needfinding interview with a local expert our specific aim was to design a robot that would be perceived as empathetic an online humansubject study nnbspnbsp26 provided preliminary support for a hypothesis that this design goal could be achieved by designing robots to maintain the flow of conversation and ask related followup questions to further understand interlocutors feelings
A53IVFEL;journalArticle;2021;"Sripian, Peeraya; Mohd Anuardi, Muhammad Nur Adilin; Kajihara, Yushun; Sugaya, Midori";Empathetic Robot Evaluation through Emotion Estimation Analysis and Facial Expression Synchronization from Biological Information;Artif. Life Robot.;NA;1433-5298;10.1007/s10015-021-00696-w;https://doi.org/10.1007/s10015-021-00696-w;Empathy is an important factor in human communication. For a robot to apply a matching emotion in human–robot communication, the robot needs to be able to understand human feelings. Therefore, in this study, we aimed to improve the human impression of the robot using a robot that expresses human-like expressions by synchronizing with human biological information and changing the expressions in real time. We first measured and estimated human emotions using an emotion estimation method based on biological information (brain waves and heartbeats). The three-emotion estimation methods were proposed and evaluated in the preliminary experiment. Among the three-emotion estimation methods proposed, the one that yields the highest impression rating was chosen to be used in the second experiment which was based on the emotional value in each cycle method. Then, we developed a robot that shows expressions in two patterns: (1) synchronized emotion (same emotion as subject conveyed) and (2) inversed emotion with the human. The subjects evaluated the robot’s expression from both patterns using semantic differential (SD) method while having their biological information measured based on the selected emotion estimation method from previous preliminary experiment. The evaluation by SD method and biological information results showed that when the human experienced the happiness emotion, and the robot synchronized and expressed the same emotion, this could increase the intimacy between human and robot. Here, it can be said that the impression created by the robot’s expression can be improved using biological information.;2021-11;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;379–389;NA;4;26;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Place: Berlin, Heidelberg Publisher: Springer-Verlag;NA;NA;NA;"Biological information; Emotion analysis; Emotion estimation; Empathetic robot; Robot expression";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empatheticrobotevaluationthroughemotionestimationanalysisandfacialexpressionsynchronizationfrombiologicalinformation;empathetic robot evaluation through emotion estimation analysis and facial expression synchronization from biological information empathy is an important factor in human communication for a robot to apply a matching emotion in humanrobot communication the robot needs to be able to understand human feelings therefore in this study we aimed to improve the human impression of the robot using a robot that expresses humanlike expressions by synchronizing with human biological information and changing the expressions in real time we first measured and estimated human emotions using an emotion estimation method based on biological information brain waves and heartbeats the threeemotion estimation methods were proposed and evaluated in the preliminary experiment among the threeemotion estimation methods proposed the one that yields the highest impression rating was chosen to be used in the second experiment which was based on the emotional value in each cycle method then we developed a robot that shows expressions in two patterns 1 synchronized emotion same emotion as subject conveyed and 2 inversed emotion with the human the subjects evaluated the robots expression from both patterns using semantic differential sd method while having their biological information measured based on the selected emotion estimation method from previous preliminary experiment the evaluation by sd method and biological information results showed that when the human experienced the happiness emotion and the robot synchronized and expressed the same emotion this could increase the intimacy between human and robot here it can be said that the impression created by the robots expression can be improved using biological information
LGGQR8TI;conferencePaper;2022;"Takahashi, Tomomi; Song, Sichao; Baba, Jun; Nakanishi, Junya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi";Can an Empathetic Teleoperated Robot Be a Working Mate That Supports Operator's Mentality?;Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;NA;NA;Customer service with teleoperated robots is susceptible to the same problems related to stress as is emotional labor in general, such as for in-person customer service representatives. In this study, we aimed to reduce that stress by constructing a buddy-like rapport between the robot, which is the target of teleoperation, and its operator. For this purpose, we designed an empathetic interaction between the robot and the operator and conducted a customer service experiment to verify its effectiveness. Our results demonstrate that the proposed interaction can build rapport between the robot and the operator and the operator can feel more reassured. Although the effect on stress could not be isolated directly from the data, detailed analyses of the response to the questionnaires indicated that the proposed interaction may be useful to relieve stress.;2022;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;1059–1063;NA;NA;NA;NA;NA;NA;HRI '22;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Sapporo, Hokkaido, Japan;NA;NA;NA;"empathetic interaction; mental stress; rapport; teleoperated robot";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;cananempatheticteleoperatedrobotbeaworkingmatethatsupportsoperatorsmentality;can an empathetic teleoperated robot be a working mate that supports operators mentality customer service with teleoperated robots is susceptible to the same problems related to stress as is emotional labor in general such as for inperson customer service representatives in this study we aimed to reduce that stress by constructing a buddylike rapport between the robot which is the target of teleoperation and its operator for this purpose we designed an empathetic interaction between the robot and the operator and conducted a customer service experiment to verify its effectiveness our results demonstrate that the proposed interaction can build rapport between the robot and the operator and the operator can feel more reassured although the effect on stress could not be isolated directly from the data detailed analyses of the response to the questionnaires indicated that the proposed interaction may be useful to relieve stress
MZUS4GYD;conferencePaper;2022;"Salutari, Agnese; Tarantino, Laura; De Gasperis, Giovanni";BlocksBot: Towards an Empathic Robot Offering Multi-Modal Emotion Detection Based on a Distributed Hybrid System;Human-Computer Interaction. Technological Innovation: Thematic Area, HCI 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings, Part II;978-3-031-05408-2;NA;10.1007/978-3-031-05409-9_45;https://doi.org/10.1007/978-3-031-05409-9_45;Studies show that people expectations on robots and their behavior are similar to those regarding living objects, and that users ascribe robots with human attributes, qualities, and capabilities even when the robot is not conceived for social interaction. Actually, the increasing availability of sensors able to capture situational data makes it possible to achieve adaptive systems able to dynamically take into account users’ and context information with unprecedented precision, thus showing some degree of empathy and emotional intelligence. Modern robots can use their sensors, like cameras and microphones, not only for their more traditional goals, but also for classifying human emotional states in order to emulate an empathic behavior, and to put the users at ease and tempt them in continuing the interaction. They can offer a human-like communication occurring over different verbal and non-verbal communication channels. Anyhow, since multi-modal emotion detection is a complex technique requiring a proper combination of all the deriving data, handling it can be very demanding, and maybe impossible to achieve for many machines because of hardware limitations or simply for an unaffordable battery power consumption, with an ultimate effect on usability, which can degrade up to an unacceptable degree. In this paper we discuss how these problems have been faced within the framework of the BlocksBot project and how its Hybrid Distributed approach allows to overcome such limitations.;2022;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;625–638;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;Springer-Verlag;Berlin, Heidelberg;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Empathy; Human-Robot Interaction; Multimodal emotion detection; Performances";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;blocksbottowardsanempathicrobotofferingmultimodalemotiondetectionbasedonadistributedhybridsystem;blocksbot towards an empathic robot offering multimodal emotion detection based on a distributed hybrid system studies show that people expectations on robots and their behavior are similar to those regarding living objects and that users ascribe robots with human attributes qualities and capabilities even when the robot is not conceived for social interaction actually the increasing availability of sensors able to capture situational data makes it possible to achieve adaptive systems able to dynamically take into account users and context information with unprecedented precision thus showing some degree of empathy and emotional intelligence modern robots can use their sensors like cameras and microphones not only for their more traditional goals but also for classifying human emotional states in order to emulate an empathic behavior and to put the users at ease and tempt them in continuing the interaction they can offer a humanlike communication occurring over different verbal and nonverbal communication channels anyhow since multimodal emotion detection is a complex technique requiring a proper combination of all the deriving data handling it can be very demanding and maybe impossible to achieve for many machines because of hardware limitations or simply for an unaffordable battery power consumption with an ultimate effect on usability which can degrade up to an unacceptable degree in this paper we discuss how these problems have been faced within the framework of the blocksbot project and how its hybrid distributed approach allows to overcome such limitations
WHE8U5HR;conferencePaper;2021;"Moon, Byeong June; Choi, JongSuk; Kwak, Sonya S.";"""Pretending to Be Okay in a Sad Voice"": Social Robot’s Usage of Verbal and Nonverbal Cue Combination and Its Effect on Human Empathy and Behavior Inducement<sup>*</sup>";2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);NA;NA;10.1109/IROS51168.2021.9636709;https://doi.org/10.1109/IROS51168.2021.9636709;Inducing a user’s behavior through social interaction is a goal that a social robot aims to achieve. It has been argued that empathy has a strong effect on behavior inducement. In human-human interaction, it has been verified that the influence of a nonverbal cue on empathy outweighs that of a verbal cue when those are used in a combined way. The objectives of this study are to explore if such outweighing effect of nonverbal cues is maintained in human-robot interaction (HRI) and to investigate the mechanism of communication cues’ effects by analyzing the mediation structure with the following mediator variables: perceived emotion, perceived intentionality, perceived malfunction, and empathy inducement. To this end, we conducted 2 (verbal type: positive verbal cue vs. negative verbal cue) × 2 (nonverbal type: positive nonverbal cue vs. negative nonverbal cue) within-participant experiment (N = 48). The experiment created a situation in which the social robot was harshly criticized during a conversation. The analysis of experiment results showed the outweighing effect of a nonverbal cue was maintained. When a nonverbal cue conveyed a negative, situation-accordant emotion, it had a decisive effect on perceived emotion, empathy, and behavior inducement. In contrast, a verbal cue induced participants’ empathy and behavior when it conveyed a positive, situation-discordant emotion. This inconsistency between verbal cue and nonverbal cue made the combination of positive verbal cue and negative nonverbal cue have the strongest effect. It implies that participants had different expectations for each of the two communication cues, just as they did in social interactions with human beings. It implies that participants might have applied normative expectations for social interaction with human beings to the social robot.;2021;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;854–861;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Prague, Czech Republic;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;pretendingtobeokayinasadvoicesocialrobotsusageofverbalandnonverbalcuecombinationanditseffectonhumanempathyandbehaviorinducementsupsup;pretending to be okay in a sad voice social robots usage of verbal and nonverbal cue combination and its effect on human empathy and behavior inducementsupsup inducing a users behavior through social interaction is a goal that a social robot aims to achieve it has been argued that empathy has a strong effect on behavior inducement in humanhuman interaction it has been verified that the influence of a nonverbal cue on empathy outweighs that of a verbal cue when those are used in a combined way the objectives of this study are to explore if such outweighing effect of nonverbal cues is maintained in humanrobot interaction hri and to investigate the mechanism of communication cues effects by analyzing the mediation structure with the following mediator variables perceived emotion perceived intentionality perceived malfunction and empathy inducement to this end we conducted 2 verbal type positive verbal cue vs negative verbal cue  2 nonverbal type positive nonverbal cue vs negative nonverbal cue withinparticipant experiment n  48 the experiment created a situation in which the social robot was harshly criticized during a conversation the analysis of experiment results showed the outweighing effect of a nonverbal cue was maintained when a nonverbal cue conveyed a negative situationaccordant emotion it had a decisive effect on perceived emotion empathy and behavior inducement in contrast a verbal cue induced participants empathy and behavior when it conveyed a positive situationdiscordant emotion this inconsistency between verbal cue and nonverbal cue made the combination of positive verbal cue and negative nonverbal cue have the strongest effect it implies that participants had different expectations for each of the two communication cues just as they did in social interactions with human beings it implies that participants might have applied normative expectations for social interaction with human beings to the social robot
ZDJ87RZ4;conferencePaper;2022;"Birmingham, Christopher; Perez, Ashley; Matarić, Maja";Perceptions of Cognitive and Affective Empathetic Statements by Socially Assistive Robots;Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;NA;NA;"Communicating empathy is important for building relationships in numerous contexts. Consequently, the failure of robots to be perceived as empathetic by human users could be detrimental to developing effective human-robot interaction. Work on computational models of empathy has been growing rapidly, reflecting the importance of this ability for machines. Despite growing recent work, there remain unanswered questions about how users perceive different forms of empathetic expression by robots and how attitudes towards robots may mediate perceptions of robot empathy. Do people really believe that robots can feel or understand emotions? This work studied the difference in viewers' perceptions of cognitive and affective empathetic statements made by a robot in response to human disclosure. In a within-subjects study, participants (n=111) watched videos in which a human disclosed negative emotions around COVID-19, and a robot responded with either affective or cognitive empathetic responses. Using an adapted version of the Robot's Perceived Empathy (RoPE) scale, participants rated their perceptions of the robot's empathy in both cases. We found that participants perceived the robot that made affective empathetic statements as being more empathetic that the robot that made cognitive empathetic statements; we also found that participants with more negative attitudes toward robots were more likely to rate the cognitive condition as more empathetic than the affective condition. These results inform HRI in general and future work into developing robots that will be perceived as empathetic and could personalize empathetic responses to each user.";2022;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;323–331;NA;NA;NA;NA;NA;NA;HRI '22;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Sapporo, Hokkaido, Japan;NA;NA;NA;"empathy; human-robot interaction; socially assistive robotics";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;perceptionsofcognitiveandaffectiveempatheticstatementsbysociallyassistiverobots;perceptions of cognitive and affective empathetic statements by socially assistive robots communicating empathy is important for building relationships in numerous contexts consequently the failure of robots to be perceived as empathetic by human users could be detrimental to developing effective humanrobot interaction work on computational models of empathy has been growing rapidly reflecting the importance of this ability for machines despite growing recent work there remain unanswered questions about how users perceive different forms of empathetic expression by robots and how attitudes towards robots may mediate perceptions of robot empathy do people really believe that robots can feel or understand emotions this work studied the difference in viewers perceptions of cognitive and affective empathetic statements made by a robot in response to human disclosure in a withinsubjects study participants n111 watched videos in which a human disclosed negative emotions around covid19 and a robot responded with either affective or cognitive empathetic responses using an adapted version of the robots perceived empathy rope scale participants rated their perceptions of the robots empathy in both cases we found that participants perceived the robot that made affective empathetic statements as being more empathetic that the robot that made cognitive empathetic statements we also found that participants with more negative attitudes toward robots were more likely to rate the cognitive condition as more empathetic than the affective condition these results inform hri in general and future work into developing robots that will be perceived as empathetic and could personalize empathetic responses to each user
PPGY7GUP;conferencePaper;2022;"Hsieh, Te-Yi; Cross, Emily S.";The Role of Empathic Traits in Emotion Recognition and Emotion Contagion of Cozmo Robots;Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction;NA;NA;NA;NA;In this online study, we investigated how well people could recognize emotions displayed by video recordings of a Cozmo robot, and the extent to which emotion recognition is shaped by individuals' empathic traits. We also explored whether participants who report more empathic tendencies experienced more emotional contagion when watching Cozmo's emotional displays, since emotion contagion is a core aspect of empathy. We tested participants' perceptions of Cozmo's happiness, anger, sadness, surprise, and neutral displays. Across 103 participants, we report high recognition rates for most emotion categories except neutral animations. Furthermore, the mixed effects modelling revealed that an empathy subtype (the empathic concern subscale from the Interpersonal Reactivity Index) significantly impacted emotional contagion. Contrary to predictions, participants with high empathic concern subscale scores were less likely to find the robot's videos emotionally contagious. The study validates the utility of Cozmo robots to display emotional cues recognizable to human users, and further suggests that empathic traits could shape our affective interactions with robots, though perhaps in a counterintuitive way.;2022;2022-07-15T08:52:46Z;2022-07-15T08:52:46Z;NA;802–806;NA;NA;NA;NA;NA;NA;HRI '22;NA;NA;NA;IEEE Press;NA;NA;NA;NA;NA;NA;NA;NA;event-place: Sapporo, Hokkaido, Japan;NA;NA;NA;"dispositional empathy; emotion contagion; emotion recognition; human-robot interaction";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;theroleofempathictraitsinemotionrecognitionandemotioncontagionofcozmorobots;the role of empathic traits in emotion recognition and emotion contagion of cozmo robots in this online study we investigated how well people could recognize emotions displayed by video recordings of a cozmo robot and the extent to which emotion recognition is shaped by individuals empathic traits we also explored whether participants who report more empathic tendencies experienced more emotional contagion when watching cozmos emotional displays since emotion contagion is a core aspect of empathy we tested participants perceptions of cozmos happiness anger sadness surprise and neutral displays across 103 participants we report high recognition rates for most emotion categories except neutral animations furthermore the mixed effects modelling revealed that an empathy subtype the empathic concern subscale from the interpersonal reactivity index significantly impacted emotional contagion contrary to predictions participants with high empathic concern subscale scores were less likely to find the robots videos emotionally contagious the study validates the utility of cozmo robots to display emotional cues recognizable to human users and further suggests that empathic traits could shape our affective interactions with robots though perhaps in a counterintuitive way
7YZ72LVZ;journalArticle;2021;"Pelau, Corina; Dabija, Dan-Cristian; Ene, Irina";What makes an AI device human-like? The role of interaction quality, empathy and perceived psychological anthropomorphic characteristics in the acceptance of artificial intelligence in the service industry;Computers in Human Behavior;NA;0747-5632;https://doi.org/10.1016/j.chb.2021.106855;https://www.sciencedirect.com/science/article/pii/S0747563221001783;Intelligent AI devices have become a common presence in the business landscape, offering a wide range of services, from the medical sector to the hospitality industry. From an organizational perspective, AI devices have several advantages, by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more cost-efficient. However, in order to maintain the high standards of a brand, they have to be accepted by consumers and deliver socially adequate performance. Therefore, it is important to determine the characteristics of AI devices which make them accepted and trusted by consumers. Based on the Computers as Social Actors (CASA) Theory, we have researched on the role of psychological anthropomorphic characteristics, perceived empathy, and interaction quality in the acceptance of AI devices in the service industry. The results show that anthropomorphic characteristics alone do not influence acceptance and trust towards AI devices. However, both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance. A human-like AI device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer. This result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and AI devices.;2021;2022-07-15T09:02:33Z;2022-07-15T09:02:33Z;NA;106855;NA;NA;122;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"AI device; Anthropomorphism; Artificial intelligence; Computers as social actors; Consumer behaviour; Human-AI interaction; Human-computer interaction; Robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;whatmakesanaidevicehumanliketheroleofinteractionqualityempathyandperceivedpsychologicalanthropomorphiccharacteristicsintheacceptanceofartificialintelligenceintheserviceindustry;what makes an ai device humanlike the role of interaction quality empathy and perceived psychological anthropomorphic characteristics in the acceptance of artificial intelligence in the service industry intelligent ai devices have become a common presence in the business landscape offering a wide range of services from the medical sector to the hospitality industry from an organizational perspective ai devices have several advantages by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more costefficient however in order to maintain the high standards of a brand they have to be accepted by consumers and deliver socially adequate performance therefore it is important to determine the characteristics of ai devices which make them accepted and trusted by consumers based on the computers as social actors casa theory we have researched on the role of psychological anthropomorphic characteristics perceived empathy and interaction quality in the acceptance of ai devices in the service industry the results show that anthropomorphic characteristics alone do not influence acceptance and trust towards ai devices however both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance a humanlike ai device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer this result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and ai devices
DJ5SHI8H;journalArticle;2022;"Blanco, Guillermo; Lourenço, Anália";Optimism and pessimism analysis using deep learning on COVID-19 related twitter conversations;Information Processing & Management;NA;0306-4573;https://doi.org/10.1016/j.ipm.2022.102918;https://www.sciencedirect.com/science/article/pii/S0306457322000437;This paper proposes a new deep learning approach to better understand how optimistic and pessimistic feelings are conveyed in Twitter conversations about COVID-19. A pre-trained transformer embedding is used to extract the semantic features and several network architectures are compared. Model performance is evaluated on two new, publicly available Twitter corpora of crisis-related posts. The best performing pessimism and optimism detection models are based on bidirectional long- and short-term memory networks. Experimental results on four periods of the COVID-19 pandemic show how the proposed approach can model optimism and pessimism in the context of a health crisis. There is a total of 150,503 tweets and 51,319 unique users. Conversations are characterised in terms of emotional signals and shifts to unravel empathy and support mechanisms. Conversations with stronger pessimistic signals denoted little emotional shift (i.e. 62.21% of these conversations experienced almost no change in emotion). In turn, only 10.42% of the conversations laying more on the optimistic side maintained the mood. User emotional volatility is further linked with social influence.;2022;2022-07-15T09:02:33Z;2022-07-15T09:02:33Z;NA;102918;NA;3;59;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Conversation; Covid-19 pandemic; Emotion classification; Emotion shift; Sociome";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;optimismandpessimismanalysisusingdeeplearningoncovid19relatedtwitterconversations;optimism and pessimism analysis using deep learning on covid19 related twitter conversations this paper proposes a new deep learning approach to better understand how optimistic and pessimistic feelings are conveyed in twitter conversations about covid19 a pretrained transformer embedding is used to extract the semantic features and several network architectures are compared model performance is evaluated on two new publicly available twitter corpora of crisisrelated posts the best performing pessimism and optimism detection models are based on bidirectional long and shortterm memory networks experimental results on four periods of the covid19 pandemic show how the proposed approach can model optimism and pessimism in the context of a health crisis there is a total of 150503 tweets and 51319 unique users conversations are characterised in terms of emotional signals and shifts to unravel empathy and support mechanisms conversations with stronger pessimistic signals denoted little emotional shift ie 6221 of these conversations experienced almost no change in emotion in turn only 1042 of the conversations laying more on the optimistic side maintained the mood user emotional volatility is further linked with social influence
DPIR67JA;journalArticle;2021;"Bisogni, Carmen; Cascone, Lucia; Castiglione, Aniello; Passero, Ignazio";Deep learning for emotion driven user experiences;Pattern Recognition Letters;NA;0167-8655;https://doi.org/10.1016/j.patrec.2021.09.004;https://www.sciencedirect.com/science/article/pii/S0167865521003159;Deep knowledge about user characteristics and behaviors opens new and promising landscapes to the User Experience. Thanks to emerging machine learning techniques, a new form of communication channel among users and applications may be exploited for customizing and finely tuning the dynamic behavior of applications to the peculiarities of their users. This work investigates the empathic improvement of the User Experiences and exploits inferences on user expressions for activating gaming and entertainment events, that are adopted in a cinematic way to create dynamic application behaviors. The presented approach is applied to a third/first-person horror adventure and a classic table game. As already verified in a preliminary phase of the research, user impressions, collected as subjective evaluation in a controlled experiment, are positive and encourage further steps, like the evaluation of other inferences on users.;2021;2022-07-15T09:02:33Z;2022-07-15T09:02:33Z;NA;115-121;NA;NA;152;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Computer vision; Deep learning; User emotions; User experience";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;deeplearningforemotiondrivenuserexperiences;deep learning for emotion driven user experiences deep knowledge about user characteristics and behaviors opens new and promising landscapes to the user experience thanks to emerging machine learning techniques a new form of communication channel among users and applications may be exploited for customizing and finely tuning the dynamic behavior of applications to the peculiarities of their users this work investigates the empathic improvement of the user experiences and exploits inferences on user expressions for activating gaming and entertainment events that are adopted in a cinematic way to create dynamic application behaviors the presented approach is applied to a thirdfirstperson horror adventure and a classic table game as already verified in a preliminary phase of the research user impressions collected as subjective evaluation in a controlled experiment are positive and encourage further steps like the evaluation of other inferences on users
NDXIP4ZK;journalArticle;2022;"Higgins, Darragh; Zibrek, Katja; Cabral, Joao; Egan, Donal; McDonnell, Rachel";Sympathy for the digital: Influence of synthetic voice on affinity, social presence and empathy for photorealistic virtual humans;Computers & Graphics;NA;0097-8493;https://doi.org/10.1016/j.cag.2022.03.009;https://www.sciencedirect.com/science/article/pii/S0097849322000474;In this paper, we investigate the effect of a realism mismatch in the voice and appearance of a photorealistic virtual character in both immersive and screen-mediated virtual contexts. While many studies have investigated voice attributes for robots, not much is known about the effect voice naturalness has on the perception of realistic virtual characters. We conducted the first experiment in Virtual Reality (VR) with over two hundred participants investigating the mismatch between realistic appearance and unrealistic voice on the feeling of presence, and the emotional response of the user to the character expressing a strong negative emotion. We predicted that the mismatched voice would lower social presence and cause users to have a negative emotional reaction and feelings of discomfort towards the character. We found that the concern for the virtual character was indeed altered by the unnatural voice, though interestingly it did not affect social presence. The second experiment was conducted with a view towards heightening the appearance realism of the same character for the same scenarios, with an additional lower level of voice realism employed to strengthen the mismatch of perceptual cues. While voice type did not appear to impact reports of empathic responses towards the character, there was an observed effect of voice realism on reported social presence, which was not detected in the first study. There were also significant results on affinity and voice trait measurements that provide evidence in support of perceptual mismatch theories of the Uncanny Valley.;2022;2022-07-15T09:02:33Z;2022-07-15T09:02:33Z;NA;116-128;NA;NA;104;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Perception; Synthetic voice; Virtual humans; Virtual reality";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;sympathyforthedigitalinfluenceofsyntheticvoiceonaffinitysocialpresenceandempathyforphotorealisticvirtualhumans;sympathy for the digital influence of synthetic voice on affinity social presence and empathy for photorealistic virtual humans in this paper we investigate the effect of a realism mismatch in the voice and appearance of a photorealistic virtual character in both immersive and screenmediated virtual contexts while many studies have investigated voice attributes for robots not much is known about the effect voice naturalness has on the perception of realistic virtual characters we conducted the first experiment in virtual reality vr with over two hundred participants investigating the mismatch between realistic appearance and unrealistic voice on the feeling of presence and the emotional response of the user to the character expressing a strong negative emotion we predicted that the mismatched voice would lower social presence and cause users to have a negative emotional reaction and feelings of discomfort towards the character we found that the concern for the virtual character was indeed altered by the unnatural voice though interestingly it did not affect social presence the second experiment was conducted with a view towards heightening the appearance realism of the same character for the same scenarios with an additional lower level of voice realism employed to strengthen the mismatch of perceptual cues while voice type did not appear to impact reports of empathic responses towards the character there was an observed effect of voice realism on reported social presence which was not detected in the first study there were also significant results on affinity and voice trait measurements that provide evidence in support of perceptual mismatch theories of the uncanny valley
AFEMQI26;journalArticle;2022;"Xie, Lishan; Liu, Canmian; Li, Dongmei";Proactivity or passivity? An investigation of the effect of service robots’ proactive behaviour on customer co-creation intention;International Journal of Hospitality Management;NA;0278-4319;https://doi.org/10.1016/j.ijhm.2022.103271;https://www.sciencedirect.com/science/article/pii/S0278431922001335;The implementation of robots in tourism services is transforming how companies interact with their customers and create value. Although corporate initiatives are beginning to focus on proactive robot services, little is known about the impact of this behavioural characteristic of service robots on customer value co-creation. Through two experiments and one field survey, this research demonstrates that customers’ co-creation intention is higher when a robot’s service proactivity is high (vs. low), and that this relationship is mediated by perceived robotic empathy. Furthermore, customer task orientation negatively moderates the mediating effect of empathy perception that underlies the relationship between service proactivity and customers’ co-creation intention. These findings provide new insights into the effect of service robots’ behavioural characteristics on customer–robot interactions.;2022;2022-07-15T09:02:34Z;2022-07-15T09:02:34Z;NA;103271;NA;NA;106;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Perceived robotic empathy; Service proactivity; Service robot; Task orientation; Value co-creation intention";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;proactivityorpassivityaninvestigationoftheeffectofservicerobotsproactivebehaviouroncustomercocreationintention;proactivity or passivity an investigation of the effect of service robots proactive behaviour on customer cocreation intention the implementation of robots in tourism services is transforming how companies interact with their customers and create value although corporate initiatives are beginning to focus on proactive robot services little is known about the impact of this behavioural characteristic of service robots on customer value cocreation through two experiments and one field survey this research demonstrates that customers cocreation intention is higher when a robots service proactivity is high vs low and that this relationship is mediated by perceived robotic empathy furthermore customer task orientation negatively moderates the mediating effect of empathy perception that underlies the relationship between service proactivity and customers cocreation intention these findings provide new insights into the effect of service robots behavioural characteristics on customerrobot interactions
88DSNL3Q;journalArticle;2021;"Chang, Yung-Chun; Hsing, Yan-Chun";Emotion-infused deep neural network for emotionally resonant conversation;Applied Soft Computing;NA;1568-4946;https://doi.org/10.1016/j.asoc.2021.107861;https://www.sciencedirect.com/science/article/pii/S1568494621007833;The widespread development of conversational agents (chatbots) has enabled us to communicate and collaborate with different forms and functions of robots using natural language, thus facilitating a closer relationship between humans and technology. Given that chatbot services infused with domain knowledge are of great interest to not only global businesses but also academics, chatbots have in recent years become a popular research topic in the field of natural language processing. We therefore aim at improving current chatbots with the addition of natural emotions. In contrast to previous work, we intend to distinguish fine-grained emotion differences between words in order to better understand emotion expressions in sentences. Our approach infuses fine-grained emotion content into the response generation process to make the dialog more emotionally resonant. The experimental results demonstrate that this method can classify emotions more effectively. In addition, the proposed hybrid model, which consists of recurrent and convolutional neural networks with additional emotion-specific valence-arousal features, can correctly identify five emotions with a 67.89% overall F1-score. We further evaluate the subjective quality of the responses and discover that the infusion of fine-grained emotion information substantially improves the quality and fluency of automatically generated empathetic conversation. We conclude that the proposed model can greatly improve the efficiency and usability of a conversational chatbot system.;2021;2022-07-15T09:03:12Z;2022-07-15T09:03:12Z;NA;107861;NA;NA;113;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Chinese emotional conversation; Dialog emotion recognition; Dialog system; Emotional dimensions; Natural language processing; Sentiment analysis";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;emotioninfuseddeepneuralnetworkforemotionallyresonantconversation;emotioninfused deep neural network for emotionally resonant conversation the widespread development of conversational agents chatbots has enabled us to communicate and collaborate with different forms and functions of robots using natural language thus facilitating a closer relationship between humans and technology given that chatbot services infused with domain knowledge are of great interest to not only global businesses but also academics chatbots have in recent years become a popular research topic in the field of natural language processing we therefore aim at improving current chatbots with the addition of natural emotions in contrast to previous work we intend to distinguish finegrained emotion differences between words in order to better understand emotion expressions in sentences our approach infuses finegrained emotion content into the response generation process to make the dialog more emotionally resonant the experimental results demonstrate that this method can classify emotions more effectively in addition the proposed hybrid model which consists of recurrent and convolutional neural networks with additional emotionspecific valencearousal features can correctly identify five emotions with a 6789 overall f1score we further evaluate the subjective quality of the responses and discover that the infusion of finegrained emotion information substantially improves the quality and fluency of automatically generated empathetic conversation we conclude that the proposed model can greatly improve the efficiency and usability of a conversational chatbot system
QJ4MM4RI;journalArticle;2022;Devaram, Rami Reddy, Beraldo, Gloria, De Benedictis, Riccardo, Mongiovï¿½ï¿½, Misael, Cesta, Amedeo,;LEMON: A Lightweight Facial Emotion Recognition System for Assistive Robotics Based on Dilated Residual Convolutional Neural Networks.;Sensors (Basel) Sensors (Basel, Switzerland);NA;1424-8220;NA;NA;"The development of a Social Intelligence System based on artificial intelligence is one of the cutting edge technologies in Assistive Robotics. Such systems need to create an empathic interaction with the users; therefore, it os required to include an Emotion Recognition (ER) framework which has to run, in near real-time, together with several other intelligent services. Most of the low-cost commercial robots, however, although more accessible by users and healthcare facilities, have to balance costs and effectiveness, resulting in under-performing hardware in terms of memory and processing unit. This aspect makes the design of the systems challenging, requiring a trade-off between the accuracy and the complexity of the adopted models. This paper proposes a compact and robust service for Assistive Robotics, called Lightweight EMotion recognitiON (LEMON), which uses image processing, Computer Vision and Deep Learning (DL) algorithms to recognize facial expressions. Specifically, the proposed DL model is based on Residual Convolutional Neural Networks with the combination of Dilated and Standard Convolution Layers. The first remarkable result is the few numbers (i.e., 1.6 Million) of parameters characterizing our model. In addition, Dilated Convolutions expand receptive fields exponentially with preserving resolution, less computation and memory cost to recognize the distinction among facial expressions by capturing the displacement of the pixels. Finally, to reduce the dying ReLU problem and improve the stability of the model, we apply an Exponential Linear Unit (ELU) activation function in the initial layers of the model. We have performed training and evaluation (via one- and five-fold cross validation) of the model with five datasets available in the community and one mixed dataset created by taking samples from all of them. With respect to the other approaches, our model achieves comparable results with a significant reduction in terms of the number of parameters.";2022;2022-07-15T09:48:06Z;2022-07-15T09:48:06Z;NA;NA;NA;9;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;lemonalightweightfacialemotionrecognitionsystemforassistiveroboticsbasedondilatedresidualconvolutionalneuralnetworks;lemon a lightweight facial emotion recognition system for assistive robotics based on dilated residual convolutional neural networks the development of a social intelligence system based on artificial intelligence is one of the cutting edge technologies in assistive robotics such systems need to create an empathic interaction with the users therefore it os required to include an emotion recognition er framework which has to run in near realtime together with several other intelligent services most of the lowcost commercial robots however although more accessible by users and healthcare facilities have to balance costs and effectiveness resulting in underperforming hardware in terms of memory and processing unit this aspect makes the design of the systems challenging requiring a tradeoff between the accuracy and the complexity of the adopted models this paper proposes a compact and robust service for assistive robotics called lightweight emotion recognition lemon which uses image processing computer vision and deep learning dl algorithms to recognize facial expressions specifically the proposed dl model is based on residual convolutional neural networks with the combination of dilated and standard convolution layers the first remarkable result is the few numbers ie 16 million of parameters characterizing our model in addition dilated convolutions expand receptive fields exponentially with preserving resolution less computation and memory cost to recognize the distinction among facial expressions by capturing the displacement of the pixels finally to reduce the dying relu problem and improve the stability of the model we apply an exponential linear unit elu activation function in the initial layers of the model we have performed training and evaluation via one and fivefold cross validation of the model with five datasets available in the community and one mixed dataset created by taking samples from all of them with respect to the other approaches our model achieves comparable results with a significant reduction in terms of the number of parameters
VLZQUAZH;journalArticle;2021;Malinowska, Joanna K.,;Can I Feel Your Pain? The Biological and Socio-Cognitive Factors Shaping Peoples Empathy with Social Robots;Int J of Soc Robotics International Journal of Social Robotics;NA;1875-4791;NA;NA;Abstract: This paper discuss the phenomenon of empathy in social robotics and is divided into three main parts. Initially, I analyse whether it is correct to use this concept to study and describe peoples reactions to robots. I present arguments in favour of the position that people actually do empathise with robots. I also consider what circumstances shape human empathy with these entities. I propose that two basic classes of such factors be distinguished: biological and socio-cognitive. In my opinion, one of the most important among them is a sense of group membership with robots, as it modulates the empathic responses to representatives of our- and other- groups. The sense of group membership with robots may be co-shaped by socio-cognitive factors such as ones experience, familiarity with the robot and its history, motivation, accepted ontology, stereotypes or language. Finally, I argue in favour of the formulation of a pragmatic and normative framework for manipulations in the level of empathy in humanrobot interactions.;2021;2022-07-15T09:48:06Z;2022-07-15T09:48:06Z;NA;341-355;NA;2;14;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;canifeelyourpainthebiologicalandsociocognitivefactorsshapingpeoplesempathywithsocialrobots;can i feel your pain the biological and sociocognitive factors shaping peoples empathy with social robots abstract this paper discuss the phenomenon of empathy in social robotics and is divided into three main parts initially i analyse whether it is correct to use this concept to study and describe peoples reactions to robots i present arguments in favour of the position that people actually do empathise with robots i also consider what circumstances shape human empathy with these entities i propose that two basic classes of such factors be distinguished biological and sociocognitive in my opinion one of the most important among them is a sense of group membership with robots as it modulates the empathic responses to representatives of our and other groups the sense of group membership with robots may be coshaped by sociocognitive factors such as ones experience familiarity with the robot and its history motivation accepted ontology stereotypes or language finally i argue in favour of the formulation of a pragmatic and normative framework for manipulations in the level of empathy in humanrobot interactions
QN9A8L2E;journalArticle;2021;Lï¿½ï¿½bbert, Annika, Gï¿½ï¿½schl, Florian, Krause, Hanna, Schneider, Till R, Maye, Alexander, Engel, Andreas K,;Socializing Sensorimotor Contingencies.;Front Hum Neurosci Frontiers in human neuroscience;NA;1662-5161;NA;NA;The aim of this review is to highlight the idea of grounding social cognition in sensorimotor interactions shared across agents. We discuss an action-oriented account that emerges from a broader interpretation of the concept of sensorimotor contingencies. We suggest that dynamic informational and sensorimotor coupling across agents can mediate the deployment of action-effect contingencies in social contexts. We propose this concept of socializing sensorimotor contingencies (socSMCs) as a shared framework of analysis for processes within and across brains and bodies, and their physical and social environments. In doing so, we integrate insights from different fields, including neuroscience, psychology, and research on human-robot interaction. We review studies on dynamic embodied interaction and highlight empirical findings that suggest an important role of sensorimotor and informational entrainment in social contexts. Furthermore, we discuss links to closely related concepts, such as enactivism, models of coordination dynamics and others, and clarify differences to approaches that focus on mentalizing and high-level cognitive representations. Moreover, we consider conceptual implications of rethinking cognition as social sensorimotor coupling. The insight that social cognitive phenomena like joint attention, mutual trust or empathy rely heavily on the informational and sensorimotor coupling between agents may provide novel remedies for people with disturbed social cognition and for situations of disturbed social interaction. Furthermore, our proposal has potential applications in the field of human-robot interaction where socSMCs principles might lead to more natural and intuitive interfaces for human users.;2021;2022-07-15T09:48:06Z;2022-07-15T09:48:06Z;NA;624610;NA;NA;15;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;socializingsensorimotorcontingencies;socializing sensorimotor contingencies the aim of this review is to highlight the idea of grounding social cognition in sensorimotor interactions shared across agents we discuss an actionoriented account that emerges from a broader interpretation of the concept of sensorimotor contingencies we suggest that dynamic informational and sensorimotor coupling across agents can mediate the deployment of actioneffect contingencies in social contexts we propose this concept of socializing sensorimotor contingencies socsmcs as a shared framework of analysis for processes within and across brains and bodies and their physical and social environments in doing so we integrate insights from different fields including neuroscience psychology and research on humanrobot interaction we review studies on dynamic embodied interaction and highlight empirical findings that suggest an important role of sensorimotor and informational entrainment in social contexts furthermore we discuss links to closely related concepts such as enactivism models of coordination dynamics and others and clarify differences to approaches that focus on mentalizing and highlevel cognitive representations moreover we consider conceptual implications of rethinking cognition as social sensorimotor coupling the insight that social cognitive phenomena like joint attention mutual trust or empathy rely heavily on the informational and sensorimotor coupling between agents may provide novel remedies for people with disturbed social cognition and for situations of disturbed social interaction furthermore our proposal has potential applications in the field of humanrobot interaction where socsmcs principles might lead to more natural and intuitive interfaces for human users
JMDP9N5J;journalArticle;2021;Gemeinboeck, Petra, Saunders, Rob,;Moving beyond the mirror: relational and performative meaning making in humanrobot communication;AI & Soc AI & SOCIETY : Journal of Knowledge, Culture and Communication;NA;0951-5666;NA;NA;Abstract: Current research in humanrobot interaction often focuses on rendering communication between humans and robots more natural by designing machinesï¿½ï¿½that appear and behave humanlike. Communication, in this human-centric approach, is often understood as a process of successfully transmitting information in the form of predefined messages and gestures. This article introduces an alternative arts-led, movement-centric approach, which embraces the differences of machinelike robotic artefacts and, instead, investigates how meaning is dynamically enacted in the encounter of humans and machines.ï¿½ï¿½Our design approach revolves around a novel embodied mapping methodology, which serves to bridge between humanmachine asymmetries and socioculturally situate abstract robotic artefacts.ï¿½ï¿½Building on concepts from performativity, material agency, enactive sense-making and kinaesthetic empathy, our Machine Movement Lab project opens up a performative-relational model of humanmachine communication, where meaning is generated through relational dynamics in the interaction itself.;2021;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;549-563;NA;2;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;movingbeyondthemirrorrelationalandperformativemeaningmakinginhumanrobotcommunication;moving beyond the mirror relational and performative meaning making in humanrobot communication abstract current research in humanrobot interaction often focuses on rendering communication between humans and robots more natural by designing machinesïïthat appear and behave humanlike communication in this humancentric approach is often understood as a process of successfully transmitting information in the form of predefined messages and gestures this article introduces an alternative artsled movementcentric approach which embraces the differences of machinelike robotic artefacts and instead investigates how meaning is dynamically enacted in the encounter of humans and machinesïïour design approach revolves around a novel embodied mapping methodology which serves to bridge between humanmachine asymmetries and socioculturally situate abstract robotic artefactsïïbuilding on concepts from performativity material agency enactive sensemaking and kinaesthetic empathy our machine movement lab project opens up a performativerelational model of humanmachine communication where meaning is generated through relational dynamics in the interaction itself
Q8XY5SII;journalArticle;2022;Osaka, Kyoko, Matsumoto, Kazuyuki, Akiyama, Toshiya, Tanioka, Ryuichi, Betriana, Feni, Zhao, Yueren, Kai, Yoshihiro, Miyagawa, Misao, Tanioka, Tetsuya, Locsin, Rozzano C,;Investigation of Methods to Create Future Multimodal Emotional Data for Robot Interactions in Patients with Schizophrenia: A Case Study.;Healthcare (Basel) Healthcare (Basel, Switzerland);NA;2227-9032;NA;NA;Rapid progress in humanoid robot investigations offers possibilities for improving the competencies of people with social disorders, although this improvement of humanoid robots remains unexplored for schizophrenic people. Methods for creating future multimodal emotional data for robot interactions were studied in this case study of a 40-year-old male patient with disorganized schizophrenia without comorbidities. The qualitative data included heart rate variability (HRV), video-audio recordings, and field notes. HRV, Haar cascade classifier (HCC), and Empath APIï¿½ï¿½ were evaluated during conversations between the patient and robot. Two expert nurses and one psychiatrist evaluated facial expressions. The research hypothesis questioned whether HRV, HCC, and Empath APIï¿½ï¿½ are useful for creating future multimodal emotional data about robot-patient interactions. The HRV analysis showed persistent sympathetic dominance, matching the human-robot conversational situation. The result of HCC was in agreement with that of human observation, in the case of rough consensus. In the case of observed results disagreed upon by experts, the HCC result was also different. However, emotional assessments by experts using Empath APIï¿½ï¿½ were also found to be inconsistent. We believe that with further investigation, a clearer identification of methods for multimodal emotional data for robot interactions can be achieved for patients with schizophrenia.;2022;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;NA;NA;5;10;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;investigationofmethodstocreatefuturemultimodalemotionaldataforrobotinteractionsinpatientswithschizophreniaacasestudy;investigation of methods to create future multimodal emotional data for robot interactions in patients with schizophrenia a case study rapid progress in humanoid robot investigations offers possibilities for improving the competencies of people with social disorders although this improvement of humanoid robots remains unexplored for schizophrenic people methods for creating future multimodal emotional data for robot interactions were studied in this case study of a 40yearold male patient with disorganized schizophrenia without comorbidities the qualitative data included heart rate variability hrv videoaudio recordings and field notes hrv haar cascade classifier hcc and empath apiïï were evaluated during conversations between the patient and robot two expert nurses and one psychiatrist evaluated facial expressions the research hypothesis questioned whether hrv hcc and empath apiïï are useful for creating future multimodal emotional data about robotpatient interactions the hrv analysis showed persistent sympathetic dominance matching the humanrobot conversational situation the result of hcc was in agreement with that of human observation in the case of rough consensus in the case of observed results disagreed upon by experts the hcc result was also different however emotional assessments by experts using empath apiïï were also found to be inconsistent we believe that with further investigation a clearer identification of methods for multimodal emotional data for robot interactions can be achieved for patients with schizophrenia
KZEUFMMB;journalArticle;2021;NA;Evaluation of an algorithm for optical pulse detection in children for application to the Pepper robot;NA;NA;2364-5504;NA;NA;To engage in socio-emotional interactions, children with autism spectrum conditions (ASC) need support to understand and convey emotions. In our approach, a humanoid robot (Pepper, Softbanks Robotics) acts as a tutor for the child within autism care. The robot, equipped with multimodal sensor technology to acquire the emotional feedback of the child, stimulates the child to perform tasks, adapted to its current arousal state. By in-, or decreasing the difficulties of implemented training modules, the child can be given the appropriate task according to its emotional state. The childs arousal is measured with different techniques implemented in and on the robot: emotion detection based on audio recordings of the speech signal and camera detected facial expressions, or heart rate. To this end, the remote Photoplethysmography (rPPG) signal from camera recordings of the subjects face is acquired. While its unintrusive measurement is an advantage, a major drawback for rPPG is its proneness to motion and light artefacts requiring de-noising steps. A wavelet transform based on log-Gabor wavelets and a filter bank with 32 filters was implemented. The signal was filtered with a prior filter and afterwards with a Markov chain in order to extract the underlying pulse rate. Within an initial study, five children were observed watching videos with different co-notated emotions. As reference for the heart rate (HR), a wristband (empatica E4) was used. The captured emotions of all subjects were annotated to identify low and high arousal parts and positive and negative emotions. Extracted HR from rPPG-data indicated a correlation with the annotated emotions.;2021;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;484-487;NA;2;7;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;evaluationofanalgorithmforopticalpulsedetectioninchildrenforapplicationtothepepperrobot;evaluation of an algorithm for optical pulse detection in children for application to the pepper robot to engage in socioemotional interactions children with autism spectrum conditions asc need support to understand and convey emotions in our approach a humanoid robot pepper softbanks robotics acts as a tutor for the child within autism care the robot equipped with multimodal sensor technology to acquire the emotional feedback of the child stimulates the child to perform tasks adapted to its current arousal state by in or decreasing the difficulties of implemented training modules the child can be given the appropriate task according to its emotional state the childs arousal is measured with different techniques implemented in and on the robot emotion detection based on audio recordings of the speech signal and camera detected facial expressions or heart rate to this end the remote photoplethysmography rppg signal from camera recordings of the subjects face is acquired while its unintrusive measurement is an advantage a major drawback for rppg is its proneness to motion and light artefacts requiring denoising steps a wavelet transform based on loggabor wavelets and a filter bank with 32 filters was implemented the signal was filtered with a prior filter and afterwards with a markov chain in order to extract the underlying pulse rate within an initial study five children were observed watching videos with different conotated emotions as reference for the heart rate hr a wristband empatica e4 was used the captured emotions of all subjects were annotated to identify low and high arousal parts and positive and negative emotions extracted hr from rppgdata indicated a correlation with the annotated emotions
NMXX2QKJ;journalArticle;2022;Fu, Changzeng, Deng, Qi, Shen, Jingcheng, Mahzoon, Hamed, Ishiguro, Hiroshi,;A Preliminary Study on Realizing Human-Robot Mental Comforting Dialogue via Sharing Experience Emotionally.;Sensors (Basel) Sensors (Basel, Switzerland);NA;1424-8220;NA;NA;Mental health issues are receiving more and more attention in society. In this paper, we introduce a preliminary study on human-robot mental comforting conversation, to make an android robot (ERICA) present an understanding of the user's situation by sharing similar emotional experiences to enhance the perception of empathy. Specifically, we create the emotional speech for ERICA by using CycleGAN-based emotional voice conversion model, in which the pitch and spectrogram of the speech are converted according to the user's mental state. Then, we design dialogue scenarios for the user to talk about his/her predicament with ERICA. In the dialogue, ERICA shares other people's similar predicaments and adopts a low-spirit voice to express empathy to the interlocutor's situation. At the end of the dialogue, ERICA tries to encourage with a positive voice. Subsequently, questionnaire-based evaluation experiments were conducted with the recorded conversation. In the questionnaire, we use the Big Five scale to evaluate ERICA's personality. In addition, the perception of emotion, empathy, and encouragement in the dialogue are evaluated. The results show that the proposed emotional expression strategy helps the android robot better present low-spirit emotion, empathy, the personality of extroversion, while making the user better feel the encouragement.;2022;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;NA;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;apreliminarystudyonrealizinghumanrobotmentalcomfortingdialogueviasharingexperienceemotionally;a preliminary study on realizing humanrobot mental comforting dialogue via sharing experience emotionally mental health issues are receiving more and more attention in society in this paper we introduce a preliminary study on humanrobot mental comforting conversation to make an android robot erica present an understanding of the users situation by sharing similar emotional experiences to enhance the perception of empathy specifically we create the emotional speech for erica by using cycleganbased emotional voice conversion model in which the pitch and spectrogram of the speech are converted according to the users mental state then we design dialogue scenarios for the user to talk about hisher predicament with erica in the dialogue erica shares other peoples similar predicaments and adopts a lowspirit voice to express empathy to the interlocutors situation at the end of the dialogue erica tries to encourage with a positive voice subsequently questionnairebased evaluation experiments were conducted with the recorded conversation in the questionnaire we use the big five scale to evaluate ericas personality in addition the perception of emotion empathy and encouragement in the dialogue are evaluated the results show that the proposed emotional expression strategy helps the android robot better present lowspirit emotion empathy the personality of extroversion while making the user better feel the encouragement
64ZH3B86;journalArticle;2021;Langedijk, Rosalyn M., Ham, Jaap,;More than advice The influence of adding references to prior discourse and signals of empathy on the persuasiveness of an advice-giving robot;Interaction Studies;NA;1572-0373;NA;NA;Persuasive social robots can influence human behavior through giving advice. The current study investigates whether references to prior discourse and signals of empathy make an advice-giving robot an even more effective persuader and whether participants follow the robot's advice and drink even more water when the robot additionally uses these strategies. We recruited students and university staff for a lab-study in which three different robot personalities on the same robot type presented health-related information. In one condition, the robot gave advice and referred to something mentioned earlier in the conversation (i.e., to dialog history), in another condition, the robot gave advice and used empathic signals, and in the third condition, the robot gave advice only. Our results show that participants drank significantly more when the advice-giving robot also used the persuasive strategies of empathy and references to dialog history than when the robot only gave advice. This study shows that both strategies increase the persuasiveness of the robot and makes it more influential.;2021;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;396-415;NA;3;22;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;morethanadvicetheinfluenceofaddingreferencestopriordiscourseandsignalsofempathyonthepersuasivenessofanadvicegivingrobot;more than advice the influence of adding references to prior discourse and signals of empathy on the persuasiveness of an advicegiving robot persuasive social robots can influence human behavior through giving advice the current study investigates whether references to prior discourse and signals of empathy make an advicegiving robot an even more effective persuader and whether participants follow the robots advice and drink even more water when the robot additionally uses these strategies we recruited students and university staff for a labstudy in which three different robot personalities on the same robot type presented healthrelated information in one condition the robot gave advice and referred to something mentioned earlier in the conversation ie to dialog history in another condition the robot gave advice and used empathic signals and in the third condition the robot gave advice only our results show that participants drank significantly more when the advicegiving robot also used the persuasive strategies of empathy and references to dialog history than when the robot only gave advice this study shows that both strategies increase the persuasiveness of the robot and makes it more influential
VA6MECH7;journalArticle;2022;Noguchi, Yohei, Kamide, Hiroko, Tanaka, Fumihide,;Weight Shift Movements of a Social Mediator Robot Make It Being Recognized as Serious and Suppress Anger, Revenge and Avoidance Motivation of the User.;Front Robot AI Frontiers in robotics and AI;NA;2296-9144;NA;NA;Humans can become aggressive during text messaging. To maintain a healthy interpersonal relationship through text messaging, our negative mental states, such as anger, have to be well-controlled. This paper discusses the use of a handheld social robot deployed as a mediator in text messaging between humans. The robot is equipped with a movable weight inside its body. By controlling the movement of the internal weight during the time when the robot speaks out messages received from a human sender, we hypothesize that the psychological state of a receiver who holds the robot can be affected (for example, he/she will listen to the messages more seriously). In a controlled study (n = 94), in which participants were manipulated to be frustrated by using a context scenario, we studied the effect of three dialogue scripts with/without weight shifts. Results showed that introducing weight shifts together with the robot speech suppressed on average 23% of the user's anger. However, only 3.5% of the anger was suppressed when the weight shifts were not applied. Additionally, in cases where the robot showed empathy to the user in words with weight shifts, the user's revenge urge was successfully reduced by 22%. There was almost no effect confirmed when the weight shifts were not applied. A similar effect was also found in avoidance motivation: 15% of the avoidance motivation was reduced if weight shifts were applied. The reductions in revenge and avoidance motivation are considered important factors for human forgiveness. Therefore, our findings provide experimental evidence that weight shifts can be an effective expression modality for mediator robots, from the perspective of not only suppressing the user's anger but also by inducing forgiveness during messaging.;2022;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;790209;NA;NA;9;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;weightshiftmovementsofasocialmediatorrobotmakeitbeingrecognizedasseriousandsuppressangerrevengeandavoidancemotivationoftheuser;weight shift movements of a social mediator robot make it being recognized as serious and suppress anger revenge and avoidance motivation of the user humans can become aggressive during text messaging to maintain a healthy interpersonal relationship through text messaging our negative mental states such as anger have to be wellcontrolled this paper discusses the use of a handheld social robot deployed as a mediator in text messaging between humans the robot is equipped with a movable weight inside its body by controlling the movement of the internal weight during the time when the robot speaks out messages received from a human sender we hypothesize that the psychological state of a receiver who holds the robot can be affected for example heshe will listen to the messages more seriously in a controlled study n  94 in which participants were manipulated to be frustrated by using a context scenario we studied the effect of three dialogue scripts withwithout weight shifts results showed that introducing weight shifts together with the robot speech suppressed on average 23 of the users anger however only 35 of the anger was suppressed when the weight shifts were not applied additionally in cases where the robot showed empathy to the user in words with weight shifts the users revenge urge was successfully reduced by 22 there was almost no effect confirmed when the weight shifts were not applied a similar effect was also found in avoidance motivation 15 of the avoidance motivation was reduced if weight shifts were applied the reductions in revenge and avoidance motivation are considered important factors for human forgiveness therefore our findings provide experimental evidence that weight shifts can be an effective expression modality for mediator robots from the perspective of not only suppressing the users anger but also by inducing forgiveness during messaging
YZ8JRFL2;journalArticle;2021;Kharub, Isha, Lwin, Michael, Khan, Aila, Mubin, Omar,;Perceived Service Quality in HRI: Applying the SERVBOT Framework.;Front Robot AI Frontiers in robotics and AI;NA;2296-9144;NA;NA;Services are intangible in nature and as a result, it is often difficult to measure the quality of the service. In the service literature, the service is usually delivered by a human to a human customer and the quality of the service is often evaluated using the SERVQUAL dimensions. An extensive review of the literature shows there is a lack of an empirical model to assess the perceived service quality provided by a social robot. Furthermore, the social robot literature highlights key differences between human service and social robots. For example, scholars have highlighted the importance of entertainment value and engagement in the adoption of social robots in the service industry. However, it is unclear whether the SERVQUAL dimensions are appropriate to measure social robot's service quality. The paper proposes the SERVBOT model to assess a social robot's service quality. It identifies, reliability, responsiveness, assurance, empathy, and entertainment as the five dimensions of SERVBOT. Further, the research will investigate how these five factors influence emotional engagement and future intentions to use the social robot in a concierge service setting. The model was tested using student sampling, and a total of 94 responses were collected for the study. The findings indicate empathy and entertainment value as key predictors of emotional engagement. Further, emotional engagement is a strong predictor of future intention to use a social robot in a service setting. This study is the first to propose the SERVBOT model to measure social robot's service quality. The model provides a theoretical underpinning on the key service quality dimensions of a social robot and gives scholars and managers a method to track the service quality of a social robot. The study also extends on the literature by exploring the key factors that influence the use of social robots (i.e., emotional engagement).;2021;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;746674;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;perceivedservicequalityinhriapplyingtheservbotframework;perceived service quality in hri applying the servbot framework services are intangible in nature and as a result it is often difficult to measure the quality of the service in the service literature the service is usually delivered by a human to a human customer and the quality of the service is often evaluated using the servqual dimensions an extensive review of the literature shows there is a lack of an empirical model to assess the perceived service quality provided by a social robot furthermore the social robot literature highlights key differences between human service and social robots for example scholars have highlighted the importance of entertainment value and engagement in the adoption of social robots in the service industry however it is unclear whether the servqual dimensions are appropriate to measure social robots service quality the paper proposes the servbot model to assess a social robots service quality it identifies reliability responsiveness assurance empathy and entertainment as the five dimensions of servbot further the research will investigate how these five factors influence emotional engagement and future intentions to use the social robot in a concierge service setting the model was tested using student sampling and a total of 94 responses were collected for the study the findings indicate empathy and entertainment value as key predictors of emotional engagement further emotional engagement is a strong predictor of future intention to use a social robot in a service setting this study is the first to propose the servbot model to measure social robots service quality the model provides a theoretical underpinning on the key service quality dimensions of a social robot and gives scholars and managers a method to track the service quality of a social robot the study also extends on the literature by exploring the key factors that influence the use of social robots ie emotional engagement
5CTXQUDN;journalArticle;2022;Wan, Guobin, Deng, Fuhao, Jiang, Zijian, Song, Sifan, Hu, Di, Chen, Lifu, Wang, Haibo, Li, Miaochun, Chen, Gong, Yan, Ting, Su, Jionglong, Zhang, Jiaming,;FECTS: A Facial Emotion Cognition and Training System for Chinese Children with Autism Spectrum Disorder.;Comput Intell Neurosci Computational intelligence and neuroscience;NA;NA;NA;NA;Traditional training methods such as card teaching, assistive technologies (e.g., augmented reality/virtual reality games and smartphone apps), DVDs, human-computer interactions, and human-robot interactions are widely applied in autistic rehabilitation training in recent years. In this article, we propose a novel framework for human-computer/robot interaction and introduce a preliminary intervention study for improving the emotion recognition of Chinese children with an autism spectrum disorder. The core of the framework is the Facial Emotion Cognition and Training System (FECTS, including six tasks to train children with ASD to match, infer, and imitate the facial expressions of happiness, sadness, fear, and anger) based on Simon Baron-Cohen's E-S (empathizing-systemizing) theory. Our system may be implemented on PCs, smartphones, mobile devices such as PADs, and robots. The training record (e.g., a tracked record of emotion imitation) of the Chinese autistic children interacting with the device implemented using our FECTS will be uploaded and stored in the database of a cloud-based evaluation system. Therapists and parents can access the analysis of the emotion learning progress of these autistic children using the cloud-based evaluation system. Deep-learning algorithms of facial expressions recognition and attention analysis will be deployed in the back end (e.g., devices such as a PC, a robotic system, or a cloud system) implementing our FECTS, which can perform real-time tracking of the imitation quality and attention of the autistic children during the expression imitation phase. In this preliminary clinical study, a total of 10 Chinese autistic children aged 3-8 are recruited, and each of them received a single 20-minute training session every day for four consecutive days. Our preliminary results validated the feasibility of the developed FECTS and the effectiveness of our algorithms based on Chinese children with an autism spectrum disorder. To verify that our FECTS can be further adapted to children from other countries, children with different cultural/sociological/linguistic contexts should be recruited in future studies.;2022;2022-07-15T09:48:07Z;2022-07-15T09:48:07Z;NA;9213526;NA;NA;2022;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;fectsafacialemotioncognitionandtrainingsystemforchinesechildrenwithautismspectrumdisorder;fects a facial emotion cognition and training system for chinese children with autism spectrum disorder traditional training methods such as card teaching assistive technologies eg augmented realityvirtual reality games and smartphone apps dvds humancomputer interactions and humanrobot interactions are widely applied in autistic rehabilitation training in recent years in this article we propose a novel framework for humancomputerrobot interaction and introduce a preliminary intervention study for improving the emotion recognition of chinese children with an autism spectrum disorder the core of the framework is the facial emotion cognition and training system fects including six tasks to train children with asd to match infer and imitate the facial expressions of happiness sadness fear and anger based on simon baroncohens es empathizingsystemizing theory our system may be implemented on pcs smartphones mobile devices such as pads and robots the training record eg a tracked record of emotion imitation of the chinese autistic children interacting with the device implemented using our fects will be uploaded and stored in the database of a cloudbased evaluation system therapists and parents can access the analysis of the emotion learning progress of these autistic children using the cloudbased evaluation system deeplearning algorithms of facial expressions recognition and attention analysis will be deployed in the back end eg devices such as a pc a robotic system or a cloud system implementing our fects which can perform realtime tracking of the imitation quality and attention of the autistic children during the expression imitation phase in this preliminary clinical study a total of 10 chinese autistic children aged 38 are recruited and each of them received a single 20minute training session every day for four consecutive days our preliminary results validated the feasibility of the developed fects and the effectiveness of our algorithms based on chinese children with an autism spectrum disorder to verify that our fects can be further adapted to children from other countries children with different culturalsociologicallinguistic contexts should be recruited in future studies
8TPE85V8;journalArticle;2021;Shiomi, Masahiro, Zheng, Xiqian, Minato, Takashi, Ishiguro, Hiroshi,;Implementation and Evaluation of a Grip Behavior Model to Express Emotions for an Android Robot.;Front Robot AI Frontiers in robotics and AI;NA;2296-9144;NA;NA;In this study, we implemented a model with which a robot expressed such complex emotions as heartwarming (e.g., happy and sad) or horror (fear and surprise) by its touches and experimentally investigated the effectiveness of the modeled touch behaviors. Robots that can express emotions through touching behaviors increase their interaction capabilities with humans. Although past studies achieved ways to express emotions through a robot's touch, such studies focused on expressing such basic emotions as happiness and sadness and downplayed these complex emotions. Such studies only proposed a model that expresses these emotions by touch behaviors without evaluations. Therefore, we conducted the experiment to evaluate the model with participants. In the experiment, they evaluated the perceived emotions and empathies from a robot's touch while they watched a video stimulus with the robot. Our results showed that the touch timing before the climax received higher evaluations than touch timing after for both the scary and heartwarming videos.;2021;2022-07-15T09:48:08Z;2022-07-15T09:48:08Z;NA;755150;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;implementationandevaluationofagripbehaviormodeltoexpressemotionsforanandroidrobot;implementation and evaluation of a grip behavior model to express emotions for an android robot in this study we implemented a model with which a robot expressed such complex emotions as heartwarming eg happy and sad or horror fear and surprise by its touches and experimentally investigated the effectiveness of the modeled touch behaviors robots that can express emotions through touching behaviors increase their interaction capabilities with humans although past studies achieved ways to express emotions through a robots touch such studies focused on expressing such basic emotions as happiness and sadness and downplayed these complex emotions such studies only proposed a model that expresses these emotions by touch behaviors without evaluations therefore we conducted the experiment to evaluate the model with participants in the experiment they evaluated the perceived emotions and empathies from a robots touch while they watched a video stimulus with the robot our results showed that the touch timing before the climax received higher evaluations than touch timing after for both the scary and heartwarming videos
K57S6FVD;journalArticle;2021;de Jong, Dorina, Hortensius, Ruud, Hsieh, Te-Yi, Cross, Emily S,;Empathy and Schadenfreude in Human-Robot Teams.;J Cogn Journal of cognition;NA;2514-4820;NA;NA;"Intergroup dynamics shape the ways in which we interact with other people. We feel more empathy towards ingroup members compared to outgroup members, and can even feel pleasure when an outgroup member experiences misfortune, known as schadenfreude. Here, we test the extent to which these intergroup biases emerge during interactions with robots. We measured trial-by-trial fluctuations in emotional reactivity to the outcome of a competitive reaction time game to assess both empathy and schadenfreude in arbitrary human-human and human-robot teams. Across four experiments (total n = 361), we observed a consistent empathy and schadenfreude bias driven by team membership. People felt more empathy towards ingroup members than outgroup members and more schadenfreude towards outgroup members. The existence of an intergroup bias did not depend on the nature of the agent: the same effects were observed for human-human and human-robot teams. People reported similar levels of empathy and schadenfreude towards a human and robot player. The human likeness of the robot did not consistently influence this intergroup bias. In other words, similar empathy and schadenfreude biases were observed for both humanoid and mechanoid robots. For all teams, this bias was influenced by the level of team identification; individuals who identified more with their team showed stronger intergroup empathy and schadenfreude bias. Together, we show that similar intergroup dynamics that shape our interactions with people can also shape interactions with robots. Our results highlight the importance of taking intergroup biases into account when examining social dynamics of human-robot interactions.";2021;2022-07-15T09:48:08Z;2022-07-15T09:48:08Z;NA;35;NA;1;4;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathyandschadenfreudeinhumanrobotteams;empathy and schadenfreude in humanrobot teams intergroup dynamics shape the ways in which we interact with other people we feel more empathy towards ingroup members compared to outgroup members and can even feel pleasure when an outgroup member experiences misfortune known as schadenfreude here we test the extent to which these intergroup biases emerge during interactions with robots we measured trialbytrial fluctuations in emotional reactivity to the outcome of a competitive reaction time game to assess both empathy and schadenfreude in arbitrary humanhuman and humanrobot teams across four experiments total n  361 we observed a consistent empathy and schadenfreude bias driven by team membership people felt more empathy towards ingroup members than outgroup members and more schadenfreude towards outgroup members the existence of an intergroup bias did not depend on the nature of the agent the same effects were observed for humanhuman and humanrobot teams people reported similar levels of empathy and schadenfreude towards a human and robot player the human likeness of the robot did not consistently influence this intergroup bias in other words similar empathy and schadenfreude biases were observed for both humanoid and mechanoid robots for all teams this bias was influenced by the level of team identification individuals who identified more with their team showed stronger intergroup empathy and schadenfreude bias together we show that similar intergroup dynamics that shape our interactions with people can also shape interactions with robots our results highlight the importance of taking intergroup biases into account when examining social dynamics of humanrobot interactions
PVCLI67R;journalArticle;2021;Roesler, E, Manzey, D, Onnasch, L,;A meta-analysis on the effectiveness of anthropomorphism in human-robot interaction.;Sci Robot Science robotics;NA;2470-9476;NA;NA;The application of anthropomorphic design features is widely assumed to facilitate human-robot interaction (HRI). However, a considerable number of study results point in the opposite direction. There is currently no comprehensive common ground on the circumstances under which anthropomorphism promotes interaction with robots. Our meta-analysis aims to close this gap. A total of 4856 abstracts were scanned. After an extensive evaluation, 78 studies involving around 6000 participants and 187 effect sizes were included in this meta-analysis. The majority of the studies addressed effects on perceptual aspects of robots. In addition, effects on attitudinal, affective, and behavioral aspects were also investigated. Overall, a medium positive effect size was found, indicating a beneficial effect of anthropomorphic design features on human-related outcomes. However, closer scrutiny of the lowest variable level revealed no positive effect for perceived safety, empathy, and task performance. Moreover, the analysis suggests that positive effects of anthropomorphism depend heavily on various moderators. For example, anthropomorphism was in contrast to other fields of application, constantly facilitating social HRI. The results of this analysis provide insights into how design features can be used to improve the quality of HRI. Moreover, they reveal areas in which more research is needed before any clear conclusions about the effects of anthropomorphic robot design can be drawn.;2021;2022-07-15T09:48:08Z;2022-07-15T09:48:08Z;NA;eabj5425;NA;58;6;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;ametaanalysisontheeffectivenessofanthropomorphisminhumanrobotinteraction;a metaanalysis on the effectiveness of anthropomorphism in humanrobot interaction the application of anthropomorphic design features is widely assumed to facilitate humanrobot interaction hri however a considerable number of study results point in the opposite direction there is currently no comprehensive common ground on the circumstances under which anthropomorphism promotes interaction with robots our metaanalysis aims to close this gap a total of 4856 abstracts were scanned after an extensive evaluation 78 studies involving around 6000 participants and 187 effect sizes were included in this metaanalysis the majority of the studies addressed effects on perceptual aspects of robots in addition effects on attitudinal affective and behavioral aspects were also investigated overall a medium positive effect size was found indicating a beneficial effect of anthropomorphic design features on humanrelated outcomes however closer scrutiny of the lowest variable level revealed no positive effect for perceived safety empathy and task performance moreover the analysis suggests that positive effects of anthropomorphism depend heavily on various moderators for example anthropomorphism was in contrast to other fields of application constantly facilitating social hri the results of this analysis provide insights into how design features can be used to improve the quality of hri moreover they reveal areas in which more research is needed before any clear conclusions about the effects of anthropomorphic robot design can be drawn
AJRHLDIB;journalArticle;2022;NA;Human-robot interaction: the impact of robotic aesthetics on anticipated human trust;NA;NA;2376-5992;NA;NA;Background Human senses have evolved to recognise sensory cues. Beyond our perception, they play an integral role in our emotional processing, learning, and interpretation. They are what help us to sculpt our everyday experiences and can be triggered by aesthetics to form the foundations of our interactions with each other and our surroundings. In terms of Human-Robot Interaction (HRI), robots have the possibility to interact with both people and environments given their senses. They can offer the attributes of human characteristics, which in turn can make the interchange with technology a more appealing and admissible experience. However, for many reasons, people still do not seem to trust and accept robots. Trust is expressed as a persons ability to accept the potential risks associated with participating alongside an entity such as a robot. Whilst trust is an important factor in building relationships with robots, the presence of uncertainties can add an additional dimension to the decision to trust a robot. In order to begin to understand how to build trust with robots and reverse the negative ideology, this paper examines the influences of aesthetic design techniques on the human ability to trust robots. Method This paper explores the potential that robots have unique opportunities to improve their facilities for empathy, emotion, and social awareness beyond their more cognitive functionalities. Through conducting an online questionnaire distributed globally, we explored participants ability and acceptance in trusting the Canbot U03 robot. Participants were presented with a range of visual questions which manipulated the robots facial screen and asked whether or not they would trust the robot. A selection of questions aimed at putting participants in situations where they were required to establish whether or not to trust a robots responses based solely on the visual appearance. We accomplished this by manipulating different design elements of the robots facial and chest screens, which influenced the human-robot interaction. Results We found that certain facial aesthetics seem to be more trustworthy than others, such as a cartoon face versus a human face, and that certain visual variables (i.e., blur) afforded uncertainty more than others. Consequentially, this paper reports that participants uncertainties of the visualisations greatly influenced their willingness to accept and trust the robot. The results of introducing certain anthropomorphic characteristics emphasised the participants embrace of the uncanny valley theory, where pushing the degree of human likeness introduced a thin line between participants accepting robots and not. By understanding what manipulation of design elements created the aesthetic effect that triggered the affective processes, this paper further enriches our knowledge of how we might design for certain emotions, feelings, and ultimately more socially acceptable and trusting robotic experiences.;2022;2022-07-15T09:48:08Z;2022-07-15T09:48:08Z;NA;e837;NA;NA;8;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;humanrobotinteractiontheimpactofroboticaestheticsonanticipatedhumantrust;humanrobot interaction the impact of robotic aesthetics on anticipated human trust background human senses have evolved to recognise sensory cues beyond our perception they play an integral role in our emotional processing learning and interpretation they are what help us to sculpt our everyday experiences and can be triggered by aesthetics to form the foundations of our interactions with each other and our surroundings in terms of humanrobot interaction hri robots have the possibility to interact with both people and environments given their senses they can offer the attributes of human characteristics which in turn can make the interchange with technology a more appealing and admissible experience however for many reasons people still do not seem to trust and accept robots trust is expressed as a persons ability to accept the potential risks associated with participating alongside an entity such as a robot whilst trust is an important factor in building relationships with robots the presence of uncertainties can add an additional dimension to the decision to trust a robot in order to begin to understand how to build trust with robots and reverse the negative ideology this paper examines the influences of aesthetic design techniques on the human ability to trust robots method this paper explores the potential that robots have unique opportunities to improve their facilities for empathy emotion and social awareness beyond their more cognitive functionalities through conducting an online questionnaire distributed globally we explored participants ability and acceptance in trusting the canbot u03 robot participants were presented with a range of visual questions which manipulated the robots facial screen and asked whether or not they would trust the robot a selection of questions aimed at putting participants in situations where they were required to establish whether or not to trust a robots responses based solely on the visual appearance we accomplished this by manipulating different design elements of the robots facial and chest screens which influenced the humanrobot interaction results we found that certain facial aesthetics seem to be more trustworthy than others such as a cartoon face versus a human face and that certain visual variables ie blur afforded uncertainty more than others consequentially this paper reports that participants uncertainties of the visualisations greatly influenced their willingness to accept and trust the robot the results of introducing certain anthropomorphic characteristics emphasised the participants embrace of the uncanny valley theory where pushing the degree of human likeness introduced a thin line between participants accepting robots and not by understanding what manipulation of design elements created the aesthetic effect that triggered the affective processes this paper further enriches our knowledge of how we might design for certain emotions feelings and ultimately more socially acceptable and trusting robotic experiences
Y9S7UUCQ;journalArticle;2021;Li, Shufei, Wang, Ruobing, Zheng, Pai, Wang, Lihui,;Towards proactive human-robot collaboration: A foreseeable cognitive manufacturing paradigm;JMSY Journal of Manufacturing Systems;NA;0278-6125;NA;NA;"Human-robot collaboration (HRC) has attracted strong interests from researchers and engineers for improved operational flexibility and efficiency towards mass personalization. Nevertheless, existing HRC development mainly undertakes either human-centered or robot-centered manner reactively, where operations are conducted by following the pre-defined instructions, thus far from an efficient integration of robotic automation and human cognitions. The prevailing research on human-level information processing of cognitive computing, the industrial IoT, and robot learning creates the possibility of bridging the gap of knowledge distilling and information sharing between onsite operators, robots and other manufacturing systems. Hence, a foreseeable informatics-based cognitive manufacturing paradigm, Proactive HRC, is introduced as an advanced form of Symbiotic HRC with high-level cognitive teamwork skills to be achieved stepwise, including: (1) <ce:italic>inter-collaboration cognition</ce:italic>, establishing bi-directional empathy in the execution loop based on a holistic understanding of humans and robots situations; (2) <ce:italic>spatio-temporal cooperation prediction</ce:italic>, estimating human-robot-object interaction of hierarchical sub-tasks/activities over time for the proactive planning; and (3) <ce:italic>self-organizing teamwork</ce:italic>, converging knowledge of distributed HRC systems for self-organization learning and task allocation. Except for the description of their technical cores, the main challenges and potential opportunities are further discussed to enable the readiness towards Proactive HRC.";2021;2022-07-15T09:48:08Z;2022-07-15T09:48:08Z;NA;547-552;NA;NA;60;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;/z-wcorg/;NA;http://worldcat.org;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;towardsproactivehumanrobotcollaborationaforeseeablecognitivemanufacturingparadigm;towards proactive humanrobot collaboration a foreseeable cognitive manufacturing paradigm humanrobot collaboration hrc has attracted strong interests from researchers and engineers for improved operational flexibility and efficiency towards mass personalization nevertheless existing hrc development mainly undertakes either humancentered or robotcentered manner reactively where operations are conducted by following the predefined instructions thus far from an efficient integration of robotic automation and human cognitions the prevailing research on humanlevel information processing of cognitive computing the industrial iot and robot learning creates the possibility of bridging the gap of knowledge distilling and information sharing between onsite operators robots and other manufacturing systems hence a foreseeable informaticsbased cognitive manufacturing paradigm proactive hrc is introduced as an advanced form of symbiotic hrc with highlevel cognitive teamwork skills to be achieved stepwise including 1 ceitalicintercollaboration cognitionceitalic establishing bidirectional empathy in the execution loop based on a holistic understanding of humans and robots situations 2 ceitalicspatiotemporal cooperation predictionceitalic estimating humanrobotobject interaction of hierarchical subtasksactivities over time for the proactive planning and 3 ceitalicselforganizing teamworkceitalic converging knowledge of distributed hrc systems for selforganization learning and task allocation except for the description of their technical cores the main challenges and potential opportunities are further discussed to enable the readiness towards proactive hrc
UKXV7M69;journalArticle;2022;Balle, Simon N.;Empathic responses and moral status for social robots: an argument in favor of robot patienthood based on K. E. Logstrup;AI & SOCIETY;NA;0951-5666;10.1007/s00146-021-01211-2;NA;"Empirical research on human-robot interaction (HRI) has demonstrated how humans tend to react to social robots with empathic responses and moral behavior. How should we ethically evaluate such responses to robots? Are people wrong to treat non-sentient artefacts as moral patients since this rests on anthropomorphism and `over-identification' (Bryson and Kime, Proc Twenty-Second Int Jt Conf Artif Intell Barc Catalonia Spain 16-22:1641-1646, 2011)-or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood, such that social robots become our `Others' (Gunkel, Robot rights, MIT Press, London, 2018; Coeckelbergh, Kairos J Philos Sci 20:141-158, 2018)?. In this research paper, I weave extant HRI studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots, on which the ethical evaluation of moral behavior toward them is dependent. Patienthood for robots has standardly been thought to obtain on some intrinsic ground, such as being sentient, conscious, or having interest. But since these attempts neglect moral experience and are curbed by epistemic difficulties, I take inspiration from Coeckelbergh and Gunkel's `relational approach' to explore an alternative way of accounting for robot patienthood based on extrinsic premises. Based on the ethics of Danish theologian K. E. Logstrup (1905-1981) I argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjects-even if they emerge from social interaction afforded by robots we have anthropomorphized. I ultimately develop an argument in defense of treating robots as moral patients.";2022-06;2022-07-15T14:59:24Z;2022-07-15T14:59:24Z;NA;535-548;NA;2;37;NA;NA;NA;NA;NA;NA;NA;NA;NA;English;NA;NA;NA;NA;NA;NA;Place: ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES Publisher: SPRINGER Type: Article;NA;NA;NA;"Empathy; Ethics; K. E. Logstrup; Moral status; Patienthood; Social robots";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;empathicresponsesandmoralstatusforsocialrobotsanargumentinfavorofrobotpatienthoodbasedonkelogstrup;empathic responses and moral status for social robots an argument in favor of robot patienthood based on k e logstrup empirical research on humanrobot interaction hri has demonstrated how humans tend to react to social robots with empathic responses and moral behavior how should we ethically evaluate such responses to robots are people wrong to treat nonsentient artefacts as moral patients since this rests on anthropomorphism and overidentification bryson and kime proc twentysecond int jt conf artif intell barc catalonia spain 162216411646 2011or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood such that social robots become our others gunkel robot rights mit press london 2018 coeckelbergh kairos j philos sci 20141158 2018 in this research paper i weave extant hri studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots on which the ethical evaluation of moral behavior toward them is dependent patienthood for robots has standardly been thought to obtain on some intrinsic ground such as being sentient conscious or having interest but since these attempts neglect moral experience and are curbed by epistemic difficulties i take inspiration from coeckelbergh and gunkels relational approach to explore an alternative way of accounting for robot patienthood based on extrinsic premises based on the ethics of danish theologian k e logstrup 19051981 i argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjectseven if they emerge from social interaction afforded by robots we have anthropomorphized i ultimately develop an argument in defense of treating robots as moral patients
RCA229Z2;conferencePaper;2022;"Gray, Carly E.; Chesser, Amber; Atchley, Andrew; Smitherman, R. Cooper; Tenhundfeld, Nathan L.";Humanlikeness and Aesthetic Customization's Effect on Trust, Performance, and Affect;2022 Systems and Information Engineering Design Symposium (SIEDS);NA;NA;10.1109/SIEDS55548.2022.9799376;NA;Human-machine interactions have become a staple of people's daily lives through the use of mobile devices, robotics, and a myriad of smart technologies. Previous research has established that anthropomorphism can significantly affect subjective perceptions of, and interactions with, machines. Furthermore, the ability to customize digital tools has been shown to affect user preferences, video game enjoyment, and the efficacy of digital mental health interventions. This study examined whether the customization of a machine teammate could influence the performance of the human-machine team and generate an affective response on the part of the human teammate. To evaluate this premise, we developed a bomb-defusing task simulation using the Unity game engine wherein participants were randomly assigned to one of two (humanlike or machinelike) robot avatars or were given the ability to customize one. The customizable robot avatar allows the participant to select either a humanlike or machinelike robot and customize the color of the wheels and casing. The customization is aesthetic in nature and has no effect on the functionality of the robot. The game design incorporates a high-risk environment and uncertainty with respect to the bomb-defusing distance and required button presses to encourage cautious guidance of the robot. We predicted that the ability to customize the robot will increase performance and subjective measures of trust, affect, attachment, identification, immersion, and control. We also predicted that the humanlikeness of the robot would increase performance and our subjective measures. Finally, we expected to see a significant effect of customization and humanlikeness such that the customization and humanlikeness have an additive effect on performance and our subjective measures. The results of all analyses were nonsignificant. These results may help inform the design of such systems and address fears that customization could lead to over-empathizing with a machine teammate in a way that would reduce use in high-risk environments.;2022-04;2022-07-15T15:05:55Z;2022-07-15T15:05:55Z;NA;403-408;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"affect; Avatars; customisation; Games; humanlikeness; Mobile robots; Power measurement; Presses; trust; Uncertainty; Wheels";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;humanlikenessandaestheticcustomizationseffectontrustperformanceandaffect;humanlikeness and aesthetic customizations effect on trust performance and affect humanmachine interactions have become a staple of peoples daily lives through the use of mobile devices robotics and a myriad of smart technologies previous research has established that anthropomorphism can significantly affect subjective perceptions of and interactions with machines furthermore the ability to customize digital tools has been shown to affect user preferences video game enjoyment and the efficacy of digital mental health interventions this study examined whether the customization of a machine teammate could influence the performance of the humanmachine team and generate an affective response on the part of the human teammate to evaluate this premise we developed a bombdefusing task simulation using the unity game engine wherein participants were randomly assigned to one of two humanlike or machinelike robot avatars or were given the ability to customize one the customizable robot avatar allows the participant to select either a humanlike or machinelike robot and customize the color of the wheels and casing the customization is aesthetic in nature and has no effect on the functionality of the robot the game design incorporates a highrisk environment and uncertainty with respect to the bombdefusing distance and required button presses to encourage cautious guidance of the robot we predicted that the ability to customize the robot will increase performance and subjective measures of trust affect attachment identification immersion and control we also predicted that the humanlikeness of the robot would increase performance and our subjective measures finally we expected to see a significant effect of customization and humanlikeness such that the customization and humanlikeness have an additive effect on performance and our subjective measures the results of all analyses were nonsignificant these results may help inform the design of such systems and address fears that customization could lead to overempathizing with a machine teammate in a way that would reduce use in highrisk environments
UTK9QL9R;conferencePaper;2022;"Eren, Eda; Navruz, Tuğba Selcen";Stress Detection with Deep Learning Using BVP and EDA Signals;2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA);NA;NA;10.1109/HORA55278.2022.9799933;NA;In daily life, a person is exposed to many negative factors and emotional states as arising from financial difficulties, working life and personal responsibilities. The aim of this study is to detect stress resulted from these factors in a way that causes the least discomfort to the person. It is quite common to use physiological data such as heart rate, electromyography (EMG), electrocardiography (ECG), electroencephalography (EEG), respiration and skin conductivity to detect when a person is exposed to stress. In this study, stress estimation was made using blood volume pulse (BVP) and electrodermal activity (EDA) sensor data obtained from the Empatica E4 device in the open source WESAD dataset. With the use of BVP and EDA sensors, the intervention to the person has been tried to be minimized. Thus, the model ans sensor method proposed in this study can be easily adapted to daily life. For stress detection, a feed forward deep learning artificial neural network (ANN) technique is proposed by using the baseline and stress labeled data in the dataset. With ANN model, %96.26 accuracy was obtained and a fairly smooth loss curve was observed. This model was compared with the ANN methods in previous studies.;2022-06;2022-07-15T15:05:56Z;2022-07-15T15:05:56Z;NA;1-7;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;"Adaptation models; Anxiety disorders; artificial neural network; Artificial neural networks; Brain modeling; BVP; Deep learning; EDA; Electrocardiography; physiological signal; Robot sensing systems; Stress detection; WESAD";NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;NA;stressdetectionwithdeeplearningusingbvpandedasignals;stress detection with deep learning using bvp and eda signals in daily life a person is exposed to many negative factors and emotional states as arising from financial difficulties working life and personal responsibilities the aim of this study is to detect stress resulted from these factors in a way that causes the least discomfort to the person it is quite common to use physiological data such as heart rate electromyography emg electrocardiography ecg electroencephalography eeg respiration and skin conductivity to detect when a person is exposed to stress in this study stress estimation was made using blood volume pulse bvp and electrodermal activity eda sensor data obtained from the empatica e4 device in the open source wesad dataset with the use of bvp and eda sensors the intervention to the person has been tried to be minimized thus the model ans sensor method proposed in this study can be easily adapted to daily life for stress detection a feed forward deep learning artificial neural network ann technique is proposed by using the baseline and stress labeled data in the dataset with ann model 9626 accuracy was obtained and a fairly smooth loss curve was observed this model was compared with the ann methods in previous studies

"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"VLBEFRAM","conferencePaper","2019","Roth, Daniel; Bloch, Carola; Schmitt, Josephine; Frischlich, Lena; Latoschik, Marc Erich; Bente, Gary","Perceived Authenticity, Empathy, and Pro-Social Intentions Evoked through Avatar-Mediated Self-Disclosures","Proceedings of Mensch Und Computer 2019","978-1-4503-7198-8","","10.1145/3340764.3340797","https://doi.org/10.1145/3340764.3340797","Avatars are our digital embodied alter egos. Virtual embodiment by avatars allows social interaction with others using the full spectrum of verbal and non-verbal behaviour. Still, one's avatar appearances is elective. Hence, avatars make it possible for users to discuss and exchange sensible or even problematic personal topics potentially hiding their real identity and hence preserving anonymity and privacy. While previous works identified similarities how participants perceive avatars compared to human stimuli, there is a question as to whether avatar-mediated self-disclosure is authentic and results in similar social responses. In the present study, we created a comparable stimulus set to investigate this issue and conducted an online study (N=172) for comparison. Our results indicate that avatars can be perceived as authentic and that empathy is attributed in similar level than to a human stimulus. In an exploratory model, we found that for in the overall results, authenticity fostered emotional empathy which in turn fostered pro-social intentions. We argue that avatars may serve as a valuable supporting medium for HCI applications related to mental well-being, self-disclosure, and support.","2019","2021-04-19 16:09:39","2021-04-19 16:09:39","","21–30","","","","","","","MuC'19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hamburg, Germany","","","","Avatars; Empathy; Social Perception; Virtual Characters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2EKRXPE4","conferencePaper","2017","Murphy, Dooley","Building a Hybrid Virtual Agent for Testing User Empathy and Arousal in Response to Avatar (Micro-)Expressions","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3141217","https://doi.org/10.1145/3139131.3141217","This poster paper describes a hybrid (i.e., film and CG) method for capturing and implementing facial expressions for/in VR. A video camera was used to capture an actor's performance. The actor's eyes and mouth were isolated, and footage was processed as movie textures to overlay a static 3D model of a head. Micro-expressions (subtle, rapid movements of muscles in and around the eyes and mouth in particular) are thus captured in a fine-grained, yet low- cost and low-tech alternative to established techniques. A future experiment will compare the emotive efficacy of the hybrid virtual agent with that of a conventional (fully CG) rigged avatar head in a 6DoF scenario that transitions from sympathetic (gauging empathy by self-report) to confrontational (gauging physiological arousal by heart-rate or GSR). The experiment's prospective design is discussed, as well as its significance for the study of the crucial intersection of social plausibility and perceptual realism in VR.","2017","2021-04-19 16:09:39","2021-04-19 16:09:39","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","avatar capture; social plausibility; social presence; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K3KXUZ3D","conferencePaper","2015","Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.","Poor Thing! Would You Feel Sorry for a Simulated Robot? A Comparison of Empathy toward a Physical and a Simulated Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696471","https://doi.org/10.1145/2696454.2696471","In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.","2015","2021-04-19 16:09:39","2021-04-19 16:09:39","","125–132","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","empathy; human-robot interaction; robot embodiment; simulated interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYV2DXRJ","conferencePaper","2019","Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji","The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot","Proceedings of the 7th International Conference on Human-Agent Interaction","978-1-4503-6922-0","","10.1145/3349537.3351891","https://doi.org/10.1145/3349537.3351891","We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","51–58","","","","","","","HAI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Kyoto, Japan","","","","animism; empathy; human-robot interaction; robots' perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CEAA5G44","conferencePaper","2019","Franzoni, Valentina; Milani, Alfredo; Biondi, Giulio; Micheli, Francesco","A Preliminary Work on Dog Emotion Recognition","IEEE/WIC/ACM International Conference on Web Intelligence - Companion Volume","978-1-4503-6988-6","","10.1145/3358695.3361750","https://doi.org/10.1145/3358695.3361750","Humans react to animal emotions, and animals react to human emotions because we share similar emotional and neurological mirroring systems. Mirror neurons fire both when an animal performs an action and when the animal observes the same action performed by another individual. This neurological system has been linked to social behaviors and abilities, from empathy to learning by imitation, both in intra-species and in inter-species communications.The aim of this paper is to study if a machine learning system can recognize animal emotions, starting from dogs’ basic emotions of joy and anger, and to investigate the opportunity of future applications concerning systems of prosthetic knowledge to help people without the proper experience or capability to understand animals aggressivity or friendliness, or for supportive systems in Artificial Intelligence.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","91–96","","","","","","","WI '19 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Thessaloniki, Greece","","","","Affective Computing; Artificial Intelligence; Emotion Recognition; Neural Networks; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPPFB5N7","conferencePaper","2015","Zuckerman, Oren; Hoffman, Guy","Empathy Objects: Robotic Devices as Conversation Companions","Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction","978-1-4503-3305-4","","10.1145/2677199.2688805","https://doi.org/10.1145/2677199.2688805","We present the notion of Empathy Objects, ambient robotic devices accompanying human-human interaction. Empathy Objects respond to human behavior using physical gestures as nonverbal expressions of their ""emotional states"". The goal is to increase people's self-awareness to the emotional state of others, leading to behavior change. We demonstrate an Empathy Object prototype, Kip1, a conversation companion designed to promote non-aggressive conversation between people.","2015","2021-04-19 16:09:40","2021-04-19 16:09:40","","593–598","","","","","","","TEI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Stanford, California, USA","","","","ambient devices; behavior change; companion devices; social robots; tangible interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKRXIKZX","book","2020","","HAI '20: Proceedings of the 8th International Conference on Human-Agent Interaction","","978-1-4503-8054-6","","","","It is our great pleasure to welcome you to the Eighth International Conference on Human-Agent Interaction HAI 2020 (Virtual Conference); hosted by the Western Sydney University (Australia) and supported by Chalmers University of Technology (Sweden).The conference is a venue with an interdisciplinary nature to discuss and disseminate state-ofthe- art research on topics related to human interactions with a range of agent systems, including physical robots and humanoids, virtual agents, socially interactive agents, and Artificially Intelligent (AI) agents. The topical areas of the conference include user studies, frameworks, simulations, technical developments and more within Human Agent and Robotic Interaction. The conference brings together a large variety of multidisciplinary research groups, companies, and researchers looking into the broader area of agents and robotics across Australia, Japan and the rest of the world.The theme for HAI 2020 is ""Artificial Intelligence + Experience Design."" The recent advent of AI has motivated researchers to focus on several algorithmic prospects in developing intelligent robotic agents and their interactions. Progressively, AI advances are leading to exciting outcomes in the HAI field and, at the same time, are opening up for a wide perspective on how to design intelligent robotic agents. For example, how to combine artificial intelligence and user experience design approaches in human-agent interaction. We are looking forward to sharing the latest research results of HAI that contribute a broad range of disciplines.Three keynote talks are featured. The first is titled ""We're in This Together: Social Robots in Group, Organizational, and Community Interactions"", by Associate Prof. Selma Šabanović, Indiana University Bloomington, USA. The second is titled ""What kind of human-centric robotics do we need? Investigations from human-robot interactions in socially assistive scenarios"", by Prof. Ginevra Castellano, Uppsala University, Sweden. The third is an industry talk titled ""The rapid rise in drone technology"", by Sebastian Robertson, CEO of BIRDI, Australia. Their keynote talks will provide cross-disciplinary examples of novel HAI research and applications that are highly inspiring for the HAI audience and research community.This year's submissions have come from more than 25 countries and cover leading-edge topics including human and machine learning, conversational agents, empathy and trust of social robots, social drones, social presence, robot applications, virtual agent applications and novel perspectives of HAI. With an acceptance rate of 38% (25 papers out of 65 submissions), the program committee has again set a high quality standard. In addition, 26 out of the 35 latebreaking poster papers submissions were accepted.","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","","","","","","","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S2JN5GLN","journalArticle","2017","Paiva, Ana; Leite, Iolanda; Boukricha, Hana; Wachsmuth, Ipke","Empathy in Virtual Agents and Robots: A Survey","ACM Trans. Interact. Intell. Syst.","","2160-6455","10.1145/2912150","https://doi.org/10.1145/2912150","This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.","2017-09","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","3","7","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","affective computing; empathy; human-computer interaction; human-robot interaction; social robots; virtual agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F56E2ALU","conferencePaper","2020","Toxtli, Carlos; Richmond-Fuller, Angela; Savage, Saiph","Reputation Agent: Prompting Fair Reviews in Gig Markets","Proceedings of The Web Conference 2020","978-1-4503-7023-3","","10.1145/3366423.3380199","https://doi.org/10.1145/3366423.3380199","Our study presents a new tool, Reputation Agent, to promote fairer reviews from requesters (employers or customers) on gig markets. Unfair reviews, created when requesters consider factors outside of a worker’s control, are known to plague gig workers and can result in lost job opportunities and even termination from the marketplace. Our tool leverages machine learning to implement an intelligent interface that: (1) uses deep learning to automatically detect when an individual has included unfair factors into her review (factors outside the worker’s control per the policies of the market); and (2) prompts the individual to reconsider her review if she has incorporated unfair factors. To study the effectiveness of Reputation Agent, we conducted a controlled experiment over different gig markets. Our experiment illustrates that across markets, Reputation Agent, in contrast with traditional approaches, motivates requesters to review gig workers’ performance more fairly. We discuss how tools that bring more transparency to employers about the policies of a gig market can help build empathy thus resulting in reasoned discussions around potential injustices towards workers generated by these interfaces. Our vision is that with tools that promote truth and transparency we can bring fairer treatment to gig workers.","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","1228–1240","","","","","","","WWW '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Taipei, Taiwan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHWMJG7N","conferencePaper","2016","Liu, Xin; London, Kati","T.A.I: A Tangible AI Interface to Enhance Human-Artificial Intelligence (AI) Communication Beyond the Screen","Proceedings of the 2016 ACM Conference on Designing Interactive Systems","978-1-4503-4031-1","","10.1145/2901790.2901896","https://doi.org/10.1145/2901790.2901896","Social and emotional intelligence of computer systems is increasingly important in human-AI (Artificial Intelligence) interactions. This paper presents a tangible AI interface, T.A.I, that enhances physical engagement in digital communication between users and a conversational AI agent. We describe a compact, pneumatically shape-changing hardware design with a rich set of physical gestures that actuate on mobile devices during real-time conversations. Our user study suggests that the physical presence provided by T.A.I increased users' empathy for, and social connection with the virtual intelligent system, leading to an improved Human-AI communication experience.","2016","2021-04-19 16:09:40","2021-04-19 16:09:40","","281–285","","","","","","","DIS '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Brisbane, QLD, Australia","","","","affective communication; shape-changing interface; social agent; tangible interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WYKGZTLU","conferencePaper","2017","Thompson, Jeff","I Touch You and You Touch Me","SIGGRAPH Asia 2017 Art Gallery","978-1-4503-5401-1","","10.1145/3143748.3143753","https://doi.org/10.1145/3143748.3143753","A robotic arm plays back hallucinated gestures from a machine learning system trained on my interactions with my phone, exploring issues of human/machine empathy and agency.","2017","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","","","","","","SA '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Bangkok, Thailand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8RH953N","conferencePaper","2019","Shvo, Maayan","Towards Empathetic Planning and Plan Recognition","Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","978-1-4503-6324-2","","10.1145/3306618.3314307","https://doi.org/10.1145/3306618.3314307","Every compassionate and functioning society requires its members to have a capacity to adopt others' perspectives. As Artificial Intelligence (AI) systems are given increasingly sensitive and impactful roles in society, it is important to enable AI to wield empathy as a tool to benefit those it interacts with. In this paper, we work towards this goal by bringing together a number of important concepts: empathy, AI planning, and plan recognition (i.e., the problem of inferring an actor's plan and goal given observations about its behavior). We formalize the notions of Empathetic Planning and Empathetic Plan Recognition which are informed by the beliefs and affective state of the actor, and propose AI planning-based computational approaches. We illustrate the benefits of our approach by conducting a study with human participants.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","525–526","","","","","","","AIES '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Honolulu, HI, USA","","","","AI planning; plan recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQDGLYA8","conferencePaper","2019","Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana","EmotoTent: Reducing School Violence through Embodied Empathy Games","Proceedings of the 18th ACM International Conference on Interaction Design and Children","978-1-4503-6690-8","","10.1145/3311927.3326596","https://doi.org/10.1145/3311927.3326596","EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (AI), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic AI agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion-sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","755–760","","","","","","","IDC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boise, ID, USA","","","","biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZH6QB6PW","conferencePaper","2017","Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama","A New Chatbot for Customer Service on Social Media","Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems","978-1-4503-4655-9","","10.1145/3025453.3025496","https://doi.org/10.1145/3025453.3025496","Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.","2017","2021-04-19 16:09:40","2021-04-19 16:09:40","","3506–3510","","","","","","","CHI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Denver, Colorado, USA","","","","chatbot; customer service; deep learning; social media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3765LVB","conferencePaper","2019","Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie","Development of a Cloud-Based Computational Framework for an Empathetic Robot","Proceedings of the 2019 11th International Conference on Computer and Automation Engineering","978-1-4503-6287-0","","10.1145/3313991.3314018","https://doi.org/10.1145/3313991.3314018","This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","102–108","","","","","","","ICCAE 2019","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Perth, WN, Australia","","","","cloud control; deep learning; emotion classification; intent perception; robot","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAK7BUPV","conferencePaper","2020","Daher, Karl; Casas, Jacky; Khaled, Omar Abou; Mugellini, Elena","Empathic Chatbot Response for Medical Assistance","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents","978-1-4503-7586-3","","10.1145/3383652.3423864","https://doi.org/10.1145/3383652.3423864","Is it helpful for a medical physical health chatbot to show empathy? How can a chatbot show empathy only based on short-term text conversations? We have investigated these questions by building two different medical assistant chatbots with the goal of providing a diagnosis for physical health problem to the user based on a short conversation. One chatbot was advice-only and asked only the necessary questions for the diagnosis without responding to the user's emotions. Another chatbot, capable of showing empathy, responded in a more supportive manner by analyzing the user's emotions and generating appropriate responses with a high empathic accuracy. Using the RoPE scale questionnaire for empathy perception in a human-robot interaction, our empathic chatbot was rated significantly better in showing empathy and was preferred by a majority of the preliminary study participants (N=12).","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","","","","","","IVA '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Virtual Event, Scotland, UK","","","","conversational agent; emotion detection; empathy; healthcare computing; pattern matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53NHR9RZ","conferencePaper","2020","Chromik, Michael; Lachner, Florian; Butz, Andreas","ML for UX? - An Inventory and Predictions on the Use of Machine Learning Techniques for UX Research","Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society","978-1-4503-7579-5","","10.1145/3419249.3420163","https://doi.org/10.1145/3419249.3420163","Machine learning (ML) techniques have successfully been applied to many complex domains. Yet, applying it to UX research (UXR) received little academic attention so far. To better understand how UX practitioners envision the synergies between empathy-focused UX work and data-driven ML techniques, we surveyed 49 practitioners experienced in UX, ML, or both and conducted 13 semi-structured interviews with UX experts. We derived an inventory of ML’s impact on current UXR activities and practitioners’ predictions about its potentials. We learned that ML methods may help to automate mundane tasks, complement decisions with data-driven insights, and enrich UXR with insights from users’ emotional worlds. Challenges may arise from a potential obligation to utilize data and a more restrictive access to user data. We embed our insights into recent academic work on ML for UXR and discuss automated UX evaluation as a promising use case for future research.","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","","","","","","NordiCHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tallinn, Estonia","","","","machine learning; User experience research; UX research","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PM7QWMZ8","journalArticle","2020","McDonald, Nora; Pan, Shimei","Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3415218","https://doi.org/10.1145/3415218","Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.","2020-10","2021-04-19 16:09:40","2021-04-19 16:09:40","","","","CSCW2","4","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","algorithm bias; artificial intelligence; education; ethics; intersectionality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNZG5XXH","conferencePaper","2020","Chen, Zhifa; Lu, Yichen; Nieminen, Mika P.; Lucero, Andrés","Creating a Chatbot for and with Migrants: Chatbot Personality Drives Co-Design Activities","Proceedings of the 2020 ACM Designing Interactive Systems Conference","978-1-4503-6974-9","","10.1145/3357236.3395495","https://doi.org/10.1145/3357236.3395495","Information portals are usually created to support the integration of migrants into a host country. However, the information-seeking process can be exhausting, cumbersome and even confusing for migrants as they must cope with time-consuming information overload while searching desired information from lists of documents. Chatbots are easy-to-use, natural, and intuitive, and thus could support information-seeking. There is a lack of research that engages and empowers migrants and other stakeholders as co-design participants in chatbot development. We explored how migrants can be empowered in designing a chatbot that supports their social integration. Using a co-design approach, we conducted a series of activities with migrants and other stakeholders (i.e., online questionnaires, empathy probes, surveys, and co-design workshops) to first understand their expectations regarding chatbots, and then co-design a personality-driven chatbot. We found that chatbot personality can drive co-designing a chatbot as design goals, design directions, and design criteria.","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","219–230","","","","","","","DIS '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Eindhoven, Netherlands","","","","avatar; chatbot; co-design; conversation design; generative toolkit; migrants; personality; probes; social integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SU2H8GVT","conferencePaper","2020","Ravi, Akhilesh; Yadav, Amit Kumar Singh; Chauhan, Jainish; Dholakia, Jatin; Jain, Naman","SentEmoji: A Dataset to Generate Empathising Conversations","Proceedings of the 7th ACM IKDD CoDS and 25th COMAD","978-1-4503-7738-6","","10.1145/3371158.3371218","https://doi.org/10.1145/3371158.3371218","Emojis are gaining popularity in day-to-day computer-mediated conversations, resulting in more interactive conversations. On the other hand, traditional chatbots lack the ability to use emojis effectively for creating an engaging and empathising conversation even after recognising feelings of the conversation partner, an essential communicative skill. This inability is majorly due to the paucity of any such suitable publicly available datasets and framework for training and evaluation of chatbot. Prior work has either classified the emojis or generated empathy dialogue without the use of emojis. Through this work, we propose a new dataset SentEmoji, generated using public dataset EmpathyDialogues, and its mapping to relevant emojis using EmojiNet dataset. We present a novel approach to generate dialogue with emojis to express empathy. A study will be conducted to get user rating on three aspects - empathy/sympathy, relevance and fluency. The comparison of this user-study with prior studies will reflect the effectiveness of this approach.","2020","2021-04-19 16:09:40","2021-04-19 16:09:40","","345–346","","","","","","","CoDS COMAD 2020","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Hyderabad, India","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6IHPTVD","conferencePaper","2019","Weisz, Justin D.; Jain, Mohit; Joshi, Narendra Nath; Johnson, James; Lange, Ingrid","BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions","Proceedings of the 24th International Conference on Intelligent User Interfaces","978-1-4503-6272-6","","10.1145/3301275.3302290","https://doi.org/10.1145/3301275.3302290","Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.","2019","2021-04-19 16:09:40","2021-04-19 16:09:40","","448–459","","","","","","","IUI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Marina del Ray, California","","","","conversational agents; explainable AI; mechanical turk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADP8JLYP","conferencePaper","2016","Ishii, Yutaka; Watanabe, Tomio; Sejima, Yoshihiro","Development of an Embodied Avatar System Using Avatar-Shadow's Color Expressions with an Interaction-Activated Communication Model","Proceedings of the Fourth International Conference on Human Agent Interaction","978-1-4503-4508-8","","10.1145/2974804.2980487","https://doi.org/10.1145/2974804.2980487","In reality, shadows are usually natural and unintentional. In virtual reality, however, they play an important role in three-dimensional effects and the perceived reality of the virtual space. An avatar's shadow can have interactive effects with the avatar itself in the virtual space. In this study, we develop an embodied avatar system using avatar-shadow color expressions with an interaction-activated communication model. This model is based on the heat conduction equation in heat-transfer engineering, and has been developed to enhance empathy during embodied interaction in avatar-mediated communication. A communication experiment is performed with 12 pairs of participants to confirm the effectiveness of the system. The results of the sensory evaluation show that interaction activation is visualized by changing avatar-shadow color.","2016","2021-04-19 16:09:41","2021-04-19 16:09:41","","337–340","","","","","","","HAI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Biopolis, Singapore","","","","avatar-mediated communication; avatar's shadow; color expression.; embodied interaction; virtual face-to-face communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5J3PIS5L","conferencePaper","2019","Degraen, Donald; Kosmalla, Felix; Krüger, Antonio","Overgrown: Supporting Plant Growth with an Endoskeleton for Ambient Notifications","Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5971-9","","10.1145/3290607.3312833","https://doi.org/10.1145/3290607.3312833","Ambient notifications are an essential element to support users in their daily activities. Designing effective and aesthetic notifications that balance the alert level while maintaining an unobtrusive dialog, require them to be seamlessly integrated into the user's environment. In an attempt to employ the living environment around us, we designed Overgrown, an actuated robotic structure capable of supporting a plant to grow over itself. As a plant endoskeleton, Overgrown aims to engage human empathy towards living creatures to increase effectiveness of ambient notifications while ensuring better integration with the environment. In a focus group, Overgrown was identified with having personality, showed potential as a user's ambient avatar, and was suited for social experiments.","2019","2021-04-19 16:09:41","2021-04-19 16:09:41","","1–6","","","","","","","CHI EA '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Glasgow, Scotland Uk","","","","ambient interfaces; ambient notifications; empathic living media; focus group","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZQCKAIV","conferencePaper","2021","Svikhnushina, Ekaterina; Pu, Pearl","Key Qualities of Conversational Chatbots – the PEACE Model","26th International Conference on Intelligent User Interfaces","978-1-4503-8017-1","","10.1145/3397481.3450643","https://doi.org/10.1145/3397481.3450643","Open-domain chatbots engage in natural conversations with the user to socialize and establish bonds. However, designing and developing an effective open-domain chatbot is challenging. It is unclear what qualities of such chatbots most correspond to users’ expectations. Even though existing work has considered a wide range of aspects, some key components are still missing. More importantly, the consistency and validity of the combined criteria have not been tested. In this paper, we describe a large-scale survey using a consolidated model to elicit users’ preferences, expectations, and concerns. We apply structural equation modeling methods to further validate the data collected from the user survey. The outcome supports the consistency, validity, and reliability of the model, which we call PEACE (Politeness, Entertainment, Attentive Curiosity, and Empathy). PEACE, therefore, defines the key determinants most predictive of user acceptance. This has allowed us to develop a set of implications useful for the development of compelling open-domain chatbots.","2021","2021-04-19 16:09:41","2021-04-19 16:09:41","","520–530","","","","","","","IUI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: College Station, TX, USA","","","","adoption; chatbots; questionnaire; SEM; user study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U88C2IMI","conferencePaper","2017","Vieira, Suanny; Santos, Alexandre; Costa, Rostand; Maritan, Tiago; Aschoff, Manuella; Veríssimo, Vinícius","A Study on the Use of Multiple Avatars in 3D Sign Language Dictionaries","Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web","978-1-4503-5096-9","","10.1145/3126858.3126865","https://doi.org/10.1145/3126858.3126865","Numerous platforms in the field of machine translation of oralized languages to sign language are available nowadays, and accessibility has been gaining more and more space. However, it is noticed that most platforms use only a unique 3D avatar, and this character is responsible for all the reproduction of signals, with no alternative of choice for users. Such a limitation may have an impact on the acceptance of automatic translation by the deaf community, since there must be empathy of the deaf with the animated agent. Having only one available avatar makes impossible a more precise choice, which may involve personal characteristics and affinities. One of the reasons for this is the great effort, human and technological, that is necessary for the construction of a sign dictionary, which can scale proportionally with the addition of new avatars. In view of such a scenario, the present study aims to investigate mechanisms that allow multiple avatars to be offered in sign dictionaries without necessarily needing to reshape them again and manually, one by one. The initial premise is to analyze the functioning of each signal in a particular avatar, in order to predict possible problems in the reproduction of the signals after the permutation to a new one (retargeting), such as improper collisions or mesh invasions. As main contributions of the work, techniques are proposed to facilitate the identification and automatic correction of nonconformities in the movement of the signals and also some practical recommendations for the modeling of new avatars in order to minimize the occurrence of errors.","2017","2021-04-19 16:09:41","2021-04-19 16:09:41","","325–332","","","","","","","WebMedia '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gramado, RS, Brazil","","","","accessibility; avatar; machine translation; retargeting; sign language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGU5BLRS","conferencePaper","2017","Tong, Xin; Ulas, Servet; Jin, Weina; Gromala, Diane; Shaw, Chris","The Design and Evaluation of a Body-Sensing Video Game to Foster Empathy towards Chronic Pain Patients","Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare","978-1-4503-6363-1","","10.1145/3154862.3154869","https://doi.org/10.1145/3154862.3154869","Chronic Pain (CP) has been identified as a complex medical condition, one that is difficult for sufferers to articulate and for others to discern. This may interfere with the ability of a patient's family, friends and healthcare practitioners to understand what it is like to live with CP, or to even believe it exists. A reluctance by or ability of others to believe a CP patient may in turn exacerbate pain and sequelae common in CP, such as depression, frustration, stigma or social isolation. The goal of this research is to help foster empathy of what CP patients experience by designing and evaluating a body-sensing video game titled AS IF. In this game, players ""inhabit"" a virtual body or avatar of a CP patient. The virtual body simulates physical limitations and displays red areas meant to indicate painful areas. A pilot study with 15 participants was conducted. Results show that while not every aspect of the game proved successful, players had a significant increase in their willingness to help patients. This research demonstrates an approach that may help foster empathy towards CP patients through an embodied game simulation, and has design implications for future research and gameplay explorations.","2017","2021-04-19 16:09:41","2021-04-19 16:09:41","","244–250","","","","","","","PervasiveHealth '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Barcelona, Spain","","","","body-sensing games; chronic pain; embodied simulation; empathy; gaming for a purpose; serious games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CA5MZU2M","conferencePaper","2015","Andersen, Josephine Soegaard; Schoenau-Fog, Henrik","Using Role-Taking and Behavioral Mimicking in Games to Increase Awareness on the Bystander Effect","Proceedings of the 19th International Academic Mindtrek Conference","978-1-4503-3948-3","","10.1145/2818187.2818290","https://doi.org/10.1145/2818187.2818290","This study presents a concept on how a serious game might raise awareness of the bystander effect by using elements of game theory as well as a few psychological terms. The paper summarizes the theories and concludes with the description of a concept, which is a third person role playing game with behavioral mimicking. The game concept should include a relatable (preferably player modifiable) avatar, so the player can relate and adhere to the empathy and intent to help. Since the bystander effect takes place in groups where deindividuation also is common, this should require a behavioral change of this particular group's norms. However, groups (especially of friends) can aid as support in case there is need for intervention as opposed to being passive bystanders.","2015","2021-04-19 16:09:41","2021-04-19 16:09:41","","69–72","","","","","","","AcademicMindTrek '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Tampere, Finland","","","","behavioral mimicking; bystander effect; mimetic activity; proteus effect; role playing; role-taking; serious game; simulations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RD85TVU","conferencePaper","2019","Charrier, Laurianne; Rieger, Alisa; Galdeano, Alexandre; Cordier, Amélie; Lefort, Mathieu; Hassas, Salima","The RoPE Scale: A Measure of How Empathic a Robot is Perceived","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","To be accepted in our everyday life and to be valuable interaction partners, robots should be able to display emotional and empathic behaviors. That is why there has been a great focus on developing empathy in robots in recent years. However, there is no consensus on how to measure how much a robot is considered to be empathic. In this context, we decided to construct a questionnaire which specifically measures the perception of a robot's empathy in human-robot interaction (HRI). Therefore we conducted pretests to generate items. These were validated by experts and will be further validated in an experimental setting.","2019","2021-04-19 16:09:41","2021-04-19 16:09:41","","656–657","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","human-robot interaction; perceived empathy; psychometrics; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKJT9RQ8","conferencePaper","2021","Billinghurst, Mark","Empathic Computing and Human Robot Interaction","Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8289-2","","10.1145/3434073.3444642","https://doi.org/10.1145/3434073.3444642","Empathic Computing is an emerging research field that aims to use technology to create deeper shared understanding or empathy between people [1]. The field sits at the junction of research in Natural Collaboration, Experience Capture and Implicit Understanding. Technologies such as Augmented Reality (AR) and Virtual Reality (VR), can be combined with the sensing of human physiological signals to create new types of collaborative experiences. For example, Empathy Glasses [2] use gaze- and face-tracking to share non-verbal communication cues and enhance remote collaborative. More complex tools, such as EEG, can measure brain activity synchronization and physiological states not normally perceived by humans [3].This talk explores how lessons learned from Empathic Computing can be applied to field of Human Robot Interaction. Previous research has shown how humans can develop empathy for robots [4], and how robots can be used as telepresence surrogates for real people [5]. This shows that there is great potential to create robot mediated Empathic Computing experiences to enhance face to face and remote collaboration.","2021","2021-04-19 16:09:41","2021-04-19 16:09:41","","5","","","","","","","HRI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boulder, CO, USA","","","","augmented reality; empathic computing; human robot interaction; tele-existence; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTDGSZWD","conferencePaper","2016","Kim, Jungwoo; Kim, Hyesook; Choi, Jaeboong","Development of Smart Product, DUET Using SQFD and Storytelling","Proceedings of HCI Korea","978-89-6848-791-0","","10.17210/hcik.2016.01.298","https://doi.org/10.17210/hcik.2016.01.298","This paper presents a smart product design process for a wearable device to provide empathy and fun to users. As the first step, keywords were extracted using open-coding methods from text WebData of online sites for wearable devices, Smardi, Sblog, and Wsite. The Smart Quality Function Deployment (SQFD) was then applied to prioritize the keywords and corresponding user requirements. The key user requirements such as 'separable band from core module' and 'function for media control' were then materialized into a wearable band, DUET, using rapid prototyping, and refined through three stages of user evaluation. DUET connectable to iOS and Android smartphones was introduced by a storytelling transmedia videoclip by experts with a theme of empathy and fun. It was also advertised on a cloud funding site, Indiegogo, and through a PPL in S entertainment program, and received positive responses. Further detailed analysis of user responses was performed for 72 days through the operation of facebook-DUET site and for 10 days through Google keyword marketing which derived various levels of user activities.","2016","2021-04-19 16:09:41","2021-04-19 16:09:41","","298–306","","","","","","","HCIK '16","","","","Hanbit Media, Inc.","Seoul, KOR","","","","","","","","event-place: Jeongseon, Republic of Korea","","","","RP; SQFD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2K4JH2U","conferencePaper","2015","Franco, Gloria Adriana Mendoza","Evaluation of the Emotional Answer in HRI on a Game Situation","Proceedings of the Latin American Conference on Human Computer Interaction","978-1-4503-3960-5","","10.1145/2824893.2824897","https://doi.org/10.1145/2824893.2824897","This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.","2015","2021-04-19 16:09:41","2021-04-19 16:09:41","","","","","","","","","CLIHC '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Córdoba, Argentina","","","","Emocards; emotional evaluation; emotional reciprocity; empathy; HRI; interaction design; lottery application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZ7X5V2B","conferencePaper","2015","Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani Sherman, Tal","Design and Evaluation of a Peripheral Robotic Conversation Companion","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696495","https://doi.org/10.1145/2696454.2696495","We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.","2015","2021-04-19 16:09:41","2021-04-19 16:09:41","","3–10","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","ambient kinetic tangibles; behavior change; design; empathy; human-robot interaction; robotic companions; smartphone robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2UU2XFW2","conferencePaper","2018","Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor","He Who Hesitates is Lost (...in Thoughts over a Robot)","Proceedings of the Technology, Mind, and Society","978-1-4503-5420-2","","10.1145/3183654.3183703","https://doi.org/10.1145/3183654.3183703","In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.","2018","2021-04-19 16:09:41","2021-04-19 16:09:41","","","","","","","","","TechMindSociety '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Washington, DC, USA","","","","Anthropomorphism; Empathy; Human Machine Team; Robotics; User Study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMS2RA9G","conferencePaper","2018","Björling, Elin A.; Rose, Emma; Ren, Rachel","Teen-Robot Interaction: A Pilot Study of Engagement with a Low-Fidelity Prototype","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177068","https://doi.org/10.1145/3173386.3177068","Today's teens will most likely be the first generation to spend a lifetime living and interacting with both mechanical and social robots. Although human-robot interaction has been explored in children, adults, and seniors, examination of teen-robot interaction has been minimal. Using human-centered design, our team is developing a social robot to gather stress and mood data from teens in a public high school. As part of our preliminary design stage, we conducted a interaction pilot study in the wild to explore and capture teens' initial interactions with a low-fidelity social robot prototype. We observed strong engagement and expressions of empathy from teens during our qualitative, interaction studies.","2018","2021-04-19 16:09:41","2021-04-19 16:09:41","","69–70","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","engagement; prototype; teen-robot interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FD2AFGA","conferencePaper","2015","Jeong, Seongmi; Gu, Jihyang; Shin, Dong-Hee","I Am Interested in What You Are Saying: Role of Nonverbal Immediacy Cues in Listening","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702040","https://doi.org/10.1145/2701973.2702040","Immediacy plays a key role in interpersonal communication. Some of immediate behaviors in human-human interaction (i. e. gaze and nodding) have received much attention in HRI, however, others (i. e. body posture) don't. This study investigates whether robot's posture (lean forward vs. upright) and nodding manner (small and fast vs. large and slow) can affect perception of the robot. The current study argues that the lean forward and nodding manner are likely to have significant effects on psychological and behavior outcomes, including perceived empathy, human-likeness, and likability of the robot.","2015","2021-04-19 16:09:41","2021-04-19 16:09:41","","129–130","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","hri; immediacy; nodding; nonverbal behavior; posture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9ZPSTNM","conferencePaper","2018","Brueckner, Sophia","Empathy Amulet: A Wearable to Connect with Strangers","Proceedings of the 2018 ACM International Symposium on Wearable Computers","978-1-4503-5967-2","","10.1145/3267242.3267301","https://doi.org/10.1145/3267242.3267301","The Empathy Amulet is a wearable interpretation of Philip K. Dick's empathy box from his novel Do Androids Dream of Electronic Sheep? [3]. In the novel, thousands of people were anonymously connected with each other both haptically and emotionally when they grabbed the handles of their empathy boxes. The Empathy Amulet similarly networks a group of strangers together through shared experiences of physical warmth. It is not yet another technology for staying in touch with people you already know (and falling short). Rather, it encourages its wearer to make a deliberate and generous choice to invest their time and energy in connection with strangers, and it incorporates reciprocity into its design, such that helping oneself means helping other people. In today's world, people are less likely to feel empathy towards those not in their immediate network of family and friends, and, despite a proliferation of connective technologies, loneliness is on the rise [2, 5]. Surprisingly, it is the perceived sense of loneliness, and not actually being physically alone that has numerous health consequences for a significant portion of the population. Lakoff and Johnson's theory of embodied mind asserts that our physical and subjective experiences are inextricably linked, and the Empathy Amulet leverages the powerful connection between the physical experience of warmth and the subjective experience of social connectedness to combat loneliness and cultivate a stronger sense of connection with strangers [1, 4].","2018","2021-04-19 16:09:41","2021-04-19 16:09:41","","248–253","","","","","","","ISWC '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Singapore, Singapore","","","","embodied cognition; haptic I/O; internet of things; prototyping; wearable electronics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLTPBW24","conferencePaper","2018","Kang, Dahyun; Kim, SunKyoung; Kwak, Sonya S.","The Effects of the Physical Contact in the Functional Intimate Distance on User's Acceptance toward Robots","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177023","https://doi.org/10.1145/3173386.3177023","We investigated the effects of physical contact of robots on the user's acceptance in the functional intimate distance. We conducted a two (robot interaction types: interaction with physical contact vs. interaction with a tool) within-participants experiment (N=18). This study was a video-based observation study. According to the experimental results, the evaluation of participants on the empathy and sociability of the robot was not affected by physical contact in the functional intimate zone. On the other hand, the participants felt secure and perceived that the robot was knowledgeable when the robot measured the patient's temperature with a thermometer instead of its hand.","2018","2021-04-19 16:09:41","2021-04-19 16:09:41","","143–144","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","empathy; functional intimacy; human-robot interaction; knowledgeableness; physical contact; safety; sociability; social distance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUHRIQ2D","conferencePaper","2021","Urakami, Jacqueline; Sutthithatip, Sujitra","Building a Collaborative Relationship between Human and Robot through Verbal and Non-Verbal Interaction","Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8290-8","","10.1145/3434074.3447171","https://doi.org/10.1145/3434074.3447171","Interpersonal communication and relationship building promote successful collaborations. This study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partner.Participants interacted with two robots that differed in their nonverbal and verbal expressiveness. The interactive robot actively engaged the participant in a conversation before, during and after a collaborative task whereas the non-interactive robot remained passive. The robots' nonverbal and verbal interactions increased participants' perception of the robot as a social actor and strengthened bonding and relationship building between human and robot. The results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact, the robot is attributed a certain personality, and the robot is perceived as being alive.Our study could not show that an interactive robot receives more help by the collaboration partner. Future research should investigate additional factors that facilitate helpful behavior among humans, such as similarity, attributional judgement and empathy.","2021","2021-04-19 16:09:41","2021-04-19 16:09:41","","257–261","","","","","","","HRI '21 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boulder, CO, USA","","","","helping; human robot collaboration; relationship building; social presence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAA4DPUE","conferencePaper","2015","Ji, Sang Hoon; YOU, Su Jeong; Cho, Hye-Kyung","Design of Emotional Conversations with a Child for a Role Playing Robot","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702009","https://doi.org/10.1145/2701973.2702009","The children who suffer from psychological and emotional disorder are unaccustomed to cooperation, shared meaning, sympathy, empathy, and magnanimity. In recent, several attempts has been tried at increasing children's social skills by emotional role-playing game with robots because the robotic system can offer dynamic, adaptive and autonomous interaction for learning of imitation skills with real-time performance evaluation and feedback. But there are limits in robot technologies. Especially, it is very difficult to understand the children's word and take suitable behaviors for the children's intents. Therefore, we suggest a method of guiding an emotional robot playing robot conversations with a child in this paper. For the purpose, we design a human-robot-interaction software and a special human intervention device (HID). And finally, we implement our suggested method with a commercial humanoid robot.","2015","2021-04-19 16:09:41","2021-04-19 16:09:41","","73–74","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","emotional role playing robot; human intervention device; human-robot-interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKR4EMH8","conferencePaper","2020","Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vázquez, Marynel","Prompting Prosocial Human Interventions in Response to Robot Mistreatment","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-6746-2","","10.1145/3319502.3374781","https://doi.org/10.1145/3319502.3374781","Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N=30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.","2020","2021-04-19 16:09:41","2021-04-19 16:09:41","","211–220","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cambridge, United Kingdom","","","","human-robot interaction; prosocial behavior; robot abuse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2I3SYLZ9","journalArticle","2019","Alves-Oliveira, Patrícia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana","Empathic Robot for Group Learning: A Field Study","J. Hum.-Robot Interact.","","","10.1145/3300188","https://doi.org/10.1145/3300188","This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.","2019-03","2021-04-19 16:09:42","2021-04-19 16:09:42","","","","1","8","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","collaborative learning; education; empathy; group learning; human-robot interaction; learning gains; Social robotics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GH97C92C","conferencePaper","2019","Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodríguez, Verónica","Good Robot Design or Machiavellian? An in-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?","2019","2021-04-19 16:09:42","2021-04-19 16:09:42","","382–391","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","culture; in the wild; persuasive robots; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3PTZ9S5","conferencePaper","2018","Lehmann, Hagen; Broz, Frank","Contagious Yawning in Human-Robot Interaction","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-5615-2","","10.1145/3173386.3177063","https://doi.org/10.1145/3173386.3177063","This late breaking report introduces an approach to measure yawning contagion between robots and humans. Understanding to what extent yawning can be contagious between robots and humans will help to generate more believable interaction behaviors for social robots and contribute to a better understanding of cognitive phenomena like empathy and their application in HRI. We will give an overview of an experiment which used an EMYS robot for the presentation of the yawning stimulus. We will present the results of our preliminary analysis of the collected data.","2018","2021-04-19 16:09:42","2021-04-19 16:09:42","","173–174","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","behavior contagion; empathy; human-robot interaction; yawning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQZRAYXM","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","The CoWriter Project: Teaching a Robot How to Write","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","978-1-4503-3318-4","","10.1145/2701973.2702091","https://doi.org/10.1145/2701973.2702091","This video (that accompanies the paper ""When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting"" by the same authors, and presented as well during this conference) presents the first results of the EPFL CoWriter project. The project aims at building a robotic partner which children can teach handwriting. The system allows for the learning by teaching paradigm to be employed in the interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. It is hypothesised that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry.","2015","2021-04-19 16:09:42","2021-04-19 16:09:42","","269","","","","","","","HRI'15 Extended Abstracts","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUUP359H","journalArticle","2020","Bagheri, Elahe; Esteban, Pablo G.; Cao, Hoang-Long; Beir, Albert De; Lefeber, Dirk; Vanderborght, Bram","An Autonomous Cognitive Empathy Model Responsive to Users’ Facial Emotion Expressions","ACM Trans. Interact. Intell. Syst.","","2160-6455","10.1145/3341198","https://doi.org/10.1145/3341198","Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user’s affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans’ emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user’s personality. Users’ affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset.The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.","2020-11","2021-04-19 16:09:42","2021-04-19 16:09:42","","","","3","10","","","","","","","","","","","","","","","","","Place: New York, NY, USA Publisher: Association for Computing Machinery","","","","adaptive interaction; Empathy; facial emotion detection; human robot interaction; non-verbal behavior; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTLY399S","conferencePaper","2020","Arnett, Marcus; Luo, Zhenyang; Paladugula, Pradeep Kumar; Cardenas, Irvin Steve; Kim, Jong-Hoon","Robots Teaching Recycling: Towards Improving Environmental Literacy of Children","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-7057-8","","10.1145/3371382.3379462","https://doi.org/10.1145/3371382.3379462","The present pollution problem can be partially attributed to the lack of empathy for learning any ecological and environmental literacy skills. Although robotics in education is increasing, there has been a lack of interest towards developing devices designed to teach children how to be environmentally conscious, and in particular, how to recycle. This gap is the basis for our robot, which we call the Smart Trash Junior, a mechatronic trashcan that uses vision recognition to identify recyclable objects and enters into a dialogue that educates children, within elementary schools, how to recycle.","2020","2021-04-19 16:09:42","2021-04-19 16:09:42","","615–616","","","","","","","HRI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Cambridge, United Kingdom","","","","children robot interaction; eco-literacy; educational robotics; environmental literacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"836TUDGG","conferencePaper","2021","Chirapornchai, Chatchai; Bremner, Paul; Daly, Joseph E.","Helper's High with a Robot Pet","Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-8290-8","","10.1145/3434074.3447165","https://doi.org/10.1145/3434074.3447165","Helper's high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement. This study investigates if a robot pet can, like a real pet, induce helpers high in people interacting with it. A Vector robot was programmed to express the need for daily exercise and attention, and participants were instructed how to help the robot meet those needs. Our within subjects design had two conditions: with and without emotional behaviour modifiers to the robot's behaviour. Our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants, which would create a stronger helper's high effect than purely functional need expression behaviours. We present a long-term (4 day) remote study design that not only facilitates the kind of interactions needed for helper's high, but abides by government guidelines on Covid-19 safety (under which a laboratory study is not possible). Preliminary results suggest that Vector was able to improve the mood of some participants, and mood changes tend to be greater when Vector expressed behaviours with emotional components. Our post-study interview data suggests that individual differences in living environment and mood impacting external factors, affected Vector's efficacy in mood influencing.","2021","2021-04-19 16:09:42","2021-04-19 16:09:42","","229–233","","","","","","","HRI '21 Companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Boulder, CO, USA","","","","empathy; helper's high; mood improvement; robot pet; vector","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A34LMTA7","conferencePaper","2017","Lin, Chaolan; Faas, Travis; Dombrowski, Lynn; Brady, Erin","Beyond Cute: Exploring User Types and Design Opportunities of Virtual Reality Pet Games","Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology","978-1-4503-5548-3","","10.1145/3139131.3139132","https://doi.org/10.1145/3139131.3139132","Virtual pet games, such as handheld games like Tamagotchi or video games like Petz, provide players with artificial pet companions or entertaining pet-raising simulations. Prior research has found that virtual pets have the potential to promote learning, collaboration, and empathy among users. While virtual reality (VR) has become an increasingly popular game medium, litle is known about users' expectations regarding game avatars, gameplay, and environments for VR-enabled pet games. We surveyed 780 respondents in an online survey and interviewed 30 participants to understand users' motivation, preferences, and game behavior in pet games played on various medium, and their expectations for VR pet games. Based on our findings, we generated three user types that reflect users' preferences and gameplay styles in VR pet games. We use these types to highlight key design opportunities and recommendations for VR pet games.","2017","2021-04-19 16:09:42","2021-04-19 16:09:42","","","","","","","","","VRST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Gothenburg, Sweden","","","","pet game; user types; virtual pet; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEWCXVAE","conferencePaper","2015","Hood, Deanna; Lemaignan, Séverin; Dillenbourg, Pierre","When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-2883-8","","10.1145/2696454.2696479","https://doi.org/10.1145/2696454.2696479","This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.","2015","2021-04-19 16:09:42","2021-04-19 16:09:42","","83–90","","","","","","","HRI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Portland, Oregon, USA","","","","education; human-robot interaction; learning by teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYWTSWS3","conferencePaper","2018","Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana","Group-Based Emotions in Teams of Humans and Robots","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","978-1-4503-4953-6","","10.1145/3171221.3171252","https://doi.org/10.1145/3171221.3171252","Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.","2018","2021-04-19 16:09:42","2021-04-19 16:09:42","","261–269","","","","","","","HRI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Chicago, IL, USA","","","","emotion; group effects; human-robot teamwork; identification; inter-group interactions; self-categorisation; trust","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z77XZHZP","conferencePaper","2019","Vertesi, Janet","Seeing like a Rover: Team Work and Human-Robot Relations","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","978-1-5386-8555-6","","","","How do you work with a robot millions of miles away to make scientific discoveries on a planet you've never set foot on? Although much work in human-robot interaction describes the meaningful relationships that humans forge with their robots in one-on-one encounters, when robots venture into places where humans cannot go — in search and rescue operations, ocean voyages, or even into space — they do so as part of a large human team. Decisions about what the robot should do and where it should go are therefore the result of large group interactions instead of individual human cognition: the realm of organizational sociology.This talk draws on over a decade of ethnography with NASA's robotic spacecraft missions, specifically focusing on the Mars Exploration Rover mission. Going behind the scenes of the mission, I show the meaning-making, emotional connections, and embodied synergy that scientists develop as they work with their robots millions of miles away on a daily basis. This begins by learning to see through the robots' ""eyes"" on another planet, yet the peculiar social arrangement of mission work produces a deeper connection to the robot explorers too: one that is no doubt responsible for the extraordinary success and unexpected longevity of the mission team.Studying robotic spacecraft teams demonstrates how humans build a particular and peculiar empathy with their robotic colleagues that goes beyond anthropomorphism. Instead, this case points to the many and unusual ways in which organizations participate in our interactions with, understanding of, and ultimately care for the robots we work with in everyday life.","2019","2021-04-19 16:09:59","2021-04-19 16:09:59","","152","","","","","","","HRI '19","","","","IEEE Press","","","","","","","","","event-place: Daegu, Republic of Korea","","","","human-robot interaction; teamwork","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"29D5GMSJ","conferencePaper","2018","de Jesus Santos, Fabrícia; de Almeida, Antonio Lucas; Santos, Breno Santana; de Souza, Caio César Alves; Santos, Marcos Neto","Empathic Computer Science: A Systematic Mapping","Proceedings of the 17th Brazilian Symposium on Human Factors in Computing Systems","978-1-4503-6601-4","","10.1145/3274192.3274238","https://doi.org/10.1145/3274192.3274238","Described as the capability to understand the emotional state of an individual and often express a response that resonates with it, empathy is a crucial factor for social interactions. However, the ability to express empathy diminishes as people rely more and more on technological resources to interact. Due to fact of being an essential component to become a more effective social relationship between humans and computers, there are several approaches, techniques, methods or mechanisms to promote empathy in these interactions. This paper proposes to identify and systematize mechanisms used in Computer Science to promote empathy. Thus, it was carried out a systematic mapping on the main research databases of the area. We identified the main approaches used to promote empathy, such as Empathic Robotic Agent/Device and Empathic Virtual Agent, as well as the countries that hold the most research in this line, especially the United Kingdom, Japan and USA. In addition, it was found that this area of research is still not being explored in any significant way.","2018","2021-04-19 16:10:00","2021-04-19 16:10:00","","","","","","","","","IHC 2018","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","event-place: Belém, Brazil","","","","Computer Science; Empathy; Rapport; Secondary Study; Systematic Mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CX3CBRLX","conferencePaper","2016","Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne","I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.","2016","2021-04-19 16:10:00","2021-04-19 16:10:00","","931–939","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","empathy; human-agent interaction; human-robot interaction; memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5CULP76","conferencePaper","2016","Aylett, Ruth","Am I Bovvered? Fifteen Years of Empathic Agents","Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems","978-1-4503-4239-1","","","","In 2001, the EU-funded project VICTEC pioneered the concept of an Empathic Agent. This was reported at AAMAS in 2004 in a well-cited paper 'Caring for Agents and Agents that Care: Building Empathic Relations with Synthetic Agents' (Paiva, Dias, Sobral, Aylett, Sobreperez, Woods, Zoll, Hall). It advanced two goals for embodied empathic agents: characters that, by their actions and behaviours, are able to show empathy (or not) for other characters; and characters that, by their appearance, situation, and behaviour, are able to trigger empathic reactions in the user.In this talk we discuss how far Embodied Empathic Agents - whether graphical or robotic - are succeeding; what we can now do, and what open research questions remain. What are the key theoretical and technological advances already made and which are still needed? What applications are Empathic Agents `good' for, and how do we know they are? And how do they relate to the broader field of social agents?","2016","2021-04-19 16:10:00","2021-04-19 16:10:00","","4","","","","","","","AAMAS '16","","","","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","","","","","","","","event-place: Singapore, Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
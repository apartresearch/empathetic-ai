Title,Citations,Author,Publication Title,Publication Year,Item Type,ISBN,ISSN,DOI,Url,Abstract Note,Date,Date Added,Date Modified,Access Date,Pages,Num Pages,Issue,Volume,Number Of Volumes,Journal Abbreviation,Short Title,Series,Series Number,Series Text,Series Title,Publisher,Place,Language,Rights,Type,Archive,Archive Location,Library Catalog,Call Number,Extra,Notes,File Attachments,Link Attachments,Manual Tags,Automatic Tags,Editor,Series Editor,Translator,Contributor,Attorney Agent,Book Author,Cast Member,Commenter,Composer,Cosponsor,Counsel,Interviewer,Producer,Recipient,Reviewed Author,Scriptwriter,Words By,Guest,Number,Edition,Running Time,Scale,Medium,Artwork Size,Filing Date,Application Number,Assignee,Issuing Authority,Country,Meeting Name,Conference Name,Court,References,Reporter,Legal Status,Priority Numbers,Programming Language,Version,System,Code,Code Number,Section,Session,Committee,History,Legislative Body,Title Duplicate,TA Keyword
Ethical and technical aspects of emotions to create empathy in medical machines,14,"Vallverdú, J.; Casacuberta, D.","Intelligent Systems, Control and Automation: Science and Engineering",2015,bookChapter,,22138986,10.1007/978-3-319-08108-3_20,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921448800&doi=10.1007%2f978-3-319-08108-3_20&partnerID=40&md5=a10a06e28a6b500f117c166167fc864e,"This chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions. Artificial emotions is still an emergent field in artificial intelligence, so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions. We argue that empathy is the key emotion in healthcare contexts. We discuss what empathy is and how it can be modeled to include it in a medical machine. We consider types of medical machines (telemedicine, care robots and mobile apps), and describe the main machines that are in use and offer some predictions about what the near future may bring. The main ethical problems we consider in machine medical ethics are: privacy violations (due to online patient databases), how to deal with error and responsibility concerning machine decisions and actions, social inequality (as a result of people being removed from an e-healthcare system), and how to build trust between machines, patients, and medical professionals. © Springer International Publishing Switzerland 2015.",2015,2021-04-20T16:38:53Z,2021-04-20T16:38:53Z,,341-362,22,,74,,,,,,,,,,English,,,,,,,Publisher: Kluwer Academic Publishers,<p>cited By 4</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ethicalandtechnicalaspectsofemotionstocreateempathyinmedicalmachines,ethical and technical aspects of emotions to create empathy in medical machines this chapter analyzes the ethical challenges in healthcare when introducing medical machines able to understand and mimic human emotions artificial emotions is still an emergent field in artificial intelligence so we devote some space in this paper in order to explain what they are and how we can have an machine able to recognize and mimic basic emotions we argue that empathy is the key emotion in healthcare contexts we discuss what empathy is and how it can be modeled to include it in a medical machine we consider types of medical machines telemedicine care robots and mobile apps and describe the main machines that are in use and offer some predictions about what the near future may bring the main ethical problems we consider in machine medical ethics are privacy violations due to online patient databases how to deal with error and responsibility concerning machine decisions and actions social inequality as a result of people being removed from an ehealthcare system and how to build trust between machines patients and medical professionals  springer international publishing switzerland 2015
Evolving Artificial Pain from Fault Detection through Pattern Data Analysis,1,"Anshar, Muh; Williams, Mary-Anne",2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR),2017,conferencePaper,978-1-5386-2035-9,,10.1109/RCAR.2017.8311945,,"Fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications. As the breath of robots applications requiring human interaction grow, it is important for robots to acquire sophisticated social skills such as empathy towards pain. However, it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects. This paper introduces the concept of pain, based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain. Faults provide the stimulus and defines a classified magnitude value, which constitutes artificial pain generation, comprised of synthetic pain classes. Our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain. The robot is also capable of alerting humans whenever a task will generate artificial pain, or whenever humans fails to acknowledge the alert, the robot can take a considerable preventive actions through joint stiffness adjustment.",2017,2021-04-19T15:57:04Z,2021-04-19T15:57:04Z,,694-699,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: Inst Elect & Elect Engineers; Inst Elect & Elect Engineers Robot & Automat Soc; Harbin Inst Technol; Beijing Inst Technol; Univ Nevada; Univ Electro Commun Tokyo; Chinese Univ Hong Kong; Chinese Acad Sci Type: Proceedings Paper,"<p>IEEE International Conference on Real-time Computing and Robotics (RCAR), Okinawa, JAPAN, JUL 14-18, 2017</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,evolvingartificialpainfromfaultdetectionthroughpatterndataanalysis,evolving artificial pain from fault detection through pattern data analysis fault detection is a classical area of study in robotics and extensive research works have been dedicated to investigate its broad applications as the breath of robots applications requiring human interaction grow it is important for robots to acquire sophisticated social skills such as empathy towards pain however it turns out that this is difficult to achieve without having an appropriate concept of pain that relies on robots being aware of their own body machinery aspects this paper introduces the concept of pain based on the ability to develop a state of awareness of robots own body and the use of the fault detection approach to generate artificial robot pain faults provide the stimulus and defines a classified magnitude value which constitutes artificial pain generation comprised of synthetic pain classes our experiment evaluates some of synthetic pain classes and the results show that the robot gains awareness of its internal state through its ability to predict its joint motion and generate appropriate artificial pain the robot is also capable of alerting humans whenever a task will generate artificial pain or whenever humans fails to acknowledge the alert the robot can take a considerable preventive actions through joint stiffness adjustment
EmotoTent: Reducing School Violence through Embodied Empathy Games,3,"Antle, Alissa N.; Sadka, Ofir; Radu, Iulian; Gong, Boxiao; Cheung, Victor; Baishya, Uddipana",PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019),2019,conferencePaper,978-1-4503-6690-8,,10.1145/3311927.3326596,,"EmotoTent is an interactive socio-emotional learning system developed in response to escalating levels of violence, inequality and marginalization in schools seen in the early 21st Century. The system is inspired by advances in biosensing wearables, tattoo displays, brain sensors, robotic agents, artificial intelligence (Al), gestural interaction and 3D holographic displays. By 2030, technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning; emotion-based human-computer interaction, affective biosensing, empathetic Al agents, and 3D interactive holographic environments. We envision EmotoTent as a modular, emotion sensing Holodeck. In the EmotoTent program children learn and practice emotion regulation and empathy with peers, pets and a robotic dog agent in ways that are experiential, embodied and playful. We propose EmotoTent as a core element of a K-6 socio-emotional learning curriculum designed to improve school culture through the enhancement of children's ability to regulate emotions and interact with human and non-human species with empathy and compassion. Enhancing these qualities has been shown to lead to reductions in violence and bullying, racism, gender inequality and other forms of marginalization. We predict that the EmotoTent socio-emotional learning program will improve school cultures and create a foundation for children's lifelong well-being.",2019,2021-04-19T15:56:26Z,2021-04-19T15:56:26Z,,755-760,6,,,,,,,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Boise State Univ; Stem Act Ctr; St Lukes; Osmo; Langan Barber Fdn; Discovery Ctr Idaho; StemFinity; NSF; Boise Type: Proceedings Paper,"<p>18th Annual ACM Interaction Design and Children (IDC), Boise, ID, JUN 12-15, 2019</p>",,,,biosensing; children; embodied learning; Empathy; experiential learning; holographic environments; mind-body interaction; robotic agents,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,emototentreducingschoolviolencethroughembodiedempathygames,emototent reducing school violence through embodied empathy games emototent is an interactive socioemotional learning system developed in response to escalating levels of violence inequality and marginalization in schools seen in the early 21st century the system is inspired by advances in biosensing wearables tattoo displays brain sensors robotic agents artificial intelligence al gestural interaction and 3d holographic displays by 2030 technological advances will enable us to prototype and investigate questions related to experiential and embodied emotional learning emotionbased humancomputer interaction affective biosensing empathetic al agents and 3d interactive holographic environments we envision emototent as a modular emotion sensing holodeck in the emototent program children learn and practice emotion regulation and empathy with peers pets and a robotic dog agent in ways that are experiential embodied and playful we propose emototent as a core element of a k6 socioemotional learning curriculum designed to improve school culture through the enhancement of childrens ability to regulate emotions and interact with human and nonhuman species with empathy and compassion enhancing these qualities has been shown to lead to reductions in violence and bullying racism gender inequality and other forms of marginalization we predict that the emototent socioemotional learning program will improve school cultures and create a foundation for childrens lifelong wellbeing
Empirical Study of Humor Support in Social Human-Robot Interaction,9,"Bechade, Lucile; Duplessis, Guillaume Dubuisson; Devillers, Laurence","DISTRIBUTED, AMBIENT AND PERVASIVE INTERACTIONS, (DAPI 2016)",2016,conferencePaper,978-3-319-39862-4 978-3-319-39861-7,,10.1007/978-3-319-39862-4_28,,"As part of the Joker project which provides a multimodal dialog system with social skills including humor and empathy, this paper explores idea concerning the human verbal responses to a joking robot. Humor support is defined as the conversational strategies used in reaction to humor utterances. This paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus. We assume that using humor in human-robot interaction sets up a positive atmosphere in which participants are willing to contribute. This study relies on 49 human-robot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses. The human humor responses, elicited through canned jokes and conversational humor, were annotated. Three main categories of human responses were found (1) providing no support, (2) recognizing the attempt of humor and (3) contributing with more humor. The findings indicate that, as in human-human interaction, strategies of humor support are strongly dependent of the humorous event's context.",2016,2021-04-19T15:57:22Z,2021-04-19T15:57:22Z,,305-316,12,,9749,,,,Lecture Notes in Computer Science,,,,SPRINGER INT PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 0302-9743 Type: Proceedings Paper,"<p>4th International Conference on Distributed, Ambient and Pervasive Interactions (DAPI) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>",,,,,"Streitz, N and Markopoulos, P",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empiricalstudyofhumorsupportinsocialhumanrobotinteraction,empirical study of humor support in social humanrobot interaction as part of the joker project which provides a multimodal dialog system with social skills including humor and empathy this paper explores idea concerning the human verbal responses to a joking robot humor support is defined as the conversational strategies used in reaction to humor utterances this paper aims at exploring the phenomenon of responses to humor interventions from the robot through the examination of a corpus we assume that using humor in humanrobot interaction sets up a positive atmosphere in which participants are willing to contribute this study relies on 49 humanrobot interaction dialogues and 381 adjacency pairs of humorous acts made by the robot and the following human responses the human humor responses elicited through canned jokes and conversational humor were annotated three main categories of human responses were found 1 providing no support 2 recognizing the attempt of humor and 3 contributing with more humor the findings indicate that as in humanhuman interaction strategies of humor support are strongly dependent of the humorous events context
The Effects of Cognitive Biases in Long-Term Human-Robot Interactions: Case Studies Using Three Cognitive Biases on MARC the Humanoid Robot,2,"Biswas, Mriganka; Murray, John","SOCIAL ROBOTICS, (ICSR 2016)",2016,conferencePaper,978-3-319-47437-3 978-3-319-47436-6,,10.1007/978-3-319-47437-3_15,,"The research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing long-term companionship between a robot and human. In this paper we discuss, how cognitive biases such as misattribution, Empathy gap and Dunning-Kruger effects can play a role in robot-human interaction with the aim of improving long-term companionship. One of the robots used in this study called MARC (See Fig. 1) was given a series of biased behaviours such as forgetting participant's names, denying its own faults for failures, unable to understand what a participant is saying, etc. Such fallible behaviours were compared to a non-biased baseline behaviour. In the current paper, we present a comparison of two case studies using these biases and a non-biased algorithm. It is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between Robots and Humans. The results of the current experiments show that the participants initially warmed to the robot with the biased behaviours.",2016,2021-04-19T15:57:22Z,2021-04-19T15:57:22Z,,148-158,11,,9979,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper","<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>",,,,Cognitive bias in robot; Human-robot interaction; Human-robot long-term interactions; Imperfect robot,"Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,theeffectsofcognitivebiasesinlongtermhumanrobotinteractionscasestudiesusingthreecognitivebiasesonmarcthehumanoidrobot,the effects of cognitive biases in longterm humanrobot interactions case studies using three cognitive biases on marc the humanoid robot the research presented in this paper is part of a wider study investigating the role cognitive bias plays in developing longterm companionship between a robot and human in this paper we discuss how cognitive biases such as misattribution empathy gap and dunningkruger effects can play a role in robothuman interaction with the aim of improving longterm companionship one of the robots used in this study called marc see fig 1 was given a series of biased behaviours such as forgetting participants names denying its own faults for failures unable to understand what a participant is saying etc such fallible behaviours were compared to a nonbiased baseline behaviour in the current paper we present a comparison of two case studies using these biases and a nonbiased algorithm it is hoped that such humanlike fallible characteristics can help in developing a more natural and believable companionship between robots and humans the results of the current experiments show that the participants initially warmed to the robot with the biased behaviours
Digital empathy secures Frankenstein’s monster,4,"Bond, R.; Engel, F.; Fuchs, M.; Hemmje, M.; Kevitt, P.M.; McTear, M.; Mulvenna, M.; Walsh, P.; Zheng, H.J.",CEUR Workshop Proceedings,2019,conferencePaper,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064815682&partnerID=40&md5=df4d3ba30de229d5c06bceb065e14210,"People’s worries about robot and AI software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like Mary Shelley’s Frankenstein monster. The term Franken-algorithms has been used. Furthermore, there are concerns about driverless cars, automated General Practitioner Doctors (GPs) and robotic surgeons, legal expert systems, and particularly autonomous military drones. Digital Empathy grows when people and computers place themselves in each other’s shoes. Some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them. However, in recent times computers have outperformed people, beating world champions at the Asian game of Go (2017), Jeopardy (2011) and chess (1997), mastering precision in medical surgical operations (STAR) and diagnosis (Watson), and in specific speech and image recognition tasks. Computers have also composed music (AIVA), generated art (Aaron), stories (Quill) and poetry (Google AI). In terms of calling for more Digital Empathy between machines and people, we refer here to theories, computational models, algorithms and systems for detecting, representing and responding to people’s emotions and sentiment in speech and images but also for people’s goals, plans, beliefs and intentions. In reciprocation, people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made, keeping in mind that they are not as prone as people to becoming tired. We conclude that if digital souls are programmed with Digital Empathy, and people have more empathy with them, by doing unto them as we would have them do unto us, this will help to secure Shelley’s monster. © 2019 CEUR-WS. All rights reserved.",2019,2021-04-20T16:38:41Z,2021-04-20T16:38:41Z,,335-349,15,,2348,,,,,,,,CEUR-WS,,English,,,,,,,ISSN: 16130073,"<p>cited By 4; Conference of 5th Collaborative European Research Conference, CERC 2019 ; Conference Date: 29 March 2019 Through 30 March 2019; Conference Code:147497</p>",,,Asian games; Computation theory; Computational model; Computer games; Diagnosis; Expert systems; General practitioners; Image recognition; Large datasets; Medical imaging; Robotic surgery; Speech recognition; Surgery; Surgical operation,,"Walsh P., Low R., Burkhardt D., Bleimann U., Regier S., Stengel I., Humm B.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,digitalempathysecuresfrankensteinsmonster,digital empathy secures frankensteins monster peoples worries about robot and ai software and how it can go wrong have led them to think of it and its associated algorithms and programs as being like mary shelleys frankenstein monster the term frankenalgorithms has been used furthermore there are concerns about driverless cars automated general practitioner doctors gps and robotic surgeons legal expert systems and particularly autonomous military drones digital empathy grows when people and computers place themselves in each others shoes some would argue that for too long people have discriminated against computers and robots by saying that they are only as good as what we put into them however in recent times computers have outperformed people beating world champions at the asian game of go 2017 jeopardy 2011 and chess 1997 mastering precision in medical surgical operations star and diagnosis watson and in specific speech and image recognition tasks computers have also composed music aiva generated art aaron stories quill and poetry google ai in terms of calling for more digital empathy between machines and people we refer here to theories computational models algorithms and systems for detecting representing and responding to peoples emotions and sentiment in speech and images but also for peoples goals plans beliefs and intentions in reciprocation people should have more empathy with machines allowing for their mistakes and also accepting that they will be better than people at performing particular tasks involving large data sets where fast decisions may need to be made keeping in mind that they are not as prone as people to becoming tired we conclude that if digital souls are programmed with digital empathy and people have more empathy with them by doing unto them as we would have them do unto us this will help to secure shelleys monster  2019 ceurws all rights reserved
Predicting Future Alleviation of Mental Illness in Social Media: An Empathy-Based Social Network Perspective,0,"Chai, Y.; Wu, F.; Sun, R.; Zhang, Z.; Bao, J.; Ma, R.; Peng, Q.; Wu, D.; Wan, Y.; Li, K.","2019 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)",2019,conferencePaper,,,10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00230,,"Numerous studies have shown that users' posts on social media can explicitly or implicitly reflect various human psychological characteristics. Through mining these data, predictive models can be built to forecast and analyze potential mental illness, which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments. However, most existing approaches face severe information loss and ignore the time dynamics of user behaviour. To fill the research gaps, we use time-aware social networks to combine various information sources in social media posts. Also, machine learning detectors are trained to automatically identify empathic interactions, filter out irrelevant information and construct empathy-based networks. Finally, we devise a hybrid deep learning algorithm to learn embeddings from the dynamic feature-rich networks and predict future alleviation of mental illness. Compared with strong baselines, our approach achieves the best-performing results with efficient computation speed.",2019-12,2021-04-19T15:42:32Z,2021-04-19T15:42:32Z,,1564-1571,8,,,,,,,,,,,,,,,,,,,,,,,Big Data; Cloud computing; deep learning; Distributed processing; Electromagnetic interference; Erbium; mental illness; online empathy.; Social computing; social media; social network,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,predictingfuturealleviationofmentalillnessinsocialmediaanempathybasedsocialnetworkperspective,predicting future alleviation of mental illness in social media an empathybased social network perspective numerous studies have shown that users posts on social media can explicitly or implicitly reflect various human psychological characteristics through mining these data predictive models can be built to forecast and analyze potential mental illness which can facilitate therapeutic decision making and offer the best hope for early interventions and treatments however most existing approaches face severe information loss and ignore the time dynamics of user behaviour to fill the research gaps we use timeaware social networks to combine various information sources in social media posts also machine learning detectors are trained to automatically identify empathic interactions filter out irrelevant information and construct empathybased networks finally we devise a hybrid deep learning algorithm to learn embeddings from the dynamic featurerich networks and predict future alleviation of mental illness compared with strong baselines our approach achieves the bestperforming results with efficient computation speed
Helper's High with a Robot Pet,0,"Chirapornchai, Chatchai; Bremner, Paul; Daly, Joseph E.",Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction,2021,conferencePaper,978-1-4503-8290-8,,10.1145/3434074.3447165,https://doi.org/10.1145/3434074.3447165,"Helper's high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement. This study investigates if a robot pet can, like a real pet, induce helpers high in people interacting with it. A Vector robot was programmed to express the need for daily exercise and attention, and participants were instructed how to help the robot meet those needs. Our within subjects design had two conditions: with and without emotional behaviour modifiers to the robot's behaviour. Our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants, which would create a stronger helper's high effect than purely functional need expression behaviours. We present a long-term (4 day) remote study design that not only facilitates the kind of interactions needed for helper's high, but abides by government guidelines on Covid-19 safety (under which a laboratory study is not possible). Preliminary results suggest that Vector was able to improve the mood of some participants, and mood changes tend to be greater when Vector expressed behaviours with emotional components. Our post-study interview data suggests that individual differences in living environment and mood impacting external factors, affected Vector's efficacy in mood influencing.",2021,2021-04-19T16:09:42Z,2021-04-19T16:09:42Z,,229–233,5,,,,,,HRI '21 Companion,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Boulder, CO, USA",,,,empathy; helper's high; mood improvement; robot pet; vector,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,helpershighwitharobotpet,helpers high with a robot pet helpers high is the phenomenon that helping someone or something else can lead to psychological benefits such as mood improvement this study investigates if a robot pet can like a real pet induce helpers high in people interacting with it a vector robot was programmed to express the need for daily exercise and attention and participants were instructed how to help the robot meet those needs our within subjects design had two conditions with and without emotional behaviour modifiers to the robots behaviour our primary research question is whether behaviours that conveyed emotion as well as needs would lead to empathy in the participants which would create a stronger helpers high effect than purely functional need expression behaviours we present a longterm 4 day remote study design that not only facilitates the kind of interactions needed for helpers high but abides by government guidelines on covid19 safety under which a laboratory study is not possible preliminary results suggest that vector was able to improve the mood of some participants and mood changes tend to be greater when vector expressed behaviours with emotional components our poststudy interview data suggests that individual differences in living environment and mood impacting external factors affected vectors efficacy in mood influencing
Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot,4,"Chumkamon, Sakmongkon; Masato, Koike; Hayashi, Eiji","2015 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC 2015): BIG DATA ANALYTICS FOR HUMAN-CENTRIC SYSTEMS",2015,conferencePaper,978-1-4799-8696-5,,10.1109/SMC.2015.45,,"This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).",2015,2021-04-19T15:57:36Z,2021-04-19T15:57:36Z,,185-190,6,,,,,,IEEE International Conference on Systems Man and Cybernetics Conference Proceedings,,,,IEEE COMPUTER SOC,"10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Comp Soc; IEEE Syst Man & Cybernet Soc; Hong Kong Polytechn Univ; K C Wong Fdn ISSN: 1062-922X Type: Proceedings Paper,"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), City Univ Hong Kong, Hong Kong, PEOPLES R CHINA, OCT 09-12, 2015</p>",,,,CBA; component; Facial Expression Recognition; Human-Robot Interactio; Social Robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,facialexpressionofsocialinteractionbasedonemotionalmotivationofanimalrobot,facial expression of social interaction based on emotional motivation of animal robot this paper aims to develop the research based on a pet robot and its artificial consciousness we propose the animal behavior and emotion using the artificial neurotransmitter and motivation this research still implements the communication between human and a pet robot respecting to a social cognitive and interaction thus the development of crosscreature communication is crucial for friendly companionship this system focuses on three points the first that is the organization of the behavior and emotion model regarding the phylogenesis the second is the method of the robot that can have empathy with user expression the third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression this paper eventually presents the performance and the experiment that the robot using crossperception and crossexpression between animal robot and social interaction of human communication based on the consciousness based architecture cba
Learning Empathy-Driven Emotion Expressions using Affective Modulations,12,"Churamani, Nikhil; Banos, Pablo; Strahl, Erik; Wermter, Stefan",2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN),2018,conferencePaper,978-1-5090-6014-6,,10.1109/IJCNN.2018.8489158,,"Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.",2018,2021-04-19T15:56:54Z,2021-04-19T15:56:54Z,,1-8,8,,,,,,IEEE International Joint Conference on Neural Networks (IJCNN),,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,ISSN: 2161-4393 Type: Proceedings Paper,"<p>International Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, BRAZIL, JUL 08-13, 2018</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,learningempathydrivenemotionexpressionsusingaffectivemodulations,learning empathydriven emotion expressions using affective modulations humanrobot interaction hri studies particularly the ones designed around social robots use emotions as important building blocks for interaction design in order to provide a natural interaction experience these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction these internal emotions act as motivation for learning to respond to the user in different situations using the physical capabilities of the robot this paper proposes a deep hybrid neural model for multimodal affect recognition analysis and behaviour modelling in social robots the model uses growing selforganising network models to encode intrinsic affective states for the robot these intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the neuroinspired companion nico robot enabling the robot to express empathy towards the users
Prompting Prosocial Human Interventions in Response to Robot Mistreatment,6,"Connolly, Joe; Mocz, Viola; Salomons, Nicole; Valdez, Joseph; Tsoi, Nathan; Scassellati, Brian; Vazquez, Marynel",PROCEEDINGS OF THE 2020 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI `20),2020,conferencePaper,978-1-4503-6746-2,,10.1145/3319502.3374781,,"Inspired by the benefits of human prosocial behavior, we explore whether prosocial behavior can be extended to a Human-Robot Interaction (HRI) context. More specifically, we study whether robots can induce prosocial behavior in humans through a 1x2 between-subjects user study (N = 30) in which a confederate abused a robot. Through this study, we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse. Our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events, despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot. Our findings demonstrate possible effects of group social influence through emotional cues by robots in human-robot interaction. They reveal a need for further research regarding human prosocial behavior within HRI.",2020,2021-04-19T15:56:13Z,2021-04-19T15:56:13Z,,211-220,10,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; SIGAI; IEEE Robot & Automat Soc; ACM Digital Lib; FN Robot; ARM; Cambridge Consultants; Furhat Robot; Halodi; Toyota Res Inst; Cambridge Univ Press; EXG Wear; Frontiers Robot & AI; Honda Res Inst; IDLab; MDPI Robot; MIT Press Europe; Promobot; Semio ISSN: 2167-2121 Type: Proceedings Paper,"<p>ACM/IEEE International Conference on Human-Robot Interaction (HRI), Cambridge, ENGLAND, MAR 23-26, 2020</p>",,,,Human-robot interaction; prosocial behavior; robot abuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,promptingprosocialhumaninterventionsinresponsetorobotmistreatment,prompting prosocial human interventions in response to robot mistreatment inspired by the benefits of human prosocial behavior we explore whether prosocial behavior can be extended to a humanrobot interaction hri context more specifically we study whether robots can induce prosocial behavior in humans through a 1x2 betweensubjects user study n  30 in which a confederate abused a robot through this study we investigated whether the emotional reactions of a group of bystander robots could motivate a human to intervene in response to robot abuse our results show that participants were more likely to prosocially intervene when the bystander robots expressed sadness in response to the abuse as opposed to when they ignored these events despite participants reporting similar perception of robot mistreatment and levels of empathy for the abused robot our findings demonstrate possible effects of group social influence through emotional cues by robots in humanrobot interaction they reveal a need for further research regarding human prosocial behavior within hri
Group-based Emotions in Teams of Humans and Robots,36,"Correia, Filipa; Mascarenhas, Samuel; Prada, Rui; Melo, Francisco S.; Paiva, Ana",HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION,2018,conferencePaper,978-1-4503-4953-6,,10.1145/3171221.3171252,,"Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.",2018,2021-04-19T15:56:48Z,2021-04-19T15:56:48Z,,261-269,9,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper,"<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>",,,,emotion; group effects; Human-robot teamwork; identification; inter-group interactions; self-categorisation; trust,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,groupbasedemotionsinteamsofhumansandrobots,groupbased emotions in teams of humans and robots providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others furthermore the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion namely groupbased emotions this paper contributes with the first model on groupbased emotions in social robotic partners we defined a model of groupbased emotions for social robots that allowed us to create two distinct robotic characters that express either individual or groupbased emotions this paper also contributes with a user study where two autonomous robots embedded the previous characters and formed two humanrobot teams to play a competitive game our results showed that participants perceived the robot that expresses groupbased emotions as more likeable and attributed higher levels of group identification and group trust towards their teams when compared to the robotic partner that expresses individualbased emotions
Empathic concern and the effect of stories in human-robot interaction,84,"Darling, Kate; Nandy, Palash; Breazeal, Cynthia",2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2015,conferencePaper,978-1-4673-6704-2,,10.1109/ROMAN.2015.7333675,,"People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.",2015,2021-04-19T15:57:38Z,2021-04-19T15:57:38Z,,770-775,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper,"<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empathicconcernandtheeffectofstoriesinhumanrobotinteraction,empathic concern and the effect of stories in humanrobot interaction people have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in humanrobot interaction our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it we measure the effects of lifelike movement and stories on peoples hesitation to strike the robot and we evaluate the relationship between hesitation and peoples trait empathy our results show that people with a certain type of high trait empathy empathic concern hesitate to strike the robots we also find that high empathic concern and hesitation are more strongly related for robots with stories this suggests that high trait empathy increases peoples hesitation to strike a robot and that stories may positively influence their empathic responses
A Laughing-driven Pupil Response System for Inducing Empathy,2,"Egawa, Shoichi; Sejima, Yoshihiro; Sato, Yoichiro; Watanabe, Tomio",2016 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII),2016,conferencePaper,978-1-5090-3329-4,,10.1109/SII.2016.7844051,,"Laughing response plays an important role in supporting human interaction and communication, and enhances empathy by sharing laughter each other. Therefore, in order to develop communication systems which enhance empathy, it is desired to design the media representation using the pupil response which is related to affective response such as pleasure-unpleasure. In this paper, we aim to enhance empathy during human and robot interaction and communication, and develop a pupil response system for inducing empathy by laughing response using hemispherical display. In addition, we evaluate the pupil response with the laughing response by using the developed system. The results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy.",2016,2021-04-19T15:57:18Z,2021-04-19T15:57:18Z,,520-525,6,,,,,,IEEE/SICE International Symposium on System Integration,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,"Backup Publisher: IEEE; SICE; SICE Syst Integrat Div; IEEE Robot & Automat Soc; IEEE ind Elect Soc; Hokkaido Univ, Grad Sch Informat Sci & Technol ISSN: 2474-2317 Type: Proceedings Paper","<p>IEEE/SICE International Symposium on System Integration (SII), Sapporo, JAPAN, DEC 13-15, 2016</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,alaughingdrivenpupilresponsesystemforinducingempathy,a laughingdriven pupil response system for inducing empathy laughing response plays an important role in supporting human interaction and communication and enhances empathy by sharing laughter each other therefore in order to develop communication systems which enhance empathy it is desired to design the media representation using the pupil response which is related to affective response such as pleasureunpleasure in this paper we aim to enhance empathy during human and robot interaction and communication and develop a pupil response system for inducing empathy by laughing response using hemispherical display in addition we evaluate the pupil response with the laughing response by using the developed system the results demonstrate that the dilated pupil response with laughing response is effective for enhancing empathy
Human-Robot Interaction based on Facial Expression Imitation,1,"Esfandbod, Alireza; Rokhi, Zeynab; Taheri, Alireza; Alemi, Minoo; Meghdari, Ali",2019 7TH INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM 2019),2019,conferencePaper,978-1-72816-604-9,,10.1109/ICRoM48714.2019.9071837,,"Mimicry during face-to-face interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner. In this paper we propose a facial expression imitation system that utilizes a convolutional neural network (CNN). The model was trained by means of the CK+ database, which is a popular benchmark in facial expression recognition. Then, we implemented the proposed system on a robotic platform and investigated the method's performance via 20 recruited participants. We observed a high mean score of the participants' viewpoints on the imitation capability of the robot of 4.1 out of 5.",2019,2021-04-19T15:56:25Z,2021-04-19T15:56:25Z,,69-73,5,,,,,,RSI International Conference on Robotics and Mechatronics ICRoM,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; Robot Soc Iran ISSN: 2377-679X Type: Proceedings Paper,"<p>7th International Conference on Robotics and Mechatronics (ICRoM), Sharif Univ Technol, Tehran, IRAN, NOV 20-21, 2019</p>",,,,Convolutional Neural Network; Facial Expression Recognition; Human Robot Interaction; Imitation; Social Robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,humanrobotinteractionbasedonfacialexpressionimitation,humanrobot interaction based on facial expression imitation mimicry during facetoface interpersonal interactions is a meaningful nonverbal communication signal that affects the quality of the communications and increases empathy towards the interaction partner in this paper we propose a facial expression imitation system that utilizes a convolutional neural network cnn the model was trained by means of the ck database which is a popular benchmark in facial expression recognition then we implemented the proposed system on a robotic platform and investigated the methods performance via 20 recruited participants we observed a high mean score of the participants viewpoints on the imitation capability of the robot of 41 out of 5
Do We Need Emotionally Intelligent Artificial Agents? First Results of Human Perceptions of Emotional Intelligence in Humans Compared to Robots,18,"Fan, Lisa; Scheutz, Matthias; Lohani, Monika; Mccoy, Marissa; Stokes, Charlene","IN℡LIGENT VIRTUAL AGENTS, IVA 2017",2017,conferencePaper,978-3-319-67401-8 978-3-319-67400-1,,10.1007/978-3-319-67401-8_15,,"Humans are very apt at reading emotional signals in other humans and even artificial agents, which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions. For artificial agents without emotional intelligence might generate behavior that is misinterpreted, unexpected, and confusing to humans, violating human expectations and possibly causing emotional harm. Surprisingly, there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions. Here, we present the first study in the perception of emotional intelligence (EI) in robots vs. humans. The objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans, and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments. Study participants were shown a scene in which either a robot or a human behaved with either high or low empathy, and then they were asked to evaluate the agent's emotional intelligence and trustworthiness. The results showed that participants could consistently distinguish the high EI condition from the low EI condition regardless of the variations in which communication methods were observed, and that whether the agent was a robot or human had no effect on the perception. We also found that relative to low EI high EI conditions led to greater trust in the agent, which implies that we must design robots to be emotionally intelligent if we wish for users to trust them.",2017,2021-04-19T15:57:11Z,2021-04-19T15:57:11Z,,129-141,13,,10498,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,Backup Publisher: KTH Royal Inst Technol ISSN: 0302-9743 Type: Proceedings Paper,"<p>17th International Conference on Intelligent Virtual Agents (IVA), Swedish Natl Museum Sci &amp; Technol, Stockholm, SWEDEN, AUG 27-30, 2017</p>",,,,emotional intelligence; empathetic robot; Human-robot interaction,"Beskow, J and Peters, C and Castellano, G and OSullivan, C and Leite, I and Kopp, S",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,doweneedemotionallyintelligentartificialagentsfirstresultsofhumanperceptionsofemotionalintelligenceinhumanscomparedtorobots,do we need emotionally intelligent artificial agents first results of human perceptions of emotional intelligence in humans compared to robots humans are very apt at reading emotional signals in other humans and even artificial agents which raises the question of whether artificial agents need to be emotionally intelligent to ensure effective social interactions for artificial agents without emotional intelligence might generate behavior that is misinterpreted unexpected and confusing to humans violating human expectations and possibly causing emotional harm surprisingly there is a dearth of investigations aimed at understanding the extent to which artificial agents need emotional intelligence for successful interactions here we present the first study in the perception of emotional intelligence ei in robots vs humans the objective was to determine whether people viewed robots as more or less emotionally intelligent when exhibiting similar behaviors as humans and to investigate which verbal and nonverbal communication methods were most crucial for human observational judgments study participants were shown a scene in which either a robot or a human behaved with either high or low empathy and then they were asked to evaluate the agents emotional intelligence and trustworthiness the results showed that participants could consistently distinguish the high ei condition from the low ei condition regardless of the variations in which communication methods were observed and that whether the agent was a robot or human had no effect on the perception we also found that relative to low ei high ei conditions led to greater trust in the agent which implies that we must design robots to be emotionally intelligent if we wish for users to trust them
Effectiveness of Android-Based Mobile Robots For Children Asperger Syndrome,0,"Febtriko, A.; Rahayuningsih, T.; Septiani, D.; Trisnawati, L.; Arisandi, D.; Sukri",2018 International Conference on Applied Information Technology and Innovation (ICAITI),2018,conferencePaper,,,10.1109/ICAITI.2018.8686759,,"Autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest. One type of autism is Asperger Syndrome is a personal qualitative weakness in communicating and social interaction. Just like any other autistic child with Asperger's Syndrome, it is very difficult to understand emotions. Limitations in expressing and understanding emotions cause children with Asperger's Syndrome to retreat socially like aloof, indifferent, less interested in others, lack empathy, think in one direction, and think hard. Therefore it is necessary to apply play therapy for children with Asperger Syndrome disorder by using Android Mobile-based robot as a robot control tool. Wheel-shaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot. Research using Pre experimental design. The population in sampling is 15 children. Children with Asperger's Syndrome take the 6 -12 year age example at special school for Pekanbaru children. Data collection to assess the outcome of play therapy using Mobile robot, the data collected were analyzed by descriptive analysis and Rank Wilcoxon test. The main purpose of this study is the influence or effectiveness of the use of android-based mobile robots as a control tool against Asperger's Syndrome disorder in children in independent schools Pekanbaru to communicate and interact socially.",2018-09,2021-04-19T15:42:27Z,2021-04-19T15:42:27Z,,208-212,5,,,,,,,,,,,,,,,,,,,,,,,Android; Asperger syndrome; Mobile Robot; Rank Wilcoxon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,effectivenessofandroidbasedmobilerobotsforchildrenaspergersyndrome,effectiveness of androidbased mobile robots for children asperger syndrome autistic disorder is a disorder or developmental disorder in social interaction and communication and is characterized by limited activity and interest one type of autism is asperger syndrome is a personal qualitative weakness in communicating and social interaction just like any other autistic child with aspergers syndrome it is very difficult to understand emotions limitations in expressing and understanding emotions cause children with aspergers syndrome to retreat socially like aloof indifferent less interested in others lack empathy think in one direction and think hard therefore it is necessary to apply play therapy for children with asperger syndrome disorder by using android mobilebased robot as a robot control tool wheelshaped robot or wheeled robot with work area in the form of obstacles and obstacles with the aim that there is a challenge to run the robot research using pre experimental design the population in sampling is 15 children children with aspergers syndrome take the 6 12 year age example at special school for pekanbaru children data collection to assess the outcome of play therapy using mobile robot the data collected were analyzed by descriptive analysis and rank wilcoxon test the main purpose of this study is the influence or effectiveness of the use of androidbased mobile robots as a control tool against aspergers syndrome disorder in children in independent schools pekanbaru to communicate and interact socially
Evaluation of the Emotional Answer in HRI on a Game Situation,1,"Franco, Gloria Adriana Mendoza",Proceedings of the Latin American Conference on Human Computer Interaction,2015,conferencePaper,978-1-4503-3960-5,,10.1145/2824893.2824897,https://doi.org/10.1145/2824893.2824897,"This project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot. A lottery game application has been developed for playing with the robot Nao, and through an experimental scenario the empathy towards a robot has been demonstrated. As a result, the Emocards are presented as a promising assessment method for the emotional answer of the users.",2015,2021-04-19T16:09:41Z,2021-04-19T16:09:41Z,,1-7,7,,,,,,CLIHC '15,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Córdoba, Argentina",,,,Emocards; emotional evaluation; emotional reciprocity; empathy; HRI; interaction design; lottery application,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,evaluationoftheemotionalanswerinhrionagamesituation,evaluation of the emotional answer in hri on a game situation this project has as purpose to propose an adequate method for the assessment of the emotional answer after an interaction with a social and emotional robot a lottery game application has been developed for playing with the robot nao and through an experimental scenario the empathy towards a robot has been demonstrated as a result the emocards are presented as a promising assessment method for the emotional answer of the users
Influence of Upper Body Pose Mirroring in Human-Robot Interaction,12,"Fuente, Luis A.; Ierardi, Hannah; Pilling, Michael; Crook, Nigel T.",SOCIAL ROBOTICS (ICSR 2015),2015,conferencePaper,978-3-319-25554-5 978-3-319-25553-8,,10.1007/978-3-319-25554-5_22,,"This paper explores the effect of upper body pose mirroring in human-robot interaction. A group of participants is used to evaluate how imitation by a robot affects people's perception of their conversation with it. A set of twelve questions about the participants' university experience serves as a backbone for the dialogue structure. In our experimental evaluation, the robot reacts in one of three ways to the human upper body pose: ignoring it, displaying its own upper body pose, and mirroring it. The manner in which the robot behaviour influences human appraisal is analysed using the standard Godspeed questionnaire. Our results show that robot body mirroring/non-mirroring influences the perceived humanness of the robot. The results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots.",2015,2021-04-19T15:57:43Z,2021-04-19T15:57:43Z,,214-223,10,,9388,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,ISSN: 0302-9743 Type: Proceedings Paper,"<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>",,,,Anthropomorphism; Body-pose mirroring; Empathy; Rapport,"Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,influenceofupperbodyposemirroringinhumanrobotinteraction,influence of upper body pose mirroring in humanrobot interaction this paper explores the effect of upper body pose mirroring in humanrobot interaction a group of participants is used to evaluate how imitation by a robot affects peoples perception of their conversation with it a set of twelve questions about the participants university experience serves as a backbone for the dialogue structure in our experimental evaluation the robot reacts in one of three ways to the human upper body pose ignoring it displaying its own upper body pose and mirroring it the manner in which the robot behaviour influences human appraisal is analysed using the standard godspeed questionnaire our results show that robot body mirroringnonmirroring influences the perceived humanness of the robot the results also indicate that body pose mirroring is an important factor in facilitating rapport and empathy in human social interactions with robots
Towards Empathetic Human-Robot Interactions,39,"Fung, Pascale; Bertero, Dario; Wan, Yan; Dey, Anik; Chan, Ricky Ho Yin; Bin Siddique, Farhad; Yang, Yang; Wu, Chien-Sheng; Lin, Ruixi","COMPUTATIONAL LINGUISTICS AND IN℡LIGENT TEXT PROCESSING, (CICLING 2016), PT II",2018,conferencePaper,978-3-319-75487-1 978-3-319-75486-4,,10.1007/978-3-319-75487-1_14,,"Since the late 1990s when speech companies began providing their customer-service software in the market, people have gotten used to speaking to machines. As people interact more often with voice and gesture controlled machines, they expect the machines to recognize different emotions, and understand other high level communication features such as humor, sarcasm and intention. In order to make such communication possible, the machines need an empathy module in them, which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot. Although research on empathetic robots is still in the primary stage, current methods involve using signal processing techniques, sentiment analysis and machine learning algorithms to make robots that can `understand' human emotion. Other aspects of human-robot interaction include facial expression and gesture recognition, as well as robot movement to convey emotion and intent. We propose Zara the Supergirl as a prototype system of empathetic robots. It is a software-based virtual android, with an animated cartoon character to present itself on the screen. She will get `smarter' and more empathetic, by having machine learning algorithms, and gathering more data and learning from it. In this paper, we present our work so far in the areas of deep learning of emotion and sentiment recognition, as well as humor recognition. We hope to explore the future direction of android development and how it can help improve people's lives.",2018,2021-04-19T15:56:56Z,2021-04-19T15:56:56Z,,173-193,21,,9624,,,,Lecture Notes in Computer Science,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 0302-9743 Issue: II Type: Proceedings Paper,"<p>17th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), Mevlana Univ, Konya, TURKEY, APR 03-09, 2016</p>",,,,,"Gelbukh, A",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,towardsempathetichumanrobotinteractions,towards empathetic humanrobot interactions since the late 1990s when speech companies began providing their customerservice software in the market people have gotten used to speaking to machines as people interact more often with voice and gesture controlled machines they expect the machines to recognize different emotions and understand other high level communication features such as humor sarcasm and intention in order to make such communication possible the machines need an empathy module in them which is a software system that can extract emotions from human speech and behavior and can decide the correct response of the robot although research on empathetic robots is still in the primary stage current methods involve using signal processing techniques sentiment analysis and machine learning algorithms to make robots that can understand human emotion other aspects of humanrobot interaction include facial expression and gesture recognition as well as robot movement to convey emotion and intent we propose zara the supergirl as a prototype system of empathetic robots it is a softwarebased virtual android with an animated cartoon character to present itself on the screen she will get smarter and more empathetic by having machine learning algorithms and gathering more data and learning from it in this paper we present our work so far in the areas of deep learning of emotion and sentiment recognition as well as humor recognition we hope to explore the future direction of android development and how it can help improve peoples lives
The Maze of Realizing Empathy with Social Robots,0,"Garcia Corretjer, Marialejandra; Ros, Raquel; Martin, Fernando; Miralles, David",2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2020,conferencePaper,978-1-72816-075-7,,10.1109/RO-MAN47096.2020.9223466,,"Current trends envisage an evolution of collaboration, engagement, and relationship between humans and devices, intelligent agents and robots in our everyday life. Some of the key elements under study are affective states, motivation, trust, care, and empathy. This paper introduces an empathy test-bed that serves as a case study for an existing empathy model. The model describes the steps that need to occur in the process to provoke meaning in empathy, as well as the variables and elements that contextualise those steps. Based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze. A set of exploratory trials are carried out to gather insights on how users perceive the proposed test-bed around attachment and trust, which are basic elements for the realisation of empathy.",2020,2021-04-19T15:56:12Z,2021-04-19T15:56:12Z,,1334-1339,6,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper,"<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,themazeofrealizingempathywithsocialrobots,the maze of realizing empathy with social robots current trends envisage an evolution of collaboration engagement and relationship between humans and devices intelligent agents and robots in our everyday life some of the key elements under study are affective states motivation trust care and empathy this paper introduces an empathy testbed that serves as a case study for an existing empathy model the model describes the steps that need to occur in the process to provoke meaning in empathy as well as the variables and elements that contextualise those steps based on this approach we have developed a fun collaborative scenario where a user and a social robot work together to solve a maze a set of exploratory trials are carried out to gather insights on how users perceive the proposed testbed around attachment and trust which are basic elements for the realisation of empathy
Expression of Emotions by a Service Robot: A Pilot Study,7,"Giambattista, Angela; Teixeira, Luis; Ayanoglu, Hande; Saraiva, Magda; Duarte, Emilia","DESIGN, USER EXPERIENCE, AND USABILITY: TECHNOLOGICAL CONTEXTS, PT III",2016,conferencePaper,978-3-319-40406-6 978-3-319-40405-9,,10.1007/978-3-319-40406-6_31,,"A successful Human-Robot Interaction (HRI) depends on the empathy that the robot has the capability of instantiating on the user, namely through the expression of emotions. In this pilot study, we examined the recognition of emotions being expressed by a service robot in a virtual environment (VE), by university students. The VE was a corridor, neutral in terms of context of use. The robot's facial expressions, body movements, and displacement were manipulated to express eight basic emotions. Results showed that participants had difficulties in recognizing the emotions (33% of success). Also, results suggested that the participants established empathy with the robot. Further work is needed to improve the emotional expression of this robot, which aims to interact with hospitalized children.",2016,2021-04-19T15:57:23Z,2021-04-19T15:57:23Z,,328-336,9,,9748,,,,Lecture Notes in Computer Science,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 0302-9743 Type: Proceedings Paper,"<p>5th International Conference on Design, User Experience, and Usability (DUXU) held as part of 18th International Conference on Human-Computer Interaction (HCI International), Toronto, CANADA, JUL 17-22, 2016</p>",,,,Emotional design; Healthcare; Human robot interaction; Service robot; User experience,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,expressionofemotionsbyaservicerobotapilotstudy,expression of emotions by a service robot a pilot study a successful humanrobot interaction hri depends on the empathy that the robot has the capability of instantiating on the user namely through the expression of emotions in this pilot study we examined the recognition of emotions being expressed by a service robot in a virtual environment ve by university students the ve was a corridor neutral in terms of context of use the robots facial expressions body movements and displacement were manipulated to express eight basic emotions results showed that participants had difficulties in recognizing the emotions 33 of success also results suggested that the participants established empathy with the robot further work is needed to improve the emotional expression of this robot which aims to interact with hospitalized children
A Deep Learning Approach to Modeling Empathy in Addiction Counseling,20,"Gibson, James; Can, Dogan; Xiao, Bo; Imel, Zac E.; Atkins, David C.; Georgiou, Panayiotis; Narayanan, Shrikanth","17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH PROCESSING IN HUMANS AND MACHINES",2016,conferencePaper,978-1-5108-3313-5,,10.21437/Interspeech.2016-554,,"Motivational interviewing is a goal-oriented psychotherapy, employed in cases such as addiction, that aims to help clients explore and resolve their ambivalence about their problem. In motivational interviewing, it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes. In this paper, we propose a deep neural network (DNN) system for predicting counselors' session level empathy ratings from transcripts of the interactions. First, we train a recurrent neural network mapping the text of each speaker turn to a set of task-specific behavioral acts that represent local dynamics of the client-counselor interaction. Subsequently, this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating. We show that this method outperforms training the DNN end-to-end in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics.",2016,2021-04-19T15:57:16Z,2021-04-19T15:57:16Z,,1447-1451,5,,,,,,Interspeech,,,,ISCA-INT SPEECH COMMUNICATION ASSOC,"C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE",English,,,,,,,Backup Publisher: apple; amazon alexa; Google; Microsoft; ebay; facebook; YAHOO JAPAN; Baidu Res; IBM Res; CIRRUS LOGIC; DATATANG; NUANCE; Speechocean Ltd; Yandex; Raytheon Technol ISSN: 2308-457X Type: Proceedings Paper,"<p>17th Annual Conference of the International-Speech-Communication-Association (INTERSPEECH 2016), San Francisco, CA, SEP 08-12, 2016</p>",,,,behavioral signal processing; motivational interviews; recurrent neural networks; word embedding,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,adeeplearningapproachtomodelingempathyinaddictioncounseling,a deep learning approach to modeling empathy in addiction counseling motivational interviewing is a goaloriented psychotherapy employed in cases such as addiction that aims to help clients explore and resolve their ambivalence about their problem in motivational interviewing it is desirable for the counselor to communicate empathy towards the client to promote better therapy outcomes in this paper we propose a deep neural network dnn system for predicting counselors session level empathy ratings from transcripts of the interactions first we train a recurrent neural network mapping the text of each speaker turn to a set of taskspecific behavioral acts that represent local dynamics of the clientcounselor interaction subsequently this network is used to initialize lower layers of a deep network predicting session level counselor empathy rating we show that this method outperforms training the dnn endtoend in a single stage and also outperforms a baseline neural network model that attempts to predict empathy ratings directly from text without modeling turn level behavioral dynamics
Biophilic Evolutionary Buildings that Restore the Experience of Animality in the City,1,"Gil, Pablo; Rossi, Claudio; Coral, William","BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2015",2015,conferencePaper,978-3-319-22979-9 978-3-319-22978-2,,10.1007/978-3-319-22979-9_47,,"In this paper, we present our work on the training of robotised architectural components of intelligent buildings, focusing on how architectural components can learn to behave animalistically, according to the judgment of human users. Our work aims at recovering the lost contact with animals in the urban context, taking advantage of biophilic empathy. The parameters governing the robotised elements we propose are mainly qualitative (emotions and aesthetical perception), which cannot easily be described by mathematical parameters. Additionally, due to their complexity, it is often impossible - or at least impractical, to hardcode suitable controllers for such structures. Thus, we propose the use of Artificial Intelligence learning techniques, concretely Evolutionary Algorithms, to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors. This idea is tested on an intelligent fa, cade that learns optimal configurations according to the perception of aggressiveness and calmness.",2015,2021-04-19T15:57:45Z,2021-04-19T15:57:45Z,,465-472,8,,9222,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Univ Sheffield; Univ Pompeu Fabra Barcelona; Inst Catalana Recerca Estudis Avancats ISSN: 0302-9743 Type: Proceedings Paper,"<p>4th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Barcelona, SPAIN, JUL 28-31, 2015</p>",,,,Biomimicry; Biophilia; Embodied evolution; Evolutionary robotics; Intelligent buildings; Wellbeing,"Wilson, SP and Verschure, PFMJ and Mura, A and Prescott, TJ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,biophilicevolutionarybuildingsthatrestoretheexperienceofanimalityinthecity,biophilic evolutionary buildings that restore the experience of animality in the city in this paper we present our work on the training of robotised architectural components of intelligent buildings focusing on how architectural components can learn to behave animalistically according to the judgment of human users our work aims at recovering the lost contact with animals in the urban context taking advantage of biophilic empathy the parameters governing the robotised elements we propose are mainly qualitative emotions and aesthetical perception which cannot easily be described by mathematical parameters additionally due to their complexity it is often impossible  or at least impractical to hardcode suitable controllers for such structures thus we propose the use of artificial intelligence learning techniques concretely evolutionary algorithms to allow the user to teach the robotised components how to behave in response to their resemblance to specific animal behaviors this idea is tested on an intelligent fa cade that learns optimal configurations according to the perception of aggressiveness and calmness
I Remember You! Interaction with Memory for an Empathic Virtual Robotic Tutor,24,"Hastie, Helen; Lim, Mei Yii; Janarthanam, Srini; Deshmukh, Amol; Aylett, Ruth; Foster, Mary Ellen; Hall, Lynne",Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems,2016,conferencePaper,978-1-4503-4239-1,,,,"We present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor. The domain is a virtual robotic tutor who is guiding and helping learners through a mobile Treasure Hunt exercise that tests their map reading skills. The contribution described in this paper is the discovery that incorporating 'memory' through utterances that recall events from previous interactions significantly increases the learner's ability to perform a pedagogical task. However, the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory. In addition, there was a significant drop in perceived empathy. This work has a large potential influence in the field of interaction design for agents as one cannot blindly add in human-like features, such as, memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability.",2016,2021-04-19T16:10:00Z,2021-04-19T16:10:00Z,,931–939,9,,,,,,AAMAS '16,,,,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,,,,,,,"event-place: Singapore, Singapore",,,,empathy; human-agent interaction; human-robot interaction; memory,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,irememberyouinteractionwithmemoryforanempathicvirtualrobotictutor,i remember you interaction with memory for an empathic virtual robotic tutor we present a study that investigates the effect of incorporating memory in the interaction for a virtual robotic tutor in terms of helping children achieve a pedagogical goal and the perceived likeability and empathy of the tutor the domain is a virtual robotic tutor who is guiding and helping learners through a mobile treasure hunt exercise that tests their map reading skills the contribution described in this paper is the discovery that incorporating memory through utterances that recall events from previous interactions significantly increases the learners ability to perform a pedagogical task however the virtual tutor with memory was perceived as less likeable and the instructions given as harder to follow than with a virtual tutor without memory in addition there was a significant drop in perceived empathy this work has a large potential influence in the field of interaction design for agents as one cannot blindly add in humanlike features such as memory that improve task performance without considering the potential detrimental effects to the perceived empathy and likeability
Expression of Grounded Affect: How Much Emotion Can Arousal Convey?,0,"Hickton, L.; Lewis, M.; Cañamero, L.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,conferencePaper,,3029743,10.1007/978-3-030-63486-5_26,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097849751&doi=10.1007%2f978-3-030-63486-5_26&partnerID=40&md5=6f0c1ea93d681540e0a00def3d996231,"In this paper we consider how non-humanoid robots can communicate their affective state via bodily forms of communication (kinesics), and the extent to which this influences how humans respond to them. We propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study (N = 9), during which participants were interviewed after watching expressive and non-expressive hexapod robots perform different ‘scenes’. A summary of these interviews is presented and a number of emerging themes are identified and discussed. Whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot, the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion. © 2020, Springer Nature Switzerland AG.",2020,2021-04-20T16:38:35Z,2021-04-20T16:38:35Z,,234-248,15,,12228 LNAI,,,,,,,,,,English,,,,,,,ISBN: 9783030634858 Publisher: Springer Science and Business Media Deutschland GmbH,"<p>cited By 0; Conference of 21th Annual Conference on Towards Autonomous Robotics, TAROS 20120 ; Conference Date: 16 September 2020 Through 16 September 2020; Conference Code:252749</p>",,,Affective state; Anthropomorphic robots; Control robots; Exploratory studies; Hexapod robots; Humanoid robot; Robotics; Simple modeling; Social robots,,"Mohammad A., Russo M., Dong X.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,expressionofgroundedaffecthowmuchemotioncanarousalconvey,expression of grounded affect how much emotion can arousal convey in this paper we consider how nonhumanoid robots can communicate their affective state via bodily forms of communication kinesics and the extent to which this influences how humans respond to them we propose a simple model of grounded affect and kinesic expression before presenting the qualitative findings of an exploratory study n  9 during which participants were interviewed after watching expressive and nonexpressive hexapod robots perform different scenes a summary of these interviews is presented and a number of emerging themes are identified and discussed whilst our findings suggest that the expressive robot did not evoke significantly greater empathy or altruistic intent in humans than the control robot the expressive robot stimulated greater desire for interaction and was also more likely to be attributed with emotion  2020 springer nature switzerland ag
Design and Evaluation of a Peripheral Robotic Conversation Companion,78,"Hoffman, Guy; Zuckerman, Oren; Hirschberger, Gilad; Luria, Michal; Shani-Sherman, Tal",PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15),2015,conferencePaper,978-1-4503-2882-1,,10.1145/2696454.2696495,,"We present the design, implementation, and evaluation of a peripheral empathy-evoking robotic conversation companion, Kip1. The robot's function is to increase people's awareness to the effect of their behavior towards others, potentially leading to behavior change. Specifically, Kip1 is designed to promote non-aggressive conversation between people. It monitors the conversation's nonverbal aspects and maintains an emotional model of its reaction to the conversation. If the conversation seems calm, Kip1 responds by a gesture designed to communicate curious interest. If the conversation seems aggressive, Kip1 responds by a gesture designed to communicate fear. We describe the design process of Kip1, guided by the principles of peripheral and evocative. We detail its hardware and software systems, and a study evaluating the effects of the robot's autonomous behavior on couples' conversations. We find support for our design goals. A conversation companion reacting to the conversation led to more gaze attention, but not more verbal distraction, compared to a robot that moves but does not react to the conversation. This suggests that robotic devices could be designed as companions to human-human interaction without compromising the natural communication flow between people. Participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them. This points to the robot's potential to elicit people's empathy.",2015,2021-04-19T15:57:41Z,2021-04-19T15:57:41Z,,3-10,8,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper,"<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>",,,,Ambient kinetic tangibles; Behavior change; Design; Empathy; Human-robot interaction; Robotic companions; Smartphone robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,designandevaluationofaperipheralroboticconversationcompanion,design and evaluation of a peripheral robotic conversation companion we present the design implementation and evaluation of a peripheral empathyevoking robotic conversation companion kip1 the robots function is to increase peoples awareness to the effect of their behavior towards others potentially leading to behavior change specifically kip1 is designed to promote nonaggressive conversation between people it monitors the conversations nonverbal aspects and maintains an emotional model of its reaction to the conversation if the conversation seems calm kip1 responds by a gesture designed to communicate curious interest if the conversation seems aggressive kip1 responds by a gesture designed to communicate fear we describe the design process of kip1 guided by the principles of peripheral and evocative we detail its hardware and software systems and a study evaluating the effects of the robots autonomous behavior on couples conversations we find support for our design goals a conversation companion reacting to the conversation led to more gaze attention but not more verbal distraction compared to a robot that moves but does not react to the conversation this suggests that robotic devices could be designed as companions to humanhuman interaction without compromising the natural communication flow between people participants also rated the reacting robot as having significantly more social human character traits and as being significantly more similar to them this points to the robots potential to elicit peoples empathy
When Children Teach a Robot to Write: An Autonomous Teachable Humanoid Which Uses Simulated Handwriting,145,"Hood, Deanna; Lemaignan, Severin; Dillenbourg, Pierre",PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15),2015,conferencePaper,978-1-4503-2882-1,,10.1145/2696454.2696479,,"This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced bene fits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.",2015,2021-04-19T15:57:42Z,2021-04-19T15:57:42Z,,83-90,8,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper,"<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,whenchildrenteacharobottowriteanautonomousteachablehumanoidwhichusessimulatedhandwriting,when children teach a robot to write an autonomous teachable humanoid which uses simulated handwriting this article presents a novel robotic partner which children can teach handwriting the system relies on the learning by teaching paradigm to build an interaction so as to stimulate metacognition empathy and increased selfesteem in the child user we hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student but could also present the opportunity for children to experience physicallyinduced bene fits encountered during humanled handwriting interventions such as motor mimicry by leveraging simulated handwriting on a synchronised tablet display anao humanoid robot with limited fine motor capabilities has been con figured as a suitably embodied handwriting partner statistical shape models derived from principal component analysis of a dataset of adultwritten letter trajectories allow the robot to draw purposefully deformed letters by incorporating feedback from user demonstrations the system is then able to learn the optimal parameters for the appropriate shape models preliminary in situ studies have been conducted with primary school classes to obtain insight into childrens use of the novel system children aged 68 successfully engaged with the robot and improved its writing to a level which they were satisfied with the validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education
Artificial Empathy in Social Robots: An analysis of Emotions in Speech,12,"James, Jesin; Watson, Catherine Inez; MacDonald, Bruce",2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018),2018,conferencePaper,978-1-5386-7980-7,,10.1109/ROMAN.2018.8525652,,"Artificial speech developed using speech synthesizers has been used as the voice for robots in Human Robot Interaction (HRI). As humans anthropomorphize robots, an empathetically interacting robot is expected to increase the level of acceptance of social robots. Here, a human perception experiment evaluates whether human subjects perceive empathy in robot speech. For this experiment, empathy is expressed only by adding appropriate emotions to the words in speech. Also, humans' preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed. The results show that humans are able to perceive empathy and emotions in robot speech, and prefer it over the standard robotic voice. It is important for the emotions in empathetic speech to be consistent with the language content of what is being said, and with the human users' emotional state. Analyzing emotions in empathetic speech using valence-arousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots.",2018,2021-04-19T15:56:47Z,2021-04-19T15:56:47Z,,632-637,6,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper,"<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>",,,,,"Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,artificialempathyinsocialrobotsananalysisofemotionsinspeech,artificial empathy in social robots an analysis of emotions in speech artificial speech developed using speech synthesizers has been used as the voice for robots in human robot interaction hri as humans anthropomorphize robots an empathetically interacting robot is expected to increase the level of acceptance of social robots here a human perception experiment evaluates whether human subjects perceive empathy in robot speech for this experiment empathy is expressed only by adding appropriate emotions to the words in speech also humans preferences for a robot interacting with empathetic speech versus a standard robotic voice are also assessed the results show that humans are able to perceive empathy and emotions in robot speech and prefer it over the standard robotic voice it is important for the emotions in empathetic speech to be consistent with the language content of what is being said and with the human users emotional state analyzing emotions in empathetic speech using valencearousal model has revealed the importance of secondary emotions in developing empathetically speaking social robots
Emotion Synchronization Method for Robot Facial Expression,0,"Kajihara, Y.; Sripian, P.; Feng, C.; Sugaya, M.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,conferencePaper,,3029743,10.1007/978-3-030-49062-1_44,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088746132&doi=10.1007%2f978-3-030-49062-1_44&partnerID=40&md5=6d35e19fe3d393e315a818e5b4539e20,"Nowadays, communication robots are becoming popular since they are actively used in both commercially and personally. Increasing empathy between human-robot can effectively enhance the positive impression. Empathy can be created by syncing human emotion with the robot expression. Emotion estimation can be done by analyzing controllable expressions like facial expression, or uncontrollable expression like biological signals. In this work, we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal. In order to find out which of the proposed methods yield the best impression, subjective impression rating is used in the experiment. From the result of the impression evaluation, we found that the robot’s facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal. © 2020, Springer Nature Switzerland AG.",2020,2021-04-20T16:38:34Z,2021-04-20T16:38:34Z,,644-653,10,,12182 LNCS,,,,,,,,,,English,,,,,,,ISBN: 9783030490614 Publisher: Springer,"<p>cited By 0; Conference of Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020 ; Conference Date: 19 July 2020 Through 24 July 2020; Conference Code:242229</p>",,,Biological signals; Communication robot; Emotion estimation; Facial Expressions; Human computer interaction; Human emotion; Human robots; Robots; Subjective impressions; Synchronization; Synchronization method,,"M, Kurosu",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,emotionsynchronizationmethodforrobotfacialexpression,emotion synchronization method for robot facial expression nowadays communication robots are becoming popular since they are actively used in both commercially and personally increasing empathy between humanrobot can effectively enhance the positive impression empathy can be created by syncing human emotion with the robot expression emotion estimation can be done by analyzing controllable expressions like facial expression or uncontrollable expression like biological signals in this work we propose the comparison of robot expression synchronization with estimated emotion based on either facial expression or biological signal in order to find out which of the proposed methods yield the best impression subjective impression rating is used in the experiment from the result of the impression evaluation we found that the robots facial expression synchronization using the synchronization based on periodical emotion value performs the best and best suitable for emotion estimated both from facial expression and biological signal  2020 springer nature switzerland ag
Smiles of children with ASD may facilitate helping behaviors to the robot,0,"Kim, S.K.; Hirokawa, M.; Matsuda, S.; Funahashi, A.; Suzuki, K.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018,conferencePaper,,3029743,10.1007/978-3-030-05204-1_6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298276&doi=10.1007%2f978-3-030-05204-1_6&partnerID=40&md5=da7067a69c6a09d4991dbdf804ffe8a5,"Helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy. In this study, we examined the potentials of using a robot as a recipient of help, and helping behaviors to a robot. Also, we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood. The results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles. It implies that smiles may facilitate helping behaviors to the robot. This preliminary research indicates the potentials of robot-assisted interventions to facilitate and increase helping behaviors of children with Autism Spectrum Disorder (ASD). © 2018, Springer Nature Switzerland AG.",2018,2021-04-20T16:38:45Z,2021-04-20T16:38:45Z,,55-64,10,,11357 LNAI,,,,,,,,,,English,,,,,,,ISBN: 9783030052034 Publisher: Springer Verlag,"<p>cited By 0; Conference of 10th International Conference on Social Robotics, ICSR 2018 ; Conference Date: 28 November 2018 Through 30 November 2018; Conference Code:221569</p>",,,Autism spectrum disorders; Children with autisms; Diseases; Helping behavior; Positive correlations; Robotics; Robots; Smile; Social communications,,"Broadbent E., Wagner A.R., Ge S.S., Salichs M.A., Castro-Gonzalez A., He H., Cabibihan J.-J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,smilesofchildrenwithasdmayfacilitatehelpingbehaviorstotherobot,smiles of children with asd may facilitate helping behaviors to the robot helping behaviors are one of the important prosocial behaviors in order to develop social communication skills based on empathy in this study we examined the potentials of using a robot as a recipient of help and helping behaviors to a robot also we explored the relationships between helping behaviors and smiles that is an indicator of a positive mood the results of this study showed that there might be a positive correlation between the amount of helping behaviors and the number of smiles it implies that smiles may facilitate helping behaviors to the robot this preliminary research indicates the potentials of robotassisted interventions to facilitate and increase helping behaviors of children with autism spectrum disorder asd  2018 springer nature switzerland ag
Development and Evaluation of an Interactive Therapy Robot,4,"Kohori, Tomoko; Hirayama, Shiho; Hara, Takenori; Muramatsu, Michiko; Naganuma, Hiroyuki; Yamano, Masayuki; Ichikawa, Kazuko; Matsumoto, Hiroko; Uchiyama, Hiroko","ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY, ACE 2017",2018,conferencePaper,978-3-319-76270-8 978-3-319-76269-2,,10.1007/978-3-319-76270-8_6,,"Interactions with animals can enhance emotions and improve mood by engendering feelings of healing, relaxation, comfort, and reduced stress. Un-fortunately, many people cannot live with animals because of allergies, infection risk, or risk of damage to rental housing. To address these problems, some research groups have investigated robot-based psychotherapy. However, the important healing elements for therapy robots were not identified. Therefore, we conducted an Internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented. We assumed that a healing mood could be induced based on the interactive functions and appearance. To verify this hypothesis, we developed and evaluated a new interactive therapy robot. Next, we conducted interviews with individuals who interacted with a prototype therapy robot. The interviews revealed that the appearance of the robot was critical to engendering feelings of healing, comfort, and empathy. In addition, the size, softness, and comfort of the interactive therapy robot contributed to people feeling affection towards it. We also confirmed the importance of the robot appearing to listen to those who interacted with it. Our results should be useful for designing companion robots for therapy purposes.",2018,2021-04-19T15:56:52Z,2021-04-19T15:56:52Z,,66-83,18,,10714,,,,Lecture Notes in Computer Science,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,Backup Publisher: Multimodal Technologies & Interact Journal ISSN: 0302-9743 Type: Proceedings Paper,"<p>14th International Conference on Advances in Computer Entertainment Technology (ACE), London, ENGLAND, DEC 14-16, 2017</p>",,,,Healing elements Therapeutic robots designed to communicate with humans; Therapeutic effect,"Cheok, AD and Inami, M and Romao, T",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,developmentandevaluationofaninteractivetherapyrobot,development and evaluation of an interactive therapy robot interactions with animals can enhance emotions and improve mood by engendering feelings of healing relaxation comfort and reduced stress unfortunately many people cannot live with animals because of allergies infection risk or risk of damage to rental housing to address these problems some research groups have investigated robotbased psychotherapy however the important healing elements for therapy robots were not identified therefore we conducted an internet survey to determine the design elements of such a robot that might engender a healing mood and the functions that should be implemented we assumed that a healing mood could be induced based on the interactive functions and appearance to verify this hypothesis we developed and evaluated a new interactive therapy robot next we conducted interviews with individuals who interacted with a prototype therapy robot the interviews revealed that the appearance of the robot was critical to engendering feelings of healing comfort and empathy in addition the size softness and comfort of the interactive therapy robot contributed to people feeling affection towards it we also confirmed the importance of the robot appearing to listen to those who interacted with it our results should be useful for designing companion robots for therapy purposes
Effect of Explicit Emotional Adaptation on Prosocial Behavior of Humans towards Robots depends on Prior Robot Experience,5,"Kuehnlenz, Barbara; Busse, Fabian; Foertsch, Pascal; Wolf, Maximilian; Kuehnlenz, Kolja",2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018),2018,conferencePaper,978-1-5386-7980-7,,10.1109/ROMAN.2018.8525515,,"Emotional adaptation increases pro-social behavior of humans towards robotic interaction partners. Social cues are an important factor in this context. This work investigates, if emotional adaptation still works under absence of human-like facial Action Units. A human-robot dialog scenario is chosen using NAO pretending to work for a supermarket and involving humans providing object names to the robot for training purposes. In a user study, two conditions are implemented with or without explicit emotional adaptation of NAO to the human user in a between-subjects design. Evaluations of user experience and acceptance are conducted based on evaluated measures of human-robot interaction (HRI). The results of the user study reveal a significant increase of helpfulness (number of named objects), anthropomorphism, and empathy in the explicit emotional adaptation condition even without social cues of facial Action Units, but only in case of prior robot contact of the test persons. Otherwise, an opposite effect is found. These findings suggest, that reduction of these social cues can be overcome by robot experience prior to the interaction task, e.g. realizable by an additional bonding phase, confirming the importance of such from previous work. Additionally, an interaction with academic background of the participants is found.",2018,2021-04-19T15:56:47Z,2021-04-19T15:56:47Z,,275-281,7,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper,"<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>",,,,,"Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,effectofexplicitemotionaladaptationonprosocialbehaviorofhumanstowardsrobotsdependsonpriorrobotexperience,effect of explicit emotional adaptation on prosocial behavior of humans towards robots depends on prior robot experience emotional adaptation increases prosocial behavior of humans towards robotic interaction partners social cues are an important factor in this context this work investigates if emotional adaptation still works under absence of humanlike facial action units a humanrobot dialog scenario is chosen using nao pretending to work for a supermarket and involving humans providing object names to the robot for training purposes in a user study two conditions are implemented with or without explicit emotional adaptation of nao to the human user in a betweensubjects design evaluations of user experience and acceptance are conducted based on evaluated measures of humanrobot interaction hri the results of the user study reveal a significant increase of helpfulness number of named objects anthropomorphism and empathy in the explicit emotional adaptation condition even without social cues of facial action units but only in case of prior robot contact of the test persons otherwise an opposite effect is found these findings suggest that reduction of these social cues can be overcome by robot experience prior to the interaction task eg realizable by an additional bonding phase confirming the importance of such from previous work additionally an interaction with academic background of the participants is found
Counseling Robot Implementation and Evaluation,3,"Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Eriko; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea","2018 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC)",2018,conferencePaper,978-1-5386-6650-0,,10.1109/SMC.2018.00297,,"A lot of IT personnel have psychological distress and counselors to help them are lack in number. Therefore, we proposed a counseling agent (CA) called CRECA (context respectful counseling agent), which listens to clients and promotes their reflection context respectfully namely in a context preserving way. This agent is now enhanced using a body language called “unazuki” in Japanese, a kind of nodding to greatly promote dialogue, often accompanying “un-un” (meaning “exactly”) of Japanese onomatopoeia. This body language significantly helps represent empathy or entire approval. Our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients' further reflection. To realize it, the robot nods twice at each end of dialog sentence input by clients. Here, we introduce a robot that behaves human-like by an appropriate nodding behavior. The motivation for such a more human-like robot was the extension of application fields from IT workers' counselling to people, who suffer from more social problems such as financial debt, or anxiety of victory or defeat. For such applications, it is important that the agent behaves as much as possible human-like. Here, we present an enhanced experimental evaluation. The quantitative evaluation is based on the utterance amounts of a test group of individuals. These amount with and without the nodding feature are compared. Additionally, the robots with and without nodding are compared according several subjective feelings by the evaluation subjects.",2018,2021-04-19T15:56:48Z,2021-04-19T15:56:48Z,,1716-1722,7,,,,,,IEEE International Conference on Systems Man and Cybernetics Conference Proceedings,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; Sci Council Japan ISSN: 1062-922X Type: Proceedings Paper,"<p>IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE Syst Man &amp; Cybernet Soc, Miyazaki, JAPAN, OCT 07-10, 2018</p>",,,,Counseling; Dialog Promotion; Nodding; Robot; unazuki,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,counselingrobotimplementationandevaluation,counseling robot implementation and evaluation a lot of it personnel have psychological distress and counselors to help them are lack in number therefore we proposed a counseling agent ca called creca context respectful counseling agent which listens to clients and promotes their reflection context respectfully namely in a context preserving way this agent is now enhanced using a body language called unazuki in japanese a kind of nodding to greatly promote dialogue often accompanying unun meaning exactly of japanese onomatopoeia this body language significantly helps represent empathy or entire approval our agent is enhanced with such dialog promotion nodding robot to continue the conversation naturally or context respectfully towards clients further reflection to realize it the robot nods twice at each end of dialog sentence input by clients here we introduce a robot that behaves humanlike by an appropriate nodding behavior the motivation for such a more humanlike robot was the extension of application fields from it workers counselling to people who suffer from more social problems such as financial debt or anxiety of victory or defeat for such applications it is important that the agent behaves as much as possible humanlike here we present an enhanced experimental evaluation the quantitative evaluation is based on the utterance amounts of a test group of individuals these amount with and without the nodding feature are compared additionally the robots with and without nodding are compared according several subjective feelings by the evaluation subjects
"Compassion, empathy and sympathy expression features in affective robotics",17,"Lewandowska-Tomaszczyk, B.; Wilson, P.A.","7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings",2017,conferencePaper,978-1-5090-2645-6,,10.1109/CogInfoCom.2016.7804526,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020084&doi=10.1109%2fCogInfoCom.2016.7804526&partnerID=40&md5=3f7f9b68bb3d08e4898a6fa56ba4ecb2,"The present paper identifies differences in the expression features of compassion, sympathy and empathy in British English and Polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures. The results showed that English compassion is characterised by more positive valence and more of a desire to act than Polish współczucie. Polish empatia is also characterised by a more negative valence than English empathy, which has a wider range of application. When used in positive contexts, English sympathy corresponds to Polish sympatia; however, it also acquires elements of negative valence in English. The results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culture-specific emotion models, the more explicit patterns of responsiveness (British English for the compassion model in our case) is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents. © 2016 IEEE.",2017,2021-04-20T16:38:48Z,2021-04-20T16:38:48Z,,65-70,6,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,English,,,,,,,,"<p>cited By 10; Conference of 7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 ; Conference Date: 16 October 2016 Through 18 October 2016; Conference Code:125734</p>",,,action tendencies; British English; compassion; Corpus linguistics; emotions; empathy; empatia; expressiveness; False negatives; False positive; GRID; Polishing; responsiveness; Robotics; sympathy; sympatia; valence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,compassionempathyandsympathyexpressionfeaturesinaffectiverobotics,compassion empathy and sympathy expression features in affective robotics the present paper identifies differences in the expression features of compassion sympathy and empathy in british english and polish that need to be tuned accordingly in socially interactive robots to enable them to operate successfully in these cultures the results showed that english compassion is characterised by more positive valence and more of a desire to act than polish współczucie polish empatia is also characterised by a more negative valence than english empathy which has a wider range of application when used in positive contexts english sympathy corresponds to polish sympatia however it also acquires elements of negative valence in english the results further showed that although the processes of emotion recognition and expression in robotics must be tuned to culturespecific emotion models the more explicit patterns of responsiveness british english for the compassion model in our case is also recommended for the transfer to make the cognitive and sensory infocommunication more readily interpretable by the interacting agents  2016 ieee
Application of Formative Assessment for the Enhanced Foreign Language Learning,1,"Macianskiene, Nemira; Bijeikiene, Vilma",EDULEARN18: 10TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING TECHNOLOGIES,2018,conferencePaper,978-84-09-02709-5,,https://hdl.handle.net/20.500.12259/58977,,"Education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking, problem-solving, global empathy, tolerance, intercultural awareness as well as team-work and collaboration. Formative assessment (FA) has emerged to be one of the efficient tools in the development of the above-mentioned competences and thus a topical issue in today's education. A number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills, student responsibility, active self-regulated learning, viewing learning as a goal rather than an outcome (Anderson, M., 2016; Brookhart, 2009; Chappuis, J., 2016; Fisher & Frey, 2014; [13]). The present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education. It aims at investigating how the application of formative assessment assists in fostering deep learning, student-centered approach, collaborative and tension free environment, active learning in small groups, enhanced dynamic exchange of feedback between teachers and students as well as self-assessment and peer-assessment both in traditional classroom as well as in virtual learning environment. It also explores the impact of formative assessment upon student lifelong learning skill development. Methodologically, the study is based on an opinion survey, reflection and class observation performed with 181 university students and 21 language teachers. The study has revealed that formative assessment adds significant value to the learning and teaching of languages. It settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality, cooperative learning, connection-building among all members of the learning and teaching process including students and teachers. It has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further in-depth research.",2018,2021-04-19T15:56:56Z,2021-04-19T15:56:56Z,,10084-10091,8,,,,,,EDULEARN Proceedings,,,,IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT,"LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN",English,,,,,,,ISSN: 2340-1117 Type: Proceedings Paper,"<p>10th International Conference on Education and New Learning Technologies (EDULEARN), Palma, SPAIN, JUL 02-04, 2018</p>",,,,foreign language learning and teaching; Formative assessment; student-centered approach; tertiary education,"Chova, LG and Martinez, AL and Torres, IC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,applicationofformativeassessmentfortheenhancedforeignlanguagelearning,application of formative assessment for the enhanced foreign language learning education of the 21st century has been strongly focused on the development of the fundamental universal skills such as critical and creative thinking problemsolving global empathy tolerance intercultural awareness as well as teamwork and collaboration formative assessment fa has emerged to be one of the efficient tools in the development of the abovementioned competences and thus a topical issue in todays education a number of studies have produced positive results investigating the use of formative assessment on the development of learner metacognitive and affective skills student responsibility active selfregulated learning viewing learning as a goal rather than an outcome anderson m 2016 brookhart 2009 chappuis j 2016 fisher  frey 2014 13 the present study intends to examine the application of formative assessment in language classes at a higher education institution whose mission is to educate citizens for our society through commitment to liberal arts and sciences education it aims at investigating how the application of formative assessment assists in fostering deep learning studentcentered approach collaborative and tension free environment active learning in small groups enhanced dynamic exchange of feedback between teachers and students as well as selfassessment and peerassessment both in traditional classroom as well as in virtual learning environment it also explores the impact of formative assessment upon student lifelong learning skill development methodologically the study is based on an opinion survey reflection and class observation performed with 181 university students and 21 language teachers the study has revealed that formative assessment adds significant value to the learning and teaching of languages it settles very well in the education process based on liberal arts and sciences grounded in the principles of collegiality cooperative learning connectionbuilding among all members of the learning and teaching process including students and teachers it has also shown that the broad possibilities for the successful exploitation of formative assessment in language education are still in need of further indepth research
Performance Analysis of Unimodal and Multimodal Models in Valence-Based Empathy Recognition,2,"Mallol-Ragolta, Adria; Schmitt, Maximilian; Baird, Alice; Cummins, Nicholas; Schuller, Bjoern",2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019),2019,conferencePaper,978-1-72810-089-0,,10.1109/FG.2019.8756517,,"The human ability to empathise is a core aspect of successful interpersonal relationships. In this regard, human-robot interaction can be improved through the automatic perception of empathy, among other human attributes, allowing robots to affectively adapt their actions to interactants' feelings in any given situation. This paper presents our contribution to the generalised track of the One-Minute Gradual ( OMG) Empathy Prediction Challenge by describing our approach to predict a listener's valence during semi-scripted actor-listener interactions. We extract visual and acoustic features from the interactions and feed them into a bidirectional long short-term memory network to capture the time-dependencies of the valence-based empathy during the interactions. Generalised and personalised unimodal and multimodal valence-based empathy models are then trained to assess the impact of each modality on the system performance. Furthermore, we analyse if intra-subject dependencies on empathy perception affect the system performance. We assess the models by computing the concordance correlation coefficient ( CCC) between the predicted and self-annotated valence scores. The results support the suitability of employing multimodal data to recognise participants' valence-based empathy during the interactions, and highlight the subject-dependency of empathy. In particular, we obtained our best result with a personalised multimodal model, which achieved a CCC of 0.11 on the test set.",2019,2021-04-19T15:56:31Z,2021-04-19T15:56:31Z,,721-725,5,,,,,,IEEE International Conference on Automatic Face and Gesture Recognition and Workshops,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper","<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,performanceanalysisofunimodalandmultimodalmodelsinvalencebasedempathyrecognition,performance analysis of unimodal and multimodal models in valencebased empathy recognition the human ability to empathise is a core aspect of successful interpersonal relationships in this regard humanrobot interaction can be improved through the automatic perception of empathy among other human attributes allowing robots to affectively adapt their actions to interactants feelings in any given situation this paper presents our contribution to the generalised track of the oneminute gradual  omg empathy prediction challenge by describing our approach to predict a listeners valence during semiscripted actorlistener interactions we extract visual and acoustic features from the interactions and feed them into a bidirectional long shortterm memory network to capture the timedependencies of the valencebased empathy during the interactions generalised and personalised unimodal and multimodal valencebased empathy models are then trained to assess the impact of each modality on the system performance furthermore we analyse if intrasubject dependencies on empathy perception affect the system performance we assess the models by computing the concordance correlation coefficient  ccc between the predicted and selfannotated valence scores the results support the suitability of employing multimodal data to recognise participants valencebased empathy during the interactions and highlight the subjectdependency of empathy in particular we obtained our best result with a personalised multimodal model which achieved a ccc of 011 on the test set
High Sensitivity Layer Feature Analysis in Food Market,1,"Matsuyama, Y.; Asahi, Y.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019,conferencePaper,,3029743,10.1007/978-3-030-22649-7_19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069728322&doi=10.1007%2f978-3-030-22649-7_19&partnerID=40&md5=9cc0b47f423fdb351e845116c0d0b335,"It is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market. However, if you actually drop it you will need a lot of money. This study, we pay attention to innovation theory. In Japan, the study reported a long sales period. However, the study didn’t report a short sales period. Therefore, we report of a short sales period, especially food. This study, we call “High Sensitivity Layer” the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products, sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers. We think that those that collect a lot of empathy in the “High Sensitivity Layer” are diffusive in the innovators and the early adopters, and grab the characteristics of highly sensitive consumers who gather many empathies. I think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer. We prepare a generalized model with a deep learning model and report features of highly sensitive consumers, visually and numerically clearly, using decision tree analysis from that model. From the analysis results, attached more images, and the older, the better it got a report that empathizes with sensitive consumers. When conducting test marketing, it is predicted that high-sensitivity consumers will be able to obtain preferable results by targeting people with this characteristic. Also, it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer. In the future, I would like to further accurate classification by text mining of posted characters and analysis of posted images. © 2019, Springer Nature Switzerland AG.",2019,2021-04-20T16:38:41Z,2021-04-20T16:38:41Z,,232-243,12,,11570 LNCS,,,,,,,,,,English,,,,,,,ISBN: 9783030226480 Publisher: Springer Verlag,"<p>cited By 1; Conference of Thematic Area on Human Interface and the Management of Information, HIMI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228569</p>",,,Commerce; Conducting tests; Decision theory; Decision tree analysis; Decision trees; Deep learning; Feature analysis; Generalized models; High sensitivity; Human computer interaction; Image analysis; Innovation theory; Intelligent systems; Market researches; Sales; Test marketing; Testing; Text processing,,"Yamamoto S., Mori H.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,highsensitivitylayerfeatureanalysisinfoodmarket,high sensitivity layer feature analysis in food market it is not uncommon to conduct test marketing for the purpose of market research when dropping new products to the market however if you actually drop it you will need a lot of money this study we pay attention to innovation theory in japan the study reported a long sales period however the study didnt report a short sales period therefore we report of a short sales period especially food this study we call high sensitivity layer the innovators and the early adopters in innovation theory in term of to be interested in the innovation of products sensitive to trends and constantly collecting new information by themselves and to have greater influence on other consumers we think that those that collect a lot of empathy in the high sensitivity layer are diffusive in the innovators and the early adopters and grab the characteristics of highly sensitive consumers who gather many empathies i think that it may be able to fulfill the purpose of test marketing by seeing the response of new products of food to this consumer we prepare a generalized model with a deep learning model and report features of highly sensitive consumers visually and numerically clearly using decision tree analysis from that model from the analysis results attached more images and the older the better it got a report that empathizes with sensitive consumers when conducting test marketing it is predicted that highsensitivity consumers will be able to obtain preferable results by targeting people with this characteristic also it was found that gender and emotion are not related to the characteristics of the person who writes the report sympathized with the consumer in the future i would like to further accurate classification by text mining of posted characters and analysis of posted images  2019 springer nature switzerland ag
"Degrees of Empathy: Humans’ Empathy Toward Humans, Animals, Robots and Objects",0,"Mattiassi, A.D.A.; Sarrica, M.; Cavallo, F.; Fortunati, L.",Lecture Notes in Electrical Engineering,2019,conferencePaper,,18761100,10.1007/978-3-030-04672-9_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061393572&doi=10.1007%2f978-3-030-04672-9_7&partnerID=40&md5=ecfa12798c4fc551842c452ab47ddb9f,"The aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans, animals, robots and objects. The present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately. Our research questions are: does the continuum represented by this set of elements elicit empathy? Is it possible to observe a linear decrease of empathy according to different features of the selected elements? More broadly, does empathy, as a construct, resist in front of the diversification of the element eliciting it? Results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated: they felt more sad, sorry, aroused and out of control for animals than for humans, but showed little to no empathy for objects. Interestingly, robots that looked more human-like evoked emotions similar to those evoked by humans, while robots that looked more animal-like evoked emotions half-way between those evoked by humans and objects. Implications are discussed. © 2019, Springer Nature Switzerland AG.",2019,2021-04-20T16:38:40Z,2021-04-20T16:38:40Z,,101-113,13,,540,,,,,,,,,,English,,,,,,,ISBN: 9783030046712 Publisher: Springer Verlag,"<p>cited By 0; Conference of 8th Italian Forum on Ambient Assisted Living, ForitAAL 2017 ; Conference Date: 12 June 2017 Through 15 June 2017; Conference Code:223489</p>",,,Animals; Assisted living; Empathy; Human-object continuum; Living-nonliving continuum; Robotics; Robots; Social distance; Social robotics,,"Casiddu N., Monteriu A., Porfirione C., Cavallo F.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,degreesofempathyhumansempathytowardhumansanimalsrobotsandobjects,degrees of empathy humans empathy toward humans animals robots and objects the aim of this paper is to present an experiment in which we compare the degree of empathy that a convenience sample of students expressed with humans animals robots and objects the present study broadens the spectrum of the elements eliciting empathy that previous research has so far explored separately our research questions are does the continuum represented by this set of elements elicit empathy is it possible to observe a linear decrease of empathy according to different features of the selected elements more broadly does empathy as a construct resist in front of the diversification of the element eliciting it results show that participants expressed empathy differently when exposed to three clusters of social actors being mistreated they felt more sad sorry aroused and out of control for animals than for humans but showed little to no empathy for objects interestingly robots that looked more humanlike evoked emotions similar to those evoked by humans while robots that looked more animallike evoked emotions halfway between those evoked by humans and objects implications are discussed  2019 springer nature switzerland ag
Robot-on-Robot Gossiping to Improve Sense of Human-Robot Conversation,1,"Mitsuno, Seiya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi",2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2020,conferencePaper,978-1-72816-075-7,,10.1109/RO-MAN47096.2020.9223442,,"In recent years, a substantial amount of research has been aimed at realizing a social robot that can maintain long-term user interest. One approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users. However, privacy problems may occur owing to private information of the user being mentioned. We propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping. This dialogue strategy can improve the sense of conversation, which results in increased interest while avoiding the privacy issue. We examined our proposal by conducting a conversation experiment evaluated by subject impressions. The results demonstrated that the proposed method could help the robot to obtain higher evaluations. In particular, the perceived mind was improved in the Likert scale evaluation, whereas the robot empathy and intention to use were improved in the binary comparison evaluation. Our dialogue strategy may contribute to understanding the factors regarding the sense of conversation, thereby adding value to the field of human-robot interaction.",2020,2021-04-19T15:56:11Z,2021-04-19T15:56:11Z,,653-658,6,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper,"<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,robotonrobotgossipingtoimprovesenseofhumanrobotconversation,robotonrobot gossiping to improve sense of humanrobot conversation in recent years a substantial amount of research has been aimed at realizing a social robot that can maintain longterm user interest one approach is using a dialogue strategy in which the robot makes a remark based on previous dialogues with users however privacy problems may occur owing to private information of the user being mentioned we propose a novel dialogue strategy whereby a robot mentions another robot in the form of gossiping this dialogue strategy can improve the sense of conversation which results in increased interest while avoiding the privacy issue we examined our proposal by conducting a conversation experiment evaluated by subject impressions the results demonstrated that the proposed method could help the robot to obtain higher evaluations in particular the perceived mind was improved in the likert scale evaluation whereas the robot empathy and intention to use were improved in the binary comparison evaluation our dialogue strategy may contribute to understanding the factors regarding the sense of conversation thereby adding value to the field of humanrobot interaction
Studying Effects of Incorporating Automated Affect Perception with Spoken Dialog in Social Robots,4,"Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H.",2018 27TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2018),2018,conferencePaper,978-1-5386-7980-7,,10.1109/ROMAN.2018.8525777,,"Social robots are becoming an integrated part of our daily lives with the goal of understanding humans' social intentions and feelings, a capability which is often referred to as empathy. Despite significant progress towards the development of empathic social agents, current social robots have yet to reach the full emotional and social capabilities. This paper presents our recent effort on incorporating an automated Facial Expression Recognition (FER) system based on deep neural networks into the spoken dialog of a social robot (Ryan) to extend and enrich its capabilities beyond spoken dialog and integrate the user's affect state into the robot's responses. In order to evaluate whether this incorporation can improve social capabilities of Ryan, we conducted a series of Human-Robot-Interaction (HRI) experiments. In these experiments the subjects watched some videos and Ryan engaged them in a conversation driven by user's facial expressions perceived by the robot. We measured the accuracy of the automated FER system on the robot when interacting with different human subjects as well as three social/interactive aspects, namely task engagement, empathy, and likability of the robot. The results of our HRI study indicate that the subjects rated empathy and likability of the affect-aware Ryan significantly higher than non-empathic (the control condition) Ryan. Interestingly, we found that the accuracy of the FER system is not a limiting factor, as subjects rated the affect-aware agent equipped with a low accuracy FER system as empathic and likable as when facial expression was recognized by a human observer.",2018,2021-04-19T15:56:47Z,2021-04-19T15:56:47Z,,783-789,7,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korea Robot Soc; Nanjing Forestry Univ ISSN: 1944-9445 Type: Proceedings Paper,"<p>27th IEEE International Symposium on Robot and Human Interactive Communication (IEEE RO-MAN), Nanjing, PEOPLES R CHINA, AUG 27-31, 2018</p>",,,,,"Cabibihan, JJ and Mastrogiovanni, F and Pandey, AK and Rossi, S and Staffa, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,studyingeffectsofincorporatingautomatedaffectperceptionwithspokendialoginsocialrobots,studying effects of incorporating automated affect perception with spoken dialog in social robots social robots are becoming an integrated part of our daily lives with the goal of understanding humans social intentions and feelings a capability which is often referred to as empathy despite significant progress towards the development of empathic social agents current social robots have yet to reach the full emotional and social capabilities this paper presents our recent effort on incorporating an automated facial expression recognition fer system based on deep neural networks into the spoken dialog of a social robot ryan to extend and enrich its capabilities beyond spoken dialog and integrate the users affect state into the robots responses in order to evaluate whether this incorporation can improve social capabilities of ryan we conducted a series of humanrobotinteraction hri experiments in these experiments the subjects watched some videos and ryan engaged them in a conversation driven by users facial expressions perceived by the robot we measured the accuracy of the automated fer system on the robot when interacting with different human subjects as well as three socialinteractive aspects namely task engagement empathy and likability of the robot the results of our hri study indicate that the subjects rated empathy and likability of the affectaware ryan significantly higher than nonempathic the control condition ryan interestingly we found that the accuracy of the fer system is not a limiting factor as subjects rated the affectaware agent equipped with a low accuracy fer system as empathic and likable as when facial expression was recognized by a human observer
The Role of Animism Tendencies and Empathy in Adult Evaluations of Robot,4,"Okanda, Mako; Taniguchi, Kosuke; Itakura, Shoji",Proceedings of the 7th International Conference on Human-Agent Interaction,2019,conferencePaper,978-1-4503-6922-0,,10.1145/3349537.3351891,https://doi.org/10.1145/3349537.3351891,"We investigated whether Japanese adults' beliefs about friendship and morality toward robots differing in appearance (i.e., humanoid, dog-like, and egg-shaped) related to their animism tendencies and empathy. University students responded to questionnaires regarding three animism tendencies (i.e., general animism or a tendency to believe souls or gods in nonliving things, aliveness animism or a tendency to consider nonliving things as live entities, and agentic animisms or a tendency to attribute biological, artifactual, psychological, perceptual, and naming properties) and empathy. We found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors. Aliveness animism, as well as a tendency to attribute perceptual and name properties toward robots, might be necessary for an individual to believe that robots could be social agents. Participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong self-oriented emotional reactivity, whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility. We discuss implications of these results and reasons why people feel that robots have a mind or consciousness.",2019,2021-04-19T16:09:40Z,2021-04-19T16:09:40Z,,51–58,8,,,,,,HAI '19,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Kyoto, Japan",,,,animism; empathy; human-robot interaction; robots' perception,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,theroleofanimismtendenciesandempathyinadultevaluationsofrobot,the role of animism tendencies and empathy in adult evaluations of robot we investigated whether japanese adults beliefs about friendship and morality toward robots differing in appearance ie humanoid doglike and eggshaped related to their animism tendencies and empathy university students responded to questionnaires regarding three animism tendencies ie general animism or a tendency to believe souls or gods in nonliving things aliveness animism or a tendency to consider nonliving things as live entities and agentic animisms or a tendency to attribute biological artifactual psychological perceptual and naming properties and empathy we found that friendship and morality were related to slightly different animism tendencies and empathy even though they shared some major factors aliveness animism as well as a tendency to attribute perceptual and name properties toward robots might be necessary for an individual to believe that robots could be social agents participants who responded that robots could be their friends showed a tendency to feel a soul in manmade objects and a strong selforiented emotional reactivity whereas participants who answered that robots were moral beings showed a tendency to exhibit strong emotional susceptibility we discuss implications of these results and reasons why people feel that robots have a mind or consciousness
Robot Mirroring: Promoting Empathy with an Artificial Agent by Reflecting the User's Physiological Affective States,0,"Perusquia-Hernandez, Monica; Balda, Marisabel Cuberos; Jauregui, David Antonio Gomez; Paez-Granados, Diego; Dollack, Felix; Salazar, Jose Victorio",2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2020,conferencePaper,978-1-72816-075-7,,10.1109/RO-MAN47096.2020.9223598,,"Self-tracking aims to increase awareness, decrease undesired behaviors, and ultimately lead towards a healthier lifestyle. However, inappropriate communication of self-tracking results might cause the opposite effect. Subtle self-tracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self. Hence, we propose a wearable pet that reflects the user's affective states through visual and haptic feedback. By eliciting empathy and fostering helping behaviors towards it, users would indirectly help themselves. A wearable prototype was built, and three user studies performed to evaluate the appropriateness of the proposed affective representations. Visual representations using facial and body cues were clear for valence and less clear for arousal. Haptic interoceptive patterns emulating heart-rate levels matched the desired feedback urgency levels with a saturation frequency. The integrated visuo-haptic representations matched to participants own affective experience. From the results, we derived three design guidelines for future robot mirroring wearable systems: physical embodiment, interoceptive feedback, and customization.",2020,2021-04-19T15:56:11Z,2021-04-19T15:56:11Z,,1328-1333,6,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper,"<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>",,,,embodiment; empathy and intersubjectivity; haptic feedback; human-machine interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,robotmirroringpromotingempathywithanartificialagentbyreflectingtheusersphysiologicalaffectivestates,robot mirroring promoting empathy with an artificial agent by reflecting the users physiological affective states selftracking aims to increase awareness decrease undesired behaviors and ultimately lead towards a healthier lifestyle however inappropriate communication of selftracking results might cause the opposite effect subtle selftracking feedback is an alternative that can be provided with the aid of an artificial agent representing the self hence we propose a wearable pet that reflects the users affective states through visual and haptic feedback by eliciting empathy and fostering helping behaviors towards it users would indirectly help themselves a wearable prototype was built and three user studies performed to evaluate the appropriateness of the proposed affective representations visual representations using facial and body cues were clear for valence and less clear for arousal haptic interoceptive patterns emulating heartrate levels matched the desired feedback urgency levels with a saturation frequency the integrated visuohaptic representations matched to participants own affective experience from the results we derived three design guidelines for future robot mirroring wearable systems physical embodiment interoceptive feedback and customization
Ideal Warrior and Robot Relations: Stress and Empathy's Role in Human-Robot Teaming,1,"Peterson, Jordan; Cohen, Chase; Harrison, Paige; Novak, Jonathan; Tossell, Chad; Phillips, Elizabeth",2019 SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS),2019,conferencePaper,978-1-72810-998-5,,10.1109/SIEDS.2019.8735613,,"The battlefield of the future will look very different than the battlefields of the past. Automated technologies are finding themselves more and more integrated into every aspect of the fight. As technology continues to advance, the United States Military must consider what a human-machine team will look like and how an optimal relationship between the two assets can be formed, especially under the stressful conditions that often characterize military contexts. For a human-machine team in a military context to work at maximum efficiency, an ideal level of empathy towards an automated teammate must be obtained. The goal of this study is to determine the effect stress can have on an individual's empathetic reaction toward a Pepper robot. Twenty-eight participants interacted with a Pepper robot either under stress or not. Empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with Pepper even though doing so would harm the robot. Although not conclusive, the results suggest an interaction between participant gender and stress on empathy toward the Pepper robot. Women showed more empathy toward Pepper under higher levels of stress than lower levels of stress. However, the opposite was true for men. Men showed less empathy toward Pepper under higher levels of stress. The results of this study could help to inform military training and robot design.",2019,2021-04-19T15:56:32Z,2021-04-19T15:56:32Z,,170-175,6,,,,,,IEEE Systems and Information Engineering Design Symposium,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,ISSN: 2639-7439 Type: Proceedings Paper,"<p>Systems and Information Engineering Design Symposium (SIEDS), Univ Virginia, Charlottesville, VA, APR 26, 2019</p>",,,,Human-machine teaming; Human-robot interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,idealwarriorandrobotrelationsstressandempathysroleinhumanrobotteaming,ideal warrior and robot relations stress and empathys role in humanrobot teaming the battlefield of the future will look very different than the battlefields of the past automated technologies are finding themselves more and more integrated into every aspect of the fight as technology continues to advance the united states military must consider what a humanmachine team will look like and how an optimal relationship between the two assets can be formed especially under the stressful conditions that often characterize military contexts for a humanmachine team in a military context to work at maximum efficiency an ideal level of empathy towards an automated teammate must be obtained the goal of this study is to determine the effect stress can have on an individuals empathetic reaction toward a pepper robot twentyeight participants interacted with a pepper robot either under stress or not empathy toward the robot was measured through subjective assessments as well as by participant decisions to continue interacting with pepper even though doing so would harm the robot although not conclusive the results suggest an interaction between participant gender and stress on empathy toward the pepper robot women showed more empathy toward pepper under higher levels of stress than lower levels of stress however the opposite was true for men men showed less empathy toward pepper under higher levels of stress the results of this study could help to inform military training and robot design
Towards a Robot Computational Model to Preserve Dignity in Stigmatizing Patient-Caregiver Relationships,7,"Pettinati, Michael J.; Arkin, Ronald C.",SOCIAL ROBOTICS (ICSR 2015),2015,conferencePaper,978-3-319-25554-5 978-3-319-25553-8,,10.1007/978-3-319-25554-5_53,,"Parkinson's disease (PD) patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels. Our approach to uphold PD patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patient-caregiver interaction. This paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during “empathetic opportunities” in their interaction. A PD patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver. When this difference falls outside of acceptable set bounds (norms), the robotic agent will act using subtle, nonverbal cues to guide the relationship back within these bounds, preserving patient dignity.",2015,2021-04-19T15:57:44Z,2021-04-19T15:57:44Z,,532-542,11,,9388,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,ISSN: 0302-9743 Type: Proceedings Paper,"<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>",,,,,"Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,towardsarobotcomputationalmodeltopreservedignityinstigmatizingpatientcaregiverrelationships,towards a robot computational model to preserve dignity in stigmatizing patientcaregiver relationships parkinsons disease pd patients with an expressive mask are particularly vulnerable to stigmatization during interactions with their caregivers due to their inability to express affect through nonverbal channels our approach to uphold pd patient dignity is through the use of an ethical robot that mediates patient shame when it recognizes norm violations in the patientcaregiver interaction this paper presents the basis for a computational model tasked with computing patient shame and the empathetic response of a caregiver during empathetic opportunities in their interaction a pd patient is liable to suffer indignity when there is a substantial difference between his experienced shame and the empathy shown by the caregiver when this difference falls outside of acceptable set bounds norms the robotic agent will act using subtle nonverbal cues to guide the relationship back within these bounds preserving patient dignity
Evaluation of Classifiers for Emotion Detection While Performing Physical and Visual Tasks: Tower of Hanoi and IAPS,0,"Qureshi, Shahnawaz; Hagelback, Johan; Iqbal, Syed Muhammad Zeeshan; Javaid, Hamad; Lindley, Craig A.","IN℡LIGENT SYSTEMS AND APPLICATIONS, VOL 1",2019,conferencePaper,978-3-030-01054-6 978-3-030-01053-9,,10.1007/978-3-030-01054-6_25,,"With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT.",2019,2021-04-19T15:56:24Z,2021-04-19T15:56:24Z,,347-363,17,,868,,,,Advances in Intelligent Systems and Computing,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 2194-5357 Type: Proceedings Paper,"<p>Intelligent Systems Conference (IntelliSys), London, ENGLAND, SEP 06-07, 2018</p>",,,,Artificial Neural Networks (ANN); Bayesian Network (BNT); Cognitive psychology; Electroencephalography (EEG); Human Computer Interaction (HCI); K-Nearest Neighbor (KNN); Regression Tree (RT); Support Vector Machine (SVM); Tower of Hanoi (ToH),"Arai, K and Kapoor, S and Bhatia, R",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,evaluationofclassifiersforemotiondetectionwhileperformingphysicalandvisualtaskstowerofhanoiandiaps,evaluation of classifiers for emotion detection while performing physical and visual tasks tower of hanoi and iaps with the advancement in robot technology smart humanrobot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities if a robot can identify emotions and intentions of a human interacting with it interactions with humans can potentially become more natural and effective however mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots electroencephalography eeg can be used for recording signals revealing emotions and motivations from a human brain this study aimed to evaluate different machine learning techniques to classify eeg data associated with specific affectiveemotional states for experimental purposes we used visual iaps and physical tower of hanoi tasks to record human emotional states in the form of eeg data the obtained eeg data processed formatted and evaluated using various machine learning techniques to find out which method can most accurately classify eeg data according to associated affectiveemotional states the experiment confirms the choice of a method for improving the accuracy of results according to the results support vector machine was the first and regression tree was the second best method for classifying eeg data associated with specific affectiveemotional states with accuracies up to 7000 and 6000 respectively in both tasks svm was better in performance than rt
An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction,4,"Ranieri, Caetano M.; Romero, Roseli A. F.",PROCEEDINGS OF 13TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 4TH BRAZILIAN SYMPOSIUM ON ROBOTICS - LARS/SBR 2016,2016,conferencePaper,978-1-5090-3656-1,,10.1109/LARS-SBR.2016.13,,"Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.",2016,2021-04-19T15:57:20Z,2021-04-19T15:57:20Z,,31-36,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: Brazilian Comp Soc; Centro Estudos Sistemas Avancados Recife; Centro Informatica UFPE; ROBOLIURE; VIRTUS IMPAVIDA; Inst Inovacao; Robolivre; CAPES; Inst SENAI Inovacao; Conselho Nacl Desenvolvimento Cientifico Tecnologico; Fundacao Amparo Ciencia Tecnologia Estado Pernambuco; IEEE Robot & Automat Soc Chapter Brazil; IEEE Latin Amer Robot Council Type: Proceedings Paper,"<p>13th Latin American Robotics Symposium / 4th Brazilian Robotics Symposium (LARS/SBR), Recife, BRAZIL, OCT 08-12, 2016</p>",,,,,"Cavalcante, SV and Tonidandel, F",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,anemotionbasedinteractionstrategytoimprovehumanrobotinteraction,an emotionbased interaction strategy to improve humanrobot interaction emotion and empathy are key subjects on humanrobot interaction especially regarding social robots several studies have investigated emotional reactions of humans toward robots while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction this paper presents an emotionaware interaction strategy applied to an embodied virtual agent implemented as an android application the system assigns two distinct paradigms to the virtual character according to the users emotion inferred through facial expressions analysis within subject user experiments have been performed in order to evaluate if the proposed strategy improves empathy and pleasantness
Empathic Interaction using the Computational Emotion Model,5,"Rasool, Zeeshan; Masuyama, Naoki; Islam, Md. Nazrul; Loo, Chu Kiong",2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL IN℡LIGENCE (IEEE SSCI),2015,conferencePaper,978-1-4799-7560-0,,10.1109/SSCI.2015.26,,"This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model; whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.",2015,2021-04-19T15:57:37Z,2021-04-19T15:57:37Z,,109-116,8,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Computational Intelligence Soc; IEEE BigData Type: Proceedings Paper,"<p>IEEE Symposium Series Computational Intelligence, Cape Town, SOUTH AFRICA, DEC 07-10, 2015</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empathicinteractionusingthecomputationalemotionmodel,empathic interaction using the computational emotion model this paper describes the empathy oriented humanrobot interaction model it is projected to design the model capable of different empathic responses parallel and reactive during the course of interaction with the user depending upon the personality and mood factors of the robot the proposed model encompasses three main stages ie perception empathic appraisal and empathic expression perception refers to capturing users emotion state via facial expression recognition empathic appraisal is based on the computational emotional model for generating its internal emotions mood state and empathic responses the internal emotions are defined using psychological studies and generated on 2d pleasurearousal scaling model whereas fuzzy logic is used to calculate the intensity of the each emotion a virtual facial expression simulator is applied for expression of resultant empathic emotions preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors
Development of a Cloud-based Computational Framework for an Empathetic Robot,1,"Salaken, Syed Moshfeq; Nahavandi, Saeid; McGinn, Conor; Hossny, Mohammed; Kelly, Kevin; Abobakr, Ahmed; Nahavandi, Darius; Iskander, Julie",PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2019),2019,conferencePaper,978-1-4503-6287-0,,10.1145/3313991.3314018,,"This article presents the development and preliminary evaluation of an empathy controlled robot. Such a robot is one step forward towards industry 5.0, as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator. An inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs. The paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost, power consumption, and computational burden of the system. We propose that tasks requiring real-time and safety critical control are processed using dedicated on-board computers, whereas functionality dedicated to system optimization, machine learning and customization are handled through use a cloud-based platform. In this paper, key components of the architecture are defined, and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operator's voice is presented.",2019,2021-04-19T15:56:34Z,2021-04-19T15:56:34Z,,102-108,7,,,,,,International Conference on Computer and Automation Engineering,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,ISSN: 2154-4352 Type: Proceedings Paper,"<p>11th International Conference on Computer and Automation Engineering (ICCAE), Perth, AUSTRALIA, FEB 23-25, 2019</p>",,,,cloud control; deep learning; emotion classification; intent perception; robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,developmentofacloudbasedcomputationalframeworkforanempatheticrobot,development of a cloudbased computational framework for an empathetic robot this article presents the development and preliminary evaluation of an empathy controlled robot such a robot is one step forward towards industry 50 as it provides a theoretical framework to enable the performance of the robot to be customized to suit the needs of both the task as well as the operator an inventive step is taken through the separation of computational resources based on whether the algorithms are addressing functional or experiential needs the paper therefore addresses the requirement for new approaches that can be employed in the design of mobile robots to reduce cost power consumption and computational burden of the system we propose that tasks requiring realtime and safety critical control are processed using dedicated onboard computers whereas functionality dedicated to system optimization machine learning and customization are handled through use a cloudbased platform in this paper key components of the architecture are defined and the development and preliminary evaluation of an exemplar robot capable of changing its behavior in accordance with the perceived emotional state of an operators voice is presented
Good Robot Design or Machiavellian? An in-the-wild robot leveraging minimal knowledge of passersby's culture,6,"Sanoubari, Elaheh; Seo, Stela H.; Garcha, Diljot; Young, James E.; Loureiro-Rodriguez, Veronica",HRI `19: 2019 14TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION,2019,conferencePaper,978-1-5386-8555-6,,10.1109/HRI.2019.8673326,,"Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people ( changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?",2019,2021-04-19T15:56:37Z,2021-04-19T15:56:37Z,,382-391,10,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; IEEE; IEEE Robot & Automat Soc; ACM SIGCHI; ACM SIGAI; AAAI; Korea Tourism Org; Daegu Convent & Visitors Bur; ColorfulDaegu ISSN: 2167-2121 Type: Proceedings Paper,"<p>14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Daegu, SOUTH KOREA, MAR 11-14, 2019</p>",,,,culture; in the wild; persuasive robots; social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,goodrobotdesignormachiavelliananinthewildrobotleveragingminimalknowledgeofpassersbysculture,good robot design or machiavellian an inthewild robot leveraging minimal knowledge of passersbys culture social robots are being designed to use humanlike communication techniques including body language social signals and empathy to work effectively with people just as between people some robots learn about people and adapt to them in this paper we present one such robot design we developed sam a robot that learns minimal information about a persons background and adapts to this background our inthewild study found that people helped sam for significantly longer when it adapted to match their background while initially we saw this as a success in reconsidering our study we started seeing a different angle our robot effectively deceived people  changed its story and text based on some knowledge of their background to get more work from them there was little direct benefit to the person from this adaptation yet the robot stood to gain free labor we would like to pose the question to the community is this simply good robot design or is our robot being manipulative where does the ethical line lay between a robot leveraging social techniques to improve interaction and the more negative framing of a robot or algorithm taking advantage of people how can we decide what is good here and what is less desirable
Approaches for generating empathy: A systematic mapping,6,"Santos, B.S.; Júnior, M.C.; Nunes, M.A.S.N.",CEUR Workshop Proceedings,2018,conferencePaper,978-3-319-54977-4,,10.1007/978-3-319-54978-1_89,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045848351&doi=10.1007%2f978-3-319-54978-1_89&partnerID=40&md5=66e183f56f1d05e03864f6396a1ac24f,"Empathy plays an important role in social interactions, such an effective teaching-learning process in a teacher-student relationship, and company-client or employee-customer relationship to retain potential clients and provide them with greater satisfaction. Increasingly, people are using technology to support their interactions, especially when the interlocutors are geographically distant from one another. This has a negative impact on the empathic capacity of individuals. In the Computer Science, there are different approaches, techniques and mechanisms to promote empathy in social or human-computer interactions. Therefore, this article presents a systematic mapping to identify and systematize the approaches, techniques and mechanisms used in computing to promote empathy. As a result, we have identified existing approaches (e.g. collaborative learning environment, virtual and robotics agents, and collaborative/affective games) to promote empathy, the main areas involved (e.g. human-computer interaction, artificial intelligence, robotics, and collaborative systems), the top researchers and their affiliations who are potential contributors to future research and, finally, the growth status of this line of research. © Springer International Publishing AG 2018.",2018,2021-04-20T16:38:45Z,2021-04-20T16:38:45Z,,715-722,8,,558,,,,,,,,Springer Verlag,,English,,,,,,,ISSN: 21945357 Journal Abbreviation: Advances in Intelligent Systems and Computing,"<p>cited By 0; Conference of 2019 Papers of the Towards Conscious AI Systems Symposium, TOCAIS 2019 ; Conference Date: 25 March 2019 Through 27 March 2019; Conference Code:143406</p>; <p>cited By 5; Conference of 14th International Conference on Information Technology - New Generations, ITNG 2017 ; Conference Date: 10 April 2017 Through 12 April 2017; Conference Code:195369</p>",,,Collaborative learning environment; Collaborative systems; Computer aided instruction; Computer games; Computer supported cooperative work; Customer relationships; Customer satisfaction; Empathy; Human computer interaction; Human robot interaction; Mapping; Public relations; Rapport; Robotics; Secondary study; Social interactions; Systematic mapping studies; Teaching; Virtual reality,,"S, Latifi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,approachesforgeneratingempathyasystematicmapping,approaches for generating empathy a systematic mapping empathy plays an important role in social interactions such an effective teachinglearning process in a teacherstudent relationship and companyclient or employeecustomer relationship to retain potential clients and provide them with greater satisfaction increasingly people are using technology to support their interactions especially when the interlocutors are geographically distant from one another this has a negative impact on the empathic capacity of individuals in the computer science there are different approaches techniques and mechanisms to promote empathy in social or humancomputer interactions therefore this article presents a systematic mapping to identify and systematize the approaches techniques and mechanisms used in computing to promote empathy as a result we have identified existing approaches eg collaborative learning environment virtual and robotics agents and collaborativeaffective games to promote empathy the main areas involved eg humancomputer interaction artificial intelligence robotics and collaborative systems the top researchers and their affiliations who are potential contributors to future research and finally the growth status of this line of research  springer international publishing ag 2018
Development of a Pupil Response System with Empathy Expression in Face-to-Face Body Contact,1,"Sejima, Y.; Sato, Y.; Watanabe, T.",Advances in Intelligent Systems and Computing,2020,conferencePaper,,21945357,10.1007/978-3-030-20441-9_11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067292321&doi=10.1007%2f978-3-030-20441-9_11&partnerID=40&md5=fca96565406ecfbf207a0f55a1651a8b,"Pupil response is closely related to human affects and emotions. Focusing on the pupil response in human- robot interaction, we developed a pupil response interface using hemisphere displays for enhancing affective expression. This interface can generate pupil response like human by speech input and enhance affective expression. In this study, for the basic research of forming an intimate communication between human and pet-robot, we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device. Based on the analysis, we developed an advanced pupil response system for enhancing intimacy. This system generates the empathy expression when the talker touches any surface of hemisphere displays. The effectiveness of the system was confirmed experimentally. © 2020, Springer Nature Switzerland AG.",2020,2021-04-20T16:38:35Z,2021-04-20T16:38:35Z,,95-102,8,,952,,,,,,,,,,English,,,,,,,ISBN: 9783030204402 Publisher: Springer Verlag,"<p>cited By 0; Conference of AHFE International Conference on Affective and Pleasurable Design, 2019 ; Conference Date: 24 July 2019 Through 28 July 2019; Conference Code:226989</p>",,,Body contacts; Emotional expressions; Empathy; Face to face; Human robot interaction; Man machine systems; Measurement device; Non-verbal communications; Pet Robots; Pupil response,,"S, Fukuda",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,developmentofapupilresponsesystemwithempathyexpressioninfacetofacebodycontact,development of a pupil response system with empathy expression in facetoface body contact pupil response is closely related to human affects and emotions focusing on the pupil response in human robot interaction we developed a pupil response interface using hemisphere displays for enhancing affective expression this interface can generate pupil response like human by speech input and enhance affective expression in this study for the basic research of forming an intimate communication between human and petrobot we analyzed the pupil response during his or her body contact stroking forearm or head by using a pupil measurement device based on the analysis we developed an advanced pupil response system for enhancing intimacy this system generates the empathy expression when the talker touches any surface of hemisphere displays the effectiveness of the system was confirmed experimentally  2020 springer nature switzerland ag
Poor Thing! Would You Feel Sorry for a Simulated Robot? A comparison of empathy toward a physical and a simulated robot,74,"Seo, Stela H.; Geiskkovitch, Denise; Nakane, Masayuki; King, Corey; Young, James E.",PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION (HRI'15),2015,conferencePaper,978-1-4503-2882-1,,10.1145/2696454.2696471,,"In designing and evaluating human-robot interactions and interfaces, researchers often use a simulated robot due to the high cost of robots and time required to program them. However, it is important to consider how interaction with a simulated robot differs from a real robot; that is, do simulated robots provide authentic interaction? We contribute to a growing body of work that explores this question and maps out simulated-versus-real differences, by explicitly investigating empathy: how people empathize with a physical or simulated robot when something bad happens to it. Our results suggest that people may empathize more with a physical robot than a simulated one, a finding that has important implications on the generalizability and applicability of simulated HRI work. Empathy is particularly relevant to social HRI and is integral to, for example, companion and care robots. Our contribution additionally includes an original and reproducible HRI experimental design to induce empathy toward robots in laboratory settings, and an experimentally validated empathy-measuring instrument from psychology for use with HRI.",2015,2021-04-19T15:57:47Z,2021-04-19T15:57:47Z,,125-132,8,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot & Automat Soc; AAAI; HFES; ACM SIGAI ISSN: 2167-2121 Type: Proceedings Paper,"<p>10th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Portland, OR, MAR 02-05, 2015</p>",,,,empathy; Human-robot interaction; robot embodiment; simulated interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,poorthingwouldyoufeelsorryforasimulatedrobotacomparisonofempathytowardaphysicalandasimulatedrobot,poor thing would you feel sorry for a simulated robot a comparison of empathy toward a physical and a simulated robot in designing and evaluating humanrobot interactions and interfaces researchers often use a simulated robot due to the high cost of robots and time required to program them however it is important to consider how interaction with a simulated robot differs from a real robot that is do simulated robots provide authentic interaction we contribute to a growing body of work that explores this question and maps out simulatedversusreal differences by explicitly investigating empathy how people empathize with a physical or simulated robot when something bad happens to it our results suggest that people may empathize more with a physical robot than a simulated one a finding that has important implications on the generalizability and applicability of simulated hri work empathy is particularly relevant to social hri and is integral to for example companion and care robots our contribution additionally includes an original and reproducible hri experimental design to induce empathy toward robots in laboratory settings and an experimentally validated empathymeasuring instrument from psychology for use with hri
Evaluation of a Head Motion Synchronization System in the Communicative Process Between Human and Robot,0,"Sin, Yap Miao Robin; Liang, Qiao; Tani, Koyu; Ogawa, Ken-ichiro; Miyake, Yoshihiro",2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE),2016,conferencePaper,978-4-907764-50-0,,10.1109/SICE.2016.7749252,,"An aging population is world-wide social problem which affects many developed and developing countries. In this regard, many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia. However, these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered. In this research, therefore, we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot. This system was evaluated by conducting one-way face-to-face human-robot communication experiments with young native Japanese speakers under three conditions, namely unreactive, reactive and interactive conditions. Head motion synchrony analysis revealed a leader-follower relationship for the reactive model and a mutual entrainment of head motion for the interactive model. Also, questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions. In addition, the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition. Hence, these indicate that empathy was shared through mutual entrainment of head motion, which could provide a smooth interface in human-robot communication. This system would be extended to elderly adults as an assistive system for the elderly's rehabilitation.",2016,2021-04-19T15:57:20Z,2021-04-19T15:57:20Z,,1514-1519,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Type: Proceedings Paper,"<p>55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE), Tsukuba, JAPAN, SEP 20-23, 2016</p>",,,,Head motion synchronization; human-robot interaction; mutual entrainment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,evaluationofaheadmotionsynchronizationsysteminthecommunicativeprocessbetweenhumanandrobot,evaluation of a head motion synchronization system in the communicative process between human and robot an aging population is worldwide social problem which affects many developed and developing countries in this regard many social robots based on reactive system have been developed to provide companionship for elderly adults with neurocognitive impairments such as dementia however these systems remain a problem such that no interactive dynamics of body gestures between human and robot has been considered in this research therefore we developed a head motion synchronization system using mutual entrainment and implement it in a communication robot this system was evaluated by conducting oneway facetoface humanrobot communication experiments with young native japanese speakers under three conditions namely unreactive reactive and interactive conditions head motion synchrony analysis revealed a leaderfollower relationship for the reactive model and a mutual entrainment of head motion for the interactive model also questionnaire survey results showed the degree of empathy for interactive condition was significantly higher as compared with reactive and unreactive conditions in addition the degree of naturalness for interactive condition was significantly higher as compared with unreactive condition hence these indicate that empathy was shared through mutual entrainment of head motion which could provide a smooth interface in humanrobot communication this system would be extended to elderly adults as an assistive system for the elderlys rehabilitation
An Architecture for Telenoid Robot as Empathic Conversational Android Companion for Elderly People,9,"Sorbello, Rosario; Chella, Antonio; Giardina, Marcello; Nishio, Shuichi; Ishiguro, Hiroshi",IN℡LIGENT AUTONOMOUS SYSTEMS 13,2016,conferencePaper,978-3-319-08338-4 978-3-319-08337-7,,10.1007/978-3-319-08338-4_68,,"In Human-Humanoid Interaction (HHI), empathy is the crucial key in order to overcome the current limitations of social robots. In facts, a principal defining characteristic of human social behaviour is empathy. The present paper presents a robotic architecture for an android robot as a basis for natural empathic human-android interaction. We start from the hypothesis that the robots, in order to become personal companions need to know how to empathic interact with human beings. To validate our research, we have used the proposed system with the minimalistic humanoid robot Telenoid. We have conducted human-robot interactions test with elderly people with no prior interaction experience with robot. During the experiment, elderly persons engaged a stimulated conversation with the humanoid robot. Our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings. The experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user.",2016,2021-04-19T15:57:25Z,2021-04-19T15:57:25Z,,939-953,15,,302,,,,Advances in Intelligent Systems and Computing,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,Backup Publisher: Univ Padova ISSN: 2194-5357 Type: Proceedings Paper,"<p>13th International Conference on Intelligent Autonomous Systems (IAS), Centro Congressi Padova, Padova, ITALY, JUL 15-18, 2014</p>",,,,Humanoid robot; Humanoid robot interaction; Life support empathic robot; Telenoid,"Menegatti, E and Michael, N and Berns, K and Yamaguchi, H",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,anarchitecturefortelenoidrobotasempathicconversationalandroidcompanionforelderlypeople,an architecture for telenoid robot as empathic conversational android companion for elderly people in humanhumanoid interaction hhi empathy is the crucial key in order to overcome the current limitations of social robots in facts a principal defining characteristic of human social behaviour is empathy the present paper presents a robotic architecture for an android robot as a basis for natural empathic humanandroid interaction we start from the hypothesis that the robots in order to become personal companions need to know how to empathic interact with human beings to validate our research we have used the proposed system with the minimalistic humanoid robot telenoid we have conducted humanrobot interactions test with elderly people with no prior interaction experience with robot during the experiment elderly persons engaged a stimulated conversation with the humanoid robot our goal is to overcome the state of loneliness of elderly people using this minimalistic humanoid robot capable to exhibit a dialogue similar to what usually happens in real life between human beings the experimental results have shown a humanoid robotic system capable to exhibit a natural and empathic interaction and conversation with a human user
Study of Empathy on Robot Expression Based on Emotion Estimated from Facial Expression and Biological Signals,2,"Sripian, Peeraya; Kurono, Yuya; Yoshida, Reiji; Sugaya, Midori",2019 28TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2019,conferencePaper,978-1-72812-622-7,,10.1109/SICE.2016.7749252,,"Empathy, the ability to share the other's feeling, is one of the effective elements in promoting mutual reliability and construction of a good relationship. In order to create empathy between human-robot, a robot must be able to estimate the emotion of human and reflect the same emotion on its expression. In general, emotion can be estimated based on observable expressions such as facial expression, or unobservable expressions such as biological signals. Although there are many methods for measuring emotion from both facial expression and biological signals, few studies have been done on the comparison of estimated emotion. In this paper, we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot. Using our proposed emotion estimation system, we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion.",2019,2021-04-19T15:56:28Z,2021-04-19T15:56:28Z,,1-8,8,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE ISSN: 1944-9445 Type: Proceedings Paper,"<p>28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), New Delhi, INDIA, OCT 14-18, 2019</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,studyofempathyonrobotexpressionbasedonemotionestimatedfromfacialexpressionandbiologicalsignals,study of empathy on robot expression based on emotion estimated from facial expression and biological signals empathy the ability to share the others feeling is one of the effective elements in promoting mutual reliability and construction of a good relationship in order to create empathy between humanrobot a robot must be able to estimate the emotion of human and reflect the same emotion on its expression in general emotion can be estimated based on observable expressions such as facial expression or unobservable expressions such as biological signals although there are many methods for measuring emotion from both facial expression and biological signals few studies have been done on the comparison of estimated emotion in this paper we investigate whether emotion estimated from facial expression or biological signals could lead to empathy toward a robot using our proposed emotion estimation system we performed two experiments and found that higher impression was rated on sociability elements with significant when the reflected emotion is estimated from uncontrollable emotion
Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction,11,"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young",2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS),2018,conferencePaper,978-1-5386-8094-0,,10.1109/IROS.2018.8593974,,"Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.",2018,2021-04-19T15:56:49Z,2021-04-19T15:56:49Z,,2008-2013,6,,,,,,IEEE International Conference on Intelligent Robots and Systems,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper","<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>",,,,,"Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,emotionalbodilyexpressionsforculturallycompetentrobotsthroughlongtermhumanrobotinteraction,emotional bodily expressions for culturally competent robots through long term humanrobot interaction generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multiculture society in this paper we propose an incremental learning model for selecting the users representative or habitual emotional behaviors which place emphasis on individual users cultural traits identified through long term interaction furthermore a transformation model is proposed to convert the obtained emotional behaviors into a specific robots motion space to validate the proposed approach the models were evaluated by two example scenarios of interaction the experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users and to generate its emotional bodily expressions it was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator
Incremental Learning of Human Emotional Behavior for Social Robot Emotional Body Expression,1,"Tuyen, Nguyen Tan Viet; Jeong, Sungmoon; Chong, Nak Young",2018 15TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS (UR),2018,conferencePaper,978-1-5386-6334-9,,10.1109/URAI.2018.8441767,,"Generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in human-robot interaction. In this paper, an enhanced model of robot emotional body expression is proposed which places emphasis on the individual user's cultural traits. Similar to our previous paper, this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background. Social referencing occurs when infants perceive their parents' facial expressions and vocal tones of emotional situations to form their own interpretation. On the other hand, this model replaces the batch learning self-organizing map with the dynamic cell structure, incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts. We demonstrate the validity of our incremental learning model through a public human action dataset, which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual user's culture.",2018,2021-04-19T15:56:51Z,2021-04-19T15:56:51Z,,377-382,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Type: Proceedings Paper,"<p>15th International Conference on Ubiquitous Robots (UR), Honolulu, HI, JUN 26-30, 2018</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,incrementallearningofhumanemotionalbehaviorforsocialrobotemotionalbodyexpression,incremental learning of human emotional behavior for social robot emotional body expression generating emotional body expressions for social robots has been gaining increased attention to enhance the engagement and empathy in humanrobot interaction in this paper an enhanced model of robot emotional body expression is proposed which places emphasis on the individual users cultural traits similar to our previous paper this approach is inspired by social and emotional development of infants interacting with their parents who have a certain cultural background social referencing occurs when infants perceive their parents facial expressions and vocal tones of emotional situations to form their own interpretation on the other hand this model replaces the batch learning selforganizing map with the dynamic cell structure incrementally training a neural network model with a variety of emotional behaviors obtained from the users with whom the robot interacts we demonstrate the validity of our incremental learning model through a public human action dataset which will facilitate the acquisition of emotional body expression of socially assistive robots as a reflection of the individual users culture
Building a Collaborative Relationship between Human and Robot through Verbal and Non-Verbal Interaction,0,"Urakami, Jacqueline; Sutthithatip, Sujitra",Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction,2021,conferencePaper,978-1-4503-8290-8,,10.1145/3434074.3447171,https://doi.org/10.1145/3434074.3447171,"Interpersonal communication and relationship building promote successful collaborations. This study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partner.Participants interacted with two robots that differed in their nonverbal and verbal expressiveness. The interactive robot actively engaged the participant in a conversation before, during and after a collaborative task whereas the non-interactive robot remained passive. The robots' nonverbal and verbal interactions increased participants' perception of the robot as a social actor and strengthened bonding and relationship building between human and robot. The results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact, the robot is attributed a certain personality, and the robot is perceived as being alive.Our study could not show that an interactive robot receives more help by the collaboration partner. Future research should investigate additional factors that facilitate helpful behavior among humans, such as similarity, attributional judgement and empathy.",2021,2021-04-19T16:09:41Z,2021-04-19T16:09:41Z,,257–261,5,,,,,,HRI '21 Companion,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Boulder, CO, USA",,,,helping; human robot collaboration; relationship building; social presence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,buildingacollaborativerelationshipbetweenhumanandrobotthroughverbalandnonverbalinteraction,building a collaborative relationship between human and robot through verbal and nonverbal interaction interpersonal communication and relationship building promote successful collaborations this study investigated the effect of conversational nonverbal and verbal interactions of a robot on bonding and relationship building with a human partnerparticipants interacted with two robots that differed in their nonverbal and verbal expressiveness the interactive robot actively engaged the participant in a conversation before during and after a collaborative task whereas the noninteractive robot remained passive the robots nonverbal and verbal interactions increased participants perception of the robot as a social actor and strengthened bonding and relationship building between human and robot the results of our study indicate that the evaluation of the collaboration improves when the robot maintains eye contact the robot is attributed a certain personality and the robot is perceived as being aliveour study could not show that an interactive robot receives more help by the collaboration partner future research should investigate additional factors that facilitate helpful behavior among humans such as similarity attributional judgement and empathy
Real-time convolutional neural networks for emotion and gender classification,161,"Valdenegro-Toro, M.; Arriaga, O.; Plöger, P.G.","ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",2019,conferencePaper,978-2-87587-065-0,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071303529&partnerID=40&md5=0fdd5efbcd6ab93001268c0448fa2ad2,"Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification. © 2019 ESANN (i6doc.com). All rights reserved.",2019,2021-04-20T16:38:41Z,2021-04-20T16:38:41Z,,221-226,6,,,,,,,,,,ESANN (i6doc.com),,English,,,,,,,,"<p>cited By 6; Conference of 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2019 ; Conference Date: 24 April 2019 Through 26 April 2019; Conference Code:149793</p>",,,Computation time; Convolution; Convolutional neural network; Facial feature; Gender classification; Gender recognition; Machine learning; Neural networks; Open source license; Open systems; Real time; Real time evaluation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,realtimeconvolutionalneuralnetworksforemotionandgenderclassification,realtime convolutional neural networks for emotion and gender classification emotion and gender recognition from facial features are important properties of human empathy robots should also have these capabilities for this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters enabling realtime evaluation on a constrained platform we report accuracies of 96 in the imdb gender dataset and 66 in the fer2013 emotion dataset while requiring a computation time of less than 0008 seconds on a core i7 cpu all our code demos and pretrained architectures have been released under an opensource license in our repository at httpsgithubcomoarriagaface classification  2019 esann i6doccom all rights reserved
Empathy and Instrumentalization: Late Ancient Cultural Critique and the Challenge of Apparently Personal Robots,0,"Wales, J.J.",Frontiers in Artificial Intelligence and Applications,2020,conferencePaper,,9226389,10.3233/FAIA200906,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098851395&doi=10.3233%2fFAIA200906&partnerID=40&md5=aa8efae84b398531ac5e35d7454eee65,"According to a tradition that we hold variously today, the relational person lives most personally in affective and cognitive empathy, whereby we enter subjective communion with another person. Near future social AIs, including social robots, will give us this experience without possessing any subjectivity of their own. They will also be consumer products, designed to be subservient instruments of their users' satisfaction. This would seem inevitable. Yet we cannot live as personal when caught between instrumentalizing apparent persons (slaveholding) or numbly dismissing the apparent personalities of our instruments (mild sociopathy). This paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century North African philosopher and theologian, Augustine of Hippo, who is among those essential in giving us our understanding of relational persons. Augustine's semiotics, deeply intertwined with our affective life, suggest that, if we are to own persuasive social robots humanely, we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails, text messages, books, and bodily movements will have provided the training data for the behavior of near-future social AIs. So doing, we may see simulation as simulation (albeit persuasive), while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation. If we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy, we will suborn the sign to ourselves, undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons. © 2020 The authors and IOS Press. All rights reserved.",2020,2021-04-20T16:38:29Z,2021-04-20T16:38:29Z,,114-124,11,,335,,,,,,,,,,English,,,,,,,ISBN: 9781643681542 Publisher: IOS Press BV,<p>cited By 0; Conference of 4th Conference on Robophilosophy 2020: Culturally Sustainable Social Robotics ; Conference Date: 18 August 2020 Through 21 August 2020; Conference Code:165874</p>,,,Augustine; Bodily movement; Consumer products; Educational robots; Instrumentalization; Personal robot; Philosophical aspects; Robotics; Social robots; Training data; Users' satisfactions,,"Norskov M., Quick O.S., Seibt J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empathyandinstrumentalizationlateancientculturalcritiqueandthechallengeofapparentlypersonalrobots,empathy and instrumentalization late ancient cultural critique and the challenge of apparently personal robots according to a tradition that we hold variously today the relational person lives most personally in affective and cognitive empathy whereby we enter subjective communion with another person near future social ais including social robots will give us this experience without possessing any subjectivity of their own they will also be consumer products designed to be subservient instruments of their users satisfaction this would seem inevitable yet we cannot live as personal when caught between instrumentalizing apparent persons slaveholding or numbly dismissing the apparent personalities of our instruments mild sociopathy this paper analyzes and proposes a step toward ameliorating this dilemma by way of the thought of a 5th century north african philosopher and theologian augustine of hippo who is among those essential in giving us our understanding of relational persons augustines semiotics deeply intertwined with our affective life suggest that if we are to own persuasive social robots humanely we must join our instinctive experience of empathy for them to an empathic acknowledgment of the real unknown relational persons whose emails text messages books and bodily movements will have provided the training data for the behavior of nearfuture social ais so doing we may see simulation as simulation albeit persuasive while expanding our empathy to include those whose refracted behavioral moments are the seedbed of this simulation if we naïvely stop at the social robot as the ultimate object of our cognitive and affective empathy we will suborn the sign to ourselves undermining rather than sustaining a culture that prizes empathy and abhors the instrumentalization of persons  2020 the authors and ios press all rights reserved
He who hesitates is lost (...in thoughts over a robot),10,"Wen, James; Stewart, Amanda; Billinghurst, Mark; Dey, Arindam; Tossell, Chad; Finomore, Victor","PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18)",2018,conferencePaper,978-1-4503-5420-2,,10.1145/3183654.3183703,,"In a team, the strong bonds that can form between teammates are often seen as critical for reaching peak performance. This perspective may need to be reconsidered, however, if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive. Previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions. As relationships extend over long periods of time, sustained empathic behavior towards robots would be of interest. In order to measure user actions that may vary over time and are affected by empathy towards a robot teammate, we created the TEAMMATE simulation system. Our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time. The results of our study can have strong implications for the overall performance of human machine teams.",2018,2021-04-19T15:56:48Z,2021-04-19T15:56:48Z,,1-6,6,,,,,,,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Amer Psychol Assoc Type: Proceedings Paper,"<p>Technology, Mind, and Society Conference (TechMindSociety), Washington, DC, APR 05-07, 2018</p>",,,,Anthropomorphism; Empathy; Human Machine Team; Robotics; User Study,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,hewhohesitatesislostinthoughtsoverarobot,he who hesitates is lost in thoughts over a robot in a team the strong bonds that can form between teammates are often seen as critical for reaching peak performance this perspective may need to be reconsidered however if some team members are autonomous robots since establishing bonds with fundamentally inanimate and expendable objects may prove counterproductive previous work has measured empathic responses towards robots as singular events at the conclusion of experimental sessions as relationships extend over long periods of time sustained empathic behavior towards robots would be of interest in order to measure user actions that may vary over time and are affected by empathy towards a robot teammate we created the teammate simulation system our findings suggest that inducing empathy through a back story narrative can significantly change participant decisions in actions that may have consequences for a robot companion over time the results of our study can have strong implications for the overall performance of human machine teams
Band of Brothers and Bolts: Caring About Your Robot Teammate,3,"Wen, James; Stewart, Amanda; Billinghurst, Mark; Tossell, Chad",2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON IN℡LIGENT ROBOTS AND SYSTEMS (IROS),2018,conferencePaper,978-1-5386-8094-0,,10.1109/IROS.2018.8594324,,It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.,2018,2021-04-19T15:56:49Z,2021-04-19T15:56:49Z,,1853-1858,6,,,,,,IEEE International Conference on Intelligent Robots and Systems,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,"Backup Publisher: IEEE Robot & Automat Soc; IEEE Ind Elect Soc; Robot Soc Japan; Soc Instrument & Control Engineers; New Technol Fdn; IEEE; Adept MobileRobots; Willow Garage; Aldebaran Robot; Natl Instruments; Reflexxes GmbH; Schunk Intec S L U; Univ Carlos III Madrid; BOSCH; JD COM; Pal Robot; KUKA; Santander; Squirrel AI Learning; Baidu; Generat Robots; KINOVA Robot; Ouster; Univ Pablo Olavide Sevilla; Rapyuta Robot; SICK; TOYOTA; UP; Amazon; ARGO; Built Robot; Disney Res; Easy Mile; Hitachi; Robot; Khalifa Univ; Magazino; MathWorks; New Dexterity; Schunk; nuTonomy; PILZ; Prophesee; Rootnik; Saga Robot; Shadow; Soft Bank Robot; Anyverse; GalTech; Generat Robot; IEEE CAA Journal Automatica Sinica; Sci Robot, AAAS; TERAS ISSN: 2153-0858 Type: Proceedings Paper","<p>25th IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, SPAIN, OCT 01-05, 2018</p>",,,,,"Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,bandofbrothersandboltscaringaboutyourrobotteammate,band of brothers and bolts caring about your robot teammate it has been observed that a robot shown as suffering is enough to cause an empathic response from a person whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern we report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion our findings suggest that induced empathy can in fact have a significant impact on a persons behavior to the extent that the ability to fulfill a mission may be affected
A New Chatbot for Customer Service on Social Media,299,"Xu, Anbang; Liu, Zhe; Guo, Yufan; Sinha, Vibha; Akkiraju, Rama",PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17),2017,conferencePaper,978-1-4503-4655-9,,10.1145/3025453.3025496,,"Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.",2017,2021-04-19T15:57:03Z,2021-04-19T15:57:03Z,,3506-3510,5,,,,,,,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper,"<p>ACM SIGCHI Conference on Human Factors in Computing Systems (CHI), Denver, CO, MAY 06-11, 2017</p>",,,,Chatbot; customer service; deep learning; social media,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,anewchatbotforcustomerserviceonsocialmedia,a new chatbot for customer service on social media users are rapidly turning to social media to request and receive customer service however a majority of these requests were not addressed timely or even not addressed at all to overcome the problem we create a new conversational system to automatically generate responses for users requests on social media our system is integrated with stateoftheart deep learning techniques and is trained by nearly 1m twitter conversations between users and agents from over 60 brands the evaluation reveals that over 40 of the requests are emotional and the system is about as good as human agents in showing empathy to help users cope with emotional situations results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric
Personality traits assessment using P.A.D. Emotional space in human-robot interaction,0,"Zafar, Z.; Ashok, A.; Berns, K.","VISIGRAPP 2021 - Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",2021,conferencePaper,978-989-758-488-6,,10.5220/0010161801110118,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974518&partnerID=40&md5=579d9d515e2e418c556711a934135b57,"Cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings. Humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish human-human interaction. Similarly, assessment of human personality is highly critical in realizing natural and intelligent human-robot interaction. Numerous personality traits assessment systems have been reported in the literature; however, most of them target the big five personality traits. From only visual information, this work proposes to use pleasure, arousal, and dominance emotional space for the assessment of personality traits based on the work of Mehrabian. To validate the system, three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot. Experimental results show that the system can assess human personality traits with 84% accuracy in real-time and, hence, it can adapt its behavior according to the perceived personality of the interaction partner. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",2021,2021-04-20T16:38:29Z,2021-04-20T16:38:29Z,,111-118,8,,2,,,,,,,,SciTePress,,English,,,,,,,,"<p>cited By 0; Conference of 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2021 ; Conference Date: 8 February 2021 Through 10 February 2021; Conference Code:167535</p>",,,Anthropomorphic robots; Assessment system; Computer graphics; Computer vision; Human being; Human-human interactions; Humanoid robot; Man machine systems; Personality traits; Real time; Social robotics; Social robots; Visual information,,"Paljic A., Bouatouch K., Peck T., Braz J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,personalitytraitsassessmentusingpademotionalspaceinhumanrobotinteraction,personality traits assessment using pad emotional space in humanrobot interaction cognitive social robotics is the field of research that is committed to building social robots that facilitate to draw parallels with human beings humans assess the behavior and personality of their counterparts to adapt their behavior and show empathy to flourish humanhuman interaction similarly assessment of human personality is highly critical in realizing natural and intelligent humanrobot interaction numerous personality traits assessment systems have been reported in the literature however most of them target the big five personality traits from only visual information this work proposes to use pleasure arousal and dominance emotional space for the assessment of personality traits based on the work of mehrabian to validate the system three different scenarios have been developed to assess 12 different personality traits on a social humanoid robot experimental results show that the system can assess human personality traits with 84 accuracy in realtime and hence it can adapt its behavior according to the perceived personality of the interaction partner copyright  2021 by scitepress  science and technology publications lda all rights reserved
User Experience Study: The Service Expectation of Hotel Guests to the Utilization of AI-Based Service Robot in Full-Service Hotels,5,"Zhang, Y.; Qi, S.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019,conferencePaper,,3029743,10.1007/978-3-030-22335-9_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069831658&doi=10.1007%2f978-3-030-22335-9_24&partnerID=40&md5=3e80fc2d1eb7b32d188423262f9c2825,"With the dramatic development of AI technology, the concept of robotic hotel is entering the public’s awareness. Although AI application brings in high efficiency, low labor cost and novelty, practical operation of robotic hotels still faces with challenges. This quantitative research aims at understanding the current user expectation level of AI robotic hotel and robot appliance. Based on that, it tries to make the user classification by demographic, behavioral and attitude factors. By using the refined SERVQUAL model, it gathers the expectation from five dimensions involving tangibles, reliability, responsiveness, assurance and empathy. These research objectives were realized by using survey-designed questionnaires and distributed by a snowball sampling method conducted in Beijing. After validity and reliability test, data collected from the field were analyzed by a variety of inspections. It is found that education, attitude and income level have a significant effect on the expectation to stay in the robotic hotel, which provided the basis of market position for robotic hotel operators. Through regression analysis, the model was established to identify what factors played an important part and how they worked. It is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels. This thesis drew up several conclusions, which would help industry players including hoteliers, AI robot suppliers better understand details of the user group in their decision-making process, as well as academic side to formulate a tailored model to evaluate the interaction between AI robots and hotel guests. © 2019, Springer Nature Switzerland AG.",2019,2021-04-20T16:38:42Z,2021-04-20T16:38:42Z,,350-366,17,,11588 LNCS,,,,,,,,,,English,,,,,,,ISBN: 9783030223342 Publisher: Springer Verlag,"<p>cited By 2; Conference of 6th International Conference on HCI in Business, Government, and Organizations, HCIBGO 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019 ; Conference Date: 26 July 2019 Through 31 July 2019; Conference Code:228649</p>",,,Consumer behavior; Decision making; Decision making process; Hospitality; Hotels; Human computer interaction; Quality of service; Quantitative research; Regression analysis; Research objectives; Robotics; Robots; Service expectations; Service quality management; Surveys; User classification; User experience; User interfaces; Wages,,"Nah F.F.-H., Siau K.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,userexperiencestudytheserviceexpectationofhotelgueststotheutilizationofaibasedservicerobotinfullservicehotels,user experience study the service expectation of hotel guests to the utilization of aibased service robot in fullservice hotels with the dramatic development of ai technology the concept of robotic hotel is entering the publics awareness although ai application brings in high efficiency low labor cost and novelty practical operation of robotic hotels still faces with challenges this quantitative research aims at understanding the current user expectation level of ai robotic hotel and robot appliance based on that it tries to make the user classification by demographic behavioral and attitude factors by using the refined servqual model it gathers the expectation from five dimensions involving tangibles reliability responsiveness assurance and empathy these research objectives were realized by using surveydesigned questionnaires and distributed by a snowball sampling method conducted in beijing after validity and reliability test data collected from the field were analyzed by a variety of inspections it is found that education attitude and income level have a significant effect on the expectation to stay in the robotic hotel which provided the basis of market position for robotic hotel operators through regression analysis the model was established to identify what factors played an important part and how they worked it is found that tangibles and responsiveness expectation significantly and positively contributed to increases in general user expectation to robotic hotels this thesis drew up several conclusions which would help industry players including hoteliers ai robot suppliers better understand details of the user group in their decisionmaking process as well as academic side to formulate a tailored model to evaluate the interaction between ai robots and hotel guests  2019 springer nature switzerland ag
Affective Embodied Agents and Their Effect on Decision Making,0,"A Acosta-Mitjans, D Cruz-Sandoval, R Hervas…",Proceedings,2019,journalArticle,,2504-3900,10.3390/proceedings2019031071,,"Embodied agents, such as avatars and social robots, are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor. This influences how users perceive these technologies and how they interact with them. We report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being. Twenty-one individuals were asked to play the ultimatum game, playing the role of a responder against another person, a computer, an avatar and a robot for a total of 32 games (8 per condition). We hypothesize that affective expressions by avatars and robots influence the emotional state of the users, leading them to irrational behavior by rejecting unfair proposals. We monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder. Our results show that most fair offers were accepted while most unfair offers were rejected. However, participants rejected more very unfair offers made by people and computers than by the avatars or robots.",2019,2021-04-20T16:56:57Z,2021-04-20T16:56:57Z,,,,1,31,,,,,,,,,,English,,,,,Open WorldCat,,OCLC: 8464672719,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,affectiveembodiedagentsandtheireffectondecisionmaking,affective embodied agents and their effect on decision making embodied agents such as avatars and social robots are increasingly incorporating a capacity to enact affective states and recognize the mood of their interlocutor this influences how users perceive these technologies and how they interact with them we report on an experiment aimed at assessing perceived empathy and fairness among individuals interacting with avatars and robots when compared to playing against a computer or a fellow human being twentyone individuals were asked to play the ultimatum game playing the role of a responder against another person a computer an avatar and a robot for a total of 32 games 8 per condition we hypothesize that affective expressions by avatars and robots influence the emotional state of the users leading them to irrational behavior by rejecting unfair proposals we monitored galvanic skin response and heart rate of the players in the period when the offer was made by the proposer until the decision was announced by the responder our results show that most fair offers were accepted while most unfair offers were rejected however participants rejected more very unfair offers made by people and computers than by the avatars or robots
"You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human-Robot Interaction",49,"Abubshait, Abdulaziz; Wiese, Eva",FRONTIERS IN PSYCHOLOGY,2017,journalArticle,,1664-1078,10.3389/fpsyg.2017.01393,,"Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human-robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human-robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human-robot interaction. The results show that both appearance and behavior affect human-robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human-robot interaction are discussed.",2017-08-23,2021-04-19T15:57:00Z,2021-04-19T15:57:00Z,,,,,8,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,human-robot interaction; intentionality; mind perception; social cognition; social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,youlookhumanbutactlikeamachineagentappearanceandbehaviormodulatedifferentaspectsofhumanrobotinteraction,you look human but act like a machine agent appearance and behavior modulate different aspects of humanrobot interaction gaze following occurs automatically in social interactions but the degree to which gaze is followed depends on whether an agent is perceived to have a mind making its behavior socially more relevant for the interaction mind perception also modulates the attitudes we have toward others and determines the degree of empathy prosociality and morality invested in social interactions seeing mind in others is not exclusive to human agents but mind can also be ascribed to nonhuman agents like robots as long as their appearance andor behavior allows them to be perceived as intentional beings previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents and positively affect attitudes and performance in humanrobot interaction what has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in humanrobot interaction we examine this question by manipulating agent appearance human vs robot and behavior reliable vs random within the same paradigm and examine how congruent humanreliable vs robotrandom versus incongruent humanrandom vs robotreliable combinations of these triggers affect performance ie gaze following and attitudes ie agent ratings in humanrobot interaction the results show that both appearance and behavior affect humanrobot interaction but that the two triggers seem to operate in isolation with appearance more strongly impacting attitudes and behavior more strongly affecting performance the implications of these findings for humanrobot interaction are discussed
Empathic Robot for Group Learning: A Field Study,28,"Alves-Oliveira, Patricia; Sequeira, Pedro; Melo, Francisco S.; Castellano, Ginevra; Paiva, Ana",ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION,2019,journalArticle,,,10.1145/3300188,,"This work explores a group learning scenario with an autonomous empathic robot. We address two research questions: (1) Can an autonomous robot designed with empathic competencies foster collaborative learning in a group context? (2) Can an empathic robot sustain positive educational outcomes in long-term collaborative learning interactions with groups of students? To answer these questions, we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development. Two studies were conducted. The first study compares learning outcomes in children across three conditions: learning with an empathic robot; learning with a robot without empathic capabilities; and learning without a robot. The results show that the autonomous robot with empathy fosters meaningful discussions about sustainability, which is a learning outcome in sustainability education. The second study features groups of students who interact with the robot in a school classroom for 2 months. The long-term educational interaction did not seem to provide significant learning gains, although there was a change in game-actions to achieve more sustainability during game-play. This result reflects the need to perform more long-term research in the field of educational robots for group learning.",2019-03,2021-04-19T15:56:23Z,2021-04-19T15:56:23Z,,,,1,8,,,,,,,,,,English,,,,,,,"Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article",,,,,collaborative learning; education; empathy; group learning; human-robot interaction; learning gains; Social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empathicrobotforgrouplearningafieldstudy,empathic robot for group learning a field study this work explores a group learning scenario with an autonomous empathic robot we address two research questions 1 can an autonomous robot designed with empathic competencies foster collaborative learning in a group context 2 can an empathic robot sustain positive educational outcomes in longterm collaborative learning interactions with groups of students to answer these questions we developed an autonomous robot with empathic competencies that is able to interact with a group of students in a learning activity about sustainable development two studies were conducted the first study compares learning outcomes in children across three conditions learning with an empathic robot learning with a robot without empathic capabilities and learning without a robot the results show that the autonomous robot with empathy fosters meaningful discussions about sustainability which is a learning outcome in sustainability education the second study features groups of students who interact with the robot in a school classroom for 2 months the longterm educational interaction did not seem to provide significant learning gains although there was a change in gameactions to achieve more sustainability during gameplay this result reflects the need to perform more longterm research in the field of educational robots for group learning
Is it the real deal? Perception of virtual characters versus humans: an affective cognitive neuroscience perspective,62,"AW de Borst, B de Gelder",Frontiers in Psychology,2015,journalArticle,,1664-1078,10.3389/fpsyg.2015.00576,,"Recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film, animations, or androids. These stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control. While avatars and androids are well suited to study human cognition, they should not be equated to human stimuli. For example, the Uncanny Valley hypothesis theorizes that artificial agents with high human-likeness may evoke feelings of eeriness in the human observer. Here we review if, when, and how the perception of human-like avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies. First, we discuss how the appearance of virtual characters affects perception. When stimuli are morphed across categories from non-human to human, the most ambiguous stimuli, rather than the most human-like stimuli, show prolonged classification times and increased eeriness. Human-like to human stimuli show a positive linear relationship with familiarity. Secondly, we show that expressions of emotions in human-like avatars can be perceived similarly to human emotions, with corresponding behavioral, physiological and neuronal activations, with exception of physical dissimilarities. Subsequently, we consider if and when one perceives differences in action representation by artificial agents versus humans. Motor resonance and predictive coding models may account for empirical findings, such as an interference effect on action for observed human-like, natural moving characters. However, the expansion of these models to explain more complex behavior, such as empathy, still needs to be investigated in more detail. Finally, we broaden our outlook to social interaction, where virtual reality stimuli can be utilized to imitate complex social situations.",2015,2021-04-20T16:55:36Z,2021-04-20T16:55:36Z,,,,,,,,Is it the real deal?,,,,,,,English,,,,,Open WorldCat,,OCLC: 7181321693,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,isittherealdealperceptionofvirtualcharactersversushumansanaffectivecognitiveneuroscienceperspective,is it the real deal perception of virtual characters versus humans an affective cognitive neuroscience perspective recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film animations or androids these stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control while avatars and androids are well suited to study human cognition they should not be equated to human stimuli for example the uncanny valley hypothesis theorizes that artificial agents with high humanlikeness may evoke feelings of eeriness in the human observer here we review if when and how the perception of humanlike avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies first we discuss how the appearance of virtual characters affects perception when stimuli are morphed across categories from nonhuman to human the most ambiguous stimuli rather than the most humanlike stimuli show prolonged classification times and increased eeriness humanlike to human stimuli show a positive linear relationship with familiarity secondly we show that expressions of emotions in humanlike avatars can be perceived similarly to human emotions with corresponding behavioral physiological and neuronal activations with exception of physical dissimilarities subsequently we consider if and when one perceives differences in action representation by artificial agents versus humans motor resonance and predictive coding models may account for empirical findings such as an interference effect on action for observed humanlike natural moving characters however the expansion of these models to explain more complex behavior such as empathy still needs to be investigated in more detail finally we broaden our outlook to social interaction where virtual reality stimuli can be utilized to imitate complex social situations
Development and Testing of Psychological Conflict Resolution Strategies for Assertive Robots to Resolve Human-Robot Goal Conflict,0,"Babel, Franziska; Kraus, Johannes M.; Baumann, Martin",FRONTIERS IN ROBOTICS AND AI,2021,journalArticle,,2296-9144,10.3389/frobt.2020.591448,,"As service robots become increasingly autonomous and follow their own task-related goals, human-robot conflicts seem inevitable, especially in shared spaces. Goal conflicts can arise from simple trajectory planning to complex task prioritization. For successful human-robot goal-conflict resolution, humans and robots need to negotiate their goals and priorities. For this, the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user. In this paper, conflict resolution strategies for service robots (public cleaning robot, home assistant robot) are developed by transferring psychological concepts (e.g., negotiation, cooperation) to HRI. Altogether, fifteen strategies were grouped by the expected affective outcome (positive, neutral, negative). In two online experiments, the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts (public: n(1) = 61; private: n(2) = 93). To obtain a comparative value, the strategies were also applied by a human. As additional outcomes trust, fear, arousal, and valence, as well as perceived politeness of the agent were assessed. The positive/neutral strategies were found to be more acceptable and effective than negative strategies. Some negative strategies (i.e., threat, command) even led to reactance and fear. Some strategies were only positively evaluated and effective for certain agents (human or robot) or only acceptable in one of the two application contexts (i.e., approach, empathy). Influences on strategy acceptance and compliance in the public context could be found: acceptance was predicted by politeness and trust. Compliance was predicted by interpersonal power. Taken together, psychological conflict resolution strategies can be applied in HRI to enhance robot task effectiveness. If applied robot-specifically and context-sensitively they are accepted by the user. The contribution of this paper is twofold: conflict resolution strategies based on Human Factors and Social Psychology are introduced and empirically evaluated in two online studies for two application contexts. Influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed.",2021-01-26,2021-04-19T15:56:00Z,2021-04-19T15:56:00Z,,,,,7,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,acceptance; HRI strategies; persuasive robots; robot assertiveness; trust; user compliance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,developmentandtestingofpsychologicalconflictresolutionstrategiesforassertiverobotstoresolvehumanrobotgoalconflict,development and testing of psychological conflict resolution strategies for assertive robots to resolve humanrobot goal conflict as service robots become increasingly autonomous and follow their own taskrelated goals humanrobot conflicts seem inevitable especially in shared spaces goal conflicts can arise from simple trajectory planning to complex task prioritization for successful humanrobot goalconflict resolution humans and robots need to negotiate their goals and priorities for this the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user in this paper conflict resolution strategies for service robots public cleaning robot home assistant robot are developed by transferring psychological concepts eg negotiation cooperation to hri altogether fifteen strategies were grouped by the expected affective outcome positive neutral negative in two online experiments the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts public n1  61 private n2  93 to obtain a comparative value the strategies were also applied by a human as additional outcomes trust fear arousal and valence as well as perceived politeness of the agent were assessed the positiveneutral strategies were found to be more acceptable and effective than negative strategies some negative strategies ie threat command even led to reactance and fear some strategies were only positively evaluated and effective for certain agents human or robot or only acceptable in one of the two application contexts ie approach empathy influences on strategy acceptance and compliance in the public context could be found acceptance was predicted by politeness and trust compliance was predicted by interpersonal power taken together psychological conflict resolution strategies can be applied in hri to enhance robot task effectiveness if applied robotspecifically and contextsensitively they are accepted by the user the contribution of this paper is twofold conflict resolution strategies based on human factors and social psychology are introduced and empirically evaluated in two online studies for two application contexts influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed
An Autonomous Cognitive Empathy Model Responsive to Users' Facial Emotion Expressions,2,"Bagheri, Elahe; Esteban, Pablo G.; Cao, Hoang-Long; De Beir, Albert; Lefeber, Dirk; Vanderborght, Bram",ACM TRANSACTIONS ON INTERACTIVE IN℡LIGENT SYSTEMS,2020,journalArticle,,2160-6455,10.1145/3341198,,"Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user's affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans' emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user's personality. Users' affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.",2020-11,2021-04-19T15:56:03Z,2021-04-19T15:56:03Z,,,,"3, SI",10,,,,,,,,,,English,,,,,,,"Place: 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA Publisher: ASSOC COMPUTING MACHINERY Type: Article",,,,,adaptive interaction; Empathy; facial emotion detection; human robot interaction; non-verbal behavior; social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,anautonomouscognitiveempathymodelresponsivetousersfacialemotionexpressions,an autonomous cognitive empathy model responsive to users facial emotion expressions successful social robot services depend on how robots can interact with users the effective service can be obtained through smooth engaged and humanoid interactions in which robots react properly to a users affective state this article proposes a novel automatic cognitive empathy model acem for humanoid robots to achieve longer and more engaged humanrobot interactions hri by considering humans emotions and replying to them appropriately the proposed model continuously detects the affective states of a user based on facial expressions and generates desired either parallel or reactive empathic behaviors that are already adapted to the users personality users affective states are detected using a stacked autoencoder network that is trained and tested on the ravdess dataset the overall proposed empathic model is verified throughout an experiment where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis the results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot
A Reinforcement Learning Based Cognitive Empathy Framework for Social Robots,0,"Bagheri, Elahe; Roesler, Oliver; Cao, Hoang-Long; Vanderborght, Bram",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2020,journalArticle,,1875-4791,10.1007/s12369-020-00683-4,,"Robots that express human's social norms, like empathy, are perceived as more friendly, understanding, and caring. However, appropriate human-like empathic behaviors cannot be defined in advance, instead, they must be learned through daily interaction with humans in different situations. Additionally, to learn and apply the correct behaviors, robots must be able to perceive and understand the affective states of humans. This study presents a framework to enable cognitive empathy in social robots, which uses facial emotion recognition to perceive and understand the affective states of human users. The perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states. The proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot Pepper. The results show that by applying empathic behaviors selected by the employed learning model, the robot is able to provide participants comfort and confidence and help them enjoy and feel better.",,2021-04-19T15:56:05Z,2021-04-19T15:56:05Z,,,,,,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access",,,,,Empathy; Human-robot interaction; Personality; Reinforcement learning; Social robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,areinforcementlearningbasedcognitiveempathyframeworkforsocialrobots,a reinforcement learning based cognitive empathy framework for social robots robots that express humans social norms like empathy are perceived as more friendly understanding and caring however appropriate humanlike empathic behaviors cannot be defined in advance instead they must be learned through daily interaction with humans in different situations additionally to learn and apply the correct behaviors robots must be able to perceive and understand the affective states of humans this study presents a framework to enable cognitive empathy in social robots which uses facial emotion recognition to perceive and understand the affective states of human users the perceived affective state is then provided to a reinforcement learning model to enable a robot to learn the most appropriate empathic behaviors for different states the proposed framework has been evaluated through an experiment between 28 individual humans and the humanoid robot pepper the results show that by applying empathic behaviors selected by the employed learning model the robot is able to provide participants comfort and confidence and help them enjoy and feel better
humanly space objects—perception and connection with the observer,11,"Balint, Tibor S.; Hall, Ashley",Acta Astronautica,2015,journalArticle,,0094-5765,https://doi.org/10.1016/j.actaastro.2015.01.010,https://www.sciencedirect.com/science/article/pii/S0094576515000144,"expanding humanity into space is an inevitable step in our quest to explore our world. yet space exploration is costly, and the awaiting environment challenges us with extreme cold, heat, vacuum and radiation, unlike anything encountered on earth. thus, the few pioneers who experience it needed to be well protected throughout their spaceflight. the resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life. such connections may occur via sensory inputs, namely vision, touch, sound, smell, and taste. this then follows the process of sensing, interpreting, and recognizing familiar patterns, or learning from new experiences. the desire to connect could even transfer to observed objects, if their movements and characteristics trigger the appropriate desires from the observer. when ordered in a familiar way, for example visual stimuli from lights and movements of an object, it may create a perceived real bond with an observer, and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable. these behavior patterns can be designed into an object and performed autonomously in front of an observer, in our case an astronaut. the experience may introduce multiple responses, including communication, connection, empathy, order, and disorder. while emotions are clearly evoked in the observer and may seem one sided, in effect the object itself provides a decoupled bond, connectivity and communication between the observer and the artist-designer of the object. in this paper we will discuss examples from the field of arts and other domains, including robotics, where human perception through object interaction was explored, and investigate the starting point for new innovative design concepts and future prototype designs, that extend these experiences beyond the boundaries of earth, while taking advantage of remoteness and the zero gravity environment. through a form of emotional connection and design, these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a co-located observer in spaceflight. we conclude that beyond providing creative expressions for humanly contacts, these experiences may also provide further insights into human perception in spaceflight, and could be tested on the international space station, and serve as a stepping-stone towards use on long-duration spaceflight to mars.",2015,2021-04-19T16:20:49Z,2021-04-19T16:20:49Z,,129-144,16,,110,,,,,,,,,,,,,,,,,,<p>Dynamics and Control of Space Systems</p>,,,Affordances; Art; Cognition; Cybernetics; Design; Perception; Tacit-knowledge,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,humanlyspaceobjectsperceptionandconnectionwiththeobserver,humanly space objectsperception and connection with the observer expanding humanity into space is an inevitable step in our quest to explore our world yet space exploration is costly and the awaiting environment challenges us with extreme cold heat vacuum and radiation unlike anything encountered on earth thus the few pioneers who experience it needed to be well protected throughout their spaceflight the resulting isolation heightens the senses and increases the desire to make humanly connections with any other perceived manifestation of life such connections may occur via sensory inputs namely vision touch sound smell and taste this then follows the process of sensing interpreting and recognizing familiar patterns or learning from new experiences the desire to connect could even transfer to observed objects if their movements and characteristics trigger the appropriate desires from the observer when ordered in a familiar way for example visual stimuli from lights and movements of an object it may create a perceived real bond with an observer and evoke the feeling of surprise when the expected behavior changes to something no longer predictable or recognizable these behavior patterns can be designed into an object and performed autonomously in front of an observer in our case an astronaut the experience may introduce multiple responses including communication connection empathy order and disorder while emotions are clearly evoked in the observer and may seem one sided in effect the object itself provides a decoupled bond connectivity and communication between the observer and the artistdesigner of the object in this paper we will discuss examples from the field of arts and other domains including robotics where human perception through object interaction was explored and investigate the starting point for new innovative design concepts and future prototype designs that extend these experiences beyond the boundaries of earth while taking advantage of remoteness and the zero gravity environment through a form of emotional connection and design these concepts will focus on the connection and brief emotional bond between a humanly animate object in space and a colocated observer in spaceflight we conclude that beyond providing creative expressions for humanly contacts these experiences may also provide further insights into human perception in spaceflight and could be tested on the international space station and serve as a steppingstone towards use on longduration spaceflight to mars
Socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot,11,"Barakova, E. I.; De Haas, M.; Kuijpers, W.; Irigoyen, N.; Betancourt, A.",CONNECTION SCIENCE,2018,journalArticle,,0954-0091,10.1080/09540091.2017.1350938,,"In search for better technological solutions for education, we adapted a principle from economic game theory, namely that giving a help will promote collaboration and eventually long-term relations between a robot and a child. This principle has been shown to be effective in games between humans and between humans and computer agents. We compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer. We found that by combining the social and game strategy the children (average age of 8.3 years) had more empathy and social engagement with the robot since the children did not want to necessarily win against it. This finding is promising for using social strategies for the creation of long-term relations between robots and children and making educational tasks more engaging. An additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game - the game with the robot was seen as more challenging and the robot - as a smarter opponent. This finding might be due to the higher perceived or expected intelligence from the robot, or because of the higher complexity of seeing patterns in three-dimensional world.",2018,2021-04-19T15:56:53Z,2021-04-19T15:56:53Z,,81-98,18,"1, SI",30,,,,,,,,,,English,,,,,,,"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article",,,,,combining social and game strategy; Economic game strategies for robots; engagement robot/computer; long-term relations with robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sociallygroundedgamestrategyenhancesbondingandperceivedsmartnessofahumanoidrobot,socially grounded game strategy enhances bonding and perceived smartness of a humanoid robot in search for better technological solutions for education we adapted a principle from economic game theory namely that giving a help will promote collaboration and eventually longterm relations between a robot and a child this principle has been shown to be effective in games between humans and between humans and computer agents we compared the social and cognitive engagement of children when playing checkers game combined with a social strategy against a robot or against a computer we found that by combining the social and game strategy the children average age of 83 years had more empathy and social engagement with the robot since the children did not want to necessarily win against it this finding is promising for using social strategies for the creation of longterm relations between robots and children and making educational tasks more engaging an additional outcome of the study was the significant difference in the perception of the children about the difficulty of the game  the game with the robot was seen as more challenging and the robot  as a smarter opponent this finding might be due to the higher perceived or expected intelligence from the robot or because of the higher complexity of seeing patterns in threedimensional world
"Exploring Teens as Robot Operators, Users and Witnesses in the Wild",2,"Bjorling, Elin A.; Thomas, Kyle; Rose, Emma J.; Cakmak, Maya",FRONTIERS IN ROBOTICS AND AI,2020,journalArticle,,2296-9144,10.3389/frobt.2020.00005,,"As social robots continue to show promise as assistive technologies, the exploration of appropriate and impactful robot behaviors is key to their eventual success. Teens are a unique population given their vulnerability to stress leading to both mental and physical illness. Much of teen stress stems from school, making the school environment an ideal location for a stress reducing technology. The goal of this mixed-methods study was to understand teens' operation of, and responsiveness to, a robot only capable of movement compared to a robot only capable of speech. Stemming from a human-centered approach, we introduce a Participatory Wizard of Oz (PWoz) interaction method that engaged teens as operators, users, and witnesses in a uniquely transparent interaction. In this paper, we illustrate the use of the PWoz interaction method as well as how it helps identify engaging robot interactions. Using this technique, we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions. We analyzed the teens' interactions with both the verbal and non-verbal robots and identified strong themes of (1) authenticity, (2) empathy, (3) emotional engagement, and (4) imperfection creates connection. Finally, we reflect on the benefits and limitations of the PWoz method and our study to identify next steps toward the design and development of our social robot.",2020-02-21,2021-04-19T15:56:09Z,2021-04-19T15:56:09Z,,,,,7,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,adolescence; empathy; human-centered design; mental health; participatory; social robots; Wizard of Oz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,exploringteensasrobotoperatorsusersandwitnessesinthewild,exploring teens as robot operators users and witnesses in the wild as social robots continue to show promise as assistive technologies the exploration of appropriate and impactful robot behaviors is key to their eventual success teens are a unique population given their vulnerability to stress leading to both mental and physical illness much of teen stress stems from school making the school environment an ideal location for a stress reducing technology the goal of this mixedmethods study was to understand teens operation of and responsiveness to a robot only capable of movement compared to a robot only capable of speech stemming from a humancentered approach we introduce a participatory wizard of oz pwoz interaction method that engaged teens as operators users and witnesses in a uniquely transparent interaction in this paper we illustrate the use of the pwoz interaction method as well as how it helps identify engaging robot interactions using this technique we present results from a study with 62 teens that includes details of the complexity of teen stress and a significant reduction in negative attitudes toward robots after interactions we analyzed the teens interactions with both the verbal and nonverbal robots and identified strong themes of 1 authenticity 2 empathy 3 emotional engagement and 4 imperfection creates connection finally we reflect on the benefits and limitations of the pwoz method and our study to identify next steps toward the design and development of our social robot
Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior,25,"Borenstein, Jason; Arkin, Ronald C.",AI & SOCIETY,2017,journalArticle,,0951-5666,10.1007/s00146-016-0684-1,,"An under-examined aspect of human-robot interaction that warrants further exploration is whether robots should be permitted to influence a user's behavior for that person's own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user's behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user's empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be.",2017-11,2021-04-19T15:56:59Z,2021-04-19T15:56:59Z,,499-507,9,4,32,,,,,,,,,,English,,,,,,,"Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article",,,,,Charity; Companion robots; Design ethics; Empathy; Nudges; Robot ethics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,nudgingforgoodrobotsandtheethicalappropriatenessofnurturingempathyandcharitablebehavior,nudging for good robots and the ethical appropriateness of nurturing empathy and charitable behavior an underexamined aspect of humanrobot interaction that warrants further exploration is whether robots should be permitted to influence a users behavior for that persons own good yet an even more controversial practice could be on the horizon which is allowing a robot to nudge a users behavior for the good of society in this article we examine the feasibility of creating companion robots that would seek to nurture a users empathy toward other human beings as more and more computing devices subtly and overtly influence human behavior it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway our primary focus is on whether a companion robot could encourage humans to perform charitable acts this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be
Perceived Mistreatment and Emotional Capability Following Aggressive Treatment of Robots and Computers,5,"Carlson, Zachary; Lemmon, Louise; Higgins, MacCallister; Frank, David; Shahrezaie, Roya Salek; Feil-Seifer, David",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2019,journalArticle,,1875-4791,10.1007/s12369-019-00599-8,,"Robots (and computers) are increasingly being used in scenarios where they interact socially with people. How people react to these agents is telling about the perceived empathy of such agents. Mistreatment of robots (or computers) by co-workers might provoke such telling reactions. This study examines perceived mistreatment directed towards a robot in comparison to a computer. This will provide some understanding of how people feel about robots in collaborative social settings. We conducted a two by two between-subjects study with 80 participants. Participants worked cooperatively with either a robot or a computer agent. An experiment confederate would either act aggressively or neutrally towards the agent. We hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves; that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer; and so would observe more mistreatment with a robot. The final results supported our hypotheses; the participants observed greater mistreatment for the robot, but not the computer. Also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable.",2019-12,2021-04-19T15:56:17Z,2021-04-19T15:56:17Z,,727-739,13,5,11,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Human-robot cooperation; Human-robot interaction; Mistreatment; Perception,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,perceivedmistreatmentandemotionalcapabilityfollowingaggressivetreatmentofrobotsandcomputers,perceived mistreatment and emotional capability following aggressive treatment of robots and computers robots and computers are increasingly being used in scenarios where they interact socially with people how people react to these agents is telling about the perceived empathy of such agents mistreatment of robots or computers by coworkers might provoke such telling reactions this study examines perceived mistreatment directed towards a robot in comparison to a computer this will provide some understanding of how people feel about robots in collaborative social settings we conducted a two by two betweensubjects study with 80 participants participants worked cooperatively with either a robot or a computer agent an experiment confederate would either act aggressively or neutrally towards the agent we hypothesized that people would not perceive aggressive speech as mistreatment when an agent was capable of emotional feelings and similar to themselves that participants would perceive the robot as more similar in appearance and emotionally capable to themselves than a computer and so would observe more mistreatment with a robot the final results supported our hypotheses the participants observed greater mistreatment for the robot but not the computer also participants felt significantly more sympathetic towards the robot and believed that it was much more emotionally capable
Poetry writing and artistic ability in problem-based learning,2,"Chan, Z.C.Y.",International Journal on Disability and Human Development,2017,journalArticle,,21911231,10.1515/ijdhd-2016-0003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012279045&doi=10.1515%2fijdhd-2016-0003&partnerID=40&md5=405d95d0f3f15bf167d19c4dcd19c1cb,"Problem-based learning (PBL) is a teaching and learning approach that is widely used in healthcare education. It has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues, medical education, and their relationship with patients. The rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose, suggesting that important and detailed information could be better memorised through poetic text. To report on how poetry writing and reciting was used in a PBL class in nursing to enhance the students' artistic ability, and on the students' perspectives on artistry in their learning. This paper presented a part of results of a main educational study where data were collected through lesson observations, reflective notes, and a follow-up interview. A total of 17 Hong Kong students were encouraged to collaborate in groups and write English poems based on a clinical case. A content analysis was conducted on their reflective notes and narratives were extracted from an interview. Although the students learned about cooperation, creativity, thinking, stress management, how to make lively presentations, deep learning, long-term memory, and professional knowledge, they expressed that the above were indirectly related to artistry. Scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students' artistic ability so as to let them learn about empathy and understand patients' sufferings and illness experiences. © 2017 Walter de Gruyter GmbH, Berlin/Boston.",2017,2021-04-20T16:38:48Z,2021-04-20T16:38:48Z,,37-44,8,1,16,,,,,,,,,,English,,,,,,,Publisher: Walter de Gruyter GmbH,<p>cited By 2</p>,,,clinical article; content analysis; creativity; empathy; follow up; Hong Kong; human; interview; literature; long term memory; narrative; nursing; problem based learning; professional knowledge; stress management; teaching; writing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,poetrywritingandartisticabilityinproblembasedlearning,poetry writing and artistic ability in problembased learning problembased learning pbl is a teaching and learning approach that is widely used in healthcare education it has similarly been suggested that poetry writing offers students a way to express their feelings and emotions related to clinical issues medical education and their relationship with patients the rhythmic structure and temporal organisation of poetry allow students to remember poetry more easily than prose suggesting that important and detailed information could be better memorised through poetic text to report on how poetry writing and reciting was used in a pbl class in nursing to enhance the students artistic ability and on the students perspectives on artistry in their learning this paper presented a part of results of a main educational study where data were collected through lesson observations reflective notes and a followup interview a total of 17 hong kong students were encouraged to collaborate in groups and write english poems based on a clinical case a content analysis was conducted on their reflective notes and narratives were extracted from an interview although the students learned about cooperation creativity thinking stress management how to make lively presentations deep learning longterm memory and professional knowledge they expressed that the above were indirectly related to artistry scholars from the fields of both health related disciplines and literature should collaborate in researching and developing some learning and teaching activities which can further enhance the students artistic ability so as to let them learn about empathy and understand patients sufferings and illness experiences  2017 walter de gruyter gmbh berlinboston
EEG based functional connectivity analysis of human pain empathy towards humans and robots,0,"Chang, Wenwen; Wang, Hong; Yan, Guanghui; Lu, Zhiguo; Liu, Chong; Hua, Chengcheng",NEUROPSYCHOLOGIA,2021,journalArticle,,0028-3932,10.1016/j.neuropsychologia.2020.107695,,"Humans can show emotional reactions toward humanoid robots, such as empathy. Previous neuroimaging studies have indicated that neural responses of empathy for others' pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process. Recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans. However, the whole-brain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown. In the present study, the functional connectivity was investigated for ERPs recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and non-painful situations. Functional brain networks for both early and late empathy responses were constructed and a new parameter, empathy index (EI), was proposed to represent the empathy ability of humans quantitatively. We found that the mutual dependences between early ERP components was significantly decreased, but for the late components, there were no significant changes. The mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components, but not for late components. The connectivity weights for early components were larger than late components. EI value shows significant difference between painful and non-painful stimuli, indicating it is a good indicator to represent the empathy of humans. This study enriches our understanding of the neurological mechanisms implicated in human empathy, and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots.",2021-01-22,2021-04-19T15:56:00Z,2021-04-19T15:56:00Z,,,,,151,,,,,,,,,,English,,,,,,,"Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article",,,,,EEG; Empathy; Empathy index; Functional connectivity; Human-robot interaction; Mutual information,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,eegbasedfunctionalconnectivityanalysisofhumanpainempathytowardshumansandrobots,eeg based functional connectivity analysis of human pain empathy towards humans and robots humans can show emotional reactions toward humanoid robots such as empathy previous neuroimaging studies have indicated that neural responses of empathy for others pain are modulated by an early automatic emotional sharing and a late controlled cognitive evaluation process recent studies about pain empathy for robots found humans present similar empathy process towards humanoid robots under painful stimuli as well as to humans however the wholebrain functional connectivity and the spatial dynamics of neural activities underlying empathic processes are still unknown in the present study the functional connectivity was investigated for erps recorded from 18 healthy adults who were presented with pictures of human hand and robot hand under painful and nonpainful situations functional brain networks for both early and late empathy responses were constructed and a new parameter empathy index ei was proposed to represent the empathy ability of humans quantitatively we found that the mutual dependences between early erp components was significantly decreased but for the late components there were no significant changes the mutual dependences for human hand stimuli were larger than to robot hand stimuli for early components but not for late components the connectivity weights for early components were larger than late components ei value shows significant difference between painful and nonpainful stimuli indicating it is a good indicator to represent the empathy of humans this study enriches our understanding of the neurological mechanisms implicated in human empathy and provides evidence of functional connectivity for both early and late responses of pain empathy towards humans and robots
Creation and Staging of Android Theatre “Sayonara” towards Developing Highly Human-Like Robots,8,"Chikaraishi, Takenobu; Yoshikawa, Yuichiro; Ogawa, Kohei; Hirata, Oriza; Ishiguro, Hiroshi",FUTURE INTERNET,2017,journalArticle,,1999-5903,10.3390/fi9040075,,"Even after long-term exposures, androids with a strikingly human-like appearance evoke unnatural feelings. The behavior that would induce human-like feelings after long exposures is difficult to determine, and it often depends on the cultural background of the observers. Therefore, in this study, we generate an acting performance system for the android, in which an android and a human interact in a stage play in the real world. We adopt the theatrical theory called Contemporary Colloquial Theatre Theory to give the android natural behaviors so that audiences can comfortably observe it even after long-minute exposure. A stage play is created and shown in various locations, and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a self-evaluating questionnaire. Overall analysis indicates that the audience had positive feelings, in terms of attractiveness, towards the android on the stage even after 20 min of exposure. The singularly high acceptance of the android by Japanese audiences seems to be correlated with a high animism tendency, rather than to empathy. We also discuss how the stage play approach is limited and could be extended to contribute to realization of human-robot interaction in the real world.",2017-12,2021-04-19T15:56:58Z,2021-04-19T15:56:58Z,,,,4,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI AG Type: Article",,,,,android theatre; contemporary colloquial theatre theory; robot theatre; social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,creationandstagingofandroidtheatresayonaratowardsdevelopinghighlyhumanlikerobots,creation and staging of android theatre sayonara towards developing highly humanlike robots even after longterm exposures androids with a strikingly humanlike appearance evoke unnatural feelings the behavior that would induce humanlike feelings after long exposures is difficult to determine and it often depends on the cultural background of the observers therefore in this study we generate an acting performance system for the android in which an android and a human interact in a stage play in the real world we adopt the theatrical theory called contemporary colloquial theatre theory to give the android natural behaviors so that audiences can comfortably observe it even after longminute exposure a stage play is created and shown in various locations and the audiences are requested to report their impressions of the stage and their cultural and psychological backgrounds in a selfevaluating questionnaire overall analysis indicates that the audience had positive feelings in terms of attractiveness towards the android on the stage even after 20 min of exposure the singularly high acceptance of the android by japanese audiences seems to be correlated with a high animism tendency rather than to empathy we also discuss how the stage play approach is limited and could be extended to contribute to realization of humanrobot interaction in the real world
A study on the potential roles of a robot peer in socio-emotional development of children,1,"Cho, H.-K.; Oh, J.; Lee, K.",International Journal of Computational Vision and Robotics,2017,journalArticle,,17529131,10.1504/IJCVR.2017.083447,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018350294&doi=10.1504%2fIJCVR.2017.083447&partnerID=40&md5=df362ada74a3acadd2ea72f6d878505b,"This paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided. The environment consists of a socially assistive robot, an auxiliary display, and a mobile device for teacher's intervention. The robot and the display are employed as mediators to give adequate affective feedbacks to children, which might not be possible among very young peers. The intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children. We intended to increase children's engagement on the activities and enhance their empathy while interacting with a friend-like robot than they do with an adult teacher. To verify the feasibility of the proposed design, we implemented an activity on emotional regulation strategies and performed a brief user study. The results clearly show that the participants prefer sociable mode of robot operation to still mode operation. Copyright © 2017 Inderscience Enterprises Ltd.",2017,2021-04-20T16:38:49Z,2021-04-20T16:38:49Z,,335-343,9,3,7,,,,,,,,,,English,,,,,,,Publisher: Inderscience Publishers,<p>cited By 1</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,astudyonthepotentialrolesofarobotpeerinsocioemotionaldevelopmentofchildren,a study on the potential roles of a robot peer in socioemotional development of children this paper presents a robot mediated learning environment for children where various educational activities regarding emotional intelligence can be provided the environment consists of a socially assistive robot an auxiliary display and a mobile device for teachers intervention the robot and the display are employed as mediators to give adequate affective feedbacks to children which might not be possible among very young peers the intervention device for teachers is employed to coach the robot on giving appropriate affective feedbacks according to the reaction of children we intended to increase childrens engagement on the activities and enhance their empathy while interacting with a friendlike robot than they do with an adult teacher to verify the feasibility of the proposed design we implemented an activity on emotional regulation strategies and performed a brief user study the results clearly show that the participants prefer sociable mode of robot operation to still mode operation copyright  2017 inderscience enterprises ltd
Consciousnes-based emotion and behavior of pet robot with brain-inspired method,0,"Chumkamon, S.; Hayashi, E.",Information (Japan),2017,journalArticle,,13434500,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033411589&partnerID=40&md5=153492716af71f45b6e7fbfbed28a1e1,"A personal robot becomes important to the future world where the robot facilitates our lives and be a friend. The understanding of emotional interaction is essential in the social behavior, including a natural behavior that is the needed functions for creature behavior-like robots. Our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion. Since the significant factor of a companionable robot is the cross-communication system without conflict. This paper then focuses on three points: The first is the organization of the behavior and emotion model regarding the phylogenetic. The second, the method of the robot that can have empathy with user expression. The third, how the robot can perform the expression to the human with emotional intelligence us-ing a biologically inspired topological on-line method for encouragement or being delighted. We additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment. © 2017 International Information Institute.",2017,2021-04-20T16:38:49Z,2021-04-20T16:38:49Z,,615-629,15,1,20,,,,,,,,,,English,,,,,,,Publisher: International Information Institute Ltd.,<p>cited By 0</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,consciousnesbasedemotionandbehaviorofpetrobotwithbraininspiredmethod,consciousnesbased emotion and behavior of pet robot with braininspired method a personal robot becomes important to the future world where the robot facilitates our lives and be a friend the understanding of emotional interaction is essential in the social behavior including a natural behavior that is the needed functions for creature behaviorlike robots our paper proposes the artificial topological consciousness based on a pet robot using a synthetic neurotransmitter and motivation including intelligent emotion since the significant factor of a companionable robot is the crosscommunication system without conflict this paper then focuses on three points the first is the organization of the behavior and emotion model regarding the phylogenetic the second the method of the robot that can have empathy with user expression the third how the robot can perform the expression to the human with emotional intelligence using a biologically inspired topological online method for encouragement or being delighted we additionally demonstrate the performance of the artificial consciousness based on complexity level and the robot social expression to enhance the users affinity with the experiment  2017 international information institute
Intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot,14,"Chumkamon, Sakmongkon; Hayashi, Eiji; Masato, Koike",BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES,2016,journalArticle,,2212-683X,10.1016/j.bica.2016.09.004,,"Companion or `pet' robots can be expected to be an important part of a future in which robots contribute to our lives in many ways. An understanding of emotional interactions would be essential to such robots' behavior. To improve the cognitive and behavior systems of such robots, we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation, including a biologically inspired emotion system. A fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot. This paper focuses on three points in the development of our proposed framework: (1) the organization of the behavior including inside-state emotion regarding the phylogenetic consciousness-based architecture; (2) a method whereby the robot can have empathy toward its human user's expressions of emotion; and (3) a method that enables the robot to select a facial expression in response to the human user, providing instant human-like `emotion' and based on emotional intelligence (El) that uses a biologically inspired topological online method to express, for example, encouragement or being delighted. We also demonstrate the performance of the artificial consciousness based on the complexity level and a robot's social expressions that are designed to enhance the users affinity with the robot. (C) 2016 Elsevier B.V. All rights reserved.",2016-10,2021-04-19T15:57:14Z,2021-04-19T15:57:14Z,,51-67,17,,18,,,,,,,,,,English,,,,,,,"Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article",,,,,Behavior; Companion robot; Consciousness based architecture; Emotional intelligence; Human-robot interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,intelligentemotionandbehaviorbasedontopologicalconsciousnessandadaptiveresonancetheoryinacompanionrobot,intelligent emotion and behavior based on topological consciousness and adaptive resonance theory in a companion robot companion or pet robots can be expected to be an important part of a future in which robots contribute to our lives in many ways an understanding of emotional interactions would be essential to such robots behavior to improve the cognitive and behavior systems of such robots we propose the use of an artificial topological consciousness that uses a synthetic neurotransmitter and motivation including a biologically inspired emotion system a fundamental aspect of a companion robot is a cross communication system that enables natural interactions between humans and the robot this paper focuses on three points in the development of our proposed framework 1 the organization of the behavior including insidestate emotion regarding the phylogenetic consciousnessbased architecture 2 a method whereby the robot can have empathy toward its human users expressions of emotion and 3 a method that enables the robot to select a facial expression in response to the human user providing instant humanlike emotion and based on emotional intelligence el that uses a biologically inspired topological online method to express for example encouragement or being delighted we also demonstrate the performance of the artificial consciousness based on the complexity level and a robots social expressions that are designed to enhance the users affinity with the robot c 2016 elsevier bv all rights reserved
Gesture design attribute and level value of social robot: A user experience based study,,"Chung, S.-E.; Ryoo, H.-Y.",Journal of System and Management Sciences,2020,journalArticle,,18166075,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090517849&partnerID=40&md5=061cc8cf686359b56d6cd0e6709071a3,"This study was to verify the attributes of the social robot's gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes. To do so, the attributes and the level value standards for the gesture interface's key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies. For the emotional gesture attributes, the level values were categorized as 'pleasure at low arousal', 'pleasure at high arousal', 'displeasure at low arousal', and 'displeasure at high arousal'. Among the communicative expression gesture attributes, the level values were categorized as ‘idling, conversation induction and concentration, and empathy’. Lastly, the derived attributes and the level values for the ‘emotional gesture’ and ‘communicative gesture’ have been integrated with the ones for the ‘functional/semantic gesture' derived on the previous studies; they have been presented as the robot's gesture interface design factors available in the aspect of the user experience. © 2020, Success Culture Press. All rights reserved.",2020,2021-04-20T16:38:36Z,2021-04-20T16:38:36Z,,108-121,14,2,10,,,,,,,,,,English,,,,,,,Publisher: Success Culture Press,<p>cited By 0</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,gesturedesignattributeandlevelvalueofsocialrobotauserexperiencebasedstudy,gesture design attribute and level value of social robot a user experience based study this study was to verify the attributes of the social robots gesture design factors that has a significant difference in the user experience and to establish the level values of the attributes to do so the attributes and the level value standards for the gesture interfaces key design factors have been organized and a user experience survey was conducted through researches on the existing literature and case studies for the emotional gesture attributes the level values were categorized as pleasure at low arousal pleasure at high arousal displeasure at low arousal and displeasure at high arousal among the communicative expression gesture attributes the level values were categorized as idling conversation induction and concentration and empathy lastly the derived attributes and the level values for the emotional gesture and communicative gesture have been integrated with the ones for the functionalsemantic gesture derived on the previous studies they have been presented as the robots gesture interface design factors available in the aspect of the user experience  2020 success culture press all rights reserved
A neurocognitive investigation of the impact of socializing with a robot on empathy for pain,20,"Cross, Emily S.; Riddoch, Katie A.; Pratts, Jaydan; Titone, Simon; Chaudhury, Bishakha; Hortensius, Ruud",PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES,2019,journalArticle,,0962-8436,10.1098/rstb.2018.0034,,"To what extent can humans form social relationships with robots? In the present study, we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy, a core component of social relationships, towards robots. Twenty-six individuals underwent identical fMRI sessions before and after being issued a social robot to take home and interact with over the course of a week. While undergoing fMRI, participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation. Repetition suppression of activity in the pain network, a collection of brain regions associated with empathy and emotional responding, was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure. In contrast to our hypothesis, functional region-of-interest analyses revealed no change in neural overlap for agents after the socializing intervention. Similarly, no increase in activation when observing a robot experiencing pain emerged post-socializing. Whole-brain analysis showed that, before the socializing intervention, superior parietal and early visual regions are sensitive to novel agents, while after socializing, medial temporal regions show agent sensitivity. A region of the inferior parietal lobule was sensitive to novel emotions, but only during the pre-socializing scan session. Together, these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot, as measured by behavioural or brain responses. We discuss the extent to which long-term socialization with robots might shape social cognitive processes and ultimately our relationships with these machines. This article is part of the theme issue `From social brains to social robots: applying neurocognitive insights to human-robot interaction'.",2019-04-29,2021-04-19T15:56:22Z,2021-04-19T15:56:22Z,,,,1771,374,,,,,,,,,,English,,,,,,,"Place: 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND Publisher: ROYAL SOC Type: Article",,,,,empathy; experience-dependent plasticity; fMRI; human-robot interaction; social cognition; social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,aneurocognitiveinvestigationoftheimpactofsocializingwitharobotonempathyforpain,a neurocognitive investigation of the impact of socializing with a robot on empathy for pain to what extent can humans form social relationships with robots in the present study we combined functional neuroimaging with a robot socializing intervention to probe the flexibility of empathy a core component of social relationships towards robots twentysix individuals underwent identical fmri sessions before and after being issued a social robot to take home and interact with over the course of a week while undergoing fmri participants observed videos of a human actor or a robot experiencing pain or pleasure in response to electrical stimulation repetition suppression of activity in the pain network a collection of brain regions associated with empathy and emotional responding was measured to test whether socializing with a social robot leads to greater overlap in neural mechanisms when observing human and robotic agents experiencing pain or pleasure in contrast to our hypothesis functional regionofinterest analyses revealed no change in neural overlap for agents after the socializing intervention similarly no increase in activation when observing a robot experiencing pain emerged postsocializing wholebrain analysis showed that before the socializing intervention superior parietal and early visual regions are sensitive to novel agents while after socializing medial temporal regions show agent sensitivity a region of the inferior parietal lobule was sensitive to novel emotions but only during the presocializing scan session together these findings suggest that a short socialization intervention with a social robot does not lead to discernible differences in empathy towards the robot as measured by behavioural or brain responses we discuss the extent to which longterm socialization with robots might shape social cognitive processes and ultimately our relationships with these machines this article is part of the theme issue from social brains to social robots applying neurocognitive insights to humanrobot interaction
Simulating empathic behavior in a social assistive robot,18,"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe",MULTIMEDIA TOOLS AND APPLICATIONS,2017,journalArticle,,1380-7501,10.1007/s11042-016-3797-0,,"When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user's affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot's affective state and, consequently, the most appropriate empathic behavior. The robot's empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.",2017-02,2021-04-19T15:57:02Z,2021-04-19T15:57:02Z,,5073-5094,22,4,76,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Affective computing; Empathy; Social assistive robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,simulatingempathicbehaviorinasocialassistiverobot,simulating empathic behavior in a social assistive robot when used as an interface in the context of ambient assisted living aal a social robot should not just provide a taskoriented support it should also try to establish a social empathic relation with the user to this aim it is crucial to endow the robot with the capability of recognizing the users affective state and reason on it for triggering the most appropriate communicative behavior in this paper we describe how such an affective reasoning has been implemented in the nao robot for simulating empathic behaviors in the context of aal in particular the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions the recognized emotion allows triggering the robots affective state and consequently the most appropriate empathic behavior the robots empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot
"Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors' intentions to use social robots",29,"de Kervenoael, Ronan; Hasan, Rajibul; Schwob, Alexandre; Goh, Edwin",TOURISM MANAGEMENT,2020,journalArticle,,0261-5177,10.1016/j.tourman.2019.104042,,"Social robots have become pervasive in the tourism and hospitality service environments. The empirical understanding of the drivers of visitors' intentions to use robots in such services has become an urgent necessity for their sustainable deployment. Certainly, using social androids within hospitality services requires organisations' attentive commitment to value creation and fulfilling service quality expectations. In this paper, via structural equation modelling (SEM) and semi-structured interviews with managers, we conceptualise and empirically test visitors' intentions to use social robots in hospitality services. With data collected in Singapore's hospitality settings, we found visitors' intentions to use social robots stem from the effects of technology acceptance variables, service quality dimensions leading to perceived value, and two further dimensions from human robot interaction (HRI): empathy and information sharing. Analysis of these dimensions' importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robot-delivered services in tourism and hospitality strategies.",2020-06,2021-04-19T15:56:07Z,2021-04-19T15:56:07Z,,,,,78,,,,,,,,,,English,,,,,,,"Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND Publisher: ELSEVIER SCI LTD Type: Article",,,,,Artificial intelligence; Hospitality services; Human-robot interaction; Intention to use robots; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,leveraginghumanrobotinteractioninhospitalityservicesincorporatingtheroleofperceivedvalueempathyandinformationsharingintovisitorsintentionstousesocialrobots,leveraging humanrobot interaction in hospitality services incorporating the role of perceived value empathy and information sharing into visitors intentions to use social robots social robots have become pervasive in the tourism and hospitality service environments the empirical understanding of the drivers of visitors intentions to use robots in such services has become an urgent necessity for their sustainable deployment certainly using social androids within hospitality services requires organisations attentive commitment to value creation and fulfilling service quality expectations in this paper via structural equation modelling sem and semistructured interviews with managers we conceptualise and empirically test visitors intentions to use social robots in hospitality services with data collected in singapores hospitality settings we found visitors intentions to use social robots stem from the effects of technology acceptance variables service quality dimensions leading to perceived value and two further dimensions from human robot interaction hri empathy and information sharing analysis of these dimensions importance provides a deeper understanding of novel opportunities managers may take advantage of to position social robotdelivered services in tourism and hospitality strategies
Robots As Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social,119,"E Wiese, G Metta, A Wykowska",Frontiers in Psychology,2017,journalArticle,,1664-1078,10.3389/fpsyg.2017.01663,,"Robots are increasingly envisaged as our future cohabitants. However, while considerable progress has been made in recent years in terms of their technological realization, the ability of robots to interact with humans in an intuitive and social way is still quite limited. An important challenge for social robotics is to determine how to design robots that can perceive the user’s needs, feelings, and intentions, and adapt to users over a broad range of cognitive abilities. It is conceivable that if robots were able to adequately demonstrate these skills, humans would eventually accept them as social companions. We argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motion/eye-tracking, electroencephalography, or functional near-infrared spectroscopy embedded in interactive human-robot paradigms. This approach requires understanding how humans interact with each other, how they perform tasks together and how they develop feelings of social connection over time, and using these insights to formulate design principles that make social robots attuned to the workings of the human brain. In this review, we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in social-cognitive processing. We first review literature related to social-cognitive processes and mechanisms involved in human-human interactions, and highlight the importance of perceiving others as intentional agents to activate these social brain areas. We then discuss how attribution of intentionality can positively affect human-robot interaction by (a) fostering feelings of social connection, empathy and prosociality, and by (b) enhancing performance on joint human-robot tasks. Lastly, we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous, and discuss challenges associated with designing social robots that are inspired by neuroscientific principles.",2017,2021-04-20T16:55:57Z,2021-04-20T16:55:57Z,,,,,,,,Robots As Intentional Agents,,,,,,,English,,,,,Open WorldCat,,OCLC: 8081319333,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,robotsasintentionalagentsusingneuroscientificmethodstomakerobotsappearmoresocial,robots as intentional agents using neuroscientific methods to make robots appear more social robots are increasingly envisaged as our future cohabitants however while considerable progress has been made in recent years in terms of their technological realization the ability of robots to interact with humans in an intuitive and social way is still quite limited an important challenge for social robotics is to determine how to design robots that can perceive the users needs feelings and intentions and adapt to users over a broad range of cognitive abilities it is conceivable that if robots were able to adequately demonstrate these skills humans would eventually accept them as social companions we argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motioneyetracking electroencephalography or functional nearinfrared spectroscopy embedded in interactive humanrobot paradigms this approach requires understanding how humans interact with each other how they perform tasks together and how they develop feelings of social connection over time and using these insights to formulate design principles that make social robots attuned to the workings of the human brain in this review we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in socialcognitive processing we first review literature related to socialcognitive processes and mechanisms involved in humanhuman interactions and highlight the importance of perceiving others as intentional agents to activate these social brain areas we then discuss how attribution of intentionality can positively affect humanrobot interaction by a fostering feelings of social connection empathy and prosociality and by b enhancing performance on joint humanrobot tasks lastly we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous and discuss challenges associated with designing social robots that are inspired by neuroscientific principles
Ordered interpersonal synchronisation in ASD children via robots,0,"Giannopulu, Irini; Etournaud, Aude; Terada, Kazunori; Velonaki, Mari; Watanabe, Tomio",SCIENTIFIC REPORTS,2020,journalArticle,,2045-2322,10.1038/s41598-020-74438-6,,"Children with autistic spectrum disorders (ASD) experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity. Robotic interventions have been explored for use with ASD children worldwide revealing that robots encourage one-to-one social and emotional interactions. However, associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in French and Japanese ASD children when they interact with a human or a robot under analogous experimental conditions. Using the paradigm of actor-perceiver, where the child was the actor and the robot or the human the perceiver, we recorded the autonomic heart rate activation and reported emotional feelings of ASD children in both countries. Japanese and French ASD children showed different interpersonal synchronisation when they interacted with the human perceiver, even though the human was the same in both countries. However, they exhibited similar interpersonal synchronisation when the perceiver was the robot. The findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in ASD children and that both French and Japanese ASD children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping.",2020-10-15,2021-04-19T15:56:04Z,2021-04-19T15:56:04Z,,,,1,10,,,,,,,,,,English,,,,,,,"Place: HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY Publisher: NATURE RESEARCH Type: Article",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,orderedinterpersonalsynchronisationinasdchildrenviarobots,ordered interpersonal synchronisation in asd children via robots children with autistic spectrum disorders asd experience persistent disrupted coordination in interpersonal synchronisation that is thought to be associated with deficits in neural connectivity robotic interventions have been explored for use with asd children worldwide revealing that robots encourage onetoone social and emotional interactions however associations between interpersonal synchronisation and emotional empathy have not yet been directly explored in french and japanese asd children when they interact with a human or a robot under analogous experimental conditions using the paradigm of actorperceiver where the child was the actor and the robot or the human the perceiver we recorded the autonomic heart rate activation and reported emotional feelings of asd children in both countries japanese and french asd children showed different interpersonal synchronisation when they interacted with the human perceiver even though the human was the same in both countries however they exhibited similar interpersonal synchronisation when the perceiver was the robot the findings suggest that the mechanism combining interpersonal synchronisation and emotional empathy might be weakened but not absent in asd children and that both french and japanese asd children do spontaneously and unconsciously discern non verbal actions of non human partners through a direct matching process that occurs via automatic mapping
Emotional Empathy as a Mechanism of Synchronisation in Child-Robot Interaction,8,"Giannopulu, Irini; Terada, Kazunori; Watanabe, Tomio",FRONTIERS IN PSYCHOLOGY,2018,journalArticle,,1664-1078,10.3389/fpsyg.2018.01852,,"Simulating emotional experience, emotional empathy is the fundamental ingredient of interpersonal communication. In the speaker-listener scenario, the speaker is always a child, the listener is a human or a toy robot. Two groups of neurotypical children aged 6 years on average composed the population: one Japanese (n = 20) and one French (n = 20). Revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot, the results might signify that emotional empathy requires the implication of an automatic identification. In this sense, emotional empathy might be considered a broad idiosyncrasy, a kind of synchronisation, offering the mind a peculiar form of communication. Our findings seem to be consistent with the assumption that children's brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation.",2018-10-16,2021-04-19T15:56:41Z,2021-04-19T15:56:41Z,,,,,9,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,child; emotional empathy; heart rate; interactor robot; synchronisation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,emotionalempathyasamechanismofsynchronisationinchildrobotinteraction,emotional empathy as a mechanism of synchronisation in childrobot interaction simulating emotional experience emotional empathy is the fundamental ingredient of interpersonal communication in the speakerlistener scenario the speaker is always a child the listener is a human or a toy robot two groups of neurotypical children aged 6 years on average composed the population one japanese n  20 and one french n  20 revealing potential similarities in communicative exchanges in both groups when in contact with a human or a toy robot the results might signify that emotional empathy requires the implication of an automatic identification in this sense emotional empathy might be considered a broad idiosyncrasy a kind of synchronisation offering the mind a peculiar form of communication our findings seem to be consistent with the assumption that childrens brains would be constructed to simulate the feelings of others in order to ensure interpersonal synchronisation
Amygdala-Inspired Affective Computing: to Realize Personalized Intracranial Emotions with Accurately Observed External Emotions,6,"Gong, Chao; Lin, Fuhong; Zhou, Xianwei; Lu, Xing",CHINA COMMUNICATIONS,2019,journalArticle,,1673-5447,10.23919/JCC.2019.08.011,,"Artificial intelligence technology has revolutionized every industry and trade in recent years. However, its own development is encountering bottlenecks that it is unable to implement empathy with human emotions. So affective computing is getting more attention from researchers. In this paper, we propose an amygdala-inspired affective computing framework to realize the recognition of all kinds of human personalized emotions. Similar to the amygdala, the instantaneous emergency emotion is first computed more quickly in a low-redundancy convolutional neural network compressed by pruning and weight sharing with hashing trick. Then, the real-time process emotion is identified more accurately by the memory level neural networks, which is good at handling time-related signals. Finally, the intracranial emotion is recognized in personalized hidden Markov models. We demonstrate on Facial Expression of Emotion Dataset and the recognition accuracy of external emotions (including the emergency emotion and the process emotion) reached 85.72%. And the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected.",2019-08,2021-04-19T15:56:19Z,2021-04-19T15:56:19Z,,115-129,15,8,16,,,,,,,,,,English,,,,,,,"Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article",,,,,affective computing; emotion recognition; external emotions; intracranial emotions; personalized machines,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,amygdalainspiredaffectivecomputingtorealizepersonalizedintracranialemotionswithaccuratelyobservedexternalemotions,amygdalainspired affective computing to realize personalized intracranial emotions with accurately observed external emotions artificial intelligence technology has revolutionized every industry and trade in recent years however its own development is encountering bottlenecks that it is unable to implement empathy with human emotions so affective computing is getting more attention from researchers in this paper we propose an amygdalainspired affective computing framework to realize the recognition of all kinds of human personalized emotions similar to the amygdala the instantaneous emergency emotion is first computed more quickly in a lowredundancy convolutional neural network compressed by pruning and weight sharing with hashing trick then the realtime process emotion is identified more accurately by the memory level neural networks which is good at handling timerelated signals finally the intracranial emotion is recognized in personalized hidden markov models we demonstrate on facial expression of emotion dataset and the recognition accuracy of external emotions including the emergency emotion and the process emotion reached 8572 and the experimental results proved that the personalized affective model can generate desired intracranial emotions as expected
Examining young children's perception toward augmented reality-infused dramatic play,120,"Han, Jeonghye; Jo, Miheon; Hyun, Eunja; So, Hyo-jeong",ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT,2015,journalArticle,,1042-1629,10.1007/s11423-015-9374-9,,"Amid the increasing interest in applying augmented reality (AR) in educational settings, this study explores the design and enactment of an AR-infused robot system to enhance children's satisfaction and sensory engagement with dramatic play activities. In particular, we conducted an exploratory study to empirically examine children's perceptions toward the computer- and robot-mediated AR systems designed to make dramatic play activities interactive and participatory. A multi-disciplinary expert group consisting of early childhood education experts, preschool teachers, AR specialists, and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play. The experiment was conducted in a kindergarten setting in Korea, with 81 children (aged 5-6 years old). The participants were placed either in the computer-mediated AR condition (n = 40) or the robot-mediated AR condition (n = 41). We administered an instrument to measure children's perceived levels of the following variables: (a) satisfaction (i.e., interest in dramatic play & user-friendliness), (b) sensory immersion (i.e., self-engagement, environment-engagement & interaction-engagement), and (c) media recognition (i.e., collaboration with media, media function & empathy with media). Data analysis indicates that children in the robot-mediated condition showed significantly higher perceptions than those in the computer-mediated condition regarding the following aspects: interest in dramatic play (satisfaction), interactive engagement (sensory immersion), and empathy with media (media recognition). Furthermore, it was found that the younger-aged children and girls, in particular, perceived AR-infused dramatic play more positively than the older-aged children and boys, respectively. The contribution of this study is to provide empirical evidence about the affordances of robots and AR-based learning systems for young children. This remains a relatively unexplored area of research in the field of learning technologies. Implications of the current study and future research directions are also discussed.",2015-06,2021-04-19T15:57:30Z,2021-04-19T15:57:30Z,,455-474,20,3,63,,,,,,,,,,English,,,,,,,"Place: 233 SPRING ST, NEW YORK, NY 10013 USA Publisher: SPRINGER Type: Article",,,,,Augmented reality; Dramatic play; Educational robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,examiningyoungchildrensperceptiontowardaugmentedrealityinfuseddramaticplay,examining young childrens perception toward augmented realityinfused dramatic play amid the increasing interest in applying augmented reality ar in educational settings this study explores the design and enactment of an arinfused robot system to enhance childrens satisfaction and sensory engagement with dramatic play activities in particular we conducted an exploratory study to empirically examine childrens perceptions toward the computer and robotmediated ar systems designed to make dramatic play activities interactive and participatory a multidisciplinary expert group consisting of early childhood education experts preschool teachers ar specialists and robot engineers collaborated to develop a learning scenario and technological systems for dramatic play the experiment was conducted in a kindergarten setting in korea with 81 children aged 56 years old the participants were placed either in the computermediated ar condition n  40 or the robotmediated ar condition n  41 we administered an instrument to measure childrens perceived levels of the following variables a satisfaction ie interest in dramatic play  userfriendliness b sensory immersion ie selfengagement environmentengagement  interactionengagement and c media recognition ie collaboration with media media function  empathy with media data analysis indicates that children in the robotmediated condition showed significantly higher perceptions than those in the computermediated condition regarding the following aspects interest in dramatic play satisfaction interactive engagement sensory immersion and empathy with media media recognition furthermore it was found that the youngeraged children and girls in particular perceived arinfused dramatic play more positively than the olderaged children and boys respectively the contribution of this study is to provide empirical evidence about the affordances of robots and arbased learning systems for young children this remains a relatively unexplored area of research in the field of learning technologies implications of the current study and future research directions are also discussed
"Perspective-Taking of Non-Player Characters in Prosocial Virtual Reality Games: Effects on Closeness, Empathy, and Game Immersion",0,"Ho, Jeffrey C. F.; Ng, Ryan",BEHAVIOUR & INFORMATION TECHNOLOGY,2020,journalArticle,,0144-929X,10.1080/0144929X.2020.1864018,,"This study explores the effects of the perspective-taking of non-player characters (NPCs) on enhancing game immersion in prosocial virtual reality (VR) games. Prosocial games are games focusing on helping others. Game researchers have been keen to investigate factors that influence the immersive experience in digital games. Previous studies show that VR allows people to take the perspective of others, inducing empathy and prosocial behaviour in the real world. In this lab-based study, we explore whether and how taking the perspective of other game characters - NPCs in a prosocial VR game - influences players' in-game empathy towards NPCs and game immersion. Participants first experienced either a robot's perspective of being destroyed by fire in VR or read a text description about the same event. Then, they participated a prosocial VR game in which they saved robots. The findings show that perspective-taking experiences indirectly enhance participants' game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player. This indirect effect is moderated by players' weekly exposure to video games. These results suggest that VR-based perspective-taking of NPCs can indirectly enhance gameplay experiences in prosocial VR games. Theoretical and game design implications are discussed.",,2021-04-19T15:56:01Z,2021-04-19T15:56:01Z,,,,,,,,,,,,,,,English,,,,,,,"Place: 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND Publisher: TAYLOR & FRANCIS LTD Type: Article; Early Access",,,,,digital games; empathy; Perspective taking; prosocial games; virtual reality,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,perspectivetakingofnonplayercharactersinprosocialvirtualrealitygameseffectsonclosenessempathyandgameimmersion,perspectivetaking of nonplayer characters in prosocial virtual reality games effects on closeness empathy and game immersion this study explores the effects of the perspectivetaking of nonplayer characters npcs on enhancing game immersion in prosocial virtual reality vr games prosocial games are games focusing on helping others game researchers have been keen to investigate factors that influence the immersive experience in digital games previous studies show that vr allows people to take the perspective of others inducing empathy and prosocial behaviour in the real world in this labbased study we explore whether and how taking the perspective of other game characters  npcs in a prosocial vr game  influences players ingame empathy towards npcs and game immersion participants first experienced either a robots perspective of being destroyed by fire in vr or read a text description about the same event then they participated a prosocial vr game in which they saved robots the findings show that perspectivetaking experiences indirectly enhance participants game immersion via the effects of closeness with the destroyed robot and empathy towards the four robots protected by the player this indirect effect is moderated by players weekly exposure to video games these results suggest that vrbased perspectivetaking of npcs can indirectly enhance gameplay experiences in prosocial vr games theoretical and game design implications are discussed
Empathetic Speech Synthesis and Testing for Healthcare Robots,0,"James, Jesin; Balamurali, B. T.; Watson, Catherine I.; MacDonald, Bruce",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2020,journalArticle,,1875-4791,10.1007/s12369-020-00691-4,,"One of the major factors that affect the acceptance of robots in Human-Robot Interaction applications is the type of voice with which they interact with humans. The robot's voice can be used to express empathy, which is an affective response of the robot to the human user. In this study, the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications. A pilot study using an empathetic voice spoken by a voice actor was conducted. Only prosody in speech is used to express empathy here, without any visual cues. Also, the emotions needed for an empathetic voice are identified. It was found that the emotions needed are not only the stronger primary emotions, but also the nuanced secondary emotions. These emotions are then synthesised using prosody modelling. A second study, replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well. This paper reports the modelling and synthesises of an empathetic voice, and experimentally shows that people prefer empathetic voice for healthcare robots. The results can be further used to develop empathetic social robots, that can improve people's acceptance of social robots.",,2021-04-19T15:56:05Z,2021-04-19T15:56:05Z,,,,,,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article; Early Access",,,,,Artificial empathy; Emotional speech synthesis; Healthcare; Prosody modelling; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,empatheticspeechsynthesisandtestingforhealthcarerobots,empathetic speech synthesis and testing for healthcare robots one of the major factors that affect the acceptance of robots in humanrobot interaction applications is the type of voice with which they interact with humans the robots voice can be used to express empathy which is an affective response of the robot to the human user in this study the aim is to find out if social robots with empathetic voice are acceptable for users in healthcare applications a pilot study using an empathetic voice spoken by a voice actor was conducted only prosody in speech is used to express empathy here without any visual cues also the emotions needed for an empathetic voice are identified it was found that the emotions needed are not only the stronger primary emotions but also the nuanced secondary emotions these emotions are then synthesised using prosody modelling a second study replicating the pilot test is conducted using the synthesised voices to investigate if empathy is perceived from the synthetic voice as well this paper reports the modelling and synthesises of an empathetic voice and experimentally shows that people prefer empathetic voice for healthcare robots the results can be further used to develop empathetic social robots that can improve peoples acceptance of social robots
The Effect of Robot Attentional Behaviors on User Perceptions and Behaviors in a Simulated Health Care Interaction: Randomized Controlled Trial,8,"Johanson, Deborah L.; Ahn, Ho Seok; MacDonald, Bruce A.; Ahn, Byeong Kyu; Lim, JongYoon; Hwang, Euijun; Sutherland, Craig J.; Broadbent, Elizabeth",JOURNAL OF MEDICAL INTERNET RESEARCH,2019,journalArticle,,1438-8871,10.2196/13667,,"Background: For robots to be effectively used in health applications, they need to display appropriate social behaviors. A fundamental requirement in all social interactions is the ability to engage, maintain, and demonstrate attention. Attentional behaviors include leaning forward, self-disclosure, and changes in voice pitch. Objective: This study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction. Methods: A parallel randomized controlled trial with a 1:1:1 allocation ration was conducted. We randomized participants to 1 of 4 experimental conditions before engaging in a scripted face-to-face interaction with a fully automated medical receptionist robot. Experimental conditions included a self-disclosure condition, voice pitch change condition, forward lean condition, and neutral condition. Participants completed paper-based postinteraction measures relating to engagement, perceived robot attention, and perceived robot empathy. We video recorded interactions and coded for participant attentional behaviors. Results: A total of 181 participants were recruited from the University of Auckland. Participants who interacted with the robot in the forward lean and self-disclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions (P=.03). Participants in the forward lean, self-disclosure, and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition (P<.001). Participants in the forward lean and self-disclosure conditions spent significantly more time looking at the robot than participants in the neutral condition (P<.001). Significantly, more participants in the self-disclosure condition laughed during the interaction (P=.01), whereas significantly more participants in the forward lean condition leant toward the robot during the interaction (P<.001). Conclusions: The use of self-disclosure and forward lean by a health care robot can increase human engagement and attentional behaviors. Voice pitch changes did not increase attention or engagement. The small effects with regard to participant perceptions are potentially because of the limitations in self-report measures or a lack of comparison for most participants who had never interacted with a robot before. Further research could explore the use of self-disclosure and forward lean using a within-subjects design and in real health care settings.",2019-10-04,2021-04-19T15:56:17Z,2021-04-19T15:56:17Z,,,,10,21,,,,,,,,,,English,,,,,,,"Place: 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article",,,,,engagement; health care robotics; robotics; social intelligence; social interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,theeffectofrobotattentionalbehaviorsonuserperceptionsandbehaviorsinasimulatedhealthcareinteractionrandomizedcontrolledtrial,the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction randomized controlled trial background for robots to be effectively used in health applications they need to display appropriate social behaviors a fundamental requirement in all social interactions is the ability to engage maintain and demonstrate attention attentional behaviors include leaning forward selfdisclosure and changes in voice pitch objective this study aimed to examine the effect of robot attentional behaviors on user perceptions and behaviors in a simulated health care interaction methods a parallel randomized controlled trial with a 111 allocation ration was conducted we randomized participants to 1 of 4 experimental conditions before engaging in a scripted facetoface interaction with a fully automated medical receptionist robot experimental conditions included a selfdisclosure condition voice pitch change condition forward lean condition and neutral condition participants completed paperbased postinteraction measures relating to engagement perceived robot attention and perceived robot empathy we video recorded interactions and coded for participant attentional behaviors results a total of 181 participants were recruited from the university of auckland participants who interacted with the robot in the forward lean and selfdisclosure conditions found the robot to be significantly more stimulating than those who interacted with the robot in the voice pitch or neutral conditions p03 participants in the forward lean selfdisclosure and neutral conditions found the robot to be significantly more interesting than those in the voice pitch condition p001 participants in the forward lean and selfdisclosure conditions spent significantly more time looking at the robot than participants in the neutral condition p001 significantly more participants in the selfdisclosure condition laughed during the interaction p01 whereas significantly more participants in the forward lean condition leant toward the robot during the interaction p001 conclusions the use of selfdisclosure and forward lean by a health care robot can increase human engagement and attentional behaviors voice pitch changes did not increase attention or engagement the small effects with regard to participant perceptions are potentially because of the limitations in selfreport measures or a lack of comparison for most participants who had never interacted with a robot before further research could explore the use of selfdisclosure and forward lean using a withinsubjects design and in real health care settings
"Differential Facial Articulacy in Robots and Humans Elicit Different Levels of Responsiveness, Empathy, and Projected Feelings",0,"Konijn, Elly A.; Hoorn, Johan F.",ROBOTICS,2020,journalArticle,,,10.3390/robotics9040092,,"Life-like humanoid robots are on the rise, aiming at communicative purposes that resemble humanlike conversation. In human social interaction, the facial expression serves important communicative functions. We examined whether a robot's face is similarly important in human-robot communication. Based on emotion research and neuropsychological insights on the parallel processing of emotions, we argue that greater plasticity in the robot's face elicits higher affective responsivity, more closely resembling human-to-human responsiveness than a more static face. We conducted a between-subjects experiment of 3 (facial plasticity: human vs. facially flexible robot vs. facially static robot) x 2 (treatment: affectionate vs. maltreated). Participants (N = 265; M-age = 31.5) were measured for their emotional responsiveness, empathy, and attribution of feelings to the robot. Results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns. Significantly different intensities of feelings and attributions (e.g., pain upon maltreatment) followed facial articulacy. Theoretical implications for underlying processes in human-robot communication are discussed. We theorize that precedence of emotion and affect over cognitive reflection, which are processed in parallel, triggers the experience of `because I feel, I believe it's real,' despite being aware of communicating with a robot. By evoking emotional responsiveness, the cognitive awareness of `it is just a robot' fades into the background and appears not relevant anymore.",2020-12,2021-04-19T15:56:02Z,2021-04-19T15:56:02Z,,,,4,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,empathy; experiment; facial expression; human-robot communication; social robots; user response,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,differentialfacialarticulacyinrobotsandhumanselicitdifferentlevelsofresponsivenessempathyandprojectedfeelings,differential facial articulacy in robots and humans elicit different levels of responsiveness empathy and projected feelings lifelike humanoid robots are on the rise aiming at communicative purposes that resemble humanlike conversation in human social interaction the facial expression serves important communicative functions we examined whether a robots face is similarly important in humanrobot communication based on emotion research and neuropsychological insights on the parallel processing of emotions we argue that greater plasticity in the robots face elicits higher affective responsivity more closely resembling humantohuman responsiveness than a more static face we conducted a betweensubjects experiment of 3 facial plasticity human vs facially flexible robot vs facially static robot x 2 treatment affectionate vs maltreated participants n  265 mage  315 were measured for their emotional responsiveness empathy and attribution of feelings to the robot results showed empathically and emotionally less intensive responsivity toward the robots than toward the human but followed similar patterns significantly different intensities of feelings and attributions eg pain upon maltreatment followed facial articulacy theoretical implications for underlying processes in humanrobot communication are discussed we theorize that precedence of emotion and affect over cognitive reflection which are processed in parallel triggers the experience of because i feel i believe its real despite being aware of communicating with a robot by evoking emotional responsiveness the cognitive awareness of it is just a robot fades into the background and appears not relevant anymore
Seeing the mind of robots: Harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes,1,"Kuester, Dennis; Swiderska, Aleksandra",INTERNATIONAL JOURNAL OF PSYCHOLOGY,2020,journalArticle,,0020-7594,10.1002/ijop.12715,,"According to moral typecasting theory, good- and evil-doers (agents) interact with the recipients of their actions (patients) in a moral dyad. When this dyad is completed, mind attribution towards intentionally harmed liminal minds is enhanced. However, from a dehumanisation view, malevolent actions may instead result in a denial of humanness. To contrast both accounts, a visual vignette experiment (N = 253) depicted either malevolent or benevolent intentions towards robotic or human avatars. Additionally, we examined the role of harm-salience by showing patients as either harmed, or still unharmed. The results revealed significantly increased mind attribution towards visibly harmed patients, mediated by perceived pain and expressed empathy. Benevolent and malevolent intentions were evaluated respectively as morally right or wrong, but their impact on the patient was diminished for the robotic avatar. Contrary to dehumanisation predictions, our manipulation of intentions failed to affect mind perception. Nonetheless, benevolent intentions reduced dehumanisation of the patients. Moreover, when pain and empathy were statistically controlled, the effect of intentions on mind perception was mediated by dehumanisation. These findings suggest that perceived intentions might only be indirectly tied to mind perception, and that their role may be better understood when additionally accounting for empathy and dehumanisation.",,2021-04-19T15:56:05Z,2021-04-19T15:56:05Z,,,,,,,,,,,,,,,English,,,,,,,"Place: THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND Publisher: JOHN WILEY & SONS LTD Type: Article; Early Access",,,,,Benevolent intentions; Dehumanisation; Mind perception; Moral typecasting theory; Robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,seeingthemindofrobotsharmaugmentsmindperceptionbutbenevolentintentionsreducedehumanisationofartificialentitiesinvisualvignettes,seeing the mind of robots harm augments mind perception but benevolent intentions reduce dehumanisation of artificial entities in visual vignettes according to moral typecasting theory good and evildoers agents interact with the recipients of their actions patients in a moral dyad when this dyad is completed mind attribution towards intentionally harmed liminal minds is enhanced however from a dehumanisation view malevolent actions may instead result in a denial of humanness to contrast both accounts a visual vignette experiment n  253 depicted either malevolent or benevolent intentions towards robotic or human avatars additionally we examined the role of harmsalience by showing patients as either harmed or still unharmed the results revealed significantly increased mind attribution towards visibly harmed patients mediated by perceived pain and expressed empathy benevolent and malevolent intentions were evaluated respectively as morally right or wrong but their impact on the patient was diminished for the robotic avatar contrary to dehumanisation predictions our manipulation of intentions failed to affect mind perception nonetheless benevolent intentions reduced dehumanisation of the patients moreover when pain and empathy were statistically controlled the effect of intentions on mind perception was mediated by dehumanisation these findings suggest that perceived intentions might only be indirectly tied to mind perception and that their role may be better understood when additionally accounting for empathy and dehumanisation
Impact of human-robot interaction on user satisfaction with humanoid-based healthcare,0,"Kwon, O.; Kim, J.; Jin, Y.; Lee, N.",International Journal of Engineering and Technology(UAE),2018,journalArticle,,2227524X,10.14419/ijet.v7i2.12.11038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045016067&doi=10.14419%2fijet.v7i2.12.11038&partnerID=40&md5=5c2596fb95a967cfa7ed39ad90f59911,"Background/Objectives: The advent of self-service technology (SST) (e.g.,kiosks and Automatic Response System), has made it possible for service providersto make use of non-face-to-face channels to meet users'needs and decrease users'costs and time. On the other hand, however, more complex technology and/or services inhibit users' satisfaction and,consequently,the intention to adopt SST, because such SST can instill fear in users. Nevertheless, at present, patients and other people who are interested in their own health and well-being are paying great attention to healthcare robots (as a form of SST)and,consequently, it has become crucial to investigate how these healthcare robots can positively influence users' satisfaction with them. Hence, this study aims to empirically investigate the factors that affect users' satisfaction with healthcare robots, especially in regard to human-robot interaction (HRI). Methods/Statistical analysis: We focused on the theory of heterophily and applied a series of factors identified in previous robot-adoption studies.Uniquely, this study focuses on users' heterophily with healthcare robots, examining heterophily through three fundamental ele-ments, empathy, professionalism, and personality, which we considered to be suitable fordetermining user satisfaction with HRI-based communication.To prove the validity of our hypotheses, we conducted an empirical testthat involved participants receiving a short health assessment from a robot. Findings: The findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot, the higher the level of user satisfaction with the humanoid-style healthcare service. Further, our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction. Improvements/Applications: First, to increase user satisfaction,robots must be provided with the ability to somehow recognizea user's personality and adjust their own accordingly before beginning the robot-based healthcare service. Secondly, users' behavior patterns should be analyzed by the healthcare robot. Overall, our study empirically shows the importance of ensuring thatprofessionalism is present in healthcare-domain-related HRI. © 2018 Ohbyung Kwon at.al.",2018,2021-04-20T16:38:45Z,2021-04-20T16:38:45Z,,68-75,8,2,7,,,,,,,,,,English,,,,,,,Publisher: Science Publishing Corporation Inc,<p>cited By 0</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,impactofhumanrobotinteractiononusersatisfactionwithhumanoidbasedhealthcare,impact of humanrobot interaction on user satisfaction with humanoidbased healthcare backgroundobjectives the advent of selfservice technology sst egkiosks and automatic response system has made it possible for service providersto make use of nonfacetoface channels to meet usersneeds and decrease userscosts and time on the other hand however more complex technology andor services inhibit users satisfaction andconsequentlythe intention to adopt sst because such sst can instill fear in users nevertheless at present patients and other people who are interested in their own health and wellbeing are paying great attention to healthcare robots as a form of sstandconsequently it has become crucial to investigate how these healthcare robots can positively influence users satisfaction with them hence this study aims to empirically investigate the factors that affect users satisfaction with healthcare robots especially in regard to humanrobot interaction hri methodsstatistical analysis we focused on the theory of heterophily and applied a series of factors identified in previous robotadoption studiesuniquely this study focuses on users heterophily with healthcare robots examining heterophily through three fundamental elements empathy professionalism and personality which we considered to be suitable fordetermining user satisfaction with hribased communicationto prove the validity of our hypotheses we conducted an empirical testthat involved participants receiving a short health assessment from a robot findings the findings of our empirical test supported our hypothesis that the lower the difference in empathy between a user and robot the higher the level of user satisfaction with the humanoidstyle healthcare service further our results also suggest that heterogeneity between a user and healthcare robot is positively associated with user satisfaction improvementsapplications first to increase user satisfactionrobots must be provided with the ability to somehow recognizea users personality and adjust their own accordingly before beginning the robotbased healthcare service secondly users behavior patterns should be analyzed by the healthcare robot overall our study empirically shows the importance of ensuring thatprofessionalism is present in healthcaredomainrelated hri  2018 ohbyung kwon atal
"A Recipe for Empathy Integrating the Mirror System, Insula, Somatosensory Cortex and Motherese",27,"Lim, Angelica; Okuno, Hiroshi G.",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2015,journalArticle,,1875-4791,10.1007/s12369-014-0262-y,,"Could a robot feel authentic empathy? What exactly is empathy, and why do most humans have it? We present a model which suggests that empathy is an emergent behavior with four main elements: a mirror neuron system, somatosensory cortices, an insula, and infant-directed “baby talk” or motherese. To test our hypothesis, we implemented a robot called MEI (multimodal emotional intelligence) with these functions, and allowed it to interact with human caregivers using comfort and approval motherese, the first kinds of vocalizations heard by infants at 3 and 6 months of age. The robot synchronized in real-time to the humans through voice and movement dynamics, while training statistical models associated with its low level gut feeling (”flourishing” or “distress”, based on battery or temperature). Experiments show that the post-interaction robot associates novel happy voices with physical flourishing 90 % of the time, sad voices with distress 84 % of the time. Our results also show that a robot trained with infant-directed “attention bids” can recognize adult fear voices. Importantly, this is the first emotion system to recognize adult emotional voices after training only with motherese, suggesting that this specific parental behavior may help build emotional intelligence.",2015-02,2021-04-19T15:57:34Z,2021-04-19T15:57:34Z,,35-49,15,1,7,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Developmental robotics; Emotional contagion based on SIRE model; MEI robot; Robot empathy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,arecipeforempathyintegratingthemirrorsysteminsulasomatosensorycortexandmotherese,a recipe for empathy integrating the mirror system insula somatosensory cortex and motherese could a robot feel authentic empathy what exactly is empathy and why do most humans have it we present a model which suggests that empathy is an emergent behavior with four main elements a mirror neuron system somatosensory cortices an insula and infantdirected baby talk or motherese to test our hypothesis we implemented a robot called mei multimodal emotional intelligence with these functions and allowed it to interact with human caregivers using comfort and approval motherese the first kinds of vocalizations heard by infants at 3 and 6 months of age the robot synchronized in realtime to the humans through voice and movement dynamics while training statistical models associated with its low level gut feeling flourishing or distress based on battery or temperature experiments show that the postinteraction robot associates novel happy voices with physical flourishing 90  of the time sad voices with distress 84  of the time our results also show that a robot trained with infantdirected attention bids can recognize adult fear voices importantly this is the first emotion system to recognize adult emotional voices after training only with motherese suggesting that this specific parental behavior may help build emotional intelligence
Robot Enhanced Therapy for Autistic Children: An Ethical Analysis,2,"McBride, Neil",IEEE TECHNOLOGY AND SOCIETY MAGAZINE,2020,journalArticle,,0278-0097,10.1109/MTS.2020.2967493,,"The use of social robots has been proposed for the delivery of therapy to autistic children. The aim of such projects, of which the DREAM project is an example, is to replace therapists by robots, operating in sensory environments that enable them to detect and respond to feedback from the child. This article considers the ethical concerns of autonomy, community, transparency, identity, value, and empathy to evaluate the ethics of such deployment of robots. In doing so it provides a response to the Richardson et al. article in IEEE Technology and Society Magazine, Mar. 2018 [20]. This article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned. The use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed, rather than on the basis of the technology itself. Particularly important is the roboticist's empathy with the user of the robot, and gaining an understanding of the individual child. The paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the child's regulation of emotions.",2020-03,2021-04-19T15:56:09Z,2021-04-19T15:56:09Z,,51-60,10,1,39,,,,,,,,,,English,,,,,,,"Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article",,,,,Autism; Ethics; Medical treatment; Pediatrics; Robot sensing systems; Social implications of technology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,robotenhancedtherapyforautisticchildrenanethicalanalysis,robot enhanced therapy for autistic children an ethical analysis the use of social robots has been proposed for the delivery of therapy to autistic children the aim of such projects of which the dream project is an example is to replace therapists by robots operating in sensory environments that enable them to detect and respond to feedback from the child this article considers the ethical concerns of autonomy community transparency identity value and empathy to evaluate the ethics of such deployment of robots in doing so it provides a response to the richardson et al article in ieee technology and society magazine mar 2018 20 this article concludes that deployment of robots to control the behavior of autistic children is ethically suspect and should be questioned the use of robots with children should be evaluated on the basis of the purpose of and process by which such robots are deployed rather than on the basis of the technology itself particularly important is the roboticists empathy with the user of the robot and gaining an understanding of the individual child the paper suggests how an understanding of the autistic child might lead to sensitive deployment of a robot to help the child manage social environments through supporting the childs regulation of emotions
Intersectional AI: A Study of How Information Science Students Think about Ethics and Their Impact,1,"McDonald, Nora; Pan, Shimei",Proc. ACM Hum.-Comput. Interact.,2020,journalArticle,,,10.1145/3415218,https://doi.org/10.1145/3415218,"Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.",2020-10,2021-04-19T16:09:40Z,2021-04-19T16:09:40Z,,,,CSCW2,4,,,,,,,,,,,,,,,,,"Place: New York, NY, USA Publisher: Association for Computing Machinery",,,,algorithm bias; artificial intelligence; education; ethics; intersectionality,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,intersectionalaiastudyofhowinformationsciencestudentsthinkaboutethicsandtheirimpact,intersectional ai a study of how information science students think about ethics and their impact recent literature has demonstrated the limited and in some instances waning role of ethical training in computing classes in the us the capacity for artificial intelligence ai to be inequitable or harmful is well documented yet its an issue that continues to lack apparent urgency or effective mitigation the question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing ai particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restrictionfrom risk assessment and bail assignment in criminal justice to public benefits distribution and access to housing and other critical resources that enable security and success within society the us is a mecca of information and computer science is and cs learning for asian students whose experiences as minorities renders them familiar with and vulnerable to the societal bias that feeds ai bias our goal was to better understand how students who are being educated to design ai systems think about these issues and in particular their sensitivity to intersectional considerations that heighten risk for vulnerable groups in this paper we report on findings from qualitative interviews with 20 graduate students 11 from an ai class and 9 from a data mining class we find that students are not predisposed to think deeply about the implications of ai design for the privacy and wellbeing of others unless explicitly encouraged to do so when they do their thinking is focused through the lens of personal identity and experience but their reflections tend to center on bias an intrinsic feature of design rather than on fairness an outcome that requires them to imagine the consequences of ai while they are in fact equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities many need help to do this empathy work notably the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias and the interaction with context our findings suggest that experience with identitybased vulnerability promotes more analytically complex thinking about ai lending further support to the argument that identityrelated ethics should be integrated into is and cs curriculums rather than positioned as a standalone course
Can You Read My Face? A Methodological Variation for Assessing Facial Expressions of Robotic Heads,13,"Mirnig, Nicole; Strasser, Ewald; Weiss, Astrid; Kuehnlenz, Barbara; Wollherr, Dirk; Tscheligi, Manfred",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2015,journalArticle,,1875-4791,10.1007/s12369-014-0261-z,,"Our paper reports about an online study on robot facial expressions. On the one hand, we performed this study to assess the quality of the current facial expressions of two robot heads. On the other hand, we aimed at developing a simple, easy-to-use methodological variation to evaluate facial expressions of robotic heads. Short movie clips of two different robot heads showing a happy, sad, surprised, and neutral facial expression were compiled into an online survey, to examine how people interpret these expressions. Additionally, we added a control condition with a human face showing the same four emotions. The results showed that the facial expressions could be recognized well for both heads. Even the blender emotion surprised was recognized, although it resulted in positive and negative connotations. These results underline the importance of the situational context to correctly interpret emotional facial expressions. Besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads, the more human-like designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animal-like features. In terms of the validation procedure, we could provide evidence for a feasible two-step procedure. By assessing the participants' dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion. In subsequence, robot facial expressions can be validated with a closed-question approach.",2015-02,2021-04-19T15:57:33Z,2021-04-19T15:57:33Z,,63-76,14,1,7,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Facial expressions; Human-robot interaction; Robot emotions; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,canyoureadmyfaceamethodologicalvariationforassessingfacialexpressionsofroboticheads,can you read my face a methodological variation for assessing facial expressions of robotic heads our paper reports about an online study on robot facial expressions on the one hand we performed this study to assess the quality of the current facial expressions of two robot heads on the other hand we aimed at developing a simple easytouse methodological variation to evaluate facial expressions of robotic heads short movie clips of two different robot heads showing a happy sad surprised and neutral facial expression were compiled into an online survey to examine how people interpret these expressions additionally we added a control condition with a human face showing the same four emotions the results showed that the facial expressions could be recognized well for both heads even the blender emotion surprised was recognized although it resulted in positive and negative connotations these results underline the importance of the situational context to correctly interpret emotional facial expressions besides the expected finding that the human is perceived significantly more anthropomorphic and animate than both robot heads the more humanlike designed robot head was rated significantly higher with respect to anthropomorphism than the robot head using animallike features in terms of the validation procedure we could provide evidence for a feasible twostep procedure by assessing the participants dispositional empathy with a questionnaire it can be ensured that they are in general able to decode facial expressions into the corresponding emotion in subsequence robot facial expressions can be validated with a closedquestion approach
Intelligent humanoid robots expressing artificial humanlike empathy in nursing situations,4,"Pepito, Joseph Andrew; Ito, Hirokazu; Betriana, Feni; Tanioka, Tetsuya; Locsin, Rozzano C.",NURSING PHILOSOPHY,2020,journalArticle,,1466-7681,10.1111/nup.12318,,"Intelligent humanoid robots (IHRs) are becoming likely to be integrated into nursing practice. However, a proper integration of IHRs requires a detailed description and explanation of their essential capabilities, particularly regarding their competencies in replicating and portraying emotive functions such as empathy. Existing humanoid robots can exhibit rudimentary forms of empathy; as these machines slowly become commonplace in healthcare settings, they will be expected to express empathy as a natural function, rather than merely to portray artificial empathy as a replication of human empathy. This article works with a twofold purpose: firstly, to consider the impact of artificial empathy in nursing and, secondly, to describe the influence of Affective Developmental Robotics (ADR) in anticipation of the empathic behaviour presented by artificial humanoid robots. The ADR has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy. This will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry. A discussion of IHRs demonstrating artificial empathy is critical to nursing practice today, particularly in healthcare settings dense with technology.",2020-10,2021-04-19T15:56:06Z,2021-04-19T15:56:06Z,,,,4,21,,,,,,,,,,English,,,,,,,"Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article",,,,,affective developmental robotics; artificial empathy; artificial intelligence; humanoid nurse robots; intelligent humanoid robots; nursing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,intelligenthumanoidrobotsexpressingartificialhumanlikeempathyinnursingsituations,intelligent humanoid robots expressing artificial humanlike empathy in nursing situations intelligent humanoid robots ihrs are becoming likely to be integrated into nursing practice however a proper integration of ihrs requires a detailed description and explanation of their essential capabilities particularly regarding their competencies in replicating and portraying emotive functions such as empathy existing humanoid robots can exhibit rudimentary forms of empathy as these machines slowly become commonplace in healthcare settings they will be expected to express empathy as a natural function rather than merely to portray artificial empathy as a replication of human empathy this article works with a twofold purpose firstly to consider the impact of artificial empathy in nursing and secondly to describe the influence of affective developmental robotics adr in anticipation of the empathic behaviour presented by artificial humanoid robots the adr has demonstrated that it can be one means by which humanoid nurse robots can achieve expressions of more relatable artificial empathy this will be one of the vital models for intelligent humanoid robots currently in nurse robot development for the healthcare industry a discussion of ihrs demonstrating artificial empathy is critical to nursing practice today particularly in healthcare settings dense with technology
"Attachment styles moderate customer responses to frontline service robots: Evidence from affective, attitudinal, and behavioral measures",0,"Pozharliev, Rumen; De Angelis, Matteo; Rossi, Dario; Romani, Simona; Verbeke, Willem; Cherubino, Patrizia",PSYCHOLOGY & MARKETING,2021,journalArticle,,0742-6046,10.1002/mar.21475,,"Despite the growing application of interactive technologies like service robots in customer service, there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees. Moreover, it is unclear whether all customers respond to the interaction with frontline service robots in the same way. Our research looks at how individual differences in social behaviors, specifically in customers' attachment styles, influence three types of customer responses: affective responses (experienced pleasantness), attitudinal responses (perceived empathy, satisfaction), and behavioral responses (word-of-mouth). Three experimental studies reveal that customers with low (vs. high) scores on anxious attachment style (AAS) measures respond more negatively to frontline service robot (compared to a frontline human agent). We investigate alternative explanations for these findings, such as robots' level of anthropomorphism and we show that human-likeness features such as voice type and level of human-like physical appearance, cannot explain our findings. Our results indicate that for low-AAS customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots, leading to possible implications on customer segmentation, targeting, and marketing communication.",,2021-04-19T15:55:59Z,2021-04-19T15:55:59Z,,,,,,,,,,,,,,,English,,,,,,,"Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article; Early Access",,,,,anthropomorphism; attachment styles; empathy; service robots; social response,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,attachmentstylesmoderatecustomerresponsestofrontlineservicerobotsevidencefromaffectiveattitudinalandbehavioralmeasures,attachment styles moderate customer responses to frontline service robots evidence from affective attitudinal and behavioral measures despite the growing application of interactive technologies like service robots in customer service there is limited understanding about how customers respond to interactions with frontline service robots compared to those with frontline human employees moreover it is unclear whether all customers respond to the interaction with frontline service robots in the same way our research looks at how individual differences in social behaviors specifically in customers attachment styles influence three types of customer responses affective responses experienced pleasantness attitudinal responses perceived empathy satisfaction and behavioral responses wordofmouth three experimental studies reveal that customers with low vs high scores on anxious attachment style aas measures respond more negatively to frontline service robot compared to a frontline human agent we investigate alternative explanations for these findings such as robots level of anthropomorphism and we show that humanlikeness features such as voice type and level of humanlike physical appearance cannot explain our findings our results indicate that for lowaas customers replacing frontline human service agent with frontline robot undermines customer attitude and behavioral responses to service robots leading to possible implications on customer segmentation targeting and marketing communication
A Computation Model for Learning Programming and Emotional Intelligence,0,"Rafique, Memoona; Hassan, Muhammad Awais; Jaleel, Abdul; Khalid, Hina; Bano, Gulshan",IEEE ACCESS,2020,journalArticle,,2169-3536,10.1109/ACCESS.2020.3015533,,"Introducing coding in early education improves the logical and computational thinking in kids. However, cognitive skills are not sufficient for a successful life. Understanding and managing the emotions of oneself is another crucial factor in success. The current state of the art teaching methods educates the kids about programming and emotional intelligence independently. In our opinion, it is advantageous to teach kids emotional intelligence, along with the programming concepts. However, the literature lacks the studies that make students emotionally aware while teaching them programming. This research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kid's emotional intelligence can be enhanced while teaching them cognitive skills. We proposed a computational model that teaches programming and emotional intelligence side by side to students. The model provides a curriculum and related tools. For evaluations, five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model. These students were divided into five groups (A, B, C, D, and E), each having a mean age of 4, 5, 6, 7, and 8 years, respectively. Students performed multiple adaptive scenarios of path-finding that were based on self-awareness, social-awareness, sharing, and empathy emotions. Students provide the programming instructions such as sequencing, conditional statements, and looping to a robot. The children have successfully improved in both fundamental programming constructs and emotional intelligence skills. The research also successfully reduced screen time problem by providing a screen-free student interface.",2020,2021-04-19T15:56:13Z,2021-04-19T15:56:13Z,,149616-149629,14,,8,,,,,,,,,,English,,,,,,,"Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article",,,,,basic programming; Computational modeling; Education; Emotional intelligence; Programming profession; Robots; robots based learning; screen-free interface; Sequential analysis; Tools,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,acomputationmodelforlearningprogrammingandemotionalintelligence,a computation model for learning programming and emotional intelligence introducing coding in early education improves the logical and computational thinking in kids however cognitive skills are not sufficient for a successful life understanding and managing the emotions of oneself is another crucial factor in success the current state of the art teaching methods educates the kids about programming and emotional intelligence independently in our opinion it is advantageous to teach kids emotional intelligence along with the programming concepts however the literature lacks the studies that make students emotionally aware while teaching them programming this research aims to prepare students to be cognitively healthy as well as emotionally intelligent with the hypothesis that a kids emotional intelligence can be enhanced while teaching them cognitive skills we proposed a computational model that teaches programming and emotional intelligence side by side to students the model provides a curriculum and related tools for evaluations five hundred students of a public school were involved in different activities to find the effectiveness of the proposed model these students were divided into five groups a b c d and e each having a mean age of 4 5 6 7 and 8 years respectively students performed multiple adaptive scenarios of pathfinding that were based on selfawareness socialawareness sharing and empathy emotions students provide the programming instructions such as sequencing conditional statements and looping to a robot the children have successfully improved in both fundamental programming constructs and emotional intelligence skills the research also successfully reduced screen time problem by providing a screenfree student interface
“Hit the Robot on the Head With This Mallet” - Making a Case for Including More Open Questions in HRI Research,0,"Riddoch, Katie A.; Cross, Emily S.",FRONTIERS IN ROBOTICS AND AI,2021,journalArticle,,2296-9144,10.3389/frobt.2021.603510,,"Researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents, as opposed to objects. One such approach involves asking participants to inflict `harm' on a robot. Researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying, and propose that relatively long periods of hesitation might reflect empathy for the robot, and perhaps even attribution of human-like qualities, such as agency and sentience. In a recent experiment, we adapted the so-called `hesitance to hit' paradigm, in which participants were instructed to hit a humanoid robot on the head with a mallet. After standing up to do so (signaling intent to hit the robot), participants were stopped, and then took part in a semi-structured interview to probe their thoughts and feelings during the period of hesitation. Thematic analysis of the responses indicate that hesitation not only reflects perceived socialness, but also other factors including (but not limited to) concerns about cost, mallet disbelief, processing of the task instruction, and the influence of authority. The open-ended, free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism, perceived power imbalances, and feelings of connection toward the robot. In addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots, we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics.",2021-02-25,2021-04-19T15:56:00Z,2021-04-19T15:56:00Z,,,,,8,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,empathy; human- robot interaction; prosocial behaviour; qualitative research; social perception; social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,hittherobotontheheadwiththismalletmakingacaseforincludingmoreopenquestionsinhriresearch,hit the robot on the head with this mallet  making a case for including more open questions in hri research researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents as opposed to objects one such approach involves asking participants to inflict harm on a robot researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying and propose that relatively long periods of hesitation might reflect empathy for the robot and perhaps even attribution of humanlike qualities such as agency and sentience in a recent experiment we adapted the socalled hesitance to hit paradigm in which participants were instructed to hit a humanoid robot on the head with a mallet after standing up to do so signaling intent to hit the robot participants were stopped and then took part in a semistructured interview to probe their thoughts and feelings during the period of hesitation thematic analysis of the responses indicate that hesitation not only reflects perceived socialness but also other factors including but not limited to concerns about cost mallet disbelief processing of the task instruction and the influence of authority the openended free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism perceived power imbalances and feelings of connection toward the robot in addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics
The Role of Personality Factors and Empathy in the Acceptance and Performance of a Social Robot for Psychometric Evaluations,2,"Rossi, Silvia; Conti, Daniela; Garramone, Federica; Santangelo, Gabriella; Staffa, Mariacarla; Varrasi, Simone; Di Nuovo, Alessandro",ROBOTICS,2020,journalArticle,,,10.3390/robotics9020039,,"Research and development in socially assistive robotics have produced several novel applications in the care of senior people. However, some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users' intellectual capacity. To fully exploit the application of a social robot as a psychometric tool, it is necessary to account for the users' factors that might influence the interaction with a robot and the evaluation of user cognitive performance. To this end, we invited senior participants to use a prototype of a robot-led cognitive test and analyzed the influence of personality traits and user's empathy on the cognitive performance and technology acceptance. Results show a positive influence of a personality trait, the “openness to experience”, on the human-robot interaction, and that other factors, such as anxiety, trust, and intention to use, are influencing technology acceptance and correlate the evaluation by psychometric tests.",2020-06,2021-04-19T15:56:07Z,2021-04-19T15:56:07Z,,,,2,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,empathy; human friendly cognitive robotics; personality factors; psychometric evaluation; social assistive robots; technology acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,theroleofpersonalityfactorsandempathyintheacceptanceandperformanceofasocialrobotforpsychometricevaluations,the role of personality factors and empathy in the acceptance and performance of a social robot for psychometric evaluations research and development in socially assistive robotics have produced several novel applications in the care of senior people however some are still unexplored such as their use as psychometric tools allowing for a quick and dependable evaluation of human users intellectual capacity to fully exploit the application of a social robot as a psychometric tool it is necessary to account for the users factors that might influence the interaction with a robot and the evaluation of user cognitive performance to this end we invited senior participants to use a prototype of a robotled cognitive test and analyzed the influence of personality traits and users empathy on the cognitive performance and technology acceptance results show a positive influence of a personality trait the openness to experience on the humanrobot interaction and that other factors such as anxiety trust and intention to use are influencing technology acceptance and correlate the evaluation by psychometric tests
Affective and Engagement Issues in the Conception and Assessment of a Robot-Assisted Psychomotor Therapy for Persons with Dementia,17,"Rouaix, Natacha; Retru-Chavastel, Laure; Rigaud, Anne-Sophie; Monnet, Clotilde; Lenoir, Hermine; Pino, Maribel",FRONTIERS IN PSYCHOLOGY,2017,journalArticle,,1664-1078,10.3389/fpsyg.2017.00950,,"The interest in robot-assisted therapies (RAT) for dementia care has grown steadily in recent years. However, RAT using humanoid robots is still a novel practice for which the adhesion mechanisms, indications and benefits remain unclear. Also, little is known about how the robot's behavioral and affective style might promote engagement of persons with dementia (PwD) in RAT. The present study sought to investigate the use of a humanoid robot in a psychomotor therapy for PwD. We examined the robot's potential to engage participants in the intervention and its effect on their emotional state. A brief psychomotor therapy program involving the robot as the therapist's assistant was created. For this purpose, a corpus of social and physical behaviors for the robot and a “control software” for customizing the program and operating the robot were also designed. Particular attention was given to components of the RAT that could promote participant's engagement (robot's interaction style, personalization of contents). In the pilot assessment of the intervention nine PwD (7 women and 2 men, M age = 86 y/o) hospitalized in a geriatrics unit participated in four individual therapy sessions: one classic therapy (CT) session (patient-therapist) and three RAT sessions (patient-therapist-robot). Outcome criteria for the evaluation of the intervention included: participant's engagement, emotional state and well-being; satisfaction of the intervention, appreciation of the robot, and empathy-related behaviors in human-robot interaction (HRI). Results showed a high constructive engagement in both CT and RAT sessions. More positive emotional responses in participants were observed in RAT compared to CT. RAT sessions were better appreciated than CT sessions. The use of a social robot as a mediating tool appeared to promote the involvement of PwD in the therapeutic intervention increasing their immediate wellbeing and satisfaction.",2017-06-30,2021-04-19T15:57:00Z,2021-04-19T15:57:00Z,,,,,8,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,control software; dementia; engagement; geriatrics; psychomotor therapy; social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,affectiveandengagementissuesintheconceptionandassessmentofarobotassistedpsychomotortherapyforpersonswithdementia,affective and engagement issues in the conception and assessment of a robotassisted psychomotor therapy for persons with dementia the interest in robotassisted therapies rat for dementia care has grown steadily in recent years however rat using humanoid robots is still a novel practice for which the adhesion mechanisms indications and benefits remain unclear also little is known about how the robots behavioral and affective style might promote engagement of persons with dementia pwd in rat the present study sought to investigate the use of a humanoid robot in a psychomotor therapy for pwd we examined the robots potential to engage participants in the intervention and its effect on their emotional state a brief psychomotor therapy program involving the robot as the therapists assistant was created for this purpose a corpus of social and physical behaviors for the robot and a control software for customizing the program and operating the robot were also designed particular attention was given to components of the rat that could promote participants engagement robots interaction style personalization of contents in the pilot assessment of the intervention nine pwd 7 women and 2 men m age  86 yo hospitalized in a geriatrics unit participated in four individual therapy sessions one classic therapy ct session patienttherapist and three rat sessions patienttherapistrobot outcome criteria for the evaluation of the intervention included participants engagement emotional state and wellbeing satisfaction of the intervention appreciation of the robot and empathyrelated behaviors in humanrobot interaction hri results showed a high constructive engagement in both ct and rat sessions more positive emotional responses in participants were observed in rat compared to ct rat sessions were better appreciated than ct sessions the use of a social robot as a mediating tool appeared to promote the involvement of pwd in the therapeutic intervention increasing their immediate wellbeing and satisfaction
Probabilistic Social Behavior Analysis by Exploring Body Motion-Based Patterns,17,"Roudposhti, Kamrad Khoshhal; Nunes, Urbano; Dias, Jorge",IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE IN℡LIGENCE,2016,journalArticle,,0162-8828,10.1109/TPAMI.2015.2496209,,"Understanding human behavior through nonverbal-based features, is interesting in several applications such as surveillance, ambient assisted living and human-robot interaction. In this article in order to analyze human behaviors in social context, we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation. The novelty of this method is that we analyze body motion-based features in frequency domain to estimate different human social patterns: Interpersonal Behaviors (IBs) and a Social Role (SR). To analyze the dynamics and interrelations of people's body motions, a human movement descriptor is used to extract discriminative features, and a multi-layer Dynamic Bayesian Network (DBN) technique is proposed to model the existent dependencies. Laban Movement Analysis (LMA) is a well-known human movement descriptor, which provides efficient mid-level information of human body motions. The mid-level information is useful to extract the complex interdependencies. The DBN technique is tested in different scenarios to model the mentioned complex dependencies. The study is applied for obtaining four IBs (Interest, Indicator, Empathy and Emphasis) to estimate one SR (Leading). The obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in human-robot interaction.",2016-08,2021-04-19T15:57:15Z,2021-04-19T15:57:15Z,,1679-1691,13,"8, SI",38,,,,,,,,,,English,,,,,,,"Place: 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA Publisher: IEEE COMPUTER SOC Type: Article",,,,,Bayesian approach; frequency domain; human movement analysis; social role; Social signal processing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,probabilisticsocialbehavioranalysisbyexploringbodymotionbasedpatterns,probabilistic social behavior analysis by exploring body motionbased patterns understanding human behavior through nonverbalbased features is interesting in several applications such as surveillance ambient assisted living and humanrobot interaction in this article in order to analyze human behaviors in social context we propose a new approach which explores interrelations between body part motions in scenarios with people doing a conversation the novelty of this method is that we analyze body motionbased features in frequency domain to estimate different human social patterns interpersonal behaviors ibs and a social role sr to analyze the dynamics and interrelations of peoples body motions a human movement descriptor is used to extract discriminative features and a multilayer dynamic bayesian network dbn technique is proposed to model the existent dependencies laban movement analysis lma is a wellknown human movement descriptor which provides efficient midlevel information of human body motions the midlevel information is useful to extract the complex interdependencies the dbn technique is tested in different scenarios to model the mentioned complex dependencies the study is applied for obtaining four ibs interest indicator empathy and emphasis to estimate one sr leading the obtained results give a good indication of the capabilities of the proposed approach for people interaction analysis with potential applications in humanrobot interaction
Vocal Synchrony of Robots Boosts Positive Affective Empathy,0,"S Nishimura, T Nakamura, W Sato, M Kanbara…",Applied Sciences,2021,journalArticle,,2076-3417,10.3390/app11062502,,"Robots that can talk with humans play increasingly important roles in society. However, current conversation robots remain unskilled at eliciting empathic feelings in humans. To address this problem, we used a robot that speaks in a voice synchronized with human vocal prosody. We conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization. We assessed seven subjective responses related to affective empathy (e.g., emotional connection) and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level. The subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the de-synchronizing condition. The physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization. These findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses.",2021,2021-04-20T16:54:53Z,2021-04-20T16:54:53Z,,,,2502,11,,,,,,,,,,English,,,,,Open WorldCat,,OCLC: 8974746860,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,vocalsynchronyofrobotsboostspositiveaffectiveempathy,vocal synchrony of robots boosts positive affective empathy robots that can talk with humans play increasingly important roles in society however current conversation robots remain unskilled at eliciting empathic feelings in humans to address this problem we used a robot that speaks in a voice synchronized with human vocal prosody we conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization we assessed seven subjective responses related to affective empathy eg emotional connection and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level the subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the desynchronizing condition the physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization these findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses
Embodiment matters: toward culture-specific robotized counselling,0,"Sakurai, Eriko; Kurashige, Kentarou; Tsuruta, Setsuo; Sakurai, Yoshitaka; Knauf, Rainer; Damiani, Ernesto; Kutics, Andrea; Frati, Fulvio",Journal of Reliable Intelligent Environments,2020,journalArticle,,2199-4668,10.1007/s40860-020-00109-y,,"Abstract: In this paper, we propose adding the traditional Japanese nodding behavior to the repertoire of social movements to be used in the context of human–robot interaction. Our approach is motivated by the notion that in many cultures, trust-building can be boosted by small body gestures. We discuss the integration of a robot capable of such movements within CRECA, our context-respectful counseling agent. The frequent nodding called “unazuki” in Japan, often accompanying the “un-un” sound (meaning “I agree”) of Japanese onomatopoeia, underlines empathy and embodies unconditioned approval. We argue that “unazuki” creates more empathy and promotes longer conversation between the robotic counsellor and people. We set up an experiment involving ten subjects to verify these effects. Our quantitative evaluation is based on the classic metrics of utterance, adapted to support the Japanese language. Interactions featuring “unazuki” showed higher value of this metrics. Moreover, subjects assessed the counselling robot’s trustworthiness and kindness as “very high” (Likert scale: 5.5 versus 3—4.5) showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation. Our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions, with unambiguous evidence that embodiment can have a positive impact that warrants further exploration. The 3D printable design of our robot supports creating culture-specific libraries of social movements, adapting the gestural repertoire to different human cultures.",2020,2021-04-20T16:55:19Z,2021-04-20T16:55:19Z,,129-139,11,3,6,,,Embodiment matters,,,,,,,English,,,,,Open WorldCat,,OCLC: 8644462671,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,embodimentmatterstowardculturespecificrobotizedcounselling,embodiment matters toward culturespecific robotized counselling abstract in this paper we propose adding the traditional japanese nodding behavior to the repertoire of social movements to be used in the context of humanrobot interaction our approach is motivated by the notion that in many cultures trustbuilding can be boosted by small body gestures we discuss the integration of a robot capable of such movements within creca our contextrespectful counseling agent the frequent nodding called unazuki in japan often accompanying the unun sound meaning i agree of japanese onomatopoeia underlines empathy and embodies unconditioned approval we argue that unazuki creates more empathy and promotes longer conversation between the robotic counsellor and people we set up an experiment involving ten subjects to verify these effects our quantitative evaluation is based on the classic metrics of utterance adapted to support the japanese language interactions featuring unazuki showed higher value of this metrics moreover subjects assessed the counselling robots trustworthiness and kindness as very high likert scale 55 versus 345 showing the effect of social gestures in promoting empathetic dialogue to general people including the younger generation our findings support the importance of social movements when using robotized agents as a therapeutic tool aimed at improving emotional state and social interactions with unambiguous evidence that embodiment can have a positive impact that warrants further exploration the 3d printable design of our robot supports creating culturespecific libraries of social movements adapting the gestural repertoire to different human cultures
A pupil response system using hemispherical displays for enhancing affective conveyance,2,"Sejima, Yoshihiro; Egawa, Shoichi; Sato, Yoichiro; Watanabe, Tomio",JOURNAL OF ADVANCED MECHANICAL DESIGN SYSTEMS AND MANUFACTURING,2019,journalArticle,,1881-3054,10.1299/jamdsm.2019jamdsm0032,,"In human interaction and communication, not only verbal messages but also nonverbal behaviors such as facial expressions, body movements, gazes and pupil responses play an important role in expressions of talker's affect. These expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy. We focused on the pupil response which is closely related to human affect, and developed an embodied communication system in which an interactive CG character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input. In addition, it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system. In this paper, in order to realize the smooth interaction between human and robot, we developed a pupil response system using hemispherical displays for enhancing affective conveyance. This system looks like robot's eyeballs and expresses vivid pupil response by speech input. We carried out a sensory evaluation experiment under the condition that the developed system speaks. The results demonstrated that the system effectively enhances affective conveyance.",2019,2021-04-19T15:56:35Z,2021-04-19T15:56:35Z,,,,2,13,,,,,,,,,,English,,,,,,,"Place: SHINANOMACHI-RENGAKAN BLDG., SHINANOMACHI 35, SHINJUKU-KU, TOKYO, 160-0016, JAPAN Publisher: JAPAN SOC MECHANICAL ENGINEERS Type: Article",,,,,Empathy; Human interface; Human-robot interaction design; Kansei and affective engineering; Media representation; Pupil response,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,apupilresponsesystemusinghemisphericaldisplaysforenhancingaffectiveconveyance,a pupil response system using hemispherical displays for enhancing affective conveyance in human interaction and communication not only verbal messages but also nonverbal behaviors such as facial expressions body movements gazes and pupil responses play an important role in expressions of talkers affect these expressions encourage to read the emotional cues and to cause the sharing of embodiment and empathy we focused on the pupil response which is closely related to human affect and developed an embodied communication system in which an interactive cg character generates the pupil response as well as communicative actions and movements such as nodding and body movements by speech input in addition it was confirmed that the pupil response is effective for supporting the embodied interaction and communication using the developed system in this paper in order to realize the smooth interaction between human and robot we developed a pupil response system using hemispherical displays for enhancing affective conveyance this system looks like robots eyeballs and expresses vivid pupil response by speech input we carried out a sensory evaluation experiment under the condition that the developed system speaks the results demonstrated that the system effectively enhances affective conveyance
Deep learning-based facial expression recognition and analysis for filipino gamers,0,"Sena, J.R.; Cabatuan, M.",International Journal of Recent Technology and Engineering,2019,journalArticle,,22773878,10.35940/ijrte.B1027.078219,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071449687&doi=10.35940%2fijrte.B1027.078219&partnerID=40&md5=041053fce7bebbb4ee45a2dd81ddb286,"This paper presents a computer vision based emotion recognition system for the identification of six basic emotions among Filipino Gamers using deep learning techniques. In particular, the proposed system utilized deep learning through the Inception Network and Long-Short Term Memory (LSTM). The researchers gathered a database for Filipino Facial Expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data. The system was able to produce a maximum categorical validation accuracy of.9983 and a test accuracy of.9940 for the six basic emotions using the Filipino database. The cross-database analysis results using the well-known Cohn-Kanade+ database showed that the proposed Inception-LSTM system has accuracy on a par with the current existing systems. The results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept. © BEIESP.",2019,2021-04-20T16:38:38Z,2021-04-20T16:38:38Z,,1822-1827,6,2,8,,,,,,,,,,English,,,,,,,Publisher: Blue Eyes Intelligence Engineering and Sciences Publication,<p>cited By 0</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,deeplearningbasedfacialexpressionrecognitionandanalysisforfilipinogamers,deep learningbased facial expression recognition and analysis for filipino gamers this paper presents a computer vision based emotion recognition system for the identification of six basic emotions among filipino gamers using deep learning techniques in particular the proposed system utilized deep learning through the inception network and longshort term memory lstm the researchers gathered a database for filipino facial expressions consisting of 74 gamers for the training data and 4 gamer subjects for the testing data the system was able to produce a maximum categorical validation accuracy of9983 and a test accuracy of9940 for the six basic emotions using the filipino database the crossdatabase analysis results using the wellknown cohnkanade database showed that the proposed inceptionlstm system has accuracy on a par with the current existing systems the results demonstrated the feasibility of the proposed system and showed sample computations of empathy and engagement based on the six basic emotions as a proof of concept  beiesp
Meeting the Needs of Mothers During the Postpartum Period: Using Co-Creation Workshops to Find Technological Solutions,18,"Slomian, Justine; Emonts, Patrick; Vigneron, Lara; Acconcia, Alessandro; Reginster, Jean-Yves; Oumourgh, Mina; Bruyere, Olivier",JMIR RESEARCH PROTOCOLS,2017,journalArticle,,1929-0748,10.2196/resprot.6831,,"Background: The postnatal period is associated with many new needs for mothers. Objective: The aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth. Methods: Two co-creation workshops were undertaken with parents and professionals. The aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth. The aim of the second workshop was to create solutions in response to the criteria selected during the first workshop. Results: Parents and health professionals want solutions that include empathy (ie, to help fight against the feelings of abnormality and loneliness), that help mothers in daily life, that are personalized and adapted to different situations, that are educational, and that assures some continuity in their contact with health professionals. In practice, we found that parents and professionals think the solution should be accessible to everyone and available at all times. To address these criteria, technology experts proposed different solutions, such as a forum dedicated to the postpartum period that is supervised by professionals, a centralized website, a system of videoconferencing, an online exchange group, a “gift voucher” system, a virtual reality app, or a companion robot. Conclusions: The human component seems to be very important during the postnatal period. Nevertheless, technology could be a great ally in helping mothers during the postpartum period. Technology can help reliably inform parents and may also give them the right tools to find supportive people. However, these technologies should be tested in clinical trials.",2017-05,2021-04-19T15:57:01Z,2021-04-19T15:57:01Z,,,,5,6,,,,,,,,,,English,,,,,,,"Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article",,,,,co-creating workshop; co-creation; mothers' needs; postpartum needs; technological solutions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,meetingtheneedsofmothersduringthepostpartumperiodusingcocreationworkshopstofindtechnologicalsolutions,meeting the needs of mothers during the postpartum period using cocreation workshops to find technological solutions background the postnatal period is associated with many new needs for mothers objective the aim of this study was to find technological solutions that meet the needs of mothers during the year following childbirth methods two cocreation workshops were undertaken with parents and professionals the aim of the first workshop was to create a list of all the criteria the proposed solution would have to address to meet the needs of mothers after childbirth the aim of the second workshop was to create solutions in response to the criteria selected during the first workshop results parents and health professionals want solutions that include empathy ie to help fight against the feelings of abnormality and loneliness that help mothers in daily life that are personalized and adapted to different situations that are educational and that assures some continuity in their contact with health professionals in practice we found that parents and professionals think the solution should be accessible to everyone and available at all times to address these criteria technology experts proposed different solutions such as a forum dedicated to the postpartum period that is supervised by professionals a centralized website a system of videoconferencing an online exchange group a gift voucher system a virtual reality app or a companion robot conclusions the human component seems to be very important during the postnatal period nevertheless technology could be a great ally in helping mothers during the postpartum period technology can help reliably inform parents and may also give them the right tools to find supportive people however these technologies should be tested in clinical trials
Measuring empathy for human and robot hand pain using electroencephalography,98,"Suzuki, Yutaka; Galli, Lisa; Ikeda, Ayaka; Itakura, Shoji; Kitazaki, Michiteru",SCIENTIFIC REPORTS,2015,journalArticle,,2045-2322,10.1038/srep15924,,"This study provides the first physiological evidence of humans' ability to empathize with robot pain and highlights the difference in empathy for humans and robots. We performed electroencephalography in 15 healthy adults who observed either human- or robot-hand pictures in painful or non-painful situations such as a finger cut by a knife. We found that the descending phase of the P3 component was larger for the painful stimuli than the non-painful stimuli, regardless of whether the hand belonged to a human or robot. In contrast, the ascending phase of the P3 component at the frontal-central electrodes was increased by painful human stimuli but not painful robot stimuli, though the interaction of ANOVA was not significant, but marginal. These results suggest that we empathize with humanoid robots in late top-down processing similarly to human others. However, the beginning of the top-down process of empathy is weaker for robots than for humans.",2015-11-03,2021-04-19T15:57:29Z,2021-04-19T15:57:29Z,,,,,5,,,,,,,,,,English,,,,,,,"Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,measuringempathyforhumanandrobothandpainusingelectroencephalography,measuring empathy for human and robot hand pain using electroencephalography this study provides the first physiological evidence of humans ability to empathize with robot pain and highlights the difference in empathy for humans and robots we performed electroencephalography in 15 healthy adults who observed either human or robothand pictures in painful or nonpainful situations such as a finger cut by a knife we found that the descending phase of the p3 component was larger for the painful stimuli than the nonpainful stimuli regardless of whether the hand belonged to a human or robot in contrast the ascending phase of the p3 component at the frontalcentral electrodes was increased by painful human stimuli but not painful robot stimuli though the interaction of anova was not significant but marginal these results suggest that we empathize with humanoid robots in late topdown processing similarly to human others however the beginning of the topdown process of empathy is weaker for robots than for humans
Avatars in Pain: Visible Harm Enhances Mind Perception in Humans and Robots,8,"Swiderska, Aleksandra; Kuester, Dennis",PERCEPTION,2018,journalArticle,,0301-0066,10.1177/0301006618809919,,"Previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind, their attributions of mind to that entity increased. Currently, we investigated if the presence of a facial wound enhanced the perception of mental capacities (experience and agency) in response to images of robotic and human-like avatars, compared with unharmed avatars. The results revealed that harmed versions of both robotic and human-like avatars were imbued with mind to a higher degree, irrespective of the baseline level of mind attributed to their unharmed counterparts. Perceptions of capacity for pain mediated attributions of experience, while both pain and empathy mediated attributions of abilities linked to agency. The findings suggest that harm, even when it appears to have been inflicted unintentionally, may augment mind perception for robotic as well as for nearly human entities, at least as long as it is perceived to elicit pain.",2018-12,2021-04-19T15:56:40Z,2021-04-19T15:56:40Z,,1139-1152,14,12,47,,,,,,,,,,English,,,,,,,"Place: 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND Publisher: SAGE PUBLICATIONS LTD Type: Article",,,,,anthropomorphism; empathy; harm; mind perception; pain; robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,avatarsinpainvisibleharmenhancesmindperceptioninhumansandrobots,avatars in pain visible harm enhances mind perception in humans and robots previous research has shown that when people read vignettes about the infliction of harm upon an entity appearing to have no more than a liminal mind their attributions of mind to that entity increased currently we investigated if the presence of a facial wound enhanced the perception of mental capacities experience and agency in response to images of robotic and humanlike avatars compared with unharmed avatars the results revealed that harmed versions of both robotic and humanlike avatars were imbued with mind to a higher degree irrespective of the baseline level of mind attributed to their unharmed counterparts perceptions of capacity for pain mediated attributions of experience while both pain and empathy mediated attributions of abilities linked to agency the findings suggest that harm even when it appears to have been inflicted unintentionally may augment mind perception for robotic as well as for nearly human entities at least as long as it is perceived to elicit pain
Testing Empathy with Robots: A Model in Four Dimensions and Sixteen Items,12,"Tisseron, Serge; Tordo, Frederic; Baddoura, Ritta",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2015,journalArticle,,1875-4791,10.1007/s12369-014-0268-5,,"The four-dimensional model of empathy presented in this paper addresses human-human, human-avatar and human-robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things - emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction.",2015-02,2021-04-19T15:57:33Z,2021-04-19T15:57:33Z,,97-102,6,1,7,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Auto-empathy; Direct empathy; Empathy with robots; Human-robot interaction; Intersubjective empathy; Psychology; Reciprocal empathy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,testingempathywithrobotsamodelinfourdimensionsandsixteenitems,testing empathy with robots a model in four dimensions and sixteen items the fourdimensional model of empathy presented in this paper addresses humanhuman humanavatar and humanrobot interaction and aims at better understanding the specificities of the empathy that humans might develop towards robots its first dimension is autoempathy and refers to an empathetic relationship with oneself how can a human directing a robot expand the various components of empathy he feels for himself to this robot the second is direct empathy what does a human attribute to a robot in terms of thoughts emotions action potentials or even altruism on the model of what he imagines and attributes to himself the third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me feel or guess my emotions and thoughts anticipate my actions and wear me assistance if necessary finally the fourth dimension intersubjective empathy is about thinking and imagining that a robot can inform me of things  emotions thoughts that i am likely to experience that i do not know about myself each of these four dimensions includes four different components 1 action empathy of action 2 emotion emotional empathy 3 cognition cognitive empathy and 4 assistance empathy of assistance this theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving humanhuman and humanrobot interaction
Fake Empathy and Human-Robot Interaction (HRI): A Preliminary Study,6,"Vallverdu, Jordi; Nishida, Toyoaki; Ohmoto, Yoshisama; Moran, Stuart; Lazare, Sarah",INTERNATIONAL JOURNAL OF TECHNOLOGY AND HUMAN INTERACTION,2018,journalArticle,,1548-3908,10.4018/IJTHI.2018010103,,"Empathy is a basic emotion trigger for human beings, especially while regulating social relationships and behaviour. The main challenge of this paper is study whether people's empathic reactions towards robots change depending on previous information given to human about the robot before the interaction. The use of false data about robot skills creates different levels of what we call `fake empathy'. This study performs an experiment in WOZ environment in which different subjects (n=17) interacting with the same robot while they believe that the robot is a different robot, up to three versions. Each robot scenario provides a different `humanoid' description, and out hypothesis is that the more human-like looks the robot, the more empathically can be the human responses. Results were obtained from questionnaires and multi-angle video recordings. Positive results reinforce the strength of our hypothesis, although we recommend a new and bigger and then more robust experiment.",2018-03,2021-04-19T15:56:58Z,2021-04-19T15:56:58Z,,44-59,16,1,14,,,,,,,,,,English,,,,,,,"Place: 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA Publisher: IGI GLOBAL Type: Article",,,,,Emotions; Empathy; Fake; HRI; Human-Robot Interaction; Robots; WOZ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,fakeempathyandhumanrobotinteractionhriapreliminarystudy,fake empathy and humanrobot interaction hri a preliminary study empathy is a basic emotion trigger for human beings especially while regulating social relationships and behaviour the main challenge of this paper is study whether peoples empathic reactions towards robots change depending on previous information given to human about the robot before the interaction the use of false data about robot skills creates different levels of what we call fake empathy this study performs an experiment in woz environment in which different subjects n17 interacting with the same robot while they believe that the robot is a different robot up to three versions each robot scenario provides a different humanoid description and out hypothesis is that the more humanlike looks the robot the more empathically can be the human responses results were obtained from questionnaires and multiangle video recordings positive results reinforce the strength of our hypothesis although we recommend a new and bigger and then more robust experiment
Embodiment into a robot increases its acceptability,9,"Ventre-Dominey, J.; Gibert, G.; Bosse-Platiere, M.; Farne, A.; Dominey, P. F.; Pavani, F.",SCIENTIFIC REPORTS,2019,journalArticle,,2045-2322,10.1038/s41598-019-46528-7,,"Recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes (closeness, empathy, racial biases). Here we use a simple neuroscience-inspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot. Participants wore a Head Mounted Display tracking their head movements and displaying the 3D visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects' head movements. As a result, participants saw themselves as a robot. When participant' and robot's head movements were correlated, participants felt that they were incorporated into the robot with a sense of agency. Critically, the robot they embodied was judged more likeable and socially closer. Remarkably, we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity, was independent of robots' humanoid's appearance. These findings not only reveal the ease of body-swapping, via visual-motor synchrony, into robots that do not share any clear human resemblance, but they may also pave a new way to make our future robotic helpers socially acceptable.",2019-07-12,2021-04-19T15:56:20Z,2021-04-19T15:56:20Z,,,,,9,,,,,,,,,,English,,,,,,,"Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,embodimentintoarobotincreasesitsacceptability,embodiment into a robot increases its acceptability recent studies have shown how embodiment induced by multisensory bodily interactions between individuals can positively change social attitudes closeness empathy racial biases here we use a simple neuroscienceinspired procedure to beam our human subjects into one of two distinct robots and demonstrate how this can readily increase acceptability and social closeness to that robot participants wore a head mounted display tracking their head movements and displaying the 3d visual scene taken from the eyes of a robot which was positioned in front of a mirror and piloted by the subjects head movements as a result participants saw themselves as a robot when participant and robots head movements were correlated participants felt that they were incorporated into the robot with a sense of agency critically the robot they embodied was judged more likeable and socially closer remarkably we found that the beaming experience with correlated head movements and corresponding sensation of embodiment and social proximity was independent of robots humanoids appearance these findings not only reveal the ease of bodyswapping via visualmotor synchrony into robots that do not share any clear human resemblance but they may also pave a new way to make our future robotic helpers socially acceptable
Emotional Empathy Model for Robot Partners Using Recurrent Spiking Neural Network Model with Hebbian-LMS Learning,12,"Woo, Jinseok; Botzheim, Janos; Kubota, Naoyuki",MALAYSIAN JOURNAL OF COMPUTER SCIENCE,2017,journalArticle,,0127-9084,10.22452/mjcs.vol30no4.1,,"This paper discusses the development of an emotion model for robot partner system. In our previous studies, we have focused only on the robot's emotional state. However, the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore, the robot partner has two emotional structures for human: empathy and robot emotion. First, human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next, we propose a recurrent simple spike response model to improve the robot's emotional model, and we apply “Hebbian-LMS” learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information, internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result, the robot partner can interact emotionally and naturally with human. First, we explain the related works and the development of the robot partner “iPhonoid-C”. Next, we define the architecture of the emotional model to realize emotional empathy towards human. Then, we discuss the algorithms and the methods for developing the emotional model. Finally, we show experimental results of the proposed method, and discuss the effectiveness of the proposed structure.",2017,2021-04-19T15:57:07Z,2021-04-19T15:57:07Z,,258-285,28,4,30,,,,,,,,,,English,,,,,,,"Place: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA Publisher: UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH Type: Article",,,,,Conversation System; Emotional Empathy Model; Hebbian-LMS Learning; Recurrent Spiking Neural Network; Robot Partner,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,emotionalempathymodelforrobotpartnersusingrecurrentspikingneuralnetworkmodelwithhebbianlmslearning,emotional empathy model for robot partners using recurrent spiking neural network model with hebbianlms learning this paper discusses the development of an emotion model for robot partner system in our previous studies we have focused only on the robots emotional state however the emotional state of the other party is also an important factor for smooth conversation in human society therefore the robot partner has two emotional structures for human empathy and robot emotion first human empathy uses a perceptual based emotion model to know the humans emotional state based on the sensory information next we propose a recurrent simple spike response model to improve the robots emotional model and we apply hebbianlms learning to modify the weights in the spiking neural network the robots emotional state is calculated by using the humans emotional information internal and external information the robot partner can use the emotional results to control the facial and gesture expression the utterance style is also changed by the robots emotional state as a result the robot partner can interact emotionally and naturally with human first we explain the related works and the development of the robot partner iphonoidc next we define the architecture of the emotional model to realize emotional empathy towards human then we discuss the algorithms and the methods for developing the emotional model finally we show experimental results of the proposed method and discuss the effectiveness of the proposed structure
A computational model of empathy for interactive agents,18,"Yalcin, Ozge Nilay; DiPaola, Steve",BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES,2018,journalArticle,,2212-683X,10.1016/j.bica.2018.07.010,,"Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.",2018-10,2021-04-19T15:56:42Z,2021-04-19T15:56:42Z,,20-25,6,,26,,,,,,,,,,English,,,,,,,"Place: PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS Publisher: ELSEVIER SCIENCE BV Type: Article",,,,,Affective computing; Conversational agents; Empathy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,acomputationalmodelofempathyforinteractiveagents,a computational model of empathy for interactive agents empathy has been defined in the scientific literature as the capacity to relate anothers emotional state and assigned to a broad spectrum of cognitive and behavioral abilities advances in neuroscience psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy recently cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents which can provide means to test these models and hypotheses a computational model of empathy not only would help to advance the technological artifacts to be more socially compatible but also understand the empathy mechanisms test theories and address the ethics and morality problems the artificial intelligence ai community is facing today in this paper we will review the empathy research from various fields gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents
Teach your robot how you want it to express emotions: On the personalized affective human-humanoid interaction,0,"Virčíkova, M.; Sinčák, P.",Advances in Intelligent Systems and Computing,2015,bookChapter,,21945357,10.1007/978-3-319-10783-7_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032118207&doi=10.1007%2f978-3-319-10783-7_9&partnerID=40&md5=22af8b608d901d438a4c1910a06c47ef,"We believe that in order for robots to interact naturally with humans, they should be able to express affective behavior. This paper deals with the development of an affective model for social robotics in which the resulting robotic expressions adapt according to the human subjective preferences. We have developed a method which can be used by non-technical individuals to design the affective models of humanoid robots. Our vision of the future research is that the proposed personalization will be treated, from user’s perspective, as an empathic response of the machine. We see the major contribution of this unique approach especially in long-term human-robot relationships and it could ultimately lead to robots being accepted in a wider domain. © Springer International Publishing Switzerland 2015.",2015,2021-05-19T13:26:44Z,2021-05-19T13:26:44Z,,81-92,12,,316,,,,,,,,,,English,,,,,,,Publisher: Springer Verlag,<p>cited By 0</p>,,,Affective behaviors; Affective model; Anthropomorphic robots; Computer vision; Economic and social effects; Express emotions; Human robot interaction; Human robots; Humanoid interaction; Humanoid robot; Machine design; Personalizations; Robotics; Robots; Social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increasing Engagement with Chameleon Robots in Bartending Services,0,"Rossi, Silvia; Dell'Aquila, Elena; Russo, Davide; Maggi, Gianpaolo",2020 29TH IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2020,conferencePaper,978-1-72816-075-7,,10.1109/RO-MAN47096.2020.9223488,,"As the field of service robotics has been rapidly growing, it is expected for such robots to be endowed with the appropriate capabilities to interact with humans in a socially acceptable way. This is particularly relevant in the case of customer relationships where a positive and affective interaction has an impact on the users' experience. In this paper, we address the question of whether a specific behavioral style of a barman-robot, acted through para-verbal and non-verbal behaviors, can affect users' engagement and the creation of positive emotions. To that end, we endowed a barman-robot taking drink orders from human customers, with an empathic behavioral style. This aims at triggering to alignment process by mimicking the conversation partner's behavior. This behavioral style is compared to an entertaining style, aiming at creating a positive relationship with the users, and a neutral style for control. Results suggest that when participants experienced more positive emotions, the robot was perceived as safer, so suggesting that interactions that stimulate positive and open relations with the robot may have a positive impact on the affective dimension of engagement. Indeed, when the empathic robot modulates its behavior according to the user's one, this interaction seems to be more effective than when interacting with a neutral robot in improving engagement and positive emotions in public-service contexts.",2020,2021-05-19T13:30:12Z,2021-05-19T13:30:12Z,,464-469,6,,,,,,IEEE RO-MAN,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Robot & Automat Soc; Robot Soc Japan; Korean Robot Soc; Furhat Robot; EurAi; Assoc Italiana Lingusitica Computazionale; Assoc Italiana Scienze Voce; Springer; Robotics ISSN: 1944-9445 Type: Proceedings Paper,"<p>29th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN), ELECTR NETWORK, AUG 31-SEP 04, 2020</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New Trend on ASD: Can Social Robot Be a Useful Tool in Joint Attention for ASD?,0,"Sani-Bozkurt, Sunagul; Bozkus-Genc, Gulden","14TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT CONFERENCE (INTED2020)",2020,conferencePaper,978-84-09-17939-8,,,,"Children with Autism Spectrum Disorder (ASD) suffer from a characteristic impairment in the ability to interpret social cues and often fail to use social gaze in empathetic and joint-attention tasks. The behavior of tracking an adult's eye movements, which appears in typically developing children in about 6th month, is considered as the beginning point of the ability to respond to joint attention. Studies show that children with ASD exhibit less joint attention skill and they fail in looking at the direction others are looking at and pointing at and in following the direction others are looking at, pointing at when they are compared to typically developing children and other children with developmental retardation. It is reported in some studies that the behaviors of responding to others' joint attention and initiation to joint attention are taught separately, and in other studies, both joint attention abilities are taught together. Nowadays, robot applications have appeared as a new approach in ASD implementations as a result of technological and scientific developments. Various social robots have been produced with an aim to increase the motivation of those with ASD by decreasing the stress level in complicated situations in the social setting and by enabling them to learn in simpler, predictable, and controlled settings. Besides, recently, social robots have increasingly been used in teaching joint attention abilities. In this study, it was aimed to give information about joint attention and types of robots, explain the characteristics of social robots, and put forward the current trends related to social robots by examining the studies conducted on the use of social robots for teaching joint attention abilities to children with ASD. Social robots could be a promising method for ASD treatment. There are remarkably different results regarding the robot applications in teaching the joint attention abilities to children with ASD. Therefore, it is not definitively known to which extent robot therapy contributes to the student's joint attention improvement. While efficiency research is frequently conducted in the studies in which robots have been used for teaching joint attention abilities to children with ASD, although rarely, comparative studies have also been conducted in recent years. Positive results are mentioned in this efficiency research, whereas there are also controversial results. In comparative studies, it is noteworthy that the human being and robot applications were compared in only one study. As a result, robots are thought to provide a significant support for the development of joint attention interactions such as attracting the attention of children, helping them participate in activities, building a bond for social interaction, motivating them, providing natural stimuli and bringing about different emotional expressions although there are different results about robot applications in the development of the joint attention abilities of children with ASD. In the related literature, it is also suggested to work with larger and different sample groups in order to generalize the existing study results since it is observed that the dimension of generalization is not addressed. Further studies in which robots play an active role compared to therapists can be carried out.",2020,2021-05-19T13:30:16Z,2021-05-19T13:30:16Z,,2090-2097,8,,,,,,INTED Proceedings,,,,IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT,"LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN",English,,,,,,,ISSN: 2340-1079 Type: Proceedings Paper,"<p>14th International Technology, Education and Development Conference (INTED), Valencia, SPAIN, MAR 02-04, 2020</p>",,,,Autism spectrum disorder; joint attention; robots; social robot,"Chova, LG and Martinez, AL and Torres, IC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Towards Metrics of Evaluation of Pepper Robot as a Social Companion for the Elderly,15,"Bechade, Lucile; Dubuisson-Duplessis, Guillaume; Pittaro, Gabrielle; Garcia, Melanie; Devillers, Laurence",ADVANCED SOCIAL INTERACTION WITH AGENTS,2019,conferencePaper,978-3-319-92108-2 978-3-319-92107-5,,10.1007/978-3-319-92108-2_11,,"For the design of socially acceptable robots, field studies in Human-Robot Interaction are necessary. Constructing dialogue benchmarks can have a meaning only if researchers take into account the evaluation of robot, human, and their interaction. This paper describes a study aiming at finding an objective evaluation procedure of the dialogue with a social robot. The goal is to build an empathic robot (JOKER project) and it focuses on elderly people, the end-users expected by ROMEO2 project. The authors carried out three experimental sessions. The first time, the robot was NAO, and it was with a Wizard of Oz (emotions were entered manually by experimenters as inputs to the program). The other times, the robot was Pepper, and it was totally autonomous (automatic detection of emotions and decision according to). Each interaction involved various scenarios dealing with emotion recognition, humor, negotiation and cultural quiz. The paper details the system functioning, the scenarios and the evaluation of the experiments.",2019,2021-05-19T13:30:29Z,2021-05-19T13:30:29Z,,89-101,13,,510,,,,Lecture Notes in Electrical Engineering,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 1876-1100 Type: Proceedings Paper,"<p>8th International Workshop on Spoken Dialogue Systems (IWSDS), Farmington, PA, JUN 06-09, 2017</p>",,,,Data collection; Elderly end-users; Evaluation; Human-Robot Interaction; Metrics,"Eskenazi, M and Devillers, L and Mariani, J",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Towards a Multimodal Time-Based Empathy Prediction System,1,"Barbieri, Francesco; Guizzo, Eric; Lucchesi, Federico; Maffei, Giovanni; del Prado Martin, Fermin Moscoso; Weyde, Tillman",2019 14TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION (FG 2019),2019,conferencePaper,978-1-72810-089-0,,10.1109/FG.2019.8756532,,We describe our system for empathic emotion recognition. It is based on deep learning on multiple modalities in a late fusion architecture. We describe the modules of our system and discuss the evaluation results. Our code is also available for the research community(1),2019,2021-05-19T13:30:34Z,2021-05-19T13:30:34Z,,716-720,5,,,,,,IEEE International Conference on Automatic Face and Gesture Recognition and Workshops,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,"Backup Publisher: IEEE; Univ Lille; Inst Mines Telecom; Univ Lille, Inst Mines Telecom, Ecole Mines Telecom, IMT Lille Douai; INRIA; 3DMD; Google; I Site Univ Lille Nord Europe; Centre Rech Informatique Signal Automatique Lille; IEEE Comp Soc; IEEE Biometr Council ISSN: 2326-5396 Type: Proceedings Paper","<p>14th IEEE International Conference on Automatic Face and Gesture Recognition (FG), Lille, FRANCE, MAY 14-18, 2019</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DYNECOM: Augmenting Empathy in VR with Dyadic Synchrony Neurofeedback,3,"Jarvela, Simo; Salminen, Mikko; Ruonala, Antti; Timonen, Janne; Mannermaa, Kristiina; Ravaja, Niklas; Jacucci, Giulio",PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES,2019,conferencePaper,978-0-9981331-2-6,,10.24251/HICSS.2019.509,,"In a novel experimental setting, we augmented a variation of traditional compassion meditation with our custom built VR environment for multiple concurrent users. The system incorporates respiration and brainwave based biofeedback that enables responsiveness to the shared physiological states of the users. The presence of another user's avatar in the shared virtual space supported low level social interactions and provided active targets for evoked compassion. We enhanced interoception and the deep empathetic processes involved in compassion meditation with real time visualizations of breathing rates and the level of approach motivation assessed from EEG frontal asymmetry, and the dyadic synchrony of those signals between the two users. We found how the different biofeedback types increased both the amount of physiological synchrony between the users and their self-reported empathy, illustrating how dyadic synchrony biofeedback can expand the possibilities of biofeedback in affective computing and VR solutions for health and wellness.",2019,2021-05-19T13:30:45Z,2021-05-19T13:30:45Z,,4212-4220,9,,,,,,,,,,HICSS,"Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES",English,,,,,,,Type: Proceedings Paper,"<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>",,,,,"Bui, TX",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"A Cross-Country Comparison of Attitudes toward Humanoid Robots in Germany, the US, and India",4,"Homburg, Nadine; Merkle, Moritz",PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES,2019,conferencePaper,978-0-9981331-2-6,,10125/59915,,"So far, researchers know very little about what people actually expect from humanoid robots during a human-robot interaction. Therefore, this study surveyed 610 non-experts from Germany (133), the US (174), and India (303) and asked them to rate the following attributes regarding humanoid robots: empathy, expertise, reliability, and trust. This paper develops hypotheses, connecting robot attributes to the four cultural dimensions suggested by Hofstede individualism, masculinity versus femininity, power distance, and uncertainty avoidance. The results show, that India rates all the attributes the highest, and that Germany and the US rate all aspects rather similarly with the largest difference regarding reliability.",2019,2021-05-19T13:30:46Z,2021-05-19T13:30:46Z,,4773-4782,10,,,,,,,,,,HICSS,"Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404 Maile Way D307, Honolulu, Hawaii, UNITED STATES",English,,,,,,,Type: Proceedings Paper,"<p>52ndHawaii International Conference on System Sciences (HICSS), HI, JAN 08-11, 2019</p>",,,,,"Bui, TX",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Inducing Bystander Interventions During Robot Abuse with Social Mechanisms,27,"Tan, Xiang Zhi; Vazquez, Marynel; Carter, Elizabeth J.; Morales, Cecilia G.; Steinfeld, Aaron",HRI `18: PROCEEDINGS OF THE 2018 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION,2018,conferencePaper,978-1-4503-4953-6,,10.1145/3171221.3171247,,"We explored whether a robot can leverage social influences to motivate nearby bystanders to intervene and defend them from human abuse. We designed a between-subjects study where 48 participants took part in a memorization task and observed a confederate mistreating a robot both verbally and physically. The robot was either empathetic towards the participant's performance in the task or indifferent. When the robot was mistreated, it ignored the abuse, shut down in response to it, or reacted emotionally. We found that the majority of the participants intervened to help the robot after it was abused. Interventions happened for a wide range of reasons. Interestingly, the empathetic robot increased the proportion of participants that self-reported intervening in comparison to the indifferent robot, but more participants moved the robot as a response to abuse in the latter case. The participants also perceived the robot being verbally mistreated more and reported higher levels of personal distress when the robot briefly shut down after abuse in comparison to when it reacted emotionally or did not react at all.",2018,2021-05-19T13:31:02Z,2021-05-19T13:31:02Z,,169-177,9,,,,,,ACM IEEE International Conference on Human-Robot Interaction,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; IEEE; ACM SIGCHI; ACM SIGAI; IEEE Robot & Automat Soc; Kinova; Disney Res; LuxAI; Toyota Res Inst; Furhat Robot; Honda Res Inst; Google; Beam; Robotis; Savioke; Yujin Robot; Misty Robot; Hebi Robot; Haption; Otto Motors; AAAI ISSN: 2167-2121 Type: Proceedings Paper,"<p>13th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), Chicago, IL, MAR 05-08, 2018</p>",,,,abuse; bullying; empathy; Human-robot interaction; peer intervention; robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Touch Your Heart: A Tone-aware Chatbot for Customer Care on Social Media,56,"Hu, Tianran; Xu, Anbang; Liu, Zhe; You, Quanzeng; Guo, Yufan; Sinha, Vibha; Luo, Jiebo; Akkiraju, Rama",PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018),2018,conferencePaper,978-1-4503-5620-6,,10.1145/3173574.3173989,,"Chatbot has become an important solution to rapidly increasing customer care demands on social media in recent years. However, current work on chatbot for customer care ignores a key to impact user experience - tones. In this work, we create a novel tone-aware chatbot that generates toned responses to user requests on social media. We first conduct a formative research, in which the effects of tones are studied. Significant and various influences of different tones on user experience are uncovered in the study. With the knowledge of effects of tones, we design a deep learning based chatbot that takes tone information into account. We train our system on over 1.5 million real customer care conversations collected from Twitter. The evaluation reveals that our tone -aware chatbot generates as appropriate responses to user requests as human agents. More importantly, our chatbot is perceived to be even more empathetic than human agents.",2018,2021-05-19T13:31:23Z,2021-05-19T13:31:23Z,,,12,,,,,,,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Assoc Comp Machinery; ACM SIGCHI Type: Proceedings Paper,"<p>CHI Conference on Human Factors in Computing Systems (CHI), Montreal, CANADA, APR 21-26, 2018</p>",,,,Chatbot; Customer Care; Deep Learning; Social Media,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stacked Deep Convolutional Auto-Encoders for Emotion Recognition from Facial Expressions,38,"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile",2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN),2017,conferencePaper,978-1-5090-6182-2,,10.1109/IJCNN.2017.7966040,,"Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system.",2017,2021-05-19T13:31:32Z,2021-05-19T13:31:32Z,,1586-1593,8,,,,,,IEEE International Joint Conference on Neural Networks (IJCNN),,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: Int Neurol Network Soc; IEEE Computat Intelligence Soc; Intel; BMI; Budapest Semester Cognit Sci ISSN: 2161-4393 Type: Proceedings Paper,"<p>International Joint Conference on Neural Networks (IJCNN), Anchorage, AK, MAY 14-19, 2017</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Robot as Tutee,5,"Pareto, Lena",ROBOTICS IN EDUCATION: RESEARCH AND PRACTICES FOR ROBOTICS IN STEM EDUCATION,2017,conferencePaper,978-3-319-42975-5 978-3-319-42974-8,,10.1007/978-3-319-42975-5_24,,"This paper explores the possible advantages of substituting teachable agents in a learning environment, with a humanoid robot as the non-human tutee. Teachable agents are used as an extension to educational games in order to leverage engagement, reflection and learning. The learning environment is engaging and shown to be effective for learning and promote self-efficacy in experimental studies in authentic classroom settings. Features beneficial for learning which are further enhanced by a robot compared to an agent are identified. These include embodiment of the robot; a social, empathic behaviour, better conversational abilities which together provide a better role model of an ideal learner for the student to identify with.",2017,2021-05-19T13:31:34Z,2021-05-19T13:31:34Z,,271-277,7,,457,,,,Advances in Intelligent Systems and Computing,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 2194-5357 Type: Proceedings Paper,"<p>7th International Conference on Robotics in Education (RiE), Vienna, AUSTRIA, APR 14-15, 2016</p>",,,,Robot tutee; Robotics; Role-model learner; Teachable agent; Tutoring,"Merdan, M and Lepuschitz, W and Koppensteiner, G and Balogh, R",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent,14,"Bin Siddique, Farhad; Kampman, Onno; Yang, Yang; Dey, Anik; Fung, Pascale",PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS,2017,conferencePaper,978-1-945626-71-5,,10.18653/v1/P17-4021,,"Virtual agents need to adapt their personality to the user in order to become more empathetic. To this end, we developed Zara the Supergirl, an interactive empathetic agent, using a modular approach. In this paper, we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks. From raw audio, an average F-score of 69.6 was obtained from real-time personality assessment using a Convolutional Neural Network (CNN) model. From text, we improved personality recognition results with a CNN model on top of pre-trained word embeddings and obtained an average F-score of 71.0. Results from our Human-Agent Interaction study confirmed our assumption that people have different agent personality preferences. We use insights from this study to adapt our agent to user personality.",2017,2021-05-19T13:31:38Z,2021-05-19T13:31:38Z,,121-126,6,,,,,,,,,,ASSOC COMPUTATIONAL LINGUISTICS-ACL,"209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA",English,,,,,,,Backup Publisher: Alibaba Grp; Amazon; Apple; Baidu; Bloomberg; Facebook; Google; Samsung; Tencent; eBay; Elsevier; IBM Res; KPMG; Maluuba; Microsoft; Naver Line; NEC; Recruit Inst Technol; SAP; Adobe; Bosch; CVTE; Duolingo; Huawei; Nuance; Oracle; Sogou; Grammarly; Toutiao; Yandex Type: Proceedings Paper,"<p>55th Annual Meeting of the Association-for-Computational-Linguistics (ACL), Vancouver, CANADA, JUL 30-AUG 04, 2017</p>",,,,,"Bansal, M and Ji, H",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Emotion Recognition Using Facial Expression Images for a Robotic Companion,6,"Ruiz-Garcia, Ariel; Elshaw, Mark; Altahhan, Abdulrahman; Palade, Vasile","ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EANN 2016",2016,conferencePaper,978-3-319-44188-7 978-3-319-44187-0,,10.1007/978-3-319-44188-7_6,,"Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5%. These experiments serve as benchmark for our current research project in the area of social robotics.",2016,2021-05-19T13:31:47Z,2021-05-19T13:31:47Z,,79-93,15,,629,,,,Communications in Computer and Information Science,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,ISSN: 1865-0929 Type: Proceedings Paper,"<p>17th International Conference on Engineering Applications of Neural Networks (EANN), Robert Gordon Univ, Aberdeen, SCOTLAND, SEP 02-05, 2016</p>",,,,Emotion recognition; Gabor filter; Image classification; Neural networks; Social robots; Support Vector Machine,"Jayne, C and Iliadis, L",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyzing Human-Avatar Interaction with Neurotypical and not Neurotypical Users,1,"Johnson, Esperanza; Lopez de la Franca, Carlos Gutierrez; Hervas, Ramon; Mondejar, Tania; Bravo, Jose","UBIQUITOUS COMPUTING AND AMBIENT IN℡LIGENCE, UCAMI 2016, PT I",2016,conferencePaper,978-3-319-48746-5 978-3-319-48745-8,,10.1007/978-3-319-48746-5_54,,"Assistive technologies have been used to improve the quality of life of people who have been diagnosed with health issues. In this case, we aim to use an assistive technology in the shape of an affective avatar to help people who have been diagnosed with different forms of Social Communications Disorders (SCD). The designed avatar presents a humanoid face that displays emotions with a subtlety akin to that of real life human emotions, with those emotions changing according to the interactions that the user chooses to perform on the avatar. We have used Blender for the design of the emotions, which are happiness, sadness, surprise, fear and anger, plus a neutral emotion, while Unity was used to dictate the behavior of the avatar when the interactions were performed, which could be positive (caress), negative (poke) or neutral (wait). The avatar has been evaluated by 48 people from different backgrounds and the results show the overall positive reception by the users, as well as the difference between neurotypical and non-neurotypical users in terms of emotion recognition and chosen interactions. A ground truth has been established in terms of prototypic empathic interactions by the users.",2016,2021-05-19T13:31:47Z,2021-05-19T13:31:47Z,,525-536,12,,10069,,,,Lecture Notes in Computer Science,,,,SPRINGER INT PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,Backup Publisher: Univ Las Palmas Gran Canaria; MAmI Res Grp ISSN: 0302-9743 Type: Proceedings Paper,"<p>10th International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI), San Bartolome de Tirajana, SPAIN, NOV 29-DEC 02, 2016</p>",,,,Affective avatar; Affective computing; Cognitive disabilities; Empathy; Human-avatar interaction; Social communication disorder,"Garcia, CR and CaballeroGil, P and Burmester, M and QuesadaArencibia, A",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Human-Robot Interactoin Design for Robot-Assisted Intervention for Children with Autism Based on E-S Theory,8,"Li, Chaochao; Jia, Qingxuan; Feng, Yongli","2016 8TH INTERNATIONAL CONFERENCE ON IN℡LIGENT HUMAN-MACHINE SYSTEMS AND CYBERNETICS (IHMSC), VOL. 2",2016,conferencePaper,978-1-5090-0768-4,,10.1109/IHMSC.2016.103,,"The paper presents a novel human-robot interaction (HRI) framework to assist intervention for children with autism, based on Empathizing-Systemizing (E-S) theory. E-S theory explains the social difficulties in autism as the result of deficits or delays in empathizing, while explaining nonsocial behavior patterns as the effect of intact or even superior skills in systemizing. In this paper, the strength of systemizing is utilized to make up the deficiency and facilitate the development in empathizing via robot-assisted intervention, which has been identified as one of the most popular methods that are producing inspiring outcomes in the rehabilitation of children with autism. The design of HRI scenarios and tasks based on E-S theory makes the robot-assisted intervention more effective and efficient.",2016,2021-05-19T13:31:49Z,2021-05-19T13:31:49Z,,320-324,5,,,,,,International Conference on Intelligent Human-Machine Systems and Cybernetics,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; IEEE Comp Soc; Univ Bristol; Japan Adv Inst Sci & Technol; Beihang Univ ISSN: 2157-8982 Type: Proceedings Paper,"<p>8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), Zhejiang Univ, Hangzhou, PEOPLES R CHINA, SEP 11-12, 2016</p>",,,,autism therapy; Empathizing-Systemizing (E-S) theory; Human Robot Interaction (HRI); social robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An Interdisciplinary Approach to Improving Cognitive Human-Robot Interaction - A Novel Emotion-Based Model,5,"Fosch-Villaronga, Eduard; Barco, Alex; Ozcan, Beste; Shukla, Jainendra",WHAT SOCIAL ROBOTS CAN AND SHOULD DO,2016,conferencePaper,978-1-61499-708-5 978-1-61499-707-8,,10.3233/978-1-61499-708-5-195,,"Socially Assistive Robotics (SAR) aims to provide robot-assisted therapy, for physical as well as cognitive rehabilitation. The paper analyzes two distinct use cases of cognitive rehabilitation therapies, one among involving children with Traumatic Brain Injury (TBI); and another one; second among involving individuals with Intellectual Disability (ID), and raises concerns regarding emotional adaptation, personalization, design, and ELS issues of human-robot interaction in such cases. The paper's aim is to provide some guidance on how social robots should be designed in order to accommodate emotions in HRI as well as to respect the rights of the persons with disabilities. We argue that it is critically important to address the concerns highlighted in order to empower robots with empathetic behavior and to deliver effective cognitive rehabilitation therapies.",2016,2021-05-19T13:31:50Z,2021-05-19T13:31:50Z,,195-205,11,,290,,,,Frontiers in Artificial Intelligence and Applications,,,,IOS PRESS,"NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",English,,,,,,,"Backup Publisher: Aarhus Univ, Sch Culture & Soc, Res Unit Robophilosophy; Res Network Transdisciplinary Studies Social Robot; Danish Res Council Humanities ISSN: 0922-6389 Type: Proceedings Paper","<p>Conference on Robot Philosophy / TRANSOR Conference on What Social Robots Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016</p>",,,,ELS aspects; emotions; human-robot interaction (HRI); social robot design; social robots,"Seibt, J and Norskov, M and Andersen, SS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ethically-Guided Emotional Responses for Social Robots: Should I Be Angry?,17,"Ojha, Suman; Williams, Mary-Anne","SOCIAL ROBOTICS, (ICSR 2016)",2016,conferencePaper,978-3-319-47437-3 978-3-319-47436-6,,10.1007/978-3-319-47437-3_23,,"Emotions play a critical role in human-robot interaction. Human-robot interaction in social contexts will be more effective if robots can understand human emotions and express (display) emotions accordingly as a means to communicate their own internal state. In this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement. There have been recent advances in developing emotion for robots. However, despite the extensive research on robot emotion, it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation. A key question is - to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity? Realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people, we present a novel Ethical Emotion Generation System (EEGS) for the expression of the most acceptable emotions in social robots.",2016,2021-05-19T13:31:54Z,2021-05-19T13:31:54Z,,233-242,10,,9979,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,"Backup Publisher: SoftBank Robot; Univ Kansas, Sch Engn; Springer ISSN: 0302-9743 Type: Proceedings Paper","<p>8th International Conference on Social Robotics (ICSR), Kansas City, MO, NOV 01-03, 2016</p>",,,,Appraisal compensation; Appraisal theory; EEGS; Ethical emotion; Social robots,"Agah, A and Cabibihan, JJ and Howard, AM and Salichs, MA and He, H",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Affect-Aware Student Models for Robot Tutors,41,"Spaulding, Samuel; Gordon, Goren; Breazeal, Cynthia",AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS,2016,conferencePaper,978-1-4503-4239-1,,,,"Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration. In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models. These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.",2016,2021-05-19T13:32:01Z,2021-05-19T13:32:01Z,,864-872,9,,,,,,,,,,ASSOC COMPUTING MACHINERY,"1515 BROADWAY, NEW YORK, NY 10036-9998 USA",English,,,,,,,Backup Publisher: Int Fdn Autonomous Agents & Multiagent Syst; Natl Sci Fdn; Artificial Intelligence Journal; Springer; Unicen; Sumitomo Elect; Living Analyt Res Ctr; Panasonic R & D Ctr Singapore; Assoc Comp Machinery Special Interest Grp Artificial Intelligence; Assoc Comp Machinery Type: Proceedings Paper,"<p>15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), Singapore, SINGAPORE, MAY 09-10, 2016</p>",,,,affective computing; child-robot interaction; educational robots; socially assistive robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A Preliminary Framework for a Social Robot “Sixth Sense”,3,"Cominelli, Lorenzo; Mazzei, Daniele; Carbonaro, Nicola; Garofalo, Roberto; Zaraki, Abolfazl; Tognetti, Alessandro; De Rossi, Danilo","BIOMIMETIC AND BIOHYBRID SYSTEMS, LIVING MACHINES 2016",2016,conferencePaper,978-3-319-42417-0 978-3-319-42416-3,,10.1007/978-3-319-42417-0_6,,"Building a social robot that is able to interact naturally with people is a challenging task that becomes even more ambitious if the robots' interlocutors are children involved in crowded scenarios like a classroom or a museum. In such scenarios, the main concern is enabling the robot to track the subjects' social and affective state modulating its behaviour on the basis of the engagement and the emotional state of its interlocutors. To reach this goal, the robot needs to gather visual and auditory data, but also to acquire physiological signals, which are fundamental for understating the interlocutors' psycho-physiological state. Following this purpose, several Human-Robot Interaction (HRI) frameworks have been proposed in the last years, although most of them have been based on the use of wearable sensors. However, wearable equipments are not the best technology for acquisition in crowded multi-party environments for obvious reasons (e.g., all the subjects should be prepared before the experiment by wearing the acquisition devices). Furthermore, wearable sensors, also if designed to be minimally intrusive, add an extra factor to the HRI scenarios, introducing a bias in the measurements due to psychological stress. In order to overcome this limitations, in this work, we present an unobtrusive method to acquire both visual and physiological signals from multiple subjects involved in HRI. The system is able to integrate acquired data and associate them with unique subjects' IDs. The implemented system has been tested with the FACE humanoid in order to assess integrated devices and algorithms technical features. Preliminary tests demonstrated that the developed system can be used for extending the FACE perception capabilities giving it a sort of sixth sense that will improve the robot empathic and behavioural capabilities.",2016,2021-05-19T13:32:02Z,2021-05-19T13:32:02Z,,58-70,13,,9793,,,,Lecture Notes in Computer Science,,,,SPRINGER INTERNATIONAL PUBLISHING AG,"GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",English,,,,,,,"Backup Publisher: Convergence Sci Network Biomimet & Neurotechnol; Future Emerging Technologies, European Unions Framework 7 Program; Heriot Watt Univ ISSN: 0302-9743 Type: Proceedings Paper","<p>5th International Conference on Biomimetic and Biohybrid Systems (Living Machines), Edinburgh, SCOTLAND, JUL 19-22, 2016</p>",,,,Affective computing; Behaviour monitoring; Human-Robot Interaction; Social robotics; Synthetic tutor,"Lepora, NF and Mura, A and Mangan, M and Verschure, PFMJ and Desmulliez, M and Prescott, TJ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The Affective Loop: A Tool for Autonomous and Adaptive Emotional Human-Robot Interaction,6,"Vircikova, Maria; Magyar, Gergely; Sincak, Peter",ROBOT IN℡LIGENCE TECHNOLOGY ANDAPPLICATIONS 3,2015,conferencePaper,978-3-319-16841-8 978-3-319-16840-1,,10.1007/978-3-319-16841-8_23,,"The paper presents an affective model for social robotics, where the robot is capable of behavior adaptation, in accordance with the needs and preferences of a particular user. The proposed approach differs from other studies in human-robot interaction as these usually have been using the `Wizard of Oz' technique, where a person remotely operates a robot. On the other side, simulated robots are not able of personalized behaviors and behave according to the preprogrammed set of rules. We provide a tool to personalize affective artificial behaviors in cooperative human-robot scenarios, where human emotion recognition, appropriate robotic behavior selection and expression of robotic emotions play a key role. The preliminary experiments show that the personalized affective robotic behavior can achieve better results in a scenario in which a robot motivates children in learning. We believe that human-robot interfaces which mimic how humans interact with one another in an empathic way could ultimately lead to robots being accepted in the wider domain.",2015,2021-05-19T13:32:12Z,2021-05-19T13:32:12Z,,247-254,8,,345,,,,Advances in Intelligent Systems and Computing,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,ISSN: 2194-5357 Type: Proceedings Paper,"<p>3rd International Conference on Robot Intelligence Technology and Applications, Beijing, PEOPLES R CHINA, NOV 06-08, 2014</p>",,,,Affective Robotics; Personalization; Social Human-Robot Interaction; Social Robots; Subjective Computing,"Kim, JH and Yang, W and Jo, J and Sincak, P and Myung, H",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Social and empathic behaviours: novel interfaces and interaction modalities,6,"Marti, Patrizia; Iacono, Iolanda",2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN),2015,conferencePaper,978-1-4673-6704-2,,10.1109/ROMAN.2015.7333634,,"This paper describes the results of a research conducted in the European project Accompany, whose aim is to provide older people with services in a motivating and socially acceptable manner to facilitate independent living at home. The project developed a system consisting of a robotic companion, Care-O-bot, as part of a smart environment. An intensive research was conducted to investigate and experiment with robot behaviours that trigger empathic exchanges between an older person and the robot. The paper is articulated in two parts. The first part illustrates the theory that inspired the development of a context-aware Graphical User Interface (GUI) used to interact with the robot. The GUI integrates an expressive mask allowing perspective taking with the aim to stimulate empathic exchanges. The second part focuses on the user evaluation, and reports the outcomes from three different tests. The results of the first two tests show a positive acceptance of the GUI by the older people. The final test reports qualitative comments by senior participants on the occurrence of empathic exchanges with the robot.",2015,2021-05-19T13:32:14Z,2021-05-19T13:32:14Z,,217-222,6,,,,,,,,,,IEEE,"345 E 47TH ST, NEW YORK, NY 10017 USA",English,,,,,,,Backup Publisher: IEEE; Robot Soc Japan; Korea Robot Soc; IEEE Robot & Automat Soc Type: Proceedings Paper,"<p>24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), Kobe, JAPAN, AUG 31-SEP 04, 2015</p>",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An Empathic Robotic Tutor for School Classrooms: Considering Expectation and Satisfaction of Children as End-Users,22,"Alves-Oliveira, Patricia; Ribeiro, Tiago; Petisca, Sofia; di Tullio, Eugenio; Melo, Francisco S.; Paiva, Ana",SOCIAL ROBOTICS (ICSR 2015),2015,conferencePaper,978-3-319-25554-5 978-3-319-25553-8,,10.1007/978-3-319-25554-5_3,,"Before interacting with a futuristic technology such as a robot, there is a lot of space for the creation of a whole set of expectations towards that interaction. Once that interaction happens, users can be left with a hand full of satisfaction, dissatisfaction, or even a mix of both. To study the possible role of experience as a mediator between expectation and satisfaction, we developed a scale for HRI that measures expectations and satisfaction of the users. Afterwards, we conducted a study with end-users interacting with a social robot. The robot is being developed to be an empathic robotic tutor to be used in real schools, with input from primary end-users (children). Children's expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed. The results can be fed back to the system developers on how well it is being designed for such a target population, and what factors regarding their expectation and satisfaction have shifted after the experience of interaction. By delivering on the children's expectations, we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational environment.",2015,2021-05-19T13:32:20Z,2021-05-19T13:32:20Z,,21-30,10,,9388,,,,Lecture Notes in Artificial Intelligence,,,,SPRINGER-VERLAG BERLIN,"HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY",English,,,,,,,ISSN: 0302-9743 Type: Proceedings Paper,"<p>7th International Conference on Social Robotics (ICSR), Paris, FRANCE, OCT 26-30, 2015</p>",,,,Expectation; Human-Robot Interaction; Robotic tutor; Satisfaction; User-centered design,"Tapus, A and Andre, E and Martin, JC and Ferland, F and Ammi, M",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DELEX: A DEep Learning Emotive EXperience: Investigating Empathic HCI,0,"Abate, Andrea F.; Castiglione, Aniello; Nappi, Michele; Passero, Ignazio",Proceedings of the International Conference on Advanced Visual Interfaces,2020,conferencePaper,978-1-4503-7535-1,,10.1145/3399715.3399820,https://doi.org/10.1145/3399715.3399820,"Recent advances in Machine Learning have unveiled interesting possibilities for real-time investigating about user characteristics and expressions like, but not limited to, age, sex, body posture, emotions and moods. These new opportunities lay the foundations for new HCI tools for interactive applications that adopt user emotions as a communication channel.This paper presents an Emotion Controlled User Experience that changes according to user feelings and emotions analysed at runtime. Aiming at obtaining a preliminary evaluation of the proposed ecosystem, a controlled experiment has been performed in an engineering and software development company, where 60 people have been involved as volunteers. The subjective evaluation has been based on a standard questionnaire commonly adopted for measuring user perceived sense of immersion in Virtual Environments. The results of the controlled experiment encourage further investigations strengthen by the analysis of objective performance measurements and user physiological parameters.",2020,2021-05-19T12:52:09Z,2021-05-19T12:52:09Z,,,,,,,,,AVI '20,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Salerno, Italy",,,,Computer Vision; Deep Learning; User Emotions; User Experience,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Modeling and Simulating Empathic Behavior in Social Assistive Robots,4,"De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe; Carofiglio, Valeria",Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter,2015,conferencePaper,978-1-4503-3684-0,,10.1145/2808435.2808445,https://doi.org/10.1145/2808435.2808445,"Several studies report successful results on how social assistive robots can be employed as interface in the assisted living domain. In our opinion, to plan their response and interact successfully with people, it is crucial to recognize human emotions. To this aim, features of the prosody of the speech together with facial expressions and gestures may be used to recognize the emotional state of the user. The information gained from these different sources may be fused in order to endow the robot with the capability to reason on the user's affective state. In this paper we describe how this capability has been implemented in the NAO robot and how this allows simulating empathic behaviors in the context of Ambient Assisted Living.",2015,2021-05-19T12:52:10Z,2021-05-19T12:52:10Z,,110–117,8,,,,,,CHItaly 2015,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Rome, Italy",,,,Affective Computing; Social Assistive Robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A Sociolinguistic Route to the Characterization and Detection of the Credibility of Events on Twitter,0,"Patro, Jasabanta; Rathore, Pushpendra Singh",Proceedings of the 31st ACM Conference on Hypertext and Social Media,2020,conferencePaper,978-1-4503-7098-1,,10.1145/3372923.3404795,https://doi.org/10.1145/3372923.3404795,"Although Twitter constitutes as one of the primary sources of real-time news with users acting as the sensors updating the content from all across the globe, yet the spread of rumours via Twitter is becoming an increasingly alarming issue and is known to have caused significant damage already. We propose a credibility analysis approach based on the linguistic structure of the tweets. We not only characterize the Twitter events but also predict their perceived credibility of them by a novel deep learning architecture. We use the huge CREDBANK data to conduct our experiments. Some of our exciting findings are that standard LIWC categories like 'negate', 'discrep', 'cogmech', 'swear' and the Empath categories like 'hate', 'poor', 'government', 'worship' and 'swearing-terms' correlate negatively with the credibility of events. While some of our results resonate with the earlier literature others represent novel insights of the fake and legitimate twitter events. Using the above observations and the current deep learning architecture we predict the credibility of an event (a four-class classification problem in our case) with an accuracy of 0.54 that improves the best-known state-of-the-art (current accuracy 0.43) by 26%. A fascinating observation is that even by looking at the first few tweets of an event, it is possible to make the prediction almost as accurate as in the case where the entire volume of tweets is observed.",2020,2021-05-19T12:52:10Z,2021-05-19T12:52:10Z,,241–250,10,,,,,,HT '20,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Virtual Event, USA",,,,credibility detection; event credibility; sociolinguistic approach,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cyrafour: How Two Human Avatars Communicate With Each Other,1,"Encinas, Enrique",Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems,2015,conferencePaper,978-1-4503-3146-3,,10.1145/2702613.2726962,https://doi.org/10.1145/2702613.2726962,"Human avatars or physical surrogates are becoming increasingly present in leisure, artistic and business activities that seek to augment the sensory richness available to telepresent participants. While a number of studies have focused on how human avatars relate to other humans, little attention has been paid to the particularities of human avatar to human avatar interaction. This paper examines characteristic features of such interaction through Cyrafour, a playful embodied identity game in which two human avatars clone various conversations generated elsewhere. Such cloning, or speech shadowing, seems to allow for an empathic embodiment of the meaning transmitted and appears to create a frame for further discussion on the topics raised. This project contributes to the study of telepresence with new insights applicable to the design and research of human computer and human robot interfaces.",2015,2021-05-19T12:52:11Z,2021-05-19T12:52:11Z,,109–114,6,,,,,,CHI EA '15,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Seoul, Republic of Korea",,,,copresence; cyranoids; embodied cognition; human avatars; personal surrogates; serious games; telepresence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sharing Emotion Described as Text on the Internet by Changing Self-Physiological Perception,1,"Sakurai, Sho; Ban, Yuki; Katsumura, Toki; Narumi, Takuji; Tanikawa, Tomohiro; Hirose, Michitaka",Proceedings of the Fourth International Conference on Human Agent Interaction,2016,conferencePaper,978-1-4503-4508-8,,10.1145/2974804.2974825,https://doi.org/10.1145/2974804.2974825,"Agents like human, such as humanoid robots or avatars can be felt as if they have and communicate and communicate due to manipulation of the bodily information. Meanwhile, as in the case of Internet bot, it is still difficult to communiate the emotion described as text, let alone empathizing due to degradation of information online. The current study proposes a method for experiencing emotion on the Internet by reproducing a mechanism of evoking emotion. This method evokes a number of emotions described on the Web, by changing of self-physiological perception with sensory stimuli. To investigate the feasibility of our method, we made a system named ""Communious Mouse."" This system rewrites the perception of self-skin temperature and pulse in a palm by presenting vibration and thermal stimulation through a mouse device for evoking emotion. The current paper discusses the feasibility of our method based on the obtained feedbacks through an exhibition of the system.",2016,2021-05-19T12:52:56Z,2021-05-19T12:52:56Z,,145–153,9,,,,,,HAI '16,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Biopolis, Singapore",,,,a sense of ownership; emotion; online communication; physiological perception; self-perception; theory of mind,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Personal Quizmaster: A Pattern Approach to Personalized Interaction Experiences with the MiRo Robot,1,"Pollmann, Kathrin; Ziegler, Daniel",Proceedings of the Conference on Mensch Und Computer,2020,conferencePaper,978-1-4503-7540-5,,10.1145/3404983.3410414,https://doi.org/10.1145/3404983.3410414,"In Human-Robot Interaction, personalization has been proposed as a strategy to increase acceptance for social robots. The present paper describes how behavioral design patterns can be used to tailor the interaction experience to the individual user's characteristics and needs. To demonstrate this approach, we designed a quiz game application for the MiRo robot. The robot acts as the quizmaster and shows different behaviors (coach-like/empathic vs. challenging/provocative) depending on the type of user who is playing the game (community-focused vs. competition-focused player). We describe the process of creating the two quizmaster personalities and related behavioral patterns as well as the technical background for integrating them with the interaction model for the quiz game. The result is a Wizard-of-Oz demonstration of the personalizable quiz game that is accompanied by an interactive video prototype remote for user studies and demo purposes.",2020,2021-05-19T12:52:57Z,2021-05-19T12:52:57Z,,485–489,5,,,,,,MuC '20,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Magdeburg, Germany",,,,behavioral patterns; multimodal behavioral expressions; personalized human-robot interaction; social robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A Social Robot System for Modeling Children's Word Pronunciation: Socially Interactive Agents Track,23,"Spaulding, Samuel; Chen, Huili; Ali, Safinah; Kulinski, Michael; Breazeal, Cynthia",Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems,2018,conferencePaper,,,https://par.nsf.gov/biblio/10072816,,"Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. In this paper we introduce an integrated system for autonomously analyzing and assessing children's speech and pronunciation in the context of an interactive word game between a social robot and a child. We present a novel game environment and its computational formulation, an integrated pipeline for capturing and analyzing children's speech in real-time, and an autonomous robot that models children's word pronunciation via Gaussian Process Regression (GPR), augmented with an Active Learning protocol that informs the robot's behavior. We show that the system is capable of autonomously assessing children's pronunciation ability, with ground truth determined by a post-experiment evaluation by human raters. We also compare phoneme- and word-level GPR models and discuss trade-offs of each approach in modeling children's pronunciation. Finally, we describe and analyze a pipeline for automatic analysis of children's speech and pronunciation, including an evaluation of SpeechAce as a tool for future development of autonomous, speech-based language tutors.",2018,2021-05-19T12:52:57Z,2021-05-19T12:52:57Z,,1658–1666,9,,,,,,AAMAS '18,,,,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,,,,,,,"event-place: Stockholm, Sweden",,,,gaussian processl; human-robot interaction; intelligent tutoring systems; social robot; speech-based systems; student modeling,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Drone in Love: Emotional Perception of Facial Expressions on Flying Robots,0,"Herdel, Viviane; Kuzminykh, Anastasia; Hildebrandt, Andrea; Cauchard, Jessica R.",Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,2021,conferencePaper,978-1-4503-8096-6,,10.1145/3411764.3445495,https://doi.org/10.1145/3411764.3445495,"Drones are rapidly populating human spaces, yet little is known about how these flying robots are perceived and understood by humans. Recent works suggested that their acceptance is predicated upon their sociability. This paper explores the use of facial expressions to represent emotions on social drones. We leveraged design practices from ground robotics and created a set of rendered robotic faces that convey basic emotions. We evaluated individuals’ response to these emotional facial expressions on drones in two empirical studies (N = 98, N = 98). Our results demonstrate that individuals accurately recognize five drone emotional expressions, as well as make sense of intensities within emotion categories. We describe how participants were emotionally affected by the drone, showed empathy towards it, and created narratives to interpret its emotions. As a consequence, we formulate design recommendations for social drones and discuss methodological insights on the use of static versus dynamic stimuli in affective robotics studies.",2021,2021-05-19T12:53:15Z,2021-05-19T12:53:15Z,,,,,,,,,CHI '21,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Yokohama, Japan",,,,Affective Computing; Anthropomorphism; Emotion Recognition; Facial Expressions; Human-Drone Interaction; Robot; UAV.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ballbit Adventure: A Physical Game for a Collaborative Racing,2,"Kuang, Quincy; Zhang, Jiaxin; Druga, Stefania",Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts,2019,conferencePaper,978-1-4503-6871-1,,10.1145/3341215.3356982,https://doi.org/10.1145/3341215.3356982,"Playtime accounts for one of the most critical learning periods for children, as they learn how to interact and socialize with their playmates. In this paper, we present a new kind of cooperation-based physical game called Ballbit Adventure. Our game provides a collaborative environment for children to communicate, cooperate, and empathize through solving challenges in an interactive maze. Each player must drive a robotic ball and work together to complete different tasks that would ultimately lead them to the finish line. Through the format of a physical racing game, Ballbit Adventure hopes to show the value of face-to-face play experience to counterbalance the disconnected online interactions that children have with video games.",2019,2021-05-19T12:53:16Z,2021-05-19T12:53:16Z,,97–103,7,,,,,,CHI PLAY '19 Extended Abstracts,,,,Association for Computing Machinery,"New York, NY, USA",,,,,,,,"event-place: Barcelona, Spain",,,,cooperation based game; hybrid game; social gaming; strategic gameplay; tangible interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Detection of Real-World Driving-Induced Affective State Using Physiological Signals and Multi-View Multi-Task Machine Learning,1,"Lopez-Martinez, Daniel; El-Haouij, Neska; Picard, Rosalind",2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),2019,conferencePaper,,,10.1109/ACIIW.2019.8925190,,"Affective states have a critical role in driving performance and safety. They can degrade driver situation awareness and negatively impact cognitive processes, severely diminishing road safety. Therefore, detecting and assessing drivers' affective states is crucial in order to help improve the driving experience, and increase safety, comfort and well-being. Recent advances in affective computing have enabled the detection of such states. This may lead to empathic automotive user interfaces that account for the driver's emotional state and influence the driver in order to improve safety. In this work, we propose a multiview multi-task machine learning method for the detection of driver's affective states using physiological signals. The proposed approach is able to account for inter-drive variability in physiological responses while enabling interpretability of the learned models, a factor that is especially important in systems deployed in the real world. We evaluate the models on three different datasets containing real-world driving experiences. Our results indicate that accounting for drive-specific differences significantly improves model performance.",2019-09,2021-05-19T12:41:49Z,2021-05-19T12:41:49Z,,356-361,6,,,,,,,,,,,,,,,,,,,,,,,Affective State; Databases; Feature extraction; Heart rate; Machine learning; Multi-task Multi-view Machine Learning; Physiological data; Physiology; Real-world driving; Stress; Vehicles,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorporating politeness across languages in customer care responses: Towards building a multi-lingual empathetic dialogue agent,0,"Firdaus, M.; Ekbal, A.; Bhattacharyya, P.","LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings",2020,conferencePaper,979-10-95546-34-4,,https://aclanthology.org/2020.lrec-1.514,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096584871&partnerID=40&md5=7e8e8d8f2bef5ac7638ad3b967c8b7f7,"Customer satisfaction is an essential aspect of customer care systems. It is imperative for such systems to be polite while handling the customer requests or demands. In this paper, we present a large multi-lingual conversational dataset for English and Hindi. We choose data from Twitter having both generic and courteous responses between customer care agents and aggrieved users. We also propose strong baselines that can induce courteous behaviour in generic customer care response in a multi-lingual scenario. We build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agent's responses. Our system is competent in generating responses in different languages (here, English and Hindi) depending on the customer's preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention. Experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system. Qualitative and quantitative analysis show that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction. © European Language Resources Association (ELRA), licensed under CC-BY-NC",2020,2021-05-19T13:26:18Z,2021-05-19T13:26:18Z,,4172-4182,11,,,,,,,,,,European Language Resources Association (ELRA),,English,,,,,,,,"<p>cited By 0; Conference of 12th International Conference on Language Resources and Evaluation, LREC 2020 ; Conference Date: 11 May 2020 Through 16 May 2020; Conference Code:164155</p>",,,Customer care; Customer care systems; Customer satisfaction; Deep learning; Information shared; Large dataset; Learning frameworks; Linguistics; Qualitative and quantitative analysis; Sales,,"Calzolari N., Piperidis S., Bechet F., Blache P., Choukri K., Cieri C., Declerck T., Goggi S., Isahara H., Maegaard B., Mariani J., Mazo H., Moreno A., Odijk J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Emotion Differentiation based on Decision-Making in Emotion Model,2,"Hieida, C.; Horii, T.; Nagai, T.",RO-MAN 2018 - 27th IEEE International Symposium on Robot and Human Interactive Communication,2018,conferencePaper,978-1-5386-7980-7,,10.1109/ROMAN.2018.8525579,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058082859&doi=10.1109%2fROMAN.2018.8525579&partnerID=40&md5=a8b97edffc128454fce9f7f211968e30,"Having emotions is essential for robots in order for them to understand and sympathize with people's feelings. In addition, it may allow robots to be accepted in human society. The role of emotions in decision-making is another important perspective. In this paper, a model of emotions is proposed based on various neurological and psychological findings related to empathic communication between humans and robots. Subsequently, a decision-making mechanism based on affects using convolutional long short-term memory and deep deterministic policy gradient is examined. We set a 'facial expression' task simulating mother-child interactions and verified emotion differentiation during the task. © 2018 IEEE.",2018,2021-05-19T13:26:28Z,2021-05-19T13:26:28Z,,659-665,7,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,English,,,,,,,,"<p>cited By 1; Conference of 27th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2018 ; Conference Date: 27 August 2018 Through 31 August 2018; Conference Code:142166</p>",,,Behavioral research; Decision making; Decision-making mechanisms; Emotion modeling; Facial Expressions; Human society; Policy gradient; Robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Emotion-recognition from speech-based interaction in AAL environment,1,"De Carolis, B.; Ferilli, S.; Palestra, G.; Redavid, D.",CEUR Workshop Proceedings,2017,conferencePaper,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016315295&partnerID=40&md5=48d39fe986e3c8fb67cf9285e325457c,"In Ambient Assisted Living environments assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. To this aim social assistive robots are being employed as a mediator interface and, in order to achieve a relation with the user, they should be endowed with the capability of recognizing the user affective state. Since a natural way to interact with a robot is speech, spoken user's input can be used to give to the robot the capability of recognizing the emotions and attitude of the user, thus providing more detail information about the user state. This paper focuses on this topic and proposes an approach based on the dimensional model of emotions in which the valence and arousal of user's spoken input are recognized. The experimental analysis shows the performance in terms of accuracy of the proposed approach on an Italian dataset. In order to show its application in the context of Ambient Assisted Living, an example is provided. © 2017, CEUR-WS. All rights reserved.",2017,2021-05-19T13:26:37Z,2021-05-19T13:26:37Z,,92-104,13,,1803,,,,,,,,CEUR-WS,,English,,,,,,,ISSN: 16130073,"<p>cited By 1; Conference of 2nd Italian Workshop on Artificial Intelligence for Ambient Assisted Living, AI*AAL.it 2016 ; Conference Date: 28 November 2016; Conference Code:126783</p>",,,Affective state; Ambient assisted living; Ambient intelligence; Artificial intelligence; Assisted living; Assistive robots; Deep neural networks; Dimensional model; Emotion recognition from speech; Experimental analysis; Interface states; ITS applications; Robots; Speech recognition; Task-oriented,,"Bandini S., Cortellessa G., Palumbo F.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Designing a robotic interface for children: The MOnarCH robot example,4,"Ferreira, M.I.A.; Sequeira, J.S.","Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016",2016,conferencePaper,978-981-314-912-0,,10.1142/9789813149137_0076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999663794&doi=10.1142%2f9789813149137_0076&partnerID=40&md5=7de84e5ccd68ae2c76e5f3801431a3f9,"The development of an empathic link between oneself and the Other is a fundamental part of interpersonal relationships determining the establishment of effective social and affective links that are the grounding basis of successful communication and cooperation on which the cohesion of human societies depend and on which harmonious global personal development also stands. The design of efficient robotic interfaces for interaction with people, namely with children, depends on the development of expressive elements to be present in the appearance of robots and in the way they address and interact with people, i.e. on the definition of a set of socially behaviours identified as communication enhancers. The present paper reflects how the previous assumptions have determined the process that led to the construction of the MOnarCH robots and some of its design options. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.",2016,2021-05-19T13:26:41Z,2021-05-19T13:26:41Z,,652-659,8,,,,,,,,,,World Scientific Publishing Co. Pte Ltd,,English,,,,,,,,"<p>cited By 1; Conference of 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016 ; Conference Date: 12 September 2016 Through 14 September 2016; Conference Code:185329</p>",,,Children/robot interaction; Communication; Designing for interaction; Economic and social effects; Expressiveness; Human society; Interpersonal relationship; Machine design; Mobile robots; Personal development; Robotic interface; Robotics; Social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Recognition and expression of emotions by a symbiotic android head,6,"Mazzei, D.; Zaraki, A.; Lazzeri, N.; De Rossi, D.",IEEE-RAS International Conference on Humanoid Robots,2015,conferencePaper,978-1-4799-7174-9,,10.1109/HUMANOIDS.2014.7041349,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945179051&doi=10.1109%2fHUMANOIDS.2014.7041349&partnerID=40&md5=f47b54fd692ed1f07a9bef8e2a4b0f1c,"The creation of social empathie communication channels between social robots and humans has started to become reality. Nowadays, the development of empathie and affective agents is giving to scientists another way to explore the social dimension of human beings. In this work, we introduce the FACE humanoid project that aims at creating a social and emotional android. FACE is an android head with an articulated neck mounted on a passive body. In order to enable FACE to perceive and express emotions, two dedicated engines have been developed. A sensory apparatus able to perceive the 'social world', and a facial expressions generation engine that allows the robot to express its synthetic emotions. The system has been also integrated with an attention-based gaze generation component that allows the robot to autonomously follow a conversation between its partners. The developed framework has been implemented and tested in several standard human-robot interaction settings. Results demonstrated the promising social capabilities of the robot to perceive and convey emotions to humans through the generation of emotional perceivable facial expressions and socially aligned behaviour. © 2014 IEEE.",2015,2021-05-19T13:26:43Z,2021-05-19T13:26:43Z,,134-139,6,,2015-February,,,,,,,,IEEE Computer Society,,English,,,,,,,ISSN: 21640572,"<p>cited By 3; Conference of 2014 14th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2014 ; Conference Date: 18 November 2014 Through 20 November 2014; Conference Code:112990</p>",,,Anthropomorphic robots; Behavioral research; Engines; Express emotions; Facial Expressions; Human being; Human robot interaction; Social dimensions; Social robots; Synthetic emotions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Towards an empathic social robot for ambient assisted living,7,"De Carolis, B.; Ferilli, S.; Palestra, G.; Carofiglio, V.",CEUR Workshop Proceedings,2015,conferencePaper,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928737527&partnerID=40&md5=b573ae7afac79bef8ae0c8f77bd8451d,"In the context of Ambient Assisted Living, assistance and care are delegated to the intelligence embedded in the environment that, in our opinion, should provide not only a task-oriented support but also an interface able to establish a social empathic relation with the user. This can be achieved, for instance, using a social assistive robot as interface towards the environment services. In the context of the NICA (Natural Interaction with a Caring Agent) project we developed the behavioral architecture of a social robot able to assist the user in the interaction with a smart home environment. In this paper we describe how this robot has been endowed with the capability of recognizing the user affective state from the combination of facial expressions and spoken utterances and to reason on in order to simulate an empathic behavior.",2015,2021-05-19T13:26:43Z,2021-05-19T13:26:43Z,,19-34,16,,1351,,,,,,,,CEUR-WS,,English,,,,,,,ISSN: 16130073,"<p>cited By 8; Conference of 2nd International Workshop on Emotion and Sentiment in Social and Expressive Media, ESSEM 2015 ; Conference Date: 5 May 2015; Conference Code:112014</p>",,,Affective state; Ambient assisted living; As interfaces; Assistive robots; Automation; Autonomous agents; Facial Expressions; Intelligent buildings; Multi agent systems; Natural interactions; Robots; Social robots; Task-oriented,,"Cambria E., Patti V., Rosso P., Bosco C., Damiano R.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Affective Internet of Things: Mimicking human-like personality in designing smart-objects,15,"Pieroni, M.; Rizzello, L.; Rosini, N.; Fantoni, G.; De Rossi, D.; Mazzei, D.","IEEE World Forum on Internet of Things, WF-IoT 2015 - Proceedings",2015,conferencePaper,978-1-5090-0365-5,,10.1109/WF-IoT.2015.7389088,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964556250&doi=10.1109%2fWF-IoT.2015.7389088&partnerID=40&md5=8a13b6d0e0a3f31879eb1dbd9bcdce78,"The paper wants to introduce the concept of Affective Internet of Things (AIoT) where smart objects are empowered with affective capability in terms of abstraction of their emotional state. Moreover each smart object can be associated with a specific 'personality'. This approach, already used in the field of social robotics, mainly exploits robots' appearance (i.e. anthropomorphism or zoomorphism). The research aims at extending such a paradigm to everyday-life objects in order to 'warm-up' the empathic connections that humans generally establish with 'cold' gadgets and devices. A new framework for the Affective IoT has been developed: EMPATI (EMPATI Mimics Personalities on Affective Things on Internet). It provides models and functions to simulate different personality for affective objects living in both virtual and real world. Finally, a set of experiments has been conceived to assess the key aspects of the framework in terms of capability to simulate emotional responses depending on the object interaction with the environment and the affective stimuli. © 2015 IEEE.",2015,2021-05-19T13:26:45Z,2021-05-19T13:26:45Z,,400-405,6,,,,,,,,,,Institute of Electrical and Electronics Engineers Inc.,,English,,,,,,,,"<p>cited By 6; Conference of 2nd IEEE World Forum on Internet of Things, WF-IoT 2015 ; Conference Date: 14 December 2015 Through 16 December 2015; Conference Code:119271</p>",,,affective object; Emotional response; Emotional state; Human computer interaction; Human like; Internet; Internet of things; Object interactions; Real-world; Robotics; Smart objects; Social robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Artificial Empathy for Clinical Companion Robots with Privacy-By-Design,0,"Vargas Martin, M.; Pérez Valle, E.; Horsburgh, S.","Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",2021,conferencePaper,,18678211,10.1007/978-3-030-70569-5_23,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104418757&doi=10.1007%2f978-3-030-70569-5_23&partnerID=40&md5=d3890f65cafff1ceba3086b0fd4212bf,"We present a prototype whereby we enabled a humanoid robot to be used to assist mental health patients and their families. Our approach removes the need for Cloud-based automatic speech recognition systems to address healthcare privacy expectations. Furthermore, we describe how the robot could be used in a mental health facility by giving directions from patient selection to metrics for evaluation. Our overarching goal is to make the robot interaction as natural as possible to the point where the robot can develop artificial empathy for the human companion through the interpretation of vocals and facial expressions to infer emotions. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",2021,2021-05-19T13:26:06Z,2021-05-19T13:26:06Z,,351-361,11,,362 LNICST,,,,,,,,,,English,,,,,,,ISBN: 9783030705688 Publisher: Springer Science and Business Media Deutschland GmbH,"<p>cited By 0; Conference of 9th EAI International Conference on Wireless Mobile Communication and Healthcare, MobiHealth 2020 ; Conference Date: 19 November 2020 Through 19 November 2020; Conference Code:255799</p>",,,Anthropomorphic robots; Automatic speech recognition system; Cloud-based; Companion robot; Facial Expressions; Health care; Human robot interaction; Humanoid robot; Machine design; Mental health; Mobile telecommunication systems; Privacy by design; Robot interactions; Speech recognition,,"Ye J., Yordanova K., O'Grady M.J., Civitarese G.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Neurophysiological indices of human social interactions between humans and robots,2,"Smith, S.J.; Stone, B.T.; Ranatunga, T.; Nel, K.; Ramsoy, T.Z.; Berka, C.",Communications in Computer and Information Science,2017,conferencePaper,,18650929,10.1007/978-3-319-58750-9_36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025174844&doi=10.1007%2f978-3-319-58750-9_36&partnerID=40&md5=a79ac8fdcd00acc223e0c6708767cf68,"Technology continues to advance at exponential rates and we are exposed to a multitude of electronic interfaces in almost every aspect of our lives. In order to achieve seamless integration of both, human and technology, we must examine the objective and subjective responses to such interactions. The goal of this study was to examine neurophysiological responses to movement, communication, and usability with a robot assistant, in comparison to human assistant, in a real-world setting. OSHbot (robot assistants designed by Fellow Robots) were utilized as mobile store clerks to identify and locate merchandise in order to assist customers in finding items within a hardware store. By acquiring neurophysiological measures (electroencephalogram; EEG and electrocardiogram; ECG) of human perception and interaction with robots, we found evidence of Mirror Neuron System (MNS) elicitation and motor imagery processing, which is consistent with other studies examining human-robot interactions. Multiple analyses were conducted to assess differences between human-human interaction and human-robot interaction. Several EEG metrics were identified that were distinguishable based on interaction type; among these was the change observed across the Mu bandwidth (8–13 Hz). The variance in this EEG correlate has been related to empathetic state change. In order to explore differences in the interactions related to gender and age additional analyses were conducted to compare the effects of human-human interaction versus human-robot interaction with data stratified by gender and age. This analysis yielded significant differences across these categories between human-human interaction and human-robot interaction within EEG metrics. These preliminary data show promise for future research in the field of human-robot relations in contributing to the design and implementation of machines that not only deliver basic services but also create a social connection with humans. © Springer International Publishing AG 2017.",2017,2021-05-19T13:26:37Z,2021-05-19T13:26:37Z,,251-262,12,,713,,,,,,,,,,English,,,,,,,ISBN: 9783319587493 Publisher: Springer Verlag,"<p>cited By 1; Conference of 19th International Conference on Human-Computer Interaction, HCI International 2017 ; Conference Date: 9 July 2017 Through 14 July 2017; Conference Code:194249</p>",,,Bandwidth; Design and implementations; Electrocardiography; Electroencephalography; Electronic interface; Eye-tracking; Human computer interaction; Human robot interaction; Human social interactions; Human-human interactions; Machine design; Man machine systems; Neurophysiological measures; Neurophysiology; Robots; Seamless integration; Social interactions; Social sciences,,"C, Stephanidis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MuDERI: Multimodal database for emotion recognition among intellectually disabled individuals,6,"Shukla, J.; Barreda-Ángeles, M.; Oliver, J.; Puig, D.",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016,conferencePaper,,3029743,10.1007/978-3-319-47437-3_26,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992523179&doi=10.1007%2f978-3-319-47437-3_26&partnerID=40&md5=5ecb6239283b3977469c0dc20359fa09,"Social robots with empathic interaction is a crucial requirement towards deliverance of an effective cognitive stimulation among individuals with Intellectual Disability (ID) and has been challenged by absence of any particular database. Project REHABIBOTICS presents a first ever multimodal database of individuals with ID, recorded in a nearly real world settings for analysis of human affective states. MuDERI is an annotated multimodal database of audiovisual recordings, RGB-D videos and physiological signals of 12 participants in actual settings, which were recorded as participants were elicited using personalized real world objects and/or activities. The database is publicly available. © Springer International Publishing AG 2016.",2016,2021-05-19T13:26:41Z,2021-05-19T13:26:41Z,,264-273,10,,9979 LNAI,,,,,,,,,,English,,,,,,,ISBN: 9783319474366 Publisher: Springer Verlag,"<p>cited By 4; Conference of 8th International Conference on Social Robotics, ICSR 2016 ; Conference Date: 1 November 2016 Through 3 November 2016; Conference Code:185229</p>",,,Assistive robotics; Cognitive stimulations; Database systems; Disabled individuals; Emotion recognition; Intellectual disability; Multimodal database; Physiological signals; Rating; Robot-assisted therapies; Robotics,,"Agah A., Howard A.M., Salichs M.A., He H., Cabibihan J.-J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A composite framework for supporting user emotion detection based on intelligent taxonomy handling,0,"Cuzzocrea, Alfredo; Pilato, Giovanni",LOGIC JOURNAL OF THE IGPL,2021,journalArticle,,1367-0751,10.1093/jigpal/jzaa047,,"One of the most relevant issues of a social robot is its capability of catching the attention of a new acquaintance and empathize with her. The first steps towards a system which can be used by a social robot in order to be empathetic are illustrated in this paper. The system can analyze the Twitter ID of the new acquaintance, trying to detect the IAB (Interactive Advertising Bureau) Tier 1 categories that possibly can let arise in him/her a joyful feeling. Furthermore, it can retrieve news about that category and report them to the user, hopefully increasing his/her curiosity towards the system, improving the naturalness of the interaction. Moreover, the system is capable of querying Wikipedia in order to clarify any doubts that may arise in the user. A sample of a possible interaction is reported at the end of the paper.",2021-04,2021-05-19T13:29:52Z,2021-05-19T13:29:52Z,,207-219,13,2,29,,,,,,,,,,English,,,,,,,"Place: GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND Publisher: OXFORD UNIV PRESS Type: Article",,,,,affective AI; human-robot interaction; Taxonomies,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Visual similarity and psychological closeness are neurally dissociable in the brain response to vicarious pain,1,"Ionta, Silvio; Costantini, Marcello; Ferretti, Antonio; Galati, Gaspare; Romani, Gian Luca; Aglioti, Salvatore M.",CORTEX,2020,journalArticle,,0010-9452,10.1016/j.cortex.2020.09.028,,"Personal and vicarious experience of pain activate partially overlapping brain networks. This brain activity is further modulated by lowand high-order factors, e.g., the perceived intensity of the model's pain and the model's similarity with the onlooker, respectively. We investigated which specific aspect of similarity modulates such empathic reactivity, focusing on the potential differentiation between visual similarity and psychological closeness between the onlooker and different types of models. To this aim, we recorded fMRI data in neurotypical participants who observed painful and tactile stimuli delivered to an adult human hand, a baby human hand, a puppy dog paw, and an anthropomorphic robotic hand. The interaction between type of vicarious experience (pain, touch) and nature of model (adult, baby, dog, robot) showed that the right supramarginal gyrus (rSMG) was selectively active for visual similarity (more active during vicarious pain for the adult and baby models), while the anterior cingulate cortex (ACC) was more sensitive to psychological closeness (specifically linked to vicarious pain for the baby model). These findings indicate that visual similarity and psychological closeness between onlooker and model differentially affect the activity of brain regions specifically implied in encoding interindividual sharing of sensorimotor and affective aspects of vicarious pain, respectively. (C) 2020 The Author(s). Published by Elsevier Ltd.",2020-12,2021-05-19T13:29:56Z,2021-05-19T13:29:56Z,,295-308,14,,133,,,,,,,,,,English,,,,,,,"Place: 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE Publisher: ELSEVIER MASSON, CORP OFF Type: Article",,,,,Affective; Empathy; fMRI; Pain; Sensorimotor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An Open-Source Social Robot Based on Compliant Soft Robotics for Therapy with Children with ASD,0,"Casas-Bocanegra, Diego; Gomez-Vargas, Daniel; Pinto-Bernal, Maria J.; Maldonado, Juan; Munera, Marcela; Villa-Moreno, Adriana; Stoelen, Martin F.; Belpaeme, Tony; Cifuentes, Carlos A.",ACTUATORS,2020,journalArticle,,,10.3390/act9030091,,"Therapy with robotic tools is a promising way to help improve verbal and nonverbal communication in children. The robotic tools are able to increase aspects such as eye contact and the ability to follow instructions and to empathize with others. This work presents the design methodology, development, and experimental validation of a novel social robot based on CompliAnt SofT Robotics called the CASTOR robot, which intends to be used as an open-source platform for the long-term therapy of children with autism spectrum disorder (CwASD). CASTOR integrates the concepts of soft actuators and compliant mechanisms to create a replicable robotic platform aimed at real therapy scenarios involving physical interaction between the children and the robot. The validation shows promising results in terms of robustness and the safety of the user and robot. Likewise, mechanical tests assess the robot's response to blocking conditions for two critical modules (i.e., neck and arm) in interaction scenarios. Future works should focus on the validation of the robot's effectiveness in the therapy of CwASD.",2020-09,2021-05-19T13:30:01Z,2021-05-19T13:30:01Z,,,,3,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,autism spectrum disorder; autism therapy; compliant mechanisms; physical interaction; robot design; series elastic actuators; social assistive robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A Robot Has a Mind of Its Own Because We Intuitively Share It,0,"Sumitani, Mizuho; Osumi, Michihiro; Abe, Hiroaki; Azuma, Kenji; Tsuchida, Rikuhei; Sumitani, Masahiko",APPLIED SCIENCES-BASEL,2020,journalArticle,,,10.3390/app10186531,,"People perceive the mind in two dimensions: intellectual and affective. Advances in artificial intelligence enable people to perceive the intellectual mind of a robot through their semantic interactions. Conversely, it has been still controversial whether a robot has an affective mind of its own without any intellectual actions or semantic interactions. We investigated pain experiences when observing three different facial expressions of a virtual agent modeling affective minds (i.e., painful, unhappy, and neutral). The cold pain detection threshold of 19 healthy subjects was measured as they watched a black screen, then changes in their cold pain detection thresholds were evaluated as they watched the facial expressions. Subjects were asked to rate the pain intensity from the respective facial expressions. Changes of cold pain detection thresholds were compared and adjusted by the respective pain intensities. Only when watching the painful expression of a virtual agent did, the cold pain detection threshold increase significantly. By directly evaluating intuitive pain responses when observing facial expressions of a virtual agent, we found that we `share' empathic neural responses, which can be intuitively emerge, according to observed pain intensity with a robot (a virtual agent).",2020-09,2021-05-19T13:30:02Z,2021-05-19T13:30:02Z,,,,18,10,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,affective mind; empathy; facial expression; pain; robot (virtual agent),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Artificial Intelligence and Robotics in Nursing: Ethics of Caring as a Guide to Dividing Tasks Between AI and Humans,2,"Stokes, Felicia; Palmer, Amitabha",NURSING PHILOSOPHY,2020,journalArticle,,1466-7681,10.1111/nup.12306,,"Nurses have traditionally been regarded as clinicians that deliver compassionate, safe, and empathetic health care (Nurses again outpace other professions for honesty & ethics, 2018). Caring is a fundamental characteristic, expectation, and moral obligation of the nursing and caregiving professions (Nursing: Scope and standards of practice, American Nurses Association, Silver Spring, MD, 2015). Along with caring, nurses are expected to undertake ever-expanding duties and complex tasks. In part because of the growing physical, intellectual and emotional demandingness, of nursing as well as technological advances, artificial intelligence (AI) and AI care robots are rapidly changing the healthcare landscape. As technology becomes more advanced, efficient, and economical, opportunities and pressure to introduce AI into nursing care will only increase. In the first part of the article, we review recent and existing applications of AI in nursing and speculate on future use. Second, situate our project within the recent literature on the ethics of nursing and AI. Third, we explore three dominant theories of caring and the two paradigmatic expressions of caring (touch and presence) and conclude that AI-at least for the foreseeable future-is incapable of caring in the sense central to nursing and caregiving ethics. We conclude that for AI to be implemented ethically, it cannot transgress the core values of nursing, usurp aspects of caring that can only meaningfully be carried out by human beings, and it must support, open, or improve opportunities for nurses to provide the uniquely human aspects of care.",2020-10,2021-05-19T13:30:03Z,2021-05-19T13:30:03Z,,,,4,21,,,,,,,,,,English,,,,,,,"Place: 111 RIVER ST, HOBOKEN 07030-5774, NJ USA Publisher: WILEY Type: Article",,,,,artificial intelligence; ethics; ethics of caring; nursing; robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot",189,"Zhou, Li; Gao, Jianfeng; Li, Di; Shum, Heung-Yeung",COMPUTATIONAL LINGUISTICS,2020,journalArticle,,0891-2017,10.1162/coli_a_00368,,"This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human-machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.",2020-03,2021-05-19T13:30:07Z,2021-05-19T13:30:07Z,,53-93,41,1,46,,,,,,,,,,English,,,,,,,"Place: ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA Publisher: MIT PRESS Type: Article",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Empathic responses to unknown others are modulated by shared behavioural traits,1,"Anders, Silke; Beck, Christian; Domin, Martin; Lotze, Martin",SCIENTIFIC REPORTS,2020,journalArticle,,2045-2322,10.1038/s41598-020-57711-6,,"How empathically people respond to a stranger's pain or pleasure does not only depend on the situational context, individual traits and intentions, but also on interindividual factors. Here we ask whether empathic responses towards unknown others are modulated by behavioural similarity as a potential marker of genetic relatedness. Participants watched two supposed human players who were modelled as having a strong (player LP) or weak (player NLP) tendency to lead in social situations executing penalty shots in a virtual reality robot soccer game. As predicted, empathic response were modulated by shared behavioural traits: participants whose tendency to lead was more similar to player LP's tendency to lead experienced more reward, and showed stronger neural activity in reward-related brain regions, when they saw player LP score a goal, and participants whose tendency to lead was more similar to player NLP's tendency to lead showed stronger empathic responses when they saw player NLP score a goal. These findings highlight the potentially evolutionary grounded role of phenotypic similarity for neural processes underlying human social perception.",2020-02-06,2021-05-19T13:30:08Z,2021-05-19T13:30:08Z,,,,1,10,,,,,,,,,,English,,,,,,,"Place: MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND Publisher: NATURE PUBLISHING GROUP Type: Article",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Android Pretending to Have Similar Traits of Imagination as Humans Evokes Stronger Perceived Capacity to Feel,1,"Tatsukawa, Kyohei; Takahashi, Hideyuki; Yoshikawa, Yuichiro; Ishiguro, Hiroshi",FRONTIERS IN ROBOTICS AND AI,2019,journalArticle,,2296-9144,10.3389/frobt.2019.00088,,"The perception of robots as mindful enriches how humans relate to them. Given that congruence in perceived representations of the world enable humans to experience commonality in mental states (a shared reality), we propose that congruence between humans, and robots will encourage humans to attribute humanlike mental capacities to robots. To investigate this, we assessed the mental perceptions of a robot in a visual imagination task using Gray et al. mind perception scale, which evaluates experience (capacity to feel), and agency (capacity to plan and do). For each ambiguous picture in the designed task, humans, and a robot imagined an animal. The task was performed under six conditions (2 x 3: Lead/Follow for Low/Medium/High). In the Lead condition, the robot records its perceived animal first; in the Follow condition, the robot records after the human participant. The experiment had three different degrees of congruence: Low (0%), Medium (60%), and High (100%). The results showed that perceived experiences were higher in the Lead condition, suggesting that the robot is perceived to be empathetic. It is probable that the Follow condition was perceived as mimicry rather than shared reality. Therefore, the order of response may have played an important role in commonality in mental states. No differences were observed in the perceived agency across all conditions. These results suggest that the order of response affects how humans perceive the minds of robots. Additionally, we assessed a post-task questionnaire to evaluate the interpersonal closeness that the humans felt toward the android. The main effect was observed in the degrees of congruence. This result is in line with those of previous studies that report relationships across sharing of similarities and friendliness.",2019-09-18,2021-05-19T13:30:20Z,2021-05-19T13:30:20Z,,,,,6,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,interpersonal closeness; mind perception; robot; shared reality; visual imagination,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Development of an Effective Information Media Using Two Android Robots,1,"Nishio, Toshiaki; Yoshikawa, Yuichiro; Ogawa, Kohei; Ishiguro, Hiroshi",APPLIED SCIENCES-BASEL,2019,journalArticle,,,10.3390/app9173442,,"Conversational robots have been used to convey information to people in the real world. Android robots, which have a human-like appearance, are expected to be able to convey not only objective information but also subjective information, such as a robot's feelings. Meanwhile, as an approach to realize attractive conversation, multi-party conversation by multiple robots was the focus of this study. By collaborating among several robots, the robots provide information while maintaining the naturalness of conversation. However, the effectiveness of interaction with people has not been surveyed using this method. In this paper, to develop more efficient media to convey information, we propose a scenario-based, semi-passive conversation system using two androids. To verify its effectiveness, we conducted a subjective experiment comparing it to a system that does not include any interaction with people, and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids. The experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids.",2019-09-01,2021-05-19T13:30:20Z,2021-05-19T13:30:20Z,,,,17,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,android robot; human robot interaction; multiple conversation robots; passive social conversation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Multimodal Integration of Emotional Signals from Voice, Body, and Context: Effects of (In)Congruence on Emotion Recognition and Attitudes Towards Robots",27,"Tsiourti, Christiana; Weiss, Astrid; Wac, Katarzyna; Vincze, Markus",INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS,2019,journalArticle,,1875-4791,10.1007/s12369-019-00524-z,,"Humanoid social robots have an increasingly prominent place in today's world. Their acceptance in social and emotional human-robot interaction (HRI) scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users. In this article, we incorporate recent findings from psychology, neuroscience, human-computer interaction, and HRI, to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots, with a particular emphasis on the effects of incongruence. In a social HRI laboratory experiment, we investigated contextual incongruence (i.e., the conflict situation where a robot's reaction is incongrous with the socio-emotional context of the interaction) and cross-modal incongruence (i.e., the conflict situation where an observer receives incongruous emotional information across the auditory (vocal prosody) and visual (whole-body expressions) modalities). Results showed that both contextual incongruence and cross-modal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot. This, in turn, gives the impression that the robot is unintelligent or unable to express “empathic” behaviour and leads to profoundly harmful effects on likability and believability. Our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way. We offer recommendations regarding design choices and discuss future research areas in the direction of multimodal HRI.",2019-08,2021-05-19T13:30:21Z,2021-05-19T13:30:21Z,,555-573,19,4,11,,,,,,,,,,English,,,,,,,"Place: VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS Publisher: SPRINGER Type: Article",,,,,Believability; Body language; Human-robot interaction; Multi-modal interaction; Robot emotions; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hybrid Spiral STC-Hedge Algebras Model in Knowledge Reasonings for Robot Coverage Path Planning and Its Applications,1,"Pham, Hai Van; Asadi, Farzin; Abut, Nurettin; Kandilli, Ismet",APPLIED SCIENCES-BASEL,2019,journalArticle,,,10.3390/app9091909,,"Robotics is a highly developed field in industry, and there is a large research effort in terms of humanoid robotics, including the development of multi-functional empathetic robots as human companions. An important function of a robot is to find an optimal coverage path planning, with obstacle avoidance in dynamic environments for cleaning and monitoring robotics. This paper proposes a novel approach to enable robotic path planning. The proposed approach combines robot reasoning with knowledge reasoning techniques, hedge algebra, and the Spiral Spanning Tree Coverage (STC) algorithm, for a cleaning and monitoring robot with optimal decisions. This approach is used to apply knowledge inference and hedge algebra with the Spiral STC algorithm to enable autonomous robot control in the optimal coverage path planning, with minimum obstacle avoidance. The results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot. Experimental results are compared with current methods under the same conditions. The proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates. Experiments are done with real robots for cleaning in dynamic environments.",2019-05-01,2021-05-19T13:30:25Z,2021-05-19T13:30:25Z,,,,9,9,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,hedge algebra; robot coverage path planning; robot knowledge reasonings; simulation of a robot; spiral spanning tree coverage,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A Wearable Skin-Stretching Tactile Interface for Human-Robot and Human-Human Communication,9,"Haynes, Alice; Simons, Melanie F.; Helps, Tim; Nakamura, Yuichi; Rossiter, Jonathan",IEEE ROBOTICS AND AUTOMATION LETTERS,2019,journalArticle,,2377-3766,10.1109/LRA.2019.2896933,,"Currently, the majority of wearable robotic haptic feedback devices rely on vibrations for relaying sensory information to the user. While this can be very effective, vibration as a physical stimulation is limited in modality and is uncommon in the natural world. In many cases, for human-robot and human-human interaction, a more natural, affective tactile interaction is needed to provide comfortable and varied stimuli. In this letter, we present the super-cutaneous wearable electrical empathic stimulator (SCWEES), a tactile device that gently stretches and squeezes the surface of the skin. Our hypothesis is that this device can create a pleasant, unobtrusive sensation that can be used to mediate social interactions or to deliver subtle alerts. We describe the design of the SCWEES, a lightweight 3D-printed semi-flexible structure that attaches to the skin at two points and actuates via two shape-memory alloy coil actuators. We evaluate the SCWEES through a range of human interaction experiments: stimulation strength and pleasantness, contraction and extension, and the conveyance of non-disruptive notifications. Quantitative and qualitative results show that the SCWEES generates a pleasant sensation, can convey useful information in human-machine interactions, and delivers affective stimulation that is less disruptive than conventional vibratory tactile stimulation when the user is engaged in a task.",2019-04,2021-05-19T13:30:26Z,2021-05-19T13:30:26Z,,1641-1646,6,2,4,,,,,,,,,,English,,,,,,,"Place: 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA Publisher: IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC Type: Article",,,,,affective tactile stimulation; haptics and haptic interfaces; social human-robot interaction; soft robot applications; Wearable robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application of autoencoders in cyber-empathic design,2,"Ghosh, Dipanjan; Olewnik, Andrew; Lewis, Kemper",DESIGN SCIENCE,2018,journalArticle,,2053-4701,10.1017/dsj.2018.11,,"A critical task in product design is mapping information from the consumer space to the design space. This process is largely dependent on the designer to identify and relate psychological and consumer level factors to engineered product attributes. In this way, current methodologies lack provision to test a designer's cognitive reasoning and may introduce bias through the mapping process. Prior work on Cyber-Empathic Design (CED) supports this mapping by relating user-product interaction data from embedded sensors to psychological constructs. To understand consumer perceptions, a network of psychological constructs is developed using Structural Equation Modeling for parameter estimation and hypothesis testing, making the framework falsifiable in nature. The focus of this technical brief is toward automating CED through unsupervised deep learning to extract features from raw data. Additionally, Partial Least Square Structural Equation Modeling is used with extracted sensor features as inputs. To demonstrate the effectiveness of the approach a case study involving sensor-integrated shoes compares three models - a survey-only model (no sensor data), the existing CED approach with manually extracted sensor features, and the proposed deep learning based CED approach. The deep learning based approach results in improved model fit.",2018-07-30,2021-05-19T13:30:50Z,2021-05-19T13:30:50Z,,,,,4,,,,,,,,,,English,,,,,,,"Place: 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA Publisher: CAMBRIDGE UNIV PRESS Type: Article",,,,,empathic design; machine learning; product design; sensors,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
An examination of gender differences versus similarities in a virtual world,10,"Martens, Amanda L.; Grover, Cathy A.; Saucier, Donald A.; Morrison, Breanna A.",COMPUTERS IN HUMAN BEHAVIOR,2018,journalArticle,,0747-5632,10.1016/j.chb.2018.03.012,,"We derived competing hypotheses from the gender similarities perspective versus the gender differences perspective to examine participants' behavior in an online virtual world in which we manipulated participants' gender. To manipulate participants' gender in the virtual environment, we randomly assigned them to one of three avatars (female, male, or robot). Using a screen recording device, we measured the percentage of time participants spent interacting with empathizing (e.g., options for shopping, telephone) and systemizing (e.g., weapons, options for building) objects in a virtual reality house that we constructed to reflect evidence put forth by the differences perspective. Because we derived competing hypotheses we expected to find support for either the similarities perspective or the differences perspective; however, our results suggested support for both. Consistent with the differences perspective hypotheses, participants paid attention to objects in the environment that were consistent with the social representation of their own gender. However, our results were consistent with the similarities perspective hypotheses, such that the avatars' gender also played a role in the percentage of time participants spent interacting with empathizing and systemizing objects. Therefore, we conclude that observable differences between men and women are the consequence of both biological and social forces, and research should focus on the interaction between the two as etiologies and explanations for sex and gender differences and similarities. (C) 2018 Elsevier Ltd. All rights reserved.",2018-07,2021-05-19T13:30:51Z,2021-05-19T13:30:51Z,,404-409,6,,84,,,,,,,,,,English,,,,,,,"Place: THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND Publisher: PERGAMON-ELSEVIER SCIENCE LTD Type: Article",,,,,Gender differences; Gender similarities; Virtual reality,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Emotional Storytelling Using Virtual and Robotic Agents,28,"Costa, Sandra; Brunete, Alberto; Bae, Byung-Chull; Mavridis, Nikolaos",INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS,2018,journalArticle,,0219-8436,10.1142/S0219843618500068,,"In order to create effective storytelling agents three fundamental questions must be answered: first, is a physically embodied agent preferable to a virtual agent or a voice-only narration? Second, does a human voice have an advantage over a synthesised voice? Third, how should the emotional trajectory of the different characters in a story be related to a storyteller's facial expressions during storytelling time, and how does this correlate with the apparent emotions on the faces of the listeners? The results of two specially designed studies indicate that the physically embodied robot produces more attention to the listener as compared to a virtual embodiment, that a human voice is preferable over the current state of the art of text-to-speech, and that there is a complex yet interesting relation between the emotion lines of the story, the facial expressions of the narrating agent, and the emotions of the listener, and that the empathising of the listener is evident through its facial expressions. This work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximise their effectiveness.",2018-06,2021-05-19T13:30:52Z,2021-05-19T13:30:52Z,,,,3,15,,,,,,,,,,English,,,,,,,"Place: 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE Publisher: WORLD SCIENTIFIC PUBL CO PTE LTD Type: Article",,,,,emotional affective response; eye blink analysis; facial expression analysis; non-verbal communication; posture analysis; robot and virtual agents; Storytelling,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Experiences of a Motivational Interview Delivered by a Robot: Qualitative Study,23,"da Silva, Joana Galvao Gomes; Kavanagh, David J.; Belpaeme, Tony; Taylor, Lloyd; Beeson, Konna; Andrade, Jackie",JOURNAL OF MEDICAL INTERNET RESEARCH,2018,journalArticle,,1438-8871,10.2196/jmir.7737,,"Background: Motivational interviewing is an effective intervention for supporting behavior change but traditionally depends on face-to-face dialogue with a human counselor. This study addressed a key challenge for the goal of developing social robotic motivational interviewers: creating an interview protocol, within the constraints of current artificial intelligence, which participants will find engaging and helpful. Objective: The aim of this study was to explore participants' qualitative experiences of a motivational interview delivered by a social robot, including their evaluation of usability of the robot during the interaction and its impact on their motivation. Methods: NAO robots are humanoid, child-sized social robots. We programmed a NAO robot with Choregraphe software to deliver a scripted motivational interview focused on increasing physical activity. The interview was designed to be comprehensible even without an empathetic response from the robot. Robot breathing and face-tracking functions were used to give an impression of attentiveness. A total of 20 participants took part in the robot-delivered motivational interview and evaluated it after 1 week by responding to a series of written open-ended questions. Each participant was left alone to speak aloud with the robot, advancing through a series of questions by tapping the robot's head sensor. Evaluations were content-analyzed utilizing Boyatzis' steps: (1) sampling and design, (2) developing themes and codes, and (3) validating and applying the codes. Results: Themes focused on interaction with the robot, motivation, change in physical activity, and overall evaluation of the intervention. Participants found the instructions clear and the navigation easy to use. Most enjoyed the interaction but also found it was restricted by the lack of individualized response from the robot. Many positively appraised the nonjudgmental aspect of the interview and how it gave space to articulate their motivation for change. Some participants felt that the intervention increased their physical activity levels. Conclusions: Social robots can achieve a fundamental objective of motivational interviewing, encouraging participants to articulate their goals and dilemmas aloud. Because they are perceived as nonjudgmental, robots may have advantages over more humanoid avatars for delivering virtual support for behavioral change.",2018-05,2021-05-19T13:30:53Z,2021-05-19T13:30:53Z,,,,5,20,,,,,,,,,,English,,,,,,,"Place: 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA Publisher: JMIR PUBLICATIONS, INC Type: Article",,,,,computer-assisted therapy; counseling; exercise; motivation; motivational interviewing; person-centered therapy; qualitative research; robotics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Designing the Mind of a Social Robot,21,"Lazzeri, Nicole; Mazzei, Daniele; Cominelli, Lorenzo; Cisternino, Antonio; De Rossi, Danilo Emilio",APPLIED SCIENCES-BASEL,2018,journalArticle,,2076-3417,10.3390/app8020302,,"Humans have an innate tendency to anthropomorphize surrounding entities and have always been fascinated by the creation of machines endowed with human-inspired capabilities and traits. In the last few decades, this has become a reality with enormous advances in hardware performance, computer graphics, robotics technology, and artificial intelligence. New interdisciplinary research fields have brought forth cognitive robotics aimed at building a new generation of control systems and providing robots with social, empathetic and affective capabilities. This paper presents the design, implementation, and test of a human-inspired cognitive architecture for social robots. State-of-the-art design approaches and methods are thoroughly analyzed and discussed, cases where the developed system has been successfully used are reported. The tests demonstrated the system's ability to endow a social humanoid robot with human social behaviors and with in-silico robotic emotions.",2018-02,2021-05-19T13:30:55Z,2021-05-19T13:30:55Z,,,,2,8,,,,,,,,,,English,,,,,,,"Place: ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND Publisher: MDPI Type: Article",,,,,cognitive architecture; human-inspired robot; humanoid; robot mind; social cognition; social robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Empathizing with Emotional Robot Based on Cognition Reappraisal,7,"Liu, Xin; Xie, Lun; Wang, Zhiliang",CHINA COMMUNICATIONS,2017,journalArticle,,1673-5447,10.1109/CC.2017.8068769,,"This paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive person's expressions. It integrates a guiding cognitive reappraisal strategy into the HMM (Hidden Markov Model) emotional interactive model for empathizing between robot and person. The emotion is considered as a source in the 3D space (Arousal, Valence, and Stance). State transition and emotion intensity can be quantitatively analyzed in the continuous space. This cognition-emotion interactive model have been verified by the expression and behavior robot. Empathizing is the main distinguishing feature of our work, and it is realized by the emotional regulation which operated in a continuous 3D emotional space enabling a wide range of intermediate emotions. The experiment results provide evidence with acceptability, accuracy, richness, fluency, interestingness, friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the human-robot interaction (HRI).",2017-09,2021-05-19T13:31:25Z,2021-05-19T13:31:25Z,,100-113,14,9,14,,,,,,,,,,English,,,,,,,"Place: NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA Publisher: CHINA INST COMMUNICATIONS Type: Article",,,,,active field emotion space; emotional regulation; emotional robot; guiding cognitive reappraisal; human-robot interaction,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Touch sensor for social robots and interactive objects affective interaction,7,"Mazzei, Daniele; De Maria, Carmelo; Vozzi, Giovanni",SENSORS AND ACTUATORS A-PHYSICAL,2016,journalArticle,,0924-4247,10.1016/j.sna.2016.10.006,,"The recognised importance of physical experience in empathic exchanges has led to the development of touch sensors for human robot affective interaction. Most of these sensors, implemented as matrix of pressure sensors, are rigid, cannot be fabricated in complex shapes, cannot be subjected to large deformations, and usually allow to capture only the contact event, without any information about the interaction context. This paper presents a tactile flux sensor able to capture the entire context of the interaction including gestures and patterns. The sensor is made of alternate layers of sensitive and insulating silicone: the soft nature of the sensor makes it adaptable to complex and deformable bodies. The main features from electrical signals are extracted with the principal component analysis, and a self-organising neural network is in charge for the classification and spatial identification of the events to acknowledge and measure the gesture. The results open to interesting applications, which span from toy manufacturing, to human-robot interaction, and even to sport and biomedical equipment and applications. (C) 2016 Elsevier B.V. All rights reserved.",2016-11-01,2021-05-19T13:31:40Z,2021-05-19T13:31:40Z,,92-99,8,,251,,,,,,,,,,English,,,,,,,"Place: PO BOX 564, 1001 LAUSANNE, SWITZERLAND Publisher: ELSEVIER SCIENCE SA Type: Article",,,,,Affective robotics; Flexible silicone sensor; Tactile interaction; Touch sensor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can a humanoid face be expressive? A psychophysiological investigation,28,"Lazzeri, Nicole; Mazzei, Daniele; Greco, Alberto; Rotesi, Annalisa; Lanata, Antonio; De Rossi, Danilo Emilio",FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,2015,journalArticle,,2296-4185,10.3389/fbioe.2015.00064,,"Non-verbal signals expressed through body language play a crucial role in multi-modal human communication during social relations. Indeed, in all cultures, facial expressions are the most universal and direct signs to express innate emotional cues. A human face conveys important information in social interactions and helps us to better understand our social partners and establish empathic links. Latest researches show that humanoid and social robots are becoming increasingly similar to humans, both esthetically and expressively. However, their visual expressiveness is a crucial issue that must be improved to make these robots more realistic and intuitively perceivable by humans as not different from them. This study concerns the capability of a humanoid robot to exhibit emotions through facial expressions. More specifically, emotional signs performed by a humanoid robot have been compared with corresponding human facial expressions in terms of recognition rate and response time. The set of stimuli included standardized human expressions taken from an Ekman-based database and the same facial expressions performed by the robot. Furthermore, participants' psychophysiological responses have been explored to investigate whether there could be differences induced by interpreting robot or human emotional stimuli. Preliminary results show a trend to better recognize expressions performed by the robot than 2D photos or 3D models. Moreover, no significant differences in the subjects' psychophysiological state have been found during the discrimination of facial expressions performed by the robot in comparison with the same task performed with 2D photos and 3D models.",2015,2021-05-19T13:32:28Z,2021-05-19T13:32:28Z,,,,,3,,,,,,,,,,English,,,,,,,"Place: AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND Publisher: FRONTIERS MEDIA SA Type: Article",,,,,affective computing; emotion perception; expression recognition; facial expressions; humanoid robot; psychophysiological signals; social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
empathy is not in our genes,53,"Heyes, Cecilia",Neuroscience & Biobehavioral Reviews,2018,journalArticle,,0149-7634,https://doi.org/10.1016/j.neubiorev.2018.11.001,https://www.sciencedirect.com/science/article/pii/S0149763418308194,"in academic and public life empathy is seen as a fundamental force of morality – a psychological phenomenon, rooted in biology, with profound effects in law, policy, and international relations. but the roots of empathy are not as firm as we like to think. the matching mechanism that distinguishes empathy from compassion, envy, schadenfreude, and sadism is a product of learning. here i present a dual system model that distinguishes empathy1, an automatic process that catches the feelings of others, from empathy2, controlled processes that interpret those feelings. research with animals, infants, adults and robots suggests that the mechanism of empathy1, emotional contagion, is constructed in the course of development through social interaction. learned matching implies that empathy is both agile and fragile. it can be enhanced and redirected by novel experience, and broken by social change.",2018,2021-05-19T13:19:57Z,2021-05-19T13:19:57Z,,499-507,9,,95,,,,,,,,,,,,,,,,,,,,,Affect mirroring; Affective empathy; Associative learning; Emotional contagion; Empathic understanding; Empathy; Learned Matching; Mirror neurons; Self-stimulation; Synchronous emotion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Promises and trust in human–robot interaction,0,"Cominelli, L.; Feri, F.; Garofalo, R.; Giannetti, C.; Meléndez-Jiménez, M.A.; Greco, A.; Nardelli, M.; Scilingo, E.P.; Kirchkamp, O.",Scientific Reports,2021,journalArticle,,20452322,10.1038/s41598-021-88622-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105440198&doi=10.1038%2fs41598-021-88622-9&partnerID=40&md5=8c892c097d8e210e475cacdab9bad379,"Understanding human trust in machine partners has become imperative due to the widespread use of intelligent machines in a variety of applications and contexts. The aim of this paper is to investigate whether human-beings trust a social robot—i.e. a human-like robot that embodies emotional states, empathy, and non-verbal communication—differently than other types of agents. To do so, we adapt the well-known economic trust-game proposed by Charness and Dufwenberg (2006) to assess whether receiving a promise from a robot increases human-trust in it. We find that receiving a promise from the robot increases the trust of the human in it, but only for individuals who perceive the robot very similar to a human-being. Importantly, we observe a similar pattern in choices when we replace the humanoid counterpart with a real human but not when it is replaced by a computer-box. Additionally, we investigate participants’ psychophysiological reaction in terms of cardiovascular and electrodermal activity. Our results highlight an increased psychophysiological arousal when the game is played with the social robot compared to the computer-box. Taken all together, these results strongly support the development of technologies enhancing the humanity of robots. © 2021, The Author(s).",2021,2021-05-19T13:26:03Z,2021-05-19T13:26:03Z,,,,1,11,,,,,,,,,,English,,,,,,,Publisher: Nature Research,<p>cited By 0</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Empathic responses and moral status for social robots: an argument in favor of robot patienthood based on K. E. Løgstrup,0,"Balle, S.N.",AI and Society,2021,journalArticle,,9515666,10.1007/s00146-021-01211-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104950822&doi=10.1007%2fs00146-021-01211-2&partnerID=40&md5=3787db2c2f40a90ea3212ba2a25225a5,"Empirical research on human–robot interaction (HRI) has demonstrated how humans tend to react to social robots with empathic responses and moral behavior. How should we ethically evaluate such responses to robots? Are people wrong to treat non-sentient artefacts as moral patients since this rests on anthropomorphism and ‘over-identification’ (Bryson and Kime, Proc Twenty-Second Int Jt Conf Artif Intell Barc Catalonia Spain 16–22:1641–1646, 2011)—or correct since spontaneous moral intuition and behavior toward nonhumans is indicative for moral patienthood, such that social robots become our ‘Others’ (Gunkel, Robot rights, MIT Press, London, 2018; Coeckelbergh, Kairos J Philos Sci 20:141–158, 2018)?. In this research paper, I weave extant HRI studies that demonstrate empathic responses toward robots with the recent debate on moral status for robots, on which the ethical evaluation of moral behavior toward them is dependent. Patienthood for robots has standardly been thought to obtain on some intrinsic ground, such as being sentient, conscious, or having interest. But since these attempts neglect moral experience and are curbed by epistemic difficulties, I take inspiration from Coeckelbergh and Gunkel’s ‘relational approach’ to explore an alternative way of accounting for robot patienthood based on extrinsic premises. Based on the ethics of Danish theologian K. E. Løgstrup (1905–1981) I argue that empathic responses can be interpreted as sovereign expressions of life and that these expressions benefit human subjects—even if they emerge from social interaction afforded by robots we have anthropomorphized. I ultimately develop an argument in defense of treating robots as moral patients. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",2021,2021-05-19T13:26:06Z,2021-05-19T13:26:06Z,,,,,,,,,,,,,,,English,,,,,,,Publisher: Springer Science and Business Media Deutschland GmbH,<p>cited By 0</p>,,,Catalonia; Empirical research; Human subjects; Philosophical aspects; Research papers; Robot interactions; Social interactions; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can communication with social robots influence how children develop empathy? Best-evidence synthesis,0,"Pashevich, E.",AI and Society,2021,journalArticle,,9515666,10.1007/s00146-021-01214-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105417711&doi=10.1007%2fs00146-021-01214-z&partnerID=40&md5=3450c898fc3bbd8515987bb1735a8566,"Social robots are gradually entering children’s lives in a period when children learn about social relationships and exercise prosocial behaviors with parents, peers, and teachers. Designed for long-term emotional engagement and to take the roles of friends, teachers, and babysitters, such robots have the potential to influence how children develop empathy. This article presents a review of the literature (2010–2020) in the fields of human–robot interaction (HRI), psychology, neuropsychology, and roboethics, discussing the potential impact of communication with social robots on children’s social and emotional development. The critical analysis of evidence behind these discussions shows that, although robots theoretically have high chances of influencing the development of empathy in children, depending on their design, intensity, and context of use, there is no certainty about the kind of effect they might have. Most of the analyzed studies, which showed the ability of robots to improve empathy levels in children, were not longitudinal, while the studies observing and arguing for the negative effect of robots on children’s empathy were either purely theoretical or dependent on the specific design of the robot and the situation. Therefore, there is a need for studies investigating the effects on children’s social and emotional development of long-term regular and consistent communication with robots of various designs and in different situations. © 2021, The Author(s).",2021,2021-05-19T13:26:06Z,2021-05-19T13:26:06Z,,,,,,,,,,,,,,,English,,,,,,,Publisher: Springer Science and Business Media Deutschland GmbH,<p>cited By 0</p>,,,CAN communications; Context of use; Critical analysis; Economic and social effects; Emotional engagements; Machine design; Neuropsychology; Potential impacts; Robot interactions; Social relationships; Social robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhancing Emotional Support: The Effect of a Robotic Object on Human–Human Support Quality,0,"Erel, H.; Trayman, D.; Levy, C.; Manor, A.; Mikulincer, M.; Zuckerman, O.",International Journal of Social Robotics,2021,journalArticle,,18754791,10.1007/s12369-021-00779-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105378198&doi=10.1007%2fs12369-021-00779-5&partnerID=40&md5=31fccb98f281cb4956d06a3377775de0,"Emotional support in the context of psychological caregiving is an important aspect of human–human interaction that can significantly increase well-being. In this study, we tested if non-verbal gestures of a non-humanoid robot can increase emotional support in a human–human interaction. Sixty-four participants were invited in pairs to take turns in disclosing a personal problem and responding in a supportive manner. In the experimental condition, the robotic object performed emphatic gestures, modeled according to the behavior of a trained therapist. In the baseline condition, the robotic object performed up-and-down gestures, without directing attention towards the participants. Findings show that the robot’s empathy-related gestures significantly improved the emotional support quality provided by one participant to another, as indicated by both subjective and objective measures. The non-humanoid robot was perceived as peripheral to the natural human–human interaction and influenced participants’ behavior without interfering. We conclude that non-humanoid gestures of a robotic object can enhance the quality of emotional support in intimate human–human interaction. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.",2021,2021-05-19T13:26:07Z,2021-05-19T13:26:07Z,,,,,,,,,,,,,,,English,,,,,,,Publisher: Springer Science and Business Media B.V.,<p>cited By 0</p>,,,Agricultural robots; Anthropomorphic robots; Base-line conditions; Emotional supports; Experimental conditions; Human interactions; Human support; Humanoid robot; Robotics; Social robots; Subjective and objective measures; Well being,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multi-modality Sentiment Analysis in Social Internet of Things based on Hierarchical Attentions and CSATTCN with MBM Network,9,"Xiao, G.; Tu, G.; Zheng, L.; Zhou, T.; Li, X.; Ahmed, S.H.; Jiang, D.",IEEE Internet of Things Journal,2020,journalArticle,,23274662,10.1109/JIOT.2020.3015381,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099552559&doi=10.1109%2fJIOT.2020.3015381&partnerID=40&md5=00cb27c2be4c5b7cab3cc2add96681ec,"Multi-modality sentiment analysis in the social internet of things is a developing field, which is basic to empathetic mechanisms, affective computing, and artificial intelligence. Current works in this domain do not explicitly consider the influence of contextual information fusion based on correlation coefficient and memory network with branch structure for sentiment analysis. Unlike present works, this paper presents a Hierarchical Self-attention Fusion (H-SATF) model for capturing contextual information better among utterances, a Contextual Self-attention Temporal Convolutional Network (CSAT-TCN) for the sentiment recognition in social internet of things, and a Multi Branches Memory (MBM) network that stores self-speaker and inter-speaker sentimental states into global memories. For the MOSI datasets, the hybrid H-SATF-CSAT-TCN-MBM model outperforms the state-of-art networks and shows 0.31 9.93% improvement. IEEE",2020,2021-05-19T13:26:16Z,2021-05-19T13:26:16Z,,,,,,,,,,,,,,,English,,,,,,,Publisher: Institute of Electrical and Electronics Engineers Inc.,<p>cited By 5</p>,,,Affective Computing; ART networks; Arts computing; Branch structure; Contextual information; Convolutional networks; Convolutional neural networks; Correlation coefficient; Internet of things; Memory network; Multi modality; Sentiment analysis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Motions with emotions? A phenomenological approach to understanding the simulated aliveness of a robot body,12,"Parviainen, J.; van Aerschot, L.; Särkikoski, T.; Pekkarinen, S.; Melkas, H.; Hennala, L.",Techne: Research in Philosophy and Technology,2019,journalArticle,,10918264,10.5840/techne20191126106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081323649&doi=10.5840%2ftechne20191126106&partnerID=40&md5=378eb5e3022a3bfccf7c5f223679272b,"This article examines how the interactive capabilities of companion robots, particularly their materiality and animate movements, appeal to human users and generate an image of aliveness. Building on Husserl's phenomenological notion of a 'double body' and theories of emotions as affective responses, we develop a new understanding of the robots' simulated aliveness. Analyzing empirical findings of a field study on the use of the robot Zora in care homes for older people, we suggest that the aliveness of companion robots is the result of a combination of four aspects: 1) material ingredients, 2) morphology, 3) animate movements guided by software programs and human operators as in Wizard of Oz-settings and 4) anthropomorphising narratives created by their users to support the robot's performance. We suggest that narratives on affective states, such as, sleepiness or becoming frightened attached to the robot trigger users' empathic feelings, caring and tenderness toward the robot. © 2019 Philosophy Documentation Center. All rights reserved.",2019,2021-05-19T13:26:26Z,2021-05-19T13:26:26Z,,318-341,24,3,23,,,,,,,,,,English,,,,,,,Publisher: Philosophy Documentation Center,<p>cited By 10</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The PAUL Suit©: An experience of ageing,11,"Bennett, P.; Moore, M.; Wenham, J.",Clinical Teacher,2016,journalArticle,,17434971,10.1111/tct.12410,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962516324&doi=10.1111%2ftct.12410&partnerID=40&md5=b1c6d99b190d125ab4dbf1d3806b09d5,"Background: An ageing population worldwide makes it increasingly important that health students understand issues that elderly people face and can provide empathic care to them. Context: This teaching department in an isolated rural setting developed an interprofessional learning session to assist health students to understand issues of functional loss and social isolation that can affect elderly people. Innovation: The Premature Ageing Unisex Leisure (PAUL) Suit© was developed as part of a 1-day learning session for undergraduate health students - including students of medicine, nursing and allied health - attending clinical placement in far-west New South Wales. The suit was developed locally and can be adjusted to simulate a wide range of functional losses in the wearer. Students undertake a range of daily tasks in the community while wearing the suit in the company of a student 'carer'. Over the past 4 years, approximately 140 students have participated in the simulation. Post-simulation evaluations report that students gain a greater understanding of some functional issues associated with ageing, and of the social isolation that can be associated with these. The experiential nature of the activity leads to some powerful insights. This activity is an innovative, experiential tool to deepen students understanding of issues related to ageing Implications: This activity is an innovative, experiential tool to deepen students understanding of issues relating to ageing. The interprofessional nature of the activity is an important factor in the success of the day, and produces a wide range of shared insights. The activity also enhances the partnerships between the university, the health service and the local community. Our experience supports the value of simulation in providing a deep learning opportunity in the area of ageing and disability. © 2016 John Wiley & Sons Ltd.",2016,2021-05-19T13:26:39Z,2021-05-19T13:26:39Z,,107-111,5,2,13,,,,,,,,,,English,,,,,,,Publisher: Blackwell Publishing Ltd,<p>cited By 8</p>,,,aging; Aging; education; health care personnel; Health Personnel; human; Humans; Interprofessional Relations; learning; Learning; Mobility Limitation; New South Wales; program evaluation; Program Evaluation; psychology; public relations; walking difficulty,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Appearance of a robot affects the impact of its behaviour on perceived trustworthiness and empathy,27,"Złotowski, J.; Sumioka, H.; Nishio, S.; Glas, D.F.; Bartneck, C.; Ishiguro, H.",Paladyn,2016,journalArticle,,20814836,10.1515/pjbr-2016-0005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018414278&doi=10.1515%2fpjbr-2016-0005&partnerID=40&md5=8b9b98387e70b4e30a81762b413ddb88,"An increasing number of companion robots have started reaching the public in the recent years. These robots vary in their appearance and behavior. Since these two factors can have an impact on lasting human-robot relationships, it is important to understand their effect for companion robots. We have conducted an experiment that evaluated the impact of a robot's appearance and its behaviour in repeated interactions on its perceived empathy, trustworthiness and anxiety experienced by a human. The results indicate that a highly humanlike robot is perceived as less trustworthy and empathic than a more machinelike robot. Moreover, negative behaviour of a machinelike robot reduces its trustworthiness and perceived empathy stronger than for highly humanlike robot. In addition, we found that a robot which disapproves of what a human says can induce anxiety felt towards its communication capabilities. Our findings suggest that more machinelike robots can be more suitable as companions than highly humanlike robots. Moreover, a robot disagreeing with a human interaction partner should be able to provide feedback on its understanding of the partner's message in order to reduce her anxiety. © 2016 Jakub Złotowski et al., published by De Gruyter Open.",2016,2021-05-19T13:26:39Z,2021-05-19T13:26:39Z,,55-66,12,1,7,,,,,,,,,,English,,,,,,,Publisher: De Gruyter Open Ltd,<p>cited By 13</p>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Leveling up: Strategies to achieve integrated cognitive architectures,1,"Silvey, P.E.",AAAI Fall Symposium - Technical Report,2017,Technical Report,978-1-57735-794-0,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044476959&partnerID=40&md5=09dc018b9aa3ed3c09f13c6428cf44b4,"Human-level cognition (most uniquely characterized by our abilities to use language) should be seen as a superset of functional and behavioral capabilities shared by lower life-forms including animals and insects, and this perspective ought to principally guide our strategies for developing integrated cognitive architectures. Just as the study of biological model organisms has led to tremendous advances in our scientific knowledge of genetics and cellular function, the study of embodied cognition in simple agent-environment simulations can yield similar advances in Cognitive Science, Artificial Intelligence, and Robotics. By working first on the foundations of intelligent interaction with one's environment, and by focusing on core functions such as predictive and inductive learning, probabilistic goal-directed behavior compilation, and empathetic reasoning, we can better establish the grounding that the physical symbol system hypothesis assumes (Newell and Simon 1976), yet often without explicit demonstration of a mechanism to derive symbolic relations and semantics from raw sensory data. Logic and language are seen to emerge from our willingness to make discrete simplifying assumptions in a continuous and probabilistic world of experience, and developing a Standard Model of the Mind can help build much-needed bridges between historically nonaligned research communities. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",2017,2021-05-19T13:26:36Z,2021-05-19T13:26:36Z,,460-465,6,,FS-17-01 - FS-17-05,,,,,,,,AI Access Foundation,,English,,,,,,,,<p>cited By 0; Conference of 2017 AAAI Fall Symposium ; Conference Date: 9 November 2017 Through 11 November 2017; Conference Code:134706</p>,,,Artificial intelligence; Bioinformatics; Biological modeling; Cognitive architectures; Cognitive systems; Environment simulation; Human robot interaction; Intelligent interactions; Intelligent robots; Military applications; Probabilistic goals; Public risks; Research communities; Scientific knowledge; Semantics; Simplifying assumptions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Towards the synthetic self: making others perceive me as an other,21,"Lallee, Stephane; Vouloutsi, Vasiliki; Munoz, Maria Blancas; Grechuta, Klaudia; Llobet, Jordi-Ysard Puigbo; Sarda, Marina; Verschure, Paul F. M. J.","Paladyn, Journal of Behavioral Robotics",2015,journalArticle,,2081-4836,10.1515/pjbr-2015-0010,http://www.degruyter.com/document/doi/10.1515/pjbr-2015-0010/html,"Future applications of robotic technologies will involve interactions with non-expert humans as machines will assume the role of companions, teachers or healthcare assistants. In all those tasks social behavior is a key ability that needs to be systematically investigated and modelled at the lowest level, as even a minor inconsistency of the robot’s behavior can greatly affect the way humans will perceive it and react to it. Here we propose an integrated architecture for generating a socially competent robot.We validate our architecture using a humanoid robot, demonstrating that gaze, eye contact and utilitarian emotions play an essential role in the psychological validity or social salience of Human-Robot Interaction (HRI). We show that this social salience affects both the empathic bonding between the human and a humanoid robot and, to a certain extent, the attribution of a Theory of Mind (ToM). More specifically, we investigate whether these social cues affect other utilitarian aspects of the interaction such as knowledge transfer within a teaching context.",2015-07-20,2021-08-16 12:08:25,2021-08-16 12:08:25,2021-08-16 12:08:09,,,1,6,,,Towards the synthetic self,,,,,,,en,,,,,www-degruyter-com.ez.statsbiblioteket.dk:12048,,"Publisher: De Gruyter Open Access Section: Paladyn, Journal of Behavioral Robotics",,C:\Users\esben\Zotero\storage\4772J84H\Lallee et al. - 2015 - Towards the synthetic self making others perceive.pdf; C:\Users\esben\Zotero\storage\Z8X7JVQK\html.html,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Public professionalism in an era of radical transformations: its meaning, challenges, and training",1,"Stillman, Richard",Revista de Administração Pública,2017,journalArticle,,"0034-7612, 1982-3134",10.1590/0034-761220170333,http://www.scielo.br/j/rap/a/98Mr3JrVYMxptD7YsBRf3vK/?lang=en,,2017-12,2021-08-16 12:09:04,2021-08-16 12:09:04,2021-08-16 12:08:57,917-926,,,51,,Rev. Adm. Pública,Public professionalism in an era of radical transformations,,,,,,,en,,,,,SciELO,,Publisher: Fundação Getulio Vargas,,C:\Users\esben\Zotero\storage\7AAZJ2UP\Stillman - 2017 - Public professionalism in an era of radical transf.pdf; C:\Users\esben\Zotero\storage\CMPFII9C\98Mr3JrVYMxptD7YsBRf3vK.html,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,